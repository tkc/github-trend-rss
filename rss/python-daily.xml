<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Wed, 23 Jul 2025 00:04:54 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[roboflow/supervision]]></title>
            <link>https://github.com/roboflow/supervision</link>
            <guid>https://github.com/roboflow/supervision</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:54 GMT</pubDate>
            <description><![CDATA[We write your reusable computer vision tools. ğŸ’œ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/roboflow/supervision">roboflow/supervision</a></h1>
            <p>We write your reusable computer vision tools. ğŸ’œ</p>
            <p>Language: Python</p>
            <p>Stars: 29,417</p>
            <p>Forks: 2,311</p>
            <p>Stars today: 676 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;p&gt;
    &lt;a align=&quot;center&quot; href=&quot;&quot; target=&quot;https://supervision.roboflow.com&quot;&gt;
      &lt;img
        width=&quot;100%&quot;
        src=&quot;https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529&quot;
      &gt;
    &lt;/a&gt;
  &lt;/p&gt;

&lt;br&gt;

[notebooks](https://github.com/roboflow/notebooks) | [inference](https://github.com/roboflow/inference) | [autodistill](https://github.com/autodistill/autodistill) | [maestro](https://github.com/roboflow/multimodal-maestro)

&lt;br&gt;

[![version](https://badge.fury.io/py/supervision.svg)](https://badge.fury.io/py/supervision)
[![downloads](https://img.shields.io/pypi/dm/supervision)](https://pypistats.org/packages/supervision)
[![snyk](https://snyk.io/advisor/python/supervision/badge.svg)](https://snyk.io/advisor/python/supervision)
[![license](https://img.shields.io/pypi/l/supervision)](https://github.com/roboflow/supervision/blob/main/LICENSE.md)
[![python-version](https://img.shields.io/pypi/pyversions/supervision)](https://badge.fury.io/py/supervision)
[![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb)
[![gradio](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/Roboflow/Annotators)
[![discord](https://img.shields.io/discord/1159501506232451173?logo=discord&amp;label=discord&amp;labelColor=fff&amp;color=5865f2&amp;link=https%3A%2F%2Fdiscord.gg%2FGbfgXGJ8Bk)](https://discord.gg/GbfgXGJ8Bk)
[![built-with-material-for-mkdocs](https://img.shields.io/badge/Material_for_MkDocs-526CFE?logo=MaterialForMkDocs&amp;logoColor=white)](https://squidfunk.github.io/mkdocs-material/)

  &lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/124&quot;  target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/124&quot; alt=&quot;roboflow%2Fsupervision | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
  &lt;/div&gt;

&lt;/div&gt;

## ğŸ‘‹ hello

**We write your reusable computer vision tools.** Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! ğŸ¤

## ğŸ’» install

Pip install the supervision package in a
[**Python&gt;=3.9**](https://www.python.org/) environment.

```bash
pip install supervision
```

Read more about conda, mamba, and installing from source in our [guide](https://roboflow.github.io/supervision/).

## ğŸ”¥ quickstart

### models

Supervision was designed to be model agnostic. Just plug in any classification, detection, or segmentation model. For your convenience, we have created [connectors](https://supervision.roboflow.com/latest/detection/core/#detections) for the most popular libraries like Ultralytics, Transformers, or MMDetection.

```python
import cv2
import supervision as sv
from ultralytics import YOLO

image = cv2.imread(...)
model = YOLO(&quot;yolov8s.pt&quot;)
result = model(image)[0]
detections = sv.Detections.from_ultralytics(result)

len(detections)
# 5
```

&lt;details&gt;
&lt;summary&gt;ğŸ‘‰ more model connectors&lt;/summary&gt;

- inference

  Running with [Inference](https://github.com/roboflow/inference) requires a [Roboflow API KEY](https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key).

  ```python
  import cv2
  import supervision as sv
  from inference import get_model

  image = cv2.imread(...)
  model = get_model(model_id=&quot;yolov8s-640&quot;, api_key=&lt;ROBOFLOW API KEY&gt;)
  result = model.infer(image)[0]
  detections = sv.Detections.from_inference(result)

  len(detections)
  # 5
  ```

&lt;/details&gt;

### annotators

Supervision offers a wide range of highly customizable [annotators](https://supervision.roboflow.com/latest/detection/annotators/), allowing you to compose the perfect visualization for your use case.

```python
import cv2
import supervision as sv

image = cv2.imread(...)
detections = sv.Detections(...)

box_annotator = sv.BoxAnnotator()
annotated_frame = box_annotator.annotate(
  scene=image.copy(),
  detections=detections)
```

https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce

### datasets

Supervision provides a set of [utils](https://supervision.roboflow.com/latest/datasets/core/) that allow you to load, split, merge, and save datasets in one of the supported formats.

```python
import supervision as sv
from roboflow import Roboflow

project = Roboflow().workspace(&lt;WORKSPACE_ID&gt;).project(&lt;PROJECT_ID&gt;)
dataset = project.version(&lt;PROJECT_VERSION&gt;).download(&quot;coco&quot;)

ds = sv.DetectionDataset.from_coco(
    images_directory_path=f&quot;{dataset.location}/train&quot;,
    annotations_path=f&quot;{dataset.location}/train/_annotations.coco.json&quot;,
)

path, image, annotation = ds[0]
    # loads image on demand

for path, image, annotation in ds:
    # loads image on demand
```

&lt;details close&gt;
&lt;summary&gt;ğŸ‘‰ more dataset utils&lt;/summary&gt;

- load

  ```python
  dataset = sv.DetectionDataset.from_yolo(
      images_directory_path=...,
      annotations_directory_path=...,
      data_yaml_path=...
  )

  dataset = sv.DetectionDataset.from_pascal_voc(
      images_directory_path=...,
      annotations_directory_path=...
  )

  dataset = sv.DetectionDataset.from_coco(
      images_directory_path=...,
      annotations_path=...
  )
  ```

- split

  ```python
  train_dataset, test_dataset = dataset.split(split_ratio=0.7)
  test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)

  len(train_dataset), len(test_dataset), len(valid_dataset)
  # (700, 150, 150)
  ```

- merge

  ```python
  ds_1 = sv.DetectionDataset(...)
  len(ds_1)
  # 100
  ds_1.classes
  # [&#039;dog&#039;, &#039;person&#039;]

  ds_2 = sv.DetectionDataset(...)
  len(ds_2)
  # 200
  ds_2.classes
  # [&#039;cat&#039;]

  ds_merged = sv.DetectionDataset.merge([ds_1, ds_2])
  len(ds_merged)
  # 300
  ds_merged.classes
  # [&#039;cat&#039;, &#039;dog&#039;, &#039;person&#039;]
  ```

- save

  ```python
  dataset.as_yolo(
      images_directory_path=...,
      annotations_directory_path=...,
      data_yaml_path=...
  )

  dataset.as_pascal_voc(
      images_directory_path=...,
      annotations_directory_path=...
  )

  dataset.as_coco(
      images_directory_path=...,
      annotations_path=...
  )
  ```

- convert

  ```python
  sv.DetectionDataset.from_yolo(
      images_directory_path=...,
      annotations_directory_path=...,
      data_yaml_path=...
  ).as_pascal_voc(
      images_directory_path=...,
      annotations_directory_path=...
  )
  ```

&lt;/details&gt;

## ğŸ¬ tutorials

Want to learn how to use Supervision? Explore our [how-to guides](https://supervision.roboflow.com/develop/how_to/detect_and_annotate/), [end-to-end examples](https://github.com/roboflow/supervision/tree/develop/examples), [cheatsheet](https://roboflow.github.io/cheatsheet-supervision/), and [cookbooks](https://supervision.roboflow.com/develop/cookbooks/)!

&lt;br/&gt;

&lt;p align=&quot;left&quot;&gt;
&lt;a href=&quot;https://youtu.be/hAWpsIuem10&quot; title=&quot;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&quot;&gt;&lt;img src=&quot;https://github.com/SkalskiP/SkalskiP/assets/26109316/a742823d-c158-407d-b30f-063a5d11b4e1&quot; alt=&quot;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&quot; width=&quot;300px&quot; align=&quot;left&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://youtu.be/hAWpsIuem10&quot; title=&quot;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&quot;&gt;&lt;strong&gt;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&lt;/strong&gt;&lt;/a&gt;
&lt;div&gt;&lt;strong&gt;Created: 5 Apr 2024&lt;/strong&gt;&lt;/div&gt;
&lt;br/&gt;Learn how to use computer vision to analyze wait times and optimize processes. This tutorial covers object detection, tracking, and calculating time spent in designated zones. Use these techniques to improve customer experience in retail, traffic management, or other scenarios.&lt;/p&gt;

&lt;br/&gt;

&lt;p align=&quot;left&quot;&gt;
&lt;a href=&quot;https://youtu.be/uWP6UjDeZvY&quot; title=&quot;Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source&quot;&gt;&lt;img src=&quot;https://github.com/SkalskiP/SkalskiP/assets/26109316/61a444c8-b135-48ce-b979-2a5ab47c5a91&quot; alt=&quot;Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source&quot; width=&quot;300px&quot; align=&quot;left&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://youtu.be/uWP6UjDeZvY&quot; title=&quot;Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source&quot;&gt;&lt;strong&gt;Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source&lt;/strong&gt;&lt;/a&gt;
&lt;div&gt;&lt;strong&gt;Created: 11 Jan 2024&lt;/strong&gt;&lt;/div&gt;
&lt;br/&gt;Learn how to track and estimate the speed of vehicles using YOLO, ByteTrack, and Roboflow Inference. This comprehensive tutorial covers object detection, multi-object tracking, filtering detections, perspective transformation, speed estimation, visualization improvements, and more.&lt;/p&gt;

## ğŸ’œ built with supervision

Did you build something cool using supervision? [Let us know!](https://github.com/roboflow/supervision/discussions/categories/built-with-supervision)

https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4

https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900

https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f

## ğŸ“š documentation

Visit our [documentation](https://roboflow.github.io/supervision) page to learn how supervision can help you build computer vision applications faster and more reliably.

## ğŸ† contribution

We love your input! Please see our [contributing guide](https://github.com/roboflow/supervision/blob/main/CONTRIBUTING.md) to get started. Thank you ğŸ™ to all our contributors!

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/roboflow/supervision/graphs/contributors&quot;&gt;
      &lt;img src=&quot;https://contrib.rocks/image?repo=roboflow/supervision&quot; /&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;br&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;div align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://youtube.com/roboflow&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/youtube.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949634652&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://roboflow.com&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/roboflow-app.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949746649&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://www.linkedin.com/company/roboflow-ai/&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/linkedin.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949633691&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://docs.roboflow.com&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/knowledge.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949634511&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://discuss.roboflow.com&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/forum.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949633584&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://blog.roboflow.com&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/blog.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949633605&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[unclecode/crawl4ai]]></title>
            <link>https://github.com/unclecode/crawl4ai</link>
            <guid>https://github.com/unclecode/crawl4ai</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:53 GMT</pubDate>
            <description><![CDATA[ğŸš€ğŸ¤– Crawl4AI: Open-source LLM Friendly Web Crawler & Scraper. Don't be shy, join here: https://discord.gg/jP8KfhDhyN]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/unclecode/crawl4ai">unclecode/crawl4ai</a></h1>
            <p>ğŸš€ğŸ¤– Crawl4AI: Open-source LLM Friendly Web Crawler & Scraper. Don't be shy, join here: https://discord.gg/jP8KfhDhyN</p>
            <p>Language: Python</p>
            <p>Stars: 49,179</p>
            <p>Forks: 4,764</p>
            <p>Stars today: 426 stars today</p>
            <h2>README</h2><pre># ğŸš€ğŸ¤– Crawl4AI: Open-source LLM Friendly Web Crawler &amp; Scraper.

&lt;div align=&quot;center&quot;&gt;

&lt;a href=&quot;https://trendshift.io/repositories/11716&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/11716&quot; alt=&quot;unclecode%2Fcrawl4ai | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

[![GitHub Stars](https://img.shields.io/github/stars/unclecode/crawl4ai?style=social)](https://github.com/unclecode/crawl4ai/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/unclecode/crawl4ai?style=social)](https://github.com/unclecode/crawl4ai/network/members)

[![PyPI version](https://badge.fury.io/py/crawl4ai.svg)](https://badge.fury.io/py/crawl4ai)
[![Python Version](https://img.shields.io/pypi/pyversions/crawl4ai)](https://pypi.org/project/crawl4ai/)
[![Downloads](https://static.pepy.tech/badge/crawl4ai/month)](https://pepy.tech/project/crawl4ai)

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://x.com/crawl4ai&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Follow%20on%20X-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white&quot; alt=&quot;Follow on X&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://www.linkedin.com/company/crawl4ai&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Follow%20on%20LinkedIn-0077B5?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white&quot; alt=&quot;Follow on LinkedIn&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/jP8KfhDhyN&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Join%20our%20Discord-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;Join our Discord&quot; /&gt;
    &lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

Crawl4AI is the #1 trending GitHub repository, actively maintained by a vibrant community. It delivers blazing-fast, AI-ready web crawling tailored for LLMs, AI agents, and data pipelines. Open source, flexible, and built for real-time performance, Crawl4AI empowers developers with unmatched speed, precision, and deployment ease.  

[âœ¨ Check out latest update v0.7.0](#-recent-updates)

ğŸ‰ **Version 0.7.0 is now available!** The Adaptive Intelligence Update introduces groundbreaking features: Adaptive Crawling that learns website patterns, Virtual Scroll support for infinite pages, intelligent Link Preview with 3-layer scoring, Async URL Seeder for massive discovery, and significant performance improvements. [Read the release notes â†’](https://docs.crawl4ai.com/blog/release-v0.7.0)

&lt;details&gt;
&lt;summary&gt;ğŸ¤“ &lt;strong&gt;My Personal Story&lt;/strong&gt;&lt;/summary&gt;

My journey with computers started in childhood when my dad, a computer scientist, introduced me to an Amstrad computer. Those early days sparked a fascination with technology, leading me to pursue computer science and specialize in NLP during my postgraduate studies. It was during this time that I first delved into web crawling, building tools to help researchers organize papers and extract information from publications a challenging yet rewarding experience that honed my skills in data extraction.

Fast forward to 2023, I was working on a tool for a project and needed a crawler to convert a webpage into markdown. While exploring solutions, I found one that claimed to be open-source but required creating an account and generating an API token. Worse, it turned out to be a SaaS model charging $16, and its quality didnâ€™t meet my standards. Frustrated, I realized this was a deeper problem. That frustration turned into turbo anger mode, and I decided to build my own solution. In just a few days, I created Crawl4AI. To my surprise, it went viral, earning thousands of GitHub stars and resonating with a global community.

I made Crawl4AI open-source for two reasons. First, itâ€™s my way of giving back to the open-source community that has supported me throughout my career. Second, I believe data should be accessible to everyone, not locked behind paywalls or monopolized by a few. Open access to data lays the foundation for the democratization of AI, a vision where individuals can train their own models and take ownership of their information. This library is the first step in a larger journey to create the best open-source data extraction and generation tool the world has ever seen, built collaboratively by a passionate community.

Thank you to everyone who has supported this project, used it, and shared feedback. Your encouragement motivates me to dream even bigger. Join us, file issues, submit PRs, or spread the word. Together, we can build a tool that truly empowers people to access their own data and reshape the future of AI.
&lt;/details&gt;

## ğŸ§ Why Crawl4AI?

1. **Built for LLMs**: Creates smart, concise Markdown optimized for RAG and fine-tuning applications.  
2. **Lightning Fast**: Delivers results 6x faster with real-time, cost-efficient performance.  
3. **Flexible Browser Control**: Offers session management, proxies, and custom hooks for seamless data access.  
4. **Heuristic Intelligence**: Uses advanced algorithms for efficient extraction, reducing reliance on costly models.  
5. **Open Source &amp; Deployable**: Fully open-source with no API keysâ€”ready for Docker and cloud integration.  
6. **Thriving Community**: Actively maintained by a vibrant community and the #1 trending GitHub repository.

## ğŸš€ Quick Start 

1. Install Crawl4AI:
```bash
# Install the package
pip install -U crawl4ai

# For pre release versions
pip install crawl4ai --pre

# Run post-installation setup
crawl4ai-setup

# Verify your installation
crawl4ai-doctor
```

If you encounter any browser-related issues, you can install them manually:
```bash
python -m playwright install --with-deps chromium
```

2. Run a simple web crawl with Python:
```python
import asyncio
from crawl4ai import *

async def main():
    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(
            url=&quot;https://www.nbcnews.com/business&quot;,
        )
        print(result.markdown)

if __name__ == &quot;__main__&quot;:
    asyncio.run(main())
```

3. Or use the new command-line interface:
```bash
# Basic crawl with markdown output
crwl https://www.nbcnews.com/business -o markdown

# Deep crawl with BFS strategy, max 10 pages
crwl https://docs.crawl4ai.com --deep-crawl bfs --max-pages 10

# Use LLM extraction with a specific question
crwl https://www.example.com/products -q &quot;Extract all product prices&quot;
```

## âœ¨ Features 

&lt;details&gt;
&lt;summary&gt;ğŸ“ &lt;strong&gt;Markdown Generation&lt;/strong&gt;&lt;/summary&gt;

- ğŸ§¹ **Clean Markdown**: Generates clean, structured Markdown with accurate formatting.
- ğŸ¯ **Fit Markdown**: Heuristic-based filtering to remove noise and irrelevant parts for AI-friendly processing.
- ğŸ”— **Citations and References**: Converts page links into a numbered reference list with clean citations.
- ğŸ› ï¸ **Custom Strategies**: Users can create their own Markdown generation strategies tailored to specific needs.
- ğŸ“š **BM25 Algorithm**: Employs BM25-based filtering for extracting core information and removing irrelevant content. 
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ğŸ“Š &lt;strong&gt;Structured Data Extraction&lt;/strong&gt;&lt;/summary&gt;

- ğŸ¤– **LLM-Driven Extraction**: Supports all LLMs (open-source and proprietary) for structured data extraction.
- ğŸ§± **Chunking Strategies**: Implements chunking (topic-based, regex, sentence-level) for targeted content processing.
- ğŸŒŒ **Cosine Similarity**: Find relevant content chunks based on user queries for semantic extraction.
- ğŸ” **CSS-Based Extraction**: Fast schema-based data extraction using XPath and CSS selectors.
- ğŸ”§ **Schema Definition**: Define custom schemas for extracting structured JSON from repetitive patterns.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ğŸŒ &lt;strong&gt;Browser Integration&lt;/strong&gt;&lt;/summary&gt;

- ğŸ–¥ï¸ **Managed Browser**: Use user-owned browsers with full control, avoiding bot detection.
- ğŸ”„ **Remote Browser Control**: Connect to Chrome Developer Tools Protocol for remote, large-scale data extraction.
- ğŸ‘¤ **Browser Profiler**: Create and manage persistent profiles with saved authentication states, cookies, and settings.
- ğŸ”’ **Session Management**: Preserve browser states and reuse them for multi-step crawling.
- ğŸ§© **Proxy Support**: Seamlessly connect to proxies with authentication for secure access.
- âš™ï¸ **Full Browser Control**: Modify headers, cookies, user agents, and more for tailored crawling setups.
- ğŸŒ **Multi-Browser Support**: Compatible with Chromium, Firefox, and WebKit.
- ğŸ“ **Dynamic Viewport Adjustment**: Automatically adjusts the browser viewport to match page content, ensuring complete rendering and capturing of all elements.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ğŸ” &lt;strong&gt;Crawling &amp; Scraping&lt;/strong&gt;&lt;/summary&gt;

- ğŸ–¼ï¸ **Media Support**: Extract images, audio, videos, and responsive image formats like `srcset` and `picture`.
- ğŸš€ **Dynamic Crawling**: Execute JS and wait for async or sync for dynamic content extraction.
- ğŸ“¸ **Screenshots**: Capture page screenshots during crawling for debugging or analysis.
- ğŸ“‚ **Raw Data Crawling**: Directly process raw HTML (`raw:`) or local files (`file://`).
- ğŸ”— **Comprehensive Link Extraction**: Extracts internal, external links, and embedded iframe content.
- ğŸ› ï¸ **Customizable Hooks**: Define hooks at every step to customize crawling behavior.
- ğŸ’¾ **Caching**: Cache data for improved speed and to avoid redundant fetches.
- ğŸ“„ **Metadata Extraction**: Retrieve structured metadata from web pages.
- ğŸ“¡ **IFrame Content Extraction**: Seamless extraction from embedded iframe content.
- ğŸ•µï¸ **Lazy Load Handling**: Waits for images to fully load, ensuring no content is missed due to lazy loading.
- ğŸ”„ **Full-Page Scanning**: Simulates scrolling to load and capture all dynamic content, perfect for infinite scroll pages.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ğŸš€ &lt;strong&gt;Deployment&lt;/strong&gt;&lt;/summary&gt;

- ğŸ³ **Dockerized Setup**: Optimized Docker image with FastAPI server for easy deployment.
- ğŸ”‘ **Secure Authentication**: Built-in JWT token authentication for API security.
- ğŸ”„ **API Gateway**: One-click deployment with secure token authentication for API-based workflows.
- ğŸŒ **Scalable Architecture**: Designed for mass-scale production and optimized server performance.
- â˜ï¸ **Cloud Deployment**: Ready-to-deploy configurations for major cloud platforms.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ğŸ¯ &lt;strong&gt;Additional Features&lt;/strong&gt;&lt;/summary&gt;

- ğŸ•¶ï¸ **Stealth Mode**: Avoid bot detection by mimicking real users.
- ğŸ·ï¸ **Tag-Based Content Extraction**: Refine crawling based on custom tags, headers, or metadata.
- ğŸ”— **Link Analysis**: Extract and analyze all links for detailed data exploration.
- ğŸ›¡ï¸ **Error Handling**: Robust error management for seamless execution.
- ğŸ” **CORS &amp; Static Serving**: Supports filesystem-based caching and cross-origin requests.
- ğŸ“– **Clear Documentation**: Simplified and updated guides for onboarding and advanced usage.
- ğŸ™Œ **Community Recognition**: Acknowledges contributors and pull requests for transparency.

&lt;/details&gt;

## Try it Now!

âœ¨ Play around with this [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1SgRPrByQLzjRfwoRNq1wSGE9nYY_EE8C?usp=sharing)

âœ¨ Visit our [Documentation Website](https://docs.crawl4ai.com/)

## Installation ğŸ› ï¸

Crawl4AI offers flexible installation options to suit various use cases. You can install it as a Python package or use Docker.

&lt;details&gt;
&lt;summary&gt;ğŸ &lt;strong&gt;Using pip&lt;/strong&gt;&lt;/summary&gt;

Choose the installation option that best fits your needs:

### Basic Installation

For basic web crawling and scraping tasks:

```bash
pip install crawl4ai
crawl4ai-setup # Setup the browser
```

By default, this will install the asynchronous version of Crawl4AI, using Playwright for web crawling.

ğŸ‘‰ **Note**: When you install Crawl4AI, the `crawl4ai-setup` should automatically install and set up Playwright. However, if you encounter any Playwright-related errors, you can manually install it using one of these methods:

1. Through the command line:

   ```bash
   playwright install
   ```

2. If the above doesn&#039;t work, try this more specific command:

   ```bash
   python -m playwright install chromium
   ```

This second method has proven to be more reliable in some cases.

---

### Installation with Synchronous Version

The sync version is deprecated and will be removed in future versions. If you need the synchronous version using Selenium:

```bash
pip install crawl4ai[sync]
```

---

### Development Installation

For contributors who plan to modify the source code:

```bash
git clone https://github.com/unclecode/crawl4ai.git
cd crawl4ai
pip install -e .                    # Basic installation in editable mode
```

Install optional features:

```bash
pip install -e &quot;.[torch]&quot;           # With PyTorch features
pip install -e &quot;.[transformer]&quot;     # With Transformer features
pip install -e &quot;.[cosine]&quot;          # With cosine similarity features
pip install -e &quot;.[sync]&quot;            # With synchronous crawling (Selenium)
pip install -e &quot;.[all]&quot;             # Install all optional features
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ğŸ³ &lt;strong&gt;Docker Deployment&lt;/strong&gt;&lt;/summary&gt;

&gt; ğŸš€ **Now Available!** Our completely redesigned Docker implementation is here! This new solution makes deployment more efficient and seamless than ever.

### New Docker Features

The new Docker implementation includes:
- **Browser pooling** with page pre-warming for faster response times
- **Interactive playground** to test and generate request code
- **MCP integration** for direct connection to AI tools like Claude Code
- **Comprehensive API endpoints** including HTML extraction, screenshots, PDF generation, and JavaScript execution
- **Multi-architecture support** with automatic detection (AMD64/ARM64)
- **Optimized resources** with improved memory management

### Getting Started

```bash
# Pull and run the latest release candidate
docker pull unclecode/crawl4ai:0.7.0
docker run -d -p 11235:11235 --name crawl4ai --shm-size=1g unclecode/crawl4ai:0.7.0

# Visit the playground at http://localhost:11235/playground
```

For complete documentation, see our [Docker Deployment Guide](https://docs.crawl4ai.com/core/docker-deployment/).

&lt;/details&gt;

---

### Quick Test

Run a quick test (works for both Docker options):

```python
import requests

# Submit a crawl job
response = requests.post(
    &quot;http://localhost:11235/crawl&quot;,
    json={&quot;urls&quot;: [&quot;https://example.com&quot;], &quot;priority&quot;: 10}
)
if response.status_code == 200:
    print(&quot;Crawl job submitted successfully.&quot;)
    
if &quot;results&quot; in response.json():
    results = response.json()[&quot;results&quot;]
    print(&quot;Crawl job completed. Results:&quot;)
    for result in results:
        print(result)
else:
    task_id = response.json()[&quot;task_id&quot;]
    print(f&quot;Crawl job submitted. Task ID:: {task_id}&quot;)
    result = requests.get(f&quot;http://localhost:11235/task/{task_id}&quot;)
```

For more examples, see our [Docker Examples](https://github.com/unclecode/crawl4ai/blob/main/docs/examples/docker_example.py). For advanced configuration, environment variables, and usage examples, see our [Docker Deployment Guide](https://docs.crawl4ai.com/basic/docker-deployment/).

&lt;/details&gt;


## ğŸ”¬ Advanced Usage Examples ğŸ”¬

You can check the project structure in the directory [https://github.com/unclecode/crawl4ai/docs/examples](docs/examples). Over there, you can find a variety of examples; here, some popular examples are shared.

&lt;details&gt;
&lt;summary&gt;ğŸ“ &lt;strong&gt;Heuristic Markdown Generation with Clean and Fit Markdown&lt;/strong&gt;&lt;/summary&gt;

```python
import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode
from crawl4ai.content_filter_strategy import PruningContentFilter, BM25ContentFilter
from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator

async def main():
    browser_config = BrowserConfig(
        headless=True,  
        verbose=True,
    )
    run_config = CrawlerRunConfig(
        cache_mode=CacheMode.ENABLED,
        markdown_generator=DefaultMarkdownGenerator(
            content_filter=PruningContentFilter(threshold=0.48, threshold_type=&quot;fixed&quot;, min_word_threshold=0)
        ),
        # markdown_generator=DefaultMarkdownGenerator(
        #     content_filter=BM25ContentFilter(user_query=&quot;WHEN_WE_FOCUS_BASED_ON_A_USER_QUERY&quot;, bm25_threshold=1.0)
        # ),
    )
    
    async with AsyncWebCrawler(config=browser_config) as crawler:
        result = await crawler.arun(
            url=&quot;https://docs.micronaut.io/4.7.6/guide/&quot;,
            config=run_config
        )
        print(len(result.markdown.raw_markdown))
        print(len(result.markdown.fit_markdown))

if __name__ == &quot;__main__&quot;:
    asyncio.run(main())
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ğŸ–¥ï¸ &lt;strong&gt;Executing JavaScript &amp; Extract Structured Data without LLMs&lt;/strong&gt;&lt;/summary&gt;

```python
import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode
from crawl4ai import JsonCssExtractionStrategy
import json

async def main():
    schema = {
    &quot;name&quot;: &quot;KidoCode Courses&quot;,
    &quot;baseSelector&quot;: &quot;section.charge-methodology .w-tab-content &gt; div&quot;,
    &quot;fields&quot;: [
        {
            &quot;name&quot;: &quot;section_title&quot;,
            &quot;selector&quot;: &quot;h3.heading-50&quot;,
            &quot;type&quot;: &quot;text&quot;,
        },
        {
            &quot;name&quot;: &quot;section_description&quot;,
            &quot;selector&quot;: &quot;.charge-content&quot;,
            &quot;type&quot;: &quot;text&quot;,
        },
        {
            &quot;name&quot;: &quot;course_name&quot;,
            &quot;selector&quot;: &quot;.text-block-93&quot;,
            &quot;type&quot;: &quot;text&quot;,
        },
        {
            &quot;name&quot;: &quot;course_description&quot;,
            &quot;selector&quot;: &quot;.course-content-text&quot;,
            &quot;type&quot;: &quot;text&quot;,
        },
        {
            &quot;name&quot;: &quot;course_icon&quot;,
            &quot;selector&quot;: &quot;.image-92&quot;,
            &quot;type&quot;: &quot;attribute&quot;,
            &quot;attribute&quot;: &quot;src&quot;
        }
    }
}

    extraction_strategy = JsonCssExtractionStrategy(schema, verbose=True)

    browser_config = BrowserConfig(
        headless=False,
        verbose=True
    )
    run_config = CrawlerRunConfig(
        extraction_strategy=extraction_strategy,
        js_code=[&quot;&quot;&quot;(async () =&gt; {const tabs = document.querySelectorAll(&quot;section.charge-methodology .tabs-menu-3 &gt; div&quot;);for(let tab of tabs) {tab.scrollIntoView();tab.click();await new Promise(r =&gt; setTimeout(r, 500));}})();&quot;&quot;&quot;],
        cache_mode=CacheMode.BYPASS
    )
        
    async with AsyncWebCrawler(config=browser_config) as crawler:
        
        result = await crawler.arun(
            url=&quot;https://www.kidocode.com/degrees/technology&quot;,
            config=run_config
        )

        companies = json.loads(result.extracted_content)
        print(f&quot;Successfully extracted {len(companies)} companies&quot;)
        print(json.dumps(companies[0], indent=2))


if __name__ == &quot;__main__&quot;:
    asyncio.run(main())
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ğŸ“š &lt;strong&gt;Extracting Structured Data with LLMs&lt;/strong&gt;&lt;/summary&gt;

```python
import os
import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode, LLMConfig
from crawl4ai import LLMExtractionStrategy
from pydantic import BaseModel, Field

class OpenAIModelFee(BaseModel):
    model_name: str = Field(..., description=&quot;Name of the OpenAI model.&quot;)
    input_fee: str = Field(..., description=&quot;Fee for input token for the OpenAI model.&quot;)
    output_fee: str = Field(..., description=&quot;Fee for output token for the OpenAI model.&quot;)

async def main():
    browser_config = BrowserConfig(verbose=True)
    run_config = CrawlerRunConfig(
        word_count_threshold=1,
        extraction_strategy=LLMExtractionStrategy(
            # Here you can use any provider that Litellm library supports, for instance: ollama/qwen2
            # provider=&quot;ollama/qwen2&quot;, api_token=&quot;no-token&quot;, 
            llm_config = LLMConfig(provider=&quot;openai/gpt-4o&quot;, api_token=os.getenv(&#039;OPENAI_API_KEY&#039;)), 
            schema=OpenAIModelFee.schema(),
            extraction_type=&quot;schema&quot;,
            instruction=&quot;&quot;&quot;From the crawled content, extract all mentioned model names along with their fees for input and output tokens. 
            Do not miss any models in the entire content. One

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[p1ngul1n0/blackbird]]></title>
            <link>https://github.com/p1ngul1n0/blackbird</link>
            <guid>https://github.com/p1ngul1n0/blackbird</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:52 GMT</pubDate>
            <description><![CDATA[An OSINT tool to search for accounts by username and email in social networks.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/p1ngul1n0/blackbird">p1ngul1n0/blackbird</a></h1>
            <p>An OSINT tool to search for accounts by username and email in social networks.</p>
            <p>Language: Python</p>
            <p>Stars: 4,023</p>
            <p>Forks: 485</p>
            <p>Stars today: 119 stars today</p>
            <h2>README</h2><pre># Blackbird

&lt;figure&gt;&lt;img src=&quot;./docs/.gitbook/assets/ai-demo.png&quot; alt=&quot;&quot;&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&gt; Blackbird is a powerful OSINT tool that combines fast username and email searches across more than 600 platforms with free AI-powered profiling. By leveraging community-driven projects like WhatsMyName, it ensures low false positive rates and high-quality results. Features include smart filters, polished PDF/CSV exports, and fully automated analysis â€” all from a single CLI.
&lt;br&gt;

[![SherlockEyeCover](./docs/.gitbook/assets/sherlockeye_cover.jpg)](https://cutt.ly/frtVNzQQ)

### Setup

**Clone the repository**

```bash
git clone https://github.com/p1ngul1n0/blackbird
cd blackbird
```

**Install requirements**

```bash
pip install -r requirements.txt
```

### Usage

**Search by username**

```bash
python blackbird.py --username johndoe
```

**Search by email**

```bash
python blackbird.py --email johndoe@example.com 
```

**Export results to PDF**

```bash
python blackbird.py --email  --pdf
```

##  âœ¨ AI (Free)
Blackbird integrates an AI engine that analyzes the sites where a username or email is found and returns a behavioral and technical profile of the user â€” helping you understand more, with less effort.

- No sensitive data is shared â€” only site names are sent

- Usage is completely free, with a fair daily limit

- AI results are also included in PDF exports (```--pdf```)
#### Generate an API key:
```bash
python blackbird.py --setup-ai
```
#### Use it
```bash
python blackbird.py --username johndoe --ai
```

## More
For more details about the project, visit the &lt;a href=&quot;https://p1ngul1n0.gitbook.io/blackbird/&quot;&gt;Docs&lt;/a&gt;

### Project Developer

[Lucas Antoniaci](https://www.linkedin.com/in/lucas-antoniaci/)

### WhatsMyName

Blackbird is fully integrated with [WhatsMyName](https://github.com/WebBreacher/WhatsMyName) project, witch has 600+ sites to perform accurate reverse username search.

### Sponsors

[![DigitalOcean Referral Badge](https://web-platforms.sfo2.cdn.digitaloceanspaces.com/WWW/Badge%203.svg)](https://www.digitalocean.com/?refcode=eae02be1dd10&amp;utm_campaign=Referral_Invite&amp;utm_medium=Referral_Program&amp;utm_source=badge)

### Disclaimer

```
This or previous program is for Educational purpose ONLY. Do not use it without permission. 
The usual disclaimer applies, especially the fact that me (P1ngul1n0) is not liable for any 
damages caused by direct or indirect use of the information or functionality provided by these 
programs. The author or any Internet provider bears NO responsibility for content or misuse 
of these programs or any derivatives thereof. By using these programs you accept the fact 
that any damage (dataloss, system crash, system compromise, etc.) caused by the use of these 
programs is not P1ngul1n0&#039;s responsibility.
```
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[hesreallyhim/awesome-claude-code]]></title>
            <link>https://github.com/hesreallyhim/awesome-claude-code</link>
            <guid>https://github.com/hesreallyhim/awesome-claude-code</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:51 GMT</pubDate>
            <description><![CDATA[A curated list of awesome commands, files, and workflows for Claude Code]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hesreallyhim/awesome-claude-code">hesreallyhim/awesome-claude-code</a></h1>
            <p>A curated list of awesome commands, files, and workflows for Claude Code</p>
            <p>Language: Python</p>
            <p>Stars: 5,848</p>
            <p>Forks: 293</p>
            <p>Stars today: 681 stars today</p>
            <h2>README</h2><pre>&lt;!--lint disable remark-lint:awesome-badge--&gt;

#

&lt;!-- [![Awesome](https://awesome.re/badge-flat2.svg)](https://awesome.re) --&gt;

&lt;pre style=&quot;display: inline-block; text-align: left;&quot;&gt;
 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ” â–ˆâ–ˆâ”    â–ˆâ–ˆâ”â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ” â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ” â–ˆâ–ˆâ–ˆâ”   â–ˆâ–ˆâ–ˆâ”â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”
â–ˆâ–ˆâ”Œâ”€â”€â–ˆâ–ˆâ”â–ˆâ–ˆâ”‚    â–ˆâ–ˆâ”‚â–ˆâ–ˆâ”Œâ”€â”€â”€â”€â”˜â–ˆâ–ˆâ”Œâ”€â”€â”€â”€â”˜â–ˆâ–ˆâ”Œâ”€â”€â”€â–ˆâ–ˆâ”â–ˆâ–ˆâ–ˆâ–ˆâ” â–ˆâ–ˆâ–ˆâ–ˆâ”‚â–ˆâ–ˆâ”Œâ”€â”€â”€â”€â”˜
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚â–ˆâ–ˆâ”‚ â–ˆâ” â–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”â–ˆâ–ˆâ”‚   â–ˆâ–ˆâ”‚â–ˆâ–ˆâ”Œâ–ˆâ–ˆâ–ˆâ–ˆâ”Œâ–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”
â–ˆâ–ˆâ”Œâ”€â”€â–ˆâ–ˆâ”‚â–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ”â–ˆâ–ˆâ”‚â–ˆâ–ˆâ”Œâ”€â”€â”˜  â””â”€â”€â”€â”€â–ˆâ–ˆâ”‚â–ˆâ–ˆâ”‚   â–ˆâ–ˆâ”‚â–ˆâ–ˆâ”‚â””â–ˆâ–ˆâ”Œâ”˜â–ˆâ–ˆâ”‚â–ˆâ–ˆâ”Œâ”€â”€â”˜
â–ˆâ–ˆâ”‚  â–ˆâ–ˆâ”‚â””â–ˆâ–ˆâ–ˆâ”Œâ–ˆâ–ˆâ–ˆâ”Œâ”˜â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚â””â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”Œâ”˜â–ˆâ–ˆâ”‚ â””â”€â”˜ â–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”
â””â”€â”˜  â””â”€â”˜ â””â”€â”€â”˜â””â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”˜     â””â”€â”˜â””â”€â”€â”€â”€â”€â”€â”˜

 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”â–ˆâ–ˆâ”      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ” â–ˆâ–ˆâ”   â–ˆâ–ˆâ”â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ” â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ” â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ” â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ” â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”
â–ˆâ–ˆâ”Œâ”€â”€â”€â”€â”˜â–ˆâ–ˆâ”‚     â–ˆâ–ˆâ”Œâ”€â”€â–ˆâ–ˆâ”â–ˆâ–ˆâ”‚   â–ˆâ–ˆâ”‚â–ˆâ–ˆâ”Œâ”€â”€â–ˆâ–ˆâ”â–ˆâ–ˆâ”Œâ”€â”€â”€â”€â”˜    â–ˆâ–ˆâ”Œâ”€â”€â”€â”€â”˜â–ˆâ–ˆâ”Œâ”€â”€â”€â–ˆâ–ˆâ”â–ˆâ–ˆâ”Œâ”€â”€â–ˆâ–ˆâ”â–ˆâ–ˆâ”Œâ”€â”€â”€â”€â”˜
â–ˆâ–ˆâ”‚     â–ˆâ–ˆâ”‚     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚â–ˆâ–ˆâ”‚   â–ˆâ–ˆâ”‚â–ˆâ–ˆâ”‚  â–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”      â–ˆâ–ˆâ”‚     â–ˆâ–ˆâ”‚   â–ˆâ–ˆâ”‚â–ˆâ–ˆâ”‚  â–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”
â–ˆâ–ˆâ”‚     â–ˆâ–ˆâ”‚     â–ˆâ–ˆâ”Œâ”€â”€â–ˆâ–ˆâ”‚â–ˆâ–ˆâ”‚   â–ˆâ–ˆâ”‚â–ˆâ–ˆâ”‚  â–ˆâ–ˆâ”‚â–ˆâ–ˆâ”Œâ”€â”€â”˜      â–ˆâ–ˆâ”‚     â–ˆâ–ˆâ”‚   â–ˆâ–ˆâ”‚â–ˆâ–ˆâ”‚  â–ˆâ–ˆâ”‚â–ˆâ–ˆâ”Œâ”€â”€â”˜
â””â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”â–ˆâ–ˆâ”‚  â–ˆâ–ˆâ”‚â””â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”Œâ”˜â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”Œâ”˜â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”    â””â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”â””â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”Œâ”˜â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”Œâ”˜â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”
 â””â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”˜  â””â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜
&lt;/pre&gt;

&lt;!--lint enable remark-lint:awesome-badge--&gt;

[![Awesome](https://awesome.re/badge-flat2.svg)](https://awesome.re)

&lt;!--lint enable remark-lint:awesome-badge--&gt;

&lt;!--lint disable double-link--&gt;

This is a curated list of slash-commands, `CLAUDE.md` files, CLI tools, and other resources and guides for enhancing your [Claude Code](https://docs.anthropic.com/en/docs/claude-code) workflow, productivity, and vibes.

&lt;!--lint enable double-link--&gt;

Claude Code is a cutting-edge CLI-based coding assistant and agent that you can access in your terminal or IDE. It is a rapidly evolving tool that offers a number of powerful capabilities, and allows for a lot of configuration, in a lot of different ways. Users are actively working out best practices and workflows. It is the hope that this repo will help the community share knowledge and understand how to get the most out of Claude Code.

### Announcements

- 2025-07-18 - I ended up over-engineering the submission workflow, but I think it&#039;s done, I just have to smoke test it and update the docs. For anyone with existing PR&#039;s, don&#039;t worry about updating them (for formatting purposes, that is), I can take care of it myself. For anoyne with new PR&#039;s, you _should_ be able to run `make submit` from the root directory of your fork for an interactive experience (as I said, needs smoke testing) - alternatively, add your entry to the bottom of [`THE_RESOURCES_TABLE`](../THE_RESOURCES_TABLE.csv) and run `make generate` to automatically update the `README.md` based on the information you filled in. If it&#039;s not working, just open a PR with the relevant information and I&#039;ll deal with it, I created this mess anyway ğŸ˜ƒ.

&lt;br&gt;

## Contents

â–ª&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Workflows &amp; Knowledge Guides](#workflows--knowledge-guides-)  
â–ª&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Tooling](#tooling-)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[IDE Integrations](#ide-integrations)  
â–ª&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Hooks](#hooks-)  
â–ª&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Slash-Commands](#slash-commands-)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Version Control &amp; Git](#version-control--git)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Code Analysis &amp; Testing](#code-analysis--testing)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Context Loading &amp; Priming](#context-loading--priming)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Documentation &amp; Changelogs](#documentation--changelogs)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[CI / Deployment](#ci--deployment)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Project &amp; Task Management](#project--task-management)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Miscellaneous](#miscellaneous)  
â–ª&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[CLAUDE.md Files](#claudemd-files-)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Language-Specific](#language-specific)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Domain-Specific](#domain-specific)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Project Scaffolding &amp; MCP](#project-scaffolding--mcp)  
â–ª&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Official Documentation](#official-documentation-)  

&lt;br&gt;

## Workflows &amp; Knowledge Guides ğŸ§ 

&gt; A **workflow** is a tightly coupled set of Claude Code-native resources that facilitate specific projects

[`Blogging Platform Instructions`](https://github.com/cloudartisan/cloudartisan.github.io/tree/main/.claude/commands) &amp;nbsp; by &amp;nbsp; [cloudartisan](https://github.com/cloudartisan)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;CC-BY-SA-4.0  
Provides a well-structured set of commands for publishing and maintaining a blogging platform, including commands for creating posts, managing categories, and handling media files.

[`ClaudeLog`](https://claudelog.com) &amp;nbsp; by &amp;nbsp; [InventorBlack](https://www.reddit.com/user/inventor_black/)    
A comprehensive knowledge repository that features detailed breakdowns of advanced Claude Code mechanics including [CLAUDE.md best practices](https://claudelog.com/mechanics/claude-md-supremacy), practical technique guides like [plan mode](https://claudelog.com/mechanics/plan-mode), and a [configuration guide](https://claudelog.com/configuration).

[`Context Priming`](https://github.com/disler/just-prompt/tree/main/.claude/commands) &amp;nbsp; by &amp;nbsp; [disler](https://github.com/disler)    
Provides a systematic approach to priming Claude Code with comprehensive project context through specialized commands for different project scenarios and development contexts.

[`n8n_agent`](https://github.com/kingler/n8n_agent/tree/main/.claude/commands) &amp;nbsp; by &amp;nbsp; [kingler](https://github.com/kingler)    
Amazing comprehensive set of comments for code analysis, QA, design, documentation, project structure, project management, optimization, and many more.

[`Project Bootstrapping and Task Management`](https://github.com/steadycursor/steadystart/tree/main/.claude/commands) &amp;nbsp; by &amp;nbsp; [steadycursor](https://github.com/steadycursor)    
Provides a structured set of commands for bootstrapping and managing a new project, including meta-commands for creating and editing custom slash-commands.

[`Project Management, Implementation, Planning, and Release`](https://github.com/scopecraft/command/tree/main/.claude/commands) &amp;nbsp; by &amp;nbsp; [scopecraft](https://github.com/scopecraft)    
Really comprehensive set of commands for all aspects of SDLC.

[`Project Workflow System`](https://github.com/harperreed/dotfiles/tree/master/.claude/commands) &amp;nbsp; by &amp;nbsp; [harperreed](https://github.com/harperreed)    
A set of commands that provide a comprehensive workflow system for managing projects, including task management, code review, and deployment processes.

[`Shipping Real Code w/ Claude`](https://diwank.space/field-notes-from-shipping-real-code-with-claude) &amp;nbsp; by &amp;nbsp; [Diwank](https://github.com/creatorrr)    
A detailed blog post explaining the author&#039;s process for shipping a product with Claude Code, including CLAUDE.md files and other interesting resources.

[`Simone`](https://github.com/Helmi/claude-simone) &amp;nbsp; by &amp;nbsp; [Helmi](https://github.com/Helmi)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT  
A broader project management workflow for Claude Code that encompasses not just a set of commands, but a system of documents, guidelines, and processes to facilitate project planning and execution.

[`Slash-commands megalist`](https://github.com/wcygan/dotfiles/tree/d8ab6b9f5a7a81007b7f5fa3025d4f83ce12cc02/claude/commands) &amp;nbsp; by &amp;nbsp; [wcygan](https://github.com/wcygan)    
A pretty stunning list (88 at the time of this post!) of slash-commands ranging from agent orchestration, code review, project management, security, documentation, self-assessment, almost anything you can dream of.

&lt;br&gt;

## Tooling ğŸ§°

&gt; **Tooling** denotes applications that are built on top of Claude Code and consist of more components than slash-commands and `CLAUDE.md` files

[`CC Usage`](https://github.com/ryoppippi/ccusage) &amp;nbsp; by &amp;nbsp; [ryoppippi](https://github.com/ryoppippi)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT  
Handy CLI tool for managing and analyzing Claude Code usage, based on analyzing local Claude Code logs. Presents a nice dashboard regarding cost information, token consumption, etc.

[`ccexp`](https://github.com/nyatinte/ccexp) &amp;nbsp; by &amp;nbsp; [nyatinte](https://github.com/nyatinte)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT  
Interactive CLI tool for discovering and managing Claude Code configuration files and slash commands with a beautiful terminal UI.

[`Claude Code Flow`](https://github.com/ruvnet/claude-code-flow) &amp;nbsp; by &amp;nbsp; [ruvnet](https://github.com/ruvnet)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT  
This mode serves as a code-first orchestration layer, enabling Claude to write, edit, test, and optimize code autonomously across recursive agent cycles.

[`Claude Composer`](https://github.com/possibilities/claude-composer) &amp;nbsp; by &amp;nbsp; [Mike Bannister](https://github.com/possibilities)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Unlicense  
A tool that adds small enhancements to Claude Code.

[`Claude Hub`](https://github.com/claude-did-this/claude-hub) &amp;nbsp; by &amp;nbsp; [Claude Did This](https://github.com/claude-did-this)    
A webhook service that connects Claude Code to GitHub repositories, enabling AI-powered code assistance directly through pull requests and issues. This integration allows Claude to analyze repositories, answer technical questions, and help developers understand and improve their codebase through simple @mentions.

[`Claude Squad`](https://github.com/smtg-ai/claude-squad) &amp;nbsp; by &amp;nbsp; [smtg-ai](https://github.com/smtg-ai)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;AGPL-3.0  
Claude Squad is a terminal app that manages multiple Claude Code, Codex (and other local agents including Aider) in separate workspaces, allowing you to work on multiple tasks simultaneously.

[`Claude Swarm`](https://github.com/parruda/claude-swarm) &amp;nbsp; by &amp;nbsp; [parruda](https://github.com/parruda)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT  
Launch Claude Code session that is connected to a swarm of Claude Code Agents.

[`Claude Task Master`](https://github.com/eyaltoledano/claude-task-master) &amp;nbsp; by &amp;nbsp; [eyaltoledano](https://github.com/eyaltoledano)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;NOASSERTION  
A task management system for AI-driven development with Claude, designed to work seamlessly with Cursor AI.

[`Claude Task Runner`](https://github.com/grahama1970/claude-task-runner) &amp;nbsp; by &amp;nbsp; [grahama1970](https://github.com/grahama1970)    
A specialized tool to manage context isolation and focused task execution with Claude Code, solving the critical challenge of context length limitations and task focus when working with Claude on complex, multi-step projects.

[`Container Use`](https://github.com/dagger/container-use) &amp;nbsp; by &amp;nbsp; [dagger](https://github.com/dagger)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0  
Development environments for coding agents. Enable multiple agents to work safely and independently with your preferred stack.


### IDE Integrations

[`claude-code.el`](https://github.com/stevemolitor/claude-code.el) &amp;nbsp; by &amp;nbsp; [stevemolitor](https://github.com/stevemolitor)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0  
An Emacs interface for Claude Code CLI.

[`claude-code.nvim`](https://github.com/greggh/claude-code.nvim) &amp;nbsp; by &amp;nbsp; [greggh](https://github.com/greggh)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT  
A seamless integration between Claude Code AI assistant and Neovim.

[`crystal`](https://github.com/stravu/crystal) &amp;nbsp; by &amp;nbsp; [stravu](https://github.com/stravu)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT  
A full-fledged desktop application for orchestrating, monitoring, and interacting with Claude Code agents.

&lt;br&gt;

## Hooks ğŸª

&gt; **Hooks** are a brand new API for Claude Code that allows users to activate commands and run scripts at different points in Claude&#039;s agentic lifecycle.

**[Experimental]** - The resources listed in this section have not been fully vetted and may not work as expected, given the bleeding-edge nature of Claude Code hooks. Nevertheless, I wished to include them at least as a source of inspiration and to explore this unknown terrain. YMMV!

[`claude-code-hooks-sdk`](https://github.com/beyondcode/claude-hooks-sdk) &amp;nbsp; by &amp;nbsp; [beyondcode](https://github.com/beyondcode)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT  
A Laravel-inspired PHP SDK for building Claude Code hook responses with a clean, fluent API. This SDK makes it easy to create structured JSON responses for Claude Code hooks using an expressive, chainable interface.

[`claude-hooks`](https://github.com/johnlindquist/claude-hooks) &amp;nbsp; by &amp;nbsp; [John Lindquist](https://github.com/johnlindquist)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT  
A TypeScript-based system for configuring and customizing Claude Code hooks with a powerful and flexible interface.

[`Linting, testing, and notifications (in go)`](https://github.com/Veraticus/nix-config/tree/main/home-manager/claude-code/hooks) &amp;nbsp; by &amp;nbsp; [Josh Symonds](https://github.com/Veraticus)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT  
Nice set of hooks for enforcing code quality (linting, testing, notifications), with a nice configuration setup as well.

[`TDD Guard`](https://github.com/nizos/tdd-guard) &amp;nbsp; by &amp;nbsp; [Nizar Selander](https://github.com/nizos)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT  
A hooks-driven system that monitors file operations in real-time and blocks changes that violate TDD principles.

&lt;br&gt;

## Slash-Commands ğŸ”ª

### Version Control &amp; Git

[`/bug-fix`](https://github.com/danielscholl/mvn-mcp-server/blob/main/.claude/commands/bug-fix.md) &amp;nbsp; by &amp;nbsp; [danielscholl](https://github.com/danielscholl)    
Streamlines bug fixing by creating a GitHub issue first, then a feature branch for implementing and thoroughly testing the solution before merging.

[`/commit`](https://github.com/evmts/tevm-monorepo/blob/main/.claude/commands/commit.md) &amp;nbsp; by &amp;nbsp; [evmts](https://github.com/evmts)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT  
Creates git commits using conventional commit format with appropriate emojis, following project standards and creating descriptive messages that explain the purpose of changes.

[`/commit-fast`](https://github.com/steadycursor/steadystart/blob/main/.claude/commands/2-commit-fast.md) &amp;nbsp; by &amp;nbsp; [steadycursor](https://github.com/steadycursor)    
Automates git commit process by selecting the first suggested message, generating structured commits with consistent formatting while skipping manual confirmation and removing Claude co-Contributorship footer

[`/create-pr`](https://github.com/toyamarinyon/giselle/blob/main/.claude/commands/create-pr.md) &amp;nbsp; by &amp;nbsp; [toyamarinyon](https://github.com/toyamarinyon)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0  
Streamlines pull request creation by handling the entire workflow: creating a new branch, committing changes, formatting modified files with Biome, and submitting the PR.

[`/create-pull-request`](https://github.com/liam-hq/liam/blob/main/.claude/commands/create-pull-request.md) &amp;nbsp; by &amp;nbsp; [liam-hq](https://github.com/liam-hq)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0  
Provides comprehensive PR creation guidance with GitHub CLI, enforcing title conventions, following template structure, and offering concrete command examples with best practices.

[`/create-worktrees`](https://github.com/evmts/tevm-monorepo/blob/main/.claude/commands/create-worktrees.md) &amp;nbsp; by &amp;nbsp; [evmts](https://github.com/evmts)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT  
Creates git worktrees for all open PRs or specific branches, handling branches with slashes, cleaning up stale worktrees, and supporting custom branch creation for development.

[`/fix-github-issue`](https://github.com/jeremymailen/kotlinter-gradle/blob/master/.claude/commands/fix-github-issue.md) &amp;nbsp; by &amp;nbsp; [jeremymailen](https://github.com/jeremymailen)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0  
Analyzes and fixes GitHub issues using a structured approach with GitHub CLI for issue details, implementing necessary code changes, running tests, and creating proper commit messages.

[`/fix-issue`](https://github.com/metabase/metabase/blob/master/.claude/commands/fix-issue.md) &amp;nbsp; by &amp;nbsp; [metabase](https://github.com/metabase)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;NOASSERTION  
Addresses GitHub issues by taking issue number as parameter, analyzing context, implementing solution, and testing/validating the fix for proper integration.

[`/fix-pr`](https://github.com/metabase/metabase/blob/master/.claude/commands/fix-pr.md) &amp;nbsp; by &amp;nbsp; [metabase](https://github.com/metabase)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;NOASSERTION  
Fetches and fixes unresolved PR comments by automatically retrieving feedback, addressing reviewer concerns, making targeted code improvements, and streamlining the review process.

[`/husky`](https://github.com/evmts/tevm-monorepo/blob/main/.claude/commands/husky.md) &amp;nbsp; by &amp;nbsp; [evmts](https://github.com/evmts)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT  
Sets up and manages Husky Git hooks by configuring pre-commit hooks, establishing commit message standards, integrating with linting tools, and ensuring code quality on commits.

[`/pr-review`](https://github.com/arkavo-org/opentdf-rs/blob/main/.claude/commands/pr-review.md) &amp;nbsp; by &amp;nbsp; [arkavo-org](https://github.com/arkavo-org)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT  
Reviews pull request changes to provide feedback, check for issues, and suggest improvements before merging into the main codebase.

[`/update-branch-name`](https://github.com/giselles-ai/giselle/blob/main/.claude/commands/update-branch-name.md) &amp;nbsp; by &amp;nbsp; [giselles-ai](https://github.com/giselles-ai)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0  
Updates branch names with proper prefixes and formats, enforcing naming conventions, supporting semantic prefixes, and managing remote branch updates.


### Code Analysis &amp; Testing

[`/check`](https://github.com/rygwdn/slack-tools/blob/main/.claude/commands/check.md) &amp;nbsp; by &amp;nbsp; [rygwdn](https://github.com/rygwdn)    
Performs comprehensive code quality and security checks, featuring static analysis integration, security vulnerability scanning, code style enforcement, and detailed reporting.

[`/clean`](https://github.com/Graphlet-AI/eridu/blob/main/.claude/commands/clean.md) &amp;nbsp; by &amp;nbsp; [Graphlet-AI](https://github.com/Graphlet-AI)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0  
Addresses code formatting and quality issues by fixing black formatting problems, organizing imports with isort, resolving flake8 linting issues, and correcting mypy type errors.

[`/code_analysis`](https://github.com/kingler/n8n_agent/blob/main/.claude/commands/code_analysis.md) &amp;nbsp; by &amp;nbsp; [kingler](https://github.com/kingler)    
Provides a menu of advanced code analysis commands for deep inspection, including knowledge graph generation, optimization suggestions, and quality evaluation.

[`/optimize`](https://github.com/to4iki/ai-project-rules/blob/main/.claude/commands/optimize.md) &amp;nbsp; by &amp;nbsp; [to4iki](https://github.com/to4iki)  &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT  
Analyzes code performance to identify bottlenecks, proposing concrete optimizations with implementation guidance for improved application performance.

[`/repro-issue`](https://github.com/rzykov/metabase/blob/master/.claude/commands/repro-issue.md) &amp;nbsp; by &amp;nbsp; [

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[jlowin/fastmcp]]></title>
            <link>https://github.com/jlowin/fastmcp</link>
            <guid>https://github.com/jlowin/fastmcp</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:50 GMT</pubDate>
            <description><![CDATA[ğŸš€ The fast, Pythonic way to build MCP servers and clients]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jlowin/fastmcp">jlowin/fastmcp</a></h1>
            <p>ğŸš€ The fast, Pythonic way to build MCP servers and clients</p>
            <p>Language: Python</p>
            <p>Stars: 15,032</p>
            <p>Forks: 948</p>
            <p>Stars today: 82 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;!-- omit in toc --&gt;
# FastMCP v2 ğŸš€

&lt;strong&gt;The fast, Pythonic way to build MCP servers and clients.&lt;/strong&gt;

*Made with â˜•ï¸ by [Prefect](https://www.prefect.io/)*

[![Docs](https://img.shields.io/badge/docs-gofastmcp.com-blue)](https://gofastmcp.com)
[![PyPI - Version](https://img.shields.io/pypi/v/fastmcp.svg)](https://pypi.org/project/fastmcp)
[![Tests](https://github.com/jlowin/fastmcp/actions/workflows/run-tests.yml/badge.svg)](https://github.com/jlowin/fastmcp/actions/workflows/run-tests.yml)
[![License](https://img.shields.io/github/license/jlowin/fastmcp.svg)](https://github.com/jlowin/fastmcp/blob/main/LICENSE)

&lt;a href=&quot;https://trendshift.io/repositories/13266&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13266&quot; alt=&quot;jlowin%2Ffastmcp | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

&gt; [!Note]
&gt;
&gt; #### Beyond the Protocol
&gt;
&gt; FastMCP is the standard framework for working with the Model Context Protocol. FastMCP 1.0 was incorporated into the [official MCP Python SDK](https://github.com/modelcontextprotocol/python-sdk) in 2024.
&gt;
&gt; This is FastMCP 2.0, the **actively maintained version** that provides a complete toolkit for working with the MCP ecosystem.
&gt;
&gt; FastMCP 2.0 has a comprehensive set of features that go far beyond the core MCP specification, all in service of providing **the simplest path to production**. These include deployment, auth, clients, server proxying and composition, generating servers from REST APIs, dynamic tool rewriting, built-in testing tools, integrations, and more.
&gt;
&gt; Ready to upgrade or get started? Follow the [installation instructions](https://gofastmcp.com/getting-started/installation), which include steps for upgrading from the official MCP SDK.

---

The [Model Context Protocol (MCP)](https://modelcontextprotocol.io) is a new, standardized way to provide context and tools to your LLMs, and FastMCP makes building MCP servers and clients simple and intuitive. Create tools, expose resources, define prompts, and connect components with clean, Pythonic code.

```python
# server.py
from fastmcp import FastMCP

mcp = FastMCP(&quot;Demo ğŸš€&quot;)

@mcp.tool
def add(a: int, b: int) -&gt; int:
    &quot;&quot;&quot;Add two numbers&quot;&quot;&quot;
    return a + b

if __name__ == &quot;__main__&quot;:
    mcp.run()
```

Run the server locally:

```bash
fastmcp run server.py
```

### ğŸ“š Documentation

FastMCP&#039;s complete documentation is available at **[gofastmcp.com](https://gofastmcp.com)**, including detailed guides, API references, and advanced patterns. This readme provides only a high-level overview.

Documentation is also available in [llms.txt format](https://llmstxt.org/), which is a simple markdown standard that LLMs can consume easily.

There are two ways to access the LLM-friendly documentation:

- [`llms.txt`](https://gofastmcp.com/llms.txt) is essentially a sitemap, listing all the pages in the documentation.
- [`llms-full.txt`](https://gofastmcp.com/llms-full.txt) contains the entire documentation. Note this may exceed the context window of your LLM.

---

&lt;!-- omit in toc --&gt;
## Table of Contents

- [What is MCP?](#what-is-mcp)
- [Why FastMCP?](#why-fastmcp)
- [Installation](#installation)
- [Core Concepts](#core-concepts)
  - [The `FastMCP` Server](#the-fastmcp-server)
  - [Tools](#tools)
  - [Resources \&amp; Templates](#resources--templates)
  - [Prompts](#prompts)
  - [Context](#context)
  - [MCP Clients](#mcp-clients)
- [Advanced Features](#advanced-features)
  - [Proxy Servers](#proxy-servers)
  - [Composing MCP Servers](#composing-mcp-servers)
  - [OpenAPI \&amp; FastAPI Generation](#openapi--fastapi-generation)
  - [Authentication \&amp; Security](#authentication--security)
- [Running Your Server](#running-your-server)
- [Contributing](#contributing)
  - [Prerequisites](#prerequisites)
  - [Setup](#setup)
  - [Unit Tests](#unit-tests)
  - [Static Checks](#static-checks)
  - [Pull Requests](#pull-requests)

---

## What is MCP?

The [Model Context Protocol (MCP)](https://modelcontextprotocol.io) lets you build servers that expose data and functionality to LLM applications in a secure, standardized way. It is often described as &quot;the USB-C port for AI&quot;, providing a uniform way to connect LLMs to resources they can use. It may be easier to think of it as an API, but specifically designed for LLM interactions. MCP servers can:

- Expose data through **Resources** (think of these sort of like GET endpoints; they are used to load information into the LLM&#039;s context)
- Provide functionality through **Tools** (sort of like POST endpoints; they are used to execute code or otherwise produce a side effect)
- Define interaction patterns through **Prompts** (reusable templates for LLM interactions)
- And more!

FastMCP provides a high-level, Pythonic interface for building, managing, and interacting with these servers.

## Why FastMCP?

The MCP protocol is powerful but implementing it involves a lot of boilerplate - server setup, protocol handlers, content types, error management. FastMCP handles all the complex protocol details and server management, so you can focus on building great tools. It&#039;s designed to be high-level and Pythonic; in most cases, decorating a function is all you need.

FastMCP 2.0 has evolved into a comprehensive platform that goes far beyond basic protocol implementation. While 1.0 provided server-building capabilities (and is now part of the official MCP SDK), 2.0 offers a complete ecosystem including client libraries, authentication systems, deployment tools, integrations with major AI platforms, testing frameworks, and production-ready infrastructure patterns.

FastMCP aims to be:

ğŸš€ **Fast:** High-level interface means less code and faster development

ğŸ€ **Simple:** Build MCP servers with minimal boilerplate

ğŸ **Pythonic:** Feels natural to Python developers

ğŸ” **Complete:** A comprehensive platform for all MCP use cases, from dev to prod

## Installation

We recommend installing FastMCP with [uv](https://docs.astral.sh/uv/):

```bash
uv pip install fastmcp
```

For full installation instructions, including verification, upgrading from the official MCPSDK, and developer setup, see the [**Installation Guide**](https://gofastmcp.com/getting-started/installation).

## Core Concepts

These are the building blocks for creating MCP servers and clients with FastMCP.

### The `FastMCP` Server

The central object representing your MCP application. It holds your tools, resources, and prompts, manages connections, and can be configured with settings like authentication.

```python
from fastmcp import FastMCP

# Create a server instance
mcp = FastMCP(name=&quot;MyAssistantServer&quot;)
```

Learn more in the [**FastMCP Server Documentation**](https://gofastmcp.com/servers/fastmcp).

### Tools

Tools allow LLMs to perform actions by executing your Python functions (sync or async). Ideal for computations, API calls, or side effects (like `POST`/`PUT`). FastMCP handles schema generation from type hints and docstrings. Tools can return various types, including text, JSON-serializable objects, and even images or audio aided by the FastMCP media helper classes.

```python
@mcp.tool
def multiply(a: float, b: float) -&gt; float:
    &quot;&quot;&quot;Multiplies two numbers.&quot;&quot;&quot;
    return a * b
```

Learn more in the [**Tools Documentation**](https://gofastmcp.com/servers/tools).

### Resources &amp; Templates

Resources expose read-only data sources (like `GET` requests). Use `@mcp.resource(&quot;your://uri&quot;)`. Use `{placeholders}` in the URI to create dynamic templates that accept parameters, allowing clients to request specific data subsets.

```python
# Static resource
@mcp.resource(&quot;config://version&quot;)
def get_version(): 
    return &quot;2.0.1&quot;

# Dynamic resource template
@mcp.resource(&quot;users://{user_id}/profile&quot;)
def get_profile(user_id: int):
    # Fetch profile for user_id...
    return {&quot;name&quot;: f&quot;User {user_id}&quot;, &quot;status&quot;: &quot;active&quot;}
```

Learn more in the [**Resources &amp; Templates Documentation**](https://gofastmcp.com/servers/resources).

### Prompts

Prompts define reusable message templates to guide LLM interactions. Decorate functions with `@mcp.prompt`. Return strings or `Message` objects.

```python
@mcp.prompt
def summarize_request(text: str) -&gt; str:
    &quot;&quot;&quot;Generate a prompt asking for a summary.&quot;&quot;&quot;
    return f&quot;Please summarize the following text:\n\n{text}&quot;
```

Learn more in the [**Prompts Documentation**](https://gofastmcp.com/servers/prompts).

### Context

Access MCP session capabilities within your tools, resources, or prompts by adding a `ctx: Context` parameter. Context provides methods for:

- **Logging:** Log messages to MCP clients with `ctx.info()`, `ctx.error()`, etc.
- **LLM Sampling:** Use `ctx.sample()` to request completions from the client&#039;s LLM.
- **HTTP Request:** Use `ctx.http_request()` to make HTTP requests to other servers.
- **Resource Access:** Use `ctx.read_resource()` to access resources on the server
- **Progress Reporting:** Use `ctx.report_progress()` to report progress to the client.
- and more...

To access the context, add a parameter annotated as `Context` to any mcp-decorated function. FastMCP will automatically inject the correct context object when the function is called.

```python
from fastmcp import FastMCP, Context

mcp = FastMCP(&quot;My MCP Server&quot;)

@mcp.tool
async def process_data(uri: str, ctx: Context):
    # Log a message to the client
    await ctx.info(f&quot;Processing {uri}...&quot;)

    # Read a resource from the server
    data = await ctx.read_resource(uri)

    # Ask client LLM to summarize the data
    summary = await ctx.sample(f&quot;Summarize: {data.content[:500]}&quot;)

    # Return the summary
    return summary.text
```

Learn more in the [**Context Documentation**](https://gofastmcp.com/servers/context).

### MCP Clients

Interact with *any* MCP server programmatically using the `fastmcp.Client`. It supports various transports (Stdio, SSE, In-Memory) and often auto-detects the correct one. The client can also handle advanced patterns like server-initiated **LLM sampling requests** if you provide an appropriate handler.

Critically, the client allows for efficient **in-memory testing** of your servers by connecting directly to a `FastMCP` server instance via the `FastMCPTransport`, eliminating the need for process management or network calls during tests.

```python
from fastmcp import Client

async def main():
    # Connect via stdio to a local script
    async with Client(&quot;my_server.py&quot;) as client:
        tools = await client.list_tools()
        print(f&quot;Available tools: {tools}&quot;)
        result = await client.call_tool(&quot;add&quot;, {&quot;a&quot;: 5, &quot;b&quot;: 3})
        print(f&quot;Result: {result.text}&quot;)

    # Connect via SSE
    async with Client(&quot;http://localhost:8000/sse&quot;) as client:
        # ... use the client
        pass
```

To use clients to test servers, use the following pattern:

```python
from fastmcp import FastMCP, Client

mcp = FastMCP(&quot;My MCP Server&quot;)

async def main():
    # Connect via in-memory transport
    async with Client(mcp) as client:
        # ... use the client
```

FastMCP also supports connecting to multiple servers through a single unified client using the standard MCP configuration format:

```python
from fastmcp import Client

# Standard MCP configuration with multiple servers
config = {
    &quot;mcpServers&quot;: {
        &quot;weather&quot;: {&quot;url&quot;: &quot;https://weather-api.example.com/mcp&quot;},
        &quot;assistant&quot;: {&quot;command&quot;: &quot;python&quot;, &quot;args&quot;: [&quot;./assistant_server.py&quot;]}
    }
}

# Create a client that connects to all servers
client = Client(config)

async def main():
    async with client:
        # Access tools and resources with server prefixes
        forecast = await client.call_tool(&quot;weather_get_forecast&quot;, {&quot;city&quot;: &quot;London&quot;})
        answer = await client.call_tool(&quot;assistant_answer_question&quot;, {&quot;query&quot;: &quot;What is MCP?&quot;})
```

Learn more in the [**Client Documentation**](https://gofastmcp.com/clients/client) and [**Transports Documentation**](https://gofastmcp.com/clients/transports).

## Advanced Features

FastMCP introduces powerful ways to structure and deploy your MCP applications.

### Proxy Servers

Create a FastMCP server that acts as an intermediary for another local or remote MCP server using `FastMCP.as_proxy()`. This is especially useful for bridging transports (e.g., remote SSE to local Stdio) or adding a layer of logic to a server you don&#039;t control.

Learn more in the [**Proxying Documentation**](https://gofastmcp.com/patterns/proxy).

### Composing MCP Servers

Build modular applications by mounting multiple `FastMCP` instances onto a parent server using `mcp.mount()` (live link) or `mcp.import_server()` (static copy).

Learn more in the [**Composition Documentation**](https://gofastmcp.com/patterns/composition).

### OpenAPI &amp; FastAPI Generation

Automatically generate FastMCP servers from existing OpenAPI specifications (`FastMCP.from_openapi()`) or FastAPI applications (`FastMCP.from_fastapi()`), instantly bringing your web APIs to the MCP ecosystem.

Learn more: [**OpenAPI Integration**](https://gofastmcp.com/servers/openapi#openapi-integration) | [**FastAPI Integration**](https://gofastmcp.com/deployment/asgi#fastapi-integration).

### Authentication &amp; Security

FastMCP provides built-in authentication support to secure both your MCP servers and clients in production environments. Protect your server endpoints from unauthorized access and authenticate your clients against secured MCP servers using industry-standard protocols.

- **Server Protection**: Secure your FastMCP server endpoints with configurable authentication providers
- **Client Authentication**: Connect to authenticated MCP servers with automatic credential management
- **Production Ready**: Support for common authentication patterns used in enterprise environments

Learn more in the **Authentication Documentation** for [servers](https://gofastmcp.com/servers/auth) and [clients](https://gofastmcp.com/clients/auth).

## Running Your Server

The main way to run a FastMCP server is by calling the `run()` method on your server instance:

```python
# server.py
from fastmcp import FastMCP

mcp = FastMCP(&quot;Demo ğŸš€&quot;)

@mcp.tool
def hello(name: str) -&gt; str:
    return f&quot;Hello, {name}!&quot;

if __name__ == &quot;__main__&quot;:
    mcp.run()  # Default: uses STDIO transport
```

FastMCP supports three transport protocols:

**STDIO (Default)**: Best for local tools and command-line scripts.

```python
mcp.run(transport=&quot;stdio&quot;)  # Default, so transport argument is optional
```

**Streamable HTTP**: Recommended for web deployments.

```python
mcp.run(transport=&quot;http&quot;, host=&quot;127.0.0.1&quot;, port=8000, path=&quot;/mcp&quot;)
```

**SSE**: For compatibility with existing SSE clients.

```python
mcp.run(transport=&quot;sse&quot;, host=&quot;127.0.0.1&quot;, port=8000)
```

See the [**Running Server Documentation**](https://gofastmcp.com/deployment/running-server) for more details.

## Contributing

Contributions are the core of open source! We welcome improvements and features.

### Prerequisites

- Python 3.10+
- [uv](https://docs.astral.sh/uv/) (Recommended for environment management)

### Setup

1. Clone the repository:

   ```bash
   git clone https://github.com/jlowin/fastmcp.git 
   cd fastmcp
   ```

2. Create and sync the environment:

   ```bash
   uv sync
   ```

   This installs all dependencies, including dev tools.

3. Activate the virtual environment (e.g., `source .venv/bin/activate` or via your IDE).

### Unit Tests

FastMCP has a comprehensive unit test suite. All PRs must introduce or update tests as appropriate and pass the full suite.

Run tests using pytest:

```bash
pytest
```

or if you want an overview of the code coverage

```bash
uv run pytest --cov=src --cov=examples --cov-report=html
```

### Static Checks

FastMCP uses `pre-commit` for code formatting, linting, and type-checking. All PRs must pass these checks (they run automatically in CI).

Install the hooks locally:

```bash
uv run pre-commit install
```

The hooks will now run automatically on `git commit`. You can also run them manually at any time:

```bash
pre-commit run --all-files
# or via uv
uv run pre-commit run --all-files
```

### Pull Requests

1. Fork the repository on GitHub.
2. Create a feature branch from `main`.
3. Make your changes, including tests and documentation updates.
4. Ensure tests and pre-commit hooks pass.
5. Commit your changes and push to your fork.
6. Open a pull request against the `main` branch of `jlowin/fastmcp`.

Please open an issue or discussion for questions or suggestions before starting significant work!
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[sooperset/mcp-atlassian]]></title>
            <link>https://github.com/sooperset/mcp-atlassian</link>
            <guid>https://github.com/sooperset/mcp-atlassian</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:49 GMT</pubDate>
            <description><![CDATA[MCP server for Atlassian tools (Confluence, Jira)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sooperset/mcp-atlassian">sooperset/mcp-atlassian</a></h1>
            <p>MCP server for Atlassian tools (Confluence, Jira)</p>
            <p>Language: Python</p>
            <p>Stars: 2,528</p>
            <p>Forks: 450</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre># MCP Atlassian

![PyPI Version](https://img.shields.io/pypi/v/mcp-atlassian)
![PyPI - Downloads](https://img.shields.io/pypi/dm/mcp-atlassian)
![PePy - Total Downloads](https://static.pepy.tech/personalized-badge/mcp-atlassian?period=total&amp;units=international_system&amp;left_color=grey&amp;right_color=blue&amp;left_text=Total%20Downloads)
[![Run Tests](https://github.com/sooperset/mcp-atlassian/actions/workflows/tests.yml/badge.svg)](https://github.com/sooperset/mcp-atlassian/actions/workflows/tests.yml)
![License](https://img.shields.io/github/license/sooperset/mcp-atlassian)

Model Context Protocol (MCP) server for Atlassian products (Confluence and Jira). This integration supports both Confluence &amp; Jira Cloud and Server/Data Center deployments.

## Example Usage

Ask your AI assistant to:

- **ğŸ“ Automatic Jira Updates** - &quot;Update Jira from our meeting notes&quot;
- **ğŸ” AI-Powered Confluence Search** - &quot;Find our OKR guide in Confluence and summarize it&quot;
- **ğŸ› Smart Jira Issue Filtering** - &quot;Show me urgent bugs in PROJ project from last week&quot;
- **ğŸ“„ Content Creation &amp; Management** - &quot;Create a tech design doc for XYZ feature&quot;

### Feature Demo

https://github.com/user-attachments/assets/35303504-14c6-4ae4-913b-7c25ea511c3e

&lt;details&gt; &lt;summary&gt;Confluence Demo&lt;/summary&gt;

https://github.com/user-attachments/assets/7fe9c488-ad0c-4876-9b54-120b666bb785

&lt;/details&gt;

### Compatibility

| Product        | Deployment Type    | Support Status              |
|----------------|--------------------|-----------------------------|
| **Confluence** | Cloud              | âœ… Fully supported           |
| **Confluence** | Server/Data Center | âœ… Supported (version 6.0+)  |
| **Jira**       | Cloud              | âœ… Fully supported           |
| **Jira**       | Server/Data Center | âœ… Supported (version 8.14+) |

## Quick Start Guide

### ğŸ” 1. Authentication Setup

MCP Atlassian supports three authentication methods:

#### A. API Token Authentication (Cloud) - **Recommended**

1. Go to https://id.atlassian.com/manage-profile/security/api-tokens
2. Click **Create API token**, name it
3. Copy the token immediately

#### B. Personal Access Token (Server/Data Center)

1. Go to your profile (avatar) â†’ **Profile** â†’ **Personal Access Tokens**
2. Click **Create token**, name it, set expiry
3. Copy the token immediately

#### C. OAuth 2.0 Authentication (Cloud) - **Advanced**

&gt; [!NOTE]
&gt; OAuth 2.0 is more complex to set up but provides enhanced security features. For most users, API Token authentication (Method A) is simpler and sufficient.

1. Go to [Atlassian Developer Console](https://developer.atlassian.com/console/myapps/)
2. Create an &quot;OAuth 2.0 (3LO) integration&quot; app
3. Configure **Permissions** (scopes) for Jira/Confluence
4. Set **Callback URL** (e.g., `http://localhost:8080/callback`)
5. Run setup wizard:
   ```bash
   docker run --rm -i \
     -p 8080:8080 \
     -v &quot;${HOME}/.mcp-atlassian:/home/app/.mcp-atlassian&quot; \
     ghcr.io/sooperset/mcp-atlassian:latest --oauth-setup -v
   ```
6. Follow prompts for `Client ID`, `Secret`, `URI`, and `Scope`
7. Complete browser authorization
8. Add obtained credentials to `.env` or IDE config:
   - `ATLASSIAN_OAUTH_CLOUD_ID` (from wizard)
   - `ATLASSIAN_OAUTH_CLIENT_ID`
   - `ATLASSIAN_OAUTH_CLIENT_SECRET`
   - `ATLASSIAN_OAUTH_REDIRECT_URI`
   - `ATLASSIAN_OAUTH_SCOPE`

&gt; [!IMPORTANT]
&gt; For the standard OAuth flow described above, include `offline_access` in your scope (e.g., `read:jira-work write:jira-work offline_access`). This allows the server to refresh the access token automatically.

&lt;details&gt;
&lt;summary&gt;Alternative: Using a Pre-existing OAuth Access Token (BYOT)&lt;/summary&gt;

If you are running mcp-atlassian part of a larger system that manages Atlassian OAuth 2.0 access tokens externally (e.g., through a central identity provider or another application), you can provide an access token directly to this MCP server. This method bypasses the interactive setup wizard and the server&#039;s internal token management (including refresh capabilities).

**Requirements:**
- A valid Atlassian OAuth 2.0 Access Token with the necessary scopes for the intended operations.
- The corresponding `ATLASSIAN_OAUTH_CLOUD_ID` for your Atlassian instance.

**Configuration:**
To use this method, set the following environment variables (or use the corresponding command-line flags when starting the server):
- `ATLASSIAN_OAUTH_CLOUD_ID`: Your Atlassian Cloud ID. (CLI: `--oauth-cloud-id`)
- `ATLASSIAN_OAUTH_ACCESS_TOKEN`: Your pre-existing OAuth 2.0 access token. (CLI: `--oauth-access-token`)

**Important Considerations for BYOT:**
- **Token Lifecycle Management:** When using BYOT, the MCP server **does not** handle token refresh. The responsibility for obtaining, refreshing (before expiry), and revoking the access token lies entirely with you or the external system providing the token.
- **Unused Variables:** The standard OAuth client variables (`ATLASSIAN_OAUTH_CLIENT_ID`, `ATLASSIAN_OAUTH_CLIENT_SECRET`, `ATLASSIAN_OAUTH_REDIRECT_URI`, `ATLASSIAN_OAUTH_SCOPE`) are **not** used and can be omitted when configuring for BYOT.
- **No Setup Wizard:** The `--oauth-setup` wizard is not applicable and should not be used for this approach.
- **No Token Cache Volume:** The Docker volume mount for token storage (e.g., `-v &quot;${HOME}/.mcp-atlassian:/home/app/.mcp-atlassian&quot;`) is also not necessary if you are exclusively using the BYOT method, as no tokens are stored or managed by this server.
- **Scope:** The provided access token must already have the necessary permissions (scopes) for the Jira/Confluence operations you intend to perform.

This option is useful in scenarios where OAuth credential management is centralized or handled by other infrastructure components.
&lt;/details&gt;

&gt; [!TIP]
&gt; **Multi-Cloud OAuth Support**: If you&#039;re building a multi-tenant application where users provide their own OAuth tokens, see the [Multi-Cloud OAuth Support](#multi-cloud-oauth-support) section for minimal configuration setup.

### ğŸ“¦ 2. Installation

MCP Atlassian is distributed as a Docker image. This is the recommended way to run the server, especially for IDE integration. Ensure you have Docker installed.

```bash
# Pull Pre-built Image
docker pull ghcr.io/sooperset/mcp-atlassian:latest
```

## ğŸ› ï¸ IDE Integration

MCP Atlassian is designed to be used with AI assistants through IDE integration.

&gt; [!TIP]
&gt; **For Claude Desktop**: Locate and edit the configuration file directly:
&gt; - **Windows**: `%APPDATA%\Claude\claude_desktop_config.json`
&gt; - **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`
&gt; - **Linux**: `~/.config/Claude/claude_desktop_config.json`
&gt;
&gt; **For Cursor**: Open Settings â†’ MCP â†’ + Add new global MCP server

### âš™ï¸ Configuration Methods

There are two main approaches to configure the Docker container:

1. **Passing Variables Directly** (shown in examples below)
2. **Using an Environment File** with `--env-file` flag (shown in collapsible sections)

&gt; [!NOTE]
&gt; Common environment variables include:
&gt;
&gt; - `CONFLUENCE_SPACES_FILTER`: Filter by space keys (e.g., &quot;DEV,TEAM,DOC&quot;)
&gt; - `JIRA_PROJECTS_FILTER`: Filter by project keys (e.g., &quot;PROJ,DEV,SUPPORT&quot;)
&gt; - `READ_ONLY_MODE`: Set to &quot;true&quot; to disable write operations
&gt; - `MCP_VERBOSE`: Set to &quot;true&quot; for more detailed logging
&gt; - `MCP_LOGGING_STDOUT`: Set to &quot;true&quot; to log to stdout instead of stderr
&gt; - `ENABLED_TOOLS`: Comma-separated list of tool names to enable (e.g., &quot;confluence_search,jira_get_issue&quot;)
&gt;
&gt; See the [.env.example](https://github.com/sooperset/mcp-atlassian/blob/main/.env.example) file for all available options.


### ğŸ“ Configuration Examples

**Method 1 (Passing Variables Directly):**
```json
{
  &quot;mcpServers&quot;: {
    &quot;mcp-atlassian&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;-i&quot;,
        &quot;--rm&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_URL&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_USERNAME&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_API_TOKEN&quot;,
        &quot;-e&quot;, &quot;JIRA_URL&quot;,
        &quot;-e&quot;, &quot;JIRA_USERNAME&quot;,
        &quot;-e&quot;, &quot;JIRA_API_TOKEN&quot;,
        &quot;ghcr.io/sooperset/mcp-atlassian:latest&quot;
      ],
      &quot;env&quot;: {
        &quot;CONFLUENCE_URL&quot;: &quot;https://your-company.atlassian.net/wiki&quot;,
        &quot;CONFLUENCE_USERNAME&quot;: &quot;your.email@company.com&quot;,
        &quot;CONFLUENCE_API_TOKEN&quot;: &quot;your_confluence_api_token&quot;,
        &quot;JIRA_URL&quot;: &quot;https://your-company.atlassian.net&quot;,
        &quot;JIRA_USERNAME&quot;: &quot;your.email@company.com&quot;,
        &quot;JIRA_API_TOKEN&quot;: &quot;your_jira_api_token&quot;
      }
    }
  }
}
```

&lt;details&gt;
&lt;summary&gt;Alternative: Using Environment File&lt;/summary&gt;

```json
{
  &quot;mcpServers&quot;: {
    &quot;mcp-atlassian&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;--rm&quot;,
        &quot;-i&quot;,
        &quot;--env-file&quot;,
        &quot;/path/to/your/mcp-atlassian.env&quot;,
        &quot;ghcr.io/sooperset/mcp-atlassian:latest&quot;
      ]
    }
  }
}
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Server/Data Center Configuration&lt;/summary&gt;

For Server/Data Center deployments, use direct variable passing:

```json
{
  &quot;mcpServers&quot;: {
    &quot;mcp-atlassian&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;--rm&quot;,
        &quot;-i&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_URL&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_PERSONAL_TOKEN&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_SSL_VERIFY&quot;,
        &quot;-e&quot;, &quot;JIRA_URL&quot;,
        &quot;-e&quot;, &quot;JIRA_PERSONAL_TOKEN&quot;,
        &quot;-e&quot;, &quot;JIRA_SSL_VERIFY&quot;,
        &quot;ghcr.io/sooperset/mcp-atlassian:latest&quot;
      ],
      &quot;env&quot;: {
        &quot;CONFLUENCE_URL&quot;: &quot;https://confluence.your-company.com&quot;,
        &quot;CONFLUENCE_PERSONAL_TOKEN&quot;: &quot;your_confluence_pat&quot;,
        &quot;CONFLUENCE_SSL_VERIFY&quot;: &quot;false&quot;,
        &quot;JIRA_URL&quot;: &quot;https://jira.your-company.com&quot;,
        &quot;JIRA_PERSONAL_TOKEN&quot;: &quot;your_jira_pat&quot;,
        &quot;JIRA_SSL_VERIFY&quot;: &quot;false&quot;
      }
    }
  }
}
```

&gt; [!NOTE]
&gt; Set `CONFLUENCE_SSL_VERIFY` and `JIRA_SSL_VERIFY` to &quot;false&quot; only if you have self-signed certificates.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;OAuth 2.0 Configuration (Cloud Only)&lt;/summary&gt;
&lt;a name=&quot;oauth-20-configuration-example-cloud-only&quot;&gt;&lt;/a&gt;

These examples show how to configure `mcp-atlassian` in your IDE (like Cursor or Claude Desktop) when using OAuth 2.0 for Atlassian Cloud.

**Example for Standard OAuth 2.0 Flow (using Setup Wizard):**

This configuration is for when you use the server&#039;s built-in OAuth client and have completed the [OAuth setup wizard](#c-oauth-20-authentication-cloud---advanced).

```json
{
  &quot;mcpServers&quot;: {
    &quot;mcp-atlassian&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;--rm&quot;,
        &quot;-i&quot;,
        &quot;-v&quot;, &quot;&lt;path_to_your_home&gt;/.mcp-atlassian:/home/app/.mcp-atlassian&quot;,
        &quot;-e&quot;, &quot;JIRA_URL&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_URL&quot;,
        &quot;-e&quot;, &quot;ATLASSIAN_OAUTH_CLIENT_ID&quot;,
        &quot;-e&quot;, &quot;ATLASSIAN_OAUTH_CLIENT_SECRET&quot;,
        &quot;-e&quot;, &quot;ATLASSIAN_OAUTH_REDIRECT_URI&quot;,
        &quot;-e&quot;, &quot;ATLASSIAN_OAUTH_SCOPE&quot;,
        &quot;-e&quot;, &quot;ATLASSIAN_OAUTH_CLOUD_ID&quot;,
        &quot;ghcr.io/sooperset/mcp-atlassian:latest&quot;
      ],
      &quot;env&quot;: {
        &quot;JIRA_URL&quot;: &quot;https://your-company.atlassian.net&quot;,
        &quot;CONFLUENCE_URL&quot;: &quot;https://your-company.atlassian.net/wiki&quot;,
        &quot;ATLASSIAN_OAUTH_CLIENT_ID&quot;: &quot;YOUR_OAUTH_APP_CLIENT_ID&quot;,
        &quot;ATLASSIAN_OAUTH_CLIENT_SECRET&quot;: &quot;YOUR_OAUTH_APP_CLIENT_SECRET&quot;,
        &quot;ATLASSIAN_OAUTH_REDIRECT_URI&quot;: &quot;http://localhost:8080/callback&quot;,
        &quot;ATLASSIAN_OAUTH_SCOPE&quot;: &quot;read:jira-work write:jira-work read:confluence-content.all write:confluence-content offline_access&quot;,
        &quot;ATLASSIAN_OAUTH_CLOUD_ID&quot;: &quot;YOUR_CLOUD_ID_FROM_SETUP_WIZARD&quot;
      }
    }
  }
}
```

&gt; [!NOTE]
&gt; - For the Standard Flow:
&gt;   - `ATLASSIAN_OAUTH_CLOUD_ID` is obtained from the `--oauth-setup` wizard output or is known for your instance.
&gt;   - Other `ATLASSIAN_OAUTH_*` client variables are from your OAuth app in the Atlassian Developer Console.
&gt;   - `JIRA_URL` and `CONFLUENCE_URL` for your Cloud instances are always required.
&gt;   - The volume mount (`-v .../.mcp-atlassian:/home/app/.mcp-atlassian`) is crucial for persisting the OAuth tokens obtained by the wizard, enabling automatic refresh.

**Example for Pre-existing Access Token (BYOT - Bring Your Own Token):**

This configuration is for when you are providing your own externally managed OAuth 2.0 access token.

```json
{
  &quot;mcpServers&quot;: {
    &quot;mcp-atlassian&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;--rm&quot;,
        &quot;-i&quot;,
        &quot;-e&quot;, &quot;JIRA_URL&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_URL&quot;,
        &quot;-e&quot;, &quot;ATLASSIAN_OAUTH_CLOUD_ID&quot;,
        &quot;-e&quot;, &quot;ATLASSIAN_OAUTH_ACCESS_TOKEN&quot;,
        &quot;ghcr.io/sooperset/mcp-atlassian:latest&quot;
      ],
      &quot;env&quot;: {
        &quot;JIRA_URL&quot;: &quot;https://your-company.atlassian.net&quot;,
        &quot;CONFLUENCE_URL&quot;: &quot;https://your-company.atlassian.net/wiki&quot;,
        &quot;ATLASSIAN_OAUTH_CLOUD_ID&quot;: &quot;YOUR_KNOWN_CLOUD_ID&quot;,
        &quot;ATLASSIAN_OAUTH_ACCESS_TOKEN&quot;: &quot;YOUR_PRE_EXISTING_OAUTH_ACCESS_TOKEN&quot;
      }
    }
  }
}
```

&gt; [!NOTE]
&gt; - For the BYOT Method:
&gt;   - You primarily need `JIRA_URL`, `CONFLUENCE_URL`, `ATLASSIAN_OAUTH_CLOUD_ID`, and `ATLASSIAN_OAUTH_ACCESS_TOKEN`.
&gt;   - Standard OAuth client variables (`ATLASSIAN_OAUTH_CLIENT_ID`, `CLIENT_SECRET`, `REDIRECT_URI`, `SCOPE`) are **not** used.
&gt;   - Token lifecycle (e.g., refreshing the token before it expires and restarting mcp-atlassian) is your responsibility, as the server will not refresh BYOT tokens.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Proxy Configuration&lt;/summary&gt;

MCP Atlassian supports routing API requests through standard HTTP/HTTPS/SOCKS proxies. Configure using environment variables:

- Supports standard `HTTP_PROXY`, `HTTPS_PROXY`, `NO_PROXY`, `SOCKS_PROXY`.
- Service-specific overrides are available (e.g., `JIRA_HTTPS_PROXY`, `CONFLUENCE_NO_PROXY`).
- Service-specific variables override global ones for that service.

Add the relevant proxy variables to the `args` (using `-e`) and `env` sections of your MCP configuration:

```json
{
  &quot;mcpServers&quot;: {
    &quot;mcp-atlassian&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;-i&quot;,
        &quot;--rm&quot;,
        &quot;-e&quot;, &quot;... existing Confluence/Jira vars&quot;,
        &quot;-e&quot;, &quot;HTTP_PROXY&quot;,
        &quot;-e&quot;, &quot;HTTPS_PROXY&quot;,
        &quot;-e&quot;, &quot;NO_PROXY&quot;,
        &quot;ghcr.io/sooperset/mcp-atlassian:latest&quot;
      ],
      &quot;env&quot;: {
        &quot;... existing Confluence/Jira vars&quot;: &quot;...&quot;,
        &quot;HTTP_PROXY&quot;: &quot;http://proxy.internal:8080&quot;,
        &quot;HTTPS_PROXY&quot;: &quot;http://proxy.internal:8080&quot;,
        &quot;NO_PROXY&quot;: &quot;localhost,.your-company.com&quot;
      }
    }
  }
}
```

Credentials in proxy URLs are masked in logs. If you set `NO_PROXY`, it will be respected for requests to matching hosts.

&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;Custom HTTP Headers Configuration&lt;/summary&gt;

MCP Atlassian supports adding custom HTTP headers to all API requests. This feature is particularly useful in corporate environments where additional headers are required for security, authentication, or routing purposes.

Custom headers are configured using environment variables with comma-separated key=value pairs:

```json
{
  &quot;mcpServers&quot;: {
    &quot;mcp-atlassian&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;-i&quot;,
        &quot;--rm&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_URL&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_USERNAME&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_API_TOKEN&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_CUSTOM_HEADERS&quot;,
        &quot;-e&quot;, &quot;JIRA_URL&quot;,
        &quot;-e&quot;, &quot;JIRA_USERNAME&quot;,
        &quot;-e&quot;, &quot;JIRA_API_TOKEN&quot;,
        &quot;-e&quot;, &quot;JIRA_CUSTOM_HEADERS&quot;,
        &quot;ghcr.io/sooperset/mcp-atlassian:latest&quot;
      ],
      &quot;env&quot;: {
        &quot;CONFLUENCE_URL&quot;: &quot;https://your-company.atlassian.net/wiki&quot;,
        &quot;CONFLUENCE_USERNAME&quot;: &quot;your.email@company.com&quot;,
        &quot;CONFLUENCE_API_TOKEN&quot;: &quot;your_confluence_api_token&quot;,
        &quot;CONFLUENCE_CUSTOM_HEADERS&quot;: &quot;X-Confluence-Service=mcp-integration,X-Custom-Auth=confluence-token,X-ALB-Token=secret-token&quot;,
        &quot;JIRA_URL&quot;: &quot;https://your-company.atlassian.net&quot;,
        &quot;JIRA_USERNAME&quot;: &quot;your.email@company.com&quot;,
        &quot;JIRA_API_TOKEN&quot;: &quot;your_jira_api_token&quot;,
        &quot;JIRA_CUSTOM_HEADERS&quot;: &quot;X-Forwarded-User=service-account,X-Company-Service=mcp-atlassian,X-Jira-Client=mcp-integration&quot;
      }
    }
  }
}
```

**Security Considerations:**

- Custom header values are masked in debug logs to protect sensitive information
- Ensure custom headers don&#039;t conflict with standard HTTP or Atlassian API headers
- Avoid including sensitive authentication tokens in custom headers if already using basic auth or OAuth
- Headers are sent with every API request - verify they don&#039;t interfere with API functionality

&lt;/details&gt;


&lt;details&gt;
&lt;summary&gt;Multi-Cloud OAuth Support&lt;/summary&gt;

MCP Atlassian supports multi-cloud OAuth scenarios where each user connects to their own Atlassian cloud instance. This is useful for multi-tenant applications, chatbots, or services where users provide their own OAuth tokens.

**Minimal OAuth Configuration:**

1. Enable minimal OAuth mode (no client credentials required):
   ```bash
   docker run -e ATLASSIAN_OAUTH_ENABLE=true -p 9000:9000 \
     ghcr.io/sooperset/mcp-atlassian:latest \
     --transport streamable-http --port 9000
   ```

2. Users provide authentication via HTTP headers:
   - `Authorization: Bearer &lt;user_oauth_token&gt;`
   - `X-Atlassian-Cloud-Id: &lt;user_cloud_id&gt;`

**Example Integration (Python):**
```python
import asyncio
from mcp.client.streamable_http import streamablehttp_client
from mcp import ClientSession

user_token = &quot;user-specific-oauth-token&quot;
user_cloud_id = &quot;user-specific-cloud-id&quot;

async def main():
    # Connect to streamable HTTP server with custom headers
    async with streamablehttp_client(
        &quot;http://localhost:9000/mcp&quot;,
        headers={
            &quot;Authorization&quot;: f&quot;Bearer {user_token}&quot;,
            &quot;X-Atlassian-Cloud-Id&quot;: user_cloud_id
        }
    ) as (read_stream, write_stream, _):
        # Create a session using the client streams
        async with ClientSession(read_stream, write_stream) as session:
            # Initialize the connection
            await session.initialize()

            # Example: Get a Jira issue
            result = await session.call_tool(
                &quot;jira_get_issue&quot;,
                {&quot;issue_key&quot;: &quot;PROJ-123&quot;}
            )
            print(result)

asyncio.run(main())
```

**Configuration Notes:**
- Each request can use a different cloud instance via the `X-Atlassian-Cloud-Id` header
- User tokens are isolated per request - no cross-tenant data leakage
- Falls back to global `ATLASSIAN_OAUTH_CLOUD_ID` if header not provided
- Compatible with standard OAuth 2.0 bearer token authentication

&lt;/details&gt;

&lt;details&gt; &lt;summary&gt;Single Service Configurations&lt;/summary&gt;

**For Confluence Cloud only:**

```json
{
  &quot;mcpServers&quot;: {
    &quot;mcp-atlassian&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;--rm&quot;,
        &quot;-i&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_URL&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_USERNAME&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_API_TOKEN&quot;,
        &quot;ghcr.io/sooperset/mcp-atlassian:latest&quot;
      ],
      &quot;env&quot;: {
        &quot;CONFLUENCE_URL&quot;: &quot;https://your-company.atlassian.net/wiki&quot;,
        &quot;CONFLUENCE_USERNAME&quot;: &quot;your.email@company.com&quot;,
        &quot;CONFLUENCE_API_TOKEN&quot;: &quot;your_api_token&quot;
      }
    }
  }
}
```

For Confluence Server/DC, use:
```json
{
  &quot;mcpServers&quot;: {
    &quot;mcp-atlassian&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;--rm&quot;,
        &quot;-i&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_URL&quot;,
        &quot;-e&quot;, &quot;CONFLUENCE_PERSONAL_TOKEN&quot;,
        &quot;ghcr.io/sooperset/mcp-atlassian:latest&quot;
      ],
      &quot;env&quot;: {
        &quot;CONFLUENCE_URL&quot;: &quot;https://confluence.your-company.com&quot;,
        &quot;CONFLUENCE_PERSONAL_TOKEN&quot;: &quot;your_personal_token&quot;
      }
    }
  }
}
```

**For Jira Cloud only:**

```json
{
  &quot;mcpServers&quot;: {
    &quot;mcp-atlassian&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;--rm&quot;,
        &quot;-i&quot;,
        &quot;-e&quot;, &quot;JIRA_URL&quot;,
        &quot;-e&quot;, &quot;JIRA_USERNAME&quot;,
        &quot;-e&quot;, &quot;JIRA_API_TOKEN&quot;,
        &quot;ghcr.io/sooperset/mcp-atlassian:latest&quot;
      ],
      &quot;env&quot;: {
        &quot;JIRA_URL&quot;: &quot;https://your-company.atlassian.net&quot;,
        &quot;JIRA_USERNAME&quot;: &quot;your.email@company.com&quot;,
        &quot;JIRA_API_TOKEN&quot;: &quot;your_api_token&quot;
      }
    }
 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[OpenBB-finance/OpenBB]]></title>
            <link>https://github.com/OpenBB-finance/OpenBB</link>
            <guid>https://github.com/OpenBB-finance/OpenBB</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:48 GMT</pubDate>
            <description><![CDATA[Investment Research for Everyone, Everywhere.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/OpenBB-finance/OpenBB">OpenBB-finance/OpenBB</a></h1>
            <p>Investment Research for Everyone, Everywhere.</p>
            <p>Language: Python</p>
            <p>Stars: 44,105</p>
            <p>Forks: 3,976</p>
            <p>Stars today: 495 stars today</p>
            <h2>README</h2><pre>&lt;br /&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/platform-light.svg?raw=true#gh-light-mode-only&quot; alt=&quot;OpenBB Platform logo&quot; width=&quot;600&quot;&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only&quot; alt=&quot;OpenBB Platform logo&quot; width=&quot;600&quot;&gt;
&lt;br /&gt;
&lt;br /&gt;

[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;label=Follow%20%40openbb_finance)](https://x.com/openbb_finance)
[![Discord Shield](https://img.shields.io/discord/831165782750789672)](https://discord.com/invite/xPHTuHCmuV)
[![Open in Dev Containers](https://img.shields.io/static/v1?label=Dev%20Containers&amp;message=Open&amp;color=blue&amp;logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB)
&lt;a href=&quot;https://codespaces.new/OpenBB-finance/OpenBB&quot;&gt;
  &lt;img src=&quot;https://github.com/codespaces/badge.svg&quot; height=&quot;20&quot; /&gt;
&lt;/a&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb&quot;&gt;
  &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open In Colab&quot;/&gt;
&lt;/a&gt;
[![PyPI](https://img.shields.io/pypi/v/openbb?color=blue&amp;label=PyPI%20Package)](https://pypi.org/project/openbb/)

The first financial Platform that is open source.

The OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.

Get started with: `pip install openbb`

```python
from openbb import obb
output = obb.equity.price.historical(&quot;AAPL&quot;)
df = output.to_dataframe()
```

You can sign up to the [OpenBB Hub](https://my.openbb.co/login) to get the most out of the OpenBB ecosystem.

Data integrations available can be found here: &lt;https://docs.openbb.co/platform/reference&gt;

---

## OpenBB Workspace

While the OpenBB Platform is all about an integration to dozens of different data vendors, the interface is either Python or a CLI.

If you want an enterprise UI to visualize this datasets and use AI agents on top, you can find OpenBB Workspace at &lt;https://pro.openbb.co&gt;.

&lt;a href=&quot;https://pro.openbb.co&quot;&gt;
  &lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png&quot; alt=&quot;Logo&quot; width=&quot;1000&quot;&gt;
  &lt;/div&gt;
&lt;/a&gt;

Data integration:

- You can learn more about adding data to the OpenBB workspace from the [docs](https://docs.openbb.co/workspace) or [this open source repository](https://github.com/OpenBB-finance/backends-for-openbb).

AI Agents integration:

- You can learn more about adding AI agents to the OpenBB workspace from [this open source repository](https://github.com/OpenBB-finance/agents-for-openbb).

### Integrating OpenBB Platform to the OpenBB Workspace

Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.

#### Run OpenBB Platform backend

- Install the packages.

```sh
pip install &quot;openbb[all]&quot;
```

- Start the API server over localhost.

```sh
openbb-api
```

This will launch a FastAPI server, via Uvicorn, at `127.0.0.1:6900`.

You can check that it works by going to &lt;http://127.0.0.1:6900&gt;.

#### Integrate OpenBB Platform backend to OpenBB Workspace

Sign-in to the [OpenBB Workspace](https://pro.openbb.co/), and follow the following steps:

![CleanShot 2025-05-17 at 09 51 56@2x](https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069)

1. Go to the &quot;Apps&quot; tab
2. Click on &quot;Connect backend&quot;
3. Fill in the form with:
   Name: OpenBB Platform
   URL: &lt;http://127.0.0.1:6900&gt;
4. Click on &quot;Test&quot;. You should get a &quot;Test successful&quot; with the number of apps found.
5. Click on &quot;Add&quot;.

That&#039;s it.

---

&lt;!-- TABLE OF CONTENTS --&gt;
&lt;details closed=&quot;closed&quot;&gt;
  &lt;summary&gt;&lt;h2 style=&quot;display: inline-block&quot;&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt;
  &lt;ol&gt;
    &lt;li&gt;&lt;a href=&quot;#1-installation&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#2-contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#3-license&quot;&gt;License&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#4-disclaimer&quot;&gt;Disclaimer&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#5-contacts&quot;&gt;Contacts&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#6-star-history&quot;&gt;Star History&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#7-contributors&quot;&gt;Contributors&lt;/a&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/details&gt;

## 1. Installation

The OpenBB Platform can be installed as a [PyPI package](https://pypi.org/project/openbb/) by running `pip install openbb`

or by cloning the repository directly with `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process, in the [OpenBB Documentation](https://docs.openbb.co/platform/installation).

### OpenBB Platform CLI installation

The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.

It can be installed by running `pip install openbb-cli`

or by cloning the repository directly with  `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process in the [OpenBB Documentation](https://docs.openbb.co/cli/installation).

## 2. Contributing

There are three main ways of contributing to this project. (Hopefully you have starred the project by now â­ï¸)

### Become a Contributor

- More information on our [Contributing Documentation](https://docs.openbb.co/platform/developer_guide/misc/contributing).

### Create a GitHub ticket

Before creating a ticket make sure the one you are creating doesn&#039;t exist already [here](https://github.com/OpenBB-finance/OpenBB/issues)

- [Report bug](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.md&amp;title=%5BBug%5D)
- [Suggest improvement](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=enhancement&amp;template=enhancement.md&amp;title=%5BIMPROVE%5D)
- [Request a feature](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=new+feature&amp;template=feature_request.md&amp;title=%5BFR%5D)

### Provide feedback

We are most active on [our Discord](https://openbb.co/discord), but feel free to reach out to us in any of [our social media](https://openbb.co/links) for feedback.

## 3. License

Distributed under the AGPLv3 License. See
[LICENSE](https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE) for more information.

## 4. Disclaimer

Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment
amount, and may not be suitable for all investors.

Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.

The data contained in the OpenBB Platform is not necessarily accurate.

OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.

All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.

Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.

## 5. Contacts

If you have any questions about the platform or anything OpenBB, feel free to email us at `support@openbb.co`

If you want to say hi, or are interested in partnering with us, feel free to reach us at `hello@openbb.co`

Any of our social media platforms: [openbb.co/links](https://openbb.co/links)

## 6. Star History

This is a proxy of our growth and that we are just getting started.

But for more metrics important to us check [openbb.co/open](https://openbb.co/open).

[![Star History Chart](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)

## 7. Contributors

OpenBB wouldn&#039;t be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.

&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/graphs/contributors&quot;&gt;
   &lt;img src=&quot;https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB&quot; width=&quot;800&quot;/&gt;
&lt;/a&gt;

&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt;
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;

[contributors-shield]: https://img.shields.io/github/contributors/OpenBB-finance/OpenBB.svg?style=for-the-badge
[contributors-url]: https://github.com/OpenBB-finance/OpenBB/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/OpenBB-finance/OpenBB.svg?style=for-the-badge
[forks-url]: https://github.com/OpenBB-finance/OpenBB/network/members
[stars-shield]: https://img.shields.io/github/stars/OpenBB-finance/OpenBB.svg?style=for-the-badge
[stars-url]: https://github.com/OpenBB-finance/OpenBB/stargazers
[issues-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB.svg?style=for-the-badge&amp;color=blue
[issues-url]: https://github.com/OpenBB-finance/OpenBB/issues
[bugs-open-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=yellow
[bugs-open-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aopen
[bugs-closed-shield]: https://img.shields.io/github/issues-closed/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=success
[bugs-closed-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aclosed
[license-shield]: https://img.shields.io/github/license/OpenBB-finance/OpenBB.svg?style=for-the-badge
[license-url]: https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&amp;logo=linkedin&amp;colorB=555
[linkedin-url]: https://linkedin.com/in/DidierRLopes
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[paperless-ngx/paperless-ngx]]></title>
            <link>https://github.com/paperless-ngx/paperless-ngx</link>
            <guid>https://github.com/paperless-ngx/paperless-ngx</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:47 GMT</pubDate>
            <description><![CDATA[A community-supported supercharged document management system: scan, index and archive all your documents]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/paperless-ngx/paperless-ngx">paperless-ngx/paperless-ngx</a></h1>
            <p>A community-supported supercharged document management system: scan, index and archive all your documents</p>
            <p>Language: Python</p>
            <p>Stars: 29,451</p>
            <p>Forks: 1,758</p>
            <p>Stars today: 62 stars today</p>
            <h2>README</h2><pre>[![ci](https://github.com/paperless-ngx/paperless-ngx/workflows/ci/badge.svg)](https://github.com/paperless-ngx/paperless-ngx/actions)
[![Crowdin](https://badges.crowdin.net/paperless-ngx/localized.svg)](https://crowdin.com/project/paperless-ngx)
[![Documentation Status](https://img.shields.io/github/deployments/paperless-ngx/paperless-ngx/github-pages?label=docs)](https://docs.paperless-ngx.com)
[![codecov](https://codecov.io/gh/paperless-ngx/paperless-ngx/branch/main/graph/badge.svg?token=VK6OUPJ3TY)](https://codecov.io/gh/paperless-ngx/paperless-ngx)
[![Chat on Matrix](https://matrix.to/img/matrix-badge.svg)](https://matrix.to/#/%23paperlessngx%3Amatrix.org)
[![demo](https://cronitor.io/badges/ve7ItY/production/W5E_B9jkelG9ZbDiNHUPQEVH3MY.svg)](https://demo.paperless-ngx.com)

&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/paperless-ngx/paperless-ngx/blob/main/resources/logo/web/png/White%20logo%20-%20no%20background.png&quot; width=&quot;50%&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/paperless-ngx/paperless-ngx/raw/main/resources/logo/web/png/Black%20logo%20-%20no%20background.png&quot; width=&quot;50%&quot;&gt;
    &lt;img src=&quot;https://github.com/paperless-ngx/paperless-ngx/raw/main/resources/logo/web/png/Black%20logo%20-%20no%20background.png&quot; width=&quot;50%&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;!-- omit in toc --&gt;

# Paperless-ngx

Paperless-ngx is a document management system that transforms your physical documents into a searchable online archive so you can keep, well, _less paper_.

Paperless-ngx is the official successor to the original [Paperless](https://github.com/the-paperless-project/paperless) &amp; [Paperless-ng](https://github.com/jonaswinkler/paperless-ng) projects and is designed to distribute the responsibility of advancing and supporting the project among a team of people. [Consider joining us!](#community-support)

Thanks to the generous folks at [DigitalOcean](https://m.do.co/c/8d70b916d462), a demo is available at [demo.paperless-ngx.com](https://demo.paperless-ngx.com) using login `demo` / `demo`. _Note: demo content is reset frequently and confidential information should not be uploaded._

- [Features](#features)
- [Getting started](#getting-started)
- [Contributing](#contributing)
  - [Community Support](#community-support)
  - [Translation](#translation)
  - [Feature Requests](#feature-requests)
  - [Bugs](#bugs)
- [Related Projects](#related-projects)
- [Important Note](#important-note)

&lt;p align=&quot;right&quot;&gt;This project is supported by:&lt;br/&gt;
  &lt;a href=&quot;https://m.do.co/c/8d70b916d462&quot; style=&quot;padding-top: 4px; display: block;&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_white.svg&quot; width=&quot;140px&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_blue.svg&quot; width=&quot;140px&quot;&gt;
      &lt;img src=&quot;https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_black_.svg&quot; width=&quot;140px&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

# Features

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/docs/assets/screenshots/documents-smallcards-dark.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/docs/assets/screenshots/documents-smallcards.png&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/docs/assets/screenshots/documents-smallcards.png&quot;&gt;
&lt;/picture&gt;

A full list of [features](https://docs.paperless-ngx.com/#features) and [screenshots](https://docs.paperless-ngx.com/#screenshots) are available in the [documentation](https://docs.paperless-ngx.com/).

# Getting started

The easiest way to deploy paperless is `docker compose`. The files in the [`/docker/compose` directory](https://github.com/paperless-ngx/paperless-ngx/tree/main/docker/compose) are configured to pull the image from the GitHub container registry.

If you&#039;d like to jump right in, you can configure a `docker compose` environment with our install script:

```bash
bash -c &quot;$(curl -L https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/install-paperless-ngx.sh)&quot;
```

More details and step-by-step guides for alternative installation methods can be found in [the documentation](https://docs.paperless-ngx.com/setup/#installation).

Migrating from Paperless-ng is easy, just drop in the new docker image! See the [documentation on migrating](https://docs.paperless-ngx.com/setup/#migrating-to-paperless-ngx) for more details.

&lt;!-- omit in toc --&gt;

### Documentation

The documentation for Paperless-ngx is available at [https://docs.paperless-ngx.com](https://docs.paperless-ngx.com/).

# Contributing

If you feel like contributing to the project, please do! Bug fixes, enhancements, visual fixes etc. are always welcome. If you want to implement something big: Please start a discussion about that! The [documentation](https://docs.paperless-ngx.com/development/) has some basic information on how to get started.

## Community Support

People interested in continuing the work on paperless-ngx are encouraged to reach out here on github and in the [Matrix Room](https://matrix.to/#/#paperless:matrix.org). If you would like to contribute to the project on an ongoing basis there are multiple [teams](https://github.com/orgs/paperless-ngx/people) (frontend, ci/cd, etc) that could use your help so please reach out!

## Translation

Paperless-ngx is available in many languages that are coordinated on Crowdin. If you want to help out by translating paperless-ngx into your language, please head over to https://crowdin.com/project/paperless-ngx, and thank you! More details can be found in [CONTRIBUTING.md](https://github.com/paperless-ngx/paperless-ngx/blob/main/CONTRIBUTING.md#translating-paperless-ngx).

## Feature Requests

Feature requests can be submitted via [GitHub Discussions](https://github.com/paperless-ngx/paperless-ngx/discussions/categories/feature-requests), you can search for existing ideas, add your own and vote for the ones you care about.

## Bugs

For bugs please [open an issue](https://github.com/paperless-ngx/paperless-ngx/issues) or [start a discussion](https://github.com/paperless-ngx/paperless-ngx/discussions) if you have questions.

# Related Projects

Please see [the wiki](https://github.com/paperless-ngx/paperless-ngx/wiki/Related-Projects) for a user-maintained list of related projects and software that is compatible with Paperless-ngx.

# Important Note

&gt; Document scanners are typically used to scan sensitive documents like your social insurance number, tax records, invoices, etc. **Paperless-ngx should never be run on an untrusted host** because information is stored in clear text without encryption. No guarantees are made regarding security (but we do try!) and you use the app at your own risk.
&gt; **The safest way to run Paperless-ngx is on a local server in your own home with backups in place**.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[langchain-ai/open_deep_research]]></title>
            <link>https://github.com/langchain-ai/open_deep_research</link>
            <guid>https://github.com/langchain-ai/open_deep_research</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:46 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/langchain-ai/open_deep_research">langchain-ai/open_deep_research</a></h1>
            <p></p>
            <p>Language: Python</p>
            <p>Stars: 6,032</p>
            <p>Forks: 818</p>
            <p>Stars today: 245 stars today</p>
            <h2>README</h2><pre># Open Deep Research

&lt;img width=&quot;1388&quot; height=&quot;298&quot; alt=&quot;full_diagram&quot; src=&quot;https://github.com/user-attachments/assets/12a2371b-8be2-4219-9b48-90503eb43c69&quot; /&gt;

Deep research has broken out as one of the most popular agent applications. This is a simple, configurable, fully open source deep research agent that works across many model providers, search tools, and MCP servers. 

* Read more in our [blog](https://blog.langchain.com/open-deep-research/) 
* See our [video](https://www.youtube.com/watch?v=agGiWUpxkhg) for a quick overview

### ğŸš€ Quickstart

1. Clone the repository and activate a virtual environment:
```bash
git clone https://github.com/langchain-ai/open_deep_research.git
cd open_deep_research
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

2. Install dependencies:
```bash
uv pip install -r pyproject.toml
```

3. Set up your `.env` file to customize the environment variables (for model selection, search tools, and other configuration settings):
```bash
cp .env.example .env
```

4. Launch the assistant with the LangGraph server locally to open LangGraph Studio in your browser:

```bash
# Install dependencies and start the LangGraph server
uvx --refresh --from &quot;langgraph-cli[inmem]&quot; --with-editable . --python 3.11 langgraph dev --allow-blocking
```

Use this to open the Studio UI:
```
- ğŸš€ API: http://127.0.0.1:2024
- ğŸ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
- ğŸ“š API Docs: http://127.0.0.1:2024/docs
```
&lt;img width=&quot;817&quot; height=&quot;666&quot; alt=&quot;Screenshot 2025-07-13 at 11 21 12â€¯PM&quot; src=&quot;https://github.com/user-attachments/assets/052f2ed3-c664-4a4f-8ec2-074349dcaa3f&quot; /&gt;

Ask a question in the `messages` input field and click `Submit`.

### Configurations

Open Deep Research offers extensive configuration options to customize the research process and model behavior. All configurations can be set via the web UI, environment variables, or by modifying the configuration directly.

#### General Settings

- **Max Structured Output Retries** (default: 3): Maximum number of retries for structured output calls from models when parsing fails
- **Allow Clarification** (default: true): Whether to allow the researcher to ask clarifying questions before starting research
- **Max Concurrent Research Units** (default: 5): Maximum number of research units to run concurrently using sub-agents. Higher values enable faster research but may hit rate limits

#### Research Configuration

- **Search API** (default: Tavily): Choose from Tavily (works with all models), OpenAI Native Web Search, Anthropic Native Web Search, or None
- **Max Researcher Iterations** (default: 3): Number of times the Research Supervisor will reflect on research and ask follow-up questions
- **Max React Tool Calls** (default: 5): Maximum number of tool calling iterations in a single researcher step

#### Models

Open Deep Research uses multiple specialized models for different research tasks:

- **Summarization Model** (default: `openai:gpt-4.1-nano`): Summarizes research results from search APIs
- **Research Model** (default: `openai:gpt-4.1`): Conducts research and analysis 
- **Compression Model** (default: `openai:gpt-4.1-mini`): Compresses research findings from sub-agents
- **Final Report Model** (default: `openai:gpt-4.1`): Writes the final comprehensive report

All models are configured using [init_chat_model() API](https://python.langchain.com/docs/how_to/chat_models_universal_init/) which supports providers like OpenAI, Anthropic, Google Vertex AI, and others.

**Important Model Requirements:**

1. **Structured Outputs**: All models must support structured outputs. Check support [here](https://python.langchain.com/docs/integrations/chat/).

2. **Search API Compatibility**: Research and Compression models must support your selected search API:
   - Anthropic search requires Anthropic models with web search capability
   - OpenAI search requires OpenAI models with web search capability  
   - Tavily works with all models

3. **Tool Calling**: All models must support tool calling functionality

4. **Special Configurations**:
   - For OpenRouter: Follow [this guide](https://github.com/langchain-ai/open_deep_research/issues/75#issuecomment-2811472408)
   - For local models via Ollama: See [setup instructions](https://github.com/langchain-ai/open_deep_research/issues/65#issuecomment-2743586318)

#### Example MCP (Model Context Protocol) Servers

Open Deep Research supports MCP servers to extend research capabilities. 

#### Local MCP Servers

**Filesystem MCP Server** provides secure file system operations with robust access control:
- Read, write, and manage files and directories
- Perform operations like reading file contents, creating directories, moving files, and searching
- Restrict operations to predefined directories for security
- Support for both command-line configuration and dynamic MCP roots

Example usage:
```bash
mcp-server-filesystem /path/to/allowed/dir1 /path/to/allowed/dir2
```

#### Remote MCP Servers  

**Remote MCP servers** enable distributed agent coordination and support streamable HTTP requests. Unlike local servers, they can be multi-tenant and require more complex authentication.

**Arcade MCP Server Example**:
```json
{
  &quot;url&quot;: &quot;https://api.arcade.dev/v1/mcps/ms_0ujssxh0cECutqzMgbtXSGnjorm&quot;,
  &quot;tools&quot;: [&quot;Search_SearchHotels&quot;, &quot;Search_SearchOneWayFlights&quot;, &quot;Search_SearchRoundtripFlights&quot;]
}
```

Remote servers can be configured as authenticated or unauthenticated and support JWT-based authentication through OAuth endpoints.

### Evaluation

A comprehensive batch evaluation system designed for detailed analysis and comparative studies.

#### **Features:**
- **Multi-dimensional Scoring**: Specialized evaluators with 0-1 scale ratings
- **Dataset-driven Evaluation**: Batch processing across multiple test cases

#### **Usage:**
```bash
# Run comprehensive evaluation on LangSmith datasets
python tests/run_evaluate.py
```
#### **Key Files:**
- `tests/run_evaluate.py`: Main evaluation script
- `tests/evaluators.py`: Specialized evaluator functions
- `tests/prompts.py`: Evaluation prompts for each dimension

### Deployments and Usages

#### LangGraph Studio

Follow the [quickstart](#-quickstart) to start LangGraph server locally and test the agent out on LangGraph Studio.

#### Hosted deployment
 
You can easily deploy to [LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/#deployment-options). 

#### Open Agent Platform

Open Agent Platform (OAP) is a UI from which non-technical users can build and configure their own agents. OAP is great for allowing users to configure the Deep Researcher with different MCP tools and search APIs that are best suited to their needs and the problems that they want to solve.

We&#039;ve deployed Open Deep Research to our public demo instance of OAP. All you need to do is add your API Keys, and you can test out the Deep Researcher for yourself! Try it out [here](https://oap.langchain.com)

You can also deploy your own instance of OAP, and make your own custom agents (like Deep Researcher) available on it to your users.
1. [Deploy Open Agent Platform](https://docs.oap.langchain.com/quickstart)
2. [Add Deep Researcher to OAP](https://docs.oap.langchain.com/setup/agents)

### Updates ğŸ”¥

### Legacy Implementations ğŸ›ï¸

The `src/legacy/` folder contains two earlier implementations that provide alternative approaches to automated research:

#### 1. Workflow Implementation (`legacy/graph.py`)
- **Plan-and-Execute**: Structured workflow with human-in-the-loop planning
- **Sequential Processing**: Creates sections one by one with reflection
- **Interactive Control**: Allows feedback and approval of report plans
- **Quality Focused**: Emphasizes accuracy through iterative refinement

#### 2. Multi-Agent Implementation (`legacy/multi_agent.py`)  
- **Supervisor-Researcher Architecture**: Coordinated multi-agent system
- **Parallel Processing**: Multiple researchers work simultaneously
- **Speed Optimized**: Faster report generation through concurrency
- **MCP Support**: Extensive Model Context Protocol integration

See `src/legacy/legacy.md` for detailed documentation, configuration options, and usage examples for both legacy implementations.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[seleniumbase/SeleniumBase]]></title>
            <link>https://github.com/seleniumbase/SeleniumBase</link>
            <guid>https://github.com/seleniumbase/SeleniumBase</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:45 GMT</pubDate>
            <description><![CDATA[Python APIs for web automation, testing, and bypassing bot-detection.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/seleniumbase/SeleniumBase">seleniumbase/SeleniumBase</a></h1>
            <p>Python APIs for web automation, testing, and bypassing bot-detection.</p>
            <p>Language: Python</p>
            <p>Stars: 11,417</p>
            <p>Forks: 1,396</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;!-- SeleniumBase Docs --&gt;

&lt;meta property=&quot;og:site_name&quot; content=&quot;SeleniumBase&quot;&gt;
&lt;meta property=&quot;og:title&quot; content=&quot;SeleniumBase: Python Web Automation and E2E Testing&quot; /&gt;
&lt;meta property=&quot;og:description&quot; content=&quot;Fast, easy, and reliable Web/UI testing with Python.&quot; /&gt;
&lt;meta property=&quot;og:keywords&quot; content=&quot;Python, pytest, selenium, webdriver, testing, automation, seleniumbase, framework, dashboard, recorder, reports, screenshots&quot;&gt;
&lt;meta property=&quot;og:image&quot; content=&quot;https://seleniumbase.github.io/cdn/img/mac_sb_logo_5b.png&quot; /&gt;
&lt;link rel=&quot;icon&quot; href=&quot;https://seleniumbase.github.io/img/logo7.png&quot; /&gt;

&lt;h1&gt;SeleniumBase&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/&quot;&gt;&lt;img src=&quot;https://seleniumbase.github.io/cdn/img/super_logo_sb3.png&quot; alt=&quot;SeleniumBase&quot; title=&quot;SeleniumBase&quot; width=&quot;350&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot; class=&quot;hero__title&quot;&gt;&lt;b&gt;All-in-one Browser Automation Framework:&lt;br /&gt;Web Crawling / Testing / Scraping / Stealth&lt;/b&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://pypi.python.org/pypi/seleniumbase&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/seleniumbase.svg?color=3399EE&quot; alt=&quot;PyPI version&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/releases&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/seleniumbase/SeleniumBase.svg?color=22AAEE&quot; alt=&quot;GitHub version&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://seleniumbase.io&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/docs-seleniumbase.io-11BBAA.svg&quot; alt=&quot;SeleniumBase Docs&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/actions&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/seleniumbase/SeleniumBase/workflows/CI%20build/badge.svg&quot; alt=&quot;SeleniumBase GitHub Actions&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/EdhQTn3EyE&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/727927627830001734?color=7289DA&amp;label=Discord&amp;logo=discord&amp;logoColor=white&quot;/&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;#python_installation&quot;&gt;ğŸš€ Start&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/features_list.md&quot;&gt;ğŸ° Features&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/customizing_test_runs.md&quot;&gt;ğŸ›ï¸ Options&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/ReadMe.md&quot;&gt;ğŸ“š Examples&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/seleniumbase/console_scripts/ReadMe.md&quot;&gt;ğŸŒ  Scripts&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/mobile_testing.md&quot;&gt;ğŸ“± Mobile&lt;/a&gt;
&lt;br /&gt;
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/method_summary.md&quot;&gt;ğŸ“˜ APIs&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/syntax_formats.md&quot;&gt; ğŸ”  Formats&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/recorder_mode.md&quot;&gt;ğŸ”´ Recorder&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/example_logs/ReadMe.md&quot;&gt;ğŸ“Š Dashboard&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/locale_codes.md&quot;&gt;ğŸ—¾ Locales&lt;/a&gt; |
&lt;a href=&quot;https://seleniumbase.io/devices/?url=seleniumbase.com&quot;&gt;ğŸ’» Farm&lt;/a&gt;
&lt;br /&gt;
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/commander.md&quot;&gt;ğŸ–ï¸ GUI&lt;/a&gt; |
&lt;a href=&quot;https://seleniumbase.io/demo_page&quot;&gt;ğŸ“° TestPage&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/uc_mode.md&quot;&gt;ğŸ‘¤ UC Mode&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/cdp_mode/ReadMe.md&quot;&gt;ğŸ™ CDP Mode&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/chart_maker/ReadMe.md&quot;&gt;ğŸ“¶ Charts&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/seleniumbase/utilities/selenium_grid/ReadMe.md&quot;&gt;ğŸŒ Grid&lt;/a&gt;
&lt;br /&gt;
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/how_it_works.md&quot;&gt;ğŸ‘ï¸ How&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/tree/master/examples/migration/raw_selenium&quot;&gt;ğŸš Migrate&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/case_plans.md&quot;&gt;ğŸ—‚ï¸ CasePlans&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/tree/master/examples/boilerplates&quot;&gt;â™»ï¸ Template&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/master_qa/ReadMe.md&quot;&gt;ğŸ§¬ Hybrid&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/tour_examples/ReadMe.md&quot;&gt;ğŸš Tours&lt;/a&gt;
&lt;br /&gt;
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/integrations/github/workflows/ReadMe.md&quot;&gt;ğŸ¤– CI/CD&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/js_package_manager.md&quot;&gt;ğŸ•¹ï¸ JSMgr&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/translations.md&quot;&gt;ğŸŒ Translator&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/presenter/ReadMe.md&quot;&gt;ğŸï¸ Presenter&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/dialog_boxes/ReadMe.md&quot;&gt;ğŸ›‚ Dialog&lt;/a&gt; |
&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/visual_testing/ReadMe.md&quot;&gt;ğŸ–¼ï¸ Visual&lt;/a&gt;
&lt;br /&gt;
&lt;/p&gt;

&lt;p&gt;SeleniumBase is the professional toolkit for web automation activities. Built for testing websites, bypassing CAPTCHAs, enhancing productivity, completing tasks, and scaling your business.&lt;/p&gt;

--------

ğŸ“š Learn from [**over 200 examples** in the **SeleniumBase/examples/** folder](https://github.com/seleniumbase/SeleniumBase/tree/master/examples).

ğŸ™ Note that &lt;a translate=&quot;no&quot; href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/uc_mode.md&quot;&gt;&lt;b&gt;UC Mode&lt;/b&gt;&lt;/a&gt; / &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/cdp_mode/ReadMe.md&quot;&gt;&lt;b&gt;CDP Mode&lt;/b&gt;&lt;/a&gt; (Stealth Mode) have their own ReadMe files.

â„¹ï¸ Most scripts run with raw &lt;code translate=&quot;no&quot;&gt;&lt;b&gt;python&lt;/b&gt;&lt;/code&gt;, although some scripts use &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/syntax_formats.md&quot;&gt;Syntax Formats&lt;/a&gt; that expect &lt;a href=&quot;https://docs.pytest.org/en/latest/how-to/usage.html&quot; translate=&quot;no&quot;&gt;&lt;b&gt;pytest&lt;/b&gt;&lt;/a&gt; (a Python unit-testing framework included with SeleniumBase that can discover, collect, and run tests automatically).

--------

&lt;p align=&quot;left&quot;&gt;ğŸ“— Here&#039;s &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/raw_google.py&quot;&gt;raw_google.py&lt;/a&gt;, which performs a Google search:&lt;/p&gt;

```python
from seleniumbase import SB

with SB(test=True, uc=True) as sb:
    sb.open(&quot;https://google.com/ncr&quot;)
    sb.type(&#039;[title=&quot;Search&quot;]&#039;, &quot;SeleniumBase GitHub page\n&quot;)
    sb.click(&#039;[href*=&quot;github.com/seleniumbase/&quot;]&#039;)
    sb.save_screenshot_to_logs()  # ./latest_logs/
    print(sb.get_page_title())
```

&gt; `python raw_google.py`

&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/raw_google.py&quot;&gt;&lt;img src=&quot;https://seleniumbase.github.io/cdn/gif/google_search.gif&quot; alt=&quot;SeleniumBase Test&quot; title=&quot;SeleniumBase Test&quot; width=&quot;480&quot; /&gt;&lt;/a&gt;

--------

&lt;p align=&quot;left&quot;&gt;ğŸ“— Here&#039;s an example of bypassing Cloudflare&#039;s challenge page: &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/cdp_mode/raw_gitlab.py&quot;&gt;SeleniumBase/examples/cdp_mode/raw_gitlab.py&lt;/a&gt;&lt;/p&gt;

```python
from seleniumbase import SB

with SB(uc=True, test=True, locale=&quot;en&quot;) as sb:
    url = &quot;https://gitlab.com/users/sign_in&quot;
    sb.activate_cdp_mode(url)
    sb.uc_gui_click_captcha()
    sb.sleep(2)
```

&lt;img src=&quot;https://seleniumbase.github.io/other/cf_sec.jpg&quot; title=&quot;SeleniumBase&quot; width=&quot;332&quot;&gt; &lt;img src=&quot;https://seleniumbase.github.io/other/gitlab_bypass.png&quot; title=&quot;SeleniumBase&quot; width=&quot;288&quot;&gt;

--------

&lt;p align=&quot;left&quot;&gt;ğŸ“— Here&#039;s &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/test_get_swag.py&quot;&gt;test_get_swag.py&lt;/a&gt;, which tests an e-commerce site:&lt;/p&gt;

```python
from seleniumbase import BaseCase
BaseCase.main(__name__, __file__)  # Call pytest

class MyTestClass(BaseCase):
    def test_swag_labs(self):
        self.open(&quot;https://www.saucedemo.com&quot;)
        self.type(&quot;#user-name&quot;, &quot;standard_user&quot;)
        self.type(&quot;#password&quot;, &quot;secret_sauce\n&quot;)
        self.assert_element(&quot;div.inventory_list&quot;)
        self.click(&#039;button[name*=&quot;backpack&quot;]&#039;)
        self.click(&quot;#shopping_cart_container a&quot;)
        self.assert_text(&quot;Backpack&quot;, &quot;div.cart_item&quot;)
        self.click(&quot;button#checkout&quot;)
        self.type(&quot;input#first-name&quot;, &quot;SeleniumBase&quot;)
        self.type(&quot;input#last-name&quot;, &quot;Automation&quot;)
        self.type(&quot;input#postal-code&quot;, &quot;77123&quot;)
        self.click(&quot;input#continue&quot;)
        self.click(&quot;button#finish&quot;)
        self.assert_text(&quot;Thank you for your order!&quot;)
```

&gt; `pytest test_get_swag.py`

&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/test_get_swag.py&quot;&gt;&lt;img src=&quot;https://seleniumbase.github.io/cdn/gif/fast_swag_2.gif&quot; alt=&quot;SeleniumBase Test&quot; title=&quot;SeleniumBase Test&quot; width=&quot;480&quot; /&gt;&lt;/a&gt;

&gt; (The default browser is ``--chrome`` if not set.)

--------

&lt;p align=&quot;left&quot;&gt;ğŸ“— Here&#039;s &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/test_coffee_cart.py&quot; target=&quot;_blank&quot;&gt;test_coffee_cart.py&lt;/a&gt;, which verifies an e-commerce site:&lt;/p&gt;

```zsh
pytest test_coffee_cart.py --demo
```

&lt;p align=&quot;left&quot;&gt;&lt;a href=&quot;https://seleniumbase.io/coffee/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://seleniumbase.github.io/cdn/gif/coffee_cart.gif&quot; width=&quot;480&quot; alt=&quot;SeleniumBase Coffee Cart Test&quot; title=&quot;SeleniumBase Coffee Cart Test&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&gt; &lt;p&gt;(&lt;code translate=&quot;no&quot;&gt;--demo&lt;/code&gt; mode slows down tests and highlights actions)&lt;/p&gt;

--------

&lt;a id=&quot;multiple_examples&quot;&gt;&lt;/a&gt;

&lt;p align=&quot;left&quot;&gt;ğŸ“— Here&#039;s &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/test_demo_site.py&quot; target=&quot;_blank&quot;&gt;test_demo_site.py&lt;/a&gt;, which covers several actions:&lt;/p&gt;

```zsh
pytest test_demo_site.py
```

&lt;p align=&quot;left&quot;&gt;&lt;a href=&quot;https://seleniumbase.io/demo_page&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://seleniumbase.github.io/cdn/gif/demo_page_5.gif&quot; width=&quot;480&quot; alt=&quot;SeleniumBase Example&quot; title=&quot;SeleniumBase Example&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&gt; Easy to type, click, select, toggle, drag &amp; drop, and more.

(For more examples, see the &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/ReadMe.md&quot;&gt;SeleniumBase/examples/&lt;/a&gt; folder.)

--------

&lt;p align=&quot;left&quot;&gt;&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/&quot;&gt;&lt;img src=&quot;https://seleniumbase.github.io/cdn/img/super_logo_sb3.png&quot; alt=&quot;SeleniumBase&quot; title=&quot;SeleniumBase&quot; width=&quot;232&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p dir=&quot;auto&quot;&gt;&lt;strong&gt;Explore the README:&lt;/strong&gt;&lt;/p&gt;
&lt;ul dir=&quot;auto&quot;&gt;
&lt;li&gt;&lt;a href=&quot;#install_seleniumbase&quot;   &gt;&lt;strong&gt;Get Started / Installation&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#basic_example_and_usage&quot;&gt;&lt;strong&gt;Basic Example / Usage&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#common_methods&quot;         &gt;&lt;strong&gt;Common Test Methods&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#fun_facts&quot;              &gt;&lt;strong&gt;Fun Facts / Learn More&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#demo_mode_and_debugging&quot;&gt;&lt;strong&gt;Demo Mode / Debugging&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#command_line_options&quot;   &gt;&lt;strong&gt;Command-line Options&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#directory_configuration&quot;&gt;&lt;strong&gt;Directory Configuration&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#seleniumbase_dashboard&quot; &gt;&lt;strong&gt;SeleniumBase Dashboard&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#creating_visual_reports&quot;&gt;&lt;strong&gt;Generating Test Reports&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

--------

&lt;details&gt;
&lt;summary&gt; â–¶ï¸ How is &lt;b&gt;SeleniumBase&lt;/b&gt; different from raw Selenium? (&lt;b&gt;click to expand&lt;/b&gt;)&lt;/summary&gt;
&lt;div&gt;

&lt;p&gt;ğŸ’¡ SeleniumBase is a Python framework for browser automation and testing. SeleniumBase uses &lt;a href=&quot;https://www.w3.org/TR/webdriver2/#endpoints&quot; target=&quot;_blank&quot;&gt;Selenium/WebDriver&lt;/a&gt; APIs and incorporates test-runners such as &lt;code translate=&quot;no&quot;&gt;pytest&lt;/code&gt;, &lt;code translate=&quot;no&quot;&gt;pynose&lt;/code&gt;, and &lt;code translate=&quot;no&quot;&gt;behave&lt;/code&gt; to provide organized structure, test discovery, test execution, test state (&lt;i&gt;eg. passed, failed, or skipped&lt;/i&gt;), and command-line options for changing default settings (&lt;i&gt;eg. browser selection&lt;/i&gt;). With raw Selenium, you would need to set up your own options-parser for configuring tests from the command-line.&lt;/p&gt;

&lt;p&gt;ğŸ’¡ SeleniumBase&#039;s driver manager gives you more control over automatic driver downloads. (Use &lt;code translate=&quot;no&quot;&gt;--driver-version=VER&lt;/code&gt; with your &lt;code translate=&quot;no&quot;&gt;pytest&lt;/code&gt; run command to specify the version.) By default, SeleniumBase will download a driver version that matches your major browser version if not set.&lt;/p&gt;

&lt;p&gt;ğŸ’¡ SeleniumBase automatically detects between CSS Selectors and XPath, which means you don&#039;t need to specify the type of selector in your commands (&lt;i&gt;but optionally you could&lt;/i&gt;).&lt;/p&gt;

&lt;p&gt;ğŸ’¡ SeleniumBase methods often perform multiple actions in a single method call. For example, &lt;code translate=&quot;no&quot;&gt;self.type(selector, text)&lt;/code&gt; does the following:&lt;br /&gt;1. Waits for the element to be visible.&lt;br /&gt;2. Waits for the element to be interactive.&lt;br /&gt;3. Clears the text field.&lt;br /&gt;4. Types in the new text.&lt;br /&gt;5. Presses Enter/Submit if the text ends in &lt;code translate=&quot;no&quot;&gt;&quot;\n&quot;&lt;/code&gt;.&lt;br /&gt;With raw Selenium, those actions require multiple method calls.&lt;/p&gt;

&lt;p&gt;ğŸ’¡ SeleniumBase uses default timeout values when not set:&lt;br /&gt;
âœ… &lt;code translate=&quot;no&quot;&gt;self.click(&quot;button&quot;)&lt;/code&gt;&lt;br /&gt;
With raw Selenium, methods would fail instantly (&lt;i&gt;by default&lt;/i&gt;) if an element needed more time to load:&lt;br /&gt;
âŒ &lt;code translate=&quot;no&quot;&gt;self.driver.find_element(by=&quot;css selector&quot;, value=&quot;button&quot;).click()&lt;/code&gt;&lt;br /&gt;
(Reliable code is better than unreliable code.)&lt;/p&gt;

&lt;p&gt;ğŸ’¡ SeleniumBase lets you change the explicit timeout values of methods:&lt;br /&gt;
âœ… &lt;code translate=&quot;no&quot;&gt;self.click(&quot;button&quot;, timeout=10)&lt;/code&gt;&lt;br /&gt;
With raw Selenium, that requires more code:&lt;br /&gt;
âŒ &lt;code translate=&quot;no&quot;&gt;WebDriverWait(driver, 10).until(EC.element_to_be_clickable(&quot;css selector&quot;, &quot;button&quot;)).click()&lt;/code&gt;&lt;br /&gt;
(Simple code is better than complex code.)&lt;/p&gt;

&lt;p&gt;ğŸ’¡ SeleniumBase gives you clean error output when a test fails. With raw Selenium, error messages can get very messy.&lt;/p&gt;

&lt;p&gt;ğŸ’¡ SeleniumBase gives you the option to generate a dashboard and reports for tests. It also saves screenshots from failing tests to the &lt;code translate=&quot;no&quot;&gt;./latest_logs/&lt;/code&gt; folder. Raw &lt;a href=&quot;https://www.selenium.dev/documentation/webdriver/&quot; translate=&quot;no&quot; target=&quot;_blank&quot;&gt;Selenium&lt;/a&gt; does not have these options out-of-the-box.&lt;/p&gt;

&lt;p&gt;ğŸ’¡ SeleniumBase includes desktop GUI apps for running tests, such as &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/commander.md&quot; translate=&quot;no&quot;&gt;SeleniumBase Commander&lt;/a&gt; for &lt;code translate=&quot;no&quot;&gt;pytest&lt;/code&gt; and &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/behave_bdd/ReadMe.md&quot; translate=&quot;no&quot;&gt;SeleniumBase Behave GUI&lt;/a&gt; for &lt;code translate=&quot;no&quot;&gt;behave&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;ğŸ’¡ SeleniumBase has its own &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/recorder_mode.md&quot;&gt;Recorder / Test Generator&lt;/a&gt; for creating tests from manual browser actions.&lt;/p&gt;

&lt;p&gt;ğŸ’¡ SeleniumBase comes with &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/case_plans.md&quot;&gt;test case management software, (&quot;CasePlans&quot;)&lt;/a&gt;, for organizing tests and step descriptions.&lt;/p&gt;

&lt;p&gt;ğŸ’¡ SeleniumBase includes tools for &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/chart_maker/ReadMe.md&quot;&gt;building data apps, (&quot;ChartMaker&quot;)&lt;/a&gt;, which can generate JavaScript from Python.&lt;/p&gt;

&lt;/div&gt;
&lt;/details&gt;

--------

&lt;p&gt;ğŸ“š &lt;b&gt;Learn about different ways of writing tests:&lt;/b&gt;&lt;/p&gt;

&lt;p align=&quot;left&quot;&gt;ğŸ“—ğŸ“ Here&#039;s &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/test_simple_login.py&quot;&gt;test_simple_login.py&lt;/a&gt;, which uses &lt;code translate=&quot;no&quot;&gt;&lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/seleniumbase/fixtures/base_case.py&quot;&gt;BaseCase&lt;/a&gt;&lt;/code&gt; class inheritance, and runs with &lt;a href=&quot;https://docs.pytest.org/en/latest/how-to/usage.html&quot;&gt;pytest&lt;/a&gt; or &lt;a href=&quot;https://github.com/mdmintz/pynose&quot;&gt;pynose&lt;/a&gt;. (Use &lt;code translate=&quot;no&quot;&gt;self.driver&lt;/code&gt; to access Selenium&#039;s raw &lt;code translate=&quot;no&quot;&gt;driver&lt;/code&gt;.)&lt;/p&gt;

```python
from seleniumbase import BaseCase
BaseCase.main(__name__, __file__)

class TestSimpleLogin(BaseCase):
    def test_simple_login(self):
        self.open(&quot;seleniumbase.io/simple/login&quot;)
        self.type(&quot;#username&quot;, &quot;demo_user&quot;)
        self.type(&quot;#password&quot;, &quot;secret_pass&quot;)
        self.click(&#039;a:contains(&quot;Sign in&quot;)&#039;)
        self.assert_exact_text(&quot;Welcome!&quot;, &quot;h1&quot;)
        self.assert_element(&quot;img#image1&quot;)
        self.highlight(&quot;#image1&quot;)
        self.click_link(&quot;Sign out&quot;)
        self.assert_text(&quot;signed out&quot;, &quot;#top_message&quot;)
```

&lt;p align=&quot;left&quot;&gt;ğŸ“˜ğŸ“ Here&#039;s &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/raw_login_sb.py&quot;&gt;raw_login_sb.py&lt;/a&gt;, which uses the &lt;b&gt;&lt;code translate=&quot;no&quot;&gt;SB&lt;/code&gt;&lt;/b&gt; Context Manager. Runs with pure &lt;code translate=&quot;no&quot;&gt;python&lt;/code&gt;. (Use &lt;code translate=&quot;no&quot;&gt;sb.driver&lt;/code&gt; to access Selenium&#039;s raw &lt;code translate=&quot;no&quot;&gt;driver&lt;/code&gt;.)&lt;/p&gt;

```python
from seleniumbase import SB

with SB() as sb:
    sb.open(&quot;seleniumbase.io/simple/login&quot;)
    sb.type(&quot;#username&quot;, &quot;demo_user&quot;)
    sb.type(&quot;#password&quot;, &quot;secret_pass&quot;)
    sb.click(&#039;a:contains(&quot;Sign in&quot;)&#039;)
    sb.assert_exact_text(&quot;Welcome!&quot;, &quot;h1&quot;)
    sb.assert_element(&quot;img#image1&quot;)
    sb.highlight(&quot;#image1&quot;)
    sb.click_link(&quot;Sign out&quot;)
    sb.assert_text(&quot;signed out&quot;, &quot;#top_message&quot;)
```

&lt;p align=&quot;left&quot;&gt;ğŸ“™ğŸ“ Here&#039;s &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/examples/raw_login_driver.py&quot;&gt;raw_login_driver.py&lt;/a&gt;, which uses the &lt;b&gt;&lt;code translate=&quot;no&quot;&gt;Driver&lt;/code&gt;&lt;/b&gt; Manager. Runs with pure &lt;code translate=&quot;no&quot;&gt;python&lt;/code&gt;. (The &lt;code&gt;driver&lt;/code&gt; is an improved version of Selenium&#039;s raw &lt;code translate=&quot;no&quot;&gt;driver&lt;/code&gt;, with more methods.)&lt;/p&gt;

```python
from seleniumbase import Driver

driver = Driver()
try:
    driver.open(&quot;seleniumbase.io/simple/login&quot;)
    driver.type(&quot;#username&quot;, &quot;demo_user&quot;)
    driver.type(&quot;#password&quot;, &quot;secret_pass&quot;)
    driver.click(&#039;a:contains(&quot;Sign in&quot;)&#039;)
    driver.assert_exact_text(&quot;Welcome!&quot;, &quot;h1&quot;)
    driver.assert_element(&quot;img#image1&quot;)
    driver.highlight(&quot;#image1&quot;)
    driver.click_link(&quot;Sign out&quot;)
    driver.assert_text(&quot;signed out&quot;, &quot;#top_message&quot;)
finally:
    driver.quit()
```

--------

&lt;a id=&quot;python_installation&quot;&gt;&lt;/a&gt;
&lt;h2&gt;&lt;img src=&quot;https://seleniumbase.github.io/cdn/img/python_logo.png&quot; title=&quot;SeleniumBase&quot; width=&quot;42&quot; /&gt; Set up Python &amp; Git:&lt;/h2&gt;

&lt;a href=&quot;https://www.python.org/downloads/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/pyversions/seleniumbase.svg?color=FACE42&quot; title=&quot;Supported Python Versions&quot; /&gt;&lt;/a&gt;

ğŸ”µ Add &lt;b&gt;&lt;a href=&quot;https://www.python.org/downloads/&quot;&gt;Python&lt;/a&gt;&lt;/b&gt; and &lt;b&gt;&lt;a href=&quot;https://git-scm.com/&quot;&gt;Git&lt;/a&gt;&lt;/b&gt; to your System PATH.

ğŸ”µ Using a &lt;a href=&quot;https://github.com/seleniumbase/SeleniumBase/blob/master/help_docs/virtualenv_instructions.md&quot;&gt;Python virtual env&lt;/a&gt; is recommended.

&lt;a id=&quot;install_seleniumbase&quot;&gt;&lt;/a&gt;
&lt;h2&gt;&lt;img src=&quot;https://seleniumbase.github.io/img/logo7.png&quot; title=&quot;SeleniumBase&quot; width=&quot;32&quot; /&gt; Install SeleniumBase:&lt;/h2&gt;

**You can install ``seleniumbase`` from [PyPI](https://pypi.org/project/seleniumbase/) or [GitHub](https://github.com/seleniumbase/SeleniumBase):**

ğŸ”µ **How to install ``seleniumbase`` from PyPI:**

```zsh
pip install seleniumbase
```

* (Add ``--upgrade`` OR ``-U`` to upgrade SeleniumBase.)
* (Add ``--force-reinstall`` to upgrade indirect packages.)
* (Use ``pip3`` if multiple versions of Python are present.)

ğŸ”µ **How to install ``seleniumbase`` from a GitHub clone:**

```zsh
git clone https://github.com/seleniumbase/SeleniumBase.git
cd SeleniumBase/
pip install -e .
```

ğŸ”µ **How to upgrade an existing install from a GitHub clone:**

```zsh
git pull
pip install -e .
```

ğŸ”µ **Type ``seleniumbase`` or ``sbase`` to verify that SeleniumBase was installed successfully:**

```zs

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[hummingbot/hummingbot]]></title>
            <link>https://github.com/hummingbot/hummingbot</link>
            <guid>https://github.com/hummingbot/hummingbot</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:44 GMT</pubDate>
            <description><![CDATA[Open source software that helps you create and deploy high-frequency crypto trading bots]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hummingbot/hummingbot">hummingbot/hummingbot</a></h1>
            <p>Open source software that helps you create and deploy high-frequency crypto trading bots</p>
            <p>Language: Python</p>
            <p>Stars: 13,476</p>
            <p>Forks: 3,715</p>
            <p>Stars today: 48 stars today</p>
            <h2>README</h2><pre>![Hummingbot](https://github.com/user-attachments/assets/3213d7f8-414b-4df8-8c1b-a0cd142a82d8)

----
[![License](https://img.shields.io/badge/License-Apache%202.0-informational.svg)](https://github.com/hummingbot/hummingbot/blob/master/LICENSE)
[![Twitter](https://img.shields.io/twitter/url?url=https://twitter.com/_hummingbot?style=social&amp;label=_hummingbot)](https://twitter.com/_hummingbot)
[![Youtube](https://img.shields.io/youtube/channel/subscribers/UCxzzdEnDRbylLMWmaMjywOA)](https://www.youtube.com/@hummingbot)
[![Discord](https://img.shields.io/discord/530578568154054663?logo=discord&amp;logoColor=white&amp;style=flat-square)](https://discord.gg/hummingbot)

Hummingbot is an open-source framework that helps you design and deploy automated trading strategies, or **bots**, that can run on many centralized or decentralized exchanges. Over the past year, Hummingbot users have generated over $34 billion in trading volume across 140+ unique trading venues.

The Hummingbot codebase is free and publicly available under the Apache 2.0 open-source license. Our mission is to **democratize high-frequency trading** by creating a global community of algorithmic traders and developers that share knowledge and contribute to the codebase.

## Quick Links

* [Website and Docs](https://hummingbot.org): Official Hummingbot website and documeniuntation
* [Installation](https://hummingbot.org/installation/docker/): Install Hummingbot on various platforms
* [Discord](https://discord.gg/hummingbot): The main gathering spot for the global Hummingbot community
* [YouTube](https://www.youtube.com/c/hummingbot): Videos that teach you how to get the most of of Hummingbot
* [Twitter](https://twitter.com/_hummingbot): Get the latest announcements about Hummingbot
* [Reported Volumes](https://p.datadoghq.com/sb/a96a744f5-a15479d77992ccba0d23aecfd4c87a52): Reported trading volumes across all Hummingbot instances
* [Newsletter](https://hummingbot.substack.com): Get our newsletter whenever we ship a new release


## Exchange Connectors

Hummingbot connectors standardize REST and WebSocket API interfaces to different types of exchanges, enabling you to build sophisticated trading strategies that can be deployed across many exchanges with minimal changes.  We classify exchanges into the following categories:

* **CEX**: Centralized exchanges that take custody of your funds. Use API keys to connect with Hummingbot.
* **DEX**: Decentralized, non-custodial exchanges that operate on a blockchain. Use wallet keys to connect with Hummingbot.

In addition, connectors differ based on the type of market supported:

 * **CLOB Spot**: Connectors to spot markets on central limit order book (CLOB) exchanges
 * **CLOB Perp**: Connectors to perpetual futures markets on CLOB exchanges
 * **AMM**: Connectors to spot markets on Automatic Market Maker (AMM) decentralized exchanges

### Exchange Sponsors

We are grateful for the following exchanges that support the development and maintenance of Hummingbot via broker partnerships and sponsorships.

| Connector ID | Exchange | CEX/DEX | Market Type | Docs | Discount |
|----|------|-------|------|------|----------|
| `binance` | [Binance](https://accounts.binance.com/register?ref=CBWO4LU6) | CEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/binance/) | [![Sign up for Binance using Hummingbot&#039;s referral link for a 10% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d10%25&amp;color=orange)](https://accounts.binance.com/register?ref=CBWO4LU6) |
| `binance_perpetual` | [Binance](https://accounts.binance.com/register?ref=CBWO4LU6) | CEX | CLOB Perp | [Docs](https://hummingbot.org/exchanges/binance/) | [![Sign up for Binance using Hummingbot&#039;s referral link for a 10% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d10%25&amp;color=orange)](https://accounts.binance.com/register?ref=CBWO4LU6) |
| `gate_io` | [Gate.io](https://www.gate.io/referral/invite/HBOTGATE_0_103) | CEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/gate-io/) | [![Sign up for Gate.io using Hummingbot&#039;s referral link for a 10% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d20%25&amp;color=orange)](https://www.gate.io/referral/invite/HBOTGATE_0_103) |
| `gate_io_perpetual` | [Gate.io](https://www.gate.io/referral/invite/HBOTGATE_0_103) | CEX | CLOB Perp | [Docs](https://hummingbot.org/exchanges/gate-io/) | [![Sign up for Gate.io using Hummingbot&#039;s referral link for a 20% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d20%25&amp;color=orange)](https://www.gate.io/referral/invite/HBOTGATE_0_103) |
| `htx` | [HTX (Huobi)](https://www.htx.com.pk/invite/en-us/1h?invite_code=re4w9223) | CEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/huobi/) | [![Sign up for HTX using Hummingbot&#039;s referral link for a 20% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d20%25&amp;color=orange)](https://www.htx.com.pk/invite/en-us/1h?invite_code=re4w9223) |
| `kucoin` | [KuCoin](https://www.kucoin.com/r/af/hummingbot) | CEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/kucoin/) | [![Sign up for Kucoin using Hummingbot&#039;s referral link for a 20% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d20%25&amp;color=orange)](https://www.kucoin.com/r/af/hummingbot) |
| `kucoin_perpetual` | [KuCoin](https://www.kucoin.com/r/af/hummingbot) | CEX | CLOB Perp | [Docs](https://hummingbot.org/exchanges/kucoin/) | [![Sign up for Kucoin using Hummingbot&#039;s referral link for a 20% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d20%25&amp;color=orange)](https://www.kucoin.com/r/af/hummingbot) |
| `okx` | [OKX](https://www.okx.com/join/1931920269) | CEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/okx/okx/) | [![Sign up for Kucoin using Hummingbot&#039;s referral link for a 20% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d20%25&amp;color=orange)](https://www.okx.com/join/1931920269) |
| `okx_perpetual` | [OKX](https://www.okx.com/join/1931920269) | CEX | CLOB Perp | [Docs](https://hummingbot.org/exchanges/okx/okx/) | [![Sign up for Kucoin using Hummingbot&#039;s referral link for a 20% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d20%25&amp;color=orange)](https://www.okx.com/join/1931920269) |
| `dydx_v4_perpetual` | [dYdX](https://www.dydx.exchange/) | DEX | CLOB Perp | [Docs](https://hummingbot.org/exchanges/dydx/) | - |
| `hyperliquid_perpetual` | [Hyperliquid](https://hyperliquid.io/) | DEX | CLOB Perp | [Docs](https://hummingbot.org/exchanges/hyperliquid/) | - |
| `xrpl` | [XRP Ledger](https://xrpl.org/) | DEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/xrpl/) | - |

### Other Exchange Connectors

Currently, the master branch of Hummingbot also includes the following exchange connectors, which are maintained and updated through the Hummingbot Foundation governance process. See [Governance](https://hummingbot.org/governance/) for more information.

| Connector ID | Exchange | CEX/DEX | Type | Docs | Discount |
|----|------|-------|------|------|----------|
| `ascend_ex` | AscendEx | CEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/ascendex/) | - |
| `balancer` | Balancer | DEX | AMM | [Docs](https://hummingbot.org/exchanges/balancer/) | - |
| `bing_x` | BingX | CEX     | CLOB Spot | [Docs](https://hummingbot.org/exchanges/bing_x/) | - |
| `bitget_perpetual` | Bitget | CEX | CLOB Perp | [Docs](https://hummingbot.org/exchanges/bitget-perpetual/) | - |
| `bitmart` | BitMart | CEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/bitmart/) | - |
| `bitrue` | Bitrue | CEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/bitrue/) | - |
| `bitstamp` | Bitstamp | CEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/bitstamp/) | - |
| `btc_markets` | BTC Markets | CEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/btc-markets/) | - |
| `bybit` | Bybit | CEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/bybit/) | - |
| `bybit_perpetual` | Bybit | CEX | CLOB Perp | [Docs](https://hummingbot.org/exchanges/bybit/) | - |
| `carbon` | Carbon | DEX | AMM | [Docs](https://hummingbot.org/exchanges/carbon/) | - |
| `coinbase_advanced_trade` | Coinbase | CEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/coinbase/) | - |
| `cube` | Cube | CEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/cube/) | - |
| `curve` | Curve | DEX | AMM | [Docs](https://hummingbot.org/exchanges/curve/) | - |
| `dexalot` | Dexalot | DEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/dexalot/) | - |
| `injective_v2` | Injective Helix | DEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/injective/) | - |
| `injective_v2_perpetual` | Injective Helix | DEX | CLOB Perp | [Docs](https://hummingbot.org/exchanges/injective/) | - |
| `kraken` | Kraken | CEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/kraken/) | - |
| `mad_meerkat` | Mad Meerkat | DEX | AMM | [Docs](https://hummingbot.org/exchanges/mad-meerkat/) | - |
| `mexc` | MEXC | CEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/mexc/) | - |
| `openocean` | OpenOcean | DEX | AMM | [Docs](https://hummingbot.org/exchanges/openocean/) | - |
| `pancakeswap` | PancakeSwap | DEX | AMM | [Docs](https://hummingbot.org/exchanges/pancakeswap/) | - |
| `pangolin` | Pangolin | CEX | DEX | [Docs](https://hummingbot.org/exchanges/pangolin/) | - |
| `quickswap` | QuickSwap | DEX | AMM | [Docs](https://hummingbot.org/exchanges/quickswap/) | - |
| `sushiswap` | SushiSwap | DEX | AMM | [Docs](https://hummingbot.org/exchanges/sushiswap/) | - |
| `tinyman` | Tinyman | DEX | AMM | [Docs](https://hummingbot.org/exchanges/tinyman/) | - |
| `traderjoe` | Trader Joe | DEX | AMM | [Docs](https://hummingbot.org/exchanges/traderjoe/) | - |
| `uniswap` | Uniswap | DEX | AMM | [Docs](https://hummingbot.org/exchanges/gateway/uniswap/) | - |
| `vertex` | Vertex | DEX | CLOB Spot | [Docs](https://hummingbot.org/exchanges/vertex/) | - |
| `vvs` | VVS | DEX | AMM | [Docs](https://hummingbot.org/exchanges/vvs/) | - |
| `xsswap` | XSSwap | DEX | AMM | [Docs](https://hummingbot.org/exchanges/xswap/) | - |

## Other Hummingbot Repos

* [Deploy](https://github.com/hummingbot/deploy): Deploy Hummingbot in various configurations with Docker
* [Dashboard](https://github.com/hummingbot/dashboard): Web app that help you create, backtest, deploy, and manage Hummingbot instances
* [Quants Lab](https://github.com/hummingbot/quants-lab): Juypter notebooks that enable you to fetch data and perform research using Hummingbot
* [Gateway](https://github.com/hummingbot/gateway): Typescript based API client for DEX connectors
* [Hummingbot Site](https://github.com/hummingbot/hummingbot-site): Official documentation for Hummingbot - we welcome contributions here too!

## Contributions

The Hummingbot architecture features modular components that can be maintained and extended by individual community members.

We welcome contributions from the community! Please review these [guidelines](./CONTRIBUTING.md) before submitting a pull request.

To have your exchange connector or other pull request merged into the codebase, please submit a New Connector Proposal or Pull Request Proposal, following these [guidelines](https://hummingbot.org/governance/proposals/). Note that you will need some amount of [HBOT tokens](https://etherscan.io/token/0xe5097d9baeafb89f9bcb78c9290d545db5f9e9cb) in your Ethereum wallet to submit a proposal.

## Legal

* **License**: Hummingbot is open source and licensed under [Apache 2.0](./LICENSE).
* **Data collection**: See [Reporting](https://hummingbot.org/reporting/) for information on anonymous data collection and reporting in Hummingbot.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[hacksider/Deep-Live-Cam]]></title>
            <link>https://github.com/hacksider/Deep-Live-Cam</link>
            <guid>https://github.com/hacksider/Deep-Live-Cam</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:43 GMT</pubDate>
            <description><![CDATA[real time face swap and one-click video deepfake with only a single image]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hacksider/Deep-Live-Cam">hacksider/Deep-Live-Cam</a></h1>
            <p>real time face swap and one-click video deepfake with only a single image</p>
            <p>Language: Python</p>
            <p>Stars: 71,984</p>
            <p>Forks: 10,337</p>
            <p>Stars today: 48 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;Deep-Live-Cam&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  Real-time face swap and video deepfake with a single click and only a single image.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/11395&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/11395&quot; alt=&quot;hacksider%2FDeep-Live-Cam | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;media/demo.gif&quot; alt=&quot;Demo GIF&quot; width=&quot;800&quot;&gt;
&lt;/p&gt;

##  Disclaimer

This deepfake software is designed to be a productive tool for the AI-generated media industry. It can assist artists in animating custom characters, creating engaging content, and even using models for clothing design.

We are aware of the potential for unethical applications and are committed to preventative measures. A built-in check prevents the program from processing inappropriate media (nudity, graphic content, sensitive material like war footage, etc.). We will continue to develop this project responsibly, adhering to the law and ethics. We may shut down the project or add watermarks if legally required.

- Ethical Use: Users are expected to use this software responsibly and legally. If using a real person&#039;s face, obtain their consent and clearly label any output as a deepfake when sharing online.

- Content Restrictions: The software includes built-in checks to prevent processing inappropriate media, such as nudity, graphic content, or sensitive material.

- Legal Compliance: We adhere to all relevant laws and ethical guidelines. If legally required, we may shut down the project or add watermarks to the output.

- User Responsibility: We are not responsible for end-user actions. Users must ensure their use of the software aligns with ethical standards and legal requirements.

By using this software, you agree to these terms and commit to using it in a manner that respects the rights and dignity of others.

Users are expected to use this software responsibly and legally. If using a real person&#039;s face, obtain their consent and clearly label any output as a deepfake when sharing online. We are not responsible for end-user actions.

## Exclusive v2.1 Quick Start - Pre-built (Windows/Mac Silicon)

  &lt;a href=&quot;https://deeplivecam.net/index.php/quickstart&quot;&gt; &lt;img src=&quot;media/Download.png&quot; width=&quot;285&quot; height=&quot;77&quot; /&gt;

##### This is the fastest build you can get if you have a discrete NVIDIA or AMD GPU or Mac Silicon, And you&#039;ll receive special priority support.
 
###### These Pre-builts are perfect for non-technical users or those who don&#039;t have time to, or can&#039;t manually install all the requirements. Just a heads-up: this is an open-source project, so you can also install it manually. 

## TLDR; Live Deepfake in just 3 Clicks
![easysteps](https://github.com/user-attachments/assets/af825228-852c-411b-b787-ffd9aac72fc6)
1. Select a face
2. Select which camera to use
3. Press live!

## Features &amp; Uses - Everything is in real-time

### Mouth Mask

**Retain your original mouth for accurate movement using Mouth Mask**

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;media/ludwig.gif&quot; alt=&quot;resizable-gif&quot;&gt;
&lt;/p&gt;

### Face Mapping

**Use different faces on multiple subjects simultaneously**

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;media/streamers.gif&quot; alt=&quot;face_mapping_source&quot;&gt;
&lt;/p&gt;

### Your Movie, Your Face

**Watch movies with any face in real-time**

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;media/movie.gif&quot; alt=&quot;movie&quot;&gt;
&lt;/p&gt;

### Live Show

**Run Live shows and performances**

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;media/live_show.gif&quot; alt=&quot;show&quot;&gt;
&lt;/p&gt;

### Memes

**Create Your Most Viral Meme Yet**

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;media/meme.gif&quot; alt=&quot;show&quot; width=&quot;450&quot;&gt; 
  &lt;br&gt;
  &lt;sub&gt;Created using Many Faces feature in Deep-Live-Cam&lt;/sub&gt;
&lt;/p&gt;

### Omegle

**Surprise people on Omegle**

&lt;p align=&quot;center&quot;&gt;
  &lt;video src=&quot;https://github.com/user-attachments/assets/2e9b9b82-fa04-4b70-9f56-b1f68e7672d0&quot; width=&quot;450&quot; controls&gt;&lt;/video&gt;
&lt;/p&gt;

## Installation (Manual)

**Please be aware that the installation requires technical skills and is not for beginners. Consider downloading the quickstart version.**

&lt;details&gt;
&lt;summary&gt;Click to see the process&lt;/summary&gt;

### Installation

This is more likely to work on your computer but will be slower as it utilizes the CPU.

**1. Set up Your Platform**

-   Python (3.11 recommended)
-   pip
-   git
-   [ffmpeg](https://www.youtube.com/watch?v=OlNWCpFdVMA) - ```iex (irm ffmpeg.tc.ht)```
-   [Visual Studio 2022 Runtimes (Windows)](https://visualstudio.microsoft.com/visual-cpp-build-tools/)

**2. Clone the Repository**

```bash
git clone https://github.com/hacksider/Deep-Live-Cam.git
cd Deep-Live-Cam
```

**3. Download the Models**

1. [GFPGANv1.4](https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth)
2. [inswapper\_128\_fp16.onnx](https://huggingface.co/hacksider/deep-live-cam/resolve/main/inswapper_128_fp16.onnx)

Place these files in the &quot;**models**&quot; folder.

**4. Install Dependencies**

We highly recommend using a `venv` to avoid issues.


For Windows:
```bash
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
```
For Linux:
```bash
# Ensure you use the installed Python 3.10
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

**For macOS:**

Apple Silicon (M1/M2/M3) requires specific setup:

```bash
# Install Python 3.11 (specific version is important)
brew install python@3.11

# Install tkinter package (required for the GUI)
brew install python-tk@3.10

# Create and activate virtual environment with Python 3.11
python3.11 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

** In case something goes wrong and you need to reinstall the virtual environment **

```bash
# Deactivate the virtual environment
rm -rf venv

# Reinstall the virtual environment
python -m venv venv
source venv/bin/activate

# install the dependencies again
pip install -r requirements.txt
```

**Run:** If you don&#039;t have a GPU, you can run Deep-Live-Cam using `python run.py`. Note that initial execution will download models (~300MB).

### GPU Acceleration

**CUDA Execution Provider (Nvidia)**

1. Install [CUDA Toolkit 12.8.0](https://developer.nvidia.com/cuda-12-8-0-download-archive)
2. Install [cuDNN v8.9.7 for CUDA 12.x](https://developer.nvidia.com/rdp/cudnn-archive) (required for onnxruntime-gpu):
   - Download cuDNN v8.9.7 for CUDA 12.x
   - Make sure the cuDNN bin directory is in your system PATH
3. Install dependencies:

```bash
pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
pip uninstall onnxruntime onnxruntime-gpu
pip install onnxruntime-gpu==1.21.0
```

3. Usage:

```bash
python run.py --execution-provider cuda
```

**CoreML Execution Provider (Apple Silicon)**

Apple Silicon (M1/M2/M3) specific installation:

1. Make sure you&#039;ve completed the macOS setup above using Python 3.10.
2. Install dependencies:

```bash
pip uninstall onnxruntime onnxruntime-silicon
pip install onnxruntime-silicon==1.13.1
```

3. Usage (important: specify Python 3.10):

```bash
python3.10 run.py --execution-provider coreml
```

**Important Notes for macOS:**
- You **must** use Python 3.10, not newer versions like 3.11 or 3.13
- Always run with `python3.10` command not just `python` if you have multiple Python versions installed
- If you get error about `_tkinter` missing, reinstall the tkinter package: `brew reinstall python-tk@3.10`
- If you get model loading errors, check that your models are in the correct folder
- If you encounter conflicts with other Python versions, consider uninstalling them:
  ```bash
  # List all installed Python versions
  brew list | grep python
  
  # Uninstall conflicting versions if needed
  brew uninstall --ignore-dependencies python@3.11 python@3.13
  
  # Keep only Python 3.11
  brew cleanup
  ```

**CoreML Execution Provider (Apple Legacy)**

1. Install dependencies:

```bash
pip uninstall onnxruntime onnxruntime-coreml
pip install onnxruntime-coreml==1.21.0
```

2. Usage:

```bash
python run.py --execution-provider coreml
```

**DirectML Execution Provider (Windows)**

1. Install dependencies:

```bash
pip uninstall onnxruntime onnxruntime-directml
pip install onnxruntime-directml==1.21.0
```

2. Usage:

```bash
python run.py --execution-provider directml
```

**OpenVINOâ„¢ Execution Provider (Intel)**

1. Install dependencies:

```bash
pip uninstall onnxruntime onnxruntime-openvino
pip install onnxruntime-openvino==1.21.0
```

2. Usage:

```bash
python run.py --execution-provider openvino
```
&lt;/details&gt;

## Usage

**1. Image/Video Mode**

-   Execute `python run.py`.
-   Choose a source face image and a target image/video.
-   Click &quot;Start&quot;.
-   The output will be saved in a directory named after the target video.

**2. Webcam Mode**

-   Execute `python run.py`.
-   Select a source face image.
-   Click &quot;Live&quot;.
-   Wait for the preview to appear (10-30 seconds).
-   Use a screen capture tool like OBS to stream.
-   To change the face, select a new source image.

## Command Line Arguments (Unmaintained)

```
options:
  -h, --help                                               show this help message and exit
  -s SOURCE_PATH, --source SOURCE_PATH                     select a source image
  -t TARGET_PATH, --target TARGET_PATH                     select a target image or video
  -o OUTPUT_PATH, --output OUTPUT_PATH                     select output file or directory
  --frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]  frame processors (choices: face_swapper, face_enhancer, ...)
  --keep-fps                                               keep original fps
  --keep-audio                                             keep original audio
  --keep-frames                                            keep temporary frames
  --many-faces                                             process every face
  --map-faces                                              map source target faces
  --mouth-mask                                             mask the mouth region
  --video-encoder {libx264,libx265,libvpx-vp9}             adjust output video encoder
  --video-quality [0-51]                                   adjust output video quality
  --live-mirror                                            the live camera display as you see it in the front-facing camera frame
  --live-resizable                                         the live camera frame is resizable
  --max-memory MAX_MEMORY                                  maximum amount of RAM in GB
  --execution-provider {cpu} [{cpu} ...]                   available execution provider (choices: cpu, ...)
  --execution-threads EXECUTION_THREADS                    number of execution threads
  -v, --version                                            show program&#039;s version number and exit
```

Looking for a CLI mode? Using the -s/--source argument will make the run program in cli mode.

## Press

**We are always open to criticism and are ready to improve, that&#039;s why we didn&#039;t cherry-pick anything.**

 - [*&quot;Deep-Live-Cam goes viral, allowing anyone to become a digital doppelganger&quot;*](https://arstechnica.com/information-technology/2024/08/new-ai-tool-enables-real-time-face-swapping-on-webcams-raising-fraud-concerns/) - Ars Technica
 - [*&quot;Thanks Deep Live Cam, shapeshifters are among us now&quot;*](https://dataconomy.com/2024/08/15/what-is-deep-live-cam-github-deepfake/) - Dataconomy
 - [*&quot;This free AI tool lets you become anyone during video-calls&quot;*](https://www.newsbytesapp.com/news/science/deep-live-cam-ai-impersonation-tool-goes-viral/story) - NewsBytes
 - [*&quot;OK, this viral AI live stream software is truly terrifying&quot;*](https://www.creativebloq.com/ai/ok-this-viral-ai-live-stream-software-is-truly-terrifying) - Creative Bloq
 - [*&quot;Deepfake AI Tool Lets You Become Anyone in a Video Call With Single Photo&quot;*](https://petapixel.com/2024/08/14/deep-live-cam-deepfake-ai-tool-lets-you-become-anyone-in-a-video-call-with-single-photo-mark-zuckerberg-jd-vance-elon-musk/) - PetaPixel
 - [*&quot;Deep-Live-Cam Uses AI to Transform Your Face in Real-Time, Celebrities Included&quot;*](https://www.techeblog.com/deep-live-cam-ai-transform-face/) - TechEBlog
 - [*&quot;An AI tool that &quot;makes you look like anyone&quot; during a video call is going viral online&quot;*](https://telegrafi.com/en/a-tool-that-makes-you-look-like-anyone-during-a-video-call-is-going-viral-on-the-Internet/) - Telegrafi
 - [*&quot;This Deepfake Tool Turning Images Into Livestreams is Topping the GitHub Charts&quot;*](https://decrypt.co/244565/this-deepfake-tool-turning-images-into-livestreams-is-topping-the-github-charts) - Emerge
 - [*&quot;New Real-Time Face-Swapping AI Allows Anyone to Mimic Famous Faces&quot;*](https://www.digitalmusicnews.com/2024/08/15/face-swapping-ai-real-time-mimic/) - Digital Music News
 - [*&quot;This real-time webcam deepfake tool raises alarms about the future of identity theft&quot;*](https://www.diyphotography.net/this-real-time-webcam-deepfake-tool-raises-alarms-about-the-future-of-identity-theft/) - DIYPhotography
 - [*&quot;That&#039;s Crazy, Oh God. That&#039;s Fucking Freaky Dude... That&#039;s So Wild Dude&quot;*](https://www.youtube.com/watch?time_continue=1074&amp;v=py4Tc-Y8BcY) - SomeOrdinaryGamers
 - [*&quot;Alright look look look, now look chat, we can do any face we want to look like chat&quot;*](https://www.youtube.com/live/mFsCe7AIxq8?feature=shared&amp;t=2686) - IShowSpeed
 - [*&quot;They do a pretty good job matching poses, expression and even the lighting&quot;*](https://www.youtube.com/watch?v=wnCghLjqv3s&amp;t=551s) - TechLinked (LTT)


## Credits

-   [ffmpeg](https://ffmpeg.org/): for making video-related operations easy
-   [deepinsight](https://github.com/deepinsight): for their [insightface](https://github.com/deepinsight/insightface) project which provided a well-made library and models. Please be reminded that the [use of the model is for non-commercial research purposes only](https://github.com/deepinsight/insightface?tab=readme-ov-file#license).
-   [havok2-htwo](https://github.com/havok2-htwo): for sharing the code for webcam
-   [GosuDRM](https://github.com/GosuDRM): for the open version of roop
-   [pereiraroland26](https://github.com/pereiraroland26): Multiple faces support
-   [vic4key](https://github.com/vic4key): For supporting/contributing to this project
-   [kier007](https://github.com/kier007): for improving the user experience
-   [qitianai](https://github.com/qitianai): for multi-lingual support
-   and [all developers](https://github.com/hacksider/Deep-Live-Cam/graphs/contributors) behind libraries used in this project.
-   Footnote: Please be informed that the base author of the code is [s0md3v](https://github.com/s0md3v/roop)
-   All the wonderful users who helped make this project go viral by starring the repo â¤ï¸

[![Stargazers](https://reporoster.com/stars/hacksider/Deep-Live-Cam)](https://github.com/hacksider/Deep-Live-Cam/stargazers)

## Contributions

![Alt](https://repobeats.axiom.co/api/embed/fec8e29c45dfdb9c5916f3a7830e1249308d20e1.svg &quot;Repobeats analytics image&quot;)

## Stars to the Moon ğŸš€

&lt;a href=&quot;https://star-history.com/#hacksider/deep-live-cam&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[soimort/you-get]]></title>
            <link>https://github.com/soimort/you-get</link>
            <guid>https://github.com/soimort/you-get</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:42 GMT</pubDate>
            <description><![CDATA[â¬ Dumb downloader that scrapes the web]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/soimort/you-get">soimort/you-get</a></h1>
            <p>â¬ Dumb downloader that scrapes the web</p>
            <p>Language: Python</p>
            <p>Stars: 56,120</p>
            <p>Forks: 9,789</p>
            <p>Stars today: 130 stars today</p>
            <h2>README</h2><pre># You-Get

[![Build Status](https://github.com/soimort/you-get/workflows/develop/badge.svg)](https://github.com/soimort/you-get/actions)
[![PyPI version](https://img.shields.io/pypi/v/you-get.svg)](https://pypi.python.org/pypi/you-get/)
[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/soimort/you-get?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge)

**NOTICE (30 May 2022): Support for Python 3.5, 3.6 and 3.7 will eventually be dropped. ([see details here](https://github.com/soimort/you-get/wiki/TLS-1.3-post-handshake-authentication-(PHA)))**

**NOTICE (8 Mar 2019): Read [this](https://github.com/soimort/you-get/blob/develop/CONTRIBUTING.md) if you are looking for the conventional &quot;Issues&quot; tab.**

---

[You-Get](https://you-get.org/) is a tiny command-line utility to download media contents (videos, audios, images) from the Web, in case there is no other handy way to do it.

Here&#039;s how you use `you-get` to download a video from [YouTube](https://www.youtube.com/watch?v=jNQXAC9IVRw):

```console
$ you-get &#039;https://www.youtube.com/watch?v=jNQXAC9IVRw&#039;
site:                YouTube
title:               Me at the zoo
stream:
    - itag:          43
      container:     webm
      quality:       medium
      size:          0.5 MiB (564215 bytes)
    # download-with: you-get --itag=43 [URL]

Downloading Me at the zoo.webm ...
 100% (  0.5/  0.5MB) â”œâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”¤[1/1]    6 MB/s

Saving Me at the zoo.en.srt ... Done.
```

And here&#039;s why you might want to use it:

* You enjoyed something on the Internet, and just want to download them for your own pleasure.
* You watch your favorite videos online from your computer, but you are prohibited from saving them. You feel that you have no control over your own computer. (And it&#039;s not how an open Web is supposed to work.)
* You want to get rid of any closed-source technology or proprietary JavaScript code, and disallow things like Flash running on your computer.
* You are an adherent of hacker culture and free software.

What `you-get` can do for you:

* Download videos / audios from popular websites such as YouTube, Youku, Niconico, and a bunch more. (See the [full list of supported sites](#supported-sites))
* Stream an online video in your media player. No web browser, no more ads.
* Download images (of interest) by scraping a web page.
* Download arbitrary non-HTML contents, i.e., binary files.

Interested? [Install it](#installation) now and [get started by examples](#getting-started).

Are you a Python programmer? Then check out [the source](https://github.com/soimort/you-get) and fork it!

![](https://i.imgur.com/GfthFAz.png)

## Installation

### Prerequisites

The following dependencies are recommended:

* **[Python](https://www.python.org/downloads/)**  3.7.4 or above
* **[FFmpeg](https://www.ffmpeg.org/)** 1.0 or above
* (Optional) [RTMPDump](https://rtmpdump.mplayerhq.hu/)

### Option 1: Install via pip

The official release of `you-get` is distributed on [PyPI](https://pypi.python.org/pypi/you-get), and can be installed easily from a PyPI mirror via the [pip](https://en.wikipedia.org/wiki/Pip_\(package_manager\)) package manager: (Note that you must use the Python 3 version of `pip`)

    $ pip install you-get

### Option 2: Install via [Antigen](https://github.com/zsh-users/antigen) (for Zsh users)

Add the following line to your `.zshrc`:

    antigen bundle soimort/you-get

### Option 3: Download from GitHub

You may either download the [stable](https://github.com/soimort/you-get/archive/master.zip) (identical with the latest release on PyPI) or the [develop](https://github.com/soimort/you-get/archive/develop.zip) (more hotfixes, unstable features) branch of `you-get`. Unzip it, and put the directory containing the `you-get` script into your `PATH`.

Alternatively, run

```
$ cd path/to/you-get
$ [sudo] python -m pip install .
```

Or

```
$ cd path/to/you-get
$ python -m pip install . --user
```

to install `you-get` to a permanent path. (And don&#039;t omit the dot `.` representing the current directory)

You can also use the [pipenv](https://pipenv.pypa.io/en/latest) to install the `you-get` in the Python virtual environment.

```
$ pipenv install -e .
$ pipenv run you-get --version
you-get: version 0.4.1555, a tiny downloader that scrapes the web.
```

### Option 4: Git clone

This is the recommended way for all developers, even if you don&#039;t often code in Python.

```
$ git clone git://github.com/soimort/you-get.git
```

Then put the cloned directory into your `PATH`, or run `python -m pip install path/to/you-get` to install `you-get` to a permanent path.

### Option 5: Homebrew (Mac only)

You can install `you-get` easily via:

```
$ brew install you-get
```

### Option 6: pkg (FreeBSD only)

You can install `you-get` easily via:

```
# pkg install you-get
```

### Option 7: Flox (Mac, Linux, and Windows WSL)

You can install `you-get` easily via:

```
$ flox install you-get
```

### Shell completion

Completion definitions for Bash, Fish and Zsh can be found in [`contrib/completion`](https://github.com/soimort/you-get/tree/develop/contrib/completion). Please consult your shell&#039;s manual for how to take advantage of them.

## Upgrading

Based on which option you chose to install `you-get`, you may upgrade it via:

```
$ pip install --upgrade you-get
```

or download the latest release via:

```
$ you-get https://github.com/soimort/you-get/archive/master.zip
```

In order to get the latest ```develop``` branch without messing up the PIP, you can try:

```
$ pip install --upgrade git+https://github.com/soimort/you-get@develop
```

## Getting Started

### Download a video

When you get a video of interest, you might want to use the `--info`/`-i` option to see all available quality and formats:

```
$ you-get -i &#039;https://www.youtube.com/watch?v=jNQXAC9IVRw&#039;
site:                YouTube
title:               Me at the zoo
streams:             # Available quality and codecs
    [ DASH ] ____________________________________
    - itag:          242
      container:     webm
      quality:       320x240
      size:          0.6 MiB (618358 bytes)
    # download-with: you-get --itag=242 [URL]

    - itag:          395
      container:     mp4
      quality:       320x240
      size:          0.5 MiB (550743 bytes)
    # download-with: you-get --itag=395 [URL]

    - itag:          133
      container:     mp4
      quality:       320x240
      size:          0.5 MiB (498558 bytes)
    # download-with: you-get --itag=133 [URL]

    - itag:          278
      container:     webm
      quality:       192x144
      size:          0.4 MiB (392857 bytes)
    # download-with: you-get --itag=278 [URL]

    - itag:          160
      container:     mp4
      quality:       192x144
      size:          0.4 MiB (370882 bytes)
    # download-with: you-get --itag=160 [URL]

    - itag:          394
      container:     mp4
      quality:       192x144
      size:          0.4 MiB (367261 bytes)
    # download-with: you-get --itag=394 [URL]

    [ DEFAULT ] _________________________________
    - itag:          43
      container:     webm
      quality:       medium
      size:          0.5 MiB (568748 bytes)
    # download-with: you-get --itag=43 [URL]

    - itag:          18
      container:     mp4
      quality:       small
    # download-with: you-get --itag=18 [URL]

    - itag:          36
      container:     3gp
      quality:       small
    # download-with: you-get --itag=36 [URL]

    - itag:          17
      container:     3gp
      quality:       small
    # download-with: you-get --itag=17 [URL]
```

By default, the one on the top is the one you will get. If that looks cool to you, download it:

```
$ you-get &#039;https://www.youtube.com/watch?v=jNQXAC9IVRw&#039;
site:                YouTube
title:               Me at the zoo
stream:
    - itag:          242
      container:     webm
      quality:       320x240
      size:          0.6 MiB (618358 bytes)
    # download-with: you-get --itag=242 [URL]

Downloading Me at the zoo.webm ...
 100% (  0.6/  0.6MB) â”œâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”¤[2/2]    2 MB/s
Merging video parts... Merged into Me at the zoo.webm

Saving Me at the zoo.en.srt ... Done.
```

(If a YouTube video has any closed captions, they will be downloaded together with the video file, in SubRip subtitle format.)

Or, if you prefer another format (mp4), just use whatever the option `you-get` shows to you:

```
$ you-get --itag=18 &#039;https://www.youtube.com/watch?v=jNQXAC9IVRw&#039;
```

**Note:**

* At this point, format selection has not been generally implemented for most of our supported sites; in that case, the default format to download is the one with the highest quality.
* `ffmpeg` is a required dependency, for downloading and joining videos streamed in multiple parts (e.g. on some sites like Youku), and for YouTube videos of 1080p or high resolution.
* If you don&#039;t want `you-get` to join video parts after downloading them, use the `--no-merge`/`-n` option.

### Download anything else

If you already have the URL of the exact resource you want, you can download it directly with:

```
$ you-get https://stallman.org/rms.jpg
Site:       stallman.org
Title:      rms
Type:       JPEG Image (image/jpeg)
Size:       0.06 MiB (66482 Bytes)

Downloading rms.jpg ...
 100% (  0.1/  0.1MB) â”œâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”¤[1/1]  127 kB/s
```

Otherwise, `you-get` will scrape the web page and try to figure out if there&#039;s anything interesting to you:

```
$ you-get https://kopasas.tumblr.com/post/69361932517
Site:       Tumblr.com
Title:      [tumblr] tumblr_mxhg13jx4n1sftq6do1_640
Type:       Portable Network Graphics (image/png)
Size:       0.11 MiB (118484 Bytes)

Downloading [tumblr] tumblr_mxhg13jx4n1sftq6do1_640.png ...
 100% (  0.1/  0.1MB) â”œâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”¤[1/1]   22 MB/s
```

**Note:**

* This feature is an experimental one and far from perfect. It works best on scraping large-sized images from popular websites like Tumblr and Blogger, but there is really no universal pattern that can apply to any site on the Internet.

### Search on Google Videos and download

You can pass literally anything to `you-get`. If it isn&#039;t a valid URL, `you-get` will do a Google search and download the most relevant video for you. (It might not be exactly the thing you wish to see, but still very likely.)

```
$ you-get &quot;Richard Stallman eats&quot;
```

### Pause and resume a download

You may use &lt;kbd&gt;Ctrl&lt;/kbd&gt;+&lt;kbd&gt;C&lt;/kbd&gt; to interrupt a download.

A temporary `.download` file is kept in the output directory. Next time you run `you-get` with the same arguments, the download progress will resume from the last session. In case the file is completely downloaded (the temporary `.download` extension is gone), `you-get` will just skip the download.

To enforce re-downloading, use the `--force`/`-f` option. (**Warning:** doing so will overwrite any existing file or temporary file with the same name!)

### Set the path and name of downloaded file

Use the `--output-dir`/`-o` option to set the path, and `--output-filename`/`-O` to set the name of the downloaded file:

```
$ you-get -o ~/Videos -O zoo.webm &#039;https://www.youtube.com/watch?v=jNQXAC9IVRw&#039;
```

**Tips:**

* These options are helpful if you encounter problems with the default video titles, which may contain special characters that do not play well with your current shell / operating system / filesystem.
* These options are also helpful if you write a script to batch download files and put them into designated folders with designated names.

### Proxy settings

You may specify an HTTP proxy for `you-get` to use, via the `--http-proxy`/`-x` option:

```
$ you-get -x 127.0.0.1:8087 &#039;https://www.youtube.com/watch?v=jNQXAC9IVRw&#039;
```

However, the system proxy setting (i.e. the environment variable `http_proxy`) is applied by default. To disable any proxy, use the `--no-proxy` option.

**Tips:**

* If you need to use proxies a lot (in case your network is blocking certain sites), you might want to use `you-get` with [proxychains](https://github.com/rofl0r/proxychains-ng) and set `alias you-get=&quot;proxychains -q you-get&quot;` (in Bash).
* For some websites (e.g. Youku), if you need access to some videos that are only available in mainland China, there is an option of using a specific proxy to extract video information from the site: `--extractor-proxy`/`-y`.

### Watch a video

Use the `--player`/`-p` option to feed the video into your media player of choice, e.g. `mpv` or `vlc`, instead of downloading it:

```
$ you-get -p vlc &#039;https://www.youtube.com/watch?v=jNQXAC9IVRw&#039;
```

Or, if you prefer to watch the video in a browser, just without ads or comment section:

```
$ you-get -p chromium &#039;https://www.youtube.com/watch?v=jNQXAC9IVRw&#039;
```

**Tips:**

* It is possible to use the `-p` option to start another download manager, e.g., `you-get -p uget-gtk &#039;https://www.youtube.com/watch?v=jNQXAC9IVRw&#039;`, though they may not play together very well.

### Load cookies

Not all videos are publicly available to anyone. If you need to log in your account to access something (e.g., a private video), it would be unavoidable to feed the browser cookies to `you-get` via the `--cookies`/`-c` option.

**Note:**

* As of now, we are supporting two formats of browser cookies: Mozilla `cookies.sqlite` and Netscape `cookies.txt`.

### Reuse extracted data

Use `--url`/`-u` to get a list of downloadable resource URLs extracted from the page. Use `--json` to get an abstract of extracted data in the JSON format.

**Warning:**

* For the time being, this feature has **NOT** been stabilized and the JSON schema may have breaking changes in the future.

## Supported Sites

| Site | URL | Videos? | Images? | Audios? |
| :--: | :-- | :-----: | :-----: | :-----: |
| **YouTube** | &lt;https://www.youtube.com/&gt;    |âœ“| | |
| **X (Twitter)** | &lt;https://x.com/&gt;        |âœ“|âœ“| |
| VK          | &lt;https://vk.com/&gt;              |âœ“|âœ“| |
| Vimeo       | &lt;https://vimeo.com/&gt;          |âœ“| | |
| Veoh        | &lt;https://www.veoh.com/&gt;        |âœ“| | |
| **Tumblr**  | &lt;https://www.tumblr.com/&gt;     |âœ“|âœ“|âœ“|
| TED         | &lt;https://www.ted.com/&gt;         |âœ“| | |
| SoundCloud  | &lt;https://soundcloud.com/&gt;     | | |âœ“|
| SHOWROOM    | &lt;https://www.showroom-live.com/&gt; |âœ“| | |
| Pinterest   | &lt;https://www.pinterest.com/&gt;  | |âœ“| |
| MTV81       | &lt;https://www.mtv81.com/&gt;       |âœ“| | |
| Mixcloud    | &lt;https://www.mixcloud.com/&gt;   | | |âœ“|
| Metacafe    | &lt;https://www.metacafe.com/&gt;    |âœ“| | |
| Magisto     | &lt;https://www.magisto.com/&gt;     |âœ“| | |
| Khan Academy | &lt;https://www.khanacademy.org/&gt; |âœ“| | |
| Internet Archive | &lt;https://archive.org/&gt;   |âœ“| | |
| **Instagram** | &lt;https://instagram.com/&gt;    |âœ“|âœ“| |
| InfoQ       | &lt;https://www.infoq.com/presentations/&gt; |âœ“| | |
| Imgur       | &lt;https://imgur.com/&gt;           | |âœ“| |
| Heavy Music Archive | &lt;https://www.heavy-music.ru/&gt; | | |âœ“|
| Freesound   | &lt;https://www.freesound.org/&gt;   | | |âœ“|
| Flickr      | &lt;https://www.flickr.com/&gt;     |âœ“|âœ“| |
| FC2 Video   | &lt;https://video.fc2.com/&gt;       |âœ“| | |
| Facebook    | &lt;https://www.facebook.com/&gt;   |âœ“| | |
| eHow        | &lt;https://www.ehow.com/&gt;        |âœ“| | |
| Dailymotion | &lt;https://www.dailymotion.com/&gt; |âœ“| | |
| Coub        | &lt;https://coub.com/&gt;            |âœ“| | |
| CBS         | &lt;https://www.cbs.com/&gt;         |âœ“| | |
| Bandcamp    | &lt;https://bandcamp.com/&gt;        | | |âœ“|
| AliveThai   | &lt;https://alive.in.th/&gt;         |âœ“| | |
| interest.me | &lt;https://ch.interest.me/tvn&gt;   |âœ“| | |
| **755&lt;br/&gt;ãƒŠãƒŠã‚´ãƒ¼ã‚´ãƒ¼** | &lt;https://7gogo.jp/&gt; |âœ“|âœ“| |
| **niconico&lt;br/&gt;ãƒ‹ã‚³ãƒ‹ã‚³å‹•ç”»** | &lt;https://www.nicovideo.jp/&gt; |âœ“| | |
| **163&lt;br/&gt;ç½‘æ˜“è§†é¢‘&lt;br/&gt;ç½‘æ˜“äº‘éŸ³ä¹** | &lt;https://v.163.com/&gt;&lt;br/&gt;&lt;https://music.163.com/&gt; |âœ“| |âœ“|
| 56ç½‘     | &lt;https://www.56.com/&gt;           |âœ“| | |
| **AcFun** | &lt;https://www.acfun.cn/&gt;        |âœ“| | |
| **Baidu&lt;br/&gt;ç™¾åº¦è´´å§** | &lt;https://tieba.baidu.com/&gt; |âœ“|âœ“| |
| çˆ†ç±³èŠ±ç½‘ | &lt;https://www.baomihua.com/&gt;     |âœ“| | |
| **bilibili&lt;br/&gt;å“”å“©å“”å“©** | &lt;https://www.bilibili.com/&gt; |âœ“|âœ“|âœ“|
| è±†ç“£     | &lt;https://www.douban.com/&gt;       |âœ“| |âœ“|
| æ–—é±¼     | &lt;https://www.douyutv.com/&gt;      |âœ“| | |
| å‡¤å‡°è§†é¢‘ | &lt;https://v.ifeng.com/&gt;          |âœ“| | |
| é£è¡Œç½‘   | &lt;https://www.fun.tv/&gt;           |âœ“| | |
| iQIYI&lt;br/&gt;çˆ±å¥‡è‰º | &lt;https://www.iqiyi.com/&gt; |âœ“| | |
| æ¿€åŠ¨ç½‘   | &lt;https://www.joy.cn/&gt;           |âœ“| | |
| é…·6ç½‘    | &lt;https://www.ku6.com/&gt;          |âœ“| | |
| é…·ç‹—éŸ³ä¹ | &lt;https://www.kugou.com/&gt;        | | |âœ“|
| é…·æˆ‘éŸ³ä¹ | &lt;https://www.kuwo.cn/&gt;          | | |âœ“|
| ä¹è§†ç½‘   | &lt;https://www.le.com/&gt;           |âœ“| | |
| è”æFM   | &lt;https://www.lizhi.fm/&gt;         | | |âœ“|
| æ‡’äººå¬ä¹¦ | &lt;https://www.lrts.me/&gt;          | | |âœ“|
| ç§’æ‹     | &lt;https://www.miaopai.com/&gt;      |âœ“| | |
| MioMioå¼¹å¹•ç½‘ | &lt;https://www.miomio.tv/&gt;    |âœ“| | |
| MissEvan&lt;br/&gt;çŒ«è€³FM | &lt;https://www.missevan.com/&gt; | | |âœ“|
| ç—å®¢é‚¦   | &lt;https://www.pixnet.net/&gt;      |âœ“| | |
| PPTVèšåŠ› | &lt;https://www.pptv.com/&gt;         |âœ“| | |
| é½é²ç½‘   | &lt;https://v.iqilu.com/&gt;          |âœ“| | |
| QQ&lt;br/&gt;è…¾è®¯è§†é¢‘ | &lt;https://v.qq.com/&gt;      |âœ“| | |
| ä¼é¹…ç›´æ’­ | &lt;https://live.qq.com/&gt;          |âœ“| | |
| Sina&lt;br/&gt;æ–°æµªè§†é¢‘&lt;br/&gt;å¾®åšç§’æ‹è§†é¢‘ | &lt;https://video.sina.com.cn/&gt;&lt;br/&gt;&lt;https://video.weibo.com/&gt; |âœ“| | |
| Sohu&lt;br/&gt;æœç‹è§†é¢‘ | &lt;https://tv.sohu.com/&gt; |âœ“| | |
| **Tudou&lt;br/&gt;åœŸè±†** | &lt;https://www.tudou.com/&gt; |âœ“| | |
| é˜³å…‰å«è§† | &lt;https://www.isuntv.com/&gt;       |âœ“| | |
| **Youku&lt;br/&gt;ä¼˜é…·** | &lt;https://www.youku.com/&gt; |âœ“| | |
| æˆ˜æ——TV   | &lt;https://www.zhanqi.tv/lives&gt;   |âœ“| | |
| å¤®è§†ç½‘   | &lt;https://www.cntv.cn/&gt;          |âœ“| | |
| Naver&lt;br/&gt;ë„¤ì´ë²„ | &lt;https://tvcast.naver.com/&gt;     |âœ“| | |
| èŠ’æœTV   | &lt;https://www.mgtv.com/&gt;         |âœ“| | |
| ç«çŒ«TV   | &lt;https://www.huomao.com/&gt;       |âœ“| | |
| é˜³å…‰å®½é¢‘ç½‘ | &lt;https://www.365yg.com/&gt;      |âœ“| | |
| è¥¿ç“œè§†é¢‘ | &lt;https://www.ixigua.com/&gt;      |âœ“| | |
| æ–°ç‰‡åœº | &lt;https://www.xinpianchang.com/&gt;      |âœ“| | |
| å¿«æ‰‹ | &lt;https://www.kuaishou.com/&gt;      |âœ“|âœ“| |
| æŠ–éŸ³ | &lt;https://www.douyin.com/&gt;      |âœ“| | |
| TikTok | &lt;https://www.tiktok.com/&gt;      |âœ“| | |
| ä¸­å›½ä½“è‚²(TV) | &lt;https://v.zhibo.tv/&gt; &lt;/br&gt;&lt;https://video.zhibo.tv/&gt;    |âœ“| | |
| çŸ¥ä¹ | &lt;https://www.zhihu.com/&gt;      |âœ“| | |

For all other sites not on the list, the universal extractor will take care of finding and downloading interesting resources from the page.

### Known bugs

If something is broken and `you-get` can&#039;t get you things you want, don&#039;t panic. (Yes, this happens all the time!)

Check if it&#039;s already a known problem on &lt;https://github.com/soimort/you-get/wiki/Known-Bugs&gt;. If not, follow the guidelines on [how to report an issue](https://github.com/soimort/you-get/blob/develop/CONTRIBUTING.md).

## Getting Involved

You can reach us on the Gitter channel [#soimort/you-get](https://gitter.im/soimort/you-get) (here&#039;s how you [set up your IRC client](https://irc.gitter.im) for Gitter). If you have a quick question regarding `you-get`, ask it there.

If you are seeking to report an issue or contribute, please make sure to read [the guidelines](https://github.com/soimort/you-get/blob/develop/CONTRIBUTING.md) first.

## Legal Issues

This software is distributed under the [MIT license](https://raw.github.com/soimort/you-get/master/LICENSE.txt).

In particular, please be aware that

&gt; THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

Translated to human words:

*In case your use of the software forms the basis of copyright infringement, or you use the software for any other illegal purposes, the authors cannot take any responsibility for you.*

We only ship the code here, and how you are going to use it is left to your own discretion.

## Authors

Made by [@soimort](https://github.com/soimort), who

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[WEIFENG2333/VideoCaptioner]]></title>
            <link>https://github.com/WEIFENG2333/VideoCaptioner</link>
            <guid>https://github.com/WEIFENG2333/VideoCaptioner</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:41 GMT</pubDate>
            <description><![CDATA[ğŸ¬ å¡å¡å­—å¹•åŠ©æ‰‹ | VideoCaptioner - åŸºäº LLM çš„æ™ºèƒ½å­—å¹•åŠ©æ‰‹ - è§†é¢‘å­—å¹•ç”Ÿæˆã€æ–­å¥ã€æ ¡æ­£ã€å­—å¹•ç¿»è¯‘å…¨æµç¨‹å¤„ç†ï¼- A powered tool for easy and efficient video subtitling.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/WEIFENG2333/VideoCaptioner">WEIFENG2333/VideoCaptioner</a></h1>
            <p>ğŸ¬ å¡å¡å­—å¹•åŠ©æ‰‹ | VideoCaptioner - åŸºäº LLM çš„æ™ºèƒ½å­—å¹•åŠ©æ‰‹ - è§†é¢‘å­—å¹•ç”Ÿæˆã€æ–­å¥ã€æ ¡æ­£ã€å­—å¹•ç¿»è¯‘å…¨æµç¨‹å¤„ç†ï¼- A powered tool for easy and efficient video subtitling.</p>
            <p>Language: Python</p>
            <p>Stars: 8,794</p>
            <p>Forks: 684</p>
            <p>Stars today: 37 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/logo.png&quot;alt=&quot;VideoCaptioner Logo&quot; width=&quot;100&quot;&gt;
  &lt;p&gt;å¡å¡å­—å¹•åŠ©æ‰‹&lt;/p&gt;
  &lt;h1&gt;VideoCaptioner&lt;/h1&gt;
  &lt;p&gt;ä¸€æ¬¾åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„è§†é¢‘å­—å¹•å¤„ç†åŠ©æ‰‹ï¼Œæ”¯æŒè¯­éŸ³è¯†åˆ«ã€å­—å¹•æ–­å¥ã€ä¼˜åŒ–ã€ç¿»è¯‘å…¨æµç¨‹å¤„ç†&lt;/p&gt;

  ç®€ä½“ä¸­æ–‡ / [æ­£é«”ä¸­æ–‡](./docs/README_TW.md) / [English](./docs/README_EN.md) / [æ—¥æœ¬èª](./docs/README_JA.md)
  
&lt;/div&gt;

## ğŸ“– é¡¹ç›®ä»‹ç»

å¡å¡å­—å¹•åŠ©æ‰‹ï¼ˆVideoCaptionerï¼‰æ“ä½œç®€å•ä¸”æ— éœ€é«˜é…ç½®ï¼Œæ”¯æŒç½‘ç»œè°ƒç”¨å’Œæœ¬åœ°ç¦»çº¿ï¼ˆæ”¯æŒè°ƒç”¨GPUï¼‰ä¸¤ç§æ–¹å¼è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œåˆ©ç”¨å¯ç”¨é€šè¿‡å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œå­—å¹•æ™ºèƒ½æ–­å¥ã€æ ¡æ­£ã€ç¿»è¯‘ï¼Œå­—å¹•è§†é¢‘å…¨æµç¨‹ä¸€é”®å¤„ç†ï¼ä¸ºè§†é¢‘é…ä¸Šæ•ˆæœæƒŠè‰³çš„å­—å¹•ã€‚

æœ€æ–°ç‰ˆæœ¬å·²ç»æ”¯æŒ VAD ã€ äººå£°åˆ†ç¦»ã€ å­—çº§æ—¶é—´æˆ³ æ‰¹é‡å­—å¹•ç­‰å®ç”¨åŠŸèƒ½

- ğŸ¯ æ— éœ€GPUå³å¯ä½¿ç”¨å¼ºå¤§çš„è¯­éŸ³è¯†åˆ«å¼•æ“ï¼Œç”Ÿæˆç²¾å‡†å­—å¹•
- âœ‚ï¸ åŸºäº LLM çš„æ™ºèƒ½åˆ†å‰²ä¸æ–­å¥ï¼Œå­—å¹•é˜…è¯»æ›´è‡ªç„¶æµç•…
- ğŸ”„ AIå­—å¹•å¤šçº¿ç¨‹ä¼˜åŒ–ä¸ç¿»è¯‘ï¼Œè°ƒæ•´å­—å¹•æ ¼å¼ã€è¡¨è¾¾æ›´åœ°é“ä¸“ä¸š
- ğŸ¬ æ”¯æŒæ‰¹é‡è§†é¢‘å­—å¹•åˆæˆï¼Œæå‡å¤„ç†æ•ˆç‡
- ğŸ“ ç›´è§‚çš„å­—å¹•ç¼–è¾‘æŸ¥çœ‹ç•Œé¢ï¼Œæ”¯æŒå®æ—¶é¢„è§ˆå’Œå¿«æ·ç¼–è¾‘
- ğŸ¤– æ¶ˆè€—æ¨¡å‹ Token å°‘ï¼Œä¸”å†…ç½®åŸºç¡€ LLM æ¨¡å‹ï¼Œä¿è¯å¼€ç®±å³ç”¨

## ğŸ“¸ ç•Œé¢é¢„è§ˆ

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://h1.appinn.me/file/1731487405884_main.png&quot; alt=&quot;è½¯ä»¶ç•Œé¢é¢„è§ˆ&quot; width=&quot;90%&quot; style=&quot;border-radius: 5px;&quot;&gt;
&lt;/div&gt;

![é¡µé¢é¢„è§ˆ](https://h1.appinn.me/file/1731487410170_preview1.png)
![é¡µé¢é¢„è§ˆ](https://h1.appinn.me/file/1731487410832_preview2.png)


## ğŸ§ª æµ‹è¯•

å…¨æµç¨‹å¤„ç†ä¸€ä¸ª14åˆ†é’Ÿ1080Pçš„ [Bç«™è‹±æ–‡ TED è§†é¢‘](https://www.bilibili.com/video/BV1jT411X7Dz)ï¼Œè°ƒç”¨æœ¬åœ° Whisper æ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œä½¿ç”¨ `gpt-4o-mini` æ¨¡å‹ä¼˜åŒ–å’Œç¿»è¯‘ä¸ºä¸­æ–‡ï¼Œæ€»å…±æ¶ˆè€—æ—¶é—´çº¦ **4 åˆ†é’Ÿ**ã€‚

 è¿‘åå°è®¡ç®—ï¼Œæ¨¡å‹ä¼˜åŒ–å’Œç¿»è¯‘æ¶ˆè€—è´¹ç”¨ä¸è¶³ ï¿¥0.01ï¼ˆä»¥OpenAIå®˜æ–¹ä»·æ ¼ä¸ºè®¡ç®—ï¼‰

å…·ä½“å­—å¹•å’Œè§†é¢‘åˆæˆçš„æ•ˆæœçš„æµ‹è¯•ç»“æœå›¾ç‰‡ï¼Œè¯·å‚è€ƒ [TEDè§†é¢‘æµ‹è¯•](./docs/test.md)


## ğŸš€ å¿«é€Ÿå¼€å§‹

### Windows ç”¨æˆ·

è½¯ä»¶è¾ƒä¸ºè½»é‡ï¼Œæ‰“åŒ…å¤§å°ä¸è¶³ 60M,å·²é›†æˆæ‰€æœ‰å¿…è¦ç¯å¢ƒï¼Œä¸‹è½½åå¯ç›´æ¥è¿è¡Œã€‚

1. ä» [Release](https://github.com/WEIFENG2333/VideoCaptioner/releases) é¡µé¢ä¸‹è½½æœ€æ–°ç‰ˆæœ¬çš„å¯æ‰§è¡Œç¨‹åºã€‚æˆ–è€…ï¼š[è“å¥ç›˜ä¸‹è½½](https://wwwm.lanzoue.com/ii14G2pdsbej)

2. æ‰“å¼€å®‰è£…åŒ…è¿›è¡Œå®‰è£…

3. LLM API é…ç½®ï¼Œï¼ˆç”¨äºå­—å¹•æ–­å¥ã€æ ¡æ­£ï¼‰ï¼Œå¯ä½¿ç”¨ [âœ¨æœ¬é¡¹ç›®çš„ä¸­è½¬ç«™ ](https://api.videocaptioner.cn) 

4. ç¿»è¯‘é…ç½®ï¼Œé€‰æ‹©æ˜¯å¦å¯ç”¨ç¿»è¯‘ï¼Œç¿»è¯‘æœåŠ¡ï¼ˆé»˜è®¤ä½¿ç”¨å¾®è½¯ç¿»è¯‘ï¼Œè´¨é‡ä¸€èˆ¬ï¼Œæ¨èä½¿ç”¨å¤§æ¨¡å‹ç¿»è¯‘ï¼‰

5. è¯­éŸ³è¯†åˆ«é…ç½®ï¼ˆé»˜è®¤ä½¿ç”¨Bæ¥å£ï¼Œä¸­è‹±ä»¥å¤–çš„è¯­è¨€è¯·ä½¿ç”¨æœ¬åœ°è½¬å½•ï¼‰

6. æ‹–æ‹½è§†é¢‘æ–‡ä»¶åˆ°è½¯ä»¶çª—å£ï¼Œå³å¯å…¨è‡ªåŠ¨å¤„ç†

æç¤ºï¼šæ¯ä¸€ä¸ªæ­¥éª¤å‡æ”¯æŒå•ç‹¬å¤„ç†ï¼Œå‡æ”¯æŒæ–‡ä»¶æ‹–æ‹½ã€‚è½¯ä»¶å…·ä½“æ¨¡å‹é€‰æ‹©å’Œå‚æ•°é…ç½®è¯´æ˜ï¼Œè¯·æŸ¥çœ‹ä¸‹æ–‡ã€‚

&lt;details&gt;
&lt;summary&gt;MacOS ç”¨æˆ·&lt;/summary&gt;
 
 
ç”±äºæœ¬äººç¼ºå°‘ Macï¼Œæ‰€ä»¥æ²¡æ³•æµ‹è¯•å’Œæ‰“åŒ…ï¼Œæš‚æ— æ³•æä¾› MacOS çš„å¯æ‰§è¡Œç¨‹åºã€‚

Mac ç”¨æˆ·è¯·è‡ªè¡Œä½¿ç”¨ä¸‹è½½æºç å’Œå®‰è£… python ä¾èµ–è¿è¡Œã€‚ï¼ˆæœ¬åœ° Whisper åŠŸèƒ½æš‚ä¸æ”¯æŒ MacOSï¼‰

1. å®‰è£… ffmpeg å’Œ Aria2 ä¸‹è½½å·¥å…·
```bash
brew install ffmpeg
brew install aria2
brew install python@3.**
```

2. å…‹éš†é¡¹ç›®
```bash
git clone https://github.com/WEIFENG2333/VideoCaptioner.git
cd VideoCaptioner
```

3. å®‰è£…ä¾èµ–
```bash
python3.** -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

4. è¿è¡Œç¨‹åº
```bash
python main.py
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Docker éƒ¨ç½²ï¼ˆbetaï¼‰&lt;/summary&gt;

ç›®å‰æœ¬é¡¹ç›®streamlitåº”ç”¨å› ä¸ºé¡¹ç›®é‡æ„è¿‡ï¼ŒDockerä¸å¯ä»¥ä½¿ç”¨ã€‚æ¬¢è¿å„ä½PRè´¡çŒ®æ–°ä»£ç ã€‚

### 1. å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/WEIFENG2333/VideoCaptioner.git
cd VideoCaptioner

```

### 2. æ„å»ºé•œåƒ

```bash
docker build -t video-captioner .
```

### 3. è¿è¡Œå®¹å™¨

ä½¿ç”¨è‡ªå®šä¹‰APIé…ç½®è¿è¡Œï¼š
```bash
docker run -d \
  -p 8501:8501 \
  -v $(pwd)/temp:/app/temp \
  -e OPENAI_BASE_URL=&quot;ä½ çš„APIåœ°å€&quot; \
  -e OPENAI_API_KEY=&quot;ä½ çš„APIå¯†é’¥&quot; \
  --name video-captioner \
  video-captioner
```

### 4. è®¿é—®åº”ç”¨

æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼š`http://localhost:8501`

### æ³¨æ„äº‹é¡¹

- å®¹å™¨å†…å·²é¢„è£…ffmpegç­‰å¿…è¦ä¾èµ–
- å¦‚éœ€ä½¿ç”¨å…¶ä»–æ¨¡å‹ï¼Œè¯·é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®

&lt;/details&gt;

## âš™ï¸ åŸºæœ¬é…ç½®

### 1. LLM API é…ç½®è¯´æ˜

LLM å¤§æ¨¡å‹æ˜¯ç”¨æ¥å­—å¹•æ®µå¥ã€å­—å¹•ä¼˜åŒ–ã€ä»¥åŠå­—å¹•ç¿»è¯‘ï¼ˆå¦‚æœé€‰æ‹©äº†LLM å¤§æ¨¡å‹ç¿»è¯‘ï¼‰ã€‚

| é…ç½®é¡¹ | è¯´æ˜ |
|--------|------|
| SiliconCloud | [SiliconCloud å®˜ç½‘](https://cloud.siliconflow.cn/i/onCHcaDx)é…ç½®æ–¹æ³•è¯·å‚è€ƒ[é…ç½®æ–‡æ¡£](./docs/llm_config.md)&lt;br&gt;è¯¥å¹¶å‘è¾ƒä½ï¼Œå»ºè®®æŠŠçº¿ç¨‹è®¾ç½®ä¸º5ä»¥ä¸‹ã€‚ |
| DeepSeek | [DeepSeek å®˜ç½‘](https://platform.deepseek.com)ï¼Œå»ºè®®ä½¿ç”¨ `deepseek-v3` æ¨¡å‹ï¼Œ&lt;br&gt;å®˜æ–¹ç½‘ç«™æœ€è¿‘æœåŠ¡å¥½åƒå¹¶ä¸å¤ªç¨³å®šã€‚ |
| Ollamaæœ¬åœ° | [Ollama å®˜ç½‘](https://ollama.com) |
| å†…ç½®å…¬ç›Šæ¨¡å‹ | å†…ç½®åŸºç¡€å¤§è¯­è¨€æ¨¡å‹ï¼ˆ`gpt-4o-mini`ï¼‰(å…¬ç›ŠæœåŠ¡ä¸ç¨³å®šï¼Œå¼ºçƒˆå»ºè®®è¯·ä½¿ç”¨è‡ªå·±çš„æ¨¡å‹API) |
| OpenAIå…¼å®¹æ¥å£ | å¦‚æœæœ‰å…¶ä»–æœåŠ¡å•†çš„APIï¼Œå¯ç›´æ¥åœ¨è½¯ä»¶ä¸­å¡«å†™ã€‚base_url å’Œapi_key |

æ³¨ï¼šå¦‚æœç”¨çš„ API æœåŠ¡å•†ä¸æ”¯æŒé«˜å¹¶å‘ï¼Œè¯·åœ¨è½¯ä»¶è®¾ç½®ä¸­å°†â€œçº¿ç¨‹æ•°â€è°ƒä½ï¼Œé¿å…è¯·æ±‚é”™è¯¯ã€‚

---

å¦‚æœå¸Œæœ›é«˜å¹¶å‘âš¡ï¸ï¼Œæˆ–è€…å¸Œæœ›åœ¨åœ¨è½¯ä»¶å†…ä½¿ç”¨ä½¿ç”¨ OpenAI æˆ–è€… Claude ç­‰ä¼˜è´¨å¤§æ¨¡å‹è¿›è¡Œå­—å¹•æ ¡æ­£å’Œç¿»è¯‘ã€‚

å¯ä½¿ç”¨æœ¬é¡¹ç›®çš„âœ¨LLM APIä¸­è½¬ç«™âœ¨ï¼š [https://api.videocaptioner.cn](https://api.videocaptioner.cn)

å…¶æ”¯æŒé«˜å¹¶å‘ï¼Œæ€§ä»·æ¯”æé«˜ï¼Œä¸”æœ‰å›½å†…å¤–å¤§é‡æ¨¡å‹å¯æŒ‘é€‰ã€‚

æ³¨å†Œè·å–keyä¹‹åï¼Œè®¾ç½®ä¸­æŒ‰ç…§ä¸‹é¢é…ç½®ï¼š

BaseURL: `https://api.videocaptioner.cn/v1`

API-key: `ä¸ªäººä¸­å¿ƒ-API ä»¤ç‰Œé¡µé¢è‡ªè¡Œè·å–ã€‚`

ğŸ’¡ æ¨¡å‹é€‰æ‹©å»ºè®® (æœ¬äººåœ¨å„è´¨é‡å±‚çº§ä¸­ç²¾é€‰å‡ºçš„é«˜æ€§ä»·æ¯”æ¨¡å‹)ï¼š 

 - é«˜è´¨é‡ä¹‹é€‰ï¼š `claude-3-5-sonnet-20241022` (è€—è´¹æ¯”ä¾‹ï¼š3) 

 - è¾ƒé«˜è´¨é‡ä¹‹é€‰ï¼š `gemini-2.0-flash`ã€`deepseek-chat` (è€—è´¹æ¯”ä¾‹ï¼š1) 

 - ä¸­è´¨é‡ä¹‹é€‰ï¼š `gpt-4o-mini`ã€`gemini-1.5-flash` (è€—è´¹æ¯”ä¾‹ï¼š0.15) 

æœ¬ç«™æ”¯æŒè¶…é«˜å¹¶å‘ï¼Œè½¯ä»¶ä¸­çº¿ç¨‹æ•°ç›´æ¥æ‹‰æ»¡å³å¯~ å¤„ç†é€Ÿåº¦éå¸¸å¿«~

æ›´è¯¦ç»†çš„APIé…ç½®æ•™ç¨‹ï¼š[ä¸­è½¬ç«™é…ç½®é…ç½®](./docs/llm_config.md#ä¸­è½¬ç«™é…ç½®)

---

## 2. ç¿»è¯‘é…ç½®

| é…ç½®é¡¹ | è¯´æ˜ |
|--------|------|
| LLM å¤§æ¨¡å‹ç¿»è¯‘ | ğŸŒŸ ç¿»è¯‘è´¨é‡æœ€å¥½çš„é€‰æ‹©ã€‚ä½¿ç”¨ AI å¤§æ¨¡å‹è¿›è¡Œç¿»è¯‘,èƒ½æ›´å¥½ç†è§£ä¸Šä¸‹æ–‡,ç¿»è¯‘æ›´è‡ªç„¶ã€‚éœ€è¦åœ¨è®¾ç½®ä¸­é…ç½® LLM API(æ¯”å¦‚ OpenAIã€DeepSeek ç­‰) |
| DeepLx ç¿»è¯‘ |  ç¿»è¯‘è¾ƒå¯é ã€‚åŸºäº DeepL ç¿»è¯‘, éœ€è¦è¦é…ç½®è‡ªå·±çš„åç«¯æ¥å£ã€‚ |
| å¾®è½¯ç¿»è¯‘ | ä½¿ç”¨å¾®è½¯çš„ç¿»è¯‘æœåŠ¡, é€Ÿåº¦éå¸¸å¿« |
| è°·æ­Œç¿»è¯‘ | è°·æ­Œçš„ç¿»è¯‘æœåŠ¡,é€Ÿåº¦å¿«,ä½†éœ€è¦èƒ½è®¿é—®è°·æ­Œçš„ç½‘ç»œç¯å¢ƒ |

æ¨èä½¿ç”¨ `LLM å¤§æ¨¡å‹ç¿»è¯‘` ï¼Œç¿»è¯‘è´¨é‡æœ€å¥½ã€‚


### 3. è¯­éŸ³è¯†åˆ«æ¥å£è¯´æ˜

| æ¥å£åç§° | æ”¯æŒè¯­è¨€ | è¿è¡Œæ–¹å¼ | è¯´æ˜ |
|---------|---------|---------|------|
| Bæ¥å£ | ä»…æ”¯æŒä¸­æ–‡ã€è‹±æ–‡ | åœ¨çº¿ | å…è´¹ã€é€Ÿåº¦è¾ƒå¿« |
| Jæ¥å£ | ä»…æ”¯æŒä¸­æ–‡ã€è‹±æ–‡ | åœ¨çº¿ | å…è´¹ã€é€Ÿåº¦è¾ƒå¿« |
| WhisperCpp | ä¸­æ–‡ã€æ—¥è¯­ã€éŸ©è¯­ã€è‹±æ–‡ç­‰ 99 ç§è¯­è¨€ï¼Œå¤–è¯­æ•ˆæœè¾ƒå¥½ | æœ¬åœ° | ï¼ˆå®é™…ä½¿ç”¨ä¸ç¨³å®šï¼‰éœ€è¦ä¸‹è½½è½¬å½•æ¨¡å‹&lt;br&gt;ä¸­æ–‡å»ºè®®mediumä»¥ä¸Šæ¨¡å‹&lt;br&gt;è‹±æ–‡ç­‰ä½¿ç”¨è¾ƒå°æ¨¡å‹å³å¯è¾¾åˆ°ä¸é”™æ•ˆæœã€‚ |
| fasterWhisper ğŸ‘ | ä¸­æ–‡ã€è‹±æ–‡ç­‰å¤š99ç§è¯­è¨€ï¼Œå¤–è¯­æ•ˆæœä¼˜ç§€ï¼Œæ—¶é—´è½´æ›´å‡†ç¡® | æœ¬åœ° | ï¼ˆğŸŒŸæåŠ›æ¨èğŸŒŸï¼‰éœ€è¦ä¸‹è½½ç¨‹åºå’Œè½¬å½•æ¨¡å‹&lt;br&gt;æ”¯æŒCUDA,é€Ÿåº¦æ›´å¿«ï¼Œè½¬å½•å‡†ç¡®ã€‚&lt;br&gt;è¶…çº§å‡†ç¡®çš„æ—¶é—´æˆ³å­—å¹•ã€‚&lt;br&gt;å»ºè®®ä¼˜å…ˆä½¿ç”¨ |


### 4. æœ¬åœ° Whisper è¯­éŸ³è¯†åˆ«æ¨¡å‹

Whisper ç‰ˆæœ¬æœ‰ WhisperCpp å’Œ fasterWhisperï¼ˆæ¨èï¼‰ ä¸¤ç§ï¼Œåè€…æ•ˆæœæ›´å¥½ï¼Œéƒ½éœ€è¦è‡ªè¡Œåœ¨è½¯ä»¶å†…ä¸‹è½½æ¨¡å‹ã€‚

| æ¨¡å‹ | ç£ç›˜ç©ºé—´ | å†…å­˜å ç”¨ | è¯´æ˜ |
|------|----------|----------|------|
| Tiny | 75 MiB | ~273 MB | è½¬å½•å¾ˆä¸€èˆ¬ï¼Œä»…ç”¨äºæµ‹è¯• |
| Small | 466 MiB | ~852 MB | è‹±æ–‡è¯†åˆ«æ•ˆæœå·²ç»ä¸é”™ |
| Medium | 1.5 GiB | ~2.1 GB | ä¸­æ–‡è¯†åˆ«å»ºè®®è‡³å°‘ä½¿ç”¨æ­¤ç‰ˆæœ¬ |
| Large-v2 ğŸ‘ | 2.9 GiB | ~3.9 GB | æ•ˆæœå¥½ï¼Œé…ç½®å…è®¸æƒ…å†µæ¨èä½¿ç”¨ |
| Large-v3 | 2.9 GiB | ~3.9 GB | ç¤¾åŒºåé¦ˆå¯èƒ½ä¼šå‡ºç°å¹»è§‰/å­—å¹•é‡å¤é—®é¢˜ |

æ¨èæ¨¡å‹: `Large-v2` ç¨³å®šä¸”è´¨é‡è¾ƒå¥½ã€‚

æ³¨ï¼šä»¥ä¸Šæ¨¡å‹å›½å†…ç½‘ç»œå¯ç›´æ¥åœ¨è½¯ä»¶å†…ä¸‹è½½ã€‚


### 5. æ–‡ç¨¿åŒ¹é…

- åœ¨&quot;å­—å¹•ä¼˜åŒ–ä¸ç¿»è¯‘&quot;é¡µé¢ï¼ŒåŒ…å«&quot;æ–‡ç¨¿åŒ¹é…&quot;é€‰é¡¹ï¼Œæ”¯æŒä»¥ä¸‹**ä¸€ç§æˆ–è€…å¤šç§**å†…å®¹ï¼Œè¾…åŠ©æ ¡æ­£å­—å¹•å’Œç¿»è¯‘:

| ç±»å‹ | è¯´æ˜ | å¡«å†™ç¤ºä¾‹ |
|------|------|------|
| æœ¯è¯­è¡¨ | ä¸“ä¸šæœ¯è¯­ã€äººåã€ç‰¹å®šè¯è¯­çš„ä¿®æ­£å¯¹ç…§è¡¨ | æœºå™¨å­¦ä¹ -&gt;Machine Learning&lt;br&gt;é©¬æ–¯å…‹-&gt;Elon Musk&lt;br&gt;æ‰“call -&gt; åº”æ´&lt;br&gt;å›¾çµæ–‘å›¾&lt;br&gt;å…¬äº¤è½¦æ‚–è®º |
| åŸå­—å¹•æ–‡ç¨¿ | è§†é¢‘çš„åŸæœ‰æ–‡ç¨¿æˆ–ç›¸å…³å†…å®¹ | å®Œæ•´çš„æ¼”è®²ç¨¿ã€è¯¾ç¨‹è®²ä¹‰ç­‰ |
| ä¿®æ­£è¦æ±‚ | å†…å®¹ç›¸å…³çš„å…·ä½“ä¿®æ­£è¦æ±‚ | ç»Ÿä¸€äººç§°ä»£è¯ã€è§„èŒƒä¸“ä¸šæœ¯è¯­ç­‰&lt;br&gt;å¡«å†™**å†…å®¹ç›¸å…³**çš„è¦æ±‚å³å¯ï¼Œ[ç¤ºä¾‹å‚è€ƒ](https://github.com/WEIFENG2333/VideoCaptioner/issues/59#issuecomment-2495849752) |

- å¦‚æœéœ€è¦æ–‡ç¨¿è¿›è¡Œå­—å¹•ä¼˜åŒ–è¾…åŠ©ï¼Œå…¨æµç¨‹å¤„ç†æ—¶ï¼Œå…ˆå¡«å†™æ–‡ç¨¿ä¿¡æ¯ï¼Œå†è¿›è¡Œå¼€å§‹ä»»åŠ¡å¤„ç†
- æ³¨æ„: ä½¿ç”¨ä¸Šä¸‹æ–‡å‚æ•°é‡ä¸é«˜çš„å°å‹LLMæ¨¡å‹æ—¶ï¼Œå»ºè®®æ§åˆ¶æ–‡ç¨¿å†…å®¹åœ¨1åƒå­—å†…ï¼Œå¦‚æœä½¿ç”¨ä¸Šä¸‹æ–‡è¾ƒå¤§çš„æ¨¡å‹ï¼Œåˆ™å¯ä»¥é€‚å½“å¢åŠ æ–‡ç¨¿å†…å®¹ã€‚

æ— ç‰¹æ®Šéœ€æ±‚ï¼Œä¸€èˆ¬ä¸å¡«å†™ã€‚



### 6. Cookie é…ç½®è¯´æ˜

å¦‚æœä½¿ç”¨URLä¸‹è½½åŠŸèƒ½æ—¶ï¼Œå¦‚æœé‡åˆ°ä»¥ä¸‹æƒ…å†µ:
1. ä¸‹è½½è§†é¢‘ç½‘ç«™éœ€è¦ç™»å½•ä¿¡æ¯æ‰å¯ä»¥ä¸‹è½½ï¼›
2. åªèƒ½ä¸‹è½½è¾ƒä½åˆ†è¾¨ç‡çš„è§†é¢‘ï¼›
3. ç½‘ç»œæ¡ä»¶è¾ƒå·®æ—¶éœ€è¦éªŒè¯ï¼›

- è¯·å‚è€ƒ [Cookie é…ç½®è¯´æ˜](./docs/get_cookies.md) è·å–Cookieä¿¡æ¯ï¼Œå¹¶å°†cookies.txtæ–‡ä»¶æ”¾ç½®åˆ°è½¯ä»¶å®‰è£…ç›®å½•çš„ `AppData` ç›®å½•ä¸‹ï¼Œå³å¯æ­£å¸¸ä¸‹è½½é«˜è´¨é‡è§†é¢‘ã€‚

## ğŸ’¡ è½¯ä»¶æµç¨‹ä»‹ç»

ç¨‹åºç®€å•çš„å¤„ç†æµç¨‹å¦‚ä¸‹:
```
è¯­éŸ³è¯†åˆ«è½¬å½• -&gt; å­—å¹•æ–­å¥(å¯é€‰) -&gt; å­—å¹•ä¼˜åŒ–ç¿»è¯‘(å¯é€‰) -&gt; å­—å¹•è§†é¢‘åˆæˆ
```

## âœ¨ è½¯ä»¶ä¸»è¦åŠŸèƒ½

è½¯ä»¶åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLM)åœ¨ç†è§£ä¸Šä¸‹æ–‡æ–¹é¢çš„ä¼˜åŠ¿ï¼Œå¯¹è¯­éŸ³è¯†åˆ«ç”Ÿæˆçš„å­—å¹•è¿›ä¸€æ­¥å¤„ç†ã€‚æœ‰æ•ˆä¿®æ­£é”™åˆ«å­—ã€ç»Ÿä¸€ä¸“ä¸šæœ¯è¯­ï¼Œè®©å­—å¹•å†…å®¹æ›´åŠ å‡†ç¡®è¿è´¯ï¼Œä¸ºç”¨æˆ·å¸¦æ¥å‡ºè‰²çš„è§‚çœ‹ä½“éªŒï¼

#### 1. å¤šå¹³å°è§†é¢‘ä¸‹è½½ä¸å¤„ç†
- æ”¯æŒå›½å†…å¤–ä¸»æµè§†é¢‘å¹³å°ï¼ˆBç«™ã€Youtubeã€å°çº¢ä¹¦ã€TikTokã€Xã€è¥¿ç“œè§†é¢‘ã€æŠ–éŸ³ç­‰ï¼‰
- è‡ªåŠ¨æå–è§†é¢‘åŸæœ‰å­—å¹•å¤„ç†

#### 2. ä¸“ä¸šçš„è¯­éŸ³è¯†åˆ«å¼•æ“
- æä¾›å¤šç§æ¥å£åœ¨çº¿è¯†åˆ«ï¼Œæ•ˆæœåª²ç¾å‰ªæ˜ ï¼ˆå…è´¹ã€é«˜é€Ÿï¼‰
- æ”¯æŒæœ¬åœ°Whisperæ¨¡å‹ï¼ˆä¿æŠ¤éšç§ã€å¯ç¦»çº¿ï¼‰

#### 3. å­—å¹•æ™ºèƒ½çº é”™
- è‡ªåŠ¨ä¼˜åŒ–ä¸“ä¸šæœ¯è¯­ã€ä»£ç ç‰‡æ®µå’Œæ•°å­¦å…¬å¼æ ¼å¼
- ä¸Šä¸‹æ–‡è¿›è¡Œæ–­å¥ä¼˜åŒ–ï¼Œæå‡é˜…è¯»ä½“éªŒ
- æ”¯æŒæ–‡ç¨¿æç¤ºï¼Œä½¿ç”¨åŸæœ‰æ–‡ç¨¿æˆ–è€…ç›¸å…³æç¤ºä¼˜åŒ–å­—å¹•æ–­å¥

#### 4. é«˜è´¨é‡å­—å¹•ç¿»è¯‘
- ç»“åˆä¸Šä¸‹æ–‡çš„æ™ºèƒ½ç¿»è¯‘ï¼Œç¡®ä¿è¯‘æ–‡å…¼é¡¾å…¨æ–‡
- é€šè¿‡PromptæŒ‡å¯¼å¤§æ¨¡å‹åæ€ç¿»è¯‘ï¼Œæå‡ç¿»è¯‘è´¨é‡
- ä½¿ç”¨åºåˆ—æ¨¡ç³ŠåŒ¹é…ç®—æ³•ã€ä¿è¯æ—¶é—´è½´å®Œå…¨ä¸€è‡´

#### 5. å­—å¹•æ ·å¼è°ƒæ•´
- ä¸°å¯Œçš„å­—å¹•æ ·å¼æ¨¡æ¿ï¼ˆç§‘æ™®é£ã€æ–°é—»é£ã€ç•ªå‰§é£ç­‰ç­‰ï¼‰
- å¤šç§æ ¼å¼å­—å¹•è§†é¢‘ï¼ˆSRTã€ASSã€VTTã€TXTï¼‰

é’ˆå¯¹å°ç™½ç”¨æˆ·ï¼Œå¯¹ä¸€äº›è½¯ä»¶å†…çš„é€‰é¡¹è¯´æ˜ï¼š

#### 1. è¯­éŸ³è½¬å½•é¡µé¢

- `VADè¿‡æ»¤`ï¼šå¼€å¯åï¼ŒVADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰å°†è¿‡æ»¤æ— äººå£°çš„è¯­éŸ³ç‰‡æ®µï¼Œä»è€Œå‡å°‘å¹»è§‰ç°è±¡ã€‚å»ºè®®ä¿æŒé»˜è®¤å¼€å¯çŠ¶æ€ã€‚å¦‚æœä¸æ‡‚ï¼Œå…¶ä»–VADé€‰é¡¹å»ºè®®ç›´æ¥ä¿æŒé»˜è®¤å³å¯ã€‚

- `éŸ³é¢‘åˆ†ç¦»`ï¼šå¼€å¯åï¼Œä½¿ç”¨MDX-Netè¿›è¡Œé™å™ªå¤„ç†ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåˆ†ç¦»äººå£°å’ŒèƒŒæ™¯éŸ³ä¹ï¼Œä»è€Œæå‡éŸ³é¢‘è´¨é‡ã€‚å»ºè®®åªåœ¨å˜ˆæ‚çš„è§†é¢‘ä¸­å¼€å¯ã€‚

#### 2. å­—å¹•ä¼˜åŒ–ä¸ç¿»è¯‘é¡µé¢

- `æ™ºèƒ½æ–­å¥`ï¼šå¼€å¯åï¼Œå…¨æµç¨‹å¤„ç†æ—¶ç”Ÿæˆå­—çº§æ—¶é—´æˆ³ï¼Œç„¶åé€šè¿‡LLMå¤§æ¨¡å‹è¿›è¡Œæ–­å¥ï¼Œä»è€Œåœ¨è§†é¢‘æœ‰æ›´å®Œç¾çš„è§‚çœ‹ä½“éªŒã€‚æœ‰æŒ‰ç…§å¥å­æ–­å¥å’ŒæŒ‰ç…§è¯­ä¹‰æ–­å¥ä¸¤ç§æ¨¡å¼ã€‚å¯æ ¹æ®è‡ªå·±çš„éœ€æ±‚é…ç½®ã€‚

- `å­—å¹•æ ¡æ­£`ï¼šå¼€å¯åï¼Œä¼šé€šè¿‡LLMå¤§æ¨¡å‹å¯¹å­—å¹•å†…å®¹è¿›è¡Œæ ¡æ­£(å¦‚ï¼šè‹±æ–‡å•è¯å¤§å°å†™ã€æ ‡ç‚¹ç¬¦å·ã€é”™åˆ«å­—ã€æ•°å­¦å…¬å¼å’Œä»£ç çš„æ ¼å¼ç­‰)ï¼Œæå‡å­—å¹•çš„è´¨é‡ã€‚

- `åæ€ç¿»è¯‘`ï¼šå¼€å¯åï¼Œä¼šé€šè¿‡LLMå¤§æ¨¡å‹è¿›è¡Œåæ€ç¿»è¯‘ï¼Œæå‡ç¿»è¯‘çš„è´¨é‡ã€‚ç›¸åº”çš„ä¼šå¢åŠ è¯·æ±‚çš„æ—¶é—´å’Œæ¶ˆè€—çš„Tokenã€‚(é€‰é¡¹åœ¨ è®¾ç½®é¡µ-LLMå¤§æ¨¡å‹ç¿»è¯‘-åæ€ç¿»è¯‘ ä¸­å¼€å¯ã€‚)

- `æ–‡ç¨¿æç¤º`ï¼šå¡«å†™åï¼Œè¿™éƒ¨åˆ†ä¹Ÿå°†ä½œä¸ºæç¤ºè¯å‘é€ç»™å¤§æ¨¡å‹ï¼Œè¾…åŠ©å­—å¹•ä¼˜åŒ–å’Œç¿»è¯‘ã€‚

#### 3. å­—å¹•è§†é¢‘åˆæˆé¡µé¢

- `è§†é¢‘åˆæˆ`ï¼šå¼€å¯åï¼Œä¼šæ ¹æ®åˆæˆå­—å¹•è§†é¢‘ï¼›å…³é—­å°†è·³è¿‡è§†é¢‘åˆæˆçš„æµç¨‹ã€‚


- `è½¯å­—å¹•`ï¼šå¼€å¯åï¼Œå­—å¹•ä¸ä¼šçƒ§å½•åˆ°è§†é¢‘ä¸­ï¼Œå¤„ç†é€Ÿåº¦æå¿«ã€‚ä½†æ˜¯è½¯å­—å¹•éœ€è¦ä¸€äº›æ’­æ”¾å™¨ï¼ˆå¦‚PotPlayerï¼‰æ”¯æŒæ‰å¯ä»¥è¿›è¡Œæ˜¾ç¤ºæ’­æ”¾ã€‚è€Œä¸”è½¯å­—å¹•çš„æ ·å¼ä¸æ˜¯è½¯ä»¶å†…è°ƒæ•´çš„å­—å¹•æ ·å¼ï¼Œè€Œæ˜¯æ’­æ”¾å™¨é»˜è®¤çš„ç™½è‰²æ ·å¼ã€‚


å®‰è£…è½¯ä»¶çš„ä¸»è¦ç›®å½•ç»“æ„è¯´æ˜å¦‚ä¸‹ï¼š
```
VideoCaptioner/
â”œâ”€â”€ runtime/                    # è¿è¡Œç¯å¢ƒç›®å½•
â”œâ”€â”€ resources/               # è½¯ä»¶èµ„æºæ–‡ä»¶ç›®å½•ï¼ˆäºŒè¿›åˆ¶ç¨‹åºã€å›¾æ ‡ç­‰,ä»¥åŠä¸‹è½½çš„faster-whisperç¨‹åºï¼‰
â”œâ”€â”€ work-dir/               # å·¥ä½œç›®å½•ï¼Œå¤„ç†å®Œæˆçš„è§†é¢‘å’Œå­—å¹•æ–‡ä»¶ä¿å­˜åœ¨è¿™é‡Œ
â”œâ”€â”€ AppData/                    # åº”ç”¨æ•°æ®ç›®å½•
    â”œâ”€â”€ cache/              # ç¼“å­˜ç›®å½•ï¼Œç¼“å­˜è½¬å½•ã€å¤§æ¨¡å‹è¯·æ±‚çš„æ•°æ®ã€‚
    â”œâ”€â”€ models/              # å­˜æ”¾ Whisper æ¨¡å‹æ–‡ä»¶
    â”œâ”€â”€ logs/               # æ—¥å¿—ç›®å½•ï¼Œè®°å½•è½¯ä»¶è¿è¡ŒçŠ¶æ€
    â”œâ”€â”€ settings.json          # å­˜å‚¨ç”¨æˆ·è®¾ç½®
    â””â”€â”€  cookies.txt           # è§†é¢‘å¹³å°çš„ cookie ä¿¡æ¯ï¼ˆä¸‹è½½é«˜æ¸…è§†é¢‘æ—¶éœ€è¦ï¼‰
â””â”€â”€ VideoCaptioner.exe      # ä¸»ç¨‹åºæ‰§è¡Œæ–‡ä»¶
```

## ğŸ“ è¯´æ˜

1. å­—å¹•æ–­å¥çš„è´¨é‡å¯¹è§‚çœ‹ä½“éªŒè‡³å…³é‡è¦ã€‚è½¯ä»¶èƒ½å°†é€å­—å­—å¹•æ™ºèƒ½é‡ç»„ä¸ºç¬¦åˆè‡ªç„¶è¯­è¨€ä¹ æƒ¯çš„æ®µè½ï¼Œå¹¶ä¸è§†é¢‘ç”»é¢å®Œç¾åŒæ­¥ã€‚

2. åœ¨å¤„ç†è¿‡ç¨‹ä¸­ï¼Œä»…å‘å¤§è¯­è¨€æ¨¡å‹å‘é€æ–‡æœ¬å†…å®¹ï¼Œä¸åŒ…å«æ—¶é—´è½´ä¿¡æ¯ï¼Œè¿™å¤§å¤§é™ä½äº†å¤„ç†å¼€é”€ã€‚

3. åœ¨ç¿»è¯‘ç¯èŠ‚ï¼Œæˆ‘ä»¬é‡‡ç”¨å´æ©è¾¾æå‡ºçš„&quot;ç¿»è¯‘-åæ€-ç¿»è¯‘&quot;æ–¹æ³•è®ºã€‚è¿™ç§è¿­ä»£ä¼˜åŒ–çš„æ–¹å¼ç¡®ä¿äº†ç¿»è¯‘çš„å‡†ç¡®æ€§ã€‚

4. å¡«å…¥ YouTube é“¾æ¥æ—¶è¿›è¡Œå¤„ç†æ—¶ï¼Œä¼šè‡ªåŠ¨ä¸‹è½½è§†é¢‘çš„å­—å¹•ï¼Œä»è€Œçœå»è½¬å½•æ­¥éª¤ï¼Œæå¤§åœ°èŠ‚çœæ“ä½œæ—¶é—´ã€‚

## ğŸ¤ è´¡çŒ®æŒ‡å—

ä½œè€…æ˜¯ä¸€åå¤§ä¸‰å­¦ç”Ÿï¼Œä¸ªäººèƒ½åŠ›å’Œé¡¹ç›®éƒ½è¿˜æœ‰è®¸å¤šä¸è¶³ï¼Œé¡¹ç›®ä¹Ÿåœ¨ä¸æ–­å®Œå–„ä¸­ï¼Œå¦‚æœåœ¨ä½¿ç”¨è¿‡ç¨‹é‡åˆ°çš„Bugï¼Œæ¬¢è¿æäº¤ [Issue](https://github.com/WEIFENG2333/VideoCaptioner/issues) å’Œ Pull Request å¸®åŠ©æ”¹è¿›é¡¹ç›®ã€‚

## æ›´æ–°æ—¥å¿—

&lt;details&gt;
&lt;summary&gt;2025.02.07&lt;/summary&gt;
### Bug ä¿®å¤ä¸å…¶ä»–æ”¹è¿›
- ä¿®å¤è°·æ­Œç¿»è¯‘è¯­è¨€ä¸æ­£ç¡®çš„é—®é¢˜ã€‚
- ä¿®éƒ¨å¾®è½¯ç¿»è¯‘ä¸å‡†ç¡®çš„é—®é¢˜ã€‚
- ä¿®å¤è¿è¡Œè®¾å¤‡ä¸é€‰æ‹©cudaæ—¶æ˜¾ç¤ºæŠ¥ winErrorçš„é”™è¯¯
- ä¿®å¤åˆæˆå¤±è´¥çš„é—®é¢˜
- ä¿®å¤asså•è¯­å­—å¹•æ²¡æœ‰å†…å®¹çš„é—®é¢˜
&lt;/details&gt;


&lt;details&gt;
&lt;summary&gt;2024.2.06&lt;/summary&gt;

### æ ¸å¿ƒåŠŸèƒ½å¢å¼º
- å®Œæ•´é‡æ„ä»£ç æ¶æ„ï¼Œä¼˜åŒ–æ•´ä½“æ€§èƒ½
- å­—å¹•ä¼˜åŒ–ä¸ç¿»è¯‘åŠŸèƒ½æ¨¡å—åˆ†ç¦»ï¼Œæä¾›æ›´çµæ´»çš„å¤„ç†é€‰é¡¹
- æ–°å¢æ‰¹é‡å¤„ç†åŠŸèƒ½ï¼šæ”¯æŒæ‰¹é‡å­—å¹•ã€æ‰¹é‡è½¬å½•ã€æ‰¹é‡å­—å¹•è§†é¢‘åˆæˆ
- å…¨é¢ä¼˜åŒ– UI ç•Œé¢ä¸äº¤äº’ç»†èŠ‚

### AI æ¨¡å‹ä¸ç¿»è¯‘å‡çº§
- æ‰©å±• LLM æ”¯æŒï¼šæ–°å¢ SiliconCloudã€DeepSeekã€Ollamaã€Geminiã€ChatGLM ç­‰æ¨¡å‹
- é›†æˆå¤šç§ç¿»è¯‘æœåŠ¡ï¼šDeepLxã€Bingã€Googleã€LLM
- æ–°å¢ faster-whisper-large-v3-turbo æ¨¡å‹æ”¯æŒ
- æ–°å¢å¤šç§ VADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰æ–¹æ³•
- æ”¯æŒè‡ªå®šä¹‰åæ€ç¿»è¯‘å¼€å…³
- å­—å¹•æ–­å¥æ”¯æŒè¯­ä¹‰/å¥å­ä¸¤ç§æ¨¡å¼
- å­—å¹•æ–­å¥ã€ä¼˜åŒ–ã€ç¿»è¯‘æç¤ºè¯çš„ä¼˜åŒ–
- å­—å¹•ã€è½¬å½•ç¼“å­˜æœºåˆ¶çš„ä¼˜åŒ–
- ä¼˜åŒ–ä¸­æ–‡å­—å¹•è‡ªåŠ¨æ¢è¡ŒåŠŸèƒ½
- æ–°å¢ç«–å±å­—å¹•æ ·å¼
- æ”¹è¿›å­—å¹•æ—¶é—´è½´åˆ‡æ¢æœºåˆ¶ï¼Œæ¶ˆé™¤é—ªçƒé—®é¢˜

### Bug ä¿®å¤ä¸å…¶ä»–æ”¹è¿›
- ä¿®å¤ Whisper API æ— æ³•ä½¿ç”¨é—®é¢˜
- æ–°å¢å¤šç§å­—å¹•è§†é¢‘æ ¼å¼æ”¯æŒ
- ä¿®å¤éƒ¨åˆ†æƒ…å†µè½¬å½•é”™è¯¯çš„é—®é¢˜
- ä¼˜åŒ–è§†é¢‘å·¥ä½œç›®å½•ç»“æ„
- æ–°å¢æ—¥å¿—æŸ¥çœ‹åŠŸèƒ½
- æ–°å¢æ³°è¯­ã€å¾·è¯­ç­‰è¯­è¨€çš„å­—å¹•ä¼˜åŒ–
- ä¿®å¤è¯¸å¤šBug...

&lt;/details&gt;


&lt;details&gt;
&lt;summary&gt;2024.12.07&lt;/summary&gt;

- æ–°å¢ Faster-whisper æ”¯æŒï¼ŒéŸ³é¢‘è½¬å­—å¹•è´¨é‡æ›´ä¼˜
- æ”¯æŒVadè¯­éŸ³æ–­ç‚¹æ£€æµ‹ï¼Œå¤§å¤§å‡å°‘å¹»è§‰ç°è±¡
- æ”¯æŒäººå£°éŸ³åˆ†ç¦»ï¼Œåˆ†ç¦»è§†é¢‘èƒŒæ™¯å™ªéŸ³
- æ”¯æŒå…³é—­è§†é¢‘åˆæˆ
- æ–°å¢å­—å¹•æœ€å¤§é•¿åº¦è®¾ç½®
- æ–°å¢å­—å¹•æœ«å°¾æ ‡ç‚¹å»é™¤è®¾ç½®
- ä¼˜åŒ–å’Œç¿»è¯‘çš„æç¤ºè¯ä¼˜åŒ–
- ä¼˜åŒ–LLMå­—å¹•æ–­å¥é”™è¯¯çš„æƒ…å†µ 
- ä¿®å¤éŸ³é¢‘è½¬æ¢æ ¼å¼ä¸ä¸€è‡´é—®é¢˜

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;2024.11.23&lt;/summary&gt;

- æ–°å¢ Whisper-v3 æ¨¡å‹æ”¯æŒï¼Œå¤§å¹…æå‡è¯­éŸ³è¯†åˆ«å‡†ç¡®ç‡
- ä¼˜åŒ–å­—å¹•æ–­å¥ç®—æ³•ï¼Œæä¾›æ›´è‡ªç„¶çš„é˜…è¯»ä½“éªŒ 
- ä¿®å¤æ£€æµ‹æ¨¡å‹å¯ç”¨æ€§æ—¶çš„ç¨³å®šæ€§é—®é¢˜
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;2024.11.20&lt;/summary&gt;

- æ”¯æŒè‡ªå®šä¹‰è°ƒèŠ‚å­—å¹•ä½ç½®å’Œæ ·å¼
- æ–°å¢å­—å¹•ä¼˜åŒ–å’Œç¿»è¯‘è¿‡ç¨‹çš„å®æ—¶æ—¥å¿—æŸ¥çœ‹
- ä¿®å¤ä½¿ç”¨ API æ—¶çš„è‡ªåŠ¨ç¿»è¯‘é—®é¢˜
- ä¼˜åŒ–è§†é¢‘å·¥ä½œç›®å½•ç»“æ„,æå‡æ–‡ä»¶ç®¡ç†æ•ˆç‡
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;2024.11.17&lt;/summary&gt;

- æ”¯æŒåŒè¯­/å•è¯­å­—å¹•çµæ´»å¯¼å‡º
- æ–°å¢æ–‡ç¨¿åŒ¹é…æç¤ºå¯¹é½åŠŸèƒ½
- ä¿®å¤å­—å¹•å¯¼å…¥æ—¶çš„ç¨³å®šæ€§é—®é¢˜
- ä¿®å¤éä¸­æ–‡è·¯å¾„ä¸‹è½½æ¨¡å‹çš„å…¼å®¹æ€§é—®é¢˜
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;2024.11.13&lt;/summary&gt;

- æ–°å¢ Whisper API è°ƒç”¨æ”¯æŒ
- æ”¯æŒå¯¼å…¥ cookie.txt ä¸‹è½½å„å¤§è§†é¢‘å¹³å°èµ„æº
- å­—å¹•æ–‡ä»¶åè‡ªåŠ¨ä¸è§†é¢‘ä¿æŒä¸€è‡´
- è½¯ä»¶ä¸»é¡µæ–°å¢è¿è¡Œæ—¥å¿—å®æ—¶æŸ¥çœ‹
- ç»Ÿä¸€å’Œå®Œå–„è½¯ä»¶å†…éƒ¨åŠŸèƒ½
&lt;/details&gt;


## ğŸ’– æ”¯æŒä½œè€…

å¦‚æœè§‰å¾—é¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œå¯ä»¥ç»™é¡¹ç›®ç‚¹ä¸ªStarï¼Œè¿™å°†æ˜¯å¯¹æˆ‘æœ€å¤§çš„é¼“åŠ±å’Œæ”¯æŒï¼

&lt;details&gt;
&lt;summary&gt;æåŠ©æ”¯æŒ&lt;/summary&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/alipay.jpg&quot; alt=&quot;æ”¯ä»˜å®äºŒç»´ç &quot; width=&quot;30%&quot;&gt;
  &lt;img src=&quot;./docs/images/wechat.jpg&quot; alt=&quot;å¾®ä¿¡äºŒç»´ç &quot; width=&quot;30%&quot;&gt;
&lt;/div&gt;
&lt;/details&gt;

## â­ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=WEIFENG2333/VideoCaptioner&amp;type=Date)](https://star-history.com/#WEIFENG2333/VideoCaptioner&amp;Date)


</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[myshell-ai/OpenVoice]]></title>
            <link>https://github.com/myshell-ai/OpenVoice</link>
            <guid>https://github.com/myshell-ai/OpenVoice</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:40 GMT</pubDate>
            <description><![CDATA[Instant voice cloning by MIT and MyShell. Audio foundation model.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/myshell-ai/OpenVoice">myshell-ai/OpenVoice</a></h1>
            <p>Instant voice cloning by MIT and MyShell. Audio foundation model.</p>
            <p>Language: Python</p>
            <p>Stars: 33,365</p>
            <p>Forks: 3,551</p>
            <p>Stars today: 210 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;div&gt;&amp;nbsp;&lt;/div&gt;
  &lt;img src=&quot;resources/openvoicelogo.jpg&quot; width=&quot;400&quot;/&gt; 

[Paper](https://arxiv.org/abs/2312.01479) |
[Website](https://research.myshell.ai/open-voice) &lt;br&gt; &lt;br&gt;
&lt;a href=&quot;https://trendshift.io/repositories/6161&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/6161&quot; alt=&quot;myshell-ai%2FOpenVoice | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

## Introduction

### OpenVoice V1

As we detailed in our [paper](https://arxiv.org/abs/2312.01479) and [website](https://research.myshell.ai/open-voice), the advantages of OpenVoice are three-fold:

**1. Accurate Tone Color Cloning.**
OpenVoice can accurately clone the reference tone color and generate speech in multiple languages and accents.

**2. Flexible Voice Style Control.**
OpenVoice enables granular control over voice styles, such as emotion and accent, as well as other style parameters including rhythm, pauses, and intonation. 

**3. Zero-shot Cross-lingual Voice Cloning.**
Neither of the language of the generated speech nor the language of the reference speech needs to be presented in the massive-speaker multi-lingual training dataset.

### OpenVoice V2

In April 2024, we released OpenVoice V2, which includes all features in V1 and has:

**1. Better Audio Quality.**
OpenVoice V2 adopts a different training strategy that delivers better audio quality.

**2. Native Multi-lingual Support.**
English, Spanish, French, Chinese, Japanese and Korean are natively supported in OpenVoice V2.

**3. Free Commercial Use.**
Starting from April 2024, both V2 and V1 are released under MIT License. Free for commercial use.

[Video](https://github.com/myshell-ai/OpenVoice/assets/40556743/3cba936f-82bf-476c-9e52-09f0f417bb2f)

OpenVoice has been powering the instant voice cloning capability of [myshell.ai](https://app.myshell.ai/explore) since May 2023. Until Nov 2023, the voice cloning model has been used tens of millions of times by users worldwide, and witnessed the explosive user growth on the platform.

## Main Contributors

- [Zengyi Qin](https://www.qinzy.tech) at MIT
- [Wenliang Zhao](https://wl-zhao.github.io) at Tsinghua University
- [Xumin Yu](https://yuxumin.github.io) at Tsinghua University
- [Ethan Sun](https://twitter.com/ethan_myshell) at MyShell

## How to Use
Please see [usage](docs/USAGE.md) for detailed instructions.

## Common Issues

Please see [QA](docs/QA.md) for common questions and answers. We will regularly update the question and answer list.

## Citation
```
@article{qin2023openvoice,
  title={OpenVoice: Versatile Instant Voice Cloning},
  author={Qin, Zengyi and Zhao, Wenliang and Yu, Xumin and Sun, Xin},
  journal={arXiv preprint arXiv:2312.01479},
  year={2023}
}
```

## License
OpenVoice V1 and V2 are MIT Licensed. Free for both commercial and research use.

## Acknowledgements
This implementation is based on several excellent projects, [TTS](https://github.com/coqui-ai/TTS), [VITS](https://github.com/jaywalnut310/vits), and [VITS2](https://github.com/daniilrobnikov/vits2). Thanks for their awesome work!
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Asabeneh/30-Days-Of-Python]]></title>
            <link>https://github.com/Asabeneh/30-Days-Of-Python</link>
            <guid>https://github.com/Asabeneh/30-Days-Of-Python</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:39 GMT</pubDate>
            <description><![CDATA[30 days of Python programming challenge is a step-by-step guide to learn the Python programming language in 30 days. This challenge may take more than100 days, follow your own pace. These videos may help too: https://www.youtube.com/channel/UC7PNRuno1rzYPb1xLa4yktw]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Asabeneh/30-Days-Of-Python">Asabeneh/30-Days-Of-Python</a></h1>
            <p>30 days of Python programming challenge is a step-by-step guide to learn the Python programming language in 30 days. This challenge may take more than100 days, follow your own pace. These videos may help too: https://www.youtube.com/channel/UC7PNRuno1rzYPb1xLa4yktw</p>
            <p>Language: Python</p>
            <p>Stars: 47,826</p>
            <p>Forks: 9,129</p>
            <p>Stars today: 60 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[frappe/hrms]]></title>
            <link>https://github.com/frappe/hrms</link>
            <guid>https://github.com/frappe/hrms</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:38 GMT</pubDate>
            <description><![CDATA[Open Source HR and Payroll Software]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/frappe/hrms">frappe/hrms</a></h1>
            <p>Open Source HR and Payroll Software</p>
            <p>Language: Python</p>
            <p>Stars: 2,924</p>
            <p>Forks: 1,255</p>
            <p>Stars today: 119 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
	&lt;a href=&quot;https://frappe.io/hr&quot;&gt;
		&lt;img src=&quot;.github/frappe-hr-logo.png&quot; height=&quot;80px&quot; width=&quot;80px&quot; alt=&quot;Frappe HR Logo&quot;&gt;
	&lt;/a&gt;
	&lt;h2&gt;Frappe HR&lt;/h2&gt;
	&lt;p align=&quot;center&quot;&gt;
		&lt;p&gt;Open Source, modern, and easy-to-use HR and Payroll Software&lt;/p&gt;
	&lt;/p&gt;

[![CI](https://github.com/frappe/hrms/actions/workflows/ci.yml/badge.svg?branch=develop)](https://github.com/frappe/hrms/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/frappe/hrms/branch/develop/graph/badge.svg?token=0TwvyUg3I5)](https://codecov.io/gh/frappe/hrms)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
	&lt;img src=&quot;.github/hrms-hero.png&quot;/&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
	&lt;a href=&quot;https://frappe.io/hr&quot;&gt;Website&lt;/a&gt;
	-
	&lt;a href=&quot;https://docs.frappe.io/hr/introduction&quot;&gt;Documentation&lt;/a&gt;
&lt;/div&gt;

## Frappe HR

Frappe HR has everything you need to drive excellence within the company. It&#039;s a complete HRMS solution with over 13 different modules right from Employee Management, Onboarding, Leaves, to Payroll, Taxation, and more!

## Motivation
When Frappe team started growing in terms of size, we needed an open-source HR and Payroll software. We didn&#039;t find any &quot;true&quot; open-source HR software out there and so decided to build one ourselves.
Initially, it was a set of modules within ERPNext but version 14 onwards, as the modules became more mature, Frappe HR was created as a separate product.

## Key Features

- **Employee Lifecycle**: From onboarding employees, managing promotions and transfers, all the way to documenting feedback with exit interviews, make life easier for employees throughout their life cycle.
- **Leave and Attendance**: Configure leave policies, pull regional holidays with a click, check-in and check-out with geolocation capturing, track leave balances and attendance with reports.
- **Expense Claims and Advances**: Manage employee advances, claim expenses, configure multi-level approval workflows, all this with seamless integration with ERPNext accounting.
- **Performance Management**: Track goals, align goals with key result areas (KRAs), enable employees to evaluate themselves, make managing appraisal cycles easy.
- **Payroll &amp; Taxation**: Create salary structures, configure income tax slabs, run standard payroll, accomodate additional salaries and off cycle payments, view income breakup on salary slips and so much more.
- **Frappe HR Mobile App**: Apply for and approve leaves on the go, check-in and check-out, access employee profile right from the mobile app.

&lt;details open&gt;

&lt;summary&gt;View Screenshots&lt;/summary&gt;
	&lt;img src=&quot;.github/hrms-appraisal.png&quot;/&gt;
	&lt;img src=&quot;.github/hrms-requisition.png&quot;/&gt;
	&lt;img src=&quot;.github/hrms-attendance.png&quot;/&gt;
	&lt;img src=&quot;.github/hrms-salary.png&quot;/&gt;
	&lt;img src=&quot;.github/hrms-pwa.png&quot;/&gt;
&lt;/details&gt;

### Under the Hood

- [**Frappe Framework**](https://github.com/frappe/frappe): A full-stack web application framework written in Python and Javascript. The framework provides a robust foundation for building web applications, including a database abstraction layer, user authentication, and a REST API.

- [**Frappe UI**](https://github.com/frappe/frappe-ui): A Vue-based UI library, to provide a modern user interface. The Frappe UI library provides a variety of components that can be used to build single-page applications on top of the Frappe Framework.

## Production Setup

### Managed Hosting

You can try [Frappe Cloud](https://frappecloud.com), a simple, user-friendly and sophisticated [open-source](https://github.com/frappe/press) platform to host Frappe applications with peace of mind.

It takes care of installation, setup, upgrades, monitoring, maintenance and support of your Frappe deployments. It is a fully featured developer platform with an ability to manage and control multiple Frappe deployments.

&lt;div&gt;
	&lt;a href=&quot;https://frappecloud.com/hrms/signup&quot; target=&quot;_blank&quot;&gt;
		&lt;picture&gt;
			&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://frappe.io/files/try-on-fc-white.png&quot;&gt;
			&lt;img src=&quot;https://frappe.io/files/try-on-fc-black.png&quot; alt=&quot;Try on Frappe Cloud&quot; height=&quot;28&quot; /&gt;
		&lt;/picture&gt;
	&lt;/a&gt;
&lt;/div&gt;


## Development setup
### Docker
You need Docker, docker-compose and git setup on your machine. Refer [Docker documentation](https://docs.docker.com/). After that, run the following commands:
```
git clone https://github.com/frappe/hrms
cd hrms/docker
docker-compose up
```

Wait for some time until the setup script creates a site. After that you can access `http://localhost:8000` in your browser and the login screen for HR should show up.

Use the following credentials to log in:

- Username: `Administrator`
- Password: `admin`

### Local

1. Set up bench by following the [Installation Steps](https://frappeframework.com/docs/user/en/installation) and start the server and keep it running
	```sh
	$ bench start
	```
2. In a separate terminal window, run the following commands
	```sh
	$ bench new-site hrms.local
	$ bench get-app erpnext
	$ bench get-app hrms
	$ bench --site hrms.local install-app hrms
	$ bench --site hrms.local add-to-hosts
	```
3. You can access the site at `http://hrms.local:8080`

## Learning and Community

1. [Frappe School](https://frappe.school) - Learn Frappe Framework and ERPNext from the various courses by the maintainers or from the community.
2. [Documentation](https://docs.frappe.io/hr) - Extensive documentation for Frappe HR.
3. [User Forum](https://discuss.erpnext.com/) - Engage with the community of ERPNext users and service providers.
4. [Telegram Group](https://t.me/frappehr) - Get instant help from the community of users.


## Contributing

1. [Issue Guidelines](https://github.com/frappe/erpnext/wiki/Issue-Guidelines)
1. [Report Security Vulnerabilities](https://erpnext.com/security)
1. [Pull Request Requirements](https://github.com/frappe/erpnext/wiki/Contribution-Guidelines)


## Logo and Trademark Policy

Please read our [Logo and Trademark Policy](TRADEMARK_POLICY.md).

&lt;br /&gt;
&lt;br /&gt;
&lt;div align=&quot;center&quot; style=&quot;padding-top: 0.75rem;&quot;&gt;
	&lt;a href=&quot;https://frappe.io&quot; target=&quot;_blank&quot;&gt;
		&lt;picture&gt;
			&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://frappe.io/files/Frappe-white.png&quot;&gt;
			&lt;img src=&quot;https://frappe.io/files/Frappe-black.png&quot; alt=&quot;Frappe Technologies&quot; height=&quot;28&quot;/&gt;
		&lt;/picture&gt;
	&lt;/a&gt;
&lt;/div&gt;

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[virattt/ai-hedge-fund]]></title>
            <link>https://github.com/virattt/ai-hedge-fund</link>
            <guid>https://github.com/virattt/ai-hedge-fund</guid>
            <pubDate>Wed, 23 Jul 2025 00:04:37 GMT</pubDate>
            <description><![CDATA[An AI Hedge Fund Team]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/virattt/ai-hedge-fund">virattt/ai-hedge-fund</a></h1>
            <p>An AI Hedge Fund Team</p>
            <p>Language: Python</p>
            <p>Stars: 38,379</p>
            <p>Forks: 6,758</p>
            <p>Stars today: 54 stars today</p>
            <h2>README</h2><pre># AI Hedge Fund

This is a proof of concept for an AI-powered hedge fund.  The goal of this project is to explore the use of AI to make trading decisions.  This project is for **educational** purposes only and is not intended for real trading or investment.

This system employs several agents working together:

1. Aswath Damodaran Agent - The Dean of Valuation, focuses on story, numbers, and disciplined valuation
2. Ben Graham Agent - The godfather of value investing, only buys hidden gems with a margin of safety
3. Bill Ackman Agent - An activist investor, takes bold positions and pushes for change
4. Cathie Wood Agent - The queen of growth investing, believes in the power of innovation and disruption
5. Charlie Munger Agent - Warren Buffett&#039;s partner, only buys wonderful businesses at fair prices
6. Michael Burry Agent - The Big Short contrarian who hunts for deep value
7. Peter Lynch Agent - Practical investor who seeks &quot;ten-baggers&quot; in everyday businesses
8. Phil Fisher Agent - Meticulous growth investor who uses deep &quot;scuttlebutt&quot; research 
9. Rakesh Jhunjhunwala Agent - The Big Bull of India
10. Stanley Druckenmiller Agent - Macro legend who hunts for asymmetric opportunities with growth potential
11. Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price
12. Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals
13. Sentiment Agent - Analyzes market sentiment and generates trading signals
14. Fundamentals Agent - Analyzes fundamental data and generates trading signals
15. Technicals Agent - Analyzes technical indicators and generates trading signals
16. Risk Manager - Calculates risk metrics and sets position limits
17. Portfolio Manager - Makes final trading decisions and generates orders

&lt;img width=&quot;1042&quot; alt=&quot;Screenshot 2025-03-22 at 6 19 07 PM&quot; src=&quot;https://github.com/user-attachments/assets/cbae3dcf-b571-490d-b0ad-3f0f035ac0d4&quot; /&gt;

Note: the system does not actually make any trades.

[![Twitter Follow](https://img.shields.io/twitter/follow/virattt?style=social)](https://twitter.com/virattt)

## Disclaimer

This project is for **educational and research purposes only**.

- Not intended for real trading or investment
- No investment advice or guarantees provided
- Creator assumes no liability for financial losses
- Consult a financial advisor for investment decisions
- Past performance does not indicate future results

By using this software, you agree to use it solely for learning purposes.

## Table of Contents
- [How to Install](#how-to-install)
- [How to Run](#how-to-run)
  - [âŒ¨ï¸ Command Line Interface](#ï¸-command-line-interface)
  - [ğŸ–¥ï¸ Web Application (NEW!)](#ï¸-web-application)
- [Contributing](#contributing)
- [Feature Requests](#feature-requests)
- [License](#license)

## How to Install

Before you can run the AI Hedge Fund, you&#039;ll need to install it and set up your API keys. These steps are common to both the full-stack web application and command line interface.

### 1. Clone the Repository

```bash
git clone https://github.com/virattt/ai-hedge-fund.git
cd ai-hedge-fund
```

### 2. Set Up Your API Keys

Create a `.env` file for your API keys:
```bash
# Create .env file for your API keys (in the root directory)
cp .env.example .env
```

Open and edit the `.env` file to add your API keys:
```bash
# For running LLMs hosted by openai (gpt-4o, gpt-4o-mini, etc.)
OPENAI_API_KEY=your-openai-api-key

# For running LLMs hosted by groq (deepseek, llama3, etc.)
GROQ_API_KEY=your-groq-api-key

# For getting financial data to power the hedge fund
FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key
```

**Important**: You must set at least one LLM API key (`OPENAI_API_KEY`, `GROQ_API_KEY`, `ANTHROPIC_API_KEY`, or `DEEPSEEK_API_KEY`) for the hedge fund to work. 

**Financial Data**: Data for AAPL, GOOGL, MSFT, NVDA, and TSLA is free and does not require an API key. For any other ticker, you will need to set the `FINANCIAL_DATASETS_API_KEY` in the .env file.

## How to Run

### âŒ¨ï¸ Command Line Interface

For users who prefer working with command line tools, you can run the AI Hedge Fund directly via terminal. This approach offers more granular control and is useful for automation, scripting, and integration purposes.

&lt;img width=&quot;992&quot; alt=&quot;Screenshot 2025-01-06 at 5 50 17 PM&quot; src=&quot;https://github.com/user-attachments/assets/e8ca04bf-9989-4a7d-a8b4-34e04666663b&quot; /&gt;

Choose one of the following installation methods:

#### Using Poetry

1. Install Poetry (if not already installed):
```bash
curl -sSL https://install.python-poetry.org | python3 -
```

2. Install dependencies:
```bash
poetry install
```

#### Using Docker

1. Make sure you have Docker installed on your system. If not, you can download it from [Docker&#039;s official website](https://www.docker.com/get-started).

2. Navigate to the docker directory:
```bash
cd docker
```

3. Build the Docker image:
```bash
# On Linux/Mac:
./run.sh build

# On Windows:
run.bat build
```

#### Running the AI Hedge Fund (with Poetry)
```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA
```

#### Running the AI Hedge Fund (with Docker)
```bash
# Navigate to the docker directory first
cd docker

# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA main

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA main
```

You can also specify a `--ollama` flag to run the AI hedge fund using local LLMs.

```bash
# With Poetry:
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --ollama

# With Docker (from docker/ directory):
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA --ollama main

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA --ollama main
```

You can also specify a `--show-reasoning` flag to print the reasoning of each agent to the console.

```bash
# With Poetry:
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --show-reasoning

# With Docker (from docker/ directory):
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA --show-reasoning main

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA --show-reasoning main
```

You can optionally specify the start and end dates to make decisions for a specific time period.

```bash
# With Poetry:
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 

# With Docker (from docker/ directory):
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 main

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 main
```

#### Running the Backtester (with Poetry)
```bash
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA
```

#### Running the Backtester (with Docker)
```bash
# Navigate to the docker directory first
cd docker

# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA backtest

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA backtest
```

**Example Output:**
&lt;img width=&quot;941&quot; alt=&quot;Screenshot 2025-01-06 at 5 47 52 PM&quot; src=&quot;https://github.com/user-attachments/assets/00e794ea-8628-44e6-9a84-8f8a31ad3b47&quot; /&gt;


You can optionally specify the start and end dates to backtest over a specific time period.

```bash
# With Poetry:
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01

# With Docker (from docker/ directory):
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 backtest

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 backtest
```

You can also specify a `--ollama` flag to run the backtester using local LLMs.
```bash
# With Poetry:
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA --ollama

# With Docker (from docker/ directory):
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA --ollama backtest

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA --ollama backtest
```

### ğŸ–¥ï¸ Web Application

The new way to run the AI Hedge Fund is through our web application that provides a user-friendly interface. **This is recommended for most users, especially those who prefer visual interfaces over command line tools.**

&lt;img width=&quot;1721&quot; alt=&quot;Screenshot 2025-06-28 at 6 41 03â€¯PM&quot; src=&quot;https://github.com/user-attachments/assets/b95ab696-c9f4-416c-9ad1-51feb1f5374b&quot; /&gt;

#### For Mac/Linux:
```bash
cd app &amp;&amp; ./run.sh
```

If you get a &quot;permission denied&quot; error, run this first:
```bash
cd app &amp;&amp; chmod +x run.sh &amp;&amp; ./run.sh
```

#### For Windows:
```bash
# Go to /app directory
cd app

# Run the app
\.run.bat
```

**That&#039;s it!** These scripts will:
1. Check for required dependencies (Node.js, Python, Poetry)
2. Install all dependencies automatically  
3. Start both frontend and backend services
4. **Automatically open your web browser** to the application


#### Detailed Setup Instructions

For detailed setup instructions, troubleshooting, and advanced configuration options, see:
- [Full-Stack App Documentation](./app/README.md)
- [Frontend Documentation](./app/frontend/README.md)  
- [Backend Documentation](./app/backend/README.md)


## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

**Important**: Please keep your pull requests small and focused.  This will make it easier to review and merge.

## Feature Requests

If you have a feature request, please open an [issue](https://github.com/virattt/ai-hedge-fund/issues) and make sure it is tagged with `enhancement`.

## License

This project is licensed under the MIT License - see the LICENSE file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>