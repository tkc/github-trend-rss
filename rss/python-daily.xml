<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Tue, 16 Sep 2025 00:04:30 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[microsoft/markitdown]]></title>
            <link>https://github.com/microsoft/markitdown</link>
            <guid>https://github.com/microsoft/markitdown</guid>
            <pubDate>Tue, 16 Sep 2025 00:04:30 GMT</pubDate>
            <description><![CDATA[Python tool for converting files and office documents to Markdown.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/markitdown">microsoft/markitdown</a></h1>
            <p>Python tool for converting files and office documents to Markdown.</p>
            <p>Language: Python</p>
            <p>Stars: 74,339</p>
            <p>Forks: 4,129</p>
            <p>Stars today: 756 stars today</p>
            <h2>README</h2><pre># MarkItDown

[![PyPI](https://img.shields.io/pypi/v/markitdown.svg)](https://pypi.org/project/markitdown/)
![PyPI - Downloads](https://img.shields.io/pypi/dd/markitdown)
[![Built by AutoGen Team](https://img.shields.io/badge/Built%20by-AutoGen%20Team-blue)](https://github.com/microsoft/autogen)

&gt; [!TIP]
&gt; MarkItDown now offers an MCP (Model Context Protocol) server for integration with LLM applications like Claude Desktop. See [markitdown-mcp](https://github.com/microsoft/markitdown/tree/main/packages/markitdown-mcp) for more information.

&gt; [!IMPORTANT]
&gt; Breaking changes between 0.0.1 to 0.1.0:
&gt; * Dependencies are now organized into optional feature-groups (further details below). Use `pip install &#039;markitdown[all]&#039;` to have backward-compatible behavior. 
&gt; * convert\_stream() now requires a binary file-like object (e.g., a file opened in binary mode, or an io.BytesIO object). This is a breaking change from the previous version, where it previously also accepted text file-like objects, like io.StringIO.
&gt; * The DocumentConverter class interface has changed to read from file-like streams rather than file paths. *No temporary files are created anymore*. If you are the maintainer of a plugin, or custom DocumentConverter, you likely need to update your code. Otherwise, if only using the MarkItDown class or CLI (as in these examples), you should not need to change anything.

MarkItDown is a lightweight Python utility for converting various files to Markdown for use with LLMs and related text analysis pipelines. To this end, it is most comparable to [textract](https://github.com/deanmalmgren/textract), but with a focus on preserving important document structure and content as Markdown (including: headings, lists, tables, links, etc.) While the output is often reasonably presentable and human-friendly, it is meant to be consumed by text analysis tools -- and may not be the best option for high-fidelity document conversions for human consumption.

MarkItDown currently supports the conversion from:

- PDF
- PowerPoint
- Word
- Excel
- Images (EXIF metadata and OCR)
- Audio (EXIF metadata and speech transcription)
- HTML
- Text-based formats (CSV, JSON, XML)
- ZIP files (iterates over contents)
- Youtube URLs
- EPubs
- ... and more!

## Why Markdown?

Markdown is extremely close to plain text, with minimal markup or formatting, but still
provides a way to represent important document structure. Mainstream LLMs, such as
OpenAI&#039;s GPT-4o, natively &quot;_speak_&quot; Markdown, and often incorporate Markdown into their
responses unprompted. This suggests that they have been trained on vast amounts of
Markdown-formatted text, and understand it well. As a side benefit, Markdown conventions
are also highly token-efficient.

## Prerequisites
MarkItDown requires Python 3.10 or higher. It is recommended to use a virtual environment to avoid dependency conflicts.

With the standard Python installation, you can create and activate a virtual environment using the following commands:

```bash
python -m venv .venv
source .venv/bin/activate
```

If using `uv`, you can create a virtual environment with:

```bash
uv venv --python=3.12 .venv
source .venv/bin/activate
# NOTE: Be sure to use &#039;uv pip install&#039; rather than just &#039;pip install&#039; to install packages in this virtual environment
```

If you are using Anaconda, you can create a virtual environment with:

```bash
conda create -n markitdown python=3.12
conda activate markitdown
```

## Installation

To install MarkItDown, use pip: `pip install &#039;markitdown[all]&#039;`. Alternatively, you can install it from the source:

```bash
git clone git@github.com:microsoft/markitdown.git
cd markitdown
pip install -e &#039;packages/markitdown[all]&#039;
```

## Usage

### Command-Line

```bash
markitdown path-to-file.pdf &gt; document.md
```

Or use `-o` to specify the output file:

```bash
markitdown path-to-file.pdf -o document.md
```

You can also pipe content:

```bash
cat path-to-file.pdf | markitdown
```

### Optional Dependencies
MarkItDown has optional dependencies for activating various file formats. Earlier in this document, we installed all optional dependencies with the `[all]` option. However, you can also install them individually for more control. For example:

```bash
pip install &#039;markitdown[pdf, docx, pptx]&#039;
```

will install only the dependencies for PDF, DOCX, and PPTX files.

At the moment, the following optional dependencies are available:

* `[all]` Installs all optional dependencies
* `[pptx]` Installs dependencies for PowerPoint files
* `[docx]` Installs dependencies for Word files
* `[xlsx]` Installs dependencies for Excel files
* `[xls]` Installs dependencies for older Excel files
* `[pdf]` Installs dependencies for PDF files
* `[outlook]` Installs dependencies for Outlook messages
* `[az-doc-intel]` Installs dependencies for Azure Document Intelligence
* `[audio-transcription]` Installs dependencies for audio transcription of wav and mp3 files
* `[youtube-transcription]` Installs dependencies for fetching YouTube video transcription

### Plugins

MarkItDown also supports 3rd-party plugins. Plugins are disabled by default. To list installed plugins:

```bash
markitdown --list-plugins
```

To enable plugins use:

```bash
markitdown --use-plugins path-to-file.pdf
```

To find available plugins, search GitHub for the hashtag `#markitdown-plugin`. To develop a plugin, see `packages/markitdown-sample-plugin`.

### Azure Document Intelligence

To use Microsoft Document Intelligence for conversion:

```bash
markitdown path-to-file.pdf -o document.md -d -e &quot;&lt;document_intelligence_endpoint&gt;&quot;
```

More information about how to set up an Azure Document Intelligence Resource can be found [here](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/create-document-intelligence-resource?view=doc-intel-4.0.0)

### Python API

Basic usage in Python:

```python
from markitdown import MarkItDown

md = MarkItDown(enable_plugins=False) # Set to True to enable plugins
result = md.convert(&quot;test.xlsx&quot;)
print(result.text_content)
```

Document Intelligence conversion in Python:

```python
from markitdown import MarkItDown

md = MarkItDown(docintel_endpoint=&quot;&lt;document_intelligence_endpoint&gt;&quot;)
result = md.convert(&quot;test.pdf&quot;)
print(result.text_content)
```

To use Large Language Models for image descriptions (currently only for pptx and image files), provide `llm_client` and `llm_model`:

```python
from markitdown import MarkItDown
from openai import OpenAI

client = OpenAI()
md = MarkItDown(llm_client=client, llm_model=&quot;gpt-4o&quot;, llm_prompt=&quot;optional custom prompt&quot;)
result = md.convert(&quot;example.jpg&quot;)
print(result.text_content)
```

### Docker

```sh
docker build -t markitdown:latest .
docker run --rm -i markitdown:latest &lt; ~/your-file.pdf &gt; output.md
```

## Contributing

This project welcomes contributions and suggestions. Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

### How to Contribute

You can help by looking at issues or helping review PRs. Any issue or PR is welcome, but we have also marked some as &#039;open for contribution&#039; and &#039;open for reviewing&#039; to help facilitate community contributions. These are of course just suggestions and you are welcome to contribute in any way you like.

&lt;div align=&quot;center&quot;&gt;

|            | All                                                          | Especially Needs Help from Community                                                                                                      |
| ---------- | ------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------- |
| **Issues** | [All Issues](https://github.com/microsoft/markitdown/issues) | [Issues open for contribution](https://github.com/microsoft/markitdown/issues?q=is%3Aissue+is%3Aopen+label%3A%22open+for+contribution%22) |
| **PRs**    | [All PRs](https://github.com/microsoft/markitdown/pulls)     | [PRs open for reviewing](https://github.com/microsoft/markitdown/pulls?q=is%3Apr+is%3Aopen+label%3A%22open+for+reviewing%22)              |

&lt;/div&gt;

### Running Tests and Checks

- Navigate to the MarkItDown package:

  ```sh
  cd packages/markitdown
  ```

- Install `hatch` in your environment and run tests:

  ```sh
  pip install hatch  # Other ways of installing hatch: https://hatch.pypa.io/dev/install/
  hatch shell
  hatch test
  ```

  (Alternative) Use the Devcontainer which has all the dependencies installed:

  ```sh
  # Reopen the project in Devcontainer and run:
  hatch test
  ```

- Run pre-commit checks before submitting a PR: `pre-commit run --all-files`

### Contributing 3rd-party Plugins

You can also contribute by creating and sharing 3rd party plugins. See `packages/markitdown-sample-plugin` for more details.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
trademarks or logos is subject to and must follow
[Microsoft&#039;s Trademark &amp; Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party&#039;s policies.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[virattt/ai-hedge-fund]]></title>
            <link>https://github.com/virattt/ai-hedge-fund</link>
            <guid>https://github.com/virattt/ai-hedge-fund</guid>
            <pubDate>Tue, 16 Sep 2025 00:04:29 GMT</pubDate>
            <description><![CDATA[An AI Hedge Fund Team]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/virattt/ai-hedge-fund">virattt/ai-hedge-fund</a></h1>
            <p>An AI Hedge Fund Team</p>
            <p>Language: Python</p>
            <p>Stars: 40,336</p>
            <p>Forks: 7,120</p>
            <p>Stars today: 132 stars today</p>
            <h2>README</h2><pre># AI Hedge Fund

This is a proof of concept for an AI-powered hedge fund.  The goal of this project is to explore the use of AI to make trading decisions.  This project is for **educational** purposes only and is not intended for real trading or investment.

This system employs several agents working together:

1. Aswath Damodaran Agent - The Dean of Valuation, focuses on story, numbers, and disciplined valuation
2. Ben Graham Agent - The godfather of value investing, only buys hidden gems with a margin of safety
3. Bill Ackman Agent - An activist investor, takes bold positions and pushes for change
4. Cathie Wood Agent - The queen of growth investing, believes in the power of innovation and disruption
5. Charlie Munger Agent - Warren Buffett&#039;s partner, only buys wonderful businesses at fair prices
6. Michael Burry Agent - The Big Short contrarian who hunts for deep value
7. Mohnish Pabrai Agent - The Dhandho investor, who looks for doubles at low risk
8. Peter Lynch Agent - Practical investor who seeks &quot;ten-baggers&quot; in everyday businesses
9. Phil Fisher Agent - Meticulous growth investor who uses deep &quot;scuttlebutt&quot; research 
10. Rakesh Jhunjhunwala Agent - The Big Bull of India
11. Stanley Druckenmiller Agent - Macro legend who hunts for asymmetric opportunities with growth potential
12. Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price
13. Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals
14. Sentiment Agent - Analyzes market sentiment and generates trading signals
15. Fundamentals Agent - Analyzes fundamental data and generates trading signals
16. Technicals Agent - Analyzes technical indicators and generates trading signals
17. Risk Manager - Calculates risk metrics and sets position limits
18. Portfolio Manager - Makes final trading decisions and generates orders

&lt;img width=&quot;1042&quot; alt=&quot;Screenshot 2025-03-22 at 6 19 07 PM&quot; src=&quot;https://github.com/user-attachments/assets/cbae3dcf-b571-490d-b0ad-3f0f035ac0d4&quot; /&gt;

Note: the system does not actually make any trades.

[![Twitter Follow](https://img.shields.io/twitter/follow/virattt?style=social)](https://twitter.com/virattt)

## Disclaimer

This project is for **educational and research purposes only**.

- Not intended for real trading or investment
- No investment advice or guarantees provided
- Creator assumes no liability for financial losses
- Consult a financial advisor for investment decisions
- Past performance does not indicate future results

By using this software, you agree to use it solely for learning purposes.

## Table of Contents
- [How to Install](#how-to-install)
- [How to Run](#how-to-run)
  - [‚å®Ô∏è Command Line Interface](#Ô∏è-command-line-interface)
  - [üñ•Ô∏è Web Application](#Ô∏è-web-application)
- [How to Contribute](#how-to-contribute)
- [Feature Requests](#feature-requests)
- [License](#license)

## How to Install

Before you can run the AI Hedge Fund, you&#039;ll need to install it and set up your API keys. These steps are common to both the full-stack web application and command line interface.

### 1. Clone the Repository

```bash
git clone https://github.com/virattt/ai-hedge-fund.git
cd ai-hedge-fund
```

### 2. Set up API keys

Create a `.env` file for your API keys:
```bash
# Create .env file for your API keys (in the root directory)
cp .env.example .env
```

Open and edit the `.env` file to add your API keys:
```bash
# For running LLMs hosted by openai (gpt-4o, gpt-4o-mini, etc.)
OPENAI_API_KEY=your-openai-api-key

# For getting financial data to power the hedge fund
FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key
```

**Important**: You must set at least one LLM API key (e.g. `OPENAI_API_KEY`, `GROQ_API_KEY`, `ANTHROPIC_API_KEY`, or `DEEPSEEK_API_KEY`) for the hedge fund to work. 

**Financial Data**: Data for AAPL, GOOGL, MSFT, NVDA, and TSLA is free and does not require an API key. For any other ticker, you will need to set the `FINANCIAL_DATASETS_API_KEY` in the .env file.

## How to Run

### ‚å®Ô∏è Command Line Interface

You can run the AI Hedge Fund directly via terminal. This approach offers more granular control and is useful for automation, scripting, and integration purposes.

&lt;img width=&quot;992&quot; alt=&quot;Screenshot 2025-01-06 at 5 50 17 PM&quot; src=&quot;https://github.com/user-attachments/assets/e8ca04bf-9989-4a7d-a8b4-34e04666663b&quot; /&gt;

#### Quick Start

1. Install Poetry (if not already installed):
```bash
curl -sSL https://install.python-poetry.org | python3 -
```

2. Install dependencies:
```bash
poetry install
```

#### Run the AI Hedge Fund
```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA
```

You can also specify a `--ollama` flag to run the AI hedge fund using local LLMs.

```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --ollama
```

You can optionally specify the start and end dates to make decisions over a specific time period.

```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01
```

#### Run the Backtester
```bash
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA
```

**Example Output:**
&lt;img width=&quot;941&quot; alt=&quot;Screenshot 2025-01-06 at 5 47 52 PM&quot; src=&quot;https://github.com/user-attachments/assets/00e794ea-8628-44e6-9a84-8f8a31ad3b47&quot; /&gt;


Note: The `--ollama`, `--start-date`, and `--end-date` flags work for the backtester, as well!

### üñ•Ô∏è Web Application

The new way to run the AI Hedge Fund is through our web application that provides a user-friendly interface. This is recommended for users who prefer visual interfaces over command line tools.

Please see detailed instructions on how to install and run the web application [here](https://github.com/virattt/ai-hedge-fund/tree/main/app).

&lt;img width=&quot;1721&quot; alt=&quot;Screenshot 2025-06-28 at 6 41 03‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/b95ab696-c9f4-416c-9ad1-51feb1f5374b&quot; /&gt;


## How to Contribute

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

**Important**: Please keep your pull requests small and focused.  This will make it easier to review and merge.

## Feature Requests

If you have a feature request, please open an [issue](https://github.com/virattt/ai-hedge-fund/issues) and make sure it is tagged with `enhancement`.

## License

This project is licensed under the MIT License - see the LICENSE file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[ccxt/ccxt]]></title>
            <link>https://github.com/ccxt/ccxt</link>
            <guid>https://github.com/ccxt/ccxt</guid>
            <pubDate>Tue, 16 Sep 2025 00:04:28 GMT</pubDate>
            <description><![CDATA[A cryptocurrency trading API with more than 100 exchanges in JavaScript / TypeScript / Python / C# / PHP / Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ccxt/ccxt">ccxt/ccxt</a></h1>
            <p>A cryptocurrency trading API with more than 100 exchanges in JavaScript / TypeScript / Python / C# / PHP / Go</p>
            <p>Language: Python</p>
            <p>Stars: 38,441</p>
            <p>Forks: 8,183</p>
            <p>Stars today: 239 stars today</p>
            <h2>README</h2><pre># CCXT ‚Äì CryptoCurrency eXchange Trading Library

[![NPM Downloads](https://img.shields.io/npm/dy/ccxt.svg)](https://www.npmjs.com/package/ccxt) [![npm](https://img.shields.io/npm/v/ccxt.svg)](https://npmjs.com/package/ccxt) [![PyPI](https://img.shields.io/pypi/v/ccxt.svg)](https://pypi.python.org/pypi/ccxt) [![NuGet version](https://img.shields.io/nuget/v/ccxt)](https://www.nuget.org/packages/ccxt) [![GoDoc](https://pkg.go.dev/badge/github.com/ccxt/ccxt/go/v4?utm_source=godoc)](https://godoc.org/github.com/ccxt/ccxt/go/v4) [![Discord](https://img.shields.io/discord/690203284119617602?logo=discord&amp;logoColor=white)](https://discord.gg/ccxt) [![Supported Exchanges](https://img.shields.io/badge/exchanges-105-blue.svg)](https://github.com/ccxt/ccxt/wiki/Exchange-Markets) [![Follow CCXT at x.com](https://img.shields.io/twitter/follow/ccxt_official.svg?style=social&amp;label=CCXT)](https://x.com/ccxt_official)

A cryptocurrency trading API with more than 100 exchanges in JavaScript / TypeScript / Python / C# / PHP / Go.

### [Install](#install) ¬∑ [Usage](#usage) ¬∑ [Manual](https://github.com/ccxt/ccxt/wiki) ¬∑ [FAQ](https://github.com/ccxt/ccxt/wiki/FAQ) ¬∑ [Examples](https://github.com/ccxt/ccxt/tree/master/examples) ¬∑ [Contributing](https://github.com/ccxt/ccxt/blob/master/CONTRIBUTING.md) ¬∑ [Disclaimer](#disclaimer) ¬∑ [Social](#social)

The **CCXT** library is used to connect and trade with cryptocurrency exchanges and payment processing services worldwide. It provides quick access to market data for storage, analysis, visualization, indicator development, algorithmic trading, strategy backtesting, bot programming, and related software engineering.

It is intended to be used by **coders, developers, technically-skilled traders, data-scientists and financial analysts** for building trading algorithms.

Current feature list:

- support for many cryptocurrency exchanges ‚Äî more coming soon
- fully implemented public and private APIs
- optional normalized data for cross-exchange analytics and arbitrage
- an out of the box unified API that is extremely easy to integrate
- works in Node 10.4+, Python 3, PHP 8.1+, netstandard2.0/2.1, Go 1.20+ and web browsers

## See Also

- &lt;sub&gt;[![TabTrader](https://user-images.githubusercontent.com/1294454/66755907-9c3e8880-eea1-11e9-846e-0bff349ceb87.png)](https://tab-trader.com/?utm_source=ccxt)&lt;/sub&gt; **[TabTrader](https://tab-trader.com/?utm_source=ccxt)** ‚Äì trading on all exchanges in one app. Available on **[Android](https://play.google.com/store/apps/details?id=com.tabtrader.android&amp;referrer=utm_source%3Dccxt)** and **[iOS](https://itunes.apple.com/app/apple-store/id1095716562?mt=8)**!
- &lt;sub&gt;[![Freqtrade](https://user-images.githubusercontent.com/1294454/114340585-8e35fa80-9b60-11eb-860f-4379125e2db6.png)](https://www.freqtrade.io)&lt;/sub&gt; **[Freqtrade](https://www.freqtrade.io)** ‚Äì leading opensource cryptocurrency algorithmic trading software!
- &lt;sub&gt;[![OctoBot](https://user-images.githubusercontent.com/1294454/132113722-007fc092-7530-4b41-b929-b8ed380b7b2e.png)](https://www.octobot.online)&lt;/sub&gt; **[OctoBot](https://www.octobot.online)** ‚Äì cryptocurrency trading bot with an advanced web interface.
- &lt;sub&gt;[![TokenBot](https://user-images.githubusercontent.com/1294454/152720975-0522b803-70f0-4f18-a305-3c99b37cd990.png)](https://tokenbot.com/?utm_source=github&amp;utm_medium=ccxt&amp;utm_campaign=algodevs)&lt;/sub&gt; **[TokenBot](https://tokenbot.com/?utm_source=github&amp;utm_medium=ccxt&amp;utm_campaign=algodevs)** ‚Äì discover and copy the best algorithmic traders in the world.

## Certified Cryptocurrency Exchanges


|logo                                                                                                                                                                         |id             |name                                                                                     |ver                                                                                                                               |type                                                                                                    |certified                                                                                                                    |pro                                                                           |discount                                                                                                                                                                                                          |
|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|-----------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------:|--------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------:|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [![binance](https://github.com/user-attachments/assets/e9419b93-ccb0-46aa-9bff-c883f096274b)](https://accounts.binance.com/en/register?ref=D7YA7CLY)                        | binance       | [Binance](https://accounts.binance.com/en/register?ref=D7YA7CLY)                        | [![API Version *](https://img.shields.io/badge/*-lightgray)](https://developers.binance.com/en)                                  | ![CEX ‚Äì Centralized EXchange](https://img.shields.io/badge/CEX-green.svg &quot;CEX ‚Äì Centralized EXchange&quot;) | [![CCXT Certified](https://img.shields.io/badge/CCXT-Certified-green.svg)](https://github.com/ccxt/ccxt/wiki/Certification) | [![CCXT Pro](https://img.shields.io/badge/CCXT-Pro-black)](https://ccxt.pro) | [![Sign up with Binance using CCXT&#039;s referral link for a 10% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d10%25&amp;color=orange)](https://accounts.binance.com/en/register?ref=D7YA7CLY)        |
| [![binanceusdm](https://github.com/user-attachments/assets/871cbea7-eebb-4b28-b260-c1c91df0487a)](https://accounts.binance.com/en/register?ref=D7YA7CLY)                    | binanceusdm   | [Binance USD‚ìà-M](https://accounts.binance.com/en/register?ref=D7YA7CLY)                 | [![API Version *](https://img.shields.io/badge/*-lightgray)](https://binance-docs.github.io/apidocs/futures/en/)                 | ![CEX ‚Äì Centralized EXchange](https://img.shields.io/badge/CEX-green.svg &quot;CEX ‚Äì Centralized EXchange&quot;) | [![CCXT Certified](https://img.shields.io/badge/CCXT-Certified-green.svg)](https://github.com/ccxt/ccxt/wiki/Certification) | [![CCXT Pro](https://img.shields.io/badge/CCXT-Pro-black)](https://ccxt.pro) | [![Sign up with Binance USD‚ìà-M using CCXT&#039;s referral link for a 10% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d10%25&amp;color=orange)](https://accounts.binance.com/en/register?ref=D7YA7CLY) |
| [![binancecoinm](https://github.com/user-attachments/assets/387cfc4e-5f33-48cd-8f5c-cd4854dabf0c)](https://accounts.binance.com/en/register?ref=D7YA7CLY)                   | binancecoinm  | [Binance COIN-M](https://accounts.binance.com/en/register?ref=D7YA7CLY)                 | [![API Version *](https://img.shields.io/badge/*-lightgray)](https://binance-docs.github.io/apidocs/delivery/en/)                | ![CEX ‚Äì Centralized EXchange](https://img.shields.io/badge/CEX-green.svg &quot;CEX ‚Äì Centralized EXchange&quot;) | [![CCXT Certified](https://img.shields.io/badge/CCXT-Certified-green.svg)](https://github.com/ccxt/ccxt/wiki/Certification) | [![CCXT Pro](https://img.shields.io/badge/CCXT-Pro-black)](https://ccxt.pro) | [![Sign up with Binance COIN-M using CCXT&#039;s referral link for a 10% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d10%25&amp;color=orange)](https://accounts.binance.com/en/register?ref=D7YA7CLY) |
| [![bybit](https://github.com/user-attachments/assets/97a5d0b3-de10-423d-90e1-6620960025ed)](https://www.bybit.com/register?affiliate_id=35953)                              | bybit         | [Bybit](https://www.bybit.com/register?affiliate_id=35953)                              | [![API Version 5](https://img.shields.io/badge/5-lightgray)](https://bybit-exchange.github.io/docs/inverse/)                     | ![CEX ‚Äì Centralized EXchange](https://img.shields.io/badge/CEX-green.svg &quot;CEX ‚Äì Centralized EXchange&quot;) | [![CCXT Certified](https://img.shields.io/badge/CCXT-Certified-green.svg)](https://github.com/ccxt/ccxt/wiki/Certification) | [![CCXT Pro](https://img.shields.io/badge/CCXT-Pro-black)](https://ccxt.pro) |                                                                                                                                                                                                                  |
| [![okx](https://user-images.githubusercontent.com/1294454/152485636-38b19e4a-bece-4dec-979a-5982859ffc04.jpg)](https://www.okx.com/join/CCXT2023)                           | okx           | [OKX](https://www.okx.com/join/CCXT2023)                                                | [![API Version 5](https://img.shields.io/badge/5-lightgray)](https://www.okx.com/docs-v5/en/)                                    | ![CEX ‚Äì Centralized EXchange](https://img.shields.io/badge/CEX-green.svg &quot;CEX ‚Äì Centralized EXchange&quot;) | [![CCXT Certified](https://img.shields.io/badge/CCXT-Certified-green.svg)](https://github.com/ccxt/ccxt/wiki/Certification) | [![CCXT Pro](https://img.shields.io/badge/CCXT-Pro-black)](https://ccxt.pro) | [![Sign up with OKX using CCXT&#039;s referral link for a 20% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d20%25&amp;color=orange)](https://www.okx.com/join/CCXT2023)                                |
| [![gate](https://github.com/user-attachments/assets/64f988c5-07b6-4652-b5c1-679a6bf67c85)](https://www.gate.io/signup/2436035)                                              | gate          | [Gate.io](https://www.gate.io/signup/2436035)                                           | [![API Version 4](https://img.shields.io/badge/4-lightgray)](https://www.gate.io/docs/developers/apiv4/en/)                      | ![CEX ‚Äì Centralized EXchange](https://img.shields.io/badge/CEX-green.svg &quot;CEX ‚Äì Centralized EXchange&quot;) | [![CCXT Certified](https://img.shields.io/badge/CCXT-Certified-green.svg)](https://github.com/ccxt/ccxt/wiki/Certification) | [![CCXT Pro](https://img.shields.io/badge/CCXT-Pro-black)](https://ccxt.pro) | [![Sign up with Gate.io using CCXT&#039;s referral link for a 20% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d20%25&amp;color=orange)](https://www.gate.io/signup/2436035)                           |
| [![kucoin](https://user-images.githubusercontent.com/51840849/87295558-132aaf80-c50e-11ea-9801-a2fb0c57c799.jpg)](https://www.kucoin.com/ucenter/signup?rcode=E5wkqe)       | kucoin        | [KuCoin](https://www.kucoin.com/ucenter/signup?rcode=E5wkqe)                            | [![API Version 2](https://img.shields.io/badge/2-lightgray)](https://docs.kucoin.com)                                            | ![CEX ‚Äì Centralized EXchange](https://img.shields.io/badge/CEX-green.svg &quot;CEX ‚Äì Centralized EXchange&quot;) | [![CCXT Certified](https://img.shields.io/badge/CCXT-Certified-green.svg)](https://github.com/ccxt/ccxt/wiki/Certification) | [![CCXT Pro](https://img.shields.io/badge/CCXT-Pro-black)](https://ccxt.pro) |                                                                                                                                                                                                                  |
| [![kucoinfutures](https://user-images.githubusercontent.com/1294454/147508995-9e35030a-d046-43a1-a006-6fabd981b554.jpg)](https://futures.kucoin.com/?rcode=E5wkqe)          | kucoinfutures | [KuCoin Futures](https://futures.kucoin.com/?rcode=E5wkqe)                              | [![API Version 1](https://img.shields.io/badge/1-lightgray)](https://docs.kucoin.com/futures)                                    | ![CEX ‚Äì Centralized EXchange](https://img.shields.io/badge/CEX-green.svg &quot;CEX ‚Äì Centralized EXchange&quot;) | [![CCXT Certified](https://img.shields.io/badge/CCXT-Certified-green.svg)](https://github.com/ccxt/ccxt/wiki/Certification) | [![CCXT Pro](https://img.shields.io/badge/CCXT-Pro-black)](https://ccxt.pro) |                                                                                                                                                                                                                  |
| [![bitget](https://github.com/user-attachments/assets/fbaa10cc-a277-441d-a5b7-997dd9a87658)](https://www.bitget.com/expressly?languageType=0&amp;channelCode=ccxt&amp;vipCode=tg9j) | bitget        | [Bitget](https://www.bitget.com/expressly?languageType=0&amp;channelCode=ccxt&amp;vipCode=tg9j) | [![API Version 2](https://img.shields.io/badge/2-lightgray)](https://www.bitget.com/api-doc/common/intro)                        | ![CEX ‚Äì Centralized EXchange](https://img.shields.io/badge/CEX-green.svg &quot;CEX ‚Äì Centralized EXchange&quot;) | [![CCXT Certified](https://img.shields.io/badge/CCXT-Certified-green.svg)](https://github.com/ccxt/ccxt/wiki/Certification) | [![CCXT Pro](https://img.shields.io/badge/CCXT-Pro-black)](https://ccxt.pro) |                                                                                                                                                                                                                  |
| [![hyperliquid](https://github.com/ccxt/ccxt/assets/43336371/b371bc6c-4a8c-489f-87f4-20a913dd8d4b)](https://app.hyperliquid.xyz/)                                           | hyperliquid   | [Hyperliquid](https://app.hyperliquid.xyz/)                                             | [![API Version 1](https://img.shields.io/badge/1-lightgray)](https://hyperliquid.gitbook.io/hyperliquid-docs/for-developers/api) | ![DEX - Distributed EXchange](https://img.shields.io/badge/DEX-blue.svg &quot;DEX - Distributed EXchange&quot;)  | [![CCXT Certified](https://img.shields.io/badge/CCXT-Certified-green.svg)](https://github.com/ccxt/ccxt/wiki/Certification) | [![CCXT Pro](https://img.shields.io/badge/CCXT-Pro-black)](https://ccxt.pro) |                                                                                                                                                                                                                  |
| [![bitmex](https://github.com/user-attachments/assets/c78425ab-78d5-49d6-bd14-db7734798f04)](https://www.bitmex.com/app/register/NZTR1q)                                    | bitmex        | [BitMEX](https://www.bitmex.com/app/register/NZTR1q)                                    | [![API Version 1](https://img.shields.io/badge/1-lightgray)](https://www.bitmex.com/app/apiOverview)                             | ![CEX ‚Äì Centralized EXchange](https://img.shields.io/badge/CEX-green.svg &quot;CEX ‚Äì Centralized EXchange&quot;) | [![CCXT Certified](https://img.shields.io/badge/CCXT-Certified-green.svg)](https://github.com/ccxt/ccxt/wiki/Certification) | [![CCXT Pro](https://img.shields.io/badge/CCXT-Pro-black)](https://ccxt.pro) | [![Sign up with BitMEX using CCXT&#039;s referral link for a 10% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d10%25&amp;color=orange)](https://www.bitmex.com/app/register/NZTR1q)                    |
| [![bingx](https://github-production-user-asset-6210df.s3.amazonaws.com/1294454/253675376-6983b72e-4999-4549-b177-33b374c195e3.jpg)](https://bingx.com/invite/OHETOM)        | bingx         | [BingX](https://bingx.com/invite/OHETOM)                                                | [![API Version 1](https://img.shields.io/badge/1-lightgray)](https://bingx-api.github.io/docs/)                                  | ![CEX ‚Äì Centralized EXchange](https://img.shields.io/badge/CEX-green.svg &quot;CEX ‚Äì Centralized EXchange&quot;) | [![CCXT Certified](https://img.shields.io/badge/CCXT-Certified-green.svg)](https://github.com/ccxt/ccxt/wiki/Certification) | [![CCXT Pro](https://img.shields.io/badge/CCXT-Pro-black)](https://ccxt.pro) |                                                                                                                                                                                                                  |
| [![htx](https://user-images.githubusercontent.com/1294454/76137448-22748a80-604e-11ea-8069-6e389271911d.jpg)](https://www.htx.com.vc/invite/en-us/1h?invite_code=6rmm2223)  | htx           | [HTX](https://www.htx.com.vc/invite/en-us/1h?invite_code=6rmm2223)                      | [![API Version 1](https://img.shields.io/badge/1-lightgray)](https://huobiapi.github.io/docs/spot/v1/en/)                        | ![CEX ‚Äì Centralized EXchange](https://img.shields.io/badge/CEX-green.svg &quot;CEX ‚Äì Centralized EXchange&quot;) | [![CCXT Certified](https://img.shields.io/badge/CCXT-Certified-green.svg)](https://github.com/ccxt/ccxt/wiki/Certification) | [![CCXT Pro](https://img.shields.io/badge/CCXT-Pro-black)](https://ccxt.pro) | [![Sign up with HTX using CCXT&#039;s referral link for a 15% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d15%25&amp;color=orange)](https://www.htx.com.vc/invite/en-us/1h?invite_code=6rmm2223)      |
| [![mexc](https://user-images.githubusercontent.com/1294454/137283979-8b2a818d-8633-461b-bfca-de89e8c446b2.jpg)](https://www.mexc.com/register?inviteCode=mexc-1FQ1GNu1)     | mexc          | [MEXC Global](https://www.mexc.com/register?inviteCode=mexc-1FQ1GNu1)                   | [![API Version 3](https://img.shields.io/badge/3-lightgray)](https://mexcdevelop.github.io/apidocs/)                             | ![CEX ‚Äì Centralized EXchange](https://img.shields.io/badge/CEX-green.svg &quot;CEX ‚Äì Centralized EXchange&quot;) | [![CCXT Certified](https://img.shields.io/badge/CCXT-Certified-green.svg)](https://github.com/ccxt/ccxt/wiki/Certification) | [![CCXT Pro](https://img.shields.io/badge/CCXT-Pro-black)](https://ccxt.pro) |                                                                                                                                                                                                                  |
| [![bitmart](https://github.com/user-attachments/assets/0623e9c4-f50e-48c9-82bd-65c3908c3a14)](http://www.bitmart.com/?r=rQCFLh)                                             | bitmart       | [BitMart](http://www.bitmart.com/?r=rQCFLh)                                             | [![API Version 2](https://img.shields.io/badge/2-lightgray)](https://developer-pro.bitmart.com/)                                 | ![CEX ‚Äì Centralized EXchange](https://img.shields.io/badge/CEX-green.svg &quot;CEX ‚Äì Centralized EXchange&quot;) | [![CCXT Certified](https://img.shields.io/badge/CCXT-Certified-green.svg)](https://github.com/ccxt/ccxt/wiki/Certification) | [![CCXT Pro](https://img.shields.io/badge/CCXT-Pro-black)](https://ccxt.pro) | [![Sign up with BitMart using CCXT&#039;s referral link for a 30% discount!](https://img.shields.io/static/v1?label=Fee&amp;message=%2d30%25&amp;color=orange)](http://www.bitmart.com/?r=rQCFLh)                             |
| [![cryptocom](https://user-images.githubusercontent.com/1294454/147792121-38ed5e36-c229-48d6-b49a-48d05fc19ed4.jpeg)](https://crypto.com/exch/kdacthrnxt)                   | cryptocom     | [Crypto.com](https://crypto.com/exch/kdacthrnxt)                                        | [![API Version 2](https://img.shields.io/badge/2-lightgray)](https://exchange-docs.crypto.com/exchange/v1/rest-ws/index.html)    | ![CEX ‚Äì Centralized EXchange](https://img.shields.io/badge/CEX-green.svg &quot;CEX ‚Äì Centralized EXchange&quot;) | [![CCXT Certifie

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[unclecode/crawl4ai]]></title>
            <link>https://github.com/unclecode/crawl4ai</link>
            <guid>https://github.com/unclecode/crawl4ai</guid>
            <pubDate>Tue, 16 Sep 2025 00:04:27 GMT</pubDate>
            <description><![CDATA[üöÄü§ñ Crawl4AI: Open-source LLM Friendly Web Crawler & Scraper. Don't be shy, join here: https://discord.gg/jP8KfhDhyN]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/unclecode/crawl4ai">unclecode/crawl4ai</a></h1>
            <p>üöÄü§ñ Crawl4AI: Open-source LLM Friendly Web Crawler & Scraper. Don't be shy, join here: https://discord.gg/jP8KfhDhyN</p>
            <p>Language: Python</p>
            <p>Stars: 53,238</p>
            <p>Forks: 5,299</p>
            <p>Stars today: 289 stars today</p>
            <h2>README</h2><pre># üöÄü§ñ Crawl4AI: Open-source LLM Friendly Web Crawler &amp; Scraper.

&lt;div align=&quot;center&quot;&gt;

&lt;a href=&quot;https://trendshift.io/repositories/11716&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/11716&quot; alt=&quot;unclecode%2Fcrawl4ai | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

[![GitHub Stars](https://img.shields.io/github/stars/unclecode/crawl4ai?style=social)](https://github.com/unclecode/crawl4ai/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/unclecode/crawl4ai?style=social)](https://github.com/unclecode/crawl4ai/network/members)

[![PyPI version](https://badge.fury.io/py/crawl4ai.svg)](https://badge.fury.io/py/crawl4ai)
[![Python Version](https://img.shields.io/pypi/pyversions/crawl4ai)](https://pypi.org/project/crawl4ai/)
[![Downloads](https://static.pepy.tech/badge/crawl4ai/month)](https://pepy.tech/project/crawl4ai)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/unclecode?style=flat&amp;logo=GitHub-Sponsors&amp;label=Sponsors&amp;color=pink)](https://github.com/sponsors/unclecode)

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://x.com/crawl4ai&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Follow%20on%20X-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white&quot; alt=&quot;Follow on X&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://www.linkedin.com/company/crawl4ai&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Follow%20on%20LinkedIn-0077B5?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white&quot; alt=&quot;Follow on LinkedIn&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/jP8KfhDhyN&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Join%20our%20Discord-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;Join our Discord&quot; /&gt;
    &lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

Crawl4AI turns the web into clean, LLM ready Markdown for RAG, agents, and data pipelines. Fast, controllable, battle tested by a 50k+ star community.

[‚ú® Check out latest update v0.7.4](#-recent-updates)

‚ú® New in v0.7.4: Revolutionary LLM Table Extraction with intelligent chunking, enhanced concurrency fixes, memory management refactor, and critical stability improvements. [Release notes ‚Üí](https://github.com/unclecode/crawl4ai/blob/main/docs/blog/release-v0.7.4.md)

‚ú® Recent v0.7.3: Undetected Browser Support, Multi-URL Configurations, Memory Monitoring, Enhanced Table Extraction, GitHub Sponsors. [Release notes ‚Üí](https://github.com/unclecode/crawl4ai/blob/main/docs/blog/release-v0.7.3.md)

&lt;details&gt;
  &lt;summary&gt;ü§ì &lt;strong&gt;My Personal Story&lt;/strong&gt;&lt;/summary&gt;

I grew up on an Amstrad, thanks to my dad, and never stopped building. In grad school I specialized in NLP and built crawlers for research. That‚Äôs where I learned how much extraction matters.

In 2023, I needed web-to-Markdown. The ‚Äúopen source‚Äù option wanted an account, API token, and $16, and still under-delivered. I went turbo anger mode, built Crawl4AI in days, and it went viral. Now it‚Äôs the most-starred crawler on GitHub.

I made it open source for **availability**, anyone can use it without a gate. Now I‚Äôm building the platform for **affordability**, anyone can run serious crawls without breaking the bank. If that resonates, join in, send feedback, or just crawl something amazing.
&lt;/details&gt;


&lt;details&gt;
  &lt;summary&gt;Why developers pick Crawl4AI&lt;/summary&gt;

- **LLM ready output**, smart Markdown with headings, tables, code, citation hints
- **Fast in practice**, async browser pool, caching, minimal hops
- **Full control**, sessions, proxies, cookies, user scripts, hooks
- **Adaptive intelligence**, learns site patterns, explores only what matters
- **Deploy anywhere**, zero keys, CLI and Docker, cloud friendly
&lt;/details&gt;


## üöÄ Quick Start 

1. Install Crawl4AI:
```bash
# Install the package
pip install -U crawl4ai

# For pre release versions
pip install crawl4ai --pre

# Run post-installation setup
crawl4ai-setup

# Verify your installation
crawl4ai-doctor
```

If you encounter any browser-related issues, you can install them manually:
```bash
python -m playwright install --with-deps chromium
```

2. Run a simple web crawl with Python:
```python
import asyncio
from crawl4ai import *

async def main():
    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(
            url=&quot;https://www.nbcnews.com/business&quot;,
        )
        print(result.markdown)

if __name__ == &quot;__main__&quot;:
    asyncio.run(main())
```

3. Or use the new command-line interface:
```bash
# Basic crawl with markdown output
crwl https://www.nbcnews.com/business -o markdown

# Deep crawl with BFS strategy, max 10 pages
crwl https://docs.crawl4ai.com --deep-crawl bfs --max-pages 10

# Use LLM extraction with a specific question
crwl https://www.example.com/products -q &quot;Extract all product prices&quot;
```

## üíñ Support Crawl4AI

&gt; üéâ **Sponsorship Program Now Open!** After powering 51K+ developers and 1 year of growth, Crawl4AI is launching dedicated support for **startups** and **enterprises**. Be among the first 50 **Founding Sponsors** for permanent recognition in our Hall of Fame.

Crawl4AI is the #1 trending open-source web crawler on GitHub. Your support keeps it independent, innovative, and free for the community ‚Äî while giving you direct access to premium benefits.

&lt;div align=&quot;&quot;&gt;
  
[![Become a Sponsor](https://img.shields.io/badge/Become%20a%20Sponsor-pink?style=for-the-badge&amp;logo=github-sponsors&amp;logoColor=white)](https://github.com/sponsors/unclecode)  
[![Current Sponsors](https://img.shields.io/github/sponsors/unclecode?style=for-the-badge&amp;logo=github&amp;label=Current%20Sponsors&amp;color=green)](https://github.com/sponsors/unclecode)

&lt;/div&gt;

### ü§ù Sponsorship Tiers

- **üå± Believer ($5/mo)** ‚Äî Join the movement for data democratization  
- **üöÄ Builder ($50/mo)** ‚Äî Priority support &amp; early access to features  
- **üíº Growing Team ($500/mo)** ‚Äî Bi-weekly syncs &amp; optimization help  
- **üè¢ Data Infrastructure Partner ($2000/mo)** ‚Äî Full partnership with dedicated support  
  *Custom arrangements available - see [SPONSORS.md](SPONSORS.md) for details &amp; contact*

**Why sponsor?**  
No rate-limited APIs. No lock-in. Build and own your data pipeline with direct guidance from the creator of Crawl4AI.

[See All Tiers &amp; Benefits ‚Üí](https://github.com/sponsors/unclecode)


## ‚ú® Features 

&lt;details&gt;
&lt;summary&gt;üìù &lt;strong&gt;Markdown Generation&lt;/strong&gt;&lt;/summary&gt;

- üßπ **Clean Markdown**: Generates clean, structured Markdown with accurate formatting.
- üéØ **Fit Markdown**: Heuristic-based filtering to remove noise and irrelevant parts for AI-friendly processing.
- üîó **Citations and References**: Converts page links into a numbered reference list with clean citations.
- üõ†Ô∏è **Custom Strategies**: Users can create their own Markdown generation strategies tailored to specific needs.
- üìö **BM25 Algorithm**: Employs BM25-based filtering for extracting core information and removing irrelevant content. 
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üìä &lt;strong&gt;Structured Data Extraction&lt;/strong&gt;&lt;/summary&gt;

- ü§ñ **LLM-Driven Extraction**: Supports all LLMs (open-source and proprietary) for structured data extraction.
- üß± **Chunking Strategies**: Implements chunking (topic-based, regex, sentence-level) for targeted content processing.
- üåå **Cosine Similarity**: Find relevant content chunks based on user queries for semantic extraction.
- üîé **CSS-Based Extraction**: Fast schema-based data extraction using XPath and CSS selectors.
- üîß **Schema Definition**: Define custom schemas for extracting structured JSON from repetitive patterns.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üåê &lt;strong&gt;Browser Integration&lt;/strong&gt;&lt;/summary&gt;

- üñ•Ô∏è **Managed Browser**: Use user-owned browsers with full control, avoiding bot detection.
- üîÑ **Remote Browser Control**: Connect to Chrome Developer Tools Protocol for remote, large-scale data extraction.
- üë§ **Browser Profiler**: Create and manage persistent profiles with saved authentication states, cookies, and settings.
- üîí **Session Management**: Preserve browser states and reuse them for multi-step crawling.
- üß© **Proxy Support**: Seamlessly connect to proxies with authentication for secure access.
- ‚öôÔ∏è **Full Browser Control**: Modify headers, cookies, user agents, and more for tailored crawling setups.
- üåç **Multi-Browser Support**: Compatible with Chromium, Firefox, and WebKit.
- üìê **Dynamic Viewport Adjustment**: Automatically adjusts the browser viewport to match page content, ensuring complete rendering and capturing of all elements.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üîé &lt;strong&gt;Crawling &amp; Scraping&lt;/strong&gt;&lt;/summary&gt;

- üñºÔ∏è **Media Support**: Extract images, audio, videos, and responsive image formats like `srcset` and `picture`.
- üöÄ **Dynamic Crawling**: Execute JS and wait for async or sync for dynamic content extraction.
- üì∏ **Screenshots**: Capture page screenshots during crawling for debugging or analysis.
- üìÇ **Raw Data Crawling**: Directly process raw HTML (`raw:`) or local files (`file://`).
- üîó **Comprehensive Link Extraction**: Extracts internal, external links, and embedded iframe content.
- üõ†Ô∏è **Customizable Hooks**: Define hooks at every step to customize crawling behavior.
- üíæ **Caching**: Cache data for improved speed and to avoid redundant fetches.
- üìÑ **Metadata Extraction**: Retrieve structured metadata from web pages.
- üì° **IFrame Content Extraction**: Seamless extraction from embedded iframe content.
- üïµÔ∏è **Lazy Load Handling**: Waits for images to fully load, ensuring no content is missed due to lazy loading.
- üîÑ **Full-Page Scanning**: Simulates scrolling to load and capture all dynamic content, perfect for infinite scroll pages.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üöÄ &lt;strong&gt;Deployment&lt;/strong&gt;&lt;/summary&gt;

- üê≥ **Dockerized Setup**: Optimized Docker image with FastAPI server for easy deployment.
- üîë **Secure Authentication**: Built-in JWT token authentication for API security.
- üîÑ **API Gateway**: One-click deployment with secure token authentication for API-based workflows.
- üåê **Scalable Architecture**: Designed for mass-scale production and optimized server performance.
- ‚òÅÔ∏è **Cloud Deployment**: Ready-to-deploy configurations for major cloud platforms.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üéØ &lt;strong&gt;Additional Features&lt;/strong&gt;&lt;/summary&gt;

- üï∂Ô∏è **Stealth Mode**: Avoid bot detection by mimicking real users.
- üè∑Ô∏è **Tag-Based Content Extraction**: Refine crawling based on custom tags, headers, or metadata.
- üîó **Link Analysis**: Extract and analyze all links for detailed data exploration.
- üõ°Ô∏è **Error Handling**: Robust error management for seamless execution.
- üîê **CORS &amp; Static Serving**: Supports filesystem-based caching and cross-origin requests.
- üìñ **Clear Documentation**: Simplified and updated guides for onboarding and advanced usage.
- üôå **Community Recognition**: Acknowledges contributors and pull requests for transparency.

&lt;/details&gt;

## Try it Now!

‚ú® Play around with this [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1SgRPrByQLzjRfwoRNq1wSGE9nYY_EE8C?usp=sharing)

‚ú® Visit our [Documentation Website](https://docs.crawl4ai.com/)

## Installation üõ†Ô∏è

Crawl4AI offers flexible installation options to suit various use cases. You can install it as a Python package or use Docker.

&lt;details&gt;
&lt;summary&gt;üêç &lt;strong&gt;Using pip&lt;/strong&gt;&lt;/summary&gt;

Choose the installation option that best fits your needs:

### Basic Installation

For basic web crawling and scraping tasks:

```bash
pip install crawl4ai
crawl4ai-setup # Setup the browser
```

By default, this will install the asynchronous version of Crawl4AI, using Playwright for web crawling.

üëâ **Note**: When you install Crawl4AI, the `crawl4ai-setup` should automatically install and set up Playwright. However, if you encounter any Playwright-related errors, you can manually install it using one of these methods:

1. Through the command line:

   ```bash
   playwright install
   ```

2. If the above doesn&#039;t work, try this more specific command:

   ```bash
   python -m playwright install chromium
   ```

This second method has proven to be more reliable in some cases.

---

### Installation with Synchronous Version

The sync version is deprecated and will be removed in future versions. If you need the synchronous version using Selenium:

```bash
pip install crawl4ai[sync]
```

---

### Development Installation

For contributors who plan to modify the source code:

```bash
git clone https://github.com/unclecode/crawl4ai.git
cd crawl4ai
pip install -e .                    # Basic installation in editable mode
```

Install optional features:

```bash
pip install -e &quot;.[torch]&quot;           # With PyTorch features
pip install -e &quot;.[transformer]&quot;     # With Transformer features
pip install -e &quot;.[cosine]&quot;          # With cosine similarity features
pip install -e &quot;.[sync]&quot;            # With synchronous crawling (Selenium)
pip install -e &quot;.[all]&quot;             # Install all optional features
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üê≥ &lt;strong&gt;Docker Deployment&lt;/strong&gt;&lt;/summary&gt;

&gt; üöÄ **Now Available!** Our completely redesigned Docker implementation is here! This new solution makes deployment more efficient and seamless than ever.

### New Docker Features

The new Docker implementation includes:
- **Browser pooling** with page pre-warming for faster response times
- **Interactive playground** to test and generate request code
- **MCP integration** for direct connection to AI tools like Claude Code
- **Comprehensive API endpoints** including HTML extraction, screenshots, PDF generation, and JavaScript execution
- **Multi-architecture support** with automatic detection (AMD64/ARM64)
- **Optimized resources** with improved memory management

### Getting Started

```bash
# Pull and run the latest release candidate
docker pull unclecode/crawl4ai:0.7.0
docker run -d -p 11235:11235 --name crawl4ai --shm-size=1g unclecode/crawl4ai:0.7.0

# Visit the playground at http://localhost:11235/playground
```

### Quick Test

Run a quick test (works for both Docker options):

```python
import requests

# Submit a crawl job
response = requests.post(
    &quot;http://localhost:11235/crawl&quot;,
    json={&quot;urls&quot;: [&quot;https://example.com&quot;], &quot;priority&quot;: 10}
)
if response.status_code == 200:
    print(&quot;Crawl job submitted successfully.&quot;)
    
if &quot;results&quot; in response.json():
    results = response.json()[&quot;results&quot;]
    print(&quot;Crawl job completed. Results:&quot;)
    for result in results:
        print(result)
else:
    task_id = response.json()[&quot;task_id&quot;]
    print(f&quot;Crawl job submitted. Task ID:: {task_id}&quot;)
    result = requests.get(f&quot;http://localhost:11235/task/{task_id}&quot;)
```

For more examples, see our [Docker Examples](https://github.com/unclecode/crawl4ai/blob/main/docs/examples/docker_example.py). For advanced configuration, environment variables, and usage examples, see our [Docker Deployment Guide](https://docs.crawl4ai.com/basic/docker-deployment/).

&lt;/details&gt;

---

## üî¨ Advanced Usage Examples üî¨

You can check the project structure in the directory [docs/examples](https://github.com/unclecode/crawl4ai/tree/main/docs/examples). Over there, you can find a variety of examples; here, some popular examples are shared.

&lt;details&gt;
&lt;summary&gt;üìù &lt;strong&gt;Heuristic Markdown Generation with Clean and Fit Markdown&lt;/strong&gt;&lt;/summary&gt;

```python
import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode
from crawl4ai.content_filter_strategy import PruningContentFilter, BM25ContentFilter
from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator

async def main():
    browser_config = BrowserConfig(
        headless=True,  
        verbose=True,
    )
    run_config = CrawlerRunConfig(
        cache_mode=CacheMode.ENABLED,
        markdown_generator=DefaultMarkdownGenerator(
            content_filter=PruningContentFilter(threshold=0.48, threshold_type=&quot;fixed&quot;, min_word_threshold=0)
        ),
        # markdown_generator=DefaultMarkdownGenerator(
        #     content_filter=BM25ContentFilter(user_query=&quot;WHEN_WE_FOCUS_BASED_ON_A_USER_QUERY&quot;, bm25_threshold=1.0)
        # ),
    )
    
    async with AsyncWebCrawler(config=browser_config) as crawler:
        result = await crawler.arun(
            url=&quot;https://docs.micronaut.io/4.7.6/guide/&quot;,
            config=run_config
        )
        print(len(result.markdown.raw_markdown))
        print(len(result.markdown.fit_markdown))

if __name__ == &quot;__main__&quot;:
    asyncio.run(main())
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üñ•Ô∏è &lt;strong&gt;Executing JavaScript &amp; Extract Structured Data without LLMs&lt;/strong&gt;&lt;/summary&gt;

```python
import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode
from crawl4ai import JsonCssExtractionStrategy
import json

async def main():
    schema = {
    &quot;name&quot;: &quot;KidoCode Courses&quot;,
    &quot;baseSelector&quot;: &quot;section.charge-methodology .w-tab-content &gt; div&quot;,
    &quot;fields&quot;: [
        {
            &quot;name&quot;: &quot;section_title&quot;,
            &quot;selector&quot;: &quot;h3.heading-50&quot;,
            &quot;type&quot;: &quot;text&quot;,
        },
        {
            &quot;name&quot;: &quot;section_description&quot;,
            &quot;selector&quot;: &quot;.charge-content&quot;,
            &quot;type&quot;: &quot;text&quot;,
        },
        {
            &quot;name&quot;: &quot;course_name&quot;,
            &quot;selector&quot;: &quot;.text-block-93&quot;,
            &quot;type&quot;: &quot;text&quot;,
        },
        {
            &quot;name&quot;: &quot;course_description&quot;,
            &quot;selector&quot;: &quot;.course-content-text&quot;,
            &quot;type&quot;: &quot;text&quot;,
        },
        {
            &quot;name&quot;: &quot;course_icon&quot;,
            &quot;selector&quot;: &quot;.image-92&quot;,
            &quot;type&quot;: &quot;attribute&quot;,
            &quot;attribute&quot;: &quot;src&quot;
        }
    }
}

    extraction_strategy = JsonCssExtractionStrategy(schema, verbose=True)

    browser_config = BrowserConfig(
        headless=False,
        verbose=True
    )
    run_config = CrawlerRunConfig(
        extraction_strategy=extraction_strategy,
        js_code=[&quot;&quot;&quot;(async () =&gt; {const tabs = document.querySelectorAll(&quot;section.charge-methodology .tabs-menu-3 &gt; div&quot;);for(let tab of tabs) {tab.scrollIntoView();tab.click();await new Promise(r =&gt; setTimeout(r, 500));}})();&quot;&quot;&quot;],
        cache_mode=CacheMode.BYPASS
    )
        
    async with AsyncWebCrawler(config=browser_config) as crawler:
        
        result = await crawler.arun(
            url=&quot;https://www.kidocode.com/degrees/technology&quot;,
            config=run_config
        )

        companies = json.loads(result.extracted_content)
        print(f&quot;Successfully extracted {len(companies)} companies&quot;)
        print(json.dumps(companies[0], indent=2))


if __name__ == &quot;__main__&quot;:
    asyncio.run(main())
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üìö &lt;strong&gt;Extracting Structured Data with LLMs&lt;/strong&gt;&lt;/summary&gt;

```python
import os
import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode, LLMConfig
from crawl4ai import LLMExtractionStrategy
from pydantic import BaseModel, Field

class OpenAIModelFee(BaseModel):
    model_name: str = Field(..., description=&quot;Name of the OpenAI model.&quot;)
    input_fee: str = Field(..., description=&quot;Fee for input token for the OpenAI model.&quot;)
    output_fee: str = Field(..., description=&quot;Fee for output token for the OpenAI model.&quot;)

async def main():
    browser_config = BrowserConfig(verbose=True)
    run_config = CrawlerRunConfig(
        word_count_threshold=1,
        extraction_strategy=LLMExtractionStrategy(
            # Here you can use any provider that Litellm library supports, for instance: ollama/qwen2
            # provider=&quot;ollama/qwen2&quot;, api_token=&quot;no-token&quot;, 
            llm_config = LLMConfig(provider=&quot;openai/gpt-4o&quot;, api_token=os.getenv(&#039;OPENAI_API_KEY&#039;)), 
            schema=OpenAIModelFee.schema(),
            extraction_type=&quot;schema&quot;,
            instruction=&quot;&quot;&quot;From the crawled content, extract all mentioned model names along with their fees for input and output tokens. 
            Do not miss any models in the entire content. One extracted model JSON format should look like this: 
            {&quot;model_name&quot;: &quot;GPT-4&quot;, &quot;input_fee&quot;: &quot;US$10.00 / 1M tokens&quot;, &quot;output_fee&quot;: &quot;

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[ml-explore/mlx-lm]]></title>
            <link>https://github.com/ml-explore/mlx-lm</link>
            <guid>https://github.com/ml-explore/mlx-lm</guid>
            <pubDate>Tue, 16 Sep 2025 00:04:26 GMT</pubDate>
            <description><![CDATA[Run LLMs with MLX]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ml-explore/mlx-lm">ml-explore/mlx-lm</a></h1>
            <p>Run LLMs with MLX</p>
            <p>Language: Python</p>
            <p>Stars: 2,104</p>
            <p>Forks: 237</p>
            <p>Stars today: 157 stars today</p>
            <h2>README</h2><pre>## MLX LM 

MLX LM is a Python package for generating text and fine-tuning large language
models on Apple silicon with MLX.

Some key features include:

* Integration with the Hugging Face Hub to easily use thousands of LLMs with a
  single command. 
* Support for quantizing and uploading models to the Hugging Face Hub.
* [Low-rank and full model
  fine-tuning](https://github.com/ml-explore/mlx-lm/blob/main/mlx_lm/LORA.md)
  with support for quantized models.
* Distributed inference and fine-tuning with `mx.distributed`

The easiest way to get started is to install the `mlx-lm` package:

**With `pip`**:

```sh
pip install mlx-lm
```

**With `conda`**:

```sh
conda install -c conda-forge mlx-lm
```

### Quick Start

To generate text with an LLM use:

```bash
mlx_lm.generate --prompt &quot;How tall is Mt Everest?&quot;
```

To chat with an LLM use:

```bash
mlx_lm.chat
```

This will give you a chat REPL that you can use to interact with the LLM. The
chat context is preserved during the lifetime of the REPL.

Commands in `mlx-lm` typically take command line options which let you specify
the model, sampling parameters, and more. Use `-h` to see a list of available
options for a command, e.g.:

```bash
mlx_lm.generate -h
```

The default model for generation and chat is
`mlx-community/Llama-3.2-3B-Instruct-4bit`.  You can specify any MLX-compatible
model with the `--model` flag. Thousands are available in the
[MLX Community](https://huggingface.co/mlx-community) Hugging Face
organization.

### Python API

You can use `mlx-lm` as a module:

```python
from mlx_lm import load, generate

model, tokenizer = load(&quot;mlx-community/Mistral-7B-Instruct-v0.3-4bit&quot;)

prompt = &quot;Write a story about Einstein&quot;

messages = [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}]
prompt = tokenizer.apply_chat_template(
    messages, add_generation_prompt=True
)

text = generate(model, tokenizer, prompt=prompt, verbose=True)
```

To see a description of all the arguments you can do:

```
&gt;&gt;&gt; help(generate)
```

Check out the [generation
example](https://github.com/ml-explore/mlx-lm/tree/main/mlx_lm/examples/generate_response.py)
to see how to use the API in more detail. Check out the [batch generation
example](https://github.com/ml-explore/mlx-lm/tree/main/mlx_lm/examples/batch_generate_response.py)
to see how to efficiently generate continuations for a batch of prompts.

The `mlx-lm` package also comes with functionality to quantize and optionally
upload models to the Hugging Face Hub.

You can convert models using the Python API:

```python
from mlx_lm import convert

repo = &quot;mistralai/Mistral-7B-Instruct-v0.3&quot;
upload_repo = &quot;mlx-community/My-Mistral-7B-Instruct-v0.3-4bit&quot;

convert(repo, quantize=True, upload_repo=upload_repo)
```

This will generate a 4-bit quantized Mistral 7B and upload it to the repo
`mlx-community/My-Mistral-7B-Instruct-v0.3-4bit`. It will also save the
converted model in the path `mlx_model` by default.

To see a description of all the arguments you can do:

```
&gt;&gt;&gt; help(convert)
```

#### Streaming

For streaming generation, use the `stream_generate` function. This yields
a generation response object.

For example,

```python
from mlx_lm import load, stream_generate

repo = &quot;mlx-community/Mistral-7B-Instruct-v0.3-4bit&quot;
model, tokenizer = load(repo)

prompt = &quot;Write a story about Einstein&quot;

messages = [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}]
prompt = tokenizer.apply_chat_template(
    messages, add_generation_prompt=True
)

for response in stream_generate(model, tokenizer, prompt, max_tokens=512):
    print(response.text, end=&quot;&quot;, flush=True)
print()
```

#### Sampling

The `generate` and `stream_generate` functions accept `sampler` and
`logits_processors` keyword arguments. A sampler is any callable which accepts
a possibly batched logits array and returns an array of sampled tokens.  The
`logits_processors` must be a list of callables which take the token history
and current logits as input and return the processed logits. The logits
processors are applied in order.

Some standard sampling functions and logits processors are provided in
`mlx_lm.sample_utils`.

### Command Line

You can also use `mlx-lm` from the command line with:

```
mlx_lm.generate --model mistralai/Mistral-7B-Instruct-v0.3 --prompt &quot;hello&quot;
```

This will download a Mistral 7B model from the Hugging Face Hub and generate
text using the given prompt.

For a full list of options run:

```
mlx_lm.generate --help
```

To quantize a model from the command line run:

```
mlx_lm.convert --hf-path mistralai/Mistral-7B-Instruct-v0.3 -q
```

For more options run:

```
mlx_lm.convert --help
```

You can upload new models to Hugging Face by specifying `--upload-repo` to
`convert`. For example, to upload a quantized Mistral-7B model to the
[MLX Hugging Face community](https://huggingface.co/mlx-community) you can do:

```
mlx_lm.convert \
    --hf-path mistralai/Mistral-7B-Instruct-v0.3 \
    -q \
    --upload-repo mlx-community/my-4bit-mistral
```

Models can also be converted and quantized directly in the
[mlx-my-repo](https://huggingface.co/spaces/mlx-community/mlx-my-repo) Hugging
Face Space.

### Long Prompts and Generations 

`mlx-lm` has some tools to scale efficiently to long prompts and generations:

- A rotating fixed-size key-value cache.
- Prompt caching

To use the rotating key-value cache pass the argument `--max-kv-size n` where
`n` can be any integer. Smaller values like `512` will use very little RAM but
result in worse quality. Larger values like `4096` or higher will use more RAM
but have better quality.

Caching prompts can substantially speedup reusing the same long context with
different queries. To cache a prompt use `mlx_lm.cache_prompt`. For example:

```bash
cat prompt.txt | mlx_lm.cache_prompt \
  --model mistralai/Mistral-7B-Instruct-v0.3 \
  --prompt - \
  --prompt-cache-file mistral_prompt.safetensors
``` 

Then use the cached prompt with `mlx_lm.generate`:

```
mlx_lm.generate \
    --prompt-cache-file mistral_prompt.safetensors \
    --prompt &quot;\nSummarize the above text.&quot;
```

The cached prompt is treated as a prefix to the supplied prompt. Also notice
when using a cached prompt, the model to use is read from the cache and need
not be supplied explicitly.

Prompt caching can also be used in the Python API in order to avoid
recomputing the prompt. This is useful in multi-turn dialogues or across
requests that use the same context. See the
[example](https://github.com/ml-explore/mlx-lm/blob/main/mlx_lm/examples/chat.py)
for more usage details.

### Supported Models

`mlx-lm` supports thousands of Hugging Face format LLMs. If the model you want to
run is not supported, file an
[issue](https://github.com/ml-explore/mlx-lm/issues/new) or better yet,
submit a pull request.

Here are a few examples of Hugging Face models that work with this example:

- [mistralai/Mistral-7B-v0.1](https://huggingface.co/mistralai/Mistral-7B-v0.1)
- [meta-llama/Llama-2-7b-hf](https://huggingface.co/meta-llama/Llama-2-7b-hf)
- [deepseek-ai/deepseek-coder-6.7b-instruct](https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-instruct)
- [01-ai/Yi-6B-Chat](https://huggingface.co/01-ai/Yi-6B-Chat)
- [microsoft/phi-2](https://huggingface.co/microsoft/phi-2)
- [mistralai/Mixtral-8x7B-Instruct-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)
- [Qwen/Qwen-7B](https://huggingface.co/Qwen/Qwen-7B)
- [pfnet/plamo-13b](https://huggingface.co/pfnet/plamo-13b)
- [pfnet/plamo-13b-instruct](https://huggingface.co/pfnet/plamo-13b-instruct)
- [stabilityai/stablelm-2-zephyr-1_6b](https://huggingface.co/stabilityai/stablelm-2-zephyr-1_6b)
- [internlm/internlm2-7b](https://huggingface.co/internlm/internlm2-7b)
- [tiiuae/falcon-mamba-7b-instruct](https://huggingface.co/tiiuae/falcon-mamba-7b-instruct)

Most
[Mistral](https://huggingface.co/models?library=transformers,safetensors&amp;other=mistral&amp;sort=trending),
[Llama](https://huggingface.co/models?library=transformers,safetensors&amp;other=llama&amp;sort=trending),
[Phi-2](https://huggingface.co/models?library=transformers,safetensors&amp;other=phi&amp;sort=trending),
and
[Mixtral](https://huggingface.co/models?library=transformers,safetensors&amp;other=mixtral&amp;sort=trending)
style models should work out of the box.

For some models (such as `Qwen` and `plamo`) the tokenizer requires you to
enable the `trust_remote_code` option. You can do this by passing
`--trust-remote-code` in the command line. If you don&#039;t specify the flag
explicitly, you will be prompted to trust remote code in the terminal when
running the model. 

For `Qwen` models you must also specify the `eos_token`. You can do this by
passing `--eos-token &quot;&lt;|endoftext|&gt;&quot;` in the command
line. 

These options can also be set in the Python API. For example:

```python
model, tokenizer = load(
    &quot;qwen/Qwen-7B&quot;,
    tokenizer_config={&quot;eos_token&quot;: &quot;&lt;|endoftext|&gt;&quot;, &quot;trust_remote_code&quot;: True},
)
```

### Large Models

&gt; [!NOTE]
    This requires macOS 15.0 or higher to work.

Models which are large relative to the total RAM available on the machine can
be slow. `mlx-lm` will attempt to make them faster by wiring the memory
occupied by the model and cache. This requires macOS 15 or higher to
work.

If you see the following warning message:

&gt; [WARNING] Generating with a model that requires ...

then the model will likely be slow on the given machine. If the model fits in
RAM then it can often be sped up by increasing the system wired memory limit.
To increase the limit, set the following `sysctl`:

```bash
sudo sysctl iogpu.wired_limit_mb=N
```

The value `N` should be larger than the size of the model in megabytes but
smaller than the memory size of the machine.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[CorentinJ/Real-Time-Voice-Cloning]]></title>
            <link>https://github.com/CorentinJ/Real-Time-Voice-Cloning</link>
            <guid>https://github.com/CorentinJ/Real-Time-Voice-Cloning</guid>
            <pubDate>Tue, 16 Sep 2025 00:04:25 GMT</pubDate>
            <description><![CDATA[Clone a voice in 5 seconds to generate arbitrary speech in real-time]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/CorentinJ/Real-Time-Voice-Cloning">CorentinJ/Real-Time-Voice-Cloning</a></h1>
            <p>Clone a voice in 5 seconds to generate arbitrary speech in real-time</p>
            <p>Language: Python</p>
            <p>Stars: 55,743</p>
            <p>Forks: 9,156</p>
            <p>Stars today: 266 stars today</p>
            <h2>README</h2><pre># Real-Time Voice Cloning
This repository is an implementation of [Transfer Learning from Speaker Verification to
Multispeaker Text-To-Speech Synthesis](https://arxiv.org/pdf/1806.04558.pdf) (SV2TTS) with a vocoder that works in real-time. This was my [master&#039;s thesis](https://matheo.uliege.be/handle/2268.2/6801).

SV2TTS is a deep learning framework in three stages. In the first stage, one creates a digital representation of a voice from a few seconds of audio. In the second and third stages, this representation is used as reference to generate speech given arbitrary text.

**Video demonstration** (click the picture):

[![Toolbox demo](https://i.imgur.com/8lFUlgz.png)](https://www.youtube.com/watch?v=-O_hYhToKoA)



### Papers implemented  
| URL | Designation | Title | Implementation source |
| --- | ----------- | ----- | --------------------- |
|[**1806.04558**](https://arxiv.org/pdf/1806.04558.pdf) | **SV2TTS** | **Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis** | This repo |
|[1802.08435](https://arxiv.org/pdf/1802.08435.pdf) | WaveRNN (vocoder) | Efficient Neural Audio Synthesis | [fatchord/WaveRNN](https://github.com/fatchord/WaveRNN) |
|[1703.10135](https://arxiv.org/pdf/1703.10135.pdf) | Tacotron (synthesizer) | Tacotron: Towards End-to-End Speech Synthesis | [fatchord/WaveRNN](https://github.com/fatchord/WaveRNN)
|[1710.10467](https://arxiv.org/pdf/1710.10467.pdf) | GE2E (encoder)| Generalized End-To-End Loss for Speaker Verification | This repo |

## Heads up
Like everything else in Deep Learning, this repo has quickly gotten old. Many SaaS apps (often paying) will give you a better audio quality than this repository will. If you wish for an open-source solution with a high voice quality:
- Check out [paperswithcode](https://paperswithcode.com/task/speech-synthesis/) for other repositories and recent research in the field of speech synthesis.
- Check out [Chatterbox](https://github.com/resemble-ai/chatterbox) for a similar project up to date with the 2025 SOTA in voice cloning

## Setup

### 1. Install Requirements
1. Both Windows and Linux are supported. A GPU is recommended for training and for inference speed, but is not mandatory.
2. Python 3.7 is recommended. Python 3.5 or greater should work, but you&#039;ll probably have to tweak the dependencies&#039; versions. I recommend setting up a virtual environment using `venv`, but this is optional.
3. Install [ffmpeg](https://ffmpeg.org/download.html#get-packages). This is necessary for reading audio files.
4. Install [PyTorch](https://pytorch.org/get-started/locally/). Pick the latest stable version, your operating system, your package manager (pip by default) and finally pick any of the proposed CUDA versions if you have a GPU, otherwise pick CPU. Run the given command.
5. Install the remaining requirements with `pip install -r requirements.txt`

### 2. (Optional) Download Pretrained Models
Pretrained models are now downloaded automatically. If this doesn&#039;t work for you, you can manually download them [here](https://github.com/CorentinJ/Real-Time-Voice-Cloning/wiki/Pretrained-models).

### 3. (Optional) Test Configuration
Before you download any dataset, you can begin by testing your configuration with:

`python demo_cli.py`

If all tests pass, you&#039;re good to go.

### 4. (Optional) Download Datasets
For playing with the toolbox alone, I only recommend downloading [`LibriSpeech/train-clean-100`](https://www.openslr.org/resources/12/train-clean-100.tar.gz). Extract the contents as `&lt;datasets_root&gt;/LibriSpeech/train-clean-100` where `&lt;datasets_root&gt;` is a directory of your choosing. Other datasets are supported in the toolbox, see [here](https://github.com/CorentinJ/Real-Time-Voice-Cloning/wiki/Training#datasets). You&#039;re free not to download any dataset, but then you will need your own data as audio files or you will have to record it with the toolbox.

### 5. Launch the Toolbox
You can then try the toolbox:

`python demo_toolbox.py -d &lt;datasets_root&gt;`  
or  
`python demo_toolbox.py`  

depending on whether you downloaded any datasets. If you are running an X-server or if you have the error `Aborted (core dumped)`, see [this issue](https://github.com/CorentinJ/Real-Time-Voice-Cloning/issues/11#issuecomment-504733590).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[HKUDS/DeepCode]]></title>
            <link>https://github.com/HKUDS/DeepCode</link>
            <guid>https://github.com/HKUDS/DeepCode</guid>
            <pubDate>Tue, 16 Sep 2025 00:04:24 GMT</pubDate>
            <description><![CDATA["DeepCode: Open Agentic Coding (Paper2Code & Text2Web & Text2Backend)"]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/HKUDS/DeepCode">HKUDS/DeepCode</a></h1>
            <p>"DeepCode: Open Agentic Coding (Paper2Code & Text2Web & Text2Backend)"</p>
            <p>Language: Python</p>
            <p>Stars: 6,279</p>
            <p>Forks: 862</p>
            <p>Stars today: 186 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;table style=&quot;border: none; margin: 0 auto; padding: 0; border-collapse: collapse;&quot;&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot; style=&quot;vertical-align: middle; padding: 10px; border: none; width: 250px;&quot;&gt;
  &lt;img src=&quot;assets/logo.png&quot; alt=&quot;DeepCode Logo&quot; width=&quot;200&quot; style=&quot;margin: 0; padding: 0; display: block;&quot;/&gt;
&lt;/td&gt;
&lt;td align=&quot;left&quot; style=&quot;vertical-align: middle; padding: 10px 0 10px 30px; border: none;&quot;&gt;
  &lt;pre style=&quot;font-family: &#039;Courier New&#039;, monospace; font-size: 16px; color: #0EA5E9; margin: 0; padding: 0; text-shadow: 0 0 10px #0EA5E9, 0 0 20px rgba(14,165,233,0.5); line-height: 1.2; transform: skew(-1deg, 0deg); display: block;&quot;&gt;    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
    ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù
    ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
    ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù
    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë     ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù      ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù&lt;/pre&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/14665&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14665&quot; alt=&quot;HKUDS%2FDeepCode | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;!-- &lt;img src=&quot;https://readme-typing-svg.herokuapp.com?font=Russo+One&amp;size=28&amp;duration=2000&amp;pause=800&amp;color=06B6D4&amp;background=00000000&amp;center=true&amp;vCenter=true&amp;width=800&amp;height=50&amp;lines=%E2%9A%A1+OPEN+AGENTIC+CODING+%E2%9A%A1&quot; alt=&quot;DeepCode Tech Subtitle&quot; style=&quot;margin-top: 5px; filter: drop-shadow(0 0 12px #06B6D4) drop-shadow(0 0 24px rgba(6,182,212,0.4));&quot;/&gt; --&gt;

# &lt;img src=&quot;https://github.com/Zongwei9888/Experiment_Images/raw/43c585dca3d21b8e4b6390d835cdd34dc4b4b23d/DeepCode_images/title_logo.svg&quot; alt=&quot;DeepCode Logo&quot; width=&quot;32&quot; height=&quot;32&quot; style=&quot;vertical-align: middle; margin-right: 8px;&quot;/&gt; DeepCode: Open Agentic Coding

### *Advancing Code Generation with Multi-Agent Systems*

&lt;!-- &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/Version-1.0.0-00d4ff?style=for-the-badge&amp;logo=rocket&amp;logoColor=white&quot; alt=&quot;Version&quot;&gt;

  &lt;img src=&quot;https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;logo=opensourceinitiative&amp;logoColor=white&quot; alt=&quot;License&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/AI-Multi--Agent-9b59b6?style=for-the-badge&amp;logo=brain&amp;logoColor=white&quot; alt=&quot;AI&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/HKU-Data_Intelligence_Lab-f39c12?style=for-the-badge&amp;logo=university&amp;logoColor=white&quot; alt=&quot;HKU&quot;&gt;
&lt;/p&gt; --&gt;
&lt;p&gt;
  &lt;a href=&quot;https://github.com/HKUDS/DeepCode/stargazers&quot;&gt;&lt;img src=&#039;https://img.shields.io/github/stars/HKUDS/DeepCode?color=00d9ff&amp;style=for-the-badge&amp;logo=star&amp;logoColor=white&amp;labelColor=1a1a2e&#039; /&gt;&lt;/a&gt;
  &lt;img src=&quot;https://img.shields.io/badge/üêçPython-3.13-4ecdc4?style=for-the-badge&amp;logo=python&amp;logoColor=white&amp;labelColor=1a1a2e&quot;&gt;
  &lt;a href=&quot;https://pypi.org/project/deepcode-hku/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/deepcode-hku.svg?style=for-the-badge&amp;logo=pypi&amp;logoColor=white&amp;labelColor=1a1a2e&amp;color=ff6b6b&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;
  &lt;a href=&quot;https://discord.gg/yF2MmDJyGJ&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/üí¨Discord-Community-7289da?style=for-the-badge&amp;logo=discord&amp;logoColor=white&amp;labelColor=1a1a2e&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/HKUDS/DeepCode/issues/11&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/üí¨WeChat-Group-07c160?style=for-the-badge&amp;logo=wechat&amp;logoColor=white&amp;labelColor=1a1a2e&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;div style=&quot;width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);&quot;&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;#-quick-start&quot; style=&quot;text-decoration: none;&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;logo=rocket&amp;logoColor=white&amp;labelColor=1a1a2e&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

### üñ•Ô∏è **Interface Showcase**

&lt;table align=&quot;center&quot; width=&quot;100%&quot; style=&quot;border: none; border-collapse: collapse; margin: 30px 0;&quot;&gt;
&lt;tr&gt;
&lt;td width=&quot;50%&quot; align=&quot;center&quot; style=&quot;vertical-align: top; padding: 20px;&quot;&gt;

#### üñ•Ô∏è **CLI Interface**
**Terminal-Based Development**

&lt;div align=&quot;center&quot;&gt;

  &lt;img src=&quot;https://github.com/Zongwei9888/Experiment_Images/blob/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/CLI.gif&quot; alt=&quot;CLI Interface Demo&quot; width=&quot;100%&quot; style=&quot;border-radius: 10px; box-shadow: 0 8px 20px rgba(45,55,72,0.3); margin: 15px 0;&quot;/&gt;

  &lt;div style=&quot;background: linear-gradient(135deg, #2D3748 0%, #4A5568 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;&quot;&gt;
    &lt;strong&gt;üöÄ Advanced Terminal Experience&lt;/strong&gt;&lt;br/&gt;
    &lt;small&gt;‚ö° Fast command-line workflow&lt;br/&gt;üîß Developer-friendly interface&lt;br/&gt;üìä Real-time progress tracking&lt;/small&gt;
  &lt;/div&gt;

  *Professional terminal interface for advanced users and CI/CD integration*
&lt;/div&gt;

&lt;/td&gt;
&lt;td width=&quot;50%&quot; align=&quot;center&quot; style=&quot;vertical-align: top; padding: 20px;&quot;&gt;

#### üåê **Web Interface**
**Visual Interactive Experience**

&lt;div align=&quot;center&quot;&gt;

  &lt;img src=&quot;https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/UI.gif&quot; alt=&quot;Web Interface Demo&quot; width=&quot;100%&quot; style=&quot;border-radius: 10px; box-shadow: 0 8px 20px rgba(14,165,233,0.3); margin: 15px 0;&quot;/&gt;

  &lt;div style=&quot;background: linear-gradient(135deg, #0EA5E9 0%, #00D4FF 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;&quot;&gt;
    &lt;strong&gt;üé® Modern Web Dashboard&lt;/strong&gt;&lt;br/&gt;
    &lt;small&gt;üñ±Ô∏è Intuitive drag-and-drop&lt;br/&gt;üì± Responsive design&lt;br/&gt;üéØ Visual progress tracking&lt;/small&gt;
  &lt;/div&gt;

  *Beautiful web interface with streamlined workflow for all skill levels*
&lt;/div&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

---

&lt;div align=&quot;center&quot;&gt;

### üé¨ **Introduction Video**

&lt;div style=&quot;margin: 20px 0;&quot;&gt;
  &lt;a href=&quot;https://youtu.be/PRgmP8pOI08&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.youtube.com/vi/PRgmP8pOI08/maxresdefault.jpg&quot;
         alt=&quot;DeepCode Introduction Video&quot;
         width=&quot;75%&quot;
         style=&quot;border-radius: 12px; box-shadow: 0 8px 25px rgba(0,0,0,0.15); transition: transform 0.3s ease;&quot;/&gt;
  &lt;/a&gt;
&lt;/div&gt;

*üéØ **Watch our complete introduction** - See how DeepCode transforms research papers and natural language into production-ready code*

&lt;p&gt;
  &lt;a href=&quot;https://youtu.be/PRgmP8pOI08&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/‚ñ∂Ô∏è_Watch_Video-FF0000?style=for-the-badge&amp;logo=youtube&amp;logoColor=white&quot; alt=&quot;Watch Video&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;/div&gt;

---




&gt; *&quot;Where AI Agents Transform Ideas into Production-Ready Code&quot;*

&lt;/div&gt;

---

## üìë Table of Contents

- [üöÄ Key Features](#-key-features)
- [üèóÔ∏è Architecture](#Ô∏è-architecture)
- [üöÄ Quick Start](#-quick-start)
- [üí° Examples](#-examples)
  - [üé¨ Live Demonstrations](#-live-demonstrations)
- [‚≠ê Star History](#-star-history)
- [üìÑ License](#-license)

---

## üöÄ Key Features

&lt;br/&gt;

&lt;table align=&quot;center&quot; width=&quot;100%&quot; style=&quot;border: none; table-layout: fixed;&quot;&gt;
&lt;tr&gt;
&lt;td width=&quot;30%&quot; align=&quot;center&quot; style=&quot;vertical-align: top; padding: 20px;&quot;&gt;

&lt;div style=&quot;height: 80px; display: flex; align-items: center; justify-content: center;&quot;&gt;
&lt;h3 style=&quot;margin: 0; padding: 0;&quot;&gt;üöÄ &lt;strong&gt;Paper2Code&lt;/strong&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot; style=&quot;margin: 15px 0;&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/ALGORITHM-IMPLEMENTATION-ff6b6b?style=for-the-badge&amp;logo=algorithm&amp;logoColor=white&quot; alt=&quot;Algorithm Badge&quot; /&gt;
&lt;/div&gt;

&lt;div style=&quot;height: 80px; display: flex; align-items: center; justify-content: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;Automated Implementation of Complex Algorithms&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;div style=&quot;height: 60px; display: flex; align-items: center; justify-content: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;Effortlessly converts complex algorithms from research papers into &lt;strong&gt;high-quality&lt;/strong&gt;, &lt;strong&gt;production-ready&lt;/strong&gt; code, accelerating algorithm reproduction.&lt;/p&gt;
&lt;/div&gt;



&lt;/td&gt;
&lt;td width=&quot;30%&quot; align=&quot;center&quot; style=&quot;vertical-align: top; padding: 20px;&quot;&gt;

&lt;div style=&quot;height: 80px; display: flex; align-items: center; justify-content: center;&quot;&gt;
&lt;h3 style=&quot;margin: 0; padding: 0;&quot;&gt;üé® &lt;strong&gt;Text2Web&lt;/strong&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot; style=&quot;margin: 15px 0;&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/FRONTEND-DEVELOPMENT-4ecdc4?style=for-the-badge&amp;logo=react&amp;logoColor=white&quot; alt=&quot;Frontend Badge&quot; /&gt;
&lt;/div&gt;

&lt;div style=&quot;height: 80px; display: flex; align-items: center; justify-content: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;Automated Front-End Web Development&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;div style=&quot;height: 60px; display: flex; align-items: center; justify-content: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;Translates plain textual descriptions into &lt;strong&gt;fully functional&lt;/strong&gt;, &lt;strong&gt;visually appealing&lt;/strong&gt; front-end web code for rapid interface creation.&lt;/p&gt;
&lt;/div&gt;



&lt;/td&gt;
&lt;td width=&quot;30%&quot; align=&quot;center&quot; style=&quot;vertical-align: top; padding: 20px;&quot;&gt;

&lt;div style=&quot;height: 80px; display: flex; align-items: center; justify-content: center;&quot;&gt;
&lt;h3 style=&quot;margin: 0; padding: 0;&quot;&gt;‚öôÔ∏è &lt;strong&gt;Text2Backend&lt;/strong&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot; style=&quot;margin: 15px 0;&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/BACKEND-DEVELOPMENT-9b59b6?style=for-the-badge&amp;logo=server&amp;logoColor=white&quot; alt=&quot;Backend Badge&quot; /&gt;
&lt;/div&gt;

&lt;div style=&quot;height: 80px; display: flex; align-items: center; justify-content: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;Automated Back-End Development&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;div style=&quot;height: 60px; display: flex; align-items: center; justify-content: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;Generates &lt;strong&gt;efficient&lt;/strong&gt;, &lt;strong&gt;scalable&lt;/strong&gt;, and &lt;strong&gt;feature-rich&lt;/strong&gt; back-end code from simple text inputs, streamlining server-side development.&lt;/p&gt;
&lt;/div&gt;



&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;br/&gt;

### üéØ **Autonomous Multi-Agent Workflow**

**The Challenges**:

- üìÑ **Implementation Complexity**: Converting academic papers and complex algorithms into working code requires significant technical effort and domain expertise

- üî¨ **Research Bottleneck**: Researchers spend valuable time implementing algorithms instead of focusing on their core research and discovery work

- ‚è±Ô∏è **Development Delays**: Product teams experience long wait times between concept and testable prototypes, slowing down innovation cycles

- üîÑ **Repetitive Coding**: Developers repeatedly implement similar patterns and functionality instead of building on existing solutions

**DeepCode** addresses these workflow inefficiencies by providing reliable automation for common development tasks, streamlining your development workflow from concept to code.

&lt;div align=&quot;center&quot;&gt;

```mermaid
flowchart LR
    A[&quot;üìÑ Research Papers&lt;br/&gt;üí¨ Text Prompts&lt;br/&gt;üåê URLs &amp; Document&lt;br/&gt;üìé Files: PDF, DOC, PPTX, TXT, HTML&quot;] --&gt; B[&quot;üß† DeepCode&lt;br/&gt;Multi-Agent Engine&quot;]
    B --&gt; C[&quot;üöÄ Algorithm Implementation &lt;br/&gt;üé® Frontend Development &lt;br/&gt;‚öôÔ∏è Backend Development&quot;]

    style A fill:#ff6b6b,stroke:#c0392b,stroke-width:2px,color:#000
    style B fill:#00d4ff,stroke:#0984e3,stroke-width:3px,color:#000
    style C fill:#00b894,stroke:#00a085,stroke-width:2px,color:#000
```

&lt;/div&gt;

---

## üèóÔ∏è Architecture

### üìä **System Overview**

**DeepCode** is an AI-powered development platform that automates code generation and implementation tasks. Our multi-agent system handles the complexity of translating requirements into functional, well-structured code, allowing you to focus on innovation rather than implementation details.

üéØ **Technical Capabilities**:

üß¨ **Research-to-Production Pipeline**&lt;br&gt;
Multi-modal document analysis engine that extracts algorithmic logic and mathematical models from academic papers. Generates optimized implementations with proper data structures while preserving computational complexity characteristics.

ü™Ñ **Natural Language Code Synthesis**&lt;br&gt;
Context-aware code generation using fine-tuned language models trained on curated code repositories. Maintains architectural consistency across modules while supporting multiple programming languages and frameworks.

‚ö° **Automated Prototyping Engine**&lt;br&gt;
Intelligent scaffolding system generating complete application structures including database schemas, API endpoints, and frontend components. Uses dependency analysis to ensure scalable architecture from initial generation.

üíé **Quality Assurance Automation**&lt;br&gt;
Integrated static analysis with automated unit test generation and documentation synthesis. Employs AST analysis for code correctness and property-based testing for comprehensive coverage.

üîÆ **CodeRAG Integration System**&lt;br&gt;
Advanced retrieval-augmented generation combining semantic vector embeddings with graph-based dependency analysis. Automatically discovers optimal libraries and implementation patterns from large-scale code corpus.

---

### üîß **Core Techniques**

- üß† **Intelligent Orchestration Agent**: Central decision-making system that coordinates workflow phases and analyzes requirements. Employs dynamic planning algorithms to adapt execution strategies in real-time based on evolving project complexity. Dynamically selects optimal processing strategies for each implementation step. &lt;br&gt;

- üíæ **Efficient Memory Mechanism**: Advanced context engineering system that manages large-scale code contexts efficiently. Implements hierarchical memory structures with intelligent compression for handling complex codebases. This component enables instant retrieval of implementation patterns and maintains semantic coherence across extended development sessions. &lt;br&gt;

- üîç **Advanced CodeRAG System**: Global code comprehension engine that analyzes complex inter-dependencies across repositories. Performs cross-codebase relationship mapping to understand architectural patterns from a holistic perspective. This module leverages dependency graphs and semantic analysis to provide globally-aware code recommendations during implementation.

---

### ü§ñ **Multi-Agent Architecture of DeepCode**:

- **üéØ Central Orchestrating Agent**: Orchestrates entire workflow execution and makes strategic decisions. Coordinates specialized agents based on input complexity analysis. Implements dynamic task planning and resource allocation algorithms. &lt;br&gt;

- **üìù Intent Understanding Agent**: Performs deep semantic analysis of user requirements to decode complex intentions. Extracts functional specifications and technical constraints through advanced NLP processing. Transforms ambiguous human descriptions into precise, actionable development specifications with structured task decomposition. &lt;br&gt;

- **üìÑ Document Parsing Agent**: Processes complex technical documents and research papers with advanced parsing capabilities. Extracts algorithms and methodologies using document understanding models. Converts academic concepts into practical implementation specifications through intelligent content analysis. &lt;br&gt;

- **üèóÔ∏è Code Planning Agent**: Performs architectural design and technology stack optimization. Dynamic planning for adaptive development roadmaps. Enforces coding standards and generates modular structures through automated design pattern selection.&lt;br&gt;

- **üîç Code Reference Mining Agent**: Discovers relevant repositories and frameworks through intelligent search algorithms. Analyzes codebases for compatibility and integration potential. Provides recommendations based on similarity metrics and automated dependency analysis. &lt;br&gt;

- **üìö Code Indexing Agent**: Builds comprehensive knowledge graphs of discovered codebases. Maintains semantic relationships between code components. Enables intelligent retrieval and cross-reference capabilities. &lt;br&gt;

- **üß¨ Code Generation Agent**: Synthesizes gathered information into executable code implementations. Creates functional interfaces and integrates discovered components. Generates comprehensive test suites and documentation for reproducibility.

---

#### üõ†Ô∏è **Implementation Tools Matrix**

**üîß Powered by MCP (Model Context Protocol)**

DeepCode leverages the **Model Context Protocol (MCP)** standard to seamlessly integrate with various tools and services. This standardized approach ensures reliable communication between AI agents and external systems, enabling powerful automation capabilities.

##### üì° **MCP Servers &amp; Tools**

| üõ†Ô∏è **MCP Server** | üîß **Primary Function** | üí° **Purpose &amp; Capabilities** |
|-------------------|-------------------------|-------------------------------|
| **üîç brave** | Web Search Engine | Real-time information retrieval via Brave Search API |
| **üåê bocha-mcp** | Alternative Search | Secondary search option with independent API access |
| **üìÇ filesystem** | File System Operations | Local file and directory management, read/write operations |
| **üåê fetch** | Web Content Retrieval | Fetch and extract content from URLs and web resources |
| **üì• github-downloader** | Repository Management | Clone and download GitHub repositories for analysis |
| **üìã file-downloader** | Document Processing | Download and convert files (PDF, DOCX, etc.) to Markdown |
| **‚ö° command-executor** | System Commands | Execute bash/shell commands for environment management |
| **üß¨ code-implementation** | Code Generation Hub | Comprehensive code reproduction with execution and testing |
| **üìö code-reference-indexer** | Smart Code Search | Intelligent indexing and search of code repositories |
| **üìÑ document-segmentation** | Smart Document Analysis | Intelligent document segmentation for large papers and technical documents |

##### üîß **Legacy Tool Functions** *(for reference)*

| üõ†Ô∏è **Function** | üéØ **Usage Context** |
|-----------------|---------------------|
| **üìÑ read_code_mem** | Efficient code context retrieval from memory |
| **‚úçÔ∏è write_file** | Direct file content generation and modification |
| **üêç execute_python** | Python code testing and validation |
| **üìÅ get_file_structure** | Project structure analysis and organization |
| **‚öôÔ∏è set_workspace** | Dynamic workspace and environment configuration |
| **üìä get_operation_history** | Process monitoring and operation tracking |


---

üéõÔ∏è **Multi-Interface Framework**&lt;br&gt;
RESTful API with CLI and web frontends featuring real-time code streaming, interactive debugging, and extensible plugin architecture for CI/CD integration.

**üöÄ Multi-Agent Intelligent Pipeline:**

&lt;div align=&quot;center&quot;&gt;

### üåü **Intelligence Processing Flow**

&lt;table align=&quot;center&quot; width=&quot;100%&quot; style=&quot;border: none; border-collapse: collapse;&quot;&gt;
&lt;tr&gt;
&lt;td colspan=&quot;3&quot; align=&quot;center&quot; style=&quot;padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white; font-weight: bold;&quot;&gt;
üí° &lt;strong&gt;INPUT LAYER&lt;/strong&gt;&lt;br/&gt;
üìÑ Research Papers ‚Ä¢ üí¨ Natural Language ‚Ä¢ üåê URLs ‚Ä¢ üìã Requirements
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan=&quot;3&quot; height=&quot;20&quot;&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&quot;3&quot; align=&quot;center&quot; style=&quot;padding: 15px; background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%); border-radius: 12px; color: white; font-weight: bold;&quot;&gt;
üéØ &lt;strong&gt;CENTRAL ORCHESTRATION&lt;/strong&gt;&lt;br/&gt;
Strategic Decision Making ‚Ä¢ Workflow Coordination ‚Ä¢ Agent Management
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan=&quot;3&quot; height=&quot;15&quot;&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot; style=&quot;padding: 12px; background: linear-gradient(135deg, #3742fa 0%, #2f3542 100%); border-radius: 10px; color: white; width: 50%;&quot;&gt;
üìù &lt;strong&gt;TEXT ANALYSIS&lt;/strong&gt;&lt;br/&gt;
&lt;small&gt;Requirement Processing&lt;/small&gt;
&lt;/td&gt;
&lt;td width=&quot;10&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot; style=&quot;padding: 12px; background: linear-gradient(135deg, #8c7ae6 0%, #9c88ff 100%); border-radius: 10px; color: white; width: 50%;&quot;&gt;
üìÑ &lt;strong&gt;DOCUMENT ANALYSIS&lt;/strong&gt;&lt;br/&gt;
&lt;small&gt;Paper &amp; Spec Processing&lt;/small&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan=&quot;3&quot; height=&quot;15&quot;&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&quot;3&quot; align=&quot;center&quot; style=&quot;padding: 15px; background: linear-gradient(135deg, #00d2d3 0%, #54a0ff 100%); border-radius: 12px; color: white; font-weight: bold;&quot;&gt;
üìã &lt;strong&gt;REPRODUCTION PLANNING&lt;/strong&gt;&lt;br/&gt;
Deep Paper Analysis ‚Ä¢ Code Requirements Parsing ‚Ä¢ Reproduction Strategy Developm

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[net4people/bbs]]></title>
            <link>https://github.com/net4people/bbs</link>
            <guid>https://github.com/net4people/bbs</guid>
            <pubDate>Tue, 16 Sep 2025 00:04:23 GMT</pubDate>
            <description><![CDATA[Forum for discussing Internet censorship circumvention]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/net4people/bbs">net4people/bbs</a></h1>
            <p>Forum for discussing Internet censorship circumvention</p>
            <p>Language: Python</p>
            <p>Stars: 4,254</p>
            <p>Forks: 95</p>
            <p>Stars today: 89 stars today</p>
            <h2>README</h2><pre># [BBS](https://github.com/net4people/bbs/issues)

### Net4People BBS
The BBS is an inclusive and multilingual forum for public discussion about Internet censorship circumvention. It is a place for **developers and researchers** to discuss and share information, techniques, and research. Feel free to write in your own language; we will translate. To start a discussion topic, [open a new issue](https://github.com/net4people/bbs/issues/new).

### Net4PeopleËÆ∫Âùõ
Êú¨BBSÊòØ‰∏Ä‰∏™ÂåÖÂÆπÁöÑÂ§öËØ≠ÁßçËÆ∫ÂùõÔºåÁî®‰∫éÂÖ¨ÂºÄËÆ®ËÆ∫ËßÑÈÅø‰∫íËÅîÁΩëÂÆ°Êü•ÁöÑËØùÈ¢ò„ÄÇÊ¨¢ËøéÂêÑ‰Ωç**ÂºÄÂèëËÄÖÂíåÁ†îÁ©∂‰∫∫Âëò**ËÆ®ËÆ∫ÂíåÂàÜ‰∫´ÊúâÂÖ≥‰∫íËÅîÁΩëÂ∞ÅÈîÅÁöÑ‰ø°ÊÅØ„ÄÅÊäÄÊúØÂèäÁ†îÁ©∂„ÄÇÊ¨¢Ëøé‰Ω†‰ΩøÁî®Ëá™Â∑±ÁöÑËØ≠Ë®ÄÔºåÊàë‰ª¨‰ºöÁøªËØëÁöÑ„ÄÇË¶ÅÂèëËµ∑‰∏Ä‰∏™ËÆ®ËÆ∫ËØùÈ¢òÔºåËØ∑[ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑissue](https://github.com/net4people/bbs/issues/new)„ÄÇ

### Net4People BBS
El BBS es un servicio inclusivo y multiling√ºe para la discusi√≥n p√∫blica acerca de las formas de elusi√≥n de la censura en Internet. Es un espacio para que **desarrolladores e investigadores** conversen y compartan informaci√≥n, t√©cnicas y resultados. Si prefieres, escribe en tu propio idioma y lo trataremos de traducir. Para iniciar un nuevo tema de discusi√≥n, por favor [crea una nueva &quot;issue&quot;](https://github.com/net4people/bbs/issues/new).

### Net4People serwis BBS
Ten BBS jest otwartym i wielojƒôzycznym forum dla publicznej dyskusji na temat obchodzenia cenzury Internetowej. To miejsce, gdzie **programi≈õci i badacze** mogƒÖ rozmawiaƒá i dzieliƒá informacje, sposoby, i wyniki badawcze. Je≈õli wolisz, proszƒô pisz po swoim jƒôzyku, a przet≈Çumaczymy. Aby rozpoczƒÖƒá temat dyskusyjny, proszƒô [otw√≥rz nowy issue](https://github.com/net4people/bbs/issues/new).

### Net4People BBS
Das BBS ist ein inklusives und vielsprachiges Forum f√ºr √∂ffentliche Diskussion um Internetzensur und Zensurumgehung. Es ist ein Ort f√ºr **Entwickler und Forscher**, um Informationen, Techniken und Forschung zu teilen. Schreibe gerne in deiner Sprache; wir werden √ºbersetzen. Um eine Diskussion zu starten, [starte ein &quot;issue&quot;](https://github.com/net4people/bbs/issues/new).

### &amp;rlm;ÿßŸÜÿ¨ŸÖŸÜ Net4People&amp;zwnj;

&amp;rlm;BBS €å⁄© ÿßŸÜÿ¨ŸÖŸÜ ŸÅÿ±ÿß⁄Ø€åÿ± Ÿà ⁄ÜŸÜÿØ ÿ≤ÿ®ÿßŸÜŸá ÿ®ÿ±ÿß€å ÿ®ÿ≠ÿ´ Ÿà ⁄ØŸÅÿ™⁄ØŸà€å ÿπŸÖŸàŸÖ€å ÿØÿ± ŸÖŸàÿ±ÿØ ÿØŸàÿ± ÿ≤ÿØŸÜ ÿ≥ÿßŸÜÿ≥Ÿàÿ± ÿß€åŸÜÿ™ÿ±ŸÜÿ™ ÿßÿ≥ÿ™. ÿß€åŸÜ ŸÖ⁄©ÿßŸÜ€å ÿ®ÿ±ÿß€å **ÿ™Ÿàÿ≥ÿπŸá ÿØŸáŸÜÿØ⁄ØÿßŸÜ Ÿà ŸÖÿ≠ŸÇŸÇÿßŸÜ** ÿßÿ≥ÿ™ ÿ™ÿß ÿ®ÿ≠ÿ´ ⁄©ŸÜŸÜÿØ Ÿà ÿßÿ∑ŸÑÿßÿπÿßÿ™ÿå ŸÅŸÜŸàŸÜ Ÿà ÿ™ÿ≠ŸÇ€åŸÇÿßÿ™ ÿ±ÿß ÿ®Ÿá ÿßÿ¥ÿ™ÿ±ÿß⁄© ÿ®⁄Øÿ∞ÿßÿ±ŸÜÿØ. ÿ®ÿß ÿÆ€åÿßŸÑ ÿ±ÿßÿ≠ÿ™ ÿ®Ÿá ÿ≤ÿ®ÿßŸÜ ÿÆŸàÿØ ÿ®ŸÜŸà€åÿ≥€åÿØÿõ ŸÖÿß ÿ™ÿ±ÿ¨ŸÖŸá ÿÆŸàÿßŸá€åŸÖ ⁄©ÿ±ÿØ. ÿ®ÿ±ÿß€å ÿ¥ÿ±Ÿàÿπ €å⁄© ŸÖŸàÿ∂Ÿàÿπ ÿ®ÿ≠ÿ´ÿå [€å⁄© ŸÖÿ≥ÿ¶ŸÑŸá €å ÿ¨ÿØ€åÿØ ÿß€åÿ¨ÿßÿØ ⁄©ŸÜ€åÿØ](https://github.com/net4people/bbs/issues/new).&amp;zwnj;

### Net4People BBS
O BBS √© um forum inclusivo e multil√≠ngue para discuss√£o p√∫blica sobre como se evadir da censura na Internet. √â um lugar para **desenvolvedores e pesquisadores** discutirem e compartilharem informa√ß√µes, t√©cnicas e pesquisas. Sinta-se √† vontade para escrever em seu pr√≥prio idioma, pois n√≥s traduziremos. Para iniciar um t√≥pico de discuss√£o, [abra um novo problema](https://github.com/net4people/bbs/issues/new).

### Net4People BBS
BBS adalah forum inklusif dan multibahasa untuk diskusi publik tentang pengelakan sensor internet. Forum ini merupakan tempat bagi para **pengembang dan peneliti** untuk berdiskusi dan berbagi informasi, teknik, dan penelitian. Jangan ragu untuk menulis dalam bahasamu sendiri; kami akan menerjemahkannya. Untuk memulai topik diskusi, [buka isu baru](https://github.com/net4people/bbs/issues/new).

### Net4People ·Äò·ÄÆ·Äò·ÄÆ·Ä°·ÄÄ·Ä∫·ÄÖ·Ä∫
·Äò·ÄÆ·Äò·ÄÆ·Ä°·ÄÄ·Ä∫·ÄÖ·Ä∫·ÄÜ·Ä≠·ÄØ·Äû·Ää·Ä∫·Äô·Äæ·Ä¨ ·Ä°·ÄÑ·Ä∫·Äê·Ä¨·Äî·ÄÄ·Ä∫·ÄÜ·ÄÑ·Ä∫·ÄÜ·Ä¨·Äï·Ä≠·Äê·Ä∫·ÄÜ·Ä≠·ÄØ·Ä∑·Äô·Äæ·ÄØ·Äô·Äª·Ä¨·Ä∏·Ä°·Ä¨·Ä∏ ·ÄÄ·Äª·Ä±·Ä¨·Ä∫·Äñ·Äº·Äê·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ ·ÄÜ·ÄΩ·Ä±·Ä∏·Äî·ÄΩ·Ä±·Ä∏·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äû·Ää·Ä∫·Ä∑ ·Äñ·Ä≠·ÄØ·Äõ·Äô·Ä∫·Äê·ÄÖ·Ä∫·ÄÅ·ÄØ·Äñ·Äº·ÄÖ·Ä∫·Äï·Ä´·Äû·Ää·Ä∫·Åã **·Äû·ÄØ·Äê·Ä±·Äû·ÄÆ·Äê·ÄΩ·Ä±·Äî·Ä≤·Ä∑ ·Äí·ÄÆ·Äó·Äú·Ä≠·ÄØ·Äï·Ä´·Äê·ÄΩ·Ä±** ·Äû·Äê·ÄÑ·Ä∫·Ä∏·Ä°·ÄÅ·Äª·ÄÄ·Ä∫·Ä°·Äú·ÄÄ·Ä∫·Åä ·Äî·Ää·Ä∫·Ä∏·ÄÖ·Äî·ÄÖ·Ä∫·Äî·Ä≤·Ä∑ ·ÄÖ·Ä¨·Äê·Äô·Ä∫·Ä∏·Äê·ÄΩ·Ä± ·Äô·Äª·Äæ·Äù·Ä±·Äî·Ä≠·ÄØ·ÄÑ·Ä∫
·Äû·Ää·Ä∫·Ä∑·Äî·Ä±·Äõ·Ä¨·Äê·ÄÖ·Ä∫·ÄÅ·ÄØ·Äú·Ää·Ä∫·Ä∏·Äñ·Äº·ÄÖ·Ä∫·Äï·Ä´·Äû·Ää·Ä∫·Åã·Äû·ÄÑ·Ä∫·Äî·Ä¨·Ä∏·Äú·Ää·Ä∫·Äê·Ä≤·Ä∑ ·Äò·Ä¨·Äû·Ä¨·ÄÖ·ÄÄ·Ä¨·Ä∏·Äî·Ä≤·Ä∑·Äù·ÄÑ·Ä∫·Äõ·Ä±·Ä¨·ÄÄ·Ä∫·ÄÜ·ÄΩ·Ä±·Ä∏·Äî·ÄΩ·Ä±·Ä∏·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äï·Ä´·Äû·Ää·Ä∫·Åã ·ÄÄ·Äª·ÄΩ·Äî·Ä∫·ÄØ·Äï·Ä∫·Äê·Ä≠·ÄØ·Ä∑·Äô·Äæ ·Äò·Ä¨·Äû·Ä¨·Äï·Äº·Äî·Ä∫·Äï·Ä±·Ä∏·Äï·Ä´·Äô·Ää·Ä∫·Åã
·Ä°·Ä±·Ä¨·ÄÄ·Ä∫·ÄÄ ·Äú·ÄÑ·Ä∫·Ä∑·ÄÄ·Ä≠·ÄØ ·Äî·Äæ·Ä≠·Äï·Ä∫·Äï·Äº·ÄÆ·Ä∏·ÄÜ·ÄΩ·Ä±·Ä∏·Äî·ÄΩ·Ä±·Ä∏·Äô·Äæ·ÄØ·Äê·ÄÖ·Ä∫·ÄÅ·ÄØ·ÄÖ·Äê·ÄÑ·Ä∫·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äï·Ä´·Äû·Ää·Ä∫·Åã
[open a new issue](https://github.com/net4people/bbs/issues/new)

### &amp;rlm;ŸÖŸÜÿ™ÿØŸâ Net4People&amp;zwnj;
&amp;rlm;ŸáŸéÿ∞Ÿéÿß ÿßŸÑŸíŸÖŸèŸÜŸíÿ™ŸéÿØŸéŸâ ŸÖŸéÿ≥ŸëŸéÿßÿ≠Ÿéÿ©Ÿå ÿ¥ŸéÿßŸÖŸêŸÑŸéÿ©Ÿå ŸàŸéŸÖŸèÿ™ŸéÿπŸéÿØŸëŸêÿØŸéÿ©Ÿè ÿßŸÑŸÑŸëŸèÿ∫Ÿéÿßÿ™Ÿê ŸÑŸêŸÑŸÜŸëŸêŸÇŸéÿßÿ¥Ÿê ÿßŸÑŸíÿπŸéÿßŸÖŸëŸê ÿ≠ŸéŸàŸíŸÑŸé ÿ™Ÿéÿ¨ŸéÿßŸàŸèÿ≤Ÿê ÿ±ŸéŸÇŸéÿßÿ®Ÿéÿ©Ÿê ÿßŸÑÿ•ŸÜÿ™ÿ±ŸÜÿ™. ŸäŸèŸÖŸíŸÉŸêŸÜŸè **ŸÑŸêŸÑŸíŸÖŸèÿ∑ŸéŸàŸëŸêÿ±ŸêŸäŸÜŸé ŸàŸéÿßŸÑŸíÿ®Ÿéÿßÿ≠Ÿêÿ´ŸêŸäŸÜŸé** ŸÖŸèŸÜŸéÿßŸÇŸéÿ¥Ÿéÿ©Ÿè ŸàŸéŸÖŸèÿ¥Ÿéÿßÿ±ŸéŸÉŸéÿ©Ÿè ÿßŸÑŸíŸÖŸéÿπŸíŸÑŸèŸàŸÖŸéÿßÿ™Ÿêÿå ŸàŸéÿßŸÑÿ™ŸëŸêŸÇŸíŸÜŸêŸäŸëŸéÿßÿ™Ÿêÿå ŸàŸéÿßŸÑŸíÿ£Ÿéÿ®Ÿíÿ≠Ÿéÿßÿ´Ÿê ŸáŸèŸÜŸéÿß. ŸÑŸéÿß ÿ™Ÿéÿ™Ÿéÿ±ŸéÿØŸëŸéÿØŸí/Ÿä ŸÅŸêŸä ÿßŸÑŸíŸÉŸèÿ™ŸëŸéÿßÿ®Ÿéÿ©Ÿê ÿ®ŸéŸÑŸéÿ∫Ÿéÿ™ŸêŸÉÿõ ÿ≥ŸéŸÜŸéŸÇŸèŸàŸÖŸè ÿ®ŸêÿßŸÑÿ™ŸëŸéÿ±Ÿíÿ¨ŸéŸÖŸéÿ©Ÿê. ŸÑŸêŸÅŸéÿ™Ÿíÿ≠Ÿê ŸÜŸêŸÇŸéÿßÿ¥Ÿê ÿ¨ŸéÿØŸäÿØŸçÿå [ÿßŸêŸÅŸíÿ™Ÿéÿ≠Ÿí/Ÿä ŸÖŸèÿ¥ŸéŸÉŸëŸéŸÑŸéÿ©Ÿé ÿ¨ŸéÿØŸäÿØŸéÿ©Ÿç](https://github.com/net4people/bbs/issues/new).&amp;zwnj;

----

[Archives of this forum](https://archive.org/search.php?query=source%3A%22https%3A%2F%2Fgithub.com%2Fnet4people%2Fbbs%22&amp;sort=-date), made using the [backup.py](backup.py) script. To make your own backup, [create a personal access token](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token) and run:
&lt;pre&gt;&lt;code&gt;./backup.py -u &lt;var&gt;username&lt;/var&gt;:&lt;var&gt;token&lt;/var&gt; net4people/bbs net4people_bbs.sqlite3&lt;/code&gt;&lt;/pre&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[donnemartin/system-design-primer]]></title>
            <link>https://github.com/donnemartin/system-design-primer</link>
            <guid>https://github.com/donnemartin/system-design-primer</guid>
            <pubDate>Tue, 16 Sep 2025 00:04:22 GMT</pubDate>
            <description><![CDATA[Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/donnemartin/system-design-primer">donnemartin/system-design-primer</a></h1>
            <p>Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.</p>
            <p>Language: Python</p>
            <p>Stars: 319,765</p>
            <p>Forks: 52,266</p>
            <p>Stars today: 221 stars today</p>
            <h2>README</h2><pre>*[English](README.md) ‚àô [Êó•Êú¨Ë™û](README-ja.md) ‚àô [ÁÆÄ‰Ωì‰∏≠Êñá](README-zh-Hans.md) ‚àô [ÁπÅÈ´î‰∏≠Êñá](README-zh-TW.md) | [ÿßŸÑÿπŸéÿ±Ÿéÿ®ŸêŸäŸéŸëÿ©‚Äé](https://github.com/donnemartin/system-design-primer/issues/170) ‚àô [‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ](https://github.com/donnemartin/system-design-primer/issues/220) ‚àô [Portugu√™s do Brasil](https://github.com/donnemartin/system-design-primer/issues/40) ‚àô [Deutsch](https://github.com/donnemartin/system-design-primer/issues/186) ‚àô [ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨](https://github.com/donnemartin/system-design-primer/issues/130) ‚àô [◊¢◊ë◊®◊ô◊™](https://github.com/donnemartin/system-design-primer/issues/272) ‚àô [Italiano](https://github.com/donnemartin/system-design-primer/issues/104) ‚àô [ÌïúÍµ≠Ïñ¥](https://github.com/donnemartin/system-design-primer/issues/102) ‚àô [ŸÅÿßÿ±ÿ≥€å](https://github.com/donnemartin/system-design-primer/issues/110) ‚àô [Polski](https://github.com/donnemartin/system-design-primer/issues/68) ‚àô [—Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫](https://github.com/donnemartin/system-design-primer/issues/87) ‚àô [Espa√±ol](https://github.com/donnemartin/system-design-primer/issues/136) ‚àô [‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢](https://github.com/donnemartin/system-design-primer/issues/187) ‚àô [T√ºrk√ße](https://github.com/donnemartin/system-design-primer/issues/39) ‚àô [ti·∫øng Vi·ªát](https://github.com/donnemartin/system-design-primer/issues/127) ‚àô [Fran√ßais](https://github.com/donnemartin/system-design-primer/issues/250) | [Add Translation](https://github.com/donnemartin/system-design-primer/issues/28)*

**Help [translate](TRANSLATIONS.md) this guide!**

# The System Design Primer

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/jj3A5N8.png&quot;&gt;
  &lt;br/&gt;
&lt;/p&gt;

## Motivation

&gt; Learn how to design large-scale systems.
&gt;
&gt; Prep for the system design interview.

### Learn how to design large-scale systems

Learning how to design scalable systems will help you become a better engineer.

System design is a broad topic.  There is a **vast amount of resources scattered throughout the web** on system design principles.

This repo is an **organized collection** of resources to help you learn how to build systems at scale.

### Learn from the open source community

This is a continually updated, open source project.

[Contributions](#contributing) are welcome!

### Prep for the system design interview

In addition to coding interviews, system design is a **required component** of the **technical interview process** at many tech companies.

**Practice common system design interview questions** and **compare** your results with **sample solutions**: discussions, code, and diagrams.

Additional topics for interview prep:

* [Study guide](#study-guide)
* [How to approach a system design interview question](#how-to-approach-a-system-design-interview-question)
* [System design interview questions, **with solutions**](#system-design-interview-questions-with-solutions)
* [Object-oriented design interview questions, **with solutions**](#object-oriented-design-interview-questions-with-solutions)
* [Additional system design interview questions](#additional-system-design-interview-questions)

## Anki flashcards

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/zdCAkB3.png&quot;&gt;
  &lt;br/&gt;
&lt;/p&gt;

The provided [Anki flashcard decks](https://apps.ankiweb.net/) use spaced repetition to help you retain key system design concepts.

* [System design deck](https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design.apkg)
* [System design exercises deck](https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design%20Exercises.apkg)
* [Object oriented design exercises deck](https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/OO%20Design.apkg)

Great for use while on-the-go.

### Coding Resource: Interactive Coding Challenges

Looking for resources to help you prep for the [**Coding Interview**](https://github.com/donnemartin/interactive-coding-challenges)?

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/b4YtAEN.png&quot;&gt;
  &lt;br/&gt;
&lt;/p&gt;

Check out the sister repo [**Interactive Coding Challenges**](https://github.com/donnemartin/interactive-coding-challenges), which contains an additional Anki deck:

* [Coding deck](https://github.com/donnemartin/interactive-coding-challenges/tree/master/anki_cards/Coding.apkg)

## Contributing

&gt; Learn from the community.

Feel free to submit pull requests to help:

* Fix errors
* Improve sections
* Add new sections
* [Translate](https://github.com/donnemartin/system-design-primer/issues/28)

Content that needs some polishing is placed [under development](#under-development).

Review the [Contributing Guidelines](CONTRIBUTING.md).

## Index of system design topics

&gt; Summaries of various system design topics, including pros and cons.  **Everything is a trade-off**.
&gt;
&gt; Each section contains links to more in-depth resources.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/jrUBAF7.png&quot;&gt;
  &lt;br/&gt;
&lt;/p&gt;

* [System design topics: start here](#system-design-topics-start-here)
    * [Step 1: Review the scalability video lecture](#step-1-review-the-scalability-video-lecture)
    * [Step 2: Review the scalability article](#step-2-review-the-scalability-article)
    * [Next steps](#next-steps)
* [Performance vs scalability](#performance-vs-scalability)
* [Latency vs throughput](#latency-vs-throughput)
* [Availability vs consistency](#availability-vs-consistency)
    * [CAP theorem](#cap-theorem)
        * [CP - consistency and partition tolerance](#cp---consistency-and-partition-tolerance)
        * [AP - availability and partition tolerance](#ap---availability-and-partition-tolerance)
* [Consistency patterns](#consistency-patterns)
    * [Weak consistency](#weak-consistency)
    * [Eventual consistency](#eventual-consistency)
    * [Strong consistency](#strong-consistency)
* [Availability patterns](#availability-patterns)
    * [Fail-over](#fail-over)
    * [Replication](#replication)
    * [Availability in numbers](#availability-in-numbers)
* [Domain name system](#domain-name-system)
* [Content delivery network](#content-delivery-network)
    * [Push CDNs](#push-cdns)
    * [Pull CDNs](#pull-cdns)
* [Load balancer](#load-balancer)
    * [Active-passive](#active-passive)
    * [Active-active](#active-active)
    * [Layer 4 load balancing](#layer-4-load-balancing)
    * [Layer 7 load balancing](#layer-7-load-balancing)
    * [Horizontal scaling](#horizontal-scaling)
* [Reverse proxy (web server)](#reverse-proxy-web-server)
    * [Load balancer vs reverse proxy](#load-balancer-vs-reverse-proxy)
* [Application layer](#application-layer)
    * [Microservices](#microservices)
    * [Service discovery](#service-discovery)
* [Database](#database)
    * [Relational database management system (RDBMS)](#relational-database-management-system-rdbms)
        * [Master-slave replication](#master-slave-replication)
        * [Master-master replication](#master-master-replication)
        * [Federation](#federation)
        * [Sharding](#sharding)
        * [Denormalization](#denormalization)
        * [SQL tuning](#sql-tuning)
    * [NoSQL](#nosql)
        * [Key-value store](#key-value-store)
        * [Document store](#document-store)
        * [Wide column store](#wide-column-store)
        * [Graph Database](#graph-database)
    * [SQL or NoSQL](#sql-or-nosql)
* [Cache](#cache)
    * [Client caching](#client-caching)
    * [CDN caching](#cdn-caching)
    * [Web server caching](#web-server-caching)
    * [Database caching](#database-caching)
    * [Application caching](#application-caching)
    * [Caching at the database query level](#caching-at-the-database-query-level)
    * [Caching at the object level](#caching-at-the-object-level)
    * [When to update the cache](#when-to-update-the-cache)
        * [Cache-aside](#cache-aside)
        * [Write-through](#write-through)
        * [Write-behind (write-back)](#write-behind-write-back)
        * [Refresh-ahead](#refresh-ahead)
* [Asynchronism](#asynchronism)
    * [Message queues](#message-queues)
    * [Task queues](#task-queues)
    * [Back pressure](#back-pressure)
* [Communication](#communication)
    * [Transmission control protocol (TCP)](#transmission-control-protocol-tcp)
    * [User datagram protocol (UDP)](#user-datagram-protocol-udp)
    * [Remote procedure call (RPC)](#remote-procedure-call-rpc)
    * [Representational state transfer (REST)](#representational-state-transfer-rest)
* [Security](#security)
* [Appendix](#appendix)
    * [Powers of two table](#powers-of-two-table)
    * [Latency numbers every programmer should know](#latency-numbers-every-programmer-should-know)
    * [Additional system design interview questions](#additional-system-design-interview-questions)
    * [Real world architectures](#real-world-architectures)
    * [Company architectures](#company-architectures)
    * [Company engineering blogs](#company-engineering-blogs)
* [Under development](#under-development)
* [Credits](#credits)
* [Contact info](#contact-info)
* [License](#license)

## Study guide

&gt; Suggested topics to review based on your interview timeline (short, medium, long).

![Imgur](images/OfVllex.png)

**Q: For interviews, do I need to know everything here?**

**A: No, you don&#039;t need to know everything here to prepare for the interview**.

What you are asked in an interview depends on variables such as:

* How much experience you have
* What your technical background is
* What positions you are interviewing for
* Which companies you are interviewing with
* Luck

More experienced candidates are generally expected to know more about system design.  Architects or team leads might be expected to know more than individual contributors.  Top tech companies are likely to have one or more design interview rounds.

Start broad and go deeper in a few areas.  It helps to know a little about various key system design topics.  Adjust the following guide based on your timeline, experience, what positions you are interviewing for, and which companies you are interviewing with.

* **Short timeline** - Aim for **breadth** with system design topics.  Practice by solving **some** interview questions.
* **Medium timeline** - Aim for **breadth** and **some depth** with system design topics.  Practice by solving **many** interview questions.
* **Long timeline** - Aim for **breadth** and **more depth** with system design topics.  Practice by solving **most** interview questions.

| | Short | Medium | Long |
|---|---|---|---|
| Read through the [System design topics](#index-of-system-design-topics) to get a broad understanding of how systems work | :+1: | :+1: | :+1: |
| Read through a few articles in the [Company engineering blogs](#company-engineering-blogs) for the companies you are interviewing with | :+1: | :+1: | :+1: |
| Read through a few [Real world architectures](#real-world-architectures) | :+1: | :+1: | :+1: |
| Review [How to approach a system design interview question](#how-to-approach-a-system-design-interview-question) | :+1: | :+1: | :+1: |
| Work through [System design interview questions with solutions](#system-design-interview-questions-with-solutions) | Some | Many | Most |
| Work through [Object-oriented design interview questions with solutions](#object-oriented-design-interview-questions-with-solutions) | Some | Many | Most |
| Review [Additional system design interview questions](#additional-system-design-interview-questions) | Some | Many | Most |

## How to approach a system design interview question

&gt; How to tackle a system design interview question.

The system design interview is an **open-ended conversation**.  You are expected to lead it.

You can use the following steps to guide the discussion.  To help solidify this process, work through the [System design interview questions with solutions](#system-design-interview-questions-with-solutions) section using the following steps.

### Step 1: Outline use cases, constraints, and assumptions

Gather requirements and scope the problem.  Ask questions to clarify use cases and constraints.  Discuss assumptions.

* Who is going to use it?
* How are they going to use it?
* How many users are there?
* What does the system do?
* What are the inputs and outputs of the system?
* How much data do we expect to handle?
* How many requests per second do we expect?
* What is the expected read to write ratio?

### Step 2: Create a high level design

Outline a high level design with all important components.

* Sketch the main components and connections
* Justify your ideas

### Step 3: Design core components

Dive into details for each core component.  For example, if you were asked to [design a url shortening service](solutions/system_design/pastebin/README.md), discuss:

* Generating and storing a hash of the full url
    * [MD5](solutions/system_design/pastebin/README.md) and [Base62](solutions/system_design/pastebin/README.md)
    * Hash collisions
    * SQL or NoSQL
    * Database schema
* Translating a hashed url to the full url
    * Database lookup
* API and object-oriented design

### Step 4: Scale the design

Identify and address bottlenecks, given the constraints.  For example, do you need the following to address scalability issues?

* Load balancer
* Horizontal scaling
* Caching
* Database sharding

Discuss potential solutions and trade-offs.  Everything is a trade-off.  Address bottlenecks using [principles of scalable system design](#index-of-system-design-topics).

### Back-of-the-envelope calculations

You might be asked to do some estimates by hand.  Refer to the [Appendix](#appendix) for the following resources:

* [Use back of the envelope calculations](http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html)
* [Powers of two table](#powers-of-two-table)
* [Latency numbers every programmer should know](#latency-numbers-every-programmer-should-know)

### Source(s) and further reading

Check out the following links to get a better idea of what to expect:

* [How to ace a systems design interview](https://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/)
* [The system design interview](http://www.hiredintech.com/system-design)
* [Intro to Architecture and Systems Design Interviews](https://www.youtube.com/watch?v=ZgdS0EUmn70)
* [System design template](https://leetcode.com/discuss/career/229177/My-System-Design-Template)

## System design interview questions with solutions

&gt; Common system design interview questions with sample discussions, code, and diagrams.
&gt;
&gt; Solutions linked to content in the `solutions/` folder.

| Question | |
|---|---|
| Design Pastebin.com (or Bit.ly) | [Solution](solutions/system_design/pastebin/README.md) |
| Design the Twitter timeline and search (or Facebook feed and search) | [Solution](solutions/system_design/twitter/README.md) |
| Design a web crawler | [Solution](solutions/system_design/web_crawler/README.md) |
| Design Mint.com | [Solution](solutions/system_design/mint/README.md) |
| Design the data structures for a social network | [Solution](solutions/system_design/social_graph/README.md) |
| Design a key-value store for a search engine | [Solution](solutions/system_design/query_cache/README.md) |
| Design Amazon&#039;s sales ranking by category feature | [Solution](solutions/system_design/sales_rank/README.md) |
| Design a system that scales to millions of users on AWS | [Solution](solutions/system_design/scaling_aws/README.md) |
| Add a system design question | [Contribute](#contributing) |

### Design Pastebin.com (or Bit.ly)

[View exercise and solution](solutions/system_design/pastebin/README.md)

![Imgur](images/4edXG0T.png)

### Design the Twitter timeline and search (or Facebook feed and search)

[View exercise and solution](solutions/system_design/twitter/README.md)

![Imgur](images/jrUBAF7.png)

### Design a web crawler

[View exercise and solution](solutions/system_design/web_crawler/README.md)

![Imgur](images/bWxPtQA.png)

### Design Mint.com

[View exercise and solution](solutions/system_design/mint/README.md)

![Imgur](images/V5q57vU.png)

### Design the data structures for a social network

[View exercise and solution](solutions/system_design/social_graph/README.md)

![Imgur](images/cdCv5g7.png)

### Design a key-value store for a search engine

[View exercise and solution](solutions/system_design/query_cache/README.md)

![Imgur](images/4j99mhe.png)

### Design Amazon&#039;s sales ranking by category feature

[View exercise and solution](solutions/system_design/sales_rank/README.md)

![Imgur](images/MzExP06.png)

### Design a system that scales to millions of users on AWS

[View exercise and solution](solutions/system_design/scaling_aws/README.md)

![Imgur](images/jj3A5N8.png)

## Object-oriented design interview questions with solutions

&gt; Common object-oriented design interview questions with sample discussions, code, and diagrams.
&gt;
&gt; Solutions linked to content in the `solutions/` folder.

&gt;**Note: This section is under development**

| Question | |
|---|---|
| Design a hash map | [Solution](solutions/object_oriented_design/hash_table/hash_map.ipynb)  |
| Design a least recently used cache | [Solution](solutions/object_oriented_design/lru_cache/lru_cache.ipynb)  |
| Design a call center | [Solution](solutions/object_oriented_design/call_center/call_center.ipynb)  |
| Design a deck of cards | [Solution](solutions/object_oriented_design/deck_of_cards/deck_of_cards.ipynb)  |
| Design a parking lot | [Solution](solutions/object_oriented_design/parking_lot/parking_lot.ipynb)  |
| Design a chat server | [Solution](solutions/object_oriented_design/online_chat/online_chat.ipynb)  |
| Design a circular array | [Contribute](#contributing)  |
| Add an object-oriented design question | [Contribute](#contributing) |

## System design topics: start here

New to system design?

First, you&#039;ll need a basic understanding of common principles, learning about what they are, how they are used, and their pros and cons.

### Step 1: Review the scalability video lecture

[Scalability Lecture at Harvard](https://www.youtube.com/watch?v=-W9F__D3oY4)

* Topics covered:
    * Vertical scaling
    * Horizontal scaling
    * Caching
    * Load balancing
    * Database replication
    * Database partitioning

### Step 2: Review the scalability article

[Scalability](https://web.archive.org/web/20221030091841/http://www.lecloud.net/tagged/scalability/chrono)

* Topics covered:
    * [Clones](https://web.archive.org/web/20220530193911/https://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones)
    * [Databases](https://web.archive.org/web/20220602114024/https://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database)
    * [Caches](https://web.archive.org/web/20230126233752/https://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache)
    * [Asynchronism](https://web.archive.org/web/20220926171507/https://www.lecloud.net/post/9699762917/scalability-for-dummies-part-4-asynchronism)

### Next steps

Next, we&#039;ll look at high-level trade-offs:

* **Performance** vs **scalability**
* **Latency** vs **throughput**
* **Availability** vs **consistency**

Keep in mind that **everything is a trade-off**.

Then we&#039;ll dive into more specific topics such as DNS, CDNs, and load balancers.

## Performance vs scalability

A service is **scalable** if it results in increased **performance** in a manner proportional to resources added. Generally, increasing performance means serving more units of work, but it can also be to handle larger units of work, such as when datasets grow.&lt;sup&gt;&lt;a href=http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html&gt;1&lt;/a&gt;&lt;/sup&gt;

Another way to look at performance vs scalability:

* If you have a **performance** problem, your system is slow for a single user.
* If you have a **scalability** problem, your system is fast for a single user but slow under heavy load.

### Source(s) and further reading

* [A word on scalability](http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html)
* [Scalability, availability, s

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[deepset-ai/haystack]]></title>
            <link>https://github.com/deepset-ai/haystack</link>
            <guid>https://github.com/deepset-ai/haystack</guid>
            <pubDate>Tue, 16 Sep 2025 00:04:21 GMT</pubDate>
            <description><![CDATA[AI orchestration framework to build customizable, production-ready LLM applications. Connect components (models, vector DBs, file converters) to pipelines or agents that can interact with your data. With advanced retrieval methods, it's best suited for building RAG, question answering, semantic search or conversational agent chatbots.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/deepset-ai/haystack">deepset-ai/haystack</a></h1>
            <p>AI orchestration framework to build customizable, production-ready LLM applications. Connect components (models, vector DBs, file converters) to pipelines or agents that can interact with your data. With advanced retrieval methods, it's best suited for building RAG, question answering, semantic search or conversational agent chatbots.</p>
            <p>Language: Python</p>
            <p>Stars: 22,518</p>
            <p>Forks: 2,363</p>
            <p>Stars today: 220 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://haystack.deepset.ai/&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/deepset-ai/haystack/main/docs/img/banner.png&quot; alt=&quot;Green logo of a stylized white &#039;H&#039; with the text &#039;Haystack, by deepset.&#039;¬†Abstract green and yellow diagrams in the background.&quot;&gt;&lt;/a&gt;

|         |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| CI/CD   | [![Tests](https://github.com/deepset-ai/haystack/actions/workflows/tests.yml/badge.svg)](https://github.com/deepset-ai/haystack/actions/workflows/tests.yml) [![types - Mypy](https://img.shields.io/badge/types-Mypy-blue.svg)](https://github.com/python/mypy) [![Coverage Status](https://coveralls.io/repos/github/deepset-ai/haystack/badge.svg?branch=main)](https://coveralls.io/github/deepset-ai/haystack?branch=main) [![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff) |
| Docs    | [![Website](https://img.shields.io/website?label=documentation&amp;up_message=online&amp;url=https%3A%2F%2Fdocs.haystack.deepset.ai)](https://docs.haystack.deepset.ai)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| Package | [![PyPI](https://img.shields.io/pypi/v/haystack-ai)](https://pypi.org/project/haystack-ai/) ![PyPI - Downloads](https://img.shields.io/pypi/dm/haystack-ai?color=blue&amp;logo=pypi&amp;logoColor=gold) ![PyPI - Python Version](https://img.shields.io/pypi/pyversions/haystack-ai?logo=python&amp;logoColor=gold) [![Conda Version](https://img.shields.io/conda/vn/conda-forge/haystack-ai.svg)](https://anaconda.org/conda-forge/haystack-ai) [![GitHub](https://img.shields.io/github/license/deepset-ai/haystack?color=blue)](LICENSE) [![License Compliance](https://github.com/deepset-ai/haystack/actions/workflows/license_compliance.yml/badge.svg)](https://github.com/deepset-ai/haystack/actions/workflows/license_compliance.yml) |
| Meta    | [![Discord](https://img.shields.io/discord/993534733298450452?logo=discord)](https://discord.com/invite/xYvH6drSmA) [![Twitter Follow](https://img.shields.io/twitter/follow/haystack_ai)](https://twitter.com/haystack_ai)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
&lt;/div&gt;

[Haystack](https://haystack.deepset.ai/) is an end-to-end LLM framework that allows you to build applications powered by
LLMs, Transformer models, vector search and more. Whether you want to perform retrieval-augmented generation (RAG),
document search, question answering or answer generation, Haystack can orchestrate state-of-the-art embedding models
and LLMs into pipelines to build end-to-end NLP applications and solve your use case.

## Table of Contents

- [Installation](#installation)
- [Documentation](#documentation)
- [Features](#features)
- [Use Cases](#features)
- [Hayhooks (REST API Deployment)](#-tip-1)
- [Haystack Enterprise](#haystack-enterprise-best-practices-and-expert-support)
- [deepset Studio](#-deepset-studio-your-development-environment-for-haystack)
- [Telemetry](#telemetry)
- [üññ Community](#-community)
- [Contributing to Haystack](#contributing-to-haystack)
- [Who Uses Haystack](#who-uses-haystack)


## Installation

The simplest way to get Haystack is via pip:

```sh
pip install haystack-ai
```

Install from the `main` branch to try the newest features:
```sh
pip install git+https://github.com/deepset-ai/haystack.git@main
```

Haystack supports multiple installation methods including Docker images. For a comprehensive guide please refer
to the [documentation](https://docs.haystack.deepset.ai/docs/installation).

## Documentation

If you&#039;re new to the project, check out [&quot;What is Haystack?&quot;](https://haystack.deepset.ai/overview/intro) then go
through the [&quot;Get Started Guide&quot;](https://haystack.deepset.ai/overview/quick-start) and build your first LLM application
in a matter of minutes. Keep learning with the [tutorials](https://haystack.deepset.ai/tutorials). For more advanced
use cases, or just to get some inspiration, you can browse our Haystack recipes in the
[Cookbook](https://haystack.deepset.ai/cookbook).

At any given point, hit the [documentation](https://docs.haystack.deepset.ai/docs/intro) to learn more about Haystack, what can it do for you and the technology behind.

## Features

- **Technology agnostic:** Allow users the flexibility to decide what vendor or technology they want and make it easy to switch out any component for another. Haystack allows you to use and compare models available from OpenAI, Cohere and Hugging Face, as well as your own local models or models hosted on Azure, Bedrock and SageMaker.
- **Explicit:** Make it transparent how different moving parts can ‚Äútalk‚Äù to each other so it&#039;s easier to fit your tech stack and use case.
- **Flexible:** Haystack provides all tooling in one place: database access, file conversion, cleaning, splitting, training, eval, inference, and more. And whenever custom behavior is desirable, it&#039;s easy to create custom components.
- **Extensible:** Provide a uniform and easy way for the community and third parties to build their own components and foster an open ecosystem around Haystack.

Some examples of what you can do with Haystack:

-   Build **retrieval augmented generation (RAG)** by making use of one of the available vector databases and customizing your LLM interaction, the sky is the limit üöÄ
-   Perform Question Answering **in natural language** to find granular answers in your documents.
-   Perform **semantic search** and retrieve documents according to meaning.
-   Build applications that can make complex decisions making to answer complex queries: such as systems that can resolve complex customer queries, do knowledge search on many disconnected resources and so on.
-   Scale to millions of docs using retrievers and production-scale components.
-   Use **off-the-shelf models** or **fine-tune** them to your data.
-   Use **user feedback** to evaluate, benchmark, and continuously improve your models.

&gt; [!TIP]
&gt;
&gt; Would you like to deploy and serve Haystack pipelines as REST APIs yourself? [Hayhooks](https://github.com/deepset-ai/hayhooks) provides a simple way to wrap your pipelines with custom logic and expose them via HTTP endpoints, including OpenAI-compatible chat completion endpoints and compatibility with fully-featured chat interfaces like [open-webui](https://openwebui.com/).

## Haystack Enterprise: Best Practices and Expert Support

Get expert support from the Haystack team, build faster with enterprise-grade templates, and scale securely with deployment guides for cloud and on-prem environments - all with **Haystack Enterprise**. Read more about it our [announcement post](https://haystack.deepset.ai/blog/announcing-haystack-enterprise).

üëâ [Get Haystack Enterprise](https://www.deepset.ai/products-and-services/haystack-enterprise?utm_source=github.com&amp;utm_medium=referral&amp;utm_campaign=haystack_enterprise) 

## deepset Studio: Your Development Environment for Haystack

Use **deepset Studio** to visually create, deploy, and test your Haystack pipelines. Learn more about it in our [announcement post](https://haystack.deepset.ai/blog/announcing-studio).

![studio](https://github.com/user-attachments/assets/e4f09746-20b5-433e-8261-eca224ac23b3)

üëâ [Sign up](https://landing.deepset.ai/deepset-studio-signup)!

&gt; [!TIP]
&gt;&lt;img src=&quot;https://github.com/deepset-ai/haystack/raw/main/docs/img/deepset-platform-logo-alternative.jpeg&quot;  width=20%&gt;
&gt;
&gt; Are you looking for a managed solution that benefits from Haystack? [deepset AI Platform](https://www.deepset.ai/products-and-services/deepset-ai-platform?utm_campaign=developer-relations&amp;utm_source=haystack&amp;utm_medium=readme) is our fully managed, end-to-end platform to integrate LLMs with your data, which uses Haystack for the LLM pipelines architecture.

## Telemetry

Haystack collects **anonymous** usage statistics of pipeline components. We receive an event every time these components are initialized. This way, we know which components are most relevant to our community.

Read more about telemetry in Haystack or how you can opt out in [Haystack docs](https://docs.haystack.deepset.ai/docs/telemetry).

## üññ Community

If you have a feature request or a bug report, feel free to open an [issue in Github](https://github.com/deepset-ai/haystack/issues). We regularly check these and you can expect a quick response. If you&#039;d like to discuss a topic, or get more general advice on how to make Haystack work for your project, you can start a thread in [Github Discussions](https://github.com/deepset-ai/haystack/discussions) or our [Discord channel](https://discord.com/invite/VBpFzsgRVF). We also check [ùïè (Twitter)](https://twitter.com/haystack_ai) and [Stack Overflow](https://stackoverflow.com/questions/tagged/haystack).

## Contributing to Haystack

We are very open to the community&#039;s contributions - be it a quick fix of a typo, or a completely new feature! You don&#039;t need to be a Haystack expert to provide meaningful improvements. To learn how to get started, check out our [Contributor Guidelines](https://github.com/deepset-ai/haystack/blob/main/CONTRIBUTING.md) first.

There are several ways you can contribute to Haystack:
- Contribute to the main Haystack project
- Contribute an integration on [haystack-core-integrations](https://github.com/deepset-ai/haystack-core-integrations)

&gt; [!TIP]
&gt;üëâ **[Check out the full list of issues that are open to contributions](https://github.com/orgs/deepset-ai/projects/14)**

## Who Uses Haystack

Here&#039;s a list of projects and companies using Haystack. Want to add yours? Open a PR, add it to the list and let the
world know that you use Haystack!

-   [Airbus](https://www.airbus.com/en)
-   [Alcatel-Lucent](https://www.al-enterprise.com/)
-   [Apple](https://www.apple.com/)
-   [BetterUp](https://www.betterup.com/)
-   [Databricks](https://www.databricks.com/)
-   [Deepset](https://deepset.ai/)
-   [Etalab](https://www.deepset.ai/blog/improving-on-site-search-for-government-agencies-etalab)
-   [Infineon](https://www.infineon.com/)
-   [Intel](https://github.com/intel/open-domain-question-and-answer#readme)
-   [Intelijus](https://www.intelijus.ai/)
-   [Intel Labs](https://github.com/IntelLabs/fastRAG#readme)
-   [LEGO](https://github.com/larsbaunwall/bricky#readme)
-   [Meta](https://www.meta.com/about)
-   [Netflix](https://netflix.com)
-   [NOS Portugal](https://www.nos.pt/en/welcome)
-   [Nvidia](https://developer.nvidia.com/blog/reducing-development-time-for-intelligent-virtual-assistants-in-contact-centers/)
-   [PostHog](https://github.com/PostHog/max-ai#readme)
-   [Rakuten](https://www.rakuten.com/)
-   [Sooth.ai](https://www.deepset.ai/blog/advanced-neural-search-with-sooth-ai)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[sherlock-project/sherlock]]></title>
            <link>https://github.com/sherlock-project/sherlock</link>
            <guid>https://github.com/sherlock-project/sherlock</guid>
            <pubDate>Tue, 16 Sep 2025 00:04:20 GMT</pubDate>
            <description><![CDATA[Hunt down social media accounts by username across social networks]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sherlock-project/sherlock">sherlock-project/sherlock</a></h1>
            <p>Hunt down social media accounts by username across social networks</p>
            <p>Language: Python</p>
            <p>Stars: 68,659</p>
            <p>Forks: 7,961</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[home-assistant/core]]></title>
            <link>https://github.com/home-assistant/core</link>
            <guid>https://github.com/home-assistant/core</guid>
            <pubDate>Tue, 16 Sep 2025 00:04:19 GMT</pubDate>
            <description><![CDATA[üè° Open source home automation that puts local control and privacy first.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/home-assistant/core">home-assistant/core</a></h1>
            <p>üè° Open source home automation that puts local control and privacy first.</p>
            <p>Language: Python</p>
            <p>Stars: 81,337</p>
            <p>Forks: 35,142</p>
            <p>Stars today: 38 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[langflow-ai/langflow]]></title>
            <link>https://github.com/langflow-ai/langflow</link>
            <guid>https://github.com/langflow-ai/langflow</guid>
            <pubDate>Tue, 16 Sep 2025 00:04:18 GMT</pubDate>
            <description><![CDATA[Langflow is a powerful tool for building and deploying AI-powered agents and workflows.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/langflow-ai/langflow">langflow-ai/langflow</a></h1>
            <p>Langflow is a powerful tool for building and deploying AI-powered agents and workflows.</p>
            <p>Language: Python</p>
            <p>Stars: 118,174</p>
            <p>Forks: 7,592</p>
            <p>Stars today: 564 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable MD030 --&gt;

![Langflow logo](./docs/static/img/langflow-logo-color-black-solid.svg)


[![Release Notes](https://img.shields.io/github/release/langflow-ai/langflow?style=flat-square)](https://github.com/langflow-ai/langflow/releases)
[![PyPI - License](https://img.shields.io/badge/license-MIT-orange)](https://opensource.org/licenses/MIT)
[![PyPI - Downloads](https://img.shields.io/pypi/dm/langflow?style=flat-square)](https://pypistats.org/packages/langflow)
[![GitHub star chart](https://img.shields.io/github/stars/langflow-ai/langflow?style=flat-square)](https://star-history.com/#langflow-ai/langflow)
[![Open Issues](https://img.shields.io/github/issues-raw/langflow-ai/langflow?style=flat-square)](https://github.com/langflow-ai/langflow/issues)
[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/langflow-ai.svg?style=social&amp;label=Follow%20%40Langflow)](https://twitter.com/langflow_ai)
[![YouTube Channel](https://img.shields.io/youtube/channel/subscribers/UCn2bInQrjdDYKEEmbpwblLQ?label=Subscribe)](https://www.youtube.com/@Langflow)
[![Discord Server](https://img.shields.io/discord/1116803230643527710?logo=discord&amp;style=social&amp;label=Join)](https://discord.gg/EqksyE2EX9)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/langflow-ai/langflow)

&gt; [!CAUTION]
&gt; - Users must update to Langflow &gt;= 1.3 to protect against [CVE-2025-3248](https://nvd.nist.gov/vuln/detail/CVE-2025-3248)
&gt; - Users must update to Langflow &gt;= 1.5.1 to protect against [CVE-2025-57760](https://github.com/langflow-ai/langflow/security/advisories/GHSA-4gv9-mp8m-592r)
&gt;
&gt; For security information, see our [Security Policy](./SECURITY.md) and [Security Advisories](https://github.com/langflow-ai/langflow/security/advisories).

[Langflow](https://langflow.org) is a powerful tool for building and deploying AI-powered agents and workflows. It provides developers with both a visual authoring experience and built-in API and MCP servers that turn every workflow into a tool that can be integrated into applications built on any framework or stack. Langflow comes with batteries included and supports all major LLMs, vector databases and a growing library of AI tools.

## ‚ú® Highlight features

- **Visual builder interface** to quickly get started and iterate .
- **Source code access** lets you customize any component using Python.
- **Interactive playground** to immediately test and refine your flows with step-by-step control.
- **Multi-agent orchestration** with conversation management and retrieval.
- **Deploy as an API** or export as JSON for Python apps.
- **Deploy as an MCP server** and turn your flows into tools for MCP clients.
- **Observability** with LangSmith, LangFuse and other integrations.
- **Enterprise-ready** security and scalability.

## ‚ö°Ô∏è Quickstart

Langflow requires [Python 3.10 to 3.13](https://www.python.org/downloads/release/python-3100/) and [uv](https://docs.astral.sh/uv/getting-started/installation/).

1. To install Langflow, run:

```shell
uv pip install langflow -U
```

2. To run Langflow, run:

```shell
uv run langflow run
```

3. Go to the default Langflow URL at `http://127.0.0.1:7860`.

For more information about installing Langflow, including Docker and Desktop options, see [Install Langflow](https://docs.langflow.org/get-started-installation).

## üì¶ Deployment

Langflow is completely open source and you can deploy it to all major deployment clouds. To learn how to use Docker to deploy Langflow, see the [Docker deployment guide](https://docs.langflow.org/deployment-docker).

## ‚≠ê Stay up-to-date

Star Langflow on GitHub to be instantly notified of new releases.

![Star Langflow](https://github.com/user-attachments/assets/03168b17-a11d-4b2a-b0f7-c1cce69e5a2c)

## üëã Contribute

We welcome contributions from developers of all levels. If you&#039;d like to contribute, please check our [contributing guidelines](./CONTRIBUTING.md) and help make Langflow more accessible.

---

[![Star History Chart](https://api.star-history.com/svg?repos=langflow-ai/langflow&amp;type=Timeline)](https://star-history.com/#langflow-ai/langflow&amp;Date)

## ‚ù§Ô∏è Contributors

[![langflow contributors](https://contrib.rocks/image?repo=langflow-ai/langflow)](https://github.com/langflow-ai/langflow/graphs/contributors)

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Arindam200/awesome-ai-apps]]></title>
            <link>https://github.com/Arindam200/awesome-ai-apps</link>
            <guid>https://github.com/Arindam200/awesome-ai-apps</guid>
            <pubDate>Tue, 16 Sep 2025 00:04:17 GMT</pubDate>
            <description><![CDATA[A collection of projects showcasing RAG, agents, workflows, and other AI use cases]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Arindam200/awesome-ai-apps">Arindam200/awesome-ai-apps</a></h1>
            <p>A collection of projects showcasing RAG, agents, workflows, and other AI use cases</p>
            <p>Language: Python</p>
            <p>Stars: 5,819</p>
            <p>Forks: 692</p>
            <p>Stars today: 401 stars today</p>
            <h2>README</h2><pre># Awesome AI Apps [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

![Banner](/assets/banner_new.png)

This repository is a comprehensive collection of practical examples, tutorials, and recipes for building powerful LLM-powered applications. From simple chatbots to advanced AI agents, these projects serve as a guide for developers working with various AI frameworks and tools.

Powered by [Nebius AI Studio](https://dub.sh/nebius) - your one-stop platform for building and deploying AI applications.

## üöÄ Featured AI Agent Frameworks

- [&lt;img src=&quot;https://raw.githubusercontent.com/google/adk-python/main/assets/agent-development-kit.png&quot; alt=&quot;Google ADK logo&quot; width=&quot;20&quot; height=&quot;20&quot;&gt; Google Agent Development Kit (ADK)](https://google.github.io/adk-docs/)
- [&lt;img src=&quot;https://avatars.githubusercontent.com/u/14957082?s=200&amp;v=4&quot; alt=&quot;OpenAI Agents SDK logo&quot; width=&quot;20&quot; height=&quot;20&quot;&gt; OpenAI Agents SDK](https://openai.github.io/openai-agents-python/)
- [&lt;img src=&quot;https://cdn.simpleicons.org/langchain&quot; alt=&quot;LangChain logo&quot; width=&quot;25&quot; height=&quot;25&quot;&gt; LangChain ](https://python.langchain.com/)
- [&lt;img src=&quot;https://avatars.githubusercontent.com/u/130722866?s=200&amp;v=4&quot; alt=&quot;Llamaindex logo&quot; width=&quot;20&quot; height=&quot;20&quot;&gt; LlamaIndex](https://www.llamaindex.ai/)
- [&lt;img src=&quot;https://avatars.githubusercontent.com/u/104874993?s=48&amp;v=4&quot; alt=&quot;Agno logo&quot; width=&quot;20&quot; height=&quot;20&quot;&gt; Agno](https://www.agno.com/)
- [&lt;img src=&quot;https://cdn.prod.website-files.com/66cf2bfc3ed15b02da0ca770/66d07240057721394308addd_Logo%20(1).svg&quot; alt=&quot;CrewAI logo&quot; width=&quot;35&quot; height=&quot;25&quot;&gt; CrewAI](https://www.crewai.com/)
- [&lt;img src=&quot;https://avatars.githubusercontent.com/u/209155962?s=200&amp;v=4&quot; alt=&quot;AWS Strands Agents logo&quot; width=&quot;20&quot; height=&quot;20&quot;&gt; AWS Strands Agent](https://strandsagents.com/)
- [&lt;img src=&quot;https://avatars.githubusercontent.com/u/110818415?s=200&amp;v=4&quot; alt=&quot;Pydantic AI logo&quot; width=&quot;20&quot; height=&quot;20&quot;&gt; Pydantic AI](https://ai.pydantic.dev/)
- [&lt;img src=&quot;https://avatars.githubusercontent.com/u/134388954?s=200&amp;v=4&quot; alt=&quot;Camel AI logo&quot; width=&quot;20&quot; height=&quot;20&quot;&gt; CAMEL‚ÄëAI](https://www.camel-ai.org/)
- [&lt;img src=&quot;assets/DSPy.png&quot; alt=&quot;DSPy logo&quot; width=&quot;20&quot; height=&quot;20&quot;&gt; DSPy](https://dspy.ai/)

## üß© Starter Agents

**Quick-start agents for learning and extending:**

- [Agno HackerNews Analysis](starter_ai_agents/agno_starter) - Agno-based agent for trend analysis on HackerNews.
- [OpenAI SDK Starter](starter_ai_agents/openai_agents_sdk) - OpenAI Agents SDK based email helper &amp; haiku writer.
- [LlamaIndex Task Manager](starter_ai_agents/llamaindex_starter) - LlamaIndex-powered task assistant.
- [CrewAI Research Crew](starter_ai_agents/crewai_starter) - Multi-agent research team.
- [PydanticAI Weather Bot](starter_ai_agents/pydantic_starter) - Real-time weather info.
- [LangChain-LangGraph Starter](starter_ai_agents/langchain_langgraph_starter) - LangChain + LangGraph starter.
- [AWS Strands Agent Starter](starter_ai_agents/aws_strands_starter) - Weather report Agent.
- [Camel AI Starter](starter_ai_agents/camel_ai_starter) - Performance benchmarking tool that compares the performance of various AI models.

## ü™∂ Simple Agents

**Straightforward, practical use-cases:**

- [Finance Agent](simple_ai_agents/finance_agent) - Tracks live stock &amp; market data.
- [Human-in-the-Loop Agent](simple_ai_agents/human_in_the_loop_agent) - HITL actions for safe AI tasks.
- [Newsletter Generator](simple_ai_agents/newsletter_agent) - AI newsletter builder with Firecrawl.
- [Reasoning Agent](simple_ai_agents/reasoning_agent) - Financial reasoning step-by-step.
- [Agno UI Example](simple_ai_agents/agno_ui_agent) - UI for web &amp; finance agents.
- [Mastra Weather Bot](simple_ai_agents/mastra_ai_weather_agent) - Weather updates with Mastra AI.
- [Calendar Assistant](simple_ai_agents/cal_scheduling_agent) - Calendar scheduling with Cal.com.
- [Web Automation Agent](simple_ai_agents/browser_agent) - Simple Browser Agent implementation with Nebius &amp; browser use.
- [Nebius Chat](simple_ai_agents/nebius_chat) - Nebius AI Studio Chat interface.
- [Talk to Your DB](simple_ai_agents/talk_to_db) - Talk to your Database with GibsonAI &amp; Langchain

## üóÇÔ∏è MCP Agents

**Examples using Model Context Protocol:**

- [Doc-MCP](mcp_ai_agents/doc_mcp) - Semantic RAG docs &amp; Q\&amp;A.
- [LangGraph MCP Agent](mcp_ai_agents/langchain_langgraph_mcp_agent) - LangChain ReAct agent with Couchbase.
- [GitHub MCP Agent](mcp_ai_agents/github_mcp_agent) - Repo insights via MCP.
- [MCP Starter](mcp_ai_agents/mcp_starter) - GitHub repo analyzer starter.
- [Talk to your Docs](mcp_ai_agents/docs_qna_agent) - Documentation QnA Agent
- [Database MCP Agent](mcp_ai_agents/database_mcp_agent) - A conversational AI agent for managing GibsonAI database projects and schemas.

## üß† Memory Agents

**Agents with advanced memory capabilities:**

- [Agno Memory Agent](memory_agents/agno_memory_agent) - Agno-based agent with persistent memory.
- [arXiv Researcher Agent with Memori](memory_agents/arxiv_researcher_agent_with_memori) - Research assistant using OpenAI Agents and GibsonAI Memori.
- [AWS Strands Agent with Memori](memory_agents/aws_strands_agent_with_memori) - AWS Strands agent enhanced with Memori memory.
- [Blog Writing Agent](memory_agents/blog_writing_agent) - Personalized blog writing agent with memory.
- [Social Media Agent](memory_agents/social_media_agent) - Social media automation agent with memory.


## üìö RAG Applications

**Retrieve-augmented generation examples:**

- [Agentic RAG](rag_apps/agentic_rag) - Agentic RAG with Agno &amp; GPT 5.
- [Agentic RAG with Web Search](rag_apps/agentic_rag_with_web_search) - Advanced RAG with CrewAI, Qdrant, and Exa for hybrid search.
- [Resume Optimizer](rag_apps/resume_optimizer) - Boost resumes with AI.
- [LlamaIndex RAG Starter](rag_apps/llamaIndex_starter) - LlamaIndex + Nebius RAG starter.
- [PDF RAG Analyzer](rag_apps/pdf_rag_analyser) - Chat with multiple PDFs.
- [Qwen3 RAG Chat](rag_apps/qwen3_rag) - PDF chatbot with Streamlit.
- [Chat with Code](rag_apps/chat_with_code) - Conversational code explorer.
- [Gemma3 OCR](rag_apps/gemma_ocr/) - OCR-based document and image processor using Gemma3

## üî¨ Advanced Agents

**Complex pipelines for end-to-end workflows:**

- [Deep Researcher](advance_ai_agents/deep_researcher_agent) - Multi-stage research with Agno &amp; Scrapegraph AI.
- [Candilyzer](advance_ai_agents/candidate_analyser) - Analyze GitHub/LinkedIn profiles.
- [Job Finder](advance_ai_agents/job_finder_agent) - LinkedIn job search with Bright Data.
- [AI Trend Analyzer](advance_ai_agents/trend_analyzer_agent) - AI trend mining with Google ADK.
- [Conference Talk Generator](advance_ai_agents/conference_talk_abstract_generator) - Draft talk abstracts with Google ADK &amp; Couchbase.
- [Finance Service Agent](advance_ai_agents/finance_service_agent) - FastAPI server for stock data and predictions with Agno.
- [Price Monitoring Agent](advance_ai_agents/price_monitoring_agent) - Price monitoring and alerting Agent powered by CrewAi, Twilio &amp; Nebius.
- [Startup Idea Validator Agent](advance_ai_agents/startup_idea_validator_agent) - Agentic Workflow to validate and analyze startup ideas.
- [Meeting Assistant Agent](advance_ai_agents/meeting_assistant_agent) - Agentic Workflow that send meeting notes and creates task based on conversation.

## üì∫ Playlist of Demo Videos &amp; Tutorials

- [Build with MCP](https://www.youtube.com/playlist?list=PLMZM1DAlf0Lolxax4L2HS54Me8gn1gkz4)
- [Build AI Agents](https://www.youtube.com/playlist?list=PLMZM1DAlf0LqixhAG9BDk4O_FjqnaogK8)
- [AI Agents, MCP and more...](https://www.youtube.com/playlist?list=PL2ambAOfYA6-LDz0KpVKu9vJKAqhv0KKI)

## Getting Started

### Prerequisites

- Python 3.10 or higher
- Git
- pip (Python package manager) or uv

### Installation Steps

1. **Clone the repository**

   ```bash
   git clone https://github.com/Arindam200/awesome-ai-apps.git
   ```

2. **Navigate to the desired project directory**

   ```bash
   cd awesome-ai-apps/starter_ai_agents/agno_starter
   ```

3. **Install the required dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Follow project-specific instructions**
   - Each project has its own README.md with detailed setup and usage instructions
   - Make sure to read the project-specific documentation before running the application

## ü§ù Contributing

We welcome contributions from the community! Whether you&#039;re a beginner or an expert, your examples and tutorials can help others learn and grow. Here&#039;s how you can contribute:

1. Submit a Pull Request with your LLM application example
2. Add detailed documentation and setup instructions
3. Include requirements.txt or environment.yml
4. Share your experience and best practices

## üìú License

This repository is licensed under the [MIT License](./LICENSE). Feel free to use and modify the examples for your projects.

## Thank You for the Support! üôè

[![Star History Chart](https://api.star-history.com/svg?repos=Arindam200/awesome-ai-apps&amp;type=Date)](https://www.star-history.com/#Arindam200/awesome-ai-apps&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[hanxi/xiaomusic]]></title>
            <link>https://github.com/hanxi/xiaomusic</link>
            <guid>https://github.com/hanxi/xiaomusic</guid>
            <pubDate>Tue, 16 Sep 2025 00:04:16 GMT</pubDate>
            <description><![CDATA[‰ΩøÁî®Â∞èÁà±Èü≥ÁÆ±Êí≠ÊîæÈü≥‰πêÔºåÈü≥‰πê‰ΩøÁî® yt-dlp ‰∏ãËΩΩ„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hanxi/xiaomusic">hanxi/xiaomusic</a></h1>
            <p>‰ΩøÁî®Â∞èÁà±Èü≥ÁÆ±Êí≠ÊîæÈü≥‰πêÔºåÈü≥‰πê‰ΩøÁî® yt-dlp ‰∏ãËΩΩ„ÄÇ</p>
            <p>Language: Python</p>
            <p>Stars: 5,379</p>
            <p>Forks: 578</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># XiaoMusic: Êó†ÈôêÂê¨Ê≠åÔºåËß£ÊîæÂ∞èÁà±Èü≥ÁÆ±

[![GitHub License](https://img.shields.io/github/license/hanxi/xiaomusic)](https://github.com/hanxi/xiaomusic)
[![Docker Image Version](https://img.shields.io/docker/v/hanxi/xiaomusic?sort=semver&amp;label=docker%20image)](https://hub.docker.com/r/hanxi/xiaomusic)
[![Docker Pulls](https://img.shields.io/docker/pulls/hanxi/xiaomusic)](https://hub.docker.com/r/hanxi/xiaomusic)
[![PyPI - Version](https://img.shields.io/pypi/v/xiaomusic)](https://pypi.org/project/xiaomusic/)
[![PyPI - Downloads](https://img.shields.io/pypi/dm/xiaomusic)](https://pypi.org/project/xiaomusic/)
[![Python Version from PEP 621 TOML](https://img.shields.io/python/required-version-toml?tomlFilePath=https%3A%2F%2Fraw.githubusercontent.com%2Fhanxi%2Fxiaomusic%2Fmain%2Fpyproject.toml)](https://pypi.org/project/xiaomusic/)
[![GitHub Release](https://img.shields.io/github/v/release/hanxi/xiaomusic)](https://github.com/hanxi/xiaomusic/releases)
[![Visitors](https://api.visitorbadge.io/api/daily?path=hanxi%2Fxiaomusic&amp;label=daily%20visitor&amp;countColor=%232ccce4&amp;style=flat)](https://visitorbadge.io/status?path=hanxi%2Fxiaomusic)
[![Visitors](https://api.visitorbadge.io/api/visitors?path=hanxi%2Fxiaomusic&amp;label=total%20visitor&amp;countColor=%232ccce4&amp;style=flat)](https://visitorbadge.io/status?path=hanxi%2Fxiaomusic)

‰ΩøÁî®Â∞èÁà±Èü≥ÁÆ±Êí≠ÊîæÈü≥‰πêÔºåÈü≥‰πê‰ΩøÁî® yt-dlp ‰∏ãËΩΩ„ÄÇ

&lt;https://github.com/hanxi/xiaomusic&gt;

ÊñáÊ°£: &lt;https://xdocs.hanxi.cc/&gt;

&gt; [!TIP]
&gt; ÂàùÊ¨°ÂÆâË£ÖÈÅáÂà∞ÈóÆÈ¢òËØ∑Êü•ÈòÖ [üí¨ FAQÈóÆÈ¢òÈõÜÂêà](https://github.com/hanxi/xiaomusic/issues/99) Ôºå‰∏ÄËà¨ÈÅáÂà∞ÁöÑÈóÆÈ¢òÈÉΩÂ∑≤ÁªèÊúâËß£ÂÜ≥ÂäûÊ≥ï„ÄÇ

## üëã ÊúÄÁÆÄÈÖçÁΩÆËøêË°å

Â∑≤ÁªèÊîØÊåÅÂú® web È°µÈù¢ÈÖçÁΩÆÂÖ∂‰ªñÂèÇÊï∞Ôºådocker ÂêØÂä®ÂëΩ‰ª§Â¶Ç‰∏ã:

```bash
docker run -p 58090:8090 -e XIAOMUSIC_PUBLIC_PORT=58090 -v /xiaomusic_music:/app/music -v /xiaomusic_conf:/app/conf hanxi/xiaomusic
```

üî• ÂõΩÂÜÖÔºö

```bash
docker run -p 58090:8090 -e XIAOMUSIC_PUBLIC_PORT=58090 -v /xiaomusic_music:/app/music -v /xiaomusic_conf:/app/conf docker.hanxi.cc/hanxi/xiaomusic
```

ÂØπÂ∫îÁöÑ docker compose ÈÖçÁΩÆÂ¶Ç‰∏ãÔºö

```yaml
services:
  xiaomusic:
    image: hanxi/xiaomusic
    container_name: xiaomusic
    restart: unless-stopped
    ports:
      - 58090:8090
    environment:
      XIAOMUSIC_PUBLIC_PORT: 58090
    volumes:
      - /xiaomusic_music:/app/music
      - /xiaomusic_conf:/app/conf
```

üî• ÂõΩÂÜÖÔºö

```yaml
services:
  xiaomusic:
    image: docker.hanxi.cc/hanxi/xiaomusic
    container_name: xiaomusic
    restart: unless-stopped
    ports:
      - 58090:8090
    environment:
      XIAOMUSIC_PUBLIC_PORT: 58090
    volumes:
      - /xiaomusic_music:/app/music
      - /xiaomusic_conf:/app/conf
```

- ÂÖ∂‰∏≠ conf ÁõÆÂΩï‰∏∫ÈÖçÁΩÆÊñá‰ª∂Â≠òÊîæÁõÆÂΩïÔºåmusic ÁõÆÂΩï‰∏∫Èü≥‰πêÂ≠òÊîæÁõÆÂΩïÔºåÂª∫ËÆÆÂàÜÂºÄÈÖçÁΩÆ‰∏∫‰∏çÂêåÁöÑÁõÆÂΩï„ÄÇ
- /xiaomusic_music Âíå /xiaomusic_conf ÊòØ docker ÊâÄÂú®ÁöÑ‰∏ªÊú∫ÁöÑÁõÆÂΩïÔºåÂèØ‰ª•‰øÆÊîπ‰∏∫ÂÖ∂‰ªñÁõÆÂΩï„ÄÇÂ¶ÇÊûúÊä•ÈîôÊâæ‰∏çÂà∞ /xiaomusic_music ÁõÆÂΩïÔºåÂèØ‰ª•ÂÖàÊâßË°å `mkdir -p /xiaomusic_{music,conf}` ÂëΩ‰ª§Êñ∞Âª∫ÁõÆÂΩï„ÄÇ
- /app/music Âíå /app/conf ÊòØ docker ÂÆπÂô®ÈáåÁöÑÁõÆÂΩïÔºå‰∏çË¶ÅÂéª‰øÆÊîπ„ÄÇ
- XIAOMUSIC_PUBLIC_PORT ÊòØÁî®Êù•ÈÖçÁΩÆ NAS Êú¨Âú∞Á´ØÂè£ÁöÑ„ÄÇ8090 ÊòØÂÆπÂô®Á´ØÂè£Ôºå‰∏çË¶ÅÂéª‰øÆÊîπ„ÄÇ
- ÂêéÂè∞ËÆøÈóÆÂú∞ÂùÄ‰∏∫Ôºö http://NAS_IP:58090

&gt; [!NOTE]
&gt; docker Âíå docker compose ‰∫åÈÄâ‰∏ÄÂç≥ÂèØÔºåÂêØÂä®ÊàêÂäüÂêéÔºåÂú® web È°µÈù¢ÂèØ‰ª•ÈÖçÁΩÆÂÖ∂‰ªñÂèÇÊï∞ÔºåÂ∏¶Êúâ `*` Âè∑ÁöÑÈÖçÁΩÆÊòØÂøÖÈ°ªË¶ÅÈÖçÁΩÆÁöÑÔºåÂÖ∂‰ªñÁöÑÁî®‰∏ç‰∏äÊó∂‰∏çÁî®‰øÆÊîπ„ÄÇÂàùÊ¨°ÈÖçÁΩÆÊó∂ÈúÄË¶ÅÂú®È°µÈù¢‰∏äËæìÂÖ•Â∞èÁ±≥Ë¥¶Âè∑ÂíåÂØÜÁ†Å‰øùÂ≠òÂêéÊâçËÉΩËé∑ÂèñÂà∞ËÆæÂ§áÂàóË°®„ÄÇ

&gt; [!TIP]
&gt; ÁõÆÂâçÂÆâË£ÖÊ≠•È™§Â∑≤ÁªèÊòØÊúÄÁÆÄÂåñ‰∫ÜÔºåÂ¶ÇÊûúËøòÊòØÂ´åÂÆâË£ÖÈ∫ªÁÉ¶ÔºåÂèØ‰ª•ÂæÆ‰ø°ÊàñËÄÖ QQ Á∫¶ÊàëËøúÁ®ãÂÆâË£ÖÔºåÊàë‰∏ÄËà¨Âë®Êú´ÂíåÊôö‰∏äÊâçÊúâÊó∂Èó¥ÔºåÈúÄË¶ÅËµûÂä©‰∏™ËæõËã¶Ë¥π :moneybag: 50 ÂÖÉ‰∏ÄÊ¨°„ÄÇ

ÈÅáÂà∞ÈóÆÈ¢òÂèØ‰ª•Âéª web ËÆæÁΩÆÈ°µÈù¢Â∫ïÈÉ®ÁÇπÂáª„Äê‰∏ãËΩΩÊó•ÂøóÊñá‰ª∂„ÄëÊåâÈíÆÔºåÁÑ∂ÂêéÊêúÁ¥¢‰∏Ä‰∏ãÊó•ÂøóÊñá‰ª∂ÂÜÖÂÆπÁ°Æ‰øùÈáåÈù¢Ê≤°ÊúâË¥¶Âè∑ÂØÜÁ†Å‰ø°ÊÅØÂêé(ÊúâÂ∞±Âà†Èô§Ëøô‰∫õÊïèÊÑü‰ø°ÊÅØ)ÔºåÁÑ∂ÂêéÂú®Êèê issues ÂèçÈ¶àÈóÆÈ¢òÊó∂Êää‰∏ãËΩΩÁöÑÊó•ÂøóÊñá‰ª∂Â∏¶‰∏ä„ÄÇ

&gt; [!TIP]
&gt; ‰ΩúËÄÖÁöÑÂè¶‰∏Ä‰∏™ÈÄÇÁî®‰∫é NAS ‰∏äÂÆâË£ÖÁöÑÂºÄÊ∫êÂ∑•ÂÖ∑Ôºö &lt;https://github.com/hanxi/tiny-nav&gt;

&gt; [!TIP]
&gt;
&gt; ÂñúÊ¨¢Âê¨‰π¶ÁöÑÂèØ‰ª•ÈÖçÂêàËøô‰∏™Â∑•ÂÖ∑‰ΩøÁî® &lt;https://github.com/hanxi/epub2mp3&gt;

&gt; [!TIP]
&gt;
&gt; - üî•„ÄêÂπøÂëä:ÂèØÁî®‰∫éÂÆâË£Ö frp ÂÆûÁé∞ÂÜÖÁΩëÁ©øÈÄè„Äë
&gt; - üî• Êµ∑Â§ñ RackNerd VPS Êú∫Âô®Êé®ËçêÔºåÂèØÊîØ‰ªòÂÆù‰ªòÊ¨æ„ÄÇ
&gt; - &lt;a href=&quot;https://my.racknerd.com/aff.php?aff=11177&quot;&gt;&lt;img src=&quot;https://racknerd.com/banners/320x50.gif&quot; alt=&quot;RackNerd Mobile Leaderboard Banner&quot; width=&quot;320&quot; height=&quot;50&quot;&gt;&lt;/a&gt;
&gt; - ‰∏çÁü•ÈÅìÈÄâÂì™‰∏™Â•óÈ§êÂèØ‰ª•Áõ¥Êé•‰π∞Ëøô‰∏™ÊúÄ‰æøÂÆúÁöÑ &lt;https://my.racknerd.com/aff.php?aff=11177&amp;pid=912&gt;
&gt; - ‰πüÂèØ‰ª•Áî®Êù•ÈÉ®ÁΩ≤‰ª£ÁêÜÔºådocker ÈÉ®ÁΩ≤ÊñπÊ≥ïËßÅ &lt;https://github.com/hanxi/blog/issues/96&gt;

&gt; [!TIP]
&gt;
&gt; - üî•„ÄêÂπøÂëä: Êê≠Âª∫ÊÇ®ÁöÑ‰∏ìÂ±ûÂ§ßÊ®°Âûã‰∏ªÈ°µ
ÂëäÂà´ÁπÅÁêêÈÖçÁΩÆÈöæÈ¢òÔºå‰∏ÄÈîÆÂç≥ÂèØÁïÖ‰∫´Á®≥ÂÆöÊµÅÁïÖÁöÑAI‰ΩìÈ™åÔºÅ„Äë&lt;https://university.aliyun.com/mobile?userCode=szqvatm6&gt;

&gt; [!TIP]
&gt; - ÂÖçË¥π‰∏ªÊú∫
&gt; - &lt;a href=&quot;https://dartnode.com?aff=SnappyPigeon570&quot;&gt;&lt;img src=&quot;https://dartnode.com/branding/DN-Open-Source-sm.png&quot; alt=&quot;Powered by DartNode - Free VPS for Open Source&quot; width=&quot;320&quot;&gt;&lt;/a&gt;


### ü§ê ÊîØÊåÅËØ≠Èü≥Âè£‰ª§

- „ÄêÊí≠ÊîæÊ≠åÊõ≤„ÄëÔºåÊí≠ÊîæÊú¨Âú∞ÁöÑÊ≠åÊõ≤
- „ÄêÊí≠ÊîæÊ≠åÊõ≤+Ê≠åÂêç„ÄëÔºåÊØîÂ¶ÇÔºöÊí≠ÊîæÊ≠åÊõ≤Âë®Êù∞‰º¶Êô¥Â§©
- „Äê‰∏ä‰∏ÄÈ¶ñ„Äë
- „Äê‰∏ã‰∏ÄÈ¶ñ„Äë
- „ÄêÂçïÊõ≤Âæ™ÁéØ„Äë
- „ÄêÂÖ®ÈÉ®Âæ™ÁéØ„Äë
- „ÄêÈöèÊú∫Êí≠Êîæ„Äë
- „ÄêÂÖ≥Êú∫„ÄëÔºå„ÄêÂÅúÊ≠¢Êí≠Êîæ„ÄëÔºå‰∏§‰∏™ÊïàÊûúÊòØ‰∏ÄÊ†∑ÁöÑ„ÄÇ
- „ÄêÂà∑Êñ∞ÂàóË°®„ÄëÔºåÂΩìÂ§çÂà∂‰∫ÜÊ≠åÊõ≤Ëøõ music ÁõÆÂΩïÂêéÔºåÂèØ‰ª•Áî®Ëøô‰∏™Âè£‰ª§Âà∑Êñ∞Ê≠åÂçï„ÄÇ
- „ÄêÊí≠ÊîæÂàóË°®+ÂàóË°®Âêç„ÄëÔºåÊØîÂ¶ÇÔºöÊí≠ÊîæÂàóË°®ÂÖ∂‰ªñ„ÄÇ
- „ÄêÂä†ÂÖ•Êî∂Ëóè„ÄëÔºåÊääÂΩìÂâçÊí≠ÊîæÁöÑÊ≠åÊõ≤Âä†ÂÖ•Êî∂ËóèÊ≠åÂçï„ÄÇ
- „ÄêÂèñÊ∂àÊî∂Ëóè„ÄëÔºåÊääÂΩìÂâçÊí≠ÊîæÁöÑÊ≠åÊõ≤‰ªéÊî∂ËóèÊ≠åÂçïÈáåÁßªÈô§„ÄÇ
- „ÄêÊí≠ÊîæÂàóË°®Êî∂Ëóè„ÄëÔºåËøô‰∏™Áî®‰∫éÊí≠ÊîæÊî∂ËóèÊ≠åÂçï„ÄÇ
- ~„ÄêÊí≠ÊîæÊú¨Âú∞Ê≠åÊõ≤+Ê≠åÂêç„ÄëÔºåËøô‰∏™Âè£‰ª§ÂíåÊí≠ÊîæÊ≠åÊõ≤ÁöÑÂå∫Âà´ÊòØÊú¨Âú∞Êâæ‰∏çÂà∞‰πü‰∏ç‰ºöÂéª‰∏ãËΩΩ„ÄÇ~
- „ÄêÊí≠ÊîæÂàóË°®Á¨¨Âá†‰∏™+ÂàóË°®Âêç„ÄëÔºåÂÖ∑‰ΩìËßÅÔºö &lt;https://github.com/hanxi/xiaomusic/issues/158&gt;
- „ÄêÊêúÁ¥¢Êí≠Êîæ+ÂÖ≥ÈîÆËØç„ÄëÔºå‰ºöÊêúÁ¥¢ÂÖ≥ÈîÆËØç‰Ωú‰∏∫‰∏¥Êó∂ÊêúÁ¥¢ÂàóË°®Êí≠ÊîæÔºåÊØîÂ¶ÇËØ¥„ÄêÊêúÁ¥¢Êí≠ÊîæÊûó‰øäÊù∞„ÄëÔºå‰ºöÊí≠ÊîæÊâÄÊúâÊûó‰øäÊù∞ÁöÑÊ≠å„ÄÇ
- „ÄêÊú¨Âú∞ÊêúÁ¥¢Êí≠Êîæ+ÂÖ≥ÈîÆËØç„ÄëÔºåË∑üÊêúÁ¥¢Êí≠ÊîæÁöÑÂå∫Âà´ÊòØÊú¨Âú∞Êâæ‰∏çÂà∞‰πü‰∏ç‰ºöÂéª‰∏ãËΩΩ„ÄÇ

&gt; [!TIP]
&gt; ÈöêËóèÁé©Ê≥ï: ÂØπÂ∞èÁà±ÂêåÂ≠¶ËØ¥Êí≠ÊîæÊ≠åÊõ≤Â∞èÁå™‰Ω©Â•áÁöÑÊïÖ‰∫ãÔºå‰ºöÂÖà‰∏ãËΩΩÂ∞èÁå™‰Ω©Â•áÁöÑÊïÖ‰∫ãÔºåÁÑ∂ÂêéÂÜçÊí≠ÊîæÂ∞èÁå™‰Ω©Â•áÁöÑÊïÖ‰∫ã„ÄÇ

## üõ†Ô∏è pip ÊñπÂºèÂÆâË£ÖËøêË°å

```shell
&gt; pip install -U xiaomusic
&gt; xiaomusic --help
 __  __  _                   __  __                 _
 \ \/ / (_)   __ _    ___   |  \/  |  _   _   ___  (_)   ___
  \  /  | |  / _` |  / _ \  | |\/| | | | | | / __| | |  / __|
  /  \  | | | (_| | | (_) | | |  | | | |_| | \__ \ | | | (__
 /_/\_\ |_|  \__,_|  \___/  |_|  |_|  \__,_| |___/ |_|  \___|
          XiaoMusic v0.3.69 by: github.com/hanxi

usage: xiaomusic [-h] [--port PORT] [--hardware HARDWARE] [--account ACCOUNT]
                 [--password PASSWORD] [--cookie COOKIE] [--verbose]
                 [--config CONFIG] [--ffmpeg_location FFMPEG_LOCATION]

options:
  -h, --help            show this help message and exit
  --port PORT           ÁõëÂê¨Á´ØÂè£
  --hardware HARDWARE   Â∞èÁà±Èü≥ÁÆ±ÂûãÂè∑
  --account ACCOUNT     xiaomi account
  --password PASSWORD   xiaomi password
  --cookie COOKIE       xiaomi cookie
  --verbose             show info
  --config CONFIG       config file path
  --ffmpeg_location FFMPEG_LOCATION
                        ffmpeg bin path
&gt; xiaomusic --config config.json
```

ÂÖ∂‰∏≠ `config.json` Êñá‰ª∂ÂèØ‰ª•ÂèÇËÄÉ `config-example.json` Êñá‰ª∂ÈÖçÁΩÆ„ÄÇËßÅ &lt;https://github.com/hanxi/xiaomusic/issues/94&gt;

‰∏ç‰øÆÊîπÈªòËÆ§Á´ØÂè£ 8090 ÁöÑÊÉÖÂÜµ‰∏ãÔºåÂè™ÈúÄË¶ÅÊâßË°å `xiaomusic` Âç≥ÂèØÂêØÂä®„ÄÇ

## üî© ÂºÄÂèëÁéØÂ¢ÉËøêË°å

- ‰ΩøÁî® install_dependencies.sh ‰∏ãËΩΩ‰æùËµñ
- ‰ΩøÁî® pdm ÂÆâË£ÖÁéØÂ¢É
- ÈªòËÆ§ÁõëÂê¨‰∫ÜÁ´ØÂè£ 8090 , ‰ΩøÁî®ÂÖ∂‰ªñÁ´ØÂè£Ëá™Ë°å‰øÆÊîπ„ÄÇ

```shell
pdm run xiaomusic.py
````

Â¶ÇÊûúÊòØÂºÄÂèëÂâçÁ´ØÁïåÈù¢ÔºåÂèØ‰ª•ÈÄöËøá &lt;http://localhost:8090/docs&gt;
Êü•ÁúãÊúâ‰ªÄ‰πàÊé•Âè£„ÄÇÁõÆÂâçÁöÑ web ÊéßÂà∂Âè∞ÈùûÂ∏∏ÁÆÄÈôãÔºåÊ¨¢ËøéÊúâÂÖ¥Ë∂£ÁöÑÊúãÂèãÂ∏ÆÂøôÂÆûÁé∞‰∏Ä‰∏™ÊºÇ‰∫ÆÁöÑÂâçÁ´ØÔºåÈúÄË¶Å‰ªÄ‰πàÊé•Âè£ÂèØ‰ª•ÈöèÊó∂ÊèêÈúÄÊ±Ç„ÄÇ

### üö¶ ‰ª£Á†ÅÊèê‰∫§ËßÑËåÉ

Êèê‰∫§ÂâçËØ∑ÊâßË°å

```
pdm lintfmt
```

Áî®‰∫éÊ£ÄÊü•‰ª£Á†ÅÂíåÊ†ºÂºèÂåñ‰ª£Á†Å„ÄÇ

### Êú¨Âú∞ÁºñËØë Docker Image

```shell
docker build -t xiaomusic .
```

### ÊäÄÊúØÊ†à

- ÂêéÁ´Ø‰ª£Á†Å‰ΩøÁî® Python ËØ≠Ë®ÄÁºñÂÜô„ÄÇ
- HTTP ÊúçÂä°‰ΩøÁî®ÁöÑÊòØ FastAPI Ê°ÜÊû∂Ôºå~~Êó©ÊúüÁâàÊú¨‰ΩøÁî®ÁöÑÊòØ Flask~~„ÄÇ
- ‰ΩøÁî®‰∫Ü Docker ÔºåÂú® NAS ‰∏äÂÆâË£ÖÊõ¥Êñπ‰æø„ÄÇ
- ÈªòËÆ§ÁöÑÂâçÁ´Ø‰∏ªÈ¢ò‰ΩøÁî®‰∫Ü jQuery „ÄÇ

## Â∑≤ÊµãËØïÊîØÊåÅÁöÑËÆæÂ§á

| ÂûãÂè∑   | ÂêçÁß∞                                                                                             |
| ---- | ---------------------------------------------------------------------------------------------- |
| L06A | [Â∞èÁà±Èü≥ÁÆ±](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.l06a)             |
| L07A | [RedmiÂ∞èÁà±Èü≥ÁÆ± Play](https://home.mi.com/webapp/content/baike/product/index.html?model=xiaomi.wifispeaker.l7a)                     |
| S12/S12A/MDZ-25-DA | [Â∞èÁ±≥AIÈü≥ÁÆ±](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.s12)            |
| LX5A | [Â∞èÁà±Èü≥ÁÆ± ‰∏áËÉΩÈÅ•ÊéßÁâà](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.lx5a)       |
| LX05 | [Â∞èÁà±Èü≥ÁÆ±PlayÔºà2019Ê¨æÔºâ](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.lx05)  |
| L15A | [Â∞èÁ±≥AIÈü≥ÁÆ±ÔºàÁ¨¨‰∫å‰ª£Ôºâ](https://home.mi.com/webapp/content/baike/product/index.html?model=xiaomi.wifispeaker.l15a#/) |
| L16A | [Xiaomi Sound](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.l16a)     |
| L17A | [Xiaomi Sound Pro](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.l17a) |
| LX06 | [Â∞èÁà±Èü≥ÁÆ±Pro](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.lx06)          |
| LX01 | [Â∞èÁà±Èü≥ÁÆ±mini](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.lx01)         |
| L05B | [Â∞èÁà±Èü≥ÁÆ±Play](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.l05b)         |
| L05C | [Â∞èÁ±≥Â∞èÁà±Èü≥ÁÆ±Play Â¢ûÂº∫Áâà](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.l05c)   |
| L09A | [Â∞èÁ±≥Èü≥ÁÆ±Art](https://home.mi.com/webapp/content/baike/product/index.html?model=xiaomi.wifispeaker.l09a) |
| LX04 X10A X08A | Â∑≤ÁªèÊîØÊåÅÁöÑËß¶Â±èÁâà |
| X08C X08E X8F | Â∑≤Áªè‰∏çÈúÄË¶ÅËÆæÁΩÆ‰∫Ü. ~ÈúÄË¶ÅËÆæÁΩÆ„ÄêÂûãÂè∑ÂÖºÂÆπÊ®°Âºè„ÄëÈÄâÈ°π‰∏∫ true~ |
| M01/XMYX01JY | Â∞èÁ±≥Â∞èÁà±Èü≥ÁÆ±HD ÈúÄË¶ÅËÆæÁΩÆ„ÄêÁâπÊÆäÂûãÂè∑Ëé∑ÂèñÂØπËØùËÆ∞ÂΩï„ÄëÈÄâÈ°π‰∏∫ true ÊâçËÉΩËØ≠Èü≥Êí≠Êîæ|
| OH2P | XIAOMI Êô∫ËÉΩÈü≥ÁÆ± Pro |
| OH2 | XIAOMI Êô∫ËÉΩÈü≥ÁÆ± |

ÂûãÂè∑‰∏é‰∫ßÂìÅÂêçÁß∞ÂØπÁÖßÂèØ‰ª•Âú®ËøôÈáåÊü•ËØ¢ &lt;https://home.miot-spec.com/s/xiaomi.wifispeaker&gt;

&gt; [!NOTE]
&gt; Â¶ÇÊûú‰Ω†ÁöÑËÆæÂ§áÊîØÊåÅÊí≠ÊîæÔºåËØ∑ÂèçÈ¶àÁªôÊàëÊ∑ªÂä†Âà∞ÊîØÊåÅÂàóË°®ÈáåÔºåË∞¢Ë∞¢„ÄÇ
&gt; ÁõÆÂâçÂ∫îËØ•ÊâÄÊúâËÆæÂ§áÁ±ªÂûãÈÉΩÂ∑≤ÁªèÊîØÊåÅÊí≠ÊîæÔºåÊúâÈóÆÈ¢òÈöèÊó∂ÂèçÈ¶à„ÄÇ
&gt; ÂÖ∂‰ªñËß¶Â±èÁâà‰∏çËÉΩÊí≠ÊîæÂèØ‰ª•ËÆæÁΩÆ„ÄêÂûãÂè∑ÂÖºÂÆπÊ®°Âºè„ÄëÈÄâÈ°π‰∏∫ true ËØïËØï„ÄÇËßÅ &lt;https://github.com/hanxi/xiaomusic/issues/30&gt;

## üéµ ÊîØÊåÅÈü≥‰πêÊ†ºÂºè

- mp3
- flac
- wav
- ape
- ogg
- m4a

&gt; [!NOTE]
&gt; Êú¨Âú∞Èü≥‰πê‰ºöÊêúÁ¥¢ÁõÆÂΩï‰∏ã‰∏äÈù¢Ê†ºÂºèÁöÑÊñá‰ª∂Ôºå‰∏ãËΩΩÁöÑÊ≠åÊõ≤ÊòØ mp3 Ê†ºÂºèÁöÑ„ÄÇ
&gt; Â∑≤Áü• L05B L05C LX06 L16A ‰∏çÊîØÊåÅ flac Ê†ºÂºè„ÄÇ
&gt; Â¶ÇÊûúÊ†ºÂºè‰∏çËÉΩÊí≠ÊîæÂèØ‰ª•ÊâìÂºÄ„ÄêËΩ¨Êç¢‰∏∫MP3„ÄëÂíå„ÄêÂûãÂè∑ÂÖºÂÆπÊ®°Âºè„ÄëÈÄâÈ°π„ÄÇÂÖ∑‰ΩìËßÅ &lt;https://github.com/hanxi/xiaomusic/issues/153#issuecomment-2328168689&gt;

## üåè ÁΩëÁªúÊ≠åÂçïÂäüËÉΩ

ÂèØ‰ª•ÈÖçÁΩÆ‰∏Ä‰∏™ json Ê†ºÂºèÁöÑÊ≠åÂçïÔºåÊîØÊåÅÁîµÂè∞ÂíåÊ≠åÊõ≤Ôºå‰πüÂèØ‰ª•Áõ¥Êé•Áî®Âà´‰∫∫ÂàÜ‰∫´ÁöÑÈìæÊé•ÔºåÂêåÊó∂ÈÖçÂ§á‰∫Ü m3u Êñá‰ª∂Ê†ºÂºèËΩ¨Êç¢Â∑•ÂÖ∑ÔºåÂèØ‰ª•ÂæàÊñπ‰æøÁöÑÊää m3u ÁîµÂè∞Êñá‰ª∂ËΩ¨Êç¢ÊàêÁΩëÁªúÊ≠åÂçïÊ†ºÂºèÁöÑ json Êñá‰ª∂ÔºåÂÖ∑‰ΩìÁî®Ê≥ïËßÅ  &lt;https://github.com/hanxi/xiaomusic/issues/78&gt;

&gt; [!NOTE]
&gt; Ê¨¢ËøéÊúâÊÉ≥Ê≥ïÁöÑÊúãÂèã‰ª¨Âà∂‰ΩúÊõ¥Â§öÁöÑÊ≠åÂçïËΩ¨Êç¢Â∑•ÂÖ∑„ÄÇ

## üç∫ Êõ¥Â§öÂÖ∂‰ªñÂèØÈÄâÈÖçÁΩÆ

ËßÅ &lt;https://github.com/hanxi/xiaomusic/issues/333&gt;

## ‚ö†Ô∏è ÂÆâÂÖ®ÊèêÈÜí

&gt; [!IMPORTANT]
&gt;
&gt; 1. Â¶ÇÊûúÈÖçÁΩÆ‰∫ÜÂÖ¨ÁΩëËÆøÈóÆ xiaomusic ÔºåËØ∑‰∏ÄÂÆöË¶ÅÂºÄÂêØÂØÜÁ†ÅÁôªÈôÜÔºåÂπ∂ËÆæÁΩÆÂ§çÊùÇÁöÑÂØÜÁ†Å„ÄÇ‰∏î‰∏çË¶ÅÂú®ÂÖ¨ÂÖ±Âú∫ÊâÄÁöÑ WiFi ÁéØÂ¢É‰∏ã‰ΩøÁî®ÔºåÂê¶ÂàôÂèØËÉΩÈÄ†ÊàêÂ∞èÁ±≥Ë¥¶Âè∑ÂØÜÁ†ÅÊ≥ÑÈú≤„ÄÇ
&gt; 2. Âº∫ÁÉà‰∏çÂª∫ËÆÆÂ∞ÜÂ∞èÁà±Èü≥ÁÆ±ÁöÑÂ∞èÁ±≥Ë¥¶Âè∑ÁªëÂÆöÊëÑÂÉèÂ§¥Ôºå‰ª£Á†ÅÈöæÂÖç‰ºöÊúâ bug Ôºå‰∏ÄÊó¶Â∞èÁ±≥Ë¥¶Âè∑ÂØÜÁ†ÅÊ≥ÑÈú≤ÔºåÂèØËÉΩÁõëÊéßÂΩïÂÉè‰πü‰ºöÊ≥ÑÈú≤„ÄÇ

## ü§î È´òÁ∫ßÁØá

- Ëá™ÂÆö‰πâÂè£‰ª§ÂäüËÉΩ &lt;https://github.com/hanxi/xiaomusic/issues/105&gt;
- &lt;https://github.com/hanxi/xiaomusic/issues/312&gt;
- &lt;https://github.com/hanxi/xiaomusic/issues/269&gt;
- &lt;https://github.com/hanxi/xiaomusic/issues/159&gt;

## üì¢ ËÆ®ËÆ∫Âå∫

- [ÁÇπÂáªÈìæÊé•Âä†ÂÖ•QQÈ¢ëÈÅì„Äêxiaomusic„Äë](https://pd.qq.com/s/e2jybz0ss)
- [ÁÇπÂáªÈìæÊé•Âä†ÂÖ•Áæ§ËÅä„ÄêÊª° xiaomusicÂÆòÊñπ‰∫§ÊµÅÁæ§1(Â∞èÁà±Èü≥ÁÆ±)„Äë 604526973](http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&amp;k=13St5PLVcTxYlWTAs_iAawazjtdD1l-a&amp;authKey=dJWEpaT2fDBDpdUUOWj%2FLt6NS1ePBfShDfz7a6seNURi05VvVnAGQzXF%2FM%2F5HgIm&amp;noverify=0&amp;group_code=604526973)
- [ÁÇπÂáªÈìæÊé•Âä†ÂÖ•Áæ§ËÅä„ÄêxiaomusicÂÆòÊñπ‰∫§ÊµÅÁæ§2(Â∞èÁà±Èü≥ÁÆ±)„Äë1021062499](https://qm.qq.com/q/BmVNqhDL3M)
- &lt;https://github.com/hanxi/xiaomusic/issues&gt;
- [ÂæÆ‰ø°Áæ§‰∫åÁª¥Á†Å](https://github.com/hanxi/xiaomusic/issues/86)

## ‚ù§Ô∏è ÊÑüË∞¢

- [xiaomi](https://www.mi.com/)
- [PDM](https://pdm.fming.dev/latest/)
- [xiaogpt](https://github.com/yihong0618/xiaogpt)
- [MiService](https://github.com/yihong0618/MiService)
- [ÂÆûÁé∞ÂéüÁêÜ](https://github.com/yihong0618/gitblog/issues/258)
- [yt-dlp](https://github.com/yt-dlp/yt-dlp)
- [awesome-xiaoai](https://github.com/zzz6519003/awesome-xiaoai)
- [ÂæÆ‰ø°Â∞èÁ®ãÂ∫è: ÂçØÂçØÈü≥‰πê](https://github.com/F-loat/xiaoplayer)
- [pure ‰∏ªÈ¢ò xiaomusicUI](https://github.com/52fisher/xiaomusicUI)
- [ÁßªÂä®Á´ØÁöÑÊí≠ÊîæÂô®‰∏ªÈ¢ò](https://github.com/52fisher/XMusicPlayer)
- [Tailwind‰∏ªÈ¢ò](https://github.com/clarencejh/xiaomusic)
- [‰∏Ä‰∏™Á¨¨‰∏âÊñπÁöÑ‰∏ªÈ¢ò](https://github.com/DarrenWen/xiaomusicui)
- [Umami ÁªüËÆ°](https://github.com/umami-software/umami)
- [Sentry Êä•ÈîôÁõëÊéß](https://github.com/getsentry/sentry)
- ÊâÄÊúâÂ∏ÆÂøôË∞ÉËØïÂíåÊµãËØïÁöÑÊúãÂèã
- ÊâÄÊúâÂèçÈ¶àÈóÆÈ¢òÂíåÂª∫ËÆÆÁöÑÊúãÂèã

### üëâ ÂÖ∂‰ªñÊïôÁ®ã

Êõ¥Â§öÂäüËÉΩËßÅ [üìù ÊñáÊ°£Ê±áÊÄª](https://github.com/hanxi/xiaomusic/issues/211)

## üö® ÂÖçË¥£Â£∞Êòé

Êú¨È°πÁõÆ‰ªÖ‰æõÂ≠¶‰π†ÂíåÁ†îÁ©∂ÁõÆÁöÑÔºå‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öÊ¥ªÂä®„ÄÇÁî®Êà∑Âú®‰ΩøÁî®Êú¨È°πÁõÆÊó∂Â∫îÈÅµÂÆàÊâÄÂú®Âú∞Âå∫ÁöÑÊ≥ïÂæãÊ≥ïËßÑÔºåÂØπ‰∫éËøùÊ≥ï‰ΩøÁî®ÊâÄÂØºËá¥ÁöÑÂêéÊûúÔºåÊú¨È°πÁõÆÂèä‰ΩúËÄÖ‰∏çÊâøÊãÖ‰ªª‰ΩïË¥£‰ªª„ÄÇ
Êú¨È°πÁõÆÂèØËÉΩÂ≠òÂú®Êú™Áü•ÁöÑÁº∫Èô∑ÂíåÈ£éÈô©ÔºàÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éËÆæÂ§áÊçüÂùèÂíåË¥¶Âè∑Â∞ÅÁ¶ÅÁ≠âÔºâÔºå‰ΩøÁî®ËÄÖÂ∫îËá™Ë°åÊâøÊãÖ‰ΩøÁî®Êú¨È°πÁõÆÊâÄ‰∫ßÁîüÁöÑÊâÄÊúâÈ£éÈô©ÂèäË¥£‰ªª„ÄÇ
‰ΩúËÄÖ‰∏ç‰øùËØÅÊú¨È°πÁõÆÁöÑÂáÜÁ°ÆÊÄß„ÄÅÂÆåÊï¥ÊÄß„ÄÅÂèäÊó∂ÊÄß„ÄÅÂèØÈù†ÊÄßÔºå‰πü‰∏çÊâøÊãÖ‰ªª‰ΩïÂõ†‰ΩøÁî®Êú¨È°πÁõÆËÄå‰∫ßÁîüÁöÑ‰ªª‰ΩïÊçüÂ§±ÊàñÊçüÂÆ≥Ë¥£‰ªª„ÄÇ
‰ΩøÁî®Êú¨È°πÁõÆÂç≥Ë°®Á§∫ÊÇ®Â∑≤ÈòÖËØªÂπ∂ÂêåÊÑèÊú¨ÂÖçË¥£Â£∞ÊòéÁöÑÂÖ®ÈÉ®ÂÜÖÂÆπ„ÄÇ

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=hanxi/xiaomusic&amp;type=Date)](https://star-history.com/#hanxi/xiaomusic&amp;Date)

## ËµûËµè

- :moneybag: Áà±ÂèëÁîµ &lt;https://afdian.com/a/imhanxi&gt;
- ÁÇπ‰∏™ Star :star:
- Ë∞¢Ë∞¢ :heart:
- ![ÂñùÊùØÂ•∂Ëå∂](https://i.v2ex.co/7Q03axO5l.png)

## License

[MIT](https://github.com/hanxi/xiaomusic/blob/main/LICENSE) License ¬© 2024 Ê∂µÊõ¶
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[cheahjs/free-llm-api-resources]]></title>
            <link>https://github.com/cheahjs/free-llm-api-resources</link>
            <guid>https://github.com/cheahjs/free-llm-api-resources</guid>
            <pubDate>Tue, 16 Sep 2025 00:04:15 GMT</pubDate>
            <description><![CDATA[A list of free LLM inference resources accessible via API.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cheahjs/free-llm-api-resources">cheahjs/free-llm-api-resources</a></h1>
            <p>A list of free LLM inference resources accessible via API.</p>
            <p>Language: Python</p>
            <p>Stars: 5,501</p>
            <p>Forks: 485</p>
            <p>Stars today: 33 stars today</p>
            <h2>README</h2><pre>&lt;!---
WARNING: DO NOT EDIT THIS FILE DIRECTLY. IT IS GENERATED BY src/pull_available_models.py
---&gt;
# Free LLM API resources

This lists various services that provide free access or credits towards API-based LLM usage.

&gt; [!NOTE]  
&gt; Please don&#039;t abuse these services, else we might lose them.

&gt; [!WARNING]  
&gt; This list explicitly excludes any services that are not legitimate (eg reverse engineers an existing chatbot)

- [Free Providers](#free-providers)
  - [OpenRouter](#openrouter)
  - [Google AI Studio](#google-ai-studio)
  - [NVIDIA NIM](#nvidia-nim)
  - [Mistral (La Plateforme)](#mistral-la-plateforme)
  - [Mistral (Codestral)](#mistral-codestral)
  - [HuggingFace Inference Providers](#huggingface-inference-providers)
  - [Vercel AI Gateway](#vercel-ai-gateway)
  - [Cerebras](#cerebras)
  - [Groq](#groq)
  - [Together (Free)](#together-free)
  - [Cohere](#cohere)
  - [GitHub Models](#github-models)
  - [Cloudflare Workers AI](#cloudflare-workers-ai)
  - [Google Cloud Vertex AI](#google-cloud-vertex-ai)
- [Providers with trial credits](#providers-with-trial-credits)
  - [Together](#together)
  - [Fireworks](#fireworks)
  - [Baseten](#baseten)
  - [Nebius](#nebius)
  - [Novita](#novita)
  - [AI21](#ai21)
  - [Upstage](#upstage)
  - [NLP Cloud](#nlp-cloud)
  - [Alibaba Cloud (International) Model Studio](#alibaba-cloud-international-model-studio)
  - [Modal](#modal)
  - [Inference.net](#inferencenet)
  - [nCompass](#ncompass)
  - [Hyperbolic](#hyperbolic)
  - [SambaNova Cloud](#sambanova-cloud)
  - [Scaleway Generative APIs](#scaleway-generative-apis)

## Free Providers

### [OpenRouter](https://openrouter.ai)

**Limits:**

[20 requests/minute&lt;br&gt;50 requests/day&lt;br&gt;1000 requests/day with $10 lifetime topup](https://openrouter.ai/docs/api-reference/limits)

Models share a common quota.

- [DeepCoder 14B Preview](https://openrouter.ai/agentica-org/deepcoder-14b-preview:free)
- [DeepHermes 3 Llama 3 8B Preview](https://openrouter.ai/nousresearch/deephermes-3-llama-3-8b-preview:free)
- [DeepSeek R1](https://openrouter.ai/deepseek/deepseek-r1:free)
- [DeepSeek R1 Distill Llama 70B](https://openrouter.ai/deepseek/deepseek-r1-distill-llama-70b:free)
- [DeepSeek R1 Distill Qwen 14B](https://openrouter.ai/deepseek/deepseek-r1-distill-qwen-14b:free)
- [DeepSeek V3 0324](https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free)
- [Dolphin 3.0 Mistral 24B](https://openrouter.ai/cognitivecomputations/dolphin3.0-mistral-24b:free)
- [Dolphin 3.0 R1 Mistral 24B](https://openrouter.ai/cognitivecomputations/dolphin3.0-r1-mistral-24b:free)
- [Gemma 2 9B Instruct](https://openrouter.ai/google/gemma-2-9b-it:free)
- [Gemma 3 12B Instruct](https://openrouter.ai/google/gemma-3-12b-it:free)
- [Gemma 3 27B Instruct](https://openrouter.ai/google/gemma-3-27b-it:free)
- [Gemma 3 4B Instruct](https://openrouter.ai/google/gemma-3-4b-it:free)
- [Kimi VL A3B Thinking](https://openrouter.ai/moonshotai/kimi-vl-a3b-thinking:free)
- [Llama 3.1 405B Instruct](https://openrouter.ai/meta-llama/llama-3.1-405b-instruct:free)
- [Llama 3.1 Nemotron Ultra 253B v1](https://openrouter.ai/nvidia/llama-3.1-nemotron-ultra-253b-v1:free)
- [Llama 3.2 3B Instruct](https://openrouter.ai/meta-llama/llama-3.2-3b-instruct:free)
- [Llama 3.3 70B Instruct](https://openrouter.ai/meta-llama/llama-3.3-70b-instruct:free)
- [Llama 4 Maverick](https://openrouter.ai/meta-llama/llama-4-maverick:free)
- [Llama 4 Scout](https://openrouter.ai/meta-llama/llama-4-scout:free)
- [Mistral 7B Instruct](https://openrouter.ai/mistralai/mistral-7b-instruct:free)
- [Mistral Nemo](https://openrouter.ai/mistralai/mistral-nemo:free)
- [Mistral Small 24B Instruct 2501](https://openrouter.ai/mistralai/mistral-small-24b-instruct-2501:free)
- [Mistral Small 3.1 24B Instruct](https://openrouter.ai/mistralai/mistral-small-3.1-24b-instruct:free)
- [QwQ 32B ArliAI RpR v1](https://openrouter.ai/arliai/qwq-32b-arliai-rpr-v1:free)
- [Qwen 2.5 72B Instruct](https://openrouter.ai/qwen/qwen-2.5-72b-instruct:free)
- [Qwen 2.5 VL 32B Instruct](https://openrouter.ai/qwen/qwen2.5-vl-32b-instruct:free)
- [Qwen QwQ 32B](https://openrouter.ai/qwen/qwq-32b:free)
- [Qwen2.5 Coder 32B Instruct](https://openrouter.ai/qwen/qwen-2.5-coder-32b-instruct:free)
- [Qwen2.5 VL 72B Instruct](https://openrouter.ai/qwen/qwen2.5-vl-72b-instruct:free)
- [Reka Flash 3](https://openrouter.ai/rekaai/reka-flash-3:free)
- [Shisa V2 Llama 3.3 70B](https://openrouter.ai/shisa-ai/shisa-v2-llama3.3-70b:free)
- [cognitivecomputations/dolphin-mistral-24b-venice-edition:free](https://openrouter.ai/cognitivecomputations/dolphin-mistral-24b-venice-edition:free)
- [deepseek/deepseek-chat-v3.1:free](https://openrouter.ai/deepseek/deepseek-chat-v3.1:free)
- [deepseek/deepseek-r1-0528-qwen3-8b:free](https://openrouter.ai/deepseek/deepseek-r1-0528-qwen3-8b:free)
- [deepseek/deepseek-r1-0528:free](https://openrouter.ai/deepseek/deepseek-r1-0528:free)
- [google/gemma-3n-e2b-it:free](https://openrouter.ai/google/gemma-3n-e2b-it:free)
- [google/gemma-3n-e4b-it:free](https://openrouter.ai/google/gemma-3n-e4b-it:free)
- [meta-llama/llama-3.3-8b-instruct:free](https://openrouter.ai/meta-llama/llama-3.3-8b-instruct:free)
- [microsoft/mai-ds-r1:free](https://openrouter.ai/microsoft/mai-ds-r1:free)
- [mistralai/devstral-small-2505:free](https://openrouter.ai/mistralai/devstral-small-2505:free)
- [mistralai/mistral-small-3.2-24b-instruct:free](https://openrouter.ai/mistralai/mistral-small-3.2-24b-instruct:free)
- [moonshotai/kimi-dev-72b:free](https://openrouter.ai/moonshotai/kimi-dev-72b:free)
- [moonshotai/kimi-k2:free](https://openrouter.ai/moonshotai/kimi-k2:free)
- [nvidia/nemotron-nano-9b-v2:free](https://openrouter.ai/nvidia/nemotron-nano-9b-v2:free)
- [openai/gpt-oss-120b:free](https://openrouter.ai/openai/gpt-oss-120b:free)
- [openai/gpt-oss-20b:free](https://openrouter.ai/openai/gpt-oss-20b:free)
- [qwen/qwen3-14b:free](https://openrouter.ai/qwen/qwen3-14b:free)
- [qwen/qwen3-235b-a22b:free](https://openrouter.ai/qwen/qwen3-235b-a22b:free)
- [qwen/qwen3-30b-a3b:free](https://openrouter.ai/qwen/qwen3-30b-a3b:free)
- [qwen/qwen3-4b:free](https://openrouter.ai/qwen/qwen3-4b:free)
- [qwen/qwen3-8b:free](https://openrouter.ai/qwen/qwen3-8b:free)
- [qwen/qwen3-coder:free](https://openrouter.ai/qwen/qwen3-coder:free)
- [tencent/hunyuan-a13b-instruct:free](https://openrouter.ai/tencent/hunyuan-a13b-instruct:free)
- [tngtech/deepseek-r1t-chimera:free](https://openrouter.ai/tngtech/deepseek-r1t-chimera:free)
- [tngtech/deepseek-r1t2-chimera:free](https://openrouter.ai/tngtech/deepseek-r1t2-chimera:free)
- [z-ai/glm-4.5-air:free](https://openrouter.ai/z-ai/glm-4.5-air:free)

### [Google AI Studio](https://aistudio.google.com)

Data is used for training when used outside of the UK/CH/EEA/EU.

&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Model Name&lt;/th&gt;&lt;th&gt;Model Limits&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;Gemini 2.5 Pro&lt;/td&gt;&lt;td&gt;3,000,000 tokens/day&lt;br&gt;125,000 tokens/minute&lt;br&gt;50 requests/day&lt;br&gt;2 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemini 2.5 Flash&lt;/td&gt;&lt;td&gt;250,000 tokens/minute&lt;br&gt;250 requests/day&lt;br&gt;10 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemini 2.5 Flash-Lite&lt;/td&gt;&lt;td&gt;250,000 tokens/minute&lt;br&gt;1,000 requests/day&lt;br&gt;15 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemini 2.5 Flash Image Preview (Nano Banana)&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemini 2.0 Flash&lt;/td&gt;&lt;td&gt;1,000,000 tokens/minute&lt;br&gt;200 requests/day&lt;br&gt;15 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemini 2.0 Flash-Lite&lt;/td&gt;&lt;td&gt;1,000,000 tokens/minute&lt;br&gt;200 requests/day&lt;br&gt;30 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemini 2.0 Flash (Experimental)&lt;/td&gt;&lt;td&gt;250,000 tokens/minute&lt;br&gt;50 requests/day&lt;br&gt;10 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemini 1.5 Flash&lt;/td&gt;&lt;td&gt;250,000 tokens/minute&lt;br&gt;50 requests/day&lt;br&gt;15 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemini 1.5 Flash-8B&lt;/td&gt;&lt;td&gt;250,000 tokens/minute&lt;br&gt;50 requests/day&lt;br&gt;15 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;LearnLM 2.0 Flash (Experimental)&lt;/td&gt;&lt;td&gt;1,500 requests/day&lt;br&gt;15 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemma 3 27B Instruct&lt;/td&gt;&lt;td&gt;15,000 tokens/minute&lt;br&gt;14,400 requests/day&lt;br&gt;30 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemma 3 12B Instruct&lt;/td&gt;&lt;td&gt;15,000 tokens/minute&lt;br&gt;14,400 requests/day&lt;br&gt;30 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemma 3 4B Instruct&lt;/td&gt;&lt;td&gt;15,000 tokens/minute&lt;br&gt;14,400 requests/day&lt;br&gt;30 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemma 3 1B Instruct&lt;/td&gt;&lt;td&gt;15,000 tokens/minute&lt;br&gt;14,400 requests/day&lt;br&gt;30 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

### [NVIDIA NIM](https://build.nvidia.com/explore/discover)

Phone number verification required.
Models tend to be context window limited.

**Limits:** 40 requests/minute

- [Various open models](https://build.nvidia.com/models)

### [Mistral (La Plateforme)](https://console.mistral.ai/)

* Free tier (Experiment plan) requires opting into data training
* Requires phone number verification.

**Limits (per-model):** 1 request/second, 500,000 tokens/minute, 1,000,000,000 tokens/month

- [Open and Proprietary Mistral models](https://docs.mistral.ai/getting-started/models/models_overview/)

### [Mistral (Codestral)](https://codestral.mistral.ai/)

* Currently free to use
* Monthly subscription based
* Requires phone number verification

**Limits:** 30 requests/minute, 2,000 requests/day

- Codestral

### [HuggingFace Inference Providers](https://huggingface.co/docs/inference-providers/en/index)

HuggingFace Serverless Inference limited to models smaller than 10GB. Some popular models are supported even if they exceed 10GB.

**Limits:** [$0.10/month in credits](https://huggingface.co/docs/inference-providers/en/pricing)

- Various open models across supported providers

### [Vercel AI Gateway](https://vercel.com/docs/ai-gateway)

Routes to various supported providers.

**Limits:** [$5/month](https://vercel.com/docs/ai-gateway/pricing)


### [Cerebras](https://cloud.cerebras.ai/)

&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Model Name&lt;/th&gt;&lt;th&gt;Model Limits&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;gpt-oss-120b&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;60,000 tokens/minute&lt;br&gt;900 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;14,400 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Qwen 3 235B A22B Instruct&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;60,000 tokens/minute&lt;br&gt;900 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;14,400 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Qwen 3 235B A22B Thinking&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;60,000 tokens/minute&lt;br&gt;900 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;14,400 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Qwen 3 Coder 480B&lt;/td&gt;&lt;td&gt;10 requests/minute&lt;br&gt;150,000 tokens/minute&lt;br&gt;100 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;100 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Llama 3.3 70B&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;64,000 tokens/minute&lt;br&gt;900 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;14,400 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Qwen 3 32B&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;64,000 tokens/minute&lt;br&gt;900 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;14,400 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Llama 3.1 8B&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;60,000 tokens/minute&lt;br&gt;900 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;14,400 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Llama 4 Scout&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;60,000 tokens/minute&lt;br&gt;900 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;14,400 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Llama 4 Maverick&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;60,000 tokens/minute&lt;br&gt;900 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;14,400 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

### [Groq](https://console.groq.com)

&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Model Name&lt;/th&gt;&lt;th&gt;Model Limits&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;Allam 2 7B&lt;/td&gt;&lt;td&gt;7,000 requests/day&lt;br&gt;6,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;DeepSeek R1 Distill Llama 70B&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;6,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemma 2 9B Instruct&lt;/td&gt;&lt;td&gt;14,400 requests/day&lt;br&gt;15,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Llama 3.1 8B&lt;/td&gt;&lt;td&gt;14,400 requests/day&lt;br&gt;6,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Llama 3.3 70B&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;12,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Llama 4 Maverick 17B 128E Instruct&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;6,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Llama 4 Scout Instruct&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;30,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Whisper Large v3&lt;/td&gt;&lt;td&gt;7,200 audio-seconds/minute&lt;br&gt;2,000 requests/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Whisper Large v3 Turbo&lt;/td&gt;&lt;td&gt;7,200 audio-seconds/minute&lt;br&gt;2,000 requests/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;groq/compound&lt;/td&gt;&lt;td&gt;250 requests/day&lt;br&gt;70,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;groq/compound-mini&lt;/td&gt;&lt;td&gt;250 requests/day&lt;br&gt;70,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;meta-llama/llama-guard-4-12b&lt;/td&gt;&lt;td&gt;14,400 requests/day&lt;br&gt;15,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;meta-llama/llama-prompt-guard-2-22m&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;meta-llama/llama-prompt-guard-2-86m&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;moonshotai/kimi-k2-instruct&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;10,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;moonshotai/kimi-k2-instruct-0905&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;10,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;openai/gpt-oss-120b&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;8,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;openai/gpt-oss-20b&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;8,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;qwen/qwen3-32b&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;6,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

### [Together (Free)](https://together.ai)

**Limits:** Up to 60 requests/minute

- [Llama 3.3 70B Instruct](https://together.ai/models/llama-3-3-70b-free)
- [DeepSeek R1 Distil Llama 70B](https://together.ai/models/deepseek-r1-distilled-llama-70b-free)

### [Cohere](https://cohere.com)

**Limits:**

[20 requests/minute&lt;br&gt;1,000 requests/month](https://docs.cohere.com/docs/rate-limits)

Models share a common quota.

- Command-A
- Command-R7B
- Command-R+
- Command-R
- Aya Expanse 8B
- Aya Expanse 32B
- Aya Vision 8B
- Aya Vision 32B

### [GitHub Models](https://github.com/marketplace/models)

Extremely restrictive input/output token limits.

**Limits:** [Dependent on Copilot subscription tier (Free/Pro/Pro+/Business/Enterprise)](https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits)

- AI21 Jamba 1.5 Large
- AI21 Jamba 1.5 Mini
- Codestral 25.01
- Cohere Command A
- Cohere Command R 08-2024
- Cohere Command R+ 08-2024
- Cohere Embed v3 English
- Cohere Embed v3 Multilingual
- DeepSeek-R1
- DeepSeek-R1-0528
- DeepSeek-V3-0324
- Grok 3
- Grok 3 Mini
- JAIS 30b Chat
- Llama 4 Maverick 17B 128E Instruct FP8
- Llama 4 Scout 17B 16E Instruct
- Llama-3.2-11B-Vision-Instruct
- Llama-3.2-90B-Vision-Instruct
- Llama-3.3-70B-Instruct
- MAI-DS-R1
- Meta-Llama-3.1-405B-Instruct
- Meta-Llama-3.1-8B-Instruct
- Ministral 3B
- Mistral Large 24.11
- Mistral Medium 3 (25.05)
- Mistral Nemo
- Mistral Small 3.1
- OpenAI GPT-4.1
- OpenAI GPT-4.1-mini
- OpenAI GPT-4.1-nano
- OpenAI GPT-4o
- OpenAI GPT-4o mini
- OpenAI Text Embedding 3 (large)
- OpenAI Text Embedding 3 (small)
- OpenAI gpt-5
- OpenAI gpt-5-chat (preview)
- OpenAI gpt-5-mini
- OpenAI gpt-5-nano
- OpenAI o1
- OpenAI o1-mini
- OpenAI o1-preview
- OpenAI o3
- OpenAI o3-mini
- OpenAI o4-mini
- Phi-4
- Phi-4-mini-instruct
- Phi-4-mini-reasoning
- Phi-4-multimodal-instruct
- Phi-4-reasoning

### [Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai)

**Limits:** [10,000 neurons/day](https://developers.cloudflare.com/workers-ai/platform/pricing/#free-allocation)

- @cf/openai/gpt-oss-120b
- @cf/openai/gpt-oss-20b
- DeepSeek R1 Distill Qwen 32B
- Deepseek Coder 6.7B Base (AWQ)
- Deepseek Coder 6.7B Instruct (AWQ)
- Deepseek Math 7B Instruct
- Discolm German 7B v1 (AWQ)
- Falcom 7B Instruct
- Gemma 2B Instruct (LoRA)
- Gemma 3 12B Instruct
- Gemma 7B Instruct
- Gemma 7B Instruct (LoRA)
- Hermes 2 Pro Mistral 7B
- Llama 2 13B Chat (AWQ)
- Llama 2 7B Chat (FP16)
- Llama 2 7B Chat (INT8)
- Llama 2 7B Chat (LoRA)
- Llama 3 8B Instruct
- Llama 3 8B Instruct
- Llama 3 8B Instruct (AWQ)
- Llama 3.1 8B Instruct (AWQ)
- Llama 3.1 8B Instruct (FP8)
- Llama 3.2 11B Vision Instruct
- Llama 3.2 1B Instruct
- Llama 3.2 3B Instruct
- Llama 3.3 70B Instruct (FP8)
- Llama 4 Scout Instruct
- Llama Guard 3 8B
- LlamaGuard 7B (AWQ)
- Mistral 7B Instruct v0.1
- Mistral 7B Instruct v0.1 (AWQ)
- Mistral 7B Instruct v0.2
- Mistral 7B Instruct v0.2 (LoRA)
- Mistral Small 3.1 24B Instruct
- Neural Chat 7B v3.1 (AWQ)
- OpenChat 3.5 0106
- OpenHermes 2.5 Mistral 7B (AWQ)
- Phi-2
- Qwen 1.5 0.5B Chat
- Qwen 1.5 1.8B Chat
- Qwen 1.5 14B Chat (AWQ)
- Qwen 1.5 7B Chat (AWQ)
- Qwen 2.5 Coder 32B Instruct
- Qwen QwQ 32B
- SQLCoder 7B 2
- Starling LM 7B Beta
- TinyLlama 1.1B Chat v1.0
- Una Cybertron 7B v2 (BF16)
- Zephyr 7B Beta (AWQ)

### [Google Cloud Vertex AI](https://console.cloud.google.com/vertex-ai/model-garden)

Very stringent payment verification for Google Cloud.

&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Model Name&lt;/th&gt;&lt;th&gt;Model Limits&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3-2-90b-vision-instruct-maas&quot; target=&quot;_blank&quot;&gt;Llama 3.2 90B Vision Instruct&lt;/a&gt;&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;Free during preview&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3-1-405b-instruct-maas&quot; target=&quot;_blank&quot;&gt;Llama 3.1 70B Instruct&lt;/a&gt;&lt;/td&gt;&lt;td&gt;60 requests/minute&lt;br&gt;Free during preview&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3-1-405b-instruct-maas&quot; target=&quot;_blank&quot;&gt;Llama 3.1 8B Instruct&lt;/a&gt;&lt;/td&gt;&lt;td&gt;60 requests/minute&lt;br&gt;Free during preview&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;



## Providers with trial credits

### [Together](https://together.ai)

**Credits:** $1 when you add a payment method

**Models:** [Various open models](https://together.ai/models)

### [Fireworks](https://fireworks.ai/)

**Credits:** $1

**Models:** [Various open models](https://fireworks.ai/models)

### [Baseten](https://app.baseten.co/)

**Credits:** $30

**Models:** [Any supported model - pay by compute time](https://www.baseten.co/library/)

### [Nebius](https://studio.nebius.com/)

**Credits:** $1

**Models:** [Various open models](https://studio.nebius.ai/models)

### [Novita](https://novita.ai/?ref=ytblmjc&amp;utm_source=affiliate)

**Credits:** $0.5 for 1 year

**Models:** [Various open models](https://novita.ai/models)

### [AI21](https://studio.ai21.com/)

**Credits:** $10 for 3 months

**Models:** Jamba family of models

### [Upstage](https://console.upstage.ai/)

**Credits:** $10 for 3 months

**Models:** Solar Pro/Mini

### [NLP Cloud](https://nlpcloud.com/home)

**Credits:** $15

**Requirements:** Phone number verification

**Models:** Various open models

### [Alibaba Cloud (International) Model Studio](https://bailian.console.alibabacloud.com/)

**Credits:** 1 million tokens/model

**Models:** [Various open and proprietary Qwen models](https://www.alibabacloud.com/en/product/modelstudio)

### [Modal](https://modal.com)

**Credits:** $5/month upon sign up, $30/month with payment method added

**Models:** Any supported model - pay by compute time

### [Inference.net](https://inference.net)

**Credits:** $1, $25 on responding to email survey

**Models:** Various open models

### [nCompass](https://ncompass.tech)

**Credits:** $1

**Models:** Various open models

### [Hyperbolic](https://app.hyperbolic.xyz/)

**Credits:** $1

**Models:**
- DeepSeek V3
- DeepSeek V3 0324
- Hermes 3 Llama 3.1 70B
- Llama 3 70B Instruct
- Llama 3.1 405B Base
- Llama 3.1 405B Base (FP8)
- Llama 3.1 405B Instruct
- Llama 3.1 70B Instruct
- Llama 3.1 8B Instruct
- Llama 3.2 3B Instruct
- Llama 3.3 70B Instruct
- Pixtral 12B (2409)
- Qwen QwQ 32B
- Qwen QwQ 32B Preview
- Qwen2.5 72B Instruct
- Qwen2.5 Coder 32B Instruct
- Qwen2.5 VL 72B Instruct
- Qwen2.5 VL 7B Instruct
- openai/gpt-oss-120b
- openai/gpt-oss-120b-turbo
- openai/gpt-oss-20b
- qwen/qwen3-235b-a22b-instruct-2507-fp8
- qwen/qwen3-coder-480b-a35b-instruct-fp8
- qwen/qwen3-next-80b-a3b-instruct
- qwen/qwen3-next-80b-a3b-thinking

### [SambaNova Cloud](ht

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>