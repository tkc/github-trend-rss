<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Mon, 07 Jul 2025 00:04:43 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[NanmiCoder/MediaCrawler]]></title>
            <link>https://github.com/NanmiCoder/MediaCrawler</link>
            <guid>https://github.com/NanmiCoder/MediaCrawler</guid>
            <pubDate>Mon, 07 Jul 2025 00:04:43 GMT</pubDate>
            <description><![CDATA[å°çº¢ä¹¦ç¬”è®° | è¯„è®ºçˆ¬è™«ã€æŠ–éŸ³è§†é¢‘ | è¯„è®ºçˆ¬è™«ã€å¿«æ‰‹è§†é¢‘ | è¯„è®ºçˆ¬è™«ã€B ç«™è§†é¢‘ ï½œ è¯„è®ºçˆ¬è™«ã€å¾®åšå¸–å­ ï½œ è¯„è®ºçˆ¬è™«ã€ç™¾åº¦è´´å§å¸–å­ ï½œ ç™¾åº¦è´´å§è¯„è®ºå›å¤çˆ¬è™« | çŸ¥ä¹é—®ç­”æ–‡ç« ï½œè¯„è®ºçˆ¬è™«]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NanmiCoder/MediaCrawler">NanmiCoder/MediaCrawler</a></h1>
            <p>å°çº¢ä¹¦ç¬”è®° | è¯„è®ºçˆ¬è™«ã€æŠ–éŸ³è§†é¢‘ | è¯„è®ºçˆ¬è™«ã€å¿«æ‰‹è§†é¢‘ | è¯„è®ºçˆ¬è™«ã€B ç«™è§†é¢‘ ï½œ è¯„è®ºçˆ¬è™«ã€å¾®åšå¸–å­ ï½œ è¯„è®ºçˆ¬è™«ã€ç™¾åº¦è´´å§å¸–å­ ï½œ ç™¾åº¦è´´å§è¯„è®ºå›å¤çˆ¬è™« | çŸ¥ä¹é—®ç­”æ–‡ç« ï½œè¯„è®ºçˆ¬è™«</p>
            <p>Language: Python</p>
            <p>Stars: 27,689</p>
            <p>Forks: 7,061</p>
            <p>Stars today: 456 stars today</p>
            <h2>README</h2><pre># ğŸ”¥ MediaCrawler - è‡ªåª’ä½“å¹³å°çˆ¬è™« ğŸ•·ï¸

&lt;div align=&quot;center&quot;&gt;

&lt;a href=&quot;https://trendshift.io/repositories/8291&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://trendshift.io/api/badge/repositories/8291&quot; alt=&quot;NanmiCoder%2FMediaCrawler | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
&lt;/a&gt;

[![GitHub Stars](https://img.shields.io/github/stars/NanmiCoder/MediaCrawler?style=social)](https://github.com/NanmiCoder/MediaCrawler/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/NanmiCoder/MediaCrawler?style=social)](https://github.com/NanmiCoder/MediaCrawler/network/members)
[![GitHub Issues](https://img.shields.io/github/issues/NanmiCoder/MediaCrawler)](https://github.com/NanmiCoder/MediaCrawler/issues)
[![GitHub Pull Requests](https://img.shields.io/github/issues-pr/NanmiCoder/MediaCrawler)](https://github.com/NanmiCoder/MediaCrawler/pulls)
[![License](https://img.shields.io/github/license/NanmiCoder/MediaCrawler)](https://github.com/NanmiCoder/MediaCrawler/blob/main/LICENSE)
[![ä¸­æ–‡](https://img.shields.io/badge/ğŸ‡¨ğŸ‡³_ä¸­æ–‡-å½“å‰-blue)](README.md)
[![English](https://img.shields.io/badge/ğŸ‡ºğŸ‡¸_English-Available-green)](README_en.md)
[![EspaÃ±ol](https://img.shields.io/badge/ğŸ‡ªğŸ‡¸_EspaÃ±ol-Available-green)](README_es.md)
&lt;/div&gt;



&gt; **å…è´£å£°æ˜ï¼š**
&gt; 
&gt; å¤§å®¶è¯·ä»¥å­¦ä¹ ä¸ºç›®çš„ä½¿ç”¨æœ¬ä»“åº“âš ï¸âš ï¸âš ï¸âš ï¸ï¼Œ[çˆ¬è™«è¿æ³•è¿è§„çš„æ¡ˆä»¶](https://github.com/HiddenStrawberry/Crawler_Illegal_Cases_In_China)  &lt;br&gt;
&gt;
&gt;æœ¬ä»“åº“çš„æ‰€æœ‰å†…å®¹ä»…ä¾›å­¦ä¹ å’Œå‚è€ƒä¹‹ç”¨ï¼Œç¦æ­¢ç”¨äºå•†ä¸šç”¨é€”ã€‚ä»»ä½•äººæˆ–ç»„ç»‡ä¸å¾—å°†æœ¬ä»“åº“çš„å†…å®¹ç”¨äºéæ³•ç”¨é€”æˆ–ä¾µçŠ¯ä»–äººåˆæ³•æƒç›Šã€‚æœ¬ä»“åº“æ‰€æ¶‰åŠçš„çˆ¬è™«æŠ€æœ¯ä»…ç”¨äºå­¦ä¹ å’Œç ”ç©¶ï¼Œä¸å¾—ç”¨äºå¯¹å…¶ä»–å¹³å°è¿›è¡Œå¤§è§„æ¨¡çˆ¬è™«æˆ–å…¶ä»–éæ³•è¡Œä¸ºã€‚å¯¹äºå› ä½¿ç”¨æœ¬ä»“åº“å†…å®¹è€Œå¼•èµ·çš„ä»»ä½•æ³•å¾‹è´£ä»»ï¼Œæœ¬ä»“åº“ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚ä½¿ç”¨æœ¬ä»“åº“çš„å†…å®¹å³è¡¨ç¤ºæ‚¨åŒæ„æœ¬å…è´£å£°æ˜çš„æ‰€æœ‰æ¡æ¬¾å’Œæ¡ä»¶ã€‚
&gt;
&gt; ç‚¹å‡»æŸ¥çœ‹æ›´ä¸ºè¯¦ç»†çš„å…è´£å£°æ˜ã€‚[ç‚¹å‡»è·³è½¬](#disclaimer)




## ğŸ“– é¡¹ç›®ç®€ä»‹

ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„**å¤šå¹³å°è‡ªåª’ä½“æ•°æ®é‡‡é›†å·¥å…·**ï¼Œæ”¯æŒå°çº¢ä¹¦ã€æŠ–éŸ³ã€å¿«æ‰‹ã€Bç«™ã€å¾®åšã€è´´å§ã€çŸ¥ä¹ç­‰ä¸»æµå¹³å°çš„å…¬å¼€ä¿¡æ¯æŠ“å–ã€‚

### ğŸ”§ æŠ€æœ¯åŸç†

- **æ ¸å¿ƒæŠ€æœ¯**ï¼šåŸºäº [Playwright](https://playwright.dev/) æµè§ˆå™¨è‡ªåŠ¨åŒ–æ¡†æ¶ç™»å½•ä¿å­˜ç™»å½•æ€
- **æ— éœ€JSé€†å‘**ï¼šåˆ©ç”¨ä¿ç•™ç™»å½•æ€çš„æµè§ˆå™¨ä¸Šä¸‹æ–‡ç¯å¢ƒï¼Œé€šè¿‡ JS è¡¨è¾¾å¼è·å–ç­¾åå‚æ•°
- **ä¼˜åŠ¿ç‰¹ç‚¹**ï¼šæ— éœ€é€†å‘å¤æ‚çš„åŠ å¯†ç®—æ³•ï¼Œå¤§å¹…é™ä½æŠ€æœ¯é—¨æ§›

## âœ¨ åŠŸèƒ½ç‰¹æ€§
| å¹³å°   | å…³é”®è¯æœç´¢ | æŒ‡å®šå¸–å­IDçˆ¬å– | äºŒçº§è¯„è®º | æŒ‡å®šåˆ›ä½œè€…ä¸»é¡µ | ç™»å½•æ€ç¼“å­˜ | IPä»£ç†æ±  | ç”Ÿæˆè¯„è®ºè¯äº‘å›¾ |
| ------ | ---------- | -------------- | -------- | -------------- | ---------- | -------- | -------------- |
| å°çº¢ä¹¦ | âœ…          | âœ…              | âœ…        | âœ…              | âœ…          | âœ…        | âœ…              |
| æŠ–éŸ³   | âœ…          | âœ…              | âœ…        | âœ…              | âœ…          | âœ…        | âœ…              |
| å¿«æ‰‹   | âœ…          | âœ…              | âœ…        | âœ…              | âœ…          | âœ…        | âœ…              |
| B ç«™   | âœ…          | âœ…              | âœ…        | âœ…              | âœ…          | âœ…        | âœ…              |
| å¾®åš   | âœ…          | âœ…              | âœ…        | âœ…              | âœ…          | âœ…        | âœ…              |
| è´´å§   | âœ…          | âœ…              | âœ…        | âœ…              | âœ…          | âœ…        | âœ…              |
| çŸ¥ä¹   | âœ…          | âœ…              | âœ…        | âœ…              | âœ…          | âœ…        | âœ…              |


&lt;details id=&quot;pro-version&quot;&gt;
&lt;summary&gt;ğŸ”— &lt;strong&gt;ğŸš€ MediaCrawlerPro é‡ç£…å‘å¸ƒï¼æ›´å¤šçš„åŠŸèƒ½ï¼Œæ›´å¥½çš„æ¶æ„è®¾è®¡ï¼&lt;/strong&gt;&lt;/summary&gt;

### ğŸš€ MediaCrawlerPro é‡ç£…å‘å¸ƒï¼

&gt; ä¸“æ³¨äºå­¦ä¹ æˆç†Ÿé¡¹ç›®çš„æ¶æ„è®¾è®¡ï¼Œä¸ä»…ä»…æ˜¯çˆ¬è™«æŠ€æœ¯ï¼ŒPro ç‰ˆæœ¬çš„ä»£ç è®¾è®¡æ€è·¯åŒæ ·å€¼å¾—æ·±å…¥å­¦ä¹ ï¼

[MediaCrawlerPro](https://github.com/MediaCrawlerPro) ç›¸è¾ƒäºå¼€æºç‰ˆæœ¬çš„æ ¸å¿ƒä¼˜åŠ¿ï¼š

#### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½å‡çº§
- âœ… **æ–­ç‚¹ç»­çˆ¬åŠŸèƒ½**ï¼ˆé‡ç‚¹ç‰¹æ€§ï¼‰
- âœ… **å¤šè´¦å· + IPä»£ç†æ± æ”¯æŒ**ï¼ˆé‡ç‚¹ç‰¹æ€§ï¼‰
- âœ… **å»é™¤ Playwright ä¾èµ–**ï¼Œä½¿ç”¨æ›´ç®€å•
- âœ… **å®Œæ•´ Linux ç¯å¢ƒæ”¯æŒ**

#### ğŸ—ï¸ æ¶æ„è®¾è®¡ä¼˜åŒ–
- âœ… **ä»£ç é‡æ„ä¼˜åŒ–**ï¼Œæ›´æ˜“è¯»æ˜“ç»´æŠ¤ï¼ˆè§£è€¦ JS ç­¾åé€»è¾‘ï¼‰
- âœ… **ä¼ä¸šçº§ä»£ç è´¨é‡**ï¼Œé€‚åˆæ„å»ºå¤§å‹çˆ¬è™«é¡¹ç›®
- âœ… **å®Œç¾æ¶æ„è®¾è®¡**ï¼Œé«˜æ‰©å±•æ€§ï¼Œæºç å­¦ä¹ ä»·å€¼æ›´å¤§

#### ğŸ é¢å¤–åŠŸèƒ½
- âœ… **è‡ªåª’ä½“è§†é¢‘ä¸‹è½½å™¨æ¡Œé¢ç«¯**ï¼ˆé€‚åˆå­¦ä¹ å…¨æ ˆå¼€å‘ï¼‰
- âœ… **å¤šå¹³å°é¦–é¡µä¿¡æ¯æµæ¨è**ï¼ˆHomeFeedï¼‰
- [ ] **åŸºäºè‡ªåª’ä½“å¹³å°çš„AI Agentæ­£åœ¨å¼€å‘ä¸­ ğŸš€ğŸš€**

ç‚¹å‡»æŸ¥çœ‹ï¼š[MediaCrawlerPro é¡¹ç›®ä¸»é¡µ](https://github.com/MediaCrawlerPro) æ›´å¤šä»‹ç»
&lt;/details&gt;

## ğŸš€ å¿«é€Ÿå¼€å§‹

&gt; ğŸ’¡ **å¼€æºä¸æ˜“ï¼Œå¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª â­ Star æ”¯æŒä¸€ä¸‹ï¼**

## ğŸ“‹ å‰ç½®ä¾èµ–

### ğŸš€ uv å®‰è£…ï¼ˆæ¨èï¼‰

åœ¨è¿›è¡Œä¸‹ä¸€æ­¥æ“ä½œä¹‹å‰ï¼Œè¯·ç¡®ä¿ç”µè„‘ä¸Šå·²ç»å®‰è£…äº† uvï¼š

- **å®‰è£…åœ°å€**ï¼š[uv å®˜æ–¹å®‰è£…æŒ‡å—](https://docs.astral.sh/uv/getting-started/installation)
- **éªŒè¯å®‰è£…**ï¼šç»ˆç«¯è¾“å…¥å‘½ä»¤ `uv --version`ï¼Œå¦‚æœæ­£å¸¸æ˜¾ç¤ºç‰ˆæœ¬å·ï¼Œè¯æ˜å·²ç»å®‰è£…æˆåŠŸ
- **æ¨èç†ç”±**ï¼šuv æ˜¯ç›®å‰æœ€å¼ºçš„ Python åŒ…ç®¡ç†å·¥å…·ï¼Œé€Ÿåº¦å¿«ã€ä¾èµ–è§£æå‡†ç¡®

### ğŸŸ¢ Node.js å®‰è£…

é¡¹ç›®ä¾èµ– Node.jsï¼Œè¯·å‰å¾€å®˜ç½‘ä¸‹è½½å®‰è£…ï¼š

- **ä¸‹è½½åœ°å€**ï¼šhttps://nodejs.org/en/download/
- **ç‰ˆæœ¬è¦æ±‚**ï¼š&gt;= 16.0.0

### ğŸ“¦ Python åŒ…å®‰è£…

```shell
# è¿›å…¥é¡¹ç›®ç›®å½•
cd MediaCrawler

# ä½¿ç”¨ uv sync å‘½ä»¤æ¥ä¿è¯ python ç‰ˆæœ¬å’Œç›¸å…³ä¾èµ–åŒ…çš„ä¸€è‡´æ€§
uv sync
```

### ğŸŒ æµè§ˆå™¨é©±åŠ¨å®‰è£…

```shell
# å®‰è£…æµè§ˆå™¨é©±åŠ¨
uv run playwright install
```

&gt; **ğŸ’¡ æç¤º**ï¼šMediaCrawler ç›®å‰å·²ç»æ”¯æŒä½¿ç”¨ playwright è¿æ¥ä½ æœ¬åœ°çš„ Chrome æµè§ˆå™¨äº†ï¼Œä¸€äº›å› ä¸º Webdriver å¯¼è‡´çš„é—®é¢˜è¿åˆƒè€Œè§£äº†ã€‚
&gt;
&gt; ç›®å‰å¼€æ”¾äº† `xhs` å’Œ `dy` è¿™ä¸¤ä¸ªä½¿ç”¨ CDP çš„æ–¹å¼è¿æ¥æœ¬åœ°æµè§ˆå™¨ï¼Œå¦‚æœ‰éœ€è¦ï¼ŒæŸ¥çœ‹ `config/base_config.py` ä¸­çš„é…ç½®é¡¹ã€‚

## ğŸš€ è¿è¡Œçˆ¬è™«ç¨‹åº

```shell
# é¡¹ç›®é»˜è®¤æ˜¯æ²¡æœ‰å¼€å¯è¯„è®ºçˆ¬å–æ¨¡å¼ï¼Œå¦‚éœ€è¯„è®ºè¯·åœ¨ config/base_config.py ä¸­çš„ ENABLE_GET_COMMENTS å˜é‡ä¿®æ”¹
# ä¸€äº›å…¶ä»–æ”¯æŒé¡¹ï¼Œä¹Ÿå¯ä»¥åœ¨ config/base_config.py æŸ¥çœ‹åŠŸèƒ½ï¼Œå†™çš„æœ‰ä¸­æ–‡æ³¨é‡Š

# ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–å…³é”®è¯æœç´¢ç›¸å…³çš„å¸–å­å¹¶çˆ¬å–å¸–å­ä¿¡æ¯ä¸è¯„è®º
uv run main.py --platform xhs --lt qrcode --type search

# ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–æŒ‡å®šçš„å¸–å­IDåˆ—è¡¨è·å–æŒ‡å®šå¸–å­çš„ä¿¡æ¯ä¸è¯„è®ºä¿¡æ¯
uv run main.py --platform xhs --lt qrcode --type detail

# æ‰“å¼€å¯¹åº”APPæ‰«äºŒç»´ç ç™»å½•

# å…¶ä»–å¹³å°çˆ¬è™«ä½¿ç”¨ç¤ºä¾‹ï¼Œæ‰§è¡Œä¸‹é¢çš„å‘½ä»¤æŸ¥çœ‹
uv run main.py --help
```

&lt;details&gt;
&lt;summary&gt;ğŸ”— &lt;strong&gt;ä½¿ç”¨ Python åŸç”Ÿ venv ç®¡ç†ç¯å¢ƒï¼ˆä¸æ¨èï¼‰&lt;/strong&gt;&lt;/summary&gt;

#### åˆ›å»ºå¹¶æ¿€æ´» Python è™šæ‹Ÿç¯å¢ƒ

&gt; å¦‚æœæ˜¯çˆ¬å–æŠ–éŸ³å’ŒçŸ¥ä¹ï¼Œéœ€è¦æå‰å®‰è£… nodejs ç¯å¢ƒï¼Œç‰ˆæœ¬å¤§äºç­‰äºï¼š`16` å³å¯

```shell
# è¿›å…¥é¡¹ç›®æ ¹ç›®å½•
cd MediaCrawler

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
# æˆ‘çš„ python ç‰ˆæœ¬æ˜¯ï¼š3.9.6ï¼Œrequirements.txt ä¸­çš„åº“æ˜¯åŸºäºè¿™ä¸ªç‰ˆæœ¬çš„
# å¦‚æœæ˜¯å…¶ä»– python ç‰ˆæœ¬ï¼Œå¯èƒ½ requirements.txt ä¸­çš„åº“ä¸å…¼å®¹ï¼Œéœ€è‡ªè¡Œè§£å†³
python -m venv venv

# macOS &amp; Linux æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# Windows æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
venv\Scripts\activate
```

#### å®‰è£…ä¾èµ–åº“

```shell
pip install -r requirements.txt
```

#### å®‰è£… playwright æµè§ˆå™¨é©±åŠ¨

```shell
playwright install
```

#### è¿è¡Œçˆ¬è™«ç¨‹åºï¼ˆåŸç”Ÿç¯å¢ƒï¼‰

```shell
# é¡¹ç›®é»˜è®¤æ˜¯æ²¡æœ‰å¼€å¯è¯„è®ºçˆ¬å–æ¨¡å¼ï¼Œå¦‚éœ€è¯„è®ºè¯·åœ¨ config/base_config.py ä¸­çš„ ENABLE_GET_COMMENTS å˜é‡ä¿®æ”¹
# ä¸€äº›å…¶ä»–æ”¯æŒé¡¹ï¼Œä¹Ÿå¯ä»¥åœ¨ config/base_config.py æŸ¥çœ‹åŠŸèƒ½ï¼Œå†™çš„æœ‰ä¸­æ–‡æ³¨é‡Š

# ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–å…³é”®è¯æœç´¢ç›¸å…³çš„å¸–å­å¹¶çˆ¬å–å¸–å­ä¿¡æ¯ä¸è¯„è®º
python main.py --platform xhs --lt qrcode --type search

# ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–æŒ‡å®šçš„å¸–å­IDåˆ—è¡¨è·å–æŒ‡å®šå¸–å­çš„ä¿¡æ¯ä¸è¯„è®ºä¿¡æ¯
python main.py --platform xhs --lt qrcode --type detail

# æ‰“å¼€å¯¹åº”APPæ‰«äºŒç»´ç ç™»å½•

# å…¶ä»–å¹³å°çˆ¬è™«ä½¿ç”¨ç¤ºä¾‹ï¼Œæ‰§è¡Œä¸‹é¢çš„å‘½ä»¤æŸ¥çœ‹
python main.py --help
```

&lt;/details&gt;


## ğŸ’¾ æ•°æ®ä¿å­˜

æ”¯æŒå¤šç§æ•°æ®å­˜å‚¨æ–¹å¼ï¼š

- **MySQL æ•°æ®åº“**ï¼šæ”¯æŒå…³ç³»å‹æ•°æ®åº“ MySQL ä¸­ä¿å­˜ï¼ˆéœ€è¦æå‰åˆ›å»ºæ•°æ®åº“ï¼‰
  - æ‰§è¡Œ `python db.py` åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„ï¼ˆåªåœ¨é¦–æ¬¡æ‰§è¡Œï¼‰
- **CSV æ–‡ä»¶**ï¼šæ”¯æŒä¿å­˜åˆ° CSV ä¸­ï¼ˆ`data/` ç›®å½•ä¸‹ï¼‰
- **JSON æ–‡ä»¶**ï¼šæ”¯æŒä¿å­˜åˆ° JSON ä¸­ï¼ˆ`data/` ç›®å½•ä¸‹ï¼‰

---

[ğŸš€ MediaCrawlerPro é‡ç£…å‘å¸ƒ ğŸš€ï¼æ›´å¤šçš„åŠŸèƒ½ï¼Œæ›´å¥½çš„æ¶æ„è®¾è®¡ï¼](https://github.com/MediaCrawlerPro)

## ğŸ¤ ç¤¾åŒºä¸æ”¯æŒ

### ğŸ’¬ äº¤æµç¾¤ç»„
- **å¾®ä¿¡äº¤æµç¾¤**ï¼š[ç‚¹å‡»åŠ å…¥](https://nanmicoder.github.io/MediaCrawler/%E5%BE%AE%E4%BF%A1%E4%BA%A4%E6%B5%81%E7%BE%A4.html)

### ğŸ“š æ–‡æ¡£ä¸æ•™ç¨‹
- **åœ¨çº¿æ–‡æ¡£**ï¼š[MediaCrawler å®Œæ•´æ–‡æ¡£](https://nanmicoder.github.io/MediaCrawler/)
- **çˆ¬è™«æ•™ç¨‹**ï¼š[CrawlerTutorial å…è´¹æ•™ç¨‹](https://github.com/NanmiCoder/CrawlerTutorial)
  

# å…¶ä»–å¸¸è§é—®é¢˜å¯ä»¥æŸ¥çœ‹åœ¨çº¿æ–‡æ¡£
&gt; 
&gt; åœ¨çº¿æ–‡æ¡£åŒ…å«ä½¿ç”¨æ–¹æ³•ã€å¸¸è§é—®é¢˜ã€åŠ å…¥é¡¹ç›®äº¤æµç¾¤ç­‰ã€‚
&gt; [MediaCrawleråœ¨çº¿æ–‡æ¡£](https://nanmicoder.github.io/MediaCrawler/)
&gt; 

# ä½œè€…æä¾›çš„çŸ¥è¯†æœåŠ¡
&gt; å¦‚æœæƒ³å¿«é€Ÿå…¥é—¨å’Œå­¦ä¹ è¯¥é¡¹ç›®çš„ä½¿ç”¨ã€æºç æ¶æ„è®¾è®¡ç­‰ã€å­¦ä¹ ç¼–ç¨‹æŠ€æœ¯ã€äº¦æˆ–è€…æƒ³äº†è§£MediaCrawlerProçš„æºä»£ç è®¾è®¡å¯ä»¥çœ‹ä¸‹æˆ‘çš„çŸ¥è¯†ä»˜è´¹æ ç›®ã€‚

[ä½œè€…çš„çŸ¥è¯†ä»˜è´¹æ ç›®ä»‹ç»](https://nanmicoder.github.io/MediaCrawler/%E7%9F%A5%E8%AF%86%E4%BB%98%E8%B4%B9%E4%BB%8B%E7%BB%8D.html)


---

## â­ Star è¶‹åŠ¿å›¾

å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª â­ Star æ”¯æŒä¸€ä¸‹ï¼Œè®©æ›´å¤šçš„äººçœ‹åˆ° MediaCrawlerï¼

[![Star History Chart](https://api.star-history.com/svg?repos=NanmiCoder/MediaCrawler&amp;type=Date)](https://star-history.com/#NanmiCoder/MediaCrawler&amp;Date)

### ğŸ’° èµåŠ©å•†å±•ç¤º

&lt;a href=&quot;https://www.swiftproxy.net/?ref=nanmi&quot;&gt;
&lt;img src=&quot;docs/static/images/img_5.png&quot;&gt;
&lt;br&gt;
**Swiftproxy** - 90M+ å…¨çƒé«˜è´¨é‡çº¯å‡€ä½å®…IPï¼Œæ³¨å†Œå¯é¢†å…è´¹ 500MB æµ‹è¯•æµé‡ï¼ŒåŠ¨æ€æµé‡ä¸è¿‡æœŸï¼
&gt; ä¸“å±æŠ˜æ‰£ç ï¼š**GHB5** ç«‹äº«ä¹æŠ˜ä¼˜æƒ ï¼
&lt;/a&gt;

&lt;br&gt;&lt;br&gt;

&lt;a href=&quot;https://sider.ai/ad-land-redirect?source=github&amp;p1=mi&amp;p2=kk&quot;&gt;**Sider** - å…¨ç½‘æœ€ç«çš„ ChatGPT æ’ä»¶ï¼Œä½“éªŒæ‹‰æ»¡ï¼&lt;/a&gt;

### ğŸ¤ æˆä¸ºèµåŠ©è€…

æˆä¸ºèµåŠ©è€…ï¼Œå¯ä»¥å°†æ‚¨çš„äº§å“å±•ç¤ºåœ¨è¿™é‡Œï¼Œæ¯å¤©è·å¾—å¤§é‡æ›å…‰ï¼

**è”ç³»æ–¹å¼**ï¼š
- å¾®ä¿¡ï¼š`yzglan`
- é‚®ç®±ï¼š`relakkes@gmail.com`


## ğŸ“š å‚è€ƒ

- **å°çº¢ä¹¦å®¢æˆ·ç«¯**ï¼š[ReaJason çš„ xhs ä»“åº“](https://github.com/ReaJason/xhs)
- **çŸ­ä¿¡è½¬å‘**ï¼š[SmsForwarder å‚è€ƒä»“åº“](https://github.com/pppscn/SmsForwarder)
- **å†…ç½‘ç©¿é€å·¥å…·**ï¼š[ngrok å®˜æ–¹æ–‡æ¡£](https://ngrok.com/docs/)


# å…è´£å£°æ˜
&lt;div id=&quot;disclaimer&quot;&gt; 

## 1. é¡¹ç›®ç›®çš„ä¸æ€§è´¨
æœ¬é¡¹ç›®ï¼ˆä»¥ä¸‹ç®€ç§°â€œæœ¬é¡¹ç›®â€ï¼‰æ˜¯ä½œä¸ºä¸€ä¸ªæŠ€æœ¯ç ”ç©¶ä¸å­¦ä¹ å·¥å…·è€Œåˆ›å»ºçš„ï¼Œæ—¨åœ¨æ¢ç´¢å’Œå­¦ä¹ ç½‘ç»œæ•°æ®é‡‡é›†æŠ€æœ¯ã€‚æœ¬é¡¹ç›®ä¸“æ³¨äºè‡ªåª’ä½“å¹³å°çš„æ•°æ®çˆ¬å–æŠ€æœ¯ç ”ç©¶ï¼Œæ—¨åœ¨æä¾›ç»™å­¦ä¹ è€…å’Œç ”ç©¶è€…ä½œä¸ºæŠ€æœ¯äº¤æµä¹‹ç”¨ã€‚

## 2. æ³•å¾‹åˆè§„æ€§å£°æ˜
æœ¬é¡¹ç›®å¼€å‘è€…ï¼ˆä»¥ä¸‹ç®€ç§°â€œå¼€å‘è€…â€ï¼‰éƒ‘é‡æé†’ç”¨æˆ·åœ¨ä¸‹è½½ã€å®‰è£…å’Œä½¿ç”¨æœ¬é¡¹ç›®æ—¶ï¼Œä¸¥æ ¼éµå®ˆä¸­åäººæ°‘å…±å’Œå›½ç›¸å…³æ³•å¾‹æ³•è§„ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºã€Šä¸­åäººæ°‘å…±å’Œå›½ç½‘ç»œå®‰å…¨æ³•ã€‹ã€ã€Šä¸­åäººæ°‘å…±å’Œå›½åé—´è°æ³•ã€‹ç­‰æ‰€æœ‰é€‚ç”¨çš„å›½å®¶æ³•å¾‹å’Œæ”¿ç­–ã€‚ç”¨æˆ·åº”è‡ªè¡Œæ‰¿æ‹…ä¸€åˆ‡å› ä½¿ç”¨æœ¬é¡¹ç›®è€Œå¯èƒ½å¼•èµ·çš„æ³•å¾‹è´£ä»»ã€‚

## 3. ä½¿ç”¨ç›®çš„é™åˆ¶
æœ¬é¡¹ç›®ä¸¥ç¦ç”¨äºä»»ä½•éæ³•ç›®çš„æˆ–éå­¦ä¹ ã€éç ”ç©¶çš„å•†ä¸šè¡Œä¸ºã€‚æœ¬é¡¹ç›®ä¸å¾—ç”¨äºä»»ä½•å½¢å¼çš„éæ³•ä¾µå…¥ä»–äººè®¡ç®—æœºç³»ç»Ÿï¼Œä¸å¾—ç”¨äºä»»ä½•ä¾µçŠ¯ä»–äººçŸ¥è¯†äº§æƒæˆ–å…¶ä»–åˆæ³•æƒç›Šçš„è¡Œä¸ºã€‚ç”¨æˆ·åº”ä¿è¯å…¶ä½¿ç”¨æœ¬é¡¹ç›®çš„ç›®çš„çº¯å±ä¸ªäººå­¦ä¹ å’ŒæŠ€æœ¯ç ”ç©¶ï¼Œä¸å¾—ç”¨äºä»»ä½•å½¢å¼çš„éæ³•æ´»åŠ¨ã€‚

## 4. å…è´£å£°æ˜
å¼€å‘è€…å·²å°½æœ€å¤§åŠªåŠ›ç¡®ä¿æœ¬é¡¹ç›®çš„æ­£å½“æ€§åŠå®‰å…¨æ€§ï¼Œä½†ä¸å¯¹ç”¨æˆ·ä½¿ç”¨æœ¬é¡¹ç›®å¯èƒ½å¼•èµ·çš„ä»»ä½•å½¢å¼çš„ç›´æ¥æˆ–é—´æ¥æŸå¤±æ‰¿æ‹…è´£ä»»ã€‚åŒ…æ‹¬ä½†ä¸é™äºç”±äºä½¿ç”¨æœ¬é¡¹ç›®è€Œå¯¼è‡´çš„ä»»ä½•æ•°æ®ä¸¢å¤±ã€è®¾å¤‡æŸåã€æ³•å¾‹è¯‰è®¼ç­‰ã€‚

## 5. çŸ¥è¯†äº§æƒå£°æ˜
æœ¬é¡¹ç›®çš„çŸ¥è¯†äº§æƒå½’å¼€å‘è€…æ‰€æœ‰ã€‚æœ¬é¡¹ç›®å—åˆ°è‘—ä½œæƒæ³•å’Œå›½é™…è‘—ä½œæƒæ¡çº¦ä»¥åŠå…¶ä»–çŸ¥è¯†äº§æƒæ³•å¾‹å’Œæ¡çº¦çš„ä¿æŠ¤ã€‚ç”¨æˆ·åœ¨éµå®ˆæœ¬å£°æ˜åŠç›¸å…³æ³•å¾‹æ³•è§„çš„å‰æä¸‹ï¼Œå¯ä»¥ä¸‹è½½å’Œä½¿ç”¨æœ¬é¡¹ç›®ã€‚

## 6. æœ€ç»ˆè§£é‡Šæƒ
å…³äºæœ¬é¡¹ç›®çš„æœ€ç»ˆè§£é‡Šæƒå½’å¼€å‘è€…æ‰€æœ‰ã€‚å¼€å‘è€…ä¿ç•™éšæ—¶æ›´æ”¹æˆ–æ›´æ–°æœ¬å…è´£å£°æ˜çš„æƒåˆ©ï¼Œæ•ä¸å¦è¡Œé€šçŸ¥ã€‚
&lt;/div&gt;


## ğŸ™ è‡´è°¢

### JetBrains å¼€æºè®¸å¯è¯æ”¯æŒ

æ„Ÿè°¢ JetBrains ä¸ºæœ¬é¡¹ç›®æä¾›å…è´¹çš„å¼€æºè®¸å¯è¯æ”¯æŒï¼

&lt;a href=&quot;https://www.jetbrains.com/?from=MediaCrawler&quot;&gt;
    &lt;img src=&quot;https://www.jetbrains.com/company/brand/img/jetbrains_logo.png&quot; width=&quot;100&quot; alt=&quot;JetBrains&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Free-TV/IPTV]]></title>
            <link>https://github.com/Free-TV/IPTV</link>
            <guid>https://github.com/Free-TV/IPTV</guid>
            <pubDate>Mon, 07 Jul 2025 00:04:42 GMT</pubDate>
            <description><![CDATA[M3U Playlist for free TV channels]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Free-TV/IPTV">Free-TV/IPTV</a></h1>
            <p>M3U Playlist for free TV channels</p>
            <p>Language: Python</p>
            <p>Stars: 6,403</p>
            <p>Forks: 1,108</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>Free TV
=======

This is an M3U playlist for free TV channels around the World.

Either free locally (over the air):

[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/us.svg&quot; width=&quot;24&quot;&gt;](lists/usa.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ca.svg&quot; width=&quot;24&quot;&gt;](lists/canada.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/gb.svg&quot; width=&quot;24&quot;&gt;](lists/uk.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ie.svg&quot; width=&quot;24&quot;&gt;](lists/ireland.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/au.svg&quot; width=&quot;24&quot;&gt;](lists/australia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/in.svg&quot; width=&quot;24&quot;&gt;](lists/india.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/jp.svg&quot; width=&quot;24&quot;&gt;](lists/japan.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/cn.svg&quot; width=&quot;24&quot;&gt;](lists/china.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/hk.svg&quot; width=&quot;24&quot;&gt;](lists/hong_kong.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/mo.svg&quot; width=&quot;24&quot;&gt;](lists/macau.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/tw.svg&quot; width=&quot;24&quot;&gt;](lists/taiwan.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/kp.svg&quot; width=&quot;24&quot;&gt;](lists/north_korea.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/kr.svg&quot; width=&quot;24&quot;&gt;](lists/korea.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/dk.svg&quot; width=&quot;24&quot;&gt;](lists/denmark.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/fo.svg&quot; width=&quot;24&quot;&gt;](lists/faroe_islands.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/gl.svg&quot; width=&quot;24&quot;&gt;](lists/greenland.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/fi.svg&quot; width=&quot;24&quot;&gt;](lists/finland.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/is.svg&quot; width=&quot;24&quot;&gt;](lists/iceland.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/no.svg&quot; width=&quot;24&quot;&gt;](lists/norway.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/se.svg&quot; width=&quot;24&quot;&gt;](lists/sweden.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ee.svg&quot; width=&quot;24&quot;&gt;](lists/estonia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/lv.svg&quot; width=&quot;24&quot;&gt;](lists/latvia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/lt.svg&quot; width=&quot;24&quot;&gt;](lists/lithuania.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/be.svg&quot; width=&quot;24&quot;&gt;](lists/belgium.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/nl.svg&quot; width=&quot;24&quot;&gt;](lists/netherlands.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/lu.svg&quot; width=&quot;24&quot;&gt;](lists/luxembourg.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/de.svg&quot; width=&quot;24&quot;&gt;](lists/germany.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/at.svg&quot; width=&quot;24&quot;&gt;](lists/austria.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ch.svg&quot; width=&quot;24&quot;&gt;](lists/switzerland.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/pl.svg&quot; width=&quot;24&quot;&gt;](lists/poland.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/cz.svg&quot; width=&quot;24&quot;&gt;](lists/czech_republic.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/sk.svg&quot; width=&quot;24&quot;&gt;](lists/slovakia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/hu.svg&quot; width=&quot;24&quot;&gt;](lists/hungary.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ro.svg&quot; width=&quot;24&quot;&gt;](lists/romania.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/md.svg&quot; width=&quot;24&quot;&gt;](lists/moldova.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/bg.svg&quot; width=&quot;24&quot;&gt;](lists/bulgaria.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/fr.svg&quot; width=&quot;24&quot;&gt;](lists/france.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/it.svg&quot; width=&quot;24&quot;&gt;](lists/italy.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/pt.svg&quot; width=&quot;24&quot;&gt;](lists/portugal.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/es.svg&quot; width=&quot;24&quot;&gt;](lists/spain.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ru.svg&quot; width=&quot;24&quot;&gt;](lists/russia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/by.svg&quot; width=&quot;24&quot;&gt;](lists/belarus.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ua.svg&quot; width=&quot;24&quot;&gt;](lists/ukraine.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/am.svg&quot; width=&quot;24&quot;&gt;](lists/armenia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/az.svg&quot; width=&quot;24&quot;&gt;](lists/azerbaijan.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ge.svg&quot; width=&quot;24&quot;&gt;](lists/georgia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ba.svg&quot; width=&quot;24&quot;&gt;](lists/bosnia_and_herzegovina.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/hr.svg&quot; width=&quot;24&quot;&gt;](lists/croatia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/me.svg&quot; width=&quot;24&quot;&gt;](lists/montenegro.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/mk.svg&quot; width=&quot;24&quot;&gt;](lists/north_macedonia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/rs.svg&quot; width=&quot;24&quot;&gt;](lists/serbia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/si.svg&quot; width=&quot;24&quot;&gt;](lists/slovenia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/al.svg&quot; width=&quot;24&quot;&gt;](lists/albania.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/xk.svg&quot; width=&quot;24&quot;&gt;](lists/kosovo.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/gr.svg&quot; width=&quot;24&quot;&gt;](lists/greece.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/cy.svg&quot; width=&quot;24&quot;&gt;](lists/cyprus.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ad.svg&quot; width=&quot;24&quot;&gt;](lists/andorra.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/mt.svg&quot; width=&quot;24&quot;&gt;](lists/malta.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/mc.svg&quot; width=&quot;24&quot;&gt;](lists/monaco.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/sm.svg&quot; width=&quot;24&quot;&gt;](lists/san_marino.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ir.svg&quot; width=&quot;24&quot;&gt;](lists/iran.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/iq.svg&quot; width=&quot;24&quot;&gt;](lists/iraq.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/il.svg&quot; width=&quot;24&quot;&gt;](lists/israel.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/qa.svg&quot; width=&quot;24&quot;&gt;](lists/qatar.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/tr.svg&quot; width=&quot;24&quot;&gt;](lists/turkey.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ae.svg&quot; width=&quot;24&quot;&gt;](lists/united_arab_emirates.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ar.svg&quot; width=&quot;24&quot;&gt;](lists/argentina.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/cr.svg&quot; width=&quot;24&quot;&gt;](lists/costa_rica.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/do.svg&quot; width=&quot;24&quot;&gt;](lists/dominican_republic.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/mx.svg&quot; width=&quot;24&quot;&gt;](lists/mexico.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/py.svg&quot; width=&quot;24&quot;&gt;](lists/paraguay.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/pe.svg&quot; width=&quot;24&quot;&gt;](lists/peru.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ve.svg&quot; width=&quot;24&quot;&gt;](lists/venezuela.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/br.svg&quot; width=&quot;24&quot;&gt;](lists/brazil.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/tt.svg&quot; width=&quot;24&quot;&gt;](lists/trinidad.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/td.svg&quot; width=&quot;24&quot;&gt;](lists/chad.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/so.svg&quot; width=&quot;24&quot;&gt;](lists/somalia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/id.svg&quot; width=&quot;24&quot;&gt;](lists/indonesia.md)

Or free on the Internet:

- Plex TV
- Pluto TV (English, Spanish, French, Italian)
- Redbox Live TV
- Roku TV
- Samsung TV Plus
- Youtube live channels

To use it point your IPTV player to https://raw.githubusercontent.com/Free-TV/IPTV/master/playlist.m3u8.

Philosophy
==========

The main goals for this playlist are listed below.

**Quality over quantity**

The less channels we support the better.

- All channels should work well.
- As much as possible channels should be in HD, not SD.
- Only one URL per channel (no +1, no alternate feeds, no regional declinations)

**Only free channels**

If a channel is normally only available via commercial subscriptions it has nothing to do in this playlist. If on the other hand it is provided for free to everybody in a particular country, then it should be in this playlist.

- No paid channels
- Only channels which are officially provided for free (via DVB-S, DVB-T, analog, etc..)

**Only mainstream channels**

This is a playlist for everybody.

- No adult channels
- No channels dedicated to any particular religion
- No channels dedicated to any particular political party
- No channels made for a country and funded by a different country

Feed sources
============

It can be quite hard to find up to date URLs, here&#039;s a list of sources:

- https://github.com/iptv-org/iptv/tree/master/streams
- Youtube: As long as the channel is live and its URL doesn&#039;t change (check the age of the stream, the number of viewers..)
- Dailymotion: Same criteria as for youtube

Format
======

The m3u8 playlist is generated by `make_playlist.py`, using the `.md` files located in `lists`.

Each .md file represesnts a group. The `&lt;h1&gt;` line is used as the group title.

Only channels which URL column starts with `[&gt;]` are included in the playlist.

Channels which are not in HD are marked with an `â“ˆ`.

Channels which use GeoIP blocking are marked with a `â’¼`.

Channels which are live Youtube channels are marked with a `â“`.

Issues
======

Only create issues for bugs and feature requests.

Do not create issues to add/edit or to remove channels. If you want to add/edit/remove channels, create a pull request directly.

Pull Requests
=============

**Only modify .md files**

If your Pull Request modifies channels, only modify .md files. Do not modify m3u8 files in your pull request.

**Adding a new Channel**

To add a new channel, make a Pull Request.

- In your Pull Request you need to provide information to show that the channel is free.
- Use imgur.com to host the channel logo and point to it.
- If you have a valid stream, add it and put `[&gt;]` in front of it.
- If you don&#039;t have an stream for the channel, add `[x]()` in the url column and place your channel in the Invalid category.
- If you have a stream but it doesn&#039;t work well, put the channel in the Invalid category and put `[x]` in front of the url.
- If you&#039;re adding geoblocked URLs specify it in your PR and specify which country they&#039;re working in. The PR will only be merged if these URLs can be tested.

**Removing a Channel**

To remove a channel, make a Pull Request.

In your Pull Request you need to provide information to show that the channel is only available via a private paid subscription.

Note: Public taxes (whether national or regional, whether called TV License or not) do not constitute a private paid subscription.

If a stream is broken, simply move the channel to the invalid category and replace `[&gt;]` with `[x]` in the url column.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[dyang886/Game-Cheats-Manager]]></title>
            <link>https://github.com/dyang886/Game-Cheats-Manager</link>
            <guid>https://github.com/dyang886/Game-Cheats-Manager</guid>
            <pubDate>Mon, 07 Jul 2025 00:04:41 GMT</pubDate>
            <description><![CDATA[Easily download and manage game cheats for your convenience]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dyang886/Game-Cheats-Manager">dyang886/Game-Cheats-Manager</a></h1>
            <p>Easily download and manage game cheats for your convenience</p>
            <p>Language: Python</p>
            <p>Stars: 8,302</p>
            <p>Forks: 301</p>
            <p>Stars today: 47 stars today</p>
            <h2>README</h2><pre># Game Cheats Manager

English | [ç®€ä½“ä¸­æ–‡](./README_CN.md) | [ç¹é«”ä¸­æ–‡](./README_TW.md)

![GitHub Downloads (all assets, all releases)](https://img.shields.io/github/downloads/dyang886/Game-Cheats-Manager/total) ![GitHub Repo stars](https://img.shields.io/github/stars/dyang886/Game-Cheats-Manager?style=flat&amp;color=ffc000) ![GitHub Release](https://img.shields.io/github/v/release/dyang886/Game-Cheats-Manager?link=https%3A%2F%2Fgithub.com%2Fdyang886%2FGame-Cheats-Manager%2Freleases%2Flatest) ![GitHub License](https://img.shields.io/github/license/dyang886/Game-Cheats-Manager) &lt;a href=&quot;https://hellogithub.com/repository/3ca6e8e23401477282ba72d2d8932311&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=3ca6e8e23401477282ba72d2d8932311&amp;claim_uid=UrZOap0AkvuRw7D&amp;theme=small&quot; alt=&quot;Featuredï½œHelloGitHub&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/d627qVyHEF&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Join_Discord-f0f0f0?logo=discord&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pd.qq.com/s/h06qbdey6&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Join_QQ-f0f0f0?logo=qq&quot;&gt;&lt;/a&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;src/assets/logo.png&quot; alt=&quot;Game Cheats Manager logo&quot; width=&quot;250&quot; /&gt;
&lt;/div&gt;

Game Cheats Manager is a one-stop solution for gamers to manage their trainers efficiently. It allows users to browse, download, and manage all their trainers from one convenient location. Each trainer, typically a standalone executable, can be launched or deleted directly through the app, simplifying your gaming experience by keeping everything organized and accessible.

## Usage

1. **Browse Trainers**: In the left column, use the search bar or browse the list to find downloaded trainers. Double-click or click on the `Launch` button to launch a trainer; click on the `Delete` button to delete a trainer.
2. **Download Trainers**: In the right column, search with keywords and press `Enter` to get a list of available trainers. Double-click the desired match to download it directly. The trainer download path is displayed at the bottom of the right column, you can change it by clicking `...` on the right.
3. **Trainer Management**: The `Trainer Management` panel provides you with all the settings for each trainer source in one place. You can find settings like automatically updating trainers and trainer search data, or changing the download server, etc.
4. **Options**: The `Options` menu bar consists of the following functionalities:
   1. **Settings**: Adjust settings like themes and languages.
   2. **Import Trainers**: Select trainers that you want to import from the file selection window. Imported trainers are unable to auto-update.
   3. **Open Trainer Download Path**: View the trainer download folder.
   4. **Add Paths to Whitelist**: Add the trainer download path to the Windows Defender whitelist. You can do it manually if you have installed other antivirus software.
   5. **About**: View app version and project-related links.

## Installation

1. **Download the Installer**: Navigate to the [latest release](https://github.com/dyang886/Game-Cheats-Manager/releases) and download the installer for Windows (64-bit).
2. **Run the Installer**: Execute the downloaded file and follow the on-screen instructions to install Game Cheats Manager.
3. **Launch the Application**: Open Game Cheats Manager from your applications folder or start menu.

## Support

For issues, feature requests, or contributions, please visit the [GitHub repository](https://github.com/dyang886/Game-Cheats-Manager).

Below are funding options:

|                            WeChat                            |                          Alipay                          |                          QQ                          |
| :----------------------------------------------------------: | :------------------------------------------------------: | :--------------------------------------------------: |
| &lt;img src=&quot;src/assets/wechat.png&quot; alt=&quot;WeChat Pay&quot; width=&quot;200&quot; /&gt; | &lt;img src=&quot;src/assets/alipay.png&quot; alt=&quot;Alipay&quot; width=&quot;200&quot; /&gt; | &lt;img src=&quot;src/assets/qq.png&quot; alt=&quot;QQ Pay&quot; width=&quot;200&quot; /&gt; |

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[megadose/toutatis]]></title>
            <link>https://github.com/megadose/toutatis</link>
            <guid>https://github.com/megadose/toutatis</guid>
            <pubDate>Mon, 07 Jul 2025 00:04:40 GMT</pubDate>
            <description><![CDATA[Toutatis is a tool that allows you to extract information from instagrams accounts such as e-mails, phone numbers and more]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/megadose/toutatis">megadose/toutatis</a></h1>
            <p>Toutatis is a tool that allows you to extract information from instagrams accounts such as e-mails, phone numbers and more</p>
            <p>Language: Python</p>
            <p>Stars: 2,769</p>
            <p>Forks: 412</p>
            <p>Stars today: 156 stars today</p>
            <h2>README</h2><pre># Toutatis
ğŸ‘‹ Hi there! For any professional inquiries or collaborations, please reach out to me at:
megadose@protonmail.com

ğŸ“§ Preferably, use your professional email for correspondence. Let&#039;s keep it short and sweet, and all in English!

Toutatis is a tool that allows you to extract information from instagrams accounts such as e-mails, phone numbers and more &lt;/br&gt;
For BTC Donations : 1FHDM49QfZX6pJmhjLE5tB2K6CaTLMZpXZ
## ğŸ’¡ Prerequisite
[Python 3](https://www.python.org/downloads/release/python-370/)

## ğŸ› ï¸ Installation
### With PyPI

```pip install toutatis```

### With Github

```bash
git clone https://github.com/megadose/toutatis.git
cd toutatis/
python3 setup.py install
```

## ğŸ“š Usage:

### Find information from a username

```
toutatis -u username -s instagramsessionid
```

### Find information from an Instagram ID

```
toutatis -i instagramID -s instagramsessionid
```

## ğŸ“ˆ Example

```
Informations about     : xxxusernamexxx
Full Name              : xxxusernamesxx | userID : 123456789
Verified               : False | Is buisness Account : False
Is private Account     : False
Follower               : xxx | Following : xxx
Number of posts        : x
Number of tag in posts : x
External url           : http://example.com
IGTV posts             : x
Biography              : example biography
Public Email           : public@example.com
Public Phone           : +00 0 00 00 00 00
Obfuscated email       : me********s@examplemail.com
Obfuscated phone       : +00 0xx xxx xx 00
------------------------
Profile Picture        : https://scontent-X-X.cdninstagram.com/
```

## ğŸ“š To retrieve the sessionID
![](https://files.catbox.moe/1rfi6j.png)

## Thank you to :

- [EyupErgin](https://github.com/eyupergin)
- [yazeed44](https://github.com/yazeed44)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[chrishayuk/mcp-cli]]></title>
            <link>https://github.com/chrishayuk/mcp-cli</link>
            <guid>https://github.com/chrishayuk/mcp-cli</guid>
            <pubDate>Mon, 07 Jul 2025 00:04:39 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/chrishayuk/mcp-cli">chrishayuk/mcp-cli</a></h1>
            <p></p>
            <p>Language: Python</p>
            <p>Stars: 1,467</p>
            <p>Forks: 255</p>
            <p>Stars today: 46 stars today</p>
            <h2>README</h2><pre># MCP CLI - Model Context Protocol Command Line Interface

A powerful, feature-rich command-line interface for interacting with Model Context Protocol servers. This client enables seamless communication with LLMs through integration with the [CHUK Tool Processor](https://github.com/chrishayuk/chuk-tool-processor) and [CHUK-LLM](https://github.com/chrishayuk/chuk-llm), providing tool usage, conversation management, and multiple operational modes.

## ğŸ”„ Architecture Overview

The MCP CLI is built on a modular architecture with clean separation of concerns:

- **[CHUK Tool Processor](https://github.com/chrishayuk/chuk-tool-processor)**: Async-native tool execution and MCP server communication
- **[CHUK-LLM](https://github.com/chrishayuk/chuk-llm)**: Unified LLM provider configuration and client management
- **MCP CLI**: Rich user interface and command orchestration (this project)

## ğŸŒŸ Features

### Multiple Operational Modes
- **Chat Mode**: Conversational interface with streaming responses and automated tool usage
- **Interactive Mode**: Command-driven shell interface for direct server operations
- **Command Mode**: Unix-friendly mode for scriptable automation and pipelines
- **Direct Commands**: Run individual commands without entering interactive mode

### Advanced Chat Interface
- **Streaming Responses**: Real-time response generation with live UI updates
- **Concurrent Tool Execution**: Execute multiple tools simultaneously while preserving conversation order
- **Smart Interruption**: Interrupt streaming responses or tool execution with Ctrl+C
- **Performance Metrics**: Response timing, words/second, and execution statistics
- **Rich Formatting**: Markdown rendering, syntax highlighting, and progress indicators

### Comprehensive Provider Support
- **OpenAI**: GPT models (`gpt-4o`, `gpt-4o-mini`, `gpt-4-turbo`, etc.)
- **Anthropic**: Claude models (`claude-3-opus`, `claude-3-sonnet`, `claude-3-haiku`)
- **Ollama**: Local models (`llama3.2`, `qwen2.5-coder`, `deepseek-coder`, etc.)
- **Custom Providers**: Extensible architecture for additional providers
- **Dynamic Switching**: Change providers and models mid-conversation

### Robust Tool System
- **Automatic Discovery**: Server-provided tools are automatically detected and catalogued
- **Provider Adaptation**: Tool names are automatically sanitized for provider compatibility
- **Concurrent Execution**: Multiple tools can run simultaneously with proper coordination
- **Rich Progress Display**: Real-time progress indicators and execution timing
- **Tool History**: Complete audit trail of all tool executions
- **Streaming Tool Calls**: Support for tools that return streaming data

### Advanced Configuration Management
- **Environment Integration**: API keys and settings via environment variables
- **File-based Config**: YAML and JSON configuration files
- **User Preferences**: Persistent settings for active providers and models
- **Validation &amp; Diagnostics**: Built-in provider health checks and configuration validation

### Enhanced User Experience
- **Cross-Platform Support**: Windows, macOS, and Linux with platform-specific optimizations
- **Rich Console Output**: Colorful, formatted output with automatic fallbacks
- **Command Completion**: Context-aware tab completion for all interfaces
- **Comprehensive Help**: Detailed help system with examples and usage patterns
- **Graceful Error Handling**: User-friendly error messages with troubleshooting hints

## ğŸ“‹ Prerequisites

- **Python 3.11 or higher**
- **API Keys** (as needed):
  - OpenAI: `OPENAI_API_KEY` environment variable
  - Anthropic: `ANTHROPIC_API_KEY` environment variable
  - Custom providers: Provider-specific configuration
- **Local Services** (as needed):
  - Ollama: Local installation for Ollama models
- **MCP Servers**: Server configuration file (default: `server_config.json`)

## ğŸš€ Installation

### Install from Source

1. **Clone the repository**:
```bash
git clone https://github.com/chrishayuk/mcp-cli
cd mcp-cli  
```

2. **Install the package**:
```bash
pip install -e &quot;.[cli,dev]&quot;
```

3. **Verify installation**:
```bash
mcp-cli --help
```

### Using UV (Recommended)

UV provides faster dependency resolution and better environment management:

```bash
# Install UV if not already installed
pip install uv

# Install dependencies
uv sync --reinstall

# Run with UV
uv run mcp-cli --help
```

## ğŸ§° Global Configuration

### Command-line Arguments

Global options available for all modes and commands:

- `--server`: Specify server(s) to connect to (comma-separated)
- `--config-file`: Path to server configuration file (default: `server_config.json`)
- `--provider`: LLM provider (`openai`, `anthropic`, `ollama`, etc.)
- `--model`: Specific model to use (provider-dependent)
- `--disable-filesystem`: Disable filesystem access (default: enabled)
- `--api-base`: Override API endpoint URL
- `--api-key`: Override API key
- `--verbose`: Enable detailed logging
- `--quiet`: Suppress non-essential output

### Environment Variables

```bash
export LLM_PROVIDER=openai              # Default provider
export LLM_MODEL=gpt-4o-mini           # Default model
export OPENAI_API_KEY=sk-...           # OpenAI API key
export ANTHROPIC_API_KEY=sk-ant-...    # Anthropic API key
export MCP_TOOL_TIMEOUT=120            # Tool execution timeout (seconds)
```

## ğŸŒ Available Modes

### 1. Chat Mode (Default)

Provides a natural language interface with streaming responses and automatic tool usage:

```bash
# Default mode (no subcommand needed)
mcp-cli --server sqlite

# Explicit chat mode
mcp-cli chat --server sqlite

# With specific provider and model
mcp-cli chat --server sqlite --provider anthropic --model claude-3-sonnet

# With custom configuration
mcp-cli chat --server sqlite --provider openai --api-key sk-... --model gpt-4o
```

### 2. Interactive Mode

Command-driven shell interface for direct server operations:

```bash
mcp-cli interactive --server sqlite

# With provider selection
mcp-cli interactive --server sqlite --provider ollama --model llama3.2
```

### 3. Command Mode

Unix-friendly interface for automation and scripting:

```bash
# Process text with LLM
mcp-cli cmd --server sqlite --prompt &quot;Analyze this data&quot; --input data.txt

# Execute tools directly
mcp-cli cmd --server sqlite --tool list_tables --output tables.json

# Pipeline-friendly processing
echo &quot;SELECT * FROM users LIMIT 5&quot; | mcp-cli cmd --server sqlite --tool read_query --input -
```

### 4. Direct Commands

Execute individual commands without entering interactive mode:

```bash
# List available tools
mcp-cli tools --server sqlite

# Show provider configuration
mcp-cli provider list

# Ping servers
mcp-cli ping --server sqlite

# List resources
mcp-cli resources --server sqlite
```

## ğŸ¤– Using Chat Mode

Chat mode provides the most advanced interface with streaming responses and intelligent tool usage.

### Starting Chat Mode

```bash
# Simple startup
mcp-cli --server sqlite

# Multiple servers
mcp-cli --server sqlite,filesystem

# Specific provider configuration
mcp-cli --server sqlite --provider anthropic --model claude-3-opus
```

### Chat Commands (Slash Commands)

#### Provider &amp; Model Management
```bash
/provider                           # Show current configuration
/provider list                      # List all providers
/provider config                    # Show detailed configuration
/provider diagnostic               # Test provider connectivity
/provider set openai api_key sk-... # Configure provider settings
/provider anthropic                # Switch to Anthropic
/provider openai gpt-4o            # Switch provider and model

/model                             # Show current model
/model gpt-4o                      # Switch to specific model
/models                            # List available models
```

#### Tool Management
```bash
/tools                             # List available tools
/tools --all                       # Show detailed tool information
/tools --raw                       # Show raw JSON definitions
/tools call                        # Interactive tool execution

/toolhistory                       # Show tool execution history
/th -n 5                          # Last 5 tool calls
/th 3                             # Details for call #3
/th --json                        # Full history as JSON
```

#### Conversation Management
```bash
/conversation                      # Show conversation history
/ch -n 10                         # Last 10 messages
/ch 5                             # Details for message #5
/ch --json                        # Full history as JSON

/save conversation.json            # Save conversation to file
/compact                          # Summarize conversation
/clear                            # Clear conversation history
/cls                              # Clear screen only
```

#### Session Control
```bash
/verbose                          # Toggle verbose/compact display
/interrupt                        # Stop running operations
/servers                          # List connected servers
/help                            # Show all commands
/help tools                       # Help for specific command
/exit                            # Exit chat mode
```

### Chat Features

#### Streaming Responses
- Real-time text generation with live updates
- Performance metrics (words/second, response time)
- Graceful interruption with Ctrl+C
- Progressive markdown rendering

#### Tool Execution
- Automatic tool discovery and usage
- Concurrent execution with progress indicators
- Verbose and compact display modes
- Complete execution history and timing

#### Provider Integration
- Seamless switching between providers
- Model-specific optimizations
- API key and endpoint management
- Health monitoring and diagnostics

## ğŸ–¥ï¸ Using Interactive Mode

Interactive mode provides a command shell for direct server interaction.

### Starting Interactive Mode

```bash
mcp-cli interactive --server sqlite
```

### Interactive Commands

```bash
help                              # Show available commands
exit                              # Exit interactive mode
clear                             # Clear terminal

# Provider management
provider                          # Show current provider
provider list                     # List providers
provider anthropic                # Switch provider

# Tool operations
tools                             # List tools
tools --all                       # Detailed tool info
tools call                        # Interactive tool execution

# Server operations
servers                           # List servers
ping                              # Ping all servers
resources                         # List resources
prompts                           # List prompts
```

## ğŸ“„ Using Command Mode

Command mode provides Unix-friendly automation capabilities.

### Command Mode Options

```bash
--input FILE                      # Input file (- for stdin)
--output FILE                     # Output file (- for stdout)
--prompt TEXT                     # Prompt template
--tool TOOL                       # Execute specific tool
--tool-args JSON                  # Tool arguments as JSON
--system-prompt TEXT              # Custom system prompt
--raw                             # Raw output without formatting
--single-turn                     # Disable multi-turn conversation
--max-turns N                     # Maximum conversation turns
```

### Examples

```bash
# Text processing
echo &quot;Analyze this data&quot; | mcp-cli cmd --server sqlite --input - --output analysis.txt

# Tool execution
mcp-cli cmd --server sqlite --tool list_tables --raw

# Complex queries
mcp-cli cmd --server sqlite --tool read_query --tool-args &#039;{&quot;query&quot;: &quot;SELECT COUNT(*) FROM users&quot;}&#039;

# Batch processing with GNU Parallel
ls *.txt | parallel mcp-cli cmd --server sqlite --input {} --output {}.summary --prompt &quot;Summarize: {{input}}&quot;
```

## ğŸ”§ Provider Configuration

### Automatic Configuration

The CLI automatically manages provider configurations using the CHUK-LLM library:

```bash
# Configure a provider
mcp-cli provider set openai api_key sk-your-key-here
mcp-cli provider set anthropic api_base https://api.anthropic.com

# Test configuration
mcp-cli provider diagnostic openai

# List available models
mcp-cli provider list
```

### Manual Configuration

Providers are configured in `~/.chuk_llm/providers.yaml`:

```yaml
openai:
  api_base: https://api.openai.com/v1
  default_model: gpt-4o-mini

anthropic:
  api_base: https://api.anthropic.com
  default_model: claude-3-sonnet

ollama:
  api_base: http://localhost:11434
  default_model: llama3.2
```

API keys are stored securely in `~/.chuk_llm/.env`:

```bash
OPENAI_API_KEY=sk-your-key-here
ANTHROPIC_API_KEY=sk-ant-your-key-here
```

## ğŸ“‚ Server Configuration

Create a `server_config.json` file with your MCP server configurations:

```json
{
  &quot;mcpServers&quot;: {
    &quot;sqlite&quot;: {
      &quot;command&quot;: &quot;python&quot;,
      &quot;args&quot;: [&quot;-m&quot;, &quot;mcp_server.sqlite_server&quot;],
      &quot;env&quot;: {
        &quot;DATABASE_PATH&quot;: &quot;database.db&quot;
      }
    },
    &quot;filesystem&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;@modelcontextprotocol/server-filesystem&quot;, &quot;/path/to/allowed/files&quot;],
      &quot;env&quot;: {}
    },
    &quot;brave-search&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;@modelcontextprotocol/server-brave-search&quot;],
      &quot;env&quot;: {
        &quot;BRAVE_API_KEY&quot;: &quot;your-brave-api-key&quot;
      }
    }
  }
}
```

## ğŸ“ˆ Advanced Usage Examples

### Multi-Provider Workflow

```bash
# Start with OpenAI
mcp-cli chat --server sqlite --provider openai --model gpt-4o

# In chat, switch to Anthropic for reasoning tasks
&gt; /provider anthropic claude-3-opus

# Switch to Ollama for local processing
&gt; /provider ollama llama3.2

# Compare responses across providers
&gt; /provider openai
&gt; What&#039;s the capital of France?
&gt; /provider anthropic  
&gt; What&#039;s the capital of France?
```

### Complex Tool Workflows

```bash
# Database analysis workflow
&gt; List all tables in the database
[Tool: list_tables] â†’ products, customers, orders

&gt; Show me the schema for the products table
[Tool: describe_table] â†’ id, name, price, category, stock

&gt; Find the top 10 most expensive products
[Tool: read_query] â†’ SELECT name, price FROM products ORDER BY price DESC LIMIT 10

&gt; Export this data to a CSV file
[Tool: write_file] â†’ Saved to expensive_products.csv
```

### Automation and Scripting

```bash
# Batch data processing
for file in data/*.csv; do
  mcp-cli cmd --server sqlite \
    --tool analyze_data \
    --tool-args &quot;{\&quot;file_path\&quot;: \&quot;$file\&quot;}&quot; \
    --output &quot;results/$(basename &quot;$file&quot; .csv)_analysis.json&quot;
done

# Pipeline processing
cat input.txt | \
  mcp-cli cmd --server sqlite --prompt &quot;Extract key entities&quot; --input - | \
  mcp-cli cmd --server sqlite --prompt &quot;Categorize these entities&quot; --input - &gt; output.txt
```

### Performance Monitoring

```bash
# Enable verbose mode for detailed timing
&gt; /verbose

# Monitor tool execution times
&gt; /toolhistory
Tool Call History (15 calls)
#  | Tool        | Arguments                    | Time
1  | list_tables | {}                          | 0.12s
2  | read_query  | {&quot;query&quot;: &quot;SELECT...&quot;}      | 0.45s
...

# Check provider performance
&gt; /provider diagnostic
Provider Diagnostics
Provider   | Status      | Response Time | Features
openai     | âœ… Ready    | 234ms        | ğŸ“¡ğŸ”§ğŸ‘ï¸
anthropic  | âœ… Ready    | 187ms        | ğŸ“¡ğŸ”§
ollama     | âœ… Ready    | 56ms         | ğŸ“¡ğŸ”§
```

## ğŸ” Troubleshooting

### Common Issues

1. **&quot;Missing argument &#039;KWARGS&#039;&quot; error**:
   ```bash
   # Use equals sign format
   mcp-cli chat --server=sqlite --provider=openai
   
   # Or add double dash
   mcp-cli chat -- --server sqlite --provider openai
   ```

2. **Provider not found**:
   ```bash
   mcp-cli provider diagnostic
   mcp-cli provider set &lt;provider&gt; api_key &lt;your-key&gt;
   ```

3. **Tool execution timeout**:
   ```bash
   export MCP_TOOL_TIMEOUT=300  # 5 minutes
   ```

4. **Connection issues**:
   ```bash
   mcp-cli ping --server &lt;server-name&gt;
   mcp-cli servers
   ```

### Debug Mode

Enable verbose logging for troubleshooting:

```bash
mcp-cli --verbose chat --server sqlite
mcp-cli --log-level DEBUG interactive --server sqlite
```

## ğŸ”’ Security Considerations

- **API Keys**: Stored securely in environment variables or protected files
- **File Access**: Filesystem access can be disabled with `--disable-filesystem`
- **Tool Validation**: All tool calls are validated before execution
- **Timeout Protection**: Configurable timeouts prevent hanging operations
- **Server Isolation**: Each server runs in its own process

## ğŸš€ Performance Features

- **Concurrent Tool Execution**: Multiple tools can run simultaneously
- **Streaming Responses**: Real-time response generation
- **Connection Pooling**: Efficient reuse of client connections
- **Caching**: Tool metadata and provider configurations are cached
- **Async Architecture**: Non-blocking operations throughout

## ğŸ“¦ Dependencies

Core dependencies are organized into feature groups:

- **cli**: Rich terminal UI, command completion, provider integrations
- **dev**: Development tools, testing utilities, linting
- **chuk-tool-processor**: Core tool execution and MCP communication
- **chuk-llm**: Unified LLM provider management

Install with specific features:
```bash
pip install &quot;mcp-cli[cli]&quot;        # Basic CLI features
pip install &quot;mcp-cli[cli,dev]&quot;    # CLI with development tools
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Setup

```bash
git clone https://github.com/chrishayuk/mcp-cli
cd mcp-cli
pip install -e &quot;.[cli,dev]&quot;
pre-commit install
```

### Running Tests

```bash
pytest
pytest --cov=mcp_cli --cov-report=html
```

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **[CHUK Tool Processor](https://github.com/chrishayuk/chuk-tool-processor)** - Async-native tool execution
- **[CHUK-LLM](https://github.com/chrishayuk/chuk-llm)** - Unified LLM provider management
- **[Rich](https://github.com/Textualize/rich)** - Beautiful terminal formatting
- **[Typer](https://typer.tiangolo.com/)** - CLI framework
- **[Prompt Toolkit](https://github.com/prompt-toolkit/python-prompt-toolkit)** - Interactive input

## ğŸ”— Related Projects

- **[Model Context Protocol](https://modelcontextprotocol.io/)** - Core protocol specification
- **[MCP Servers](https://github.com/modelcontextprotocol/servers)** - Official MCP server implementations
- **[CHUK Tool Processor](https://github.com/chrishayuk/chuk-tool-processor)** - Tool execution engine
- **[CHUK-LLM](https://github.com/chrishayuk/chuk-llm)** - LLM provider abstraction</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[coleam00/local-ai-packaged]]></title>
            <link>https://github.com/coleam00/local-ai-packaged</link>
            <guid>https://github.com/coleam00/local-ai-packaged</guid>
            <pubDate>Mon, 07 Jul 2025 00:04:38 GMT</pubDate>
            <description><![CDATA[Run all your local AI together in one package - Ollama, Supabase, n8n, Open WebUI, and more!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/coleam00/local-ai-packaged">coleam00/local-ai-packaged</a></h1>
            <p>Run all your local AI together in one package - Ollama, Supabase, n8n, Open WebUI, and more!</p>
            <p>Language: Python</p>
            <p>Stars: 2,220</p>
            <p>Forks: 860</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre># Self-hosted AI Package

**Self-hosted AI Package** is an open, docker compose template that
quickly bootstraps a fully featured Local AI and Low Code development
environment including Ollama for your local LLMs, Open WebUI for an interface to chat with your N8N agents, and Supabase for your database, vector store, and authentication. 

This is Cole&#039;s version with a couple of improvements and the addition of Supabase, Open WebUI, Flowise, Neo4j, Langfuse, SearXNG, and Caddy!
Also, the local RAG AI Agent workflows from the video will be automatically in your 
n8n instance if you use this setup instead of the base one provided by n8n!

**IMPORANT**: Supabase has updated a couple environment variables so you may have to add some new default values in your .env that I have in my .env.example if you have had this project up and running already and are just pulling new changes. Specifically, you need to add &quot;POOLER_DB_POOL_SIZE=5&quot; to your .env. This is required if you have had the package running before June 14th.

## Important Links

- [Local AI community](https://thinktank.ottomator.ai/c/local-ai/18) forum over in the oTTomator Think Tank

- [GitHub Kanban board](https://github.com/users/coleam00/projects/2/views/1) for feature implementation and bug squashing.

- [Original Local AI Starter Kit](https://github.com/n8n-io/self-hosted-ai-starter-kit) by the n8n team

- Download my N8N + OpenWebUI integration [directly on the Open WebUI site.](https://openwebui.com/f/coleam/n8n_pipe/) (more instructions below)

![n8n.io - Screenshot](https://raw.githubusercontent.com/n8n-io/self-hosted-ai-starter-kit/main/assets/n8n-demo.gif)

Curated by &lt;https://github.com/n8n-io&gt; and &lt;https://github.com/coleam00&gt;, it combines the self-hosted n8n
platform with a curated list of compatible AI products and components to
quickly get started with building self-hosted AI workflows.

### Whatâ€™s included

âœ… [**Self-hosted n8n**](https://n8n.io/) - Low-code platform with over 400
integrations and advanced AI components

âœ… [**Supabase**](https://supabase.com/) - Open source database as a service -
most widely used database for AI agents

âœ… [**Ollama**](https://ollama.com/) - Cross-platform LLM platform to install
and run the latest local LLMs

âœ… [**Open WebUI**](https://openwebui.com/) - ChatGPT-like interface to
privately interact with your local models and N8N agents

âœ… [**Flowise**](https://flowiseai.com/) - No/low code AI agent
builder that pairs very well with n8n

âœ… [**Qdrant**](https://qdrant.tech/) - Open source, high performance vector
store with an comprehensive API. Even though you can use Supabase for RAG, this was
kept unlike Postgres since it&#039;s faster than Supabase so sometimes is the better option.

âœ… [**Neo4j**](https://neo4j.com/) - Knowledge graph engine that powers tools like GraphRAG, LightRAG, and Graphiti 

âœ… [**SearXNG**](https://searxng.org/) - Open source, free internet metasearch engine which aggregates 
results from up to 229 search services. Users are neither tracked nor profiled, hence the fit with the local AI package.

âœ… [**Caddy**](https://caddyserver.com/) - Managed HTTPS/TLS for custom domains

âœ… [**Langfuse**](https://langfuse.com/) - Open source LLM engineering platform for agent observability

## Prerequisites

Before you begin, make sure you have the following software installed:

- [Python](https://www.python.org/downloads/) - Required to run the setup script
- [Git/GitHub Desktop](https://desktop.github.com/) - For easy repository management
- [Docker/Docker Desktop](https://www.docker.com/products/docker-desktop/) - Required to run all services

## Installation

Clone the repository and navigate to the project directory:
```bash
git clone -b stable https://github.com/coleam00/local-ai-packaged.git
cd local-ai-packaged
```

Before running the services, you need to set up your environment variables for Supabase following their [self-hosting guide](https://supabase.com/docs/guides/self-hosting/docker#securing-your-services).

1. Make a copy of `.env.example` and rename it to `.env` in the root directory of the project
2. Set the following required environment variables:
   ```bash
   ############
   # N8N Configuration
   ############
   N8N_ENCRYPTION_KEY=
   N8N_USER_MANAGEMENT_JWT_SECRET=

   ############
   # Supabase Secrets
   ############
   POSTGRES_PASSWORD=
   JWT_SECRET=
   ANON_KEY=
   SERVICE_ROLE_KEY=
   DASHBOARD_USERNAME=
   DASHBOARD_PASSWORD=
   POOLER_TENANT_ID=

   ############
   # Neo4j Secrets
   ############   
   NEO4J_AUTH=

   ############
   # Langfuse credentials
   ############

   CLICKHOUSE_PASSWORD=
   MINIO_ROOT_PASSWORD=
   LANGFUSE_SALT=
   NEXTAUTH_SECRET=
   ENCRYPTION_KEY=  
   ```

&gt; [!IMPORTANT]
&gt; Make sure to generate secure random values for all secrets. Never use the example values in production.

3. Set the following environment variables if deploying to production, otherwise leave commented:
   ```bash
   ############
   # Caddy Config
   ############

   N8N_HOSTNAME=n8n.yourdomain.com
   WEBUI_HOSTNAME=:openwebui.yourdomain.com
   FLOWISE_HOSTNAME=:flowise.yourdomain.com
   SUPABASE_HOSTNAME=:supabase.yourdomain.com
   OLLAMA_HOSTNAME=:ollama.yourdomain.com
   SEARXNG_HOSTNAME=searxng.yourdomain.com
   NEO4J_HOSTNAME=neo4j.yourdomain.com
   LETSENCRYPT_EMAIL=your-email-address
   ```   

---

The project includes a `start_services.py` script that handles starting both the Supabase and local AI services. The script accepts a `--profile` flag to specify which GPU configuration to use.

### For Nvidia GPU users

```bash
python start_services.py --profile gpu-nvidia
```

&gt; [!NOTE]
&gt; If you have not used your Nvidia GPU with Docker before, please follow the
&gt; [Ollama Docker instructions](https://github.com/ollama/ollama/blob/main/docs/docker.md).

### For AMD GPU users on Linux

```bash
python start_services.py --profile gpu-amd
```

### For Mac / Apple Silicon users

If you&#039;re using a Mac with an M1 or newer processor, you can&#039;t expose your GPU to the Docker instance, unfortunately. There are two options in this case:

1. Run the starter kit fully on CPU:
   ```bash
   python start_services.py --profile cpu
   ```

2. Run Ollama on your Mac for faster inference, and connect to that from the n8n instance:
   ```bash
   python start_services.py --profile none
   ```

   If you want to run Ollama on your mac, check the [Ollama homepage](https://ollama.com/) for installation instructions.

#### For Mac users running OLLAMA locally

If you&#039;re running OLLAMA locally on your Mac (not in Docker), you need to modify the OLLAMA_HOST environment variable in the n8n service configuration. Update the x-n8n section in your Docker Compose file as follows:

```yaml
x-n8n: &amp;service-n8n
  # ... other configurations ...
  environment:
    # ... other environment variables ...
    - OLLAMA_HOST=host.docker.internal:11434
```

Additionally, after you see &quot;Editor is now accessible via: http://localhost:5678/&quot;:

1. Head to http://localhost:5678/home/credentials
2. Click on &quot;Local Ollama service&quot;
3. Change the base URL to &quot;http://host.docker.internal:11434/&quot;

### For everyone else

```bash
python start_services.py --profile cpu
```

### The environment argument
The **start-services.py** script offers the possibility to pass one of two options for the environment argument, **private** (default environment) and **public**:
- **private:** you are deploying the stack in a safe environment, hence a lot of ports can be made accessible without having to worry about security
- **public:** the stack is deployed in a public environment, which means the attack surface should be made as small as possible. All ports except for 80 and 443 are closed

The stack initialized with
```bash
   python start_services.py --profile gpu-nvidia --environment private
   ```
equals the one initialized with
```bash
   python start_services.py --profile gpu-nvidia
   ```

## Deploying to the Cloud

### Prerequisites for the below steps

- Linux machine (preferably Unbuntu) with Nano, Git, and Docker installed

### Extra steps

Before running the above commands to pull the repo and install everything:

1. Run the commands as root to open up the necessary ports:
   - ufw enable
   - ufw allow 80 &amp;&amp; ufw allow 443
   - ufw reload
   ---
   **WARNING**

   ufw does not shield ports published by docker, because the iptables rules configured by docker are analyzed before those configured by ufw. There is a solution to change this behavior, but that is out of scope for this project. Just make sure that all traffic runs through the caddy service via port 443. Port 80 should only be used to redirect to port 443.

   ---
2. Run the **start-services.py** script with the environment argument **public** to indicate you are going to run the package in a public environment. The script will make sure that all ports, except for 80 and 443, are closed down, e.g.

```bash
   python3 start_services.py --profile gpu-nvidia --environment public
   ```

3. Set up A records for your DNS provider to point your subdomains you&#039;ll set up in the .env file for Caddy
to the IP address of your cloud instance.

   For example, A record to point n8n to [cloud instance IP] for n8n.yourdomain.com


**NOTE**: If you are using a cloud machine without the &quot;docker compose&quot; command available by default, such as a Ubuntu GPU instance on DigitalOcean, run these commands before running start_services.py:

- DOCKER_COMPOSE_VERSION=$(curl -s https://api.github.com/repos/docker/compose/releases/latest | grep &#039;tag_name&#039; | cut -d\\&quot; -f4)
- sudo curl -L &quot;https://github.com/docker/compose/releases/download/${DOCKER_COMPOSE_VERSION}/docker-compose-linux-x86_64&quot; -o /usr/local/bin/docker-compose
- sudo chmod +x /usr/local/bin/docker-compose
- sudo mkdir -p /usr/local/lib/docker/cli-plugins
- sudo ln -s /usr/local/bin/docker-compose /usr/local/lib/docker/cli-plugins/docker-compose

## âš¡ï¸ Quick start and usage

The main component of the self-hosted AI starter kit is a docker compose file
pre-configured with network and disk so there isnâ€™t much else you need to
install. After completing the installation steps above, follow the steps below
to get started.

1. Open &lt;http://localhost:5678/&gt; in your browser to set up n8n. Youâ€™ll only
   have to do this once. You are NOT creating an account with n8n in the setup here,
   it is only a local account for your instance!
2. Open the included workflow:
   &lt;http://localhost:5678/workflow/vTN9y2dLXqTiDfPT&gt;
3. Create credentials for every service:
   
   Ollama URL: http://ollama:11434

   Postgres (through Supabase): use DB, username, and password from .env. IMPORTANT: Host is &#039;db&#039;
   Since that is the name of the service running Supabase

   Qdrant URL: http://qdrant:6333 (API key can be whatever since this is running locally)

   Google Drive: Follow [this guide from n8n](https://docs.n8n.io/integrations/builtin/credentials/google/).
   Don&#039;t use localhost for the redirect URI, just use another domain you have, it will still work!
   Alternatively, you can set up [local file triggers](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.localfiletrigger/).
4. Select **Test workflow** to start running the workflow.
5. If this is the first time youâ€™re running the workflow, you may need to wait
   until Ollama finishes downloading Llama3.1. You can inspect the docker
   console logs to check on the progress.
6. Make sure to toggle the workflow as active and copy the &quot;Production&quot; webhook URL!
7. Open &lt;http://localhost:3000/&gt; in your browser to set up Open WebUI.
Youâ€™ll only have to do this once. You are NOT creating an account with Open WebUI in the 
setup here, it is only a local account for your instance!
8. Go to Workspace -&gt; Functions -&gt; Add Function -&gt; Give name + description then paste in
the code from `n8n_pipe.py`

   The function is also [published here on Open WebUI&#039;s site](https://openwebui.com/f/coleam/n8n_pipe/).

9. Click on the gear icon and set the n8n_url to the production URL for the webhook
you copied in a previous step.
10. Toggle the function on and now it will be available in your model dropdown in the top left! 

To open n8n at any time, visit &lt;http://localhost:5678/&gt; in your browser.
To open Open WebUI at any time, visit &lt;http://localhost:3000/&gt;.

With your n8n instance, youâ€™ll have access to over 400 integrations and a
suite of basic and advanced AI nodes such as
[AI Agent](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/),
[Text classifier](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.text-classifier/),
and [Information Extractor](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.information-extractor/)
nodes. To keep everything local, just remember to use the Ollama node for your
language model and Qdrant as your vector store.

&gt; [!NOTE]
&gt; This starter kit is designed to help you get started with self-hosted AI
&gt; workflows. While itâ€™s not fully optimized for production environments, it
&gt; combines robust components that work well together for proof-of-concept
&gt; projects. You can customize it to meet your specific needs

## Upgrading

To update all containers to their latest versions (n8n, Open WebUI, etc.), run these commands:

```bash
# Stop all services
docker compose -p localai -f docker-compose.yml --profile &lt;your-profile&gt; down

# Pull latest versions of all containers
docker compose -p localai -f docker-compose.yml --profile &lt;your-profile&gt; pull

# Start services again with your desired profile
python start_services.py --profile &lt;your-profile&gt;
```

Replace `&lt;your-profile&gt;` with one of: `cpu`, `gpu-nvidia`, `gpu-amd`, or `none`.

Note: The `start_services.py` script itself does not update containers - it only restarts them or pulls them if you are downloading these containers for the first time. To get the latest versions, you must explicitly run the commands above.

## Troubleshooting

Here are solutions to common issues you might encounter:

### Supabase Issues

- **Supabase Pooler Restarting**: If the supabase-pooler container keeps restarting itself, follow the instructions in [this GitHub issue](https://github.com/supabase/supabase/issues/30210#issuecomment-2456955578).

- **Supabase Analytics Startup Failure**: If the supabase-analytics container fails to start after changing your Postgres password, delete the folder `supabase/docker/volumes/db/data`.

- **If using Docker Desktop**: Go into the Docker settings and make sure &quot;Expose daemon on tcp://localhost:2375 without TLS&quot; is turned on

- **Supabase Service Unavailable** - Make sure you don&#039;t have an &quot;@&quot; character in your Postgres password! If the connection to the kong container is working (the container logs say it is receiving requests from n8n) but n8n says it cannot connect, this is generally the problem from what the community has shared. Other characters might not be allowed too, the @ symbol is just the one I know for sure!

- **SearXNG Restarting**: If the SearXNG container keeps restarting, run the command &quot;chmod 755 searxng&quot; within the local-ai-packaged folder so SearXNG has the permissions it needs to create the uwsgi.ini file.

- **Files not Found in Supabase Folder** - If you get any errors around files missing in the supabase/ folder like .env, docker/docker-compose.yml, etc. this most likely means you had a &quot;bad&quot; pull of the Supabase GitHub repository when you ran the start_services.py script. Delete the supabase/ folder within the Local AI Package folder entirely and try again.

### GPU Support Issues

- **Windows GPU Support**: If you&#039;re having trouble running Ollama with GPU support on Windows with Docker Desktop:
  1. Open Docker Desktop settings
  2. Enable WSL 2 backend
  3. See the [Docker GPU documentation](https://docs.docker.com/desktop/features/gpu/) for more details

- **Linux GPU Support**: If you&#039;re having trouble running Ollama with GPU support on Linux, follow the [Ollama Docker instructions](https://github.com/ollama/ollama/blob/main/docs/docker.md).

## ğŸ‘“ Recommended reading

n8n is full of useful content for getting started quickly with its AI concepts
and nodes. If you run into an issue, go to [support](#support).

- [AI agents for developers: from theory to practice with n8n](https://blog.n8n.io/ai-agents/)
- [Tutorial: Build an AI workflow in n8n](https://docs.n8n.io/advanced-ai/intro-tutorial/)
- [Langchain Concepts in n8n](https://docs.n8n.io/advanced-ai/langchain/langchain-n8n/)
- [Demonstration of key differences between agents and chains](https://docs.n8n.io/advanced-ai/examples/agent-chain-comparison/)
- [What are vector databases?](https://docs.n8n.io/advanced-ai/examples/understand-vector-databases/)

## ğŸ¥ Video walkthrough

- [Cole&#039;s Guide to the Local AI Starter Kit](https://youtu.be/pOsO40HSbOo)

## ğŸ›ï¸ More AI templates

For more AI workflow ideas, visit the [**official n8n AI template
gallery**](https://n8n.io/workflows/?categories=AI). From each workflow,
select the **Use workflow** button to automatically import the workflow into
your local n8n instance.

### Learn AI key concepts

- [AI Agent Chat](https://n8n.io/workflows/1954-ai-agent-chat/)
- [AI chat with any data source (using the n8n workflow too)](https://n8n.io/workflows/2026-ai-chat-with-any-data-source-using-the-n8n-workflow-tool/)
- [Chat with OpenAI Assistant (by adding a memory)](https://n8n.io/workflows/2098-chat-with-openai-assistant-by-adding-a-memory/)
- [Use an open-source LLM (via HuggingFace)](https://n8n.io/workflows/1980-use-an-open-source-llm-via-huggingface/)
- [Chat with PDF docs using AI (quoting sources)](https://n8n.io/workflows/2165-chat-with-pdf-docs-using-ai-quoting-sources/)
- [AI agent that can scrape webpages](https://n8n.io/workflows/2006-ai-agent-that-can-scrape-webpages/)

### Local AI templates

- [Tax Code Assistant](https://n8n.io/workflows/2341-build-a-tax-code-assistant-with-qdrant-mistralai-and-openai/)
- [Breakdown Documents into Study Notes with MistralAI and Qdrant](https://n8n.io/workflows/2339-breakdown-documents-into-study-notes-using-templating-mistralai-and-qdrant/)
- [Financial Documents Assistant using Qdrant and](https://n8n.io/workflows/2335-build-a-financial-documents-assistant-using-qdrant-and-mistralai/)Â [Â Mistral.ai](http://mistral.ai/)
- [Recipe Recommendations with Qdrant and Mistral](https://n8n.io/workflows/2333-recipe-recommendations-with-qdrant-and-mistral/)

## Tips &amp; tricks

### Accessing local files

The self-hosted AI starter kit will create a shared folder (by default,
located in the same directory) which is mounted to the n8n container and
allows n8n to access files on disk. This folder within the n8n container is
located at `/data/shared` -- this is the path youâ€™ll need to use in nodes that
interact with the local filesystem.

**Nodes that interact with the local filesystem**

- [Read/Write Files from Disk](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.filesreadwrite/)
- [Local File Trigger](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.localfiletrigger/)
- [Execute Command](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.executecommand/)

## ğŸ“œÂ License

This project (originally created by the n8n team, link at the top of the README) is licensed under the Apache License 2.0 - see the
[LICENSE](LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[WEIFENG2333/VideoCaptioner]]></title>
            <link>https://github.com/WEIFENG2333/VideoCaptioner</link>
            <guid>https://github.com/WEIFENG2333/VideoCaptioner</guid>
            <pubDate>Mon, 07 Jul 2025 00:04:37 GMT</pubDate>
            <description><![CDATA[ğŸ¬ å¡å¡å­—å¹•åŠ©æ‰‹ | VideoCaptioner - åŸºäº LLM çš„æ™ºèƒ½å­—å¹•åŠ©æ‰‹ - è§†é¢‘å­—å¹•ç”Ÿæˆã€æ–­å¥ã€æ ¡æ­£ã€å­—å¹•ç¿»è¯‘å…¨æµç¨‹å¤„ç†ï¼- A powered tool for easy and efficient video subtitling.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/WEIFENG2333/VideoCaptioner">WEIFENG2333/VideoCaptioner</a></h1>
            <p>ğŸ¬ å¡å¡å­—å¹•åŠ©æ‰‹ | VideoCaptioner - åŸºäº LLM çš„æ™ºèƒ½å­—å¹•åŠ©æ‰‹ - è§†é¢‘å­—å¹•ç”Ÿæˆã€æ–­å¥ã€æ ¡æ­£ã€å­—å¹•ç¿»è¯‘å…¨æµç¨‹å¤„ç†ï¼- A powered tool for easy and efficient video subtitling.</p>
            <p>Language: Python</p>
            <p>Stars: 8,003</p>
            <p>Forks: 646</p>
            <p>Stars today: 160 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/logo.png&quot;alt=&quot;VideoCaptioner Logo&quot; width=&quot;100&quot;&gt;
  &lt;p&gt;å¡å¡å­—å¹•åŠ©æ‰‹&lt;/p&gt;
  &lt;h1&gt;VideoCaptioner&lt;/h1&gt;
  &lt;p&gt;ä¸€æ¬¾åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„è§†é¢‘å­—å¹•å¤„ç†åŠ©æ‰‹ï¼Œæ”¯æŒè¯­éŸ³è¯†åˆ«ã€å­—å¹•æ–­å¥ã€ä¼˜åŒ–ã€ç¿»è¯‘å…¨æµç¨‹å¤„ç†&lt;/p&gt;

  ç®€ä½“ä¸­æ–‡ / [æ­£é«”ä¸­æ–‡](./docs/README_TW.md) / [English](./docs/README_EN.md) / [æ—¥æœ¬èª](./docs/README_JA.md)
  
&lt;/div&gt;

## ğŸ“– é¡¹ç›®ä»‹ç»

å¡å¡å­—å¹•åŠ©æ‰‹ï¼ˆVideoCaptionerï¼‰æ“ä½œç®€å•ä¸”æ— éœ€é«˜é…ç½®ï¼Œæ”¯æŒç½‘ç»œè°ƒç”¨å’Œæœ¬åœ°ç¦»çº¿ï¼ˆæ”¯æŒè°ƒç”¨GPUï¼‰ä¸¤ç§æ–¹å¼è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œåˆ©ç”¨å¯ç”¨é€šè¿‡å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œå­—å¹•æ™ºèƒ½æ–­å¥ã€æ ¡æ­£ã€ç¿»è¯‘ï¼Œå­—å¹•è§†é¢‘å…¨æµç¨‹ä¸€é”®å¤„ç†ï¼ä¸ºè§†é¢‘é…ä¸Šæ•ˆæœæƒŠè‰³çš„å­—å¹•ã€‚

æœ€æ–°ç‰ˆæœ¬å·²ç»æ”¯æŒ VAD ã€ äººå£°åˆ†ç¦»ã€ å­—çº§æ—¶é—´æˆ³ æ‰¹é‡å­—å¹•ç­‰å®ç”¨åŠŸèƒ½

- ğŸ¯ æ— éœ€GPUå³å¯ä½¿ç”¨å¼ºå¤§çš„è¯­éŸ³è¯†åˆ«å¼•æ“ï¼Œç”Ÿæˆç²¾å‡†å­—å¹•
- âœ‚ï¸ åŸºäº LLM çš„æ™ºèƒ½åˆ†å‰²ä¸æ–­å¥ï¼Œå­—å¹•é˜…è¯»æ›´è‡ªç„¶æµç•…
- ğŸ”„ AIå­—å¹•å¤šçº¿ç¨‹ä¼˜åŒ–ä¸ç¿»è¯‘ï¼Œè°ƒæ•´å­—å¹•æ ¼å¼ã€è¡¨è¾¾æ›´åœ°é“ä¸“ä¸š
- ğŸ¬ æ”¯æŒæ‰¹é‡è§†é¢‘å­—å¹•åˆæˆï¼Œæå‡å¤„ç†æ•ˆç‡
- ğŸ“ ç›´è§‚çš„å­—å¹•ç¼–è¾‘æŸ¥çœ‹ç•Œé¢ï¼Œæ”¯æŒå®æ—¶é¢„è§ˆå’Œå¿«æ·ç¼–è¾‘
- ğŸ¤– æ¶ˆè€—æ¨¡å‹ Token å°‘ï¼Œä¸”å†…ç½®åŸºç¡€ LLM æ¨¡å‹ï¼Œä¿è¯å¼€ç®±å³ç”¨

## ğŸ“¸ ç•Œé¢é¢„è§ˆ

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://h1.appinn.me/file/1731487405884_main.png&quot; alt=&quot;è½¯ä»¶ç•Œé¢é¢„è§ˆ&quot; width=&quot;90%&quot; style=&quot;border-radius: 5px;&quot;&gt;
&lt;/div&gt;

![é¡µé¢é¢„è§ˆ](https://h1.appinn.me/file/1731487410170_preview1.png)
![é¡µé¢é¢„è§ˆ](https://h1.appinn.me/file/1731487410832_preview2.png)


## ğŸ§ª æµ‹è¯•

å…¨æµç¨‹å¤„ç†ä¸€ä¸ª14åˆ†é’Ÿ1080Pçš„ [Bç«™è‹±æ–‡ TED è§†é¢‘](https://www.bilibili.com/video/BV1jT411X7Dz)ï¼Œè°ƒç”¨æœ¬åœ° Whisper æ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œä½¿ç”¨ `gpt-4o-mini` æ¨¡å‹ä¼˜åŒ–å’Œç¿»è¯‘ä¸ºä¸­æ–‡ï¼Œæ€»å…±æ¶ˆè€—æ—¶é—´çº¦ **4 åˆ†é’Ÿ**ã€‚

 è¿‘åå°è®¡ç®—ï¼Œæ¨¡å‹ä¼˜åŒ–å’Œç¿»è¯‘æ¶ˆè€—è´¹ç”¨ä¸è¶³ ï¿¥0.01ï¼ˆä»¥OpenAIå®˜æ–¹ä»·æ ¼ä¸ºè®¡ç®—ï¼‰

å…·ä½“å­—å¹•å’Œè§†é¢‘åˆæˆçš„æ•ˆæœçš„æµ‹è¯•ç»“æœå›¾ç‰‡ï¼Œè¯·å‚è€ƒ [TEDè§†é¢‘æµ‹è¯•](./docs/test.md)


## ğŸš€ å¿«é€Ÿå¼€å§‹

### Windows ç”¨æˆ·

è½¯ä»¶è¾ƒä¸ºè½»é‡ï¼Œæ‰“åŒ…å¤§å°ä¸è¶³ 60M,å·²é›†æˆæ‰€æœ‰å¿…è¦ç¯å¢ƒï¼Œä¸‹è½½åå¯ç›´æ¥è¿è¡Œã€‚

1. ä» [Release](https://github.com/WEIFENG2333/VideoCaptioner/releases) é¡µé¢ä¸‹è½½æœ€æ–°ç‰ˆæœ¬çš„å¯æ‰§è¡Œç¨‹åºã€‚æˆ–è€…ï¼š[è“å¥ç›˜ä¸‹è½½](https://wwwm.lanzoue.com/ii14G2pdsbej)

2. æ‰“å¼€å®‰è£…åŒ…è¿›è¡Œå®‰è£…

3. LLM API é…ç½®ï¼Œï¼ˆç”¨äºå­—å¹•æ–­å¥ã€æ ¡æ­£ï¼‰ï¼Œå¯ä½¿ç”¨ [âœ¨æœ¬é¡¹ç›®çš„ä¸­è½¬ç«™ ](https://api.videocaptioner.cn) 

4. ç¿»è¯‘é…ç½®ï¼Œé€‰æ‹©æ˜¯å¦å¯ç”¨ç¿»è¯‘ï¼Œç¿»è¯‘æœåŠ¡ï¼ˆé»˜è®¤ä½¿ç”¨å¾®è½¯ç¿»è¯‘ï¼Œè´¨é‡ä¸€èˆ¬ï¼Œæ¨èä½¿ç”¨å¤§æ¨¡å‹ç¿»è¯‘ï¼‰

5. è¯­éŸ³è¯†åˆ«é…ç½®ï¼ˆé»˜è®¤ä½¿ç”¨Bæ¥å£ï¼Œä¸­è‹±ä»¥å¤–çš„è¯­è¨€è¯·ä½¿ç”¨æœ¬åœ°è½¬å½•ï¼‰

6. æ‹–æ‹½è§†é¢‘æ–‡ä»¶åˆ°è½¯ä»¶çª—å£ï¼Œå³å¯å…¨è‡ªåŠ¨å¤„ç†

æç¤ºï¼šæ¯ä¸€ä¸ªæ­¥éª¤å‡æ”¯æŒå•ç‹¬å¤„ç†ï¼Œå‡æ”¯æŒæ–‡ä»¶æ‹–æ‹½ã€‚è½¯ä»¶å…·ä½“æ¨¡å‹é€‰æ‹©å’Œå‚æ•°é…ç½®è¯´æ˜ï¼Œè¯·æŸ¥çœ‹ä¸‹æ–‡ã€‚

&lt;details&gt;
&lt;summary&gt;MacOS ç”¨æˆ·&lt;/summary&gt;
 
 
ç”±äºæœ¬äººç¼ºå°‘ Macï¼Œæ‰€ä»¥æ²¡æ³•æµ‹è¯•å’Œæ‰“åŒ…ï¼Œæš‚æ— æ³•æä¾› MacOS çš„å¯æ‰§è¡Œç¨‹åºã€‚

Mac ç”¨æˆ·è¯·è‡ªè¡Œä½¿ç”¨ä¸‹è½½æºç å’Œå®‰è£… python ä¾èµ–è¿è¡Œã€‚ï¼ˆæœ¬åœ° Whisper åŠŸèƒ½æš‚ä¸æ”¯æŒ MacOSï¼‰

1. å®‰è£… ffmpeg å’Œ Aria2 ä¸‹è½½å·¥å…·
```bash
brew install ffmpeg
brew install aria2
brew install python@3.**
```

2. å…‹éš†é¡¹ç›®
```bash
git clone https://github.com/WEIFENG2333/VideoCaptioner.git
cd VideoCaptioner
```

3. å®‰è£…ä¾èµ–
```bash
python3.** -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

4. è¿è¡Œç¨‹åº
```bash
python main.py
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Docker éƒ¨ç½²ï¼ˆbetaï¼‰&lt;/summary&gt;

ç›®å‰æœ¬é¡¹ç›®streamlitåº”ç”¨å› ä¸ºé¡¹ç›®é‡æ„è¿‡ï¼ŒDockerä¸å¯ä»¥ä½¿ç”¨ã€‚æ¬¢è¿å„ä½PRè´¡çŒ®æ–°ä»£ç ã€‚

### 1. å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/WEIFENG2333/VideoCaptioner.git
cd VideoCaptioner

```

### 2. æ„å»ºé•œåƒ

```bash
docker build -t video-captioner .
```

### 3. è¿è¡Œå®¹å™¨

ä½¿ç”¨è‡ªå®šä¹‰APIé…ç½®è¿è¡Œï¼š
```bash
docker run -d \
  -p 8501:8501 \
  -v $(pwd)/temp:/app/temp \
  -e OPENAI_BASE_URL=&quot;ä½ çš„APIåœ°å€&quot; \
  -e OPENAI_API_KEY=&quot;ä½ çš„APIå¯†é’¥&quot; \
  --name video-captioner \
  video-captioner
```

### 4. è®¿é—®åº”ç”¨

æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼š`http://localhost:8501`

### æ³¨æ„äº‹é¡¹

- å®¹å™¨å†…å·²é¢„è£…ffmpegç­‰å¿…è¦ä¾èµ–
- å¦‚éœ€ä½¿ç”¨å…¶ä»–æ¨¡å‹ï¼Œè¯·é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®

&lt;/details&gt;

## âš™ï¸ åŸºæœ¬é…ç½®

### 1. LLM API é…ç½®è¯´æ˜

LLM å¤§æ¨¡å‹æ˜¯ç”¨æ¥å­—å¹•æ®µå¥ã€å­—å¹•ä¼˜åŒ–ã€ä»¥åŠå­—å¹•ç¿»è¯‘ï¼ˆå¦‚æœé€‰æ‹©äº†LLM å¤§æ¨¡å‹ç¿»è¯‘ï¼‰ã€‚

| é…ç½®é¡¹ | è¯´æ˜ |
|--------|------|
| SiliconCloud | [SiliconCloud å®˜ç½‘](https://cloud.siliconflow.cn/i/onCHcaDx)é…ç½®æ–¹æ³•è¯·å‚è€ƒ[é…ç½®æ–‡æ¡£](./docs/llm_config.md)&lt;br&gt;è¯¥å¹¶å‘è¾ƒä½ï¼Œå»ºè®®æŠŠçº¿ç¨‹è®¾ç½®ä¸º5ä»¥ä¸‹ã€‚ |
| DeepSeek | [DeepSeek å®˜ç½‘](https://platform.deepseek.com)ï¼Œå»ºè®®ä½¿ç”¨ `deepseek-v3` æ¨¡å‹ï¼Œ&lt;br&gt;å®˜æ–¹ç½‘ç«™æœ€è¿‘æœåŠ¡å¥½åƒå¹¶ä¸å¤ªç¨³å®šã€‚ |
| Ollamaæœ¬åœ° | [Ollama å®˜ç½‘](https://ollama.com) |
| å†…ç½®å…¬ç›Šæ¨¡å‹ | å†…ç½®åŸºç¡€å¤§è¯­è¨€æ¨¡å‹ï¼ˆ`gpt-4o-mini`ï¼‰(å…¬ç›ŠæœåŠ¡ä¸ç¨³å®šï¼Œå¼ºçƒˆå»ºè®®è¯·ä½¿ç”¨è‡ªå·±çš„æ¨¡å‹API) |
| OpenAIå…¼å®¹æ¥å£ | å¦‚æœæœ‰å…¶ä»–æœåŠ¡å•†çš„APIï¼Œå¯ç›´æ¥åœ¨è½¯ä»¶ä¸­å¡«å†™ã€‚base_url å’Œapi_key |

æ³¨ï¼šå¦‚æœç”¨çš„ API æœåŠ¡å•†ä¸æ”¯æŒé«˜å¹¶å‘ï¼Œè¯·åœ¨è½¯ä»¶è®¾ç½®ä¸­å°†â€œçº¿ç¨‹æ•°â€è°ƒä½ï¼Œé¿å…è¯·æ±‚é”™è¯¯ã€‚

---

å¦‚æœå¸Œæœ›é«˜å¹¶å‘âš¡ï¸ï¼Œæˆ–è€…å¸Œæœ›åœ¨åœ¨è½¯ä»¶å†…ä½¿ç”¨ä½¿ç”¨ OpenAI æˆ–è€… Claude ç­‰ä¼˜è´¨å¤§æ¨¡å‹è¿›è¡Œå­—å¹•æ ¡æ­£å’Œç¿»è¯‘ã€‚

å¯ä½¿ç”¨æœ¬é¡¹ç›®çš„âœ¨LLM APIä¸­è½¬ç«™âœ¨ï¼š [https://api.videocaptioner.cn](https://api.videocaptioner.cn)

å…¶æ”¯æŒé«˜å¹¶å‘ï¼Œæ€§ä»·æ¯”æé«˜ï¼Œä¸”æœ‰å›½å†…å¤–å¤§é‡æ¨¡å‹å¯æŒ‘é€‰ã€‚

æ³¨å†Œè·å–keyä¹‹åï¼Œè®¾ç½®ä¸­æŒ‰ç…§ä¸‹é¢é…ç½®ï¼š

BaseURL: `https://api.videocaptioner.cn/v1`

API-key: `ä¸ªäººä¸­å¿ƒ-API ä»¤ç‰Œé¡µé¢è‡ªè¡Œè·å–ã€‚`

ğŸ’¡ æ¨¡å‹é€‰æ‹©å»ºè®® (æœ¬äººåœ¨å„è´¨é‡å±‚çº§ä¸­ç²¾é€‰å‡ºçš„é«˜æ€§ä»·æ¯”æ¨¡å‹)ï¼š 

 - é«˜è´¨é‡ä¹‹é€‰ï¼š `claude-3-5-sonnet-20241022` (è€—è´¹æ¯”ä¾‹ï¼š3) 

 - è¾ƒé«˜è´¨é‡ä¹‹é€‰ï¼š `gemini-2.0-flash`ã€`deepseek-chat` (è€—è´¹æ¯”ä¾‹ï¼š1) 

 - ä¸­è´¨é‡ä¹‹é€‰ï¼š `gpt-4o-mini`ã€`gemini-1.5-flash` (è€—è´¹æ¯”ä¾‹ï¼š0.15) 

æœ¬ç«™æ”¯æŒè¶…é«˜å¹¶å‘ï¼Œè½¯ä»¶ä¸­çº¿ç¨‹æ•°ç›´æ¥æ‹‰æ»¡å³å¯~ å¤„ç†é€Ÿåº¦éå¸¸å¿«~

æ›´è¯¦ç»†çš„APIé…ç½®æ•™ç¨‹ï¼š[ä¸­è½¬ç«™é…ç½®é…ç½®](./docs/llm_config.md#ä¸­è½¬ç«™é…ç½®)

---

## 2. ç¿»è¯‘é…ç½®

| é…ç½®é¡¹ | è¯´æ˜ |
|--------|------|
| LLM å¤§æ¨¡å‹ç¿»è¯‘ | ğŸŒŸ ç¿»è¯‘è´¨é‡æœ€å¥½çš„é€‰æ‹©ã€‚ä½¿ç”¨ AI å¤§æ¨¡å‹è¿›è¡Œç¿»è¯‘,èƒ½æ›´å¥½ç†è§£ä¸Šä¸‹æ–‡,ç¿»è¯‘æ›´è‡ªç„¶ã€‚éœ€è¦åœ¨è®¾ç½®ä¸­é…ç½® LLM API(æ¯”å¦‚ OpenAIã€DeepSeek ç­‰) |
| DeepLx ç¿»è¯‘ |  ç¿»è¯‘è¾ƒå¯é ã€‚åŸºäº DeepL ç¿»è¯‘, éœ€è¦è¦é…ç½®è‡ªå·±çš„åç«¯æ¥å£ã€‚ |
| å¾®è½¯ç¿»è¯‘ | ä½¿ç”¨å¾®è½¯çš„ç¿»è¯‘æœåŠ¡, é€Ÿåº¦éå¸¸å¿« |
| è°·æ­Œç¿»è¯‘ | è°·æ­Œçš„ç¿»è¯‘æœåŠ¡,é€Ÿåº¦å¿«,ä½†éœ€è¦èƒ½è®¿é—®è°·æ­Œçš„ç½‘ç»œç¯å¢ƒ |

æ¨èä½¿ç”¨ `LLM å¤§æ¨¡å‹ç¿»è¯‘` ï¼Œç¿»è¯‘è´¨é‡æœ€å¥½ã€‚


### 3. è¯­éŸ³è¯†åˆ«æ¥å£è¯´æ˜

| æ¥å£åç§° | æ”¯æŒè¯­è¨€ | è¿è¡Œæ–¹å¼ | è¯´æ˜ |
|---------|---------|---------|------|
| Bæ¥å£ | ä»…æ”¯æŒä¸­æ–‡ã€è‹±æ–‡ | åœ¨çº¿ | å…è´¹ã€é€Ÿåº¦è¾ƒå¿« |
| Jæ¥å£ | ä»…æ”¯æŒä¸­æ–‡ã€è‹±æ–‡ | åœ¨çº¿ | å…è´¹ã€é€Ÿåº¦è¾ƒå¿« |
| WhisperCpp | ä¸­æ–‡ã€æ—¥è¯­ã€éŸ©è¯­ã€è‹±æ–‡ç­‰ 99 ç§è¯­è¨€ï¼Œå¤–è¯­æ•ˆæœè¾ƒå¥½ | æœ¬åœ° | ï¼ˆå®é™…ä½¿ç”¨ä¸ç¨³å®šï¼‰éœ€è¦ä¸‹è½½è½¬å½•æ¨¡å‹&lt;br&gt;ä¸­æ–‡å»ºè®®mediumä»¥ä¸Šæ¨¡å‹&lt;br&gt;è‹±æ–‡ç­‰ä½¿ç”¨è¾ƒå°æ¨¡å‹å³å¯è¾¾åˆ°ä¸é”™æ•ˆæœã€‚ |
| fasterWhisper ğŸ‘ | ä¸­æ–‡ã€è‹±æ–‡ç­‰å¤š99ç§è¯­è¨€ï¼Œå¤–è¯­æ•ˆæœä¼˜ç§€ï¼Œæ—¶é—´è½´æ›´å‡†ç¡® | æœ¬åœ° | ï¼ˆğŸŒŸæåŠ›æ¨èğŸŒŸï¼‰éœ€è¦ä¸‹è½½ç¨‹åºå’Œè½¬å½•æ¨¡å‹&lt;br&gt;æ”¯æŒCUDA,é€Ÿåº¦æ›´å¿«ï¼Œè½¬å½•å‡†ç¡®ã€‚&lt;br&gt;è¶…çº§å‡†ç¡®çš„æ—¶é—´æˆ³å­—å¹•ã€‚&lt;br&gt;å»ºè®®ä¼˜å…ˆä½¿ç”¨ |


### 4. æœ¬åœ° Whisper è¯­éŸ³è¯†åˆ«æ¨¡å‹

Whisper ç‰ˆæœ¬æœ‰ WhisperCpp å’Œ fasterWhisperï¼ˆæ¨èï¼‰ ä¸¤ç§ï¼Œåè€…æ•ˆæœæ›´å¥½ï¼Œéƒ½éœ€è¦è‡ªè¡Œåœ¨è½¯ä»¶å†…ä¸‹è½½æ¨¡å‹ã€‚

| æ¨¡å‹ | ç£ç›˜ç©ºé—´ | å†…å­˜å ç”¨ | è¯´æ˜ |
|------|----------|----------|------|
| Tiny | 75 MiB | ~273 MB | è½¬å½•å¾ˆä¸€èˆ¬ï¼Œä»…ç”¨äºæµ‹è¯• |
| Small | 466 MiB | ~852 MB | è‹±æ–‡è¯†åˆ«æ•ˆæœå·²ç»ä¸é”™ |
| Medium | 1.5 GiB | ~2.1 GB | ä¸­æ–‡è¯†åˆ«å»ºè®®è‡³å°‘ä½¿ç”¨æ­¤ç‰ˆæœ¬ |
| Large-v2 ğŸ‘ | 2.9 GiB | ~3.9 GB | æ•ˆæœå¥½ï¼Œé…ç½®å…è®¸æƒ…å†µæ¨èä½¿ç”¨ |
| Large-v3 | 2.9 GiB | ~3.9 GB | ç¤¾åŒºåé¦ˆå¯èƒ½ä¼šå‡ºç°å¹»è§‰/å­—å¹•é‡å¤é—®é¢˜ |

æ¨èæ¨¡å‹: `Large-v2` ç¨³å®šä¸”è´¨é‡è¾ƒå¥½ã€‚

æ³¨ï¼šä»¥ä¸Šæ¨¡å‹å›½å†…ç½‘ç»œå¯ç›´æ¥åœ¨è½¯ä»¶å†…ä¸‹è½½ã€‚


### 5. æ–‡ç¨¿åŒ¹é…

- åœ¨&quot;å­—å¹•ä¼˜åŒ–ä¸ç¿»è¯‘&quot;é¡µé¢ï¼ŒåŒ…å«&quot;æ–‡ç¨¿åŒ¹é…&quot;é€‰é¡¹ï¼Œæ”¯æŒä»¥ä¸‹**ä¸€ç§æˆ–è€…å¤šç§**å†…å®¹ï¼Œè¾…åŠ©æ ¡æ­£å­—å¹•å’Œç¿»è¯‘:

| ç±»å‹ | è¯´æ˜ | å¡«å†™ç¤ºä¾‹ |
|------|------|------|
| æœ¯è¯­è¡¨ | ä¸“ä¸šæœ¯è¯­ã€äººåã€ç‰¹å®šè¯è¯­çš„ä¿®æ­£å¯¹ç…§è¡¨ | æœºå™¨å­¦ä¹ -&gt;Machine Learning&lt;br&gt;é©¬æ–¯å…‹-&gt;Elon Musk&lt;br&gt;æ‰“call -&gt; åº”æ´&lt;br&gt;å›¾çµæ–‘å›¾&lt;br&gt;å…¬äº¤è½¦æ‚–è®º |
| åŸå­—å¹•æ–‡ç¨¿ | è§†é¢‘çš„åŸæœ‰æ–‡ç¨¿æˆ–ç›¸å…³å†…å®¹ | å®Œæ•´çš„æ¼”è®²ç¨¿ã€è¯¾ç¨‹è®²ä¹‰ç­‰ |
| ä¿®æ­£è¦æ±‚ | å†…å®¹ç›¸å…³çš„å…·ä½“ä¿®æ­£è¦æ±‚ | ç»Ÿä¸€äººç§°ä»£è¯ã€è§„èŒƒä¸“ä¸šæœ¯è¯­ç­‰&lt;br&gt;å¡«å†™**å†…å®¹ç›¸å…³**çš„è¦æ±‚å³å¯ï¼Œ[ç¤ºä¾‹å‚è€ƒ](https://github.com/WEIFENG2333/VideoCaptioner/issues/59#issuecomment-2495849752) |

- å¦‚æœéœ€è¦æ–‡ç¨¿è¿›è¡Œå­—å¹•ä¼˜åŒ–è¾…åŠ©ï¼Œå…¨æµç¨‹å¤„ç†æ—¶ï¼Œå…ˆå¡«å†™æ–‡ç¨¿ä¿¡æ¯ï¼Œå†è¿›è¡Œå¼€å§‹ä»»åŠ¡å¤„ç†
- æ³¨æ„: ä½¿ç”¨ä¸Šä¸‹æ–‡å‚æ•°é‡ä¸é«˜çš„å°å‹LLMæ¨¡å‹æ—¶ï¼Œå»ºè®®æ§åˆ¶æ–‡ç¨¿å†…å®¹åœ¨1åƒå­—å†…ï¼Œå¦‚æœä½¿ç”¨ä¸Šä¸‹æ–‡è¾ƒå¤§çš„æ¨¡å‹ï¼Œåˆ™å¯ä»¥é€‚å½“å¢åŠ æ–‡ç¨¿å†…å®¹ã€‚

æ— ç‰¹æ®Šéœ€æ±‚ï¼Œä¸€èˆ¬ä¸å¡«å†™ã€‚



### 6. Cookie é…ç½®è¯´æ˜

å¦‚æœä½¿ç”¨URLä¸‹è½½åŠŸèƒ½æ—¶ï¼Œå¦‚æœé‡åˆ°ä»¥ä¸‹æƒ…å†µ:
1. ä¸‹è½½è§†é¢‘ç½‘ç«™éœ€è¦ç™»å½•ä¿¡æ¯æ‰å¯ä»¥ä¸‹è½½ï¼›
2. åªèƒ½ä¸‹è½½è¾ƒä½åˆ†è¾¨ç‡çš„è§†é¢‘ï¼›
3. ç½‘ç»œæ¡ä»¶è¾ƒå·®æ—¶éœ€è¦éªŒè¯ï¼›

- è¯·å‚è€ƒ [Cookie é…ç½®è¯´æ˜](./docs/get_cookies.md) è·å–Cookieä¿¡æ¯ï¼Œå¹¶å°†cookies.txtæ–‡ä»¶æ”¾ç½®åˆ°è½¯ä»¶å®‰è£…ç›®å½•çš„ `AppData` ç›®å½•ä¸‹ï¼Œå³å¯æ­£å¸¸ä¸‹è½½é«˜è´¨é‡è§†é¢‘ã€‚

## ğŸ’¡ è½¯ä»¶æµç¨‹ä»‹ç»

ç¨‹åºç®€å•çš„å¤„ç†æµç¨‹å¦‚ä¸‹:
```
è¯­éŸ³è¯†åˆ«è½¬å½• -&gt; å­—å¹•æ–­å¥(å¯é€‰) -&gt; å­—å¹•ä¼˜åŒ–ç¿»è¯‘(å¯é€‰) -&gt; å­—å¹•è§†é¢‘åˆæˆ
```

## âœ¨ è½¯ä»¶ä¸»è¦åŠŸèƒ½

è½¯ä»¶åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLM)åœ¨ç†è§£ä¸Šä¸‹æ–‡æ–¹é¢çš„ä¼˜åŠ¿ï¼Œå¯¹è¯­éŸ³è¯†åˆ«ç”Ÿæˆçš„å­—å¹•è¿›ä¸€æ­¥å¤„ç†ã€‚æœ‰æ•ˆä¿®æ­£é”™åˆ«å­—ã€ç»Ÿä¸€ä¸“ä¸šæœ¯è¯­ï¼Œè®©å­—å¹•å†…å®¹æ›´åŠ å‡†ç¡®è¿è´¯ï¼Œä¸ºç”¨æˆ·å¸¦æ¥å‡ºè‰²çš„è§‚çœ‹ä½“éªŒï¼

#### 1. å¤šå¹³å°è§†é¢‘ä¸‹è½½ä¸å¤„ç†
- æ”¯æŒå›½å†…å¤–ä¸»æµè§†é¢‘å¹³å°ï¼ˆBç«™ã€Youtubeã€å°çº¢ä¹¦ã€TikTokã€Xã€è¥¿ç“œè§†é¢‘ã€æŠ–éŸ³ç­‰ï¼‰
- è‡ªåŠ¨æå–è§†é¢‘åŸæœ‰å­—å¹•å¤„ç†

#### 2. ä¸“ä¸šçš„è¯­éŸ³è¯†åˆ«å¼•æ“
- æä¾›å¤šç§æ¥å£åœ¨çº¿è¯†åˆ«ï¼Œæ•ˆæœåª²ç¾å‰ªæ˜ ï¼ˆå…è´¹ã€é«˜é€Ÿï¼‰
- æ”¯æŒæœ¬åœ°Whisperæ¨¡å‹ï¼ˆä¿æŠ¤éšç§ã€å¯ç¦»çº¿ï¼‰

#### 3. å­—å¹•æ™ºèƒ½çº é”™
- è‡ªåŠ¨ä¼˜åŒ–ä¸“ä¸šæœ¯è¯­ã€ä»£ç ç‰‡æ®µå’Œæ•°å­¦å…¬å¼æ ¼å¼
- ä¸Šä¸‹æ–‡è¿›è¡Œæ–­å¥ä¼˜åŒ–ï¼Œæå‡é˜…è¯»ä½“éªŒ
- æ”¯æŒæ–‡ç¨¿æç¤ºï¼Œä½¿ç”¨åŸæœ‰æ–‡ç¨¿æˆ–è€…ç›¸å…³æç¤ºä¼˜åŒ–å­—å¹•æ–­å¥

#### 4. é«˜è´¨é‡å­—å¹•ç¿»è¯‘
- ç»“åˆä¸Šä¸‹æ–‡çš„æ™ºèƒ½ç¿»è¯‘ï¼Œç¡®ä¿è¯‘æ–‡å…¼é¡¾å…¨æ–‡
- é€šè¿‡PromptæŒ‡å¯¼å¤§æ¨¡å‹åæ€ç¿»è¯‘ï¼Œæå‡ç¿»è¯‘è´¨é‡
- ä½¿ç”¨åºåˆ—æ¨¡ç³ŠåŒ¹é…ç®—æ³•ã€ä¿è¯æ—¶é—´è½´å®Œå…¨ä¸€è‡´

#### 5. å­—å¹•æ ·å¼è°ƒæ•´
- ä¸°å¯Œçš„å­—å¹•æ ·å¼æ¨¡æ¿ï¼ˆç§‘æ™®é£ã€æ–°é—»é£ã€ç•ªå‰§é£ç­‰ç­‰ï¼‰
- å¤šç§æ ¼å¼å­—å¹•è§†é¢‘ï¼ˆSRTã€ASSã€VTTã€TXTï¼‰

é’ˆå¯¹å°ç™½ç”¨æˆ·ï¼Œå¯¹ä¸€äº›è½¯ä»¶å†…çš„é€‰é¡¹è¯´æ˜ï¼š

#### 1. è¯­éŸ³è½¬å½•é¡µé¢

- `VADè¿‡æ»¤`ï¼šå¼€å¯åï¼ŒVADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰å°†è¿‡æ»¤æ— äººå£°çš„è¯­éŸ³ç‰‡æ®µï¼Œä»è€Œå‡å°‘å¹»è§‰ç°è±¡ã€‚å»ºè®®ä¿æŒé»˜è®¤å¼€å¯çŠ¶æ€ã€‚å¦‚æœä¸æ‡‚ï¼Œå…¶ä»–VADé€‰é¡¹å»ºè®®ç›´æ¥ä¿æŒé»˜è®¤å³å¯ã€‚

- `éŸ³é¢‘åˆ†ç¦»`ï¼šå¼€å¯åï¼Œä½¿ç”¨MDX-Netè¿›è¡Œé™å™ªå¤„ç†ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåˆ†ç¦»äººå£°å’ŒèƒŒæ™¯éŸ³ä¹ï¼Œä»è€Œæå‡éŸ³é¢‘è´¨é‡ã€‚å»ºè®®åªåœ¨å˜ˆæ‚çš„è§†é¢‘ä¸­å¼€å¯ã€‚

#### 2. å­—å¹•ä¼˜åŒ–ä¸ç¿»è¯‘é¡µé¢

- `æ™ºèƒ½æ–­å¥`ï¼šå¼€å¯åï¼Œå…¨æµç¨‹å¤„ç†æ—¶ç”Ÿæˆå­—çº§æ—¶é—´æˆ³ï¼Œç„¶åé€šè¿‡LLMå¤§æ¨¡å‹è¿›è¡Œæ–­å¥ï¼Œä»è€Œåœ¨è§†é¢‘æœ‰æ›´å®Œç¾çš„è§‚çœ‹ä½“éªŒã€‚æœ‰æŒ‰ç…§å¥å­æ–­å¥å’ŒæŒ‰ç…§è¯­ä¹‰æ–­å¥ä¸¤ç§æ¨¡å¼ã€‚å¯æ ¹æ®è‡ªå·±çš„éœ€æ±‚é…ç½®ã€‚

- `å­—å¹•æ ¡æ­£`ï¼šå¼€å¯åï¼Œä¼šé€šè¿‡LLMå¤§æ¨¡å‹å¯¹å­—å¹•å†…å®¹è¿›è¡Œæ ¡æ­£(å¦‚ï¼šè‹±æ–‡å•è¯å¤§å°å†™ã€æ ‡ç‚¹ç¬¦å·ã€é”™åˆ«å­—ã€æ•°å­¦å…¬å¼å’Œä»£ç çš„æ ¼å¼ç­‰)ï¼Œæå‡å­—å¹•çš„è´¨é‡ã€‚

- `åæ€ç¿»è¯‘`ï¼šå¼€å¯åï¼Œä¼šé€šè¿‡LLMå¤§æ¨¡å‹è¿›è¡Œåæ€ç¿»è¯‘ï¼Œæå‡ç¿»è¯‘çš„è´¨é‡ã€‚ç›¸åº”çš„ä¼šå¢åŠ è¯·æ±‚çš„æ—¶é—´å’Œæ¶ˆè€—çš„Tokenã€‚(é€‰é¡¹åœ¨ è®¾ç½®é¡µ-LLMå¤§æ¨¡å‹ç¿»è¯‘-åæ€ç¿»è¯‘ ä¸­å¼€å¯ã€‚)

- `æ–‡ç¨¿æç¤º`ï¼šå¡«å†™åï¼Œè¿™éƒ¨åˆ†ä¹Ÿå°†ä½œä¸ºæç¤ºè¯å‘é€ç»™å¤§æ¨¡å‹ï¼Œè¾…åŠ©å­—å¹•ä¼˜åŒ–å’Œç¿»è¯‘ã€‚

#### 3. å­—å¹•è§†é¢‘åˆæˆé¡µé¢

- `è§†é¢‘åˆæˆ`ï¼šå¼€å¯åï¼Œä¼šæ ¹æ®åˆæˆå­—å¹•è§†é¢‘ï¼›å…³é—­å°†è·³è¿‡è§†é¢‘åˆæˆçš„æµç¨‹ã€‚


- `è½¯å­—å¹•`ï¼šå¼€å¯åï¼Œå­—å¹•ä¸ä¼šçƒ§å½•åˆ°è§†é¢‘ä¸­ï¼Œå¤„ç†é€Ÿåº¦æå¿«ã€‚ä½†æ˜¯è½¯å­—å¹•éœ€è¦ä¸€äº›æ’­æ”¾å™¨ï¼ˆå¦‚PotPlayerï¼‰æ”¯æŒæ‰å¯ä»¥è¿›è¡Œæ˜¾ç¤ºæ’­æ”¾ã€‚è€Œä¸”è½¯å­—å¹•çš„æ ·å¼ä¸æ˜¯è½¯ä»¶å†…è°ƒæ•´çš„å­—å¹•æ ·å¼ï¼Œè€Œæ˜¯æ’­æ”¾å™¨é»˜è®¤çš„ç™½è‰²æ ·å¼ã€‚


å®‰è£…è½¯ä»¶çš„ä¸»è¦ç›®å½•ç»“æ„è¯´æ˜å¦‚ä¸‹ï¼š
```
VideoCaptioner/
â”œâ”€â”€ runtime/                    # è¿è¡Œç¯å¢ƒç›®å½•
â”œâ”€â”€ resources/               # è½¯ä»¶èµ„æºæ–‡ä»¶ç›®å½•ï¼ˆäºŒè¿›åˆ¶ç¨‹åºã€å›¾æ ‡ç­‰,ä»¥åŠä¸‹è½½çš„faster-whisperç¨‹åºï¼‰
â”œâ”€â”€ work-dir/               # å·¥ä½œç›®å½•ï¼Œå¤„ç†å®Œæˆçš„è§†é¢‘å’Œå­—å¹•æ–‡ä»¶ä¿å­˜åœ¨è¿™é‡Œ
â”œâ”€â”€ AppData/                    # åº”ç”¨æ•°æ®ç›®å½•
    â”œâ”€â”€ cache/              # ç¼“å­˜ç›®å½•ï¼Œç¼“å­˜è½¬å½•ã€å¤§æ¨¡å‹è¯·æ±‚çš„æ•°æ®ã€‚
    â”œâ”€â”€ models/              # å­˜æ”¾ Whisper æ¨¡å‹æ–‡ä»¶
    â”œâ”€â”€ logs/               # æ—¥å¿—ç›®å½•ï¼Œè®°å½•è½¯ä»¶è¿è¡ŒçŠ¶æ€
    â”œâ”€â”€ settings.json          # å­˜å‚¨ç”¨æˆ·è®¾ç½®
    â””â”€â”€  cookies.txt           # è§†é¢‘å¹³å°çš„ cookie ä¿¡æ¯ï¼ˆä¸‹è½½é«˜æ¸…è§†é¢‘æ—¶éœ€è¦ï¼‰
â””â”€â”€ VideoCaptioner.exe      # ä¸»ç¨‹åºæ‰§è¡Œæ–‡ä»¶
```

## ğŸ“ è¯´æ˜

1. å­—å¹•æ–­å¥çš„è´¨é‡å¯¹è§‚çœ‹ä½“éªŒè‡³å…³é‡è¦ã€‚è½¯ä»¶èƒ½å°†é€å­—å­—å¹•æ™ºèƒ½é‡ç»„ä¸ºç¬¦åˆè‡ªç„¶è¯­è¨€ä¹ æƒ¯çš„æ®µè½ï¼Œå¹¶ä¸è§†é¢‘ç”»é¢å®Œç¾åŒæ­¥ã€‚

2. åœ¨å¤„ç†è¿‡ç¨‹ä¸­ï¼Œä»…å‘å¤§è¯­è¨€æ¨¡å‹å‘é€æ–‡æœ¬å†…å®¹ï¼Œä¸åŒ…å«æ—¶é—´è½´ä¿¡æ¯ï¼Œè¿™å¤§å¤§é™ä½äº†å¤„ç†å¼€é”€ã€‚

3. åœ¨ç¿»è¯‘ç¯èŠ‚ï¼Œæˆ‘ä»¬é‡‡ç”¨å´æ©è¾¾æå‡ºçš„&quot;ç¿»è¯‘-åæ€-ç¿»è¯‘&quot;æ–¹æ³•è®ºã€‚è¿™ç§è¿­ä»£ä¼˜åŒ–çš„æ–¹å¼ç¡®ä¿äº†ç¿»è¯‘çš„å‡†ç¡®æ€§ã€‚

4. å¡«å…¥ YouTube é“¾æ¥æ—¶è¿›è¡Œå¤„ç†æ—¶ï¼Œä¼šè‡ªåŠ¨ä¸‹è½½è§†é¢‘çš„å­—å¹•ï¼Œä»è€Œçœå»è½¬å½•æ­¥éª¤ï¼Œæå¤§åœ°èŠ‚çœæ“ä½œæ—¶é—´ã€‚

## ğŸ¤ è´¡çŒ®æŒ‡å—

ä½œè€…æ˜¯ä¸€åå¤§ä¸‰å­¦ç”Ÿï¼Œä¸ªäººèƒ½åŠ›å’Œé¡¹ç›®éƒ½è¿˜æœ‰è®¸å¤šä¸è¶³ï¼Œé¡¹ç›®ä¹Ÿåœ¨ä¸æ–­å®Œå–„ä¸­ï¼Œå¦‚æœåœ¨ä½¿ç”¨è¿‡ç¨‹é‡åˆ°çš„Bugï¼Œæ¬¢è¿æäº¤ [Issue](https://github.com/WEIFENG2333/VideoCaptioner/issues) å’Œ Pull Request å¸®åŠ©æ”¹è¿›é¡¹ç›®ã€‚

## æ›´æ–°æ—¥å¿—

&lt;details&gt;
&lt;summary&gt;2025.02.07&lt;/summary&gt;
### Bug ä¿®å¤ä¸å…¶ä»–æ”¹è¿›
- ä¿®å¤è°·æ­Œç¿»è¯‘è¯­è¨€ä¸æ­£ç¡®çš„é—®é¢˜ã€‚
- ä¿®éƒ¨å¾®è½¯ç¿»è¯‘ä¸å‡†ç¡®çš„é—®é¢˜ã€‚
- ä¿®å¤è¿è¡Œè®¾å¤‡ä¸é€‰æ‹©cudaæ—¶æ˜¾ç¤ºæŠ¥ winErrorçš„é”™è¯¯
- ä¿®å¤åˆæˆå¤±è´¥çš„é—®é¢˜
- ä¿®å¤asså•è¯­å­—å¹•æ²¡æœ‰å†…å®¹çš„é—®é¢˜
&lt;/details&gt;


&lt;details&gt;
&lt;summary&gt;2024.2.06&lt;/summary&gt;

### æ ¸å¿ƒåŠŸèƒ½å¢å¼º
- å®Œæ•´é‡æ„ä»£ç æ¶æ„ï¼Œä¼˜åŒ–æ•´ä½“æ€§èƒ½
- å­—å¹•ä¼˜åŒ–ä¸ç¿»è¯‘åŠŸèƒ½æ¨¡å—åˆ†ç¦»ï¼Œæä¾›æ›´çµæ´»çš„å¤„ç†é€‰é¡¹
- æ–°å¢æ‰¹é‡å¤„ç†åŠŸèƒ½ï¼šæ”¯æŒæ‰¹é‡å­—å¹•ã€æ‰¹é‡è½¬å½•ã€æ‰¹é‡å­—å¹•è§†é¢‘åˆæˆ
- å…¨é¢ä¼˜åŒ– UI ç•Œé¢ä¸äº¤äº’ç»†èŠ‚

### AI æ¨¡å‹ä¸ç¿»è¯‘å‡çº§
- æ‰©å±• LLM æ”¯æŒï¼šæ–°å¢ SiliconCloudã€DeepSeekã€Ollamaã€Geminiã€ChatGLM ç­‰æ¨¡å‹
- é›†æˆå¤šç§ç¿»è¯‘æœåŠ¡ï¼šDeepLxã€Bingã€Googleã€LLM
- æ–°å¢ faster-whisper-large-v3-turbo æ¨¡å‹æ”¯æŒ
- æ–°å¢å¤šç§ VADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰æ–¹æ³•
- æ”¯æŒè‡ªå®šä¹‰åæ€ç¿»è¯‘å¼€å…³
- å­—å¹•æ–­å¥æ”¯æŒè¯­ä¹‰/å¥å­ä¸¤ç§æ¨¡å¼
- å­—å¹•æ–­å¥ã€ä¼˜åŒ–ã€ç¿»è¯‘æç¤ºè¯çš„ä¼˜åŒ–
- å­—å¹•ã€è½¬å½•ç¼“å­˜æœºåˆ¶çš„ä¼˜åŒ–
- ä¼˜åŒ–ä¸­æ–‡å­—å¹•è‡ªåŠ¨æ¢è¡ŒåŠŸèƒ½
- æ–°å¢ç«–å±å­—å¹•æ ·å¼
- æ”¹è¿›å­—å¹•æ—¶é—´è½´åˆ‡æ¢æœºåˆ¶ï¼Œæ¶ˆé™¤é—ªçƒé—®é¢˜

### Bug ä¿®å¤ä¸å…¶ä»–æ”¹è¿›
- ä¿®å¤ Whisper API æ— æ³•ä½¿ç”¨é—®é¢˜
- æ–°å¢å¤šç§å­—å¹•è§†é¢‘æ ¼å¼æ”¯æŒ
- ä¿®å¤éƒ¨åˆ†æƒ…å†µè½¬å½•é”™è¯¯çš„é—®é¢˜
- ä¼˜åŒ–è§†é¢‘å·¥ä½œç›®å½•ç»“æ„
- æ–°å¢æ—¥å¿—æŸ¥çœ‹åŠŸèƒ½
- æ–°å¢æ³°è¯­ã€å¾·è¯­ç­‰è¯­è¨€çš„å­—å¹•ä¼˜åŒ–
- ä¿®å¤è¯¸å¤šBug...

&lt;/details&gt;


&lt;details&gt;
&lt;summary&gt;2024.12.07&lt;/summary&gt;

- æ–°å¢ Faster-whisper æ”¯æŒï¼ŒéŸ³é¢‘è½¬å­—å¹•è´¨é‡æ›´ä¼˜
- æ”¯æŒVadè¯­éŸ³æ–­ç‚¹æ£€æµ‹ï¼Œå¤§å¤§å‡å°‘å¹»è§‰ç°è±¡
- æ”¯æŒäººå£°éŸ³åˆ†ç¦»ï¼Œåˆ†ç¦»è§†é¢‘èƒŒæ™¯å™ªéŸ³
- æ”¯æŒå…³é—­è§†é¢‘åˆæˆ
- æ–°å¢å­—å¹•æœ€å¤§é•¿åº¦è®¾ç½®
- æ–°å¢å­—å¹•æœ«å°¾æ ‡ç‚¹å»é™¤è®¾ç½®
- ä¼˜åŒ–å’Œç¿»è¯‘çš„æç¤ºè¯ä¼˜åŒ–
- ä¼˜åŒ–LLMå­—å¹•æ–­å¥é”™è¯¯çš„æƒ…å†µ 
- ä¿®å¤éŸ³é¢‘è½¬æ¢æ ¼å¼ä¸ä¸€è‡´é—®é¢˜

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;2024.11.23&lt;/summary&gt;

- æ–°å¢ Whisper-v3 æ¨¡å‹æ”¯æŒï¼Œå¤§å¹…æå‡è¯­éŸ³è¯†åˆ«å‡†ç¡®ç‡
- ä¼˜åŒ–å­—å¹•æ–­å¥ç®—æ³•ï¼Œæä¾›æ›´è‡ªç„¶çš„é˜…è¯»ä½“éªŒ 
- ä¿®å¤æ£€æµ‹æ¨¡å‹å¯ç”¨æ€§æ—¶çš„ç¨³å®šæ€§é—®é¢˜
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;2024.11.20&lt;/summary&gt;

- æ”¯æŒè‡ªå®šä¹‰è°ƒèŠ‚å­—å¹•ä½ç½®å’Œæ ·å¼
- æ–°å¢å­—å¹•ä¼˜åŒ–å’Œç¿»è¯‘è¿‡ç¨‹çš„å®æ—¶æ—¥å¿—æŸ¥çœ‹
- ä¿®å¤ä½¿ç”¨ API æ—¶çš„è‡ªåŠ¨ç¿»è¯‘é—®é¢˜
- ä¼˜åŒ–è§†é¢‘å·¥ä½œç›®å½•ç»“æ„,æå‡æ–‡ä»¶ç®¡ç†æ•ˆç‡
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;2024.11.17&lt;/summary&gt;

- æ”¯æŒåŒè¯­/å•è¯­å­—å¹•çµæ´»å¯¼å‡º
- æ–°å¢æ–‡ç¨¿åŒ¹é…æç¤ºå¯¹é½åŠŸèƒ½
- ä¿®å¤å­—å¹•å¯¼å…¥æ—¶çš„ç¨³å®šæ€§é—®é¢˜
- ä¿®å¤éä¸­æ–‡è·¯å¾„ä¸‹è½½æ¨¡å‹çš„å…¼å®¹æ€§é—®é¢˜
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;2024.11.13&lt;/summary&gt;

- æ–°å¢ Whisper API è°ƒç”¨æ”¯æŒ
- æ”¯æŒå¯¼å…¥ cookie.txt ä¸‹è½½å„å¤§è§†é¢‘å¹³å°èµ„æº
- å­—å¹•æ–‡ä»¶åè‡ªåŠ¨ä¸è§†é¢‘ä¿æŒä¸€è‡´
- è½¯ä»¶ä¸»é¡µæ–°å¢è¿è¡Œæ—¥å¿—å®æ—¶æŸ¥çœ‹
- ç»Ÿä¸€å’Œå®Œå–„è½¯ä»¶å†…éƒ¨åŠŸèƒ½
&lt;/details&gt;


## ğŸ’– æ”¯æŒä½œè€…

å¦‚æœè§‰å¾—é¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œå¯ä»¥ç»™é¡¹ç›®ç‚¹ä¸ªStarï¼Œè¿™å°†æ˜¯å¯¹æˆ‘æœ€å¤§çš„é¼“åŠ±å’Œæ”¯æŒï¼

&lt;details&gt;
&lt;summary&gt;æåŠ©æ”¯æŒ&lt;/summary&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/alipay.jpg&quot; alt=&quot;æ”¯ä»˜å®äºŒç»´ç &quot; width=&quot;30%&quot;&gt;
  &lt;img src=&quot;./docs/images/wechat.jpg&quot; alt=&quot;å¾®ä¿¡äºŒç»´ç &quot; width=&quot;30%&quot;&gt;
&lt;/div&gt;
&lt;/details&gt;

## â­ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=WEIFENG2333/VideoCaptioner&amp;type=Date)](https://star-history.com/#WEIFENG2333/VideoCaptioner&amp;Date)


</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Genesis-Embodied-AI/Genesis]]></title>
            <link>https://github.com/Genesis-Embodied-AI/Genesis</link>
            <guid>https://github.com/Genesis-Embodied-AI/Genesis</guid>
            <pubDate>Mon, 07 Jul 2025 00:04:36 GMT</pubDate>
            <description><![CDATA[A generative world for general-purpose robotics & embodied AI learning.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Genesis-Embodied-AI/Genesis">Genesis-Embodied-AI/Genesis</a></h1>
            <p>A generative world for general-purpose robotics & embodied AI learning.</p>
            <p>Language: Python</p>
            <p>Stars: 25,735</p>
            <p>Forks: 2,321</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>![Genesis](imgs/big_text.png)

![Teaser](imgs/teaser.png)

[![PyPI - Version](https://img.shields.io/pypi/v/genesis-world)](https://pypi.org/project/genesis-world/)
[![PyPI Downloads](https://static.pepy.tech/badge/genesis-world)](https://pepy.tech/projects/genesis-world)
[![GitHub Issues](https://img.shields.io/github/issues/Genesis-Embodied-AI/Genesis)](https://github.com/Genesis-Embodied-AI/Genesis/issues)
[![GitHub Discussions](https://img.shields.io/github/discussions/Genesis-Embodied-AI/Genesis)](https://github.com/Genesis-Embodied-AI/Genesis/discussions)
[![Discord](https://img.shields.io/discord/1322086972302430269?logo=discord)](https://discord.gg/nukCuhB47p)
&lt;a href=&quot;https://drive.google.com/uc?export=view&amp;id=1ZS9nnbQ-t1IwkzJlENBYqYIIOOZhXuBZ&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/WeChat-07C160?style=for-the-badge&amp;logo=wechat&amp;logoColor=white&quot; height=&quot;20&quot; style=&quot;display:inline&quot;&gt;&lt;/a&gt;

[![README in English](https://img.shields.io/badge/English-d9d9d9)](./README.md)
[![README en FranÃ§ais](https://img.shields.io/badge/Francais-d9d9d9)](./README_FR.md)
[![í•œêµ­ì–´ README](https://img.shields.io/badge/í•œêµ­ì–´-d9d9d9)](./README_KR.md)
[![ç®€ä½“ä¸­æ–‡ç‰ˆè‡ªè¿°æ–‡ä»¶](https://img.shields.io/badge/ç®€ä½“ä¸­æ–‡-d9d9d9)](./README_CN.md)
[![æ—¥æœ¬èªç‰ˆ README](https://img.shields.io/badge/æ—¥æœ¬èª-d9d9d9)](./README_JA.md)

# Genesis

## ğŸ”¥ News
- [2025-07-02] The development of Genesis is now officially supported by [Genesis AI](https://genesis-ai.company/).
- [2025-01-09] We released a [detailed performance benchmarking and comparison report](https://github.com/zhouxian/genesis-speed-benchmark) on Genesis, together with all the test scripts.
- [2025-01-08] Released v0.2.1 ğŸŠ ğŸ‰
- [2025-01-08] Created [Discord](https://discord.gg/nukCuhB47p) and [Wechat](https://drive.google.com/uc?export=view&amp;id=1ZS9nnbQ-t1IwkzJlENBYqYIIOOZhXuBZ) group.
- [2024-12-25] Added a [docker](#docker) including support for the ray-tracing renderer
- [2024-12-24] Added guidelines for [contributing to Genesis](https://github.com/Genesis-Embodied-AI/Genesis/blob/main/.github/CONTRIBUTING.md)

## Table of Contents

1. [What is Genesis?](#what-is-genesis)
2. [Key Features](#key-features)
3. [Quick Installation](#quick-installation)
4. [Docker](#docker)
5. [Documentation](#documentation)
6. [Contributing to Genesis](#contributing-to-genesis)
7. [Support](#support)
8. [License and Acknowledgments](#license-and-acknowledgments)
9. [Associated Papers](#associated-papers)
10. [Citation](#citation)

## What is Genesis?

Genesis is a physics platform designed for general-purpose *Robotics/Embodied AI/Physical AI* applications. It is simultaneously multiple things:

1. A **universal physics engine** re-built from the ground up, capable of simulating a wide range of materials and physical phenomena.
2. A **lightweight**, **ultra-fast**, **pythonic**, and **user-friendly** robotics simulation platform.
3. A powerful and fast **photo-realistic rendering system**.
4. A **generative data engine** that transforms user-prompted natural language description into various modalities of data.

Powered by a universal physics engine re-designed and re-built from the ground up, Genesis integrates various physics solvers and their coupling into a unified framework. This core physics engine is further enhanced by a generative agent framework that operates at an upper level, aiming towards fully automated data generation for robotics and beyond.

**Note**: Currently, we are open-sourcing the _underlying physics engine_ and the _simulation platform_. Our _generative framework_ is a modular system that incorporates many different generative modules, each handling a certain range of data modalities, routed by a high level agent. Some of the modules integrated existing papers and some are still under submission. Access to our generative feature will be gradually rolled out in the near future. If you are interested, feel free to explore more in the [paper list](#associated-papers) below.

Genesis aims to:

- **Lower the barrier** to using physics simulations, making robotics research accessible to everyone. See our [mission statement](https://genesis-world.readthedocs.io/en/latest/user_guide/overview/mission.html).
- **Unify diverse physics solvers** into a single framework to recreate the physical world with the highest fidelity.
- **Automate data generation**, reducing human effort and letting the data flywheel spin on its own.

Project Page: &lt;https://genesis-embodied-ai.github.io/&gt;

## Key Features

- **Speed**: Over 43 million FPS when simulating a Franka robotic arm with a single RTX 4090 (430,000 times faster than real-time).
- **Cross-platform**: Runs on Linux, macOS, Windows, and supports multiple compute backends (CPU, Nvidia/AMD GPUs, Apple Metal).
- **Integration of diverse physics solvers**: Rigid body, MPM, SPH, FEM, PBD, Stable Fluid.
- **Wide range of material models**: Simulation and coupling of rigid bodies, liquids, gases, deformable objects, thin-shell objects, and granular materials.
- **Compatibility with various robots**: Robotic arms, legged robots, drones, *soft robots*, and support for loading `MJCF (.xml)`, `URDF`, `.obj`, `.glb`, `.ply`, `.stl`, and more.
- **Photo-realistic rendering**: Native ray-tracing-based rendering.
- **Differentiability**: Genesis is designed to be fully differentiable. Currently, our MPM solver and Tool Solver support differentiability, with other solvers planned for future versions (starting with rigid &amp; articulated body solver).
- **Physics-based tactile simulation**: Differentiable [tactile sensor simulation](https://github.com/Genesis-Embodied-AI/DiffTactile) coming soon (expected in version 0.3.0).
- **User-friendliness**: Designed for simplicity, with intuitive installation and APIs.

## Quick Installation

Install **PyTorch** first following the [official instructions](https://pytorch.org/get-started/locally/).

Then, install Genesis via PyPI:
```bash
pip install genesis-world  # Requires Python&gt;=3.10,&lt;3.13;
```

For the latest version to date, make sure that `pip` is up-to-date via `pip install --upgrade pip`, then run command:
```bash
pip install git+https://github.com/Genesis-Embodied-AI/Genesis.git
```
Note that the package must still be updated manually to sync with main branch.

Users seeking to edit the source code of Genesis are encourage to install Genesis in editable mode. First, make sure that `genesis-world` has been uninstalled, then clone the repository and install locally:
```bash
git clone https://github.com/Genesis-Embodied-AI/Genesis.git
cd Genesis
pip install -e &quot;.[dev]&quot;
```

## Docker

If you want to use Genesis from Docker, you can first build the Docker image as:

```bash
docker build -t genesis -f docker/Dockerfile docker
```

Then you can run the examples inside the docker image (mounted to `/workspace/examples`):

```bash
xhost +local:root # Allow the container to access the display

docker run --gpus all --rm -it \
-e DISPLAY=$DISPLAY \
-v /dev/dri:/dev/dri \
-v /tmp/.X11-unix/:/tmp/.X11-unix \
-v $PWD:/workspace \
genesis
```

### AMD users
AMD users can use Genesis using the `docker/Dockerfile.amdgpu` file, which is built by running:
```
docker build -t genesis-amd -f docker/Dockerfile.amdgpu docker
```

and can then be used by running:

```xhost +local:docker \
docker run -it --network=host \
 --device=/dev/kfd \
 --device=/dev/dri \
 --group-add=video \
 --ipc=host \
 --cap-add=SYS_PTRACE \
 --security-opt seccomp=unconfined \
 --shm-size 8G \
 -v $PWD:/workspace \
 -e DISPLAY=$DISPLAY \
 genesis-amd
 ```

The examples will be accessible from `/workspace/examples`. Note: AMD users should use the vulkan backend. This means you will need to call `gs.init(vulkan)` to initialise Genesis.


## Documentation

Comprehensive documentation is available in [English](https://genesis-world.readthedocs.io/en/latest/user_guide/index.html), [Chinese](https://genesis-world.readthedocs.io/zh-cn/latest/user_guide/index.html), and [Japanese](https://genesis-world.readthedocs.io/ja/latest/user_guide/index.html). This includes detailed installation steps, tutorials, and API references.

## Contributing to Genesis

The Genesis project is an open and collaborative effort. We welcome all forms of contributions from the community, including:

- **Pull requests** for new features or bug fixes.
- **Bug reports** through GitHub Issues.
- **Suggestions** to improve Genesis&#039;s usability.

Refer to our [contribution guide](https://github.com/Genesis-Embodied-AI/Genesis/blob/main/.github/CONTRIBUTING.md) for more details.

## Support

- Report bugs or request features via GitHub [Issues](https://github.com/Genesis-Embodied-AI/Genesis/issues).
- Join discussions or ask questions on GitHub [Discussions](https://github.com/Genesis-Embodied-AI/Genesis/discussions).

## License and Acknowledgments

The Genesis source code is licensed under Apache 2.0.

Genesis&#039;s development has been made possible thanks to these open-source projects:

- [Taichi](https://github.com/taichi-dev/taichi): High-performance cross-platform compute backend. Kudos to the Taichi team for their technical support!
- [FluidLab](https://github.com/zhouxian/FluidLab): Reference MPM solver implementation.
- [SPH_Taichi](https://github.com/erizmr/SPH_Taichi): Reference SPH solver implementation.
- [Ten Minute Physics](https://matthias-research.github.io/pages/tenMinutePhysics/index.html) and [PBF3D](https://github.com/WASD4959/PBF3D): Reference PBD solver implementations.
- [MuJoCo](https://github.com/google-deepmind/mujoco): Reference for rigid body dynamics.
- [libccd](https://github.com/danfis/libccd): Reference for collision detection.
- [PyRender](https://github.com/mmatl/pyrender): Rasterization-based renderer.
- [LuisaCompute](https://github.com/LuisaGroup/LuisaCompute) and [LuisaRender](https://github.com/LuisaGroup/LuisaRender): Ray-tracing DSL.

## Associated Papers

Genesis is a large scale effort that integrates state-of-the-art technologies of various existing and on-going research work into a single system. Here we include a non-exhaustive list of all the papers that contributed to the Genesis project in one way or another:

- Xian, Zhou, et al. &quot;Fluidlab: A differentiable environment for benchmarking complex fluid manipulation.&quot; arXiv preprint arXiv:2303.02346 (2023).
- Xu, Zhenjia, et al. &quot;Roboninja: Learning an adaptive cutting policy for multi-material objects.&quot; arXiv preprint arXiv:2302.11553 (2023).
- Wang, Yufei, et al. &quot;Robogen: Towards unleashing infinite data for automated robot learning via generative simulation.&quot; arXiv preprint arXiv:2311.01455 (2023).
- Wang, Tsun-Hsuan, et al. &quot;Softzoo: A soft robot co-design benchmark for locomotion in diverse environments.&quot; arXiv preprint arXiv:2303.09555 (2023).
- Wang, Tsun-Hsuan Johnson, et al. &quot;Diffusebot: Breeding soft robots with physics-augmented generative diffusion models.&quot; Advances in Neural Information Processing Systems 36 (2023): 44398-44423.
- Katara, Pushkal, Zhou Xian, and Katerina Fragkiadaki. &quot;Gen2sim: Scaling up robot learning in simulation with generative models.&quot; 2024 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2024.
- Si, Zilin, et al. &quot;DiffTactile: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation.&quot; arXiv preprint arXiv:2403.08716 (2024).
- Wang, Yian, et al. &quot;Thin-Shell Object Manipulations With Differentiable Physics Simulations.&quot; arXiv preprint arXiv:2404.00451 (2024).
- Lin, Chunru, et al. &quot;UBSoft: A Simulation Platform for Robotic Skill Learning in Unbounded Soft Environments.&quot; arXiv preprint arXiv:2411.12711 (2024).
- Zhou, Wenyang, et al. &quot;EMDM: Efficient motion diffusion model for fast and high-quality motion generation.&quot; European Conference on Computer Vision. Springer, Cham, 2025.
- Qiao, Yi-Ling, Junbang Liang, Vladlen Koltun, and Ming C. Lin. &quot;Scalable differentiable physics for learning and control.&quot; International Conference on Machine Learning. PMLR, 2020.
- Qiao, Yi-Ling, Junbang Liang, Vladlen Koltun, and Ming C. Lin. &quot;Efficient differentiable simulation of articulated bodies.&quot; In International Conference on Machine Learning, PMLR, 2021.
- Qiao, Yi-Ling, Junbang Liang, Vladlen Koltun, and Ming Lin. &quot;Differentiable simulation of soft multi-body systems.&quot; Advances in Neural Information Processing Systems 34 (2021).
- Wan, Weilin, et al. &quot;Tlcontrol: Trajectory and language control for human motion synthesis.&quot; arXiv preprint arXiv:2311.17135 (2023).
- Wang, Yian, et al. &quot;Architect: Generating Vivid and Interactive 3D Scenes with Hierarchical 2D Inpainting.&quot; arXiv preprint arXiv:2411.09823 (2024).
- Zheng, Shaokun, et al. &quot;LuisaRender: A high-performance rendering framework with layered and unified interfaces on stream architectures.&quot; ACM Transactions on Graphics (TOG) 41.6 (2022): 1-19.
- Fan, Yingruo, et al. &quot;Faceformer: Speech-driven 3d facial animation with transformers.&quot; Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.
- Wu, Sichun, Kazi Injamamul Haque, and Zerrin Yumak. &quot;ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE.&quot; Proceedings of the 17th ACM SIGGRAPH Conference on Motion, Interaction, and Games. 2024.
- Dou, Zhiyang, et al. &quot;CÂ· ase: Learning conditional adversarial skill embeddings for physics-based characters.&quot; SIGGRAPH Asia 2023 Conference Papers. 2023.

... and many more on-going work.

## Citation

If you use Genesis in your research, please consider citing:

```bibtex
@misc{Genesis,
  author = {Genesis Authors},
  title = {Genesis: A Generative and Universal Physics Engine for Robotics and Beyond},
  month = {December},
  year = {2024},
  url = {https://github.com/Genesis-Embodied-AI/Genesis}
}
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[freqtrade/freqtrade]]></title>
            <link>https://github.com/freqtrade/freqtrade</link>
            <guid>https://github.com/freqtrade/freqtrade</guid>
            <pubDate>Mon, 07 Jul 2025 00:04:35 GMT</pubDate>
            <description><![CDATA[Free, open source crypto trading bot]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/freqtrade/freqtrade">freqtrade/freqtrade</a></h1>
            <p>Free, open source crypto trading bot</p>
            <p>Language: Python</p>
            <p>Stars: 40,232</p>
            <p>Forks: 8,019</p>
            <p>Stars today: 39 stars today</p>
            <h2>README</h2><pre># ![freqtrade](https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade_poweredby.svg)

[![Freqtrade CI](https://github.com/freqtrade/freqtrade/actions/workflows/ci.yml/badge.svg?branch=develop)](https://github.com/freqtrade/freqtrade/actions/)
[![DOI](https://joss.theoj.org/papers/10.21105/joss.04864/status.svg)](https://doi.org/10.21105/joss.04864)
[![Coverage Status](https://coveralls.io/repos/github/freqtrade/freqtrade/badge.svg?branch=develop&amp;service=github)](https://coveralls.io/github/freqtrade/freqtrade?branch=develop)
[![Documentation](https://readthedocs.org/projects/freqtrade/badge/)](https://www.freqtrade.io)
[![Maintainability](https://api.codeclimate.com/v1/badges/5737e6d668200b7518ff/maintainability)](https://codeclimate.com/github/freqtrade/freqtrade/maintainability)

Freqtrade is a free and open source crypto trading bot written in Python. It is designed to support all major exchanges and be controlled via Telegram or webUI. It contains backtesting, plotting and money management tools as well as strategy optimization by machine learning.

![freqtrade](https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade-screenshot.png)

## Disclaimer

This software is for educational purposes only. Do not risk money which
you are afraid to lose. USE THE SOFTWARE AT YOUR OWN RISK. THE AUTHORS
AND ALL AFFILIATES ASSUME NO RESPONSIBILITY FOR YOUR TRADING RESULTS.

Always start by running a trading bot in Dry-run and do not engage money
before you understand how it works and what profit/loss you should
expect.

We strongly recommend you to have coding and Python knowledge. Do not
hesitate to read the source code and understand the mechanism of this bot.

## Supported Exchange marketplaces

Please read the [exchange specific notes](docs/exchanges.md) to learn about eventual, special configurations needed for each exchange.

- [X] [Binance](https://www.binance.com/)
- [X] [Bitmart](https://bitmart.com/)
- [X] [BingX](https://bingx.com/invite/0EM9RX)
- [X] [Bybit](https://bybit.com/)
- [X] [Gate.io](https://www.gate.io/ref/6266643)
- [X] [HTX](https://www.htx.com/)
- [X] [Hyperliquid](https://hyperliquid.xyz/) (A decentralized exchange, or DEX)
- [X] [Kraken](https://kraken.com/)
- [X] [OKX](https://okx.com/)
- [X] [MyOKX](https://okx.com/) (OKX EEA)
- [ ] [potentially many others](https://github.com/ccxt/ccxt/). _(We cannot guarantee they will work)_

### Supported Futures Exchanges (experimental)

- [X] [Binance](https://www.binance.com/)
- [X] [Gate.io](https://www.gate.io/ref/6266643)
- [X] [Hyperliquid](https://hyperliquid.xyz/) (A decentralized exchange, or DEX)
- [X] [OKX](https://okx.com/)
- [X] [Bybit](https://bybit.com/)

Please make sure to read the [exchange specific notes](docs/exchanges.md), as well as the [trading with leverage](docs/leverage.md) documentation before diving in.

### Community tested

Exchanges confirmed working by the community:

- [X] [Bitvavo](https://bitvavo.com/)
- [X] [Kucoin](https://www.kucoin.com/)

## Documentation

We invite you to read the bot documentation to ensure you understand how the bot is working.

Please find the complete documentation on the [freqtrade website](https://www.freqtrade.io).

## Features

- [x] **Based on Python 3.11+**: For botting on any operating system - Windows, macOS and Linux.
- [x] **Persistence**: Persistence is achieved through sqlite.
- [x] **Dry-run**: Run the bot without paying money.
- [x] **Backtesting**: Run a simulation of your buy/sell strategy.
- [x] **Strategy Optimization by machine learning**: Use machine learning to optimize your buy/sell strategy parameters with real exchange data.
- [X] **Adaptive prediction modeling**: Build a smart strategy with FreqAI that self-trains to the market via adaptive machine learning methods. [Learn more](https://www.freqtrade.io/en/stable/freqai/)
- [x] **Whitelist crypto-currencies**: Select which crypto-currency you want to trade or use dynamic whitelists.
- [x] **Blacklist crypto-currencies**: Select which crypto-currency you want to avoid.
- [x] **Builtin WebUI**: Builtin web UI to manage your bot.
- [x] **Manageable via Telegram**: Manage the bot with Telegram.
- [x] **Display profit/loss in fiat**: Display your profit/loss in fiat currency.
- [x] **Performance status report**: Provide a performance status of your current trades.

## Quick start

Please refer to the [Docker Quickstart documentation](https://www.freqtrade.io/en/stable/docker_quickstart/) on how to get started quickly.

For further (native) installation methods, please refer to the [Installation documentation page](https://www.freqtrade.io/en/stable/installation/).

## Basic Usage

### Bot commands

```
usage: freqtrade [-h] [-V]
                 {trade,create-userdir,new-config,show-config,new-strategy,download-data,convert-data,convert-trade-data,trades-to-ohlcv,list-data,backtesting,backtesting-show,backtesting-analysis,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-markets,list-pairs,list-strategies,list-hyperoptloss,list-freqaimodels,list-timeframes,show-trades,test-pairlist,convert-db,install-ui,plot-dataframe,plot-profit,webserver,strategy-updater,lookahead-analysis,recursive-analysis}
                 ...

Free, open source crypto trading bot

positional arguments:
  {trade,create-userdir,new-config,show-config,new-strategy,download-data,convert-data,convert-trade-data,trades-to-ohlcv,list-data,backtesting,backtesting-show,backtesting-analysis,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-markets,list-pairs,list-strategies,list-hyperoptloss,list-freqaimodels,list-timeframes,show-trades,test-pairlist,convert-db,install-ui,plot-dataframe,plot-profit,webserver,strategy-updater,lookahead-analysis,recursive-analysis}
    trade               Trade module.
    create-userdir      Create user-data directory.
    new-config          Create new config
    show-config         Show resolved config
    new-strategy        Create new strategy
    download-data       Download backtesting data.
    convert-data        Convert candle (OHLCV) data from one format to
                        another.
    convert-trade-data  Convert trade data from one format to another.
    trades-to-ohlcv     Convert trade data to OHLCV data.
    list-data           List downloaded data.
    backtesting         Backtesting module.
    backtesting-show    Show past Backtest results
    backtesting-analysis
                        Backtest Analysis module.
    hyperopt            Hyperopt module.
    hyperopt-list       List Hyperopt results
    hyperopt-show       Show details of Hyperopt results
    list-exchanges      Print available exchanges.
    list-markets        Print markets on exchange.
    list-pairs          Print pairs on exchange.
    list-strategies     Print available strategies.
    list-hyperoptloss   Print available hyperopt loss functions.
    list-freqaimodels   Print available freqAI models.
    list-timeframes     Print available timeframes for the exchange.
    show-trades         Show trades.
    test-pairlist       Test your pairlist configuration.
    convert-db          Migrate database to different system
    install-ui          Install FreqUI
    plot-dataframe      Plot candles with indicators.
    plot-profit         Generate plot showing profits.
    webserver           Webserver module.
    strategy-updater    updates outdated strategy files to the current version
    lookahead-analysis  Check for potential look ahead bias.
    recursive-analysis  Check for potential recursive formula issue.

options:
  -h, --help            show this help message and exit
  -V, --version         show program&#039;s version number and exit
```

### Telegram RPC commands

Telegram is not mandatory. However, this is a great way to control your bot. More details and the full command list on the [documentation](https://www.freqtrade.io/en/latest/telegram-usage/)

- `/start`: Starts the trader.
- `/stop`: Stops the trader.
- `/stopentry`: Stop entering new trades.
- `/status &lt;trade_id&gt;|[table]`: Lists all or specific open trades.
- `/profit [&lt;n&gt;]`: Lists cumulative profit from all finished trades, over the last n days.
- `/forceexit &lt;trade_id&gt;|all`: Instantly exits the given trade (Ignoring `minimum_roi`).
- `/fx &lt;trade_id&gt;|all`: Alias to `/forceexit`
- `/performance`: Show performance of each finished trade grouped by pair
- `/balance`: Show account balance per currency.
- `/daily &lt;n&gt;`: Shows profit or loss per day, over the last n days.
- `/help`: Show help message.
- `/version`: Show version.

## Development branches

The project is currently setup in two main branches:

- `develop` - This branch has often new features, but might also contain breaking changes. We try hard to keep this branch as stable as possible.
- `stable` - This branch contains the latest stable release. This branch is generally well tested.
- `feat/*` - These are feature branches, which are being worked on heavily. Please don&#039;t use these unless you want to test a specific feature.

## Support

### Help / Discord

For any questions not covered by the documentation or for further information about the bot, or to simply engage with like-minded individuals, we encourage you to join the Freqtrade [discord server](https://discord.gg/p7nuUNVfP7).

### [Bugs / Issues](https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue)

If you discover a bug in the bot, please
[search the issue tracker](https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue)
first. If it hasn&#039;t been reported, please
[create a new issue](https://github.com/freqtrade/freqtrade/issues/new/choose) and
ensure you follow the template guide so that the team can assist you as
quickly as possible.

For every [issue](https://github.com/freqtrade/freqtrade/issues/new/choose) created, kindly follow up and mark satisfaction or reminder to close issue when equilibrium ground is reached.

--Maintain github&#039;s [community policy](https://docs.github.com/en/site-policy/github-terms/github-community-code-of-conduct)--

### [Feature Requests](https://github.com/freqtrade/freqtrade/labels/enhancement)

Have you a great idea to improve the bot you want to share? Please,
first search if this feature was not [already discussed](https://github.com/freqtrade/freqtrade/labels/enhancement).
If it hasn&#039;t been requested, please
[create a new request](https://github.com/freqtrade/freqtrade/issues/new/choose)
and ensure you follow the template guide so that it does not get lost
in the bug reports.

### [Pull Requests](https://github.com/freqtrade/freqtrade/pulls)

Feel like the bot is missing a feature? We welcome your pull requests!

Please read the
[Contributing document](https://github.com/freqtrade/freqtrade/blob/develop/CONTRIBUTING.md)
to understand the requirements before sending your pull-requests.

Coding is not a necessity to contribute - maybe start with improving the documentation?
Issues labeled [good first issue](https://github.com/freqtrade/freqtrade/labels/good%20first%20issue) can be good first contributions, and will help get you familiar with the codebase.

**Note** before starting any major new feature work, *please open an issue describing what you are planning to do* or talk to us on [discord](https://discord.gg/p7nuUNVfP7) (please use the #dev channel for this). This will ensure that interested parties can give valuable feedback on the feature, and let others know that you are working on it.

**Important:** Always create your PR against the `develop` branch, not `stable`.

## Requirements

### Up-to-date clock

The clock must be accurate, synchronized to a NTP server very frequently to avoid problems with communication to the exchanges.

### Minimum hardware required

To run this bot we recommend you a cloud instance with a minimum of:

- Minimal (advised) system requirements: 2GB RAM, 1GB disk space, 2vCPU

### Software requirements

- [Python &gt;= 3.11](http://docs.python-guide.org/en/latest/starting/installation/)
- [pip](https://pip.pypa.io/en/stable/installing/)
- [git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)
- [TA-Lib](https://ta-lib.github.io/ta-lib-python/)
- [virtualenv](https://virtualenv.pypa.io/en/stable/installation.html) (Recommended)
- [Docker](https://www.docker.com/products/docker) (Recommended)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[geekcomputers/Python]]></title>
            <link>https://github.com/geekcomputers/Python</link>
            <guid>https://github.com/geekcomputers/Python</guid>
            <pubDate>Mon, 07 Jul 2025 00:04:34 GMT</pubDate>
            <description><![CDATA[My Python Examples]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/geekcomputers/Python">geekcomputers/Python</a></h1>
            <p>My Python Examples</p>
            <p>Language: Python</p>
            <p>Stars: 33,391</p>
            <p>Forks: 12,563</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre>#This is a new repo
# My Python Eggs ğŸ ğŸ˜„

&lt;hr&gt;

I do not consider myself as a programmer. I create these little programs as experiments to play with Python, or to solve problems for myself. I would gladly accept pointers from others to improve, simplify, or make the code more efficient. If you would like to make any comments then please feel free to email me: craig@geekcomputers.co.uk.

&lt;hr&gt;

This repository contains a collection of Python scripts that are designed to reduce human workload and serve as educational examples for beginners to get started with Python. The code documentation is aligned correctly for viewing in [Notepad++](https://notepad-plus-plus.org/) :spiral_notepad:

Feel free to explore the scripts and use them for your learning and automation needs!

## List of Scripts:

1. [batch_file_rename.py](https://github.com/geekcomputers/Python/blob/master/batch_file_rename.py) - Batch rename a group of files in a specified directory, changing their extensions.
2. [create_dir_if_not_there.py](https://github.com/geekcomputers/Python/blob/master/create_dir_if_not_there.py) - Check if a directory exists in the user&#039;s home directory. Create it if it doesn&#039;t exist.
3. [Fast Youtube Downloader](https://github.com/geekcomputers/Python/blob/master/youtubedownloader.py) - Download YouTube videos quickly with parallel threads using aria2c.
4. [Google Image Downloader](https://github.com/geekcomputers/Python/tree/master/Google_Image_Downloader) - Query a given term and retrieve images from the Google Image database.
5. [dir_test.py](https://github.com/geekcomputers/Python/blob/master/dir_test.py) - Test if the directory `testdir` exists. If not, create it.
6. [env_check.py](https://github.com/geekcomputers/Python/blob/master/env_check.py) - Check if all the required environment variables are set.
7. [blackjack.py](https://github.com/Ratna04priya/Python/blob/master/BlackJack_game/blackjack.py) - Casino Blackjack-21 game in Python.
8. [fileinfo.py](https://github.com/geekcomputers/Python/blob/master/fileinfo.py) - Show file information for a given file.
9. [folder_size.py](https://github.com/geekcomputers/Python/blob/master/folder_size.py) - Scan the current directory and all subdirectories and display their sizes.
10. [logs.py](https://github.com/geekcomputers/Python/blob/master/logs.py) - Search for all `*.log` files in a directory, zip them using the specified program, and date stamp them.
11. [move_files_over_x_days.py](https://github.com/geekcomputers/Python/blob/master/move_files_over_x_days.py) - Move all files over a specified age (in days) from the source directory to the destination directory.
12. [nslookup_check.py](https://github.com/geekcomputers/Python/blob/master/nslookup_check.py) - Open the file `server_list.txt` and perform nslookup for each server to check the DNS entry.
13. [osinfo.py](https://github.com/geekcomputers/Python/blob/master/osinfo.py) - Display information about the operating system on which the script is running.
14. [ping_servers.py](https://github.com/geekcomputers/Python/blob/master/ping_servers.py) - Ping the servers associated with the specified application group.
15. [ping_subnet.py](https://github.com/geekcomputers/Python/blob/master/ping_subnet.py) - Scan the final range of a given IP subnet for available addresses.
16. [powerdown_startup.py](https://github.com/geekcomputers/Python/blob/master/powerdown_startup.py) - Ping machines in the server list. Load the putty session if the machine is up, or notify if it is not.
17. [puttylogs.py](https://github.com/geekcomputers/Python/blob/master/puttylogs.py) - Zip all the logs in the given directory.
18. [script_count.py](https://github.com/geekcomputers/Python/blob/master/script_count.py) - Scan the scripts directory and count the different types of scripts.
19. [get_youtube_view.py](https://github.com/geekcomputers/Python/blob/master/get_youtube_view.py) - Get more views for YouTube videos and repeat songs on YouTube.
20. [script_listing.py](https://github.com/geekcomputers/Python/blob/master/script_listing.py) - List all files in a given directory and its subdirectories.
21. [testlines.py](https://github.com/geekcomputers/Python/blob/master/testlines.py) - Open a file and print out 100 lines of the set line variable.
22. [tweeter.py](https://github.com/geekcomputers/Python/blob/master/tweeter.py) - Tweet text or a picture from the terminal.
23. [serial_scanner.py](https://github.com/geekcomputers/Python/blob/master/serial_scanner.py) - List available serial ports in use on Linux and Windows systems.
24. [get_youtube_view.py](https://github.com/geekcomputers/Python/blob/master/get_youtube_view.py) - Get more views for YouTube videos and repeat songs on YouTube.
25. [CountMillionCharacter.py](https://github.com/geekcomputers/Python/blob/master/CountMillionCharacter.py) and [CountMillionCharacter2.0](https://github.com/geekcomputers/Python/blob/master/CountMillionCharacters-2.0.py) - Get character count of a text file.
26. [xkcd_downloader.py](https://github.com/geekcomputers/Python/blob/master/xkcd_downloader.py) - Download the latest XKCD comic and place them in a new folder called &quot;comics&quot;.
27. [timymodule.py](https://github.com/geekcomputers/Python/blob/master/timymodule.py) - An alternative to Python&#039;s &#039;timeit&#039; module and easier to use.
28. [calculator.py](https://github.com/geekcomputers/Python/blob/master/calculator.py) - Implement a calculator using Python&#039;s eval() function.
29. [Google_News.py](https://github.com/geekcomputers/Python/blob/master/Google_News.py) - Use BeautifulSoup to provide latest news headlines along with news links.
30. [cricket_live_score](https://github.com/geekcomputers/Python/blob/master/Cricket_score.py) - Use BeautifulSoup to provide live cricket scores.
31. [youtube.py](https://github.com/geekcomputers/Python/blob/master/youtube.py) - Take a song name as input and fetch the YouTube URL of the best matching song and play it.
32. [site_health.py](https://github.com/geekcomputers/Python/blob/master/site_health.py) - Check the health of a remote server.
33. [SimpleStopWatch.py](https://github.com/geekcomputers/Python/blob/master/SimpleStopWatch.py) - Simple stop watch implementation using Python&#039;s time module.
34. [Changemac.py](https://github.com/geekcomputers/Python/blob/master/changemac.py) - Change your MAC address, generate a random MAC address, or enter input as a new MAC address on Linux (Successfully Tested in Ubuntu 18.04).
35. [whatsapp-monitor.py](https://github.com/geekcomputers/Python/blob/master/whatsapp-monitor.py) - Use Selenium to give online status updates about your contacts in WhatsApp on the terminal.
36. [whatsapp-chat-analyzer.py](https://github.com/subahanii/whatsapp-Chat-Analyzer) - WhatsApp group/individual chat analyzer that visualizes chat activity using matplotlib.
37. [JARVIS.py](https://git.io/fjH8m) - Control Windows programs with your voice.
38. [Images Downloader](https://git.io/JvnJh) - Download images from webpages on Unix-based systems.
39. [space_invader.py.py](https://github.com/meezan-mallick/space_invader_game) - Classical 2D space invader game to recall your childhood memories.
40. [Test Case Generator](https://github.com/Tanmay-901/test-case-generator/blob/master/test_case.py) - Generate different types of test cases with a clean and friendly UI, used in competitive programming and software testing.
41. [Extract Thumbnail From Video](https://github.com/geekcomputers/Python/tree/ExtractThumbnailFromVideo) - Extract Thumbnail from video files
42. [How to begin the journey of open source (first contribution)](https://www.youtube.com/watch?v=v2X51AVgl3o) - First Contribution of open source
&lt;hr&gt;

_**Note**: The content in this repository belongs to the respective authors and creators. I&#039;m just providing a formatted README.md for better presentation._
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[kyutai-labs/moshi]]></title>
            <link>https://github.com/kyutai-labs/moshi</link>
            <guid>https://github.com/kyutai-labs/moshi</guid>
            <pubDate>Mon, 07 Jul 2025 00:04:33 GMT</pubDate>
            <description><![CDATA[Moshi is a speech-text foundation model and full-duplex spoken dialogue framework. It uses Mimi, a state-of-the-art streaming neural audio codec.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kyutai-labs/moshi">kyutai-labs/moshi</a></h1>
            <p>Moshi is a speech-text foundation model and full-duplex spoken dialogue framework. It uses Mimi, a state-of-the-art streaming neural audio codec.</p>
            <p>Language: Python</p>
            <p>Stars: 8,587</p>
            <p>Forks: 731</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre># Moshi: a speech-text foundation model for real time dialogue

![precommit badge](https://github.com/kyutai-labs/moshi/workflows/precommit/badge.svg)
![rust ci badge](https://github.com/kyutai-labs/moshi/workflows/Rust%20CI/badge.svg)

[[Read the paper]][moshi] [[Demo]](https://moshi.chat) [[Hugging Face]](https://huggingface.co/collections/kyutai/moshi-v01-release-66eaeaf3302bef6bd9ad7acd)

 [Moshi][moshi] is a speech-text foundation model and **full-duplex** spoken dialogue framework.
 It uses [Mimi][moshi], a state-of-the-art streaming neural audio codec. Mimi processes 24 kHz audio, down to a 12.5 Hz representation
 with a bandwidth of 1.1 kbps, in a fully streaming manner (latency of 80ms, the frame size),
 yet performs better than existing, non-streaming, codecs like
 [SpeechTokenizer](https://github.com/ZhangXInFD/SpeechTokenizer) (50 Hz, 4kbps), or [SemantiCodec](https://github.com/haoheliu/SemantiCodec-inference) (50 Hz, 1.3kbps).

 Moshi models **two streams of audio**: one corresponds to Moshi, and the other one to the user.
 At inference, the stream from the user is taken from the audio input,
and the one for Moshi is sampled from the model&#039;s output. Along these two audio streams, Moshi predicts text tokens corresponding to its own speech, its **inner monologue**,
which greatly improves the quality of its generation. A small Depth Transformer models inter codebook dependencies for a given time step,
while a large, 7B parameter Temporal Transformer models the temporal dependencies. Moshi achieves a theoretical latency
of 160ms (80ms for the frame size of Mimi + 80ms of acoustic delay), with a practical overall latency as low as 200ms on an L4 GPU.

[Talk to Moshi](https://moshi.chat) now on our live demo.


&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;./moshi.png&quot; alt=&quot;Schema representing the structure of Moshi. Moshi models two streams of audio:
    one corresponds to Moshi, and the other one to the user. At inference, the audio stream of the user is taken from the audio input, and the audio stream for Moshi is sampled from the model&#039;s output. Along that, Moshi predicts text tokens corresponding to its own speech for improved accuracy. A small Depth Transformer models inter codebook dependencies for a given step.&quot;
width=&quot;650px&quot;&gt;&lt;/p&gt;

Mimi builds on previous neural audio codecs such as [SoundStream](https://arxiv.org/abs/2107.03312)
and [EnCodec](https://github.com/facebookresearch/encodec), adding a Transformer both in the encoder and decoder,
and adapting the strides to match an overall frame rate of 12.5 Hz. This allows Mimi to get closer to the
average frame rate of text tokens (~3-4 Hz), and limit the number of autoregressive steps in Moshi.
Similarly to SpeechTokenizer, Mimi uses a distillation loss so that the first codebook tokens match
a self-supervised representation from [WavLM](https://arxiv.org/abs/2110.13900), which allows modeling semantic and acoustic information with a single model. Interestingly, while Mimi is fully causal and streaming, it learns to match sufficiently well the non-causal
representation from WavLM, without introducing any delays. Finally, and similarly to [EBEN](https://arxiv.org/pdf/2210.14090),
Mimi uses **only an adversarial training loss**, along with feature matching, showing strong improvements in terms of
subjective quality despite its low bitrate.

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;./mimi.png&quot; alt=&quot;Schema representing the structure of Mimi, our proposed neural codec. Mimi contains a Transformer
in both its encoder and decoder, and achieves a frame rate closer to that of text tokens. This allows us to reduce
the number of auto-regressive steps taken by Moshi, thus reducing the latency of the model.&quot;
width=&quot;800px&quot;&gt;&lt;/p&gt;



## Organisation of the repository

There are three separate versions of the moshi inference stack in this repo.
- The Python version using PyTorch is in the [`moshi/`](moshi/) directory.
- The Python version using MLX for M series Macs is in the [`moshi_mlx/`](moshi_mlx/) directory.
- The Rust version used in production is in the [`rust/`](rust/) directory.
    This contains in particular a Mimi implementation in Rust, with Python bindings available
    as `rustymimi`.

Finally, the code for the live demo is provided in the [`client/`](client/) directory.

If you want to fine tune Moshi, head out to [kyutai-labs/moshi-finetune](https://github.com/kyutai-labs/moshi-finetune).


## Models

We release three models:
- our speech codec Mimi,
- Moshi fine-tuned on a male synthetic voice (Moshiko),
- Moshi fine-tuned on a female synthetic voice (Moshika).

Note that this codebase also supports [Hibiki](https://github.com/kyutai-labs/hibiki), check out the dedicated repo for more information.

Depending on the backend, the file format and quantization available will vary. Here is the list
of the HuggingFace repo with each model. Mimi is bundled in each of those, and always use the same checkpoint format.

- Moshika for PyTorch (bf16, int8): [kyutai/moshika-pytorch-bf16](https://huggingface.co/kyutai/moshika-pytorch-bf16), [kyutai/moshika-pytorch-q8](https://huggingface.co/kyutai/moshika-pytorch-q8) (experimental).
- Moshiko for PyTorch (bf16, int8): [kyutai/moshiko-pytorch-bf16](https://huggingface.co/kyutai/moshiko-pytorch-bf16), [kyutai/moshiko-pytorch-q8](https://huggingface.co/kyutai/moshiko-pytorch-q8) (experimental).
- Moshika for MLX (int4, int8, bf16): [kyutai/moshika-mlx-q4](https://huggingface.co/kyutai/moshika-mlx-q4), [kyutai/moshika-mlx-q8](https://huggingface.co/kyutai/moshika-mlx-q8),  [kyutai/moshika-mlx-bf16](https://huggingface.co/kyutai/moshika-mlx-bf16).
- Moshiko for MLX (int4, int8, bf16): [kyutai/moshiko-mlx-q4](https://huggingface.co/kyutai/moshiko-mlx-q4), [kyutai/moshiko-mlx-q8](https://huggingface.co/kyutai/moshiko-mlx-q8),  [kyutai/moshiko-mlx-bf16](https://huggingface.co/kyutai/moshiko-mlx-bf16).
- Moshika for Rust/Candle (int8, bf16): [kyutai/moshika-candle-q8](https://huggingface.co/kyutai/moshika-candle-q8),  [kyutai/moshika-mlx-bf16](https://huggingface.co/kyutai/moshika-candle-bf16).
- Moshiko for Rust/Candle (int8, bf16): [kyutai/moshiko-candle-q8](https://huggingface.co/kyutai/moshiko-candle-q8),  [kyutai/moshiko-mlx-bf16](https://huggingface.co/kyutai/moshiko-candle-bf16).

All models are released under the CC-BY 4.0 license.

## Requirements

You will need at least Python 3.10, with 3.12 recommended. For specific requirements, please check the individual backends
directories. You can install the PyTorch and MLX clients with the following:

```bash
pip install -U moshi      # moshi PyTorch, from PyPI
pip install -U moshi_mlx  # moshi MLX, from PyPI, best with Python 3.12.
# Or the bleeding edge versions for Moshi and Moshi-MLX.
pip install -U -e &quot;git+https://git@github.com/kyutai-labs/moshi.git#egg=moshi&amp;subdirectory=moshi&quot;
pip install -U -e &quot;git+https://git@github.com/kyutai-labs/moshi.git#egg=moshi_mlx&amp;subdirectory=moshi_mlx&quot;

pip install rustymimi  # mimi, rust implementation with Python bindings from PyPI
```

If you are not using Python 3.12, you might get an error when installing
`moshi_mlx` or `rustymimi` (which `moshi_mlx` depends on). Then, you will need to install the [Rust toolchain](https://rustup.rs/), or switch to Python 3.12.

While we hope that the present codebase will work on Windows, we do not provide official support for it.
We have tested the MLX version on a MacBook Pro M3. At the moment, we do not support quantization
for the PyTorch version, so you will need a GPU with a significant amount of memory (24GB).

For using the Rust backend, you will need a recent version of the [Rust toolchain](https://rustup.rs/).
To compile GPU support, you will also need the [CUDA](https://developer.nvidia.com/cuda-toolkit) properly installed for your GPU, in particular with `nvcc`.

## Python (PyTorch)

The PyTorch based API can be found in the `moshi` directory. It provides a streaming
version of the audio tokenizer (mimi) and the language model (moshi).

In order to run in interactive mode, you need to start a server which will
run the model, you can then use either the web UI or a command line client.

Start the server with:
```bash
python -m moshi.server [--gradio-tunnel] [--hf-repo kyutai/moshika-pytorch-bf16]
```

And then access the web UI on [localhost:8998](http://localhost:8998).
If your GPU is on a distant machine this will not work as websites using http
are not allowed to use the audio worklet api. There are two ways to get around
this:
- Forward the remote 8998 port to your localhost using ssh `-L` flag. Then
  connects to [localhost:8998](http://localhost:8998) as mentionned previously.
- Use the `--gradio-tunnel` argument, this sets up a tunnel with a URL accessible from anywhere.
  Keep in mind that this tunnel goes through the US and can add significant
  latency (up to 500ms from Europe). You can use `--gradio-tunnel-token` to set a
  fixed secret token and reuse the same address over time.

You can use `--hf-repo` to select a different pretrained model, by setting the proper Hugging Face repository.

Accessing a server that is not localhost via http may cause issues with using
the microphone in the web UI (in some browsers this is only allowed using
https).

A local client is also available, as
```bash
python -m moshi.client [--url URL_TO_GRADIO]
```
However note that, unlike the web browser, this client is barebone: it does not perform any echo cancellation,
nor does it try to compensate for a growing lag by skipping frames.

For more information, in particular on how to use the API directly, please
checkout [moshi/README.md](moshi/README.md).

## Python (MLX) for local inference on macOS

Once you have installed `moshi_mlx`, you can run
```bash
python -m moshi_mlx.local -q 4   # weights quantized to 4 bits
python -m moshi_mlx.local -q 8   # weights quantized to 8 bits
# And using a different pretrained model:
python -m moshi_mlx.local -q 4 --hf-repo kyutai/moshika-mlx-q4
python -m moshi_mlx.local -q 8 --hf-repo kyutai/moshika-mlx-q8
# be careful to always match the `-q` and `--hf-repo` flag.
```

This command line interface is also barebone. It does not perform any echo cancellation,
nor does it try to compensate for a growing lag by skipping frames.

Alternatively you can run `python -m moshi_mlx.local_web` to use
the web UI, the connection is via http and will be at [localhost:8998](http://localhost:8998).


## Rust

In order to run the Rust inference server, use the following command from within
the `rust` directory:

```bash
cargo run --features cuda --bin moshi-backend -r -- --config moshi-backend/config.json standalone
```

When using macOS, you can replace `--features cuda` with `--features metal`.

Alternatively you can use `config-q8.json` rather than `config.json` to use the
quantized q8 model. You can select a different pretrained model, e.g. Moshika,
by changing the `&quot;hf_repo&quot;` key in either file.

Once the server has printed &#039;standalone worker listening&#039;, you can use the web
UI. By default the Rust server uses https so it will be at
[localhost:8998](https://localhost:8998).

You will get warnings about the site being unsafe. When using chrome you
can bypass these by selecting &quot;Details&quot; or &quot;Advanced&quot;, then &quot;Visit this unsafe
site&quot; or &quot;Proceed to localhost (unsafe)&quot;.

## Clients

We recommend using the web UI as it provides additional echo cancellation that helps
the overall model quality. Note that most commands will directly serve this UI
in the provided URL, and there is in general nothing more to do.

Alternatively, we provide command line interfaces
for the Rust and Python versions, the protocol is the same as with the web UI so
there is nothing to change on the server side.

For reference, here is the list of clients for Moshi.

### Rust Command Line

From within the `rust` directory, run the following:
```bash
cargo run --bin moshi-cli -r -- tui --host localhost
```

### Python with PyTorch

```bash
python -m moshi.client
```

### Gradio Demo

You can launch a Gradio demo locally with the following command:

```bash
python -m moshi.client_gradio --url &lt;moshi-server-url&gt;
```

Prior to running the Gradio demo, please install `gradio-webrtc&gt;=0.0.18`.

### Docker Compose (CUDA only)

```bash
docker compose up
```

* Requires [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)

### WebUI

The web UI can be built from this repo via the
following steps (these will require `npm` being installed).
```bash
cd client
npm install
npm run build
```

The web UI can then be found in the `client/dist` directory.

## Development

If you wish to install from a clone of this repository, maybe to further develop Moshi, you can do the following:
```bash
# From the root of the clone of the repo
pip install -e &#039;moshi[dev]&#039;
pip install -e &#039;moshi_mlx[dev]&#039;
pre-commit install
```

If you wish to build locally `rustymimi` (assuming you have Rust properly installed):
```bash
pip install maturin
maturin dev -r -m rust/mimi-pyo3/Cargo.toml
```

## FAQ

Checkout the [Frequently Asked Questions](FAQ.md) section before opening an issue.


## License

The present code is provided under the MIT license for the Python parts, and Apache license for the Rust backend.
The web client code is provided under the MIT license.
Note that parts of this code is based on [AudioCraft](https://github.com/facebookresearch/audiocraft), released under
the MIT license.

The weights for the models are released under the CC-BY 4.0 license.

## Citation

If you use either Mimi or Moshi, please cite the following paper,

```
@techreport{kyutai2024moshi,
      title={Moshi: a speech-text foundation model for real-time dialogue},
      author={Alexandre D\&#039;efossez and Laurent Mazar\&#039;e and Manu Orsini and
      Am\&#039;elie Royer and Patrick P\&#039;erez and Herv\&#039;e J\&#039;egou and Edouard Grave and Neil Zeghidour},
      year={2024},
      eprint={2410.00037},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2410.00037},
}
```

[moshi]: https://arxiv.org/abs/2410.00037
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[swisskyrepo/PayloadsAllTheThings]]></title>
            <link>https://github.com/swisskyrepo/PayloadsAllTheThings</link>
            <guid>https://github.com/swisskyrepo/PayloadsAllTheThings</guid>
            <pubDate>Mon, 07 Jul 2025 00:04:32 GMT</pubDate>
            <description><![CDATA[A list of useful payloads and bypass for Web Application Security and Pentest/CTF]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/swisskyrepo/PayloadsAllTheThings">swisskyrepo/PayloadsAllTheThings</a></h1>
            <p>A list of useful payloads and bypass for Web Application Security and Pentest/CTF</p>
            <p>Language: Python</p>
            <p>Stars: 67,833</p>
            <p>Forks: 15,598</p>
            <p>Stars today: 237 stars today</p>
            <h2>README</h2><pre># Payloads All The Things

A list of useful payloads and bypasses for Web Application Security.
Feel free to improve with your payloads and techniques !
I :heart: pull requests :)

You can also contribute with a :beers: IRL, or using the sponsor button

[![Sponsor](https://img.shields.io/static/v1?label=Sponsor&amp;message=%E2%9D%A4&amp;logo=GitHub&amp;link=https://github.com/sponsors/swisskyrepo)](https://github.com/sponsors/swisskyrepo)
[![Tweet](https://img.shields.io/twitter/url/http/shields.io.svg?style=social)](https://twitter.com/intent/tweet?text=Payloads%20All%20The%20Things,%20a%20list%20of%20useful%20payloads%20and%20bypasses%20for%20Web%20Application%20Security%20-%20by%20@pentest_swissky&amp;url=https://github.com/swisskyrepo/PayloadsAllTheThings/)

An alternative display version is available at [PayloadsAllTheThingsWeb](https://swisskyrepo.github.io/PayloadsAllTheThings/).

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/swisskyrepo/PayloadsAllTheThings/master/.github/banner.png&quot; alt=&quot;banner&quot;&gt;
&lt;/p&gt;

## :book: Documentation

Every section contains the following files, you can use the `_template_vuln` folder to create a new chapter:

- README.md - vulnerability description and how to exploit it, including several payloads
- Intruder - a set of files to give to Burp Intruder
- Images - pictures for the README.md
- Files - some files referenced in the README.md

You might also like the other projects from the AllTheThings family :

- [InternalAllTheThings](https://swisskyrepo.github.io/InternalAllTheThings/) - Active Directory and Internal Pentest Cheatsheets
- [HardwareAllTheThings](https://swisskyrepo.github.io/HardwareAllTheThings/) - Hardware/IOT Pentesting Wiki

You want more ? Check the [Books](https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/_LEARNING_AND_SOCIALS/BOOKS.md) and [Youtube channel](https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/_LEARNING_AND_SOCIALS/YOUTUBE.md) selections.

## :technologist: Contributions

Be sure to read [CONTRIBUTING.md](https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/CONTRIBUTING.md)

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/swisskyrepo/PayloadsAllTheThings/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=swisskyrepo/PayloadsAllTheThings&amp;max=36&quot; alt=&quot;sponsors-list&quot; &gt;
&lt;/a&gt;
&lt;/p&gt;

Thanks again for your contribution! :heart:

## :beers: Sponsors

This project is proudly sponsored by these companies:

[&lt;img src=&quot;https://avatars.githubusercontent.com/u/48131541?s=40&amp;v=4&quot; alt=&quot;sponsor-vaadata&quot;&gt;](https://www.vaadata.com/)
[&lt;img src=&quot;https://avatars.githubusercontent.com/u/50994705?s=40&amp;v=4&quot; alt=&quot;sponsor-projectdiscovery&quot;&gt;](https://github.com/projectdiscovery)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>