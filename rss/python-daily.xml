<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Wed, 24 Sep 2025 00:04:28 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[EbookFoundation/free-programming-books]]></title>
            <link>https://github.com/EbookFoundation/free-programming-books</link>
            <guid>https://github.com/EbookFoundation/free-programming-books</guid>
            <pubDate>Wed, 24 Sep 2025 00:04:28 GMT</pubDate>
            <description><![CDATA[ğŸ“š Freely available programming books]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/EbookFoundation/free-programming-books">EbookFoundation/free-programming-books</a></h1>
            <p>ğŸ“š Freely available programming books</p>
            <p>Language: Python</p>
            <p>Stars: 370,059</p>
            <p>Forks: 64,285</p>
            <p>Stars today: 441 stars today</p>
            <h2>README</h2><pre># List of Free Learning Resources In Many Languages

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)&amp;#160;
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)&amp;#160;
[![Hacktoberfest 2023 stats](https://img.shields.io/github/hacktoberfest/2023/EbookFoundation/free-programming-books?label=Hacktoberfest+2023)](https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged+created%3A2023-10-01..2023-10-31)

&lt;/div&gt;

Search the list at [https://ebookfoundation.github.io/free-programming-books-search/](https://ebookfoundation.github.io/free-programming-books-search/) [![https://ebookfoundation.github.io/free-programming-books-search/](https://img.shields.io/website?style=flat&amp;logo=www&amp;logoColor=whitesmoke&amp;label=Dynamic%20search%20site&amp;down_color=red&amp;down_message=down&amp;up_color=green&amp;up_message=up&amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books-search%2F)](https://ebookfoundation.github.io/free-programming-books-search/).

This page is available as an easy-to-read website. Access it by clicking on [![https://ebookfoundation.github.io/free-programming-books/](https://img.shields.io/website?style=flat&amp;logo=www&amp;logoColor=whitesmoke&amp;label=Static%20site&amp;down_color=red&amp;down_message=down&amp;up_color=green&amp;up_message=up&amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books%2F)](https://ebookfoundation.github.io/free-programming-books/).

&lt;div align=&quot;center&quot;&gt;
  &lt;form action=&quot;https://ebookfoundation.github.io/free-programming-books-search&quot;&gt;
    &lt;input type=&quot;text&quot; id=&quot;fpbSearch&quot; name=&quot;search&quot; required placeholder=&quot;Search Book or Author&quot;/&gt;
    &lt;label for=&quot;submit&quot;&gt; &lt;/label&gt;
    &lt;input type=&quot;submit&quot; id=&quot;submit&quot; name=&quot;submit&quot; value=&quot;Search&quot; /&gt;
  &lt;/form&gt;
&lt;/div&gt;

## Intro

This list was originally a clone of [StackOverflow - List of Freely Available Programming Books](https://web.archive.org/web/20140606191453/http://stackoverflow.com/questions/194812/list-of-freely-available-programming-books/392926) with contributions from Karan Bhangui and George Stocker.

The list was moved to GitHub by Victor Felder for collaborative updating and maintenance. It has grown to become one of [GitHub&#039;s most popular repositories](https://octoverse.github.com/).

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

[![GitHub repo forks](https://img.shields.io/github/forks/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Forks)](https://github.com/EbookFoundation/free-programming-books/network)&amp;#160;
[![GitHub repo stars](https://img.shields.io/github/stars/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Stars)](https://github.com/EbookFoundation/free-programming-books/stargazers)&amp;#160;
[![GitHub repo contributors](https://img.shields.io/github/contributors-anon/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Contributors)](https://github.com/EbookFoundation/free-programming-books/graphs/contributors)    
[![GitHub org sponsors](https://img.shields.io/github/sponsors/EbookFoundation?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Sponsors)](https://github.com/sponsors/EbookFoundation)&amp;#160;
[![GitHub repo watchers](https://img.shields.io/github/watchers/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Watchers)](https://github.com/EbookFoundation/free-programming-books/watchers)&amp;#160;
[![GitHub repo size](https://img.shields.io/github/repo-size/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Repo%20Size)](https://github.com/EbookFoundation/free-programming-books/archive/refs/heads/main.zip)

&lt;/div&gt;

The [Free Ebook Foundation](https://ebookfoundation.org) now administers the repo, a not-for-profit organization devoted to promoting the creation, distribution, archiving, and sustainability of free ebooks. [Donations](https://ebookfoundation.org/contributions.html) to the Free Ebook Foundation are tax-deductible in the US.


## How To Contribute

Please read [CONTRIBUTING](docs/CONTRIBUTING.md). If you&#039;re new to GitHub, [welcome](docs/HOWTO.md)! Remember to abide by our adapted from ![Contributor Covenant 1.3](https://img.shields.io/badge/Contributor%20Covenant-1.3-4baaaa.svg) [Code of Conduct](docs/CODE_OF_CONDUCT.md) too ([translations](#translations) also available).

Click on these badges to see how you might be able to help:

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

[![GitHub repo Issues](https://img.shields.io/github/issues/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=red&amp;label=Issues)](https://github.com/EbookFoundation/free-programming-books/issues)&amp;#160;
[![GitHub repo Good Issues for newbies](https://img.shields.io/github/issues/EbookFoundation/free-programming-books/good%20first%20issue?style=flat&amp;logo=github&amp;logoColor=green&amp;label=Good%20First%20issues)](https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)&amp;#160;
[![GitHub Help Wanted issues](https://img.shields.io/github/issues/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;logo=github&amp;logoColor=b545d1&amp;label=%22Help%20Wanted%22%20issues)](https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)    
[![GitHub repo PRs](https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=orange&amp;label=PRs)](https://github.com/EbookFoundation/free-programming-books/pulls)&amp;#160;
[![GitHub repo Merged PRs](https://img.shields.io/github/issues-search/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=green&amp;label=Merged%20PRs&amp;query=is%3Amerged)](https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged)&amp;#160;
[![GitHub Help Wanted PRs](https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;logo=github&amp;logoColor=b545d1&amp;label=%22Help%20Wanted%22%20PRs)](https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)

&lt;/div&gt;

## How To Share

&lt;div align=&quot;left&quot; markdown=&quot;1&quot;&gt;
&lt;a href=&quot;https://www.facebook.com/share.php?u=https%3A%2F%2Fgithub.com%2FEbookFoundation%2Ffree-programming-books&amp;p[images][0]=&amp;p[title]=Free%20Programming%20Books&amp;p[summary]=&quot;&gt;Share on Facebook&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;http://www.linkedin.com/shareArticle?mini=true&amp;url=https://github.com/EbookFoundation/free-programming-books&amp;title=Free%20Programming%20Books&amp;summary=&amp;source=&quot;&gt;Share on LinkedIn&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;https://toot.kytta.dev/?mini=true&amp;url=https://github.com/EbookFoundation/free-programming-books&amp;title=Free%20Programming%20Books&amp;summary=&amp;source=&quot;&gt;Share on Mastodon/Fediverse&lt;/a&gt;&lt;br&gt;    
&lt;a href=&quot;https://t.me/share/url?url=https://github.com/EbookFoundation/free-programming-books&quot;&gt;Share on Telegram&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;https://twitter.com/intent/tweet?text=https://github.com/EbookFoundation/free-programming-books%0AFree%20Programming%20Books&quot;&gt;Share on ğ• (Twitter)&lt;/a&gt;&lt;br&gt;
&lt;/div&gt;

## Resources

This project lists books and other resources grouped by genres:

### Books

[English, By Programming Language](books/free-programming-books-langs.md)

[English, By Subject](books/free-programming-books-subjects.md)

#### Other Languages

+ [Arabic / al arabiya / Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](books/free-programming-books-ar.md)
+ [Armenian / Õ€Õ¡ÕµÕ¥Ö€Õ¥Õ¶](books/free-programming-books-hy.md)
+ [Azerbaijani / ĞĞ·Ó™Ñ€Ğ±Ğ°Ñ˜Ò¹Ğ°Ğ½ Ğ´Ğ¸Ğ»Ğ¸ / Ø¢Ø°Ø±Ø¨Ø§ÙŠØ¬Ø§Ù†Ø¬Ø§ Ø¯ÙŠÙ„ÙŠ](books/free-programming-books-az.md)
+ [Bengali / à¦¬à¦¾à¦‚à¦²à¦¾](books/free-programming-books-bn.md)
+ [Bulgarian / Ğ±ÑŠĞ»Ğ³Ğ°Ñ€ÑĞºĞ¸](books/free-programming-books-bg.md)
+ [Burmese / á€™á€¼á€”á€ºá€™á€¬á€˜á€¬á€á€¬](books/free-programming-books-my.md)
+ [Chinese / ä¸­æ–‡](books/free-programming-books-zh.md)
+ [Czech / ÄeÅ¡tina / ÄeskÃ½ jazyk](books/free-programming-books-cs.md)
+ [Catalan / catalan/ catalÃ ](books/free-programming-books-ca.md)
+ [Danish / dansk](books/free-programming-books-da.md)
+ [Dutch / Nederlands](books/free-programming-books-nl.md)
+ [Estonian / eesti keel](books/free-programming-books-et.md)
+ [Finnish / suomi / suomen kieli](books/free-programming-books-fi.md)
+ [French / franÃ§ais](books/free-programming-books-fr.md)
+ [German / Deutsch](books/free-programming-books-de.md)
+ [Greek / ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬](books/free-programming-books-el.md)
+ [Hebrew / ×¢×‘×¨×™×ª](books/free-programming-books-he.md)
+ [Hindi / à¤¹à¤¿à¤¨à¥à¤¦à¥€](books/free-programming-books-hi.md)
+ [Hungarian / magyar / magyar nyelv](books/free-programming-books-hu.md)
+ [Indonesian / Bahasa Indonesia](books/free-programming-books-id.md)
+ [Italian / italiano](books/free-programming-books-it.md)
+ [Japanese / æ—¥æœ¬èª](books/free-programming-books-ja.md)
+ [Korean / í•œêµ­ì–´](books/free-programming-books-ko.md)
+ [Latvian / LatvieÅ¡u](books/free-programming-books-lv.md)
+ [Malayalam / à´®à´²à´¯à´¾à´³à´‚](books/free-programming-books-ml.md)
+ [Norwegian / Norsk](books/free-programming-books-no.md)
+ [Persian / Farsi (Iran) / ÙØ§Ø±Ø³Ù‰](books/free-programming-books-fa_IR.md)
+ [Polish / polski / jÄ™zyk polski / polszczyzna](books/free-programming-books-pl.md)
+ [Portuguese (Brazil)](books/free-programming-books-pt_BR.md)
+ [Portuguese (Portugal)](books/free-programming-books-pt_PT.md)
+ [Romanian (Romania) / limba romÃ¢nÄƒ / romÃ¢n](books/free-programming-books-ro.md)
+ [Russian / Ğ ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº](books/free-programming-books-ru.md)
+ [Serbian / ÑÑ€Ğ¿ÑĞºĞ¸ Ñ˜ĞµĞ·Ğ¸Ğº / srpski jezik](books/free-programming-books-sr.md)
+ [Slovak / slovenÄina](books/free-programming-books-sk.md)
+ [Spanish / espaÃ±ol / castellano](books/free-programming-books-es.md)
+ [Swedish / Svenska](books/free-programming-books-sv.md)
+ [Tamil / à®¤à®®à®¿à®´à¯](books/free-programming-books-ta.md)
+ [Telugu / à°¤à±†à°²à±à°—à±](books/free-programming-books-te.md)
+ [Thai / à¹„à¸—à¸¢](books/free-programming-books-th.md)
+ [Turkish / TÃ¼rkÃ§e](books/free-programming-books-tr.md)
+ [Ukrainian / Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°](books/free-programming-books-uk.md)
+ [Vietnamese / Tiáº¿ng Viá»‡t](books/free-programming-books-vi.md)

### Cheat Sheets

+ [All Languages](more/free-programming-cheatsheets.md)

### Free Online Courses

+ [Arabic / al arabiya / Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](courses/free-courses-ar.md)
+ [Bengali / à¦¬à¦¾à¦‚à¦²à¦¾](courses/free-courses-bn.md)
+ [Bulgarian / Ğ±ÑŠĞ»Ğ³Ğ°Ñ€ÑĞºĞ¸](courses/free-courses-bg.md)
+ [Burmese / á€™á€¼á€”á€ºá€™á€¬á€˜á€¬á€á€¬](courses/free-courses-my.md)
+ [Chinese / ä¸­æ–‡](courses/free-courses-zh.md)
+ [English](courses/free-courses-en.md)
+ [Finnish / suomi / suomen kieli](courses/free-courses-fi.md)
+ [French / franÃ§ais](courses/free-courses-fr.md)
+ [German / Deutsch](courses/free-courses-de.md)
+ [Greek / ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬](courses/free-courses-el.md)
+ [Hebrew / ×¢×‘×¨×™×ª](courses/free-courses-he.md)
+ [Hindi / à¤¹à¤¿à¤‚à¤¦à¥€](courses/free-courses-hi.md)
+ [Indonesian / Bahasa Indonesia](courses/free-courses-id.md)
+ [Italian / italiano](courses/free-courses-it.md)
+ [Japanese / æ—¥æœ¬èª](courses/free-courses-ja.md)
+ [Kannada/à²•à²¨à³à²¨à²¡](courses/free-courses-kn.md)
+ [Kazakh / Ò›Ğ°Ğ·Ğ°Ò›ÑˆĞ°](courses/free-courses-kk.md)
+ [Khmer / á—á¶áŸá¶ááŸ’á˜áŸ‚áš](courses/free-courses-km.md)
+ [Korean / í•œêµ­ì–´](courses/free-courses-ko.md)
+ [Malayalam / à´®à´²à´¯à´¾à´³à´‚](courses/free-courses-ml.md)
+ [Marathi / à¤®à¤°à¤¾à¤ à¥€](courses/free-courses-mr.md)
+ [Nepali / à¤¨à¥‡à¤ªà¤¾à¤²à¥€](courses/free-courses-ne.md)
+ [Norwegian / Norsk](courses/free-courses-no.md)
+ [Persian / Farsi (Iran) / ÙØ§Ø±Ø³Ù‰](courses/free-courses-fa_IR.md)
+ [Polish / polski / jÄ™zyk polski / polszczyzna](courses/free-courses-pl.md)
+ [Portuguese (Brazil)](courses/free-courses-pt_BR.md)
+ [Portuguese (Portugal)](courses/free-courses-pt_PT.md)
+ [Russian / Ğ ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº](courses/free-courses-ru.md)
+ [Sinhala / à·ƒà·’à¶‚à·„à¶½](courses/free-courses-si.md)
+ [Spanish / espaÃ±ol / castellano](courses/free-courses-es.md)
+ [Swedish / svenska](courses/free-courses-sv.md)
+ [Tamil / à®¤à®®à®¿à®´à¯](courses/free-courses-ta.md)
+ [Telugu / à°¤à±†à°²à±à°—à±](courses/free-courses-te.md)
+ [Thai / à¸ à¸²à¸©à¸²à¹„à¸—à¸¢](courses/free-courses-th.md)
+ [Turkish / TÃ¼rkÃ§e](courses/free-courses-tr.md)
+ [Ukrainian / Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°](courses/free-courses-uk.md)
+ [Urdu / Ø§Ø±Ø¯Ùˆ](courses/free-courses-ur.md)
+ [Vietnamese / Tiáº¿ng Viá»‡t](courses/free-courses-vi.md)


### Interactive Programming Resources

+ [Chinese / ä¸­æ–‡](more/free-programming-interactive-tutorials-zh.md)
+ [English](more/free-programming-interactive-tutorials-en.md)
+ [German / Deutsch](more/free-programming-interactive-tutorials-de.md)
+ [Japanese / æ—¥æœ¬èª](more/free-programming-interactive-tutorials-ja.md)
+ [Russian / Ğ ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº](more/free-programming-interactive-tutorials-ru.md)


### Problem Sets and Competitive Programming

+ [Problem Sets](more/problem-sets-competitive-programming.md)


### Podcast - Screencast

Free Podcasts and Screencasts:

+ [Arabic / al Arabiya / Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](casts/free-podcasts-screencasts-ar.md)
+ [Burmese / á€™á€¼á€”á€ºá€™á€¬á€˜á€¬á€á€¬](casts/free-podcasts-screencasts-my.md)
+ [Chinese / ä¸­æ–‡](casts/free-podcasts-screencasts-zh.md)
+ [Czech / ÄeÅ¡tina / ÄeskÃ½ jazyk](casts/free-podcasts-screencasts-cs.md)
+ [Dutch / Nederlands](casts/free-podcasts-screencasts-nl.md)
+ [English](casts/free-podcasts-screencasts-en.md)
+ [Finnish / Suomi](casts/free-podcasts-screencasts-fi.md)
+ [French / franÃ§ais](casts/free-podcasts-screencasts-fr.md)
+ [German / Deutsch](casts/free-podcasts-screencasts-de.md)
+ [Hebrew / ×¢×‘×¨×™×ª](casts/free-podcasts-screencasts-he.md)
+ [Indonesian / Bahasa Indonesia](casts/free-podcasts-screencasts-id.md)
+ [Persian / Farsi (Iran) / ÙØ§Ø±Ø³Ù‰](casts/free-podcasts-screencasts-fa_IR.md)
+ [Polish / polski / jÄ™zyk polski / polszczyzna](casts/free-podcasts-screencasts-pl.md)
+ [Portuguese (Brazil)](casts/free-podcasts-screencasts-pt_BR.md)
+ [Portuguese (Portugal)](casts/free-podcasts-screencasts-pt_PT.md)
+ [Russian / Ğ ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº](casts/free-podcasts-screencasts-ru.md)
+ [Sinhala / à·ƒà·’à¶‚à·„à¶½](casts/free-podcasts-screencasts-si.md)
+ [Spanish / espaÃ±ol / castellano](casts/free-podcasts-screencasts-es.md)
+ [Swedish / Svenska](casts/free-podcasts-screencasts-sv.md)
+ [Turkish / TÃ¼rkÃ§e](casts/free-podcasts-screencasts-tr.md)
+ [Ukrainian / Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°](casts/free-podcasts-screencasts-uk.md)


### Programming Playgrounds

Write, compile, and run your code within a browser. Try it out!

+ [Chinese / ä¸­æ–‡](more/free-programming-playgrounds-zh.md)
+ [English](more/free-programming-playgrounds.md)
+ [German / Deutsch](more/free-programming-playgrounds-de.md)

## Translations

Volunteers have translated many of our Contributing, How-to, and Code of Conduct documents into languages covered by our lists.

+ English
  + [Code of Conduct](docs/CODE_OF_CONDUCT.md)
  + [Contributing](docs/CONTRIBUTING.md)
  + [How-to](docs/HOWTO.md)
+ ... *[More languages](docs/README.md#translations)* ...

You might notice that there are [some missing translations here](docs/README.md#translations) - perhaps you would like to help out by [contributing a translation](docs/CONTRIBUTING.md#help-out-by-contributing-a-translation)?


## License

Each file included in this repository is licensed under the [CC BY License](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[WECENG/ticket-purchase]]></title>
            <link>https://github.com/WECENG/ticket-purchase</link>
            <guid>https://github.com/WECENG/ticket-purchase</guid>
            <pubDate>Wed, 24 Sep 2025 00:04:27 GMT</pubDate>
            <description><![CDATA[å¤§éº¦è‡ªåŠ¨æŠ¢ç¥¨ï¼Œæ”¯æŒäººå‘˜ã€åŸå¸‚ã€æ—¥æœŸåœºæ¬¡ã€ä»·æ ¼é€‰æ‹©]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/WECENG/ticket-purchase">WECENG/ticket-purchase</a></h1>
            <p>å¤§éº¦è‡ªåŠ¨æŠ¢ç¥¨ï¼Œæ”¯æŒäººå‘˜ã€åŸå¸‚ã€æ—¥æœŸåœºæ¬¡ã€ä»·æ ¼é€‰æ‹©</p>
            <p>Language: Python</p>
            <p>Stars: 3,128</p>
            <p>Forks: 427</p>
            <p>Stars today: 84 stars today</p>
            <h2>README</h2><pre># å¤§éº¦æŠ¢ç¥¨è„šæœ¬ V1.0
### ç‰¹å¾

- è‡ªåŠ¨æ— å»¶æ—¶æŠ¢ç¥¨
- æ”¯æŒäººå‘˜ã€åŸå¸‚ã€æ—¥æœŸåœºæ¬¡ã€ä»·æ ¼é€‰æ‹©

## åŠŸèƒ½ä»‹ç»
é€šè¿‡seleniumæ‰“å¼€é¡µé¢è¿›è¡Œç™»å½•ï¼Œæ¨¡æ‹Ÿç”¨æˆ·è´­ç¥¨æµç¨‹è‡ªåŠ¨è´­ç¥¨

å…¶æµç¨‹å›¾å¦‚ä¸‹:

&lt;img src=&quot;img/å¤§éº¦æŠ¢ç¥¨æµç¨‹.png&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;

## å‡†å¤‡å·¥ä½œ
### 1. é…ç½®ç¯å¢ƒ

#### 1.1å®‰è£…python3ç¯å¢ƒ

**Windows**

1. è®¿é—®Pythonå®˜æ–¹ç½‘ç«™ï¼šhttps://www.python.org/downloads/windows/
2. ä¸‹è½½æœ€æ–°çš„Python 3.9+ç‰ˆæœ¬çš„å®‰è£…ç¨‹åºã€‚
3. è¿è¡Œå®‰è£…ç¨‹åºã€‚
4. åœ¨å®‰è£…ç¨‹åºä¸­ï¼Œç¡®ä¿å‹¾é€‰ &quot;Add Python X.X to PATH&quot; é€‰é¡¹ï¼Œè¿™å°†è‡ªåŠ¨å°†Pythonæ·»åŠ åˆ°ç³»ç»Ÿç¯å¢ƒå˜é‡ä¸­ï¼Œæ–¹ä¾¿åœ¨å‘½ä»¤è¡Œä¸­ä½¿ç”¨Pythonã€‚
5. å®Œæˆå®‰è£…åï¼Œä½ å¯ä»¥åœ¨å‘½ä»¤æç¤ºç¬¦æˆ–PowerShellä¸­è¾“å…¥ `python3` æ¥å¯åŠ¨Pythonè§£é‡Šå™¨ã€‚

**macOS**

1. ä½ å¯ä»¥ä½¿ç”¨Homebrewæ¥å®‰è£…Python 3ã€‚

   - å®‰è£…Homebrewï¼ˆå¦‚æœæœªå®‰è£…ï¼‰ï¼šæ‰“å¼€ç»ˆç«¯å¹¶è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

     ```shell
     /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;
     ```

   - å®‰è£…Python 3ï¼šè¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥å®‰è£…Python 3ï¼š

     ```shell
     brew install python@3
     ```

#### 1.2 å®‰è£…æ‰€éœ€è¦çš„ç¯å¢ƒ

åœ¨å‘½ä»¤çª—å£è¾“å…¥å¦‚ä¸‹æŒ‡ä»¤

```shell
pip3 install selenium
```

#### 1.3 ä¸‹è½½google chromeæµè§ˆå™¨

ä¸‹è½½åœ°å€: https://www.google.cn/intl/zh-CN/chrome/?brand=YTUH&amp;gclid=Cj0KCQjwj5mpBhDJARIsAOVjBdoV_1sBwdqKGHV3rUU1vJmNKZdy5QNzbRT8F5O0-_jq1WHXurE8a7MaAkWrEALw_wcB&amp;gclsrc=aw.ds

### 2. ä¿®æ”¹é…ç½®æ–‡ä»¶

åœ¨è¿è¡Œç¨‹åºä¹‹å‰ï¼Œéœ€è¦å…ˆä¿®æ”¹`config.json`æ–‡ä»¶ã€‚è¯¥æ–‡ä»¶ç”¨äºæŒ‡å®šç”¨æˆ·éœ€è¦æŠ¢ç¥¨çš„ç›¸å…³ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ¼”å”±ä¼šçš„åœºæ¬¡ã€è§‚æ¼”çš„äººå‘˜ã€åŸå¸‚ã€æ—¥æœŸã€ä»·æ ¼ç­‰ã€‚æ–‡ä»¶ç»“æœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

&lt;img src=&quot;img/config_json.png&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;

#### 2.1 æ–‡ä»¶å†…å®¹è¯´æ˜

- `index_url`ä¸ºå¤§éº¦ç½‘çš„åœ°å€ï¼Œ**æ— éœ€ä¿®æ”¹**
- `login_url`ä¸ºå¤§éº¦ç½‘çš„ç™»å½•åœ°å€ï¼Œ**æ— éœ€ä¿®æ”¹**
- `target_url`ä¸ºç”¨æˆ·éœ€è¦æŠ¢çš„æ¼”å”±ä¼šç¥¨çš„ç›®æ ‡åœ°å€ï¼Œ**å¾…ä¿®æ”¹**
- `users`ä¸ºè§‚æ¼”äººçš„å§“åï¼Œ**è§‚æ¼”äººéœ€è¦ç”¨æˆ·åœ¨æ‰‹æœºå¤§éº¦APPä¸­å…ˆå¡«å†™å¥½ï¼Œç„¶åå†å¡«å…¥è¯¥é…ç½®æ–‡ä»¶ä¸­**ï¼Œ**å¾…ä¿®æ”¹**
- `city`ä¸ºåŸå¸‚ï¼Œ**å¦‚æœç”¨æˆ·éœ€è¦æŠ¢çš„æ¼”å”±ä¼šç¥¨éœ€è¦é€‰æ‹©åŸå¸‚ï¼Œè¯·æŠŠåŸå¸‚å¡«å…¥æ­¤å¤„ã€‚å¦‚æ— éœ€é€‰æ‹©ï¼Œåˆ™ä¸å¡«**
- `date`ä¸ºåœºæ¬¡æ—¥æœŸï¼Œ**å¾…ä¿®æ”¹ï¼Œå¯å¤šé€‰**
- `price`ä¸ºç¥¨æ¡£çš„ä»·æ ¼ï¼Œ**å¾…ä¿®æ”¹ï¼Œå¯å¤šé€‰**
- `if_commit_order`ä¸ºæ˜¯å¦è¦è‡ªåŠ¨æäº¤è®¢å•ï¼Œ**æ”¹æˆ true**
- if_listenä¸ºæ˜¯å¦å›æµç›‘å¬ï¼Œ**æ”¹æˆtrue**



#### 2.2 ç¤ºä¾‹è¯´æ˜

è¿›å…¥å¤§éº¦ç½‘https://www.damai.cn/ï¼Œé€‰æ‹©ä½ éœ€è¦æŠ¢ç¥¨çš„æ¼”å”±ä¼šã€‚å‡è®¾å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

&lt;img src=&quot;img/example.png&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;

æ¥ä¸‹æ¥æŒ‰ç…§ä¸‹å›¾çš„æ ‡æ³¨å¯¹é…ç½®æ–‡ä»¶è¿›è¡Œä¿®æ”¹ï¼š

&lt;img src=&quot;img/example_detail.png&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;

æœ€ç»ˆ`config.json`çš„æ–‡ä»¶å†…å®¹å¦‚ä¸‹ï¼š

```json
{
  &quot;index_url&quot;: &quot;https://www.damai.cn/&quot;,
  &quot;login_url&quot;: &quot;https://passport.damai.cn/login?ru=https%3A%2F%2Fwww.damai.cn%2F&quot;,
  &quot;target_url&quot;: &quot;https://detail.damai.cn/item.htm?spm=a2oeg.home.card_0.ditem_1.591b23e1JQGWHg&amp;id=740680932762&quot;,
  &quot;users&quot;: [
    &quot;åå­—1&quot;,
    &quot;åå­—2&quot;
  ],
  &quot;city&quot;: &quot;å¹¿å·&quot;,
  &quot;date&quot;: &quot;2023-10-28&quot;,
  &quot;price&quot;: &quot;1039&quot;,
  &quot;if_listen&quot;:true,
  &quot;if_commit_order&quot;: true
}
```



### 3.è¿è¡Œç¨‹åº

è¿è¡Œç¨‹åºå¼€å§‹æŠ¢ç¥¨ï¼Œè¿›å…¥å‘½ä»¤çª—å£ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼š

```shell
cd damai
python3 damai.py
```



# å¤§éº¦appæŠ¢ç¥¨

å¤§éº¦appæŠ¢ç¥¨è„šæœ¬éœ€è¦ä¾èµ–appiumï¼Œå› æ­¤éœ€è¦ç°åœ¨å®‰è£…appium server&amp;clientç¯å¢ƒï¼Œæ­¥éª¤å¦‚ä¸‹ï¼š

## appium server

### ä¸‹è½½

- å…ˆå®‰è£…å¥½nodeç¯å¢ƒï¼ˆå…·å¤‡npmï¼‰nodeç‰ˆæœ¬å·18.0.0

- å…ˆä¸‹è½½å¹¶å®‰è£…å¥½android sdkï¼Œå¹¶é…ç½®ç¯å¢ƒå˜é‡ï¼ˆappium serverè¿è¡Œéœ€ä¾èµ–android sdk)

- ä¸‹è½½appium

  ```shell
  npm install -g appium
  ```

- æŸ¥çœ‹appiumæ˜¯å¦å®‰è£…æˆåŠŸ

  ```shell
  appium -v
  ```

- ä¸‹è½½UiAutomator2é©±åŠ¨

  ```shell
  npm install appium-uiautomator2-driver
  ```

â€‹		å¯èƒ½ä¼šé‡åˆ°å¦‚ä¸‹é”™è¯¯ï¼š

```tex
âœ  xcode git:(master) âœ— npm install appium-uiautomator2-driver

npm ERR! code 1
npm ERR! path /Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver/node_modules/appium-chromedriver
npm ERR! command failed
npm ERR! command sh -c node install-npm.js
npm ERR! [11:57:54] Error installing Chromedriver: Request failed with status code 404
npm ERR! [11:57:54] AxiosError: Request failed with status code 404
npm ERR!     at settle (/Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver/node_modules/axios/lib/core/settle.js:19:12)
npm ERR!     at IncomingMessage.handleStreamEnd (/Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver/node_modules/axios/lib/adapters/http.js:572:11)
npm ERR!     at IncomingMessage.emit (node:events:539:35)
npm ERR!     at endReadableNT (node:internal/streams/readable:1344:12)
npm ERR!     at processTicksAndRejections (node:internal/process/task_queues:82:21)
npm ERR! [11:57:54] Downloading Chromedriver can be skipped by setting the&#039;APPIUM_SKIP_CHROMEDRIVER_INSTALL&#039; environment variable.

npm ERR! A complete log of this run can be found in:
npm ERR!     /Users/chenweicheng/.npm/_logs/2023-10-26T03_57_35_950Z-debug-0.log
```

â€‹		è§£å†³åŠæ³•ï¼ˆæ·»åŠ ç¯å¢ƒå˜é‡ï¼Œé”™è¯¯åŸå› æ˜¯æ²¡æœ‰æ‰¾åˆ°chromeæµè§ˆå™¨é©±åŠ¨ï¼Œå¿½ç•¥å³å¯ï¼‰

```shell
export APPIUM_SKIP_CHROMEDRIVER_INSTALL=true
```

### å¯åŠ¨

å¯åŠ¨appium serverå¹¶ä½¿ç”¨uiautomator2é©±åŠ¨

```shell
appium --use-plugins uiautomator2
```

å¯åŠ¨æˆåŠŸå°†å‡ºç°å¦‚ä¸‹ä¿¡æ¯ï¼š

```
[Appium] Welcome to Appium v2.2.1 (REV 2176894a5be5da17a362bf3f20678641a78f4b69)
[Appium] Non-default server args:
[Appium] {
[Appium]   usePlugins: [
[Appium]     &#039;uiautomator2&#039;
[Appium]   ]
[Appium] }
[Appium] Attempting to load driver uiautomator2...
[Appium] Requiring driver at /Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver
[Appium] Appium REST http interface listener started on http://0.0.0.0:4723
[Appium] You can provide the following URLs in your client code to connect to this server:
[Appium] 	http://127.0.0.1:4723/ (only accessible from the same host)
[Appium] 	http://172.31.102.45:4723/
[Appium] 	http://198.18.0.1:4723/
[Appium] Available drivers:
[Appium]   - uiautomator2@2.32.3 (automationName &#039;UiAutomator2&#039;)
[Appium] No plugins have been installed. Use the &quot;appium plugin&quot; command to install the one(s) you want to use.
```

å…¶ä¸­`[Appium] 	http://127.0.0.1:4723/ (only accessible from the same host)
[Appium] 	http://172.31.102.45:4723/
[Appium] 	http://198.18.0.1:4723/`ä¸ºappium serverè¿æ¥åœ°å€



## appium client

- å…ˆä¸‹è½½å¹¶å®‰è£…å¥½python3å’Œpip3

- å®‰è£…

  ```shell
  pip3 install appium-python-client
  ```

- åœ¨ä»£ç ä¸­å¼•å…¥å¹¶ä½¿ç”¨appium

  ```python
  from appium import webdriver
  from appium.options.common.base import AppiumOptions
  
  device_app_info = AppiumOptions()
  device_app_info.set_capability(&#039;platformName&#039;, &#039;Android&#039;)
  device_app_info.set_capability(&#039;platformVersion&#039;, &#039;10&#039;)
  device_app_info.set_capability(&#039;deviceName&#039;, &#039;YourDeviceName&#039;)
  device_app_info.set_capability(&#039;appPackage&#039;, &#039;cn.damai&#039;)
  device_app_info.set_capability(&#039;appActivity&#039;, &#039;.launcher.splash.SplashMainActivity&#039;)
  device_app_info.set_capability(&#039;unicodeKeyboard&#039;, True)
  device_app_info.set_capability(&#039;resetKeyboard&#039;, True)
  device_app_info.set_capability(&#039;noReset&#039;, True)
  device_app_info.set_capability(&#039;newCommandTimeout&#039;, 6000)
  device_app_info.set_capability(&#039;automationName&#039;, &#039;UiAutomator2&#039;)
  
  # è¿æ¥appium serverï¼Œserveråœ°å€æŸ¥çœ‹appiumå¯åŠ¨ä¿¡æ¯
  driver = webdriver.Remote(&#039;http://127.0.0.1:4723&#039;, options=device_app_info)
  
  ```

- å¯åŠ¨è„šæœ¬ç¨‹åº

  ```shell
  cd damai_appium
  python3 damai_appium.py
  ```

  

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[HKUDS/AI-Researcher]]></title>
            <link>https://github.com/HKUDS/AI-Researcher</link>
            <guid>https://github.com/HKUDS/AI-Researcher</guid>
            <pubDate>Wed, 24 Sep 2025 00:04:26 GMT</pubDate>
            <description><![CDATA[[NeurIPS2025] "AI-Researcher: Autonomous Scientific Innovation" -- A production-ready version: https://novix.science/chat]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/HKUDS/AI-Researcher">HKUDS/AI-Researcher</a></h1>
            <p>[NeurIPS2025] "AI-Researcher: Autonomous Scientific Innovation" -- A production-ready version: https://novix.science/chat</p>
            <p>Language: Python</p>
            <p>Stars: 2,877</p>
            <p>Forks: 335</p>
            <p>Stars today: 41 stars today</p>
            <h2>README</h2><pre>&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./assets/ai-researcher.png&quot; alt=&quot;Logo&quot; width=&quot;400&quot;&gt;
  &lt;h1 align=&quot;center&quot;&gt;&quot;AI-Researcher: Autonomous Scientific Innovation&quot;
 &lt;/h1&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/14638&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14638&quot; alt=&quot;HKUDS%2FAI-Researcher | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://autoresearcher.github.io&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&amp;color=FFE165&amp;logo=homepage&amp;logoColor=white&quot; alt=&quot;Project Page&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://join.slack.com/t/ai-researchergroup/shared_invite/zt-30y5a070k-C0ajQt1zmVczFnfGkIicvA&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Slack-Join%20Us-red?logo=slack&amp;logoColor=white&amp;style=for-the-badge&quot; alt=&quot;Join our Slack community&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/zBNYTk5q2g&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-Join%20Us-purple?logo=discord&amp;logoColor=white&amp;style=for-the-badge&quot; alt=&quot;Join our Discord community&quot;&gt;&lt;/a&gt;
  &lt;br/&gt;
  &lt;a href=&quot;https://autoresearcher.github.io/docs&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Documentation-000?logo=googledocs&amp;logoColor=FFE165&amp;style=for-the-badge&quot; alt=&quot;Check out the documentation&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://arxiv.org/abs/2505.18705&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Paper%20on%20Arxiv-000?logoColor=FFE165&amp;logo=arxiv&amp;style=for-the-badge&quot; alt=&quot;Paper&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://autoresearcher.github.io/leaderboard&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/DATASETS-000?logoColor=FFE165&amp;logo=huggingface&amp;style=for-the-badge&quot; alt=&quot;Benchmark&quot;&gt;&lt;/a&gt;
  &lt;hr&gt;
&lt;/div&gt;

Welcome to **AI-Researcher**ğŸ¤— AI-Researcher introduces a revolutionary breakthrough in **Automated Scientific Discovery**ğŸ”¬, presenting a new system that fundamentally **Reshapes the Traditional Research Paradigm**. This state-of-the-art platform empowers researchers with:

 - ğŸ¯ **Full Autonomy**: Complete end-to-end research automation
 - ğŸ”„ **Seamless Orchestration**: From concept to publication
 - ğŸ§  **Advanced AI Integration**: Powered by cutting-edge AI agents
 - ğŸš€ **Research Acceleration**: Streamlined scientific innovation

--------------------------------------------------------------------------------

âœ¨ The AI-Researcher system accepts user input queries at two distinct levels âœ¨

**Level 1: Detailed Idea Description**
&lt;br/&gt; At this level, users provide comprehensive descriptions of their specific research ideas. The system processes these detailed inputs to develop implementation strategies based on the user&#039;s explicit requirements.

**Level 2: Reference-Based Ideation**
&lt;br/&gt; This simpler level involves users submitting reference papers without a specific idea in mind. The user query typically follows the format: &quot;I have some reference papers, please come up with an innovative idea and implement it with these papers.&quot; The system then analyzes the provided references to generate and develop novel research concepts.

--------------------------------------------------------------------------------

ğŸŒŸ**Core Capabilities &amp; Integration**&lt;/br&gt;
**AI-Researcher** delivers a **Comprehensive Research Ecosystem** through seamless integration of critical components:

ğŸš€**Primary Research Functions**
 - ğŸ“š **Literature Review**: Conducts comprehensive analysis and synthesis of existing research.
 - ğŸ“Š **Idea Generation**: Systematically gathers, organizes, and formulates novel research directions.
 - ğŸ§ª **Algorithm Design and Implementation**: Develops methodologies and transforms ideas into functional implementations.
 - ğŸ’» **Algorithm Validation and Refinement**: Automates testing, performance evaluation, and iterative optimization.
 - ğŸ“ˆ **Result Analysis**: Delivers advanced interpretation of experimental data and insights.
 - âœï¸ **Manuscript Creation**: Automatically generates polished, full-length academic papers.

&lt;div align=&quot;center&quot;&gt;
  &lt;!-- &lt;img src=&quot;./assets/AI-Researchernew-intro.pdf&quot; alt=&quot;Logo&quot; width=&quot;100%&quot;&gt; --&gt;
  &lt;figure&gt;
    &lt;img src=&quot;./assets/AI-Researcher-Framework.png&quot; alt=&quot;Logo&quot; style=&quot;max-width: 100%; height: auto;&quot;&gt;
    &lt;br&gt;
    &lt;figcaption&gt;&lt;em&gt;Quick Overview of AI-Researcher.&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;span id=&#039;news&#039;/&gt;

## ğŸ”¥ News

&lt;div class=&quot;scrollable&quot;&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;[2025. 09]&lt;/strong&gt;: &amp;nbsp; ğŸ¯ğŸ¯ğŸ“¢ğŸ“¢ Exciting News! We are thrilled to announce that our ğŸŒŸAI-ResearcherğŸŒŸ has been accepted as a Spotlight paper at NeurIPS 2025! ğŸ‰ğŸ‰ Thanks to all the team members ğŸ¤— &lt;/b&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;[2025. 05]&lt;/strong&gt;: &amp;nbsp;ğŸ‰ğŸ‰ &lt;b&gt;Major Release! AI-Researcher Comprehensive Upgrade!&lt;/b&gt; ğŸš€
        &lt;br&gt;We are excited to announce a significant milestone for AI-Researcher:
        &lt;ul&gt;
          &lt;li&gt;ğŸ“„ &lt;b&gt;&lt;a href=&quot;https://arxiv.org/abs/2505.18705&quot;&gt;Academic Paper Release&lt;/a&gt;&lt;/b&gt;: Detailed exposition of our innovative methods and experimental results&lt;/li&gt;
          &lt;li&gt;ğŸ“Š &lt;b&gt;&lt;a href=&quot;https://autoresearcher.github.io/leaderboard&quot;&gt;Benchmark Suite&lt;/a&gt;&lt;/b&gt;: Comprehensive evaluation framework and datasets&lt;/li&gt;
          &lt;li&gt;ğŸ–¥ï¸ &lt;b&gt;Web GUI Interface&lt;/b&gt;: User-friendly graphical interface making research more convenient&lt;/li&gt;
        &lt;/ul&gt;
        &lt;b&gt;ğŸ¤ Join Us!&lt;/b&gt; We welcome researchers, developers, and AI enthusiasts to contribute together and advance AI research development. Whether it&#039;s code contributions, bug reports, feature suggestions, or documentation improvements, every contribution is valuable!
        &lt;br&gt;ğŸ’¡ &lt;i&gt;Let&#039;s build a smarter AI research assistant together!&lt;/i&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;[2025, Mar 04]&lt;/strong&gt;: &amp;nbsp;ğŸ‰ğŸ‰We&#039;ve launched &lt;b&gt;AI-Researcher!&lt;/b&gt;, The release includes the complete framework, datasets, benchmark construction pipeline, and much more. Stay tunedâ€”there&#039;s plenty more to come! ğŸš€&lt;/li&gt;
    &lt;/ul&gt;
&lt;/div&gt;

&lt;span id=&#039;table-of-contents&#039;/&gt;

## ğŸ“‘ Table of Contents


* &lt;a href=&#039;#news&#039;&gt;ğŸ”¥ News&lt;/a&gt;
* &lt;a href=&#039;#quick-start&#039;&gt;âš¡ Quick Start&lt;/a&gt;
  * &lt;a href=&#039;#installation&#039;&gt;Installation&lt;/a&gt;
  * &lt;a href=&#039;#api-keys-setup&#039;&gt;API Keys Setup&lt;/a&gt;
* &lt;a href=&#039;#examples&#039;&gt;â¬‡ï¸ Examples&lt;/a&gt;
* &lt;a href=&#039;#how-it-works&#039;&gt;âœ¨ How AI-Researcher works&lt;/a&gt;
* &lt;a href=&#039;#how-to-use&#039;&gt;ğŸ” How to use AI-Researcher&lt;/a&gt;
* &lt;a href=&#039;#documentation&#039;&gt;ğŸ“– Documentation&lt;/a&gt;
* &lt;a href=&#039;#community&#039;&gt;ğŸ¤ Join the Community&lt;/a&gt;
* &lt;a href=&#039;#acknowledgements&#039;&gt;ğŸ™ Acknowledgements&lt;/a&gt;
* &lt;a href=&#039;#cite&#039;&gt;ğŸŒŸ Cite&lt;/a&gt;


&lt;span id=&#039;quick-start&#039;/&gt;

## âš¡ Quick Start

&lt;span id=&#039;installation&#039;/&gt;

### Installation

#### AI Installation

1. Using [uv](https://docs.astral.sh/uv/)

&gt; We recommend to use [uv](https://docs.astral.sh/uv/) to manage packages in our project (Much more faster than conda)

```bash
# install uv
curl -LsSf https://astral.sh/uv/install.sh | sh
source ~/.bashrc

# clone the project
git clone https://github.com/HKUDS/AI-Researcher.git
cd AI-Researcher

# install and activate enviroment
uv venv --python 3.11
source ./.venv/bin/activate
uv pip install -e .
playwright install
```

#### Docker Installation

To set up the agent-interactive environment, we use Docker for containerization. Please ensure you have [Docker](https://www.docker.com/) installed on your system before proceeding. For running the research agent, we utilize the Docker image &#039;tjbtech1/airesearcher:v1t&#039;. You can pull this image by executing the following command:

```bash
docker pull tjbtech1/airesearcher:v1
```

or you can build the docker image from our provided [Dockerfile](./docker/Dockerfile). 

```bash
cd ./docker &amp;&amp; docker build -t tjbtech1/airesearcher:v1 .
```

&lt;span id=&#039;api-keys-setup&#039;/&gt;

### API Keys Setup

Create an environment variable file based on the provided &#039;.env.template&#039; file. In this file, you should set the configuration including api key, instance id of the test case. 

```bash

# ================ container configuration ================
# workplace of the research agent
DOCKER_WORKPLACE_NAME=workplace_paper
# base image of the research agent
BASE_IMAGES=tjbtech1/airesearcher:v1
# completion model name, configuration details see: https://docs.litellm.ai/docs/
COMPLETION_MODEL=openrouter/google/gemini-2.5-pro-preview-05-20
# cheep model name, configuration details see: https://docs.litellm.ai/docs/
CHEEP_MODEL=openrouter/google/gemini-2.5-pro-preview-05-20
# specific gpu of the research agent, can be: 
# &#039;&quot;device=0&quot;&#039; using the first gpu
# &#039;&quot;device=0,1&quot;&#039; using the first and second gpu
# &#039;&quot;all&quot;&#039; using all gpus
# None for no gpu
GPUS=&#039;&quot;device=0&quot;&#039;
# name of the container
CONTAINER_NAME=paper_eval
# name of the workplace
WORKPLACE_NAME=workplace
# path of the cache
CACHE_PATH=cache
# port of the research agent
PORT=7020
# platform of the research agent
PLATFORM=linux/amd64

# ================ llm configuration ================
# github ai token of the research agent
GITHUB_AI_TOKEN=your_github_ai_token
# openrouter api key of the research agent
OPENROUTER_API_KEY=your_openrouter_api_key
# openrouter api base url of the research agent
OPENROUTER_API_BASE=https://openrouter.ai/api/v1

# ================ task configuration ================
# category of the research agent, based on: ./benchmark/final. Can be: 
# diffu_flow
# gnn
# reasoning
# recommendation
# vq
# example: ./benchmark/final/vq
CATEGORY=vq
# instance id of the research agent, example: ./benchmark/final/vq/one_layer_vq.json
INSTANCE_ID=one_layer_vq
# task level of the research agent, can be: 
# task1
# task2
TASK_LEVEL=task1
# maximum iteration times of the research agent
MAX_ITER_TIMES=0
```

### ğŸ”¥ Web GUI

We add a webgui based on gradio. Just run the following command: 

```bash
python web_ai_researcher.py
```

![image-20250606135137558](./assets/webgui/image-20250606135137558.png)

You can configure the environment variables in the following tab: 

![image-20250606135325373](./assets/webgui/image-20250606135325373.png)

Select the following example to run our AI-Researcher: 

&lt;img src=&quot;./assets/webgui/image-20250606135507970.png&quot; alt=&quot;image-20250606135507970&quot; style=&quot;zoom:67%;&quot; /&gt;



&lt;span id=&#039;examples&#039;/&gt;

## â¬‡ï¸ Examples

&gt; âš ï¸ **ALERT**: The GIFs below are large files and may **take some time to load**. **Please be patient while they render completely**.

### Example 1 (Vector Quantized)

&lt;details&gt;
  &lt;summary&gt;&lt;b&gt;Input:Prompt&lt;/b&gt;&lt;br&gt;&lt;p&gt;I have some reference papers, please implement the following idea with these papers:&lt;/p&gt;&lt;ol&gt;
    &lt;li&gt;The proposed model designed in this paper is designed to improve the performance of Vector Quantized Variational AutoEncoders (VQ-VAEs) by addressing issues with gradient propagation through the non-differentiable vector quantization layer.&lt;/li&gt;...&lt;/ol&gt;&lt;/summary&gt;
&lt;div&gt;
  &lt;!-- &lt;p&gt;I have some reference papers, please implement the following idea with these papers:&lt;/p&gt; --&gt;
  &lt;ol start=&quot;2&quot;&gt;
    &lt;li&gt;The core methodologies utilized include:
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;Rotation and Rescaling Transformation&lt;/strong&gt;: A linear transformation that alters the encoder output to align it with the nearest codebook vector without changing the forward pass output.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Gradient Propagation Method&lt;/strong&gt;: The proposed model ensures that gradients flow from the decoder to the encoder while preserving the angle between the gradient and codebook vector.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Codebook Management&lt;/strong&gt;: Utilizes the connection between the encoder output and the corresponding codebook vectors to mitigate codebook collapse and improve utilization.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;The primary functions of these components are:
      &lt;ul&gt;
        &lt;li&gt;The rotation and rescaling transformation modifies how the encoder output is quantized and how information is retained during backpropagation, enabling gradients to reflect the true positioning of the encoder output relative to the codebook vectors.&lt;/li&gt;
        &lt;li&gt;The gradient propagation method redefines how gradients are transported back to the encoder, allowing for an enhanced and nuanced movement through the quantization layer, which leads to a better performance during training.&lt;/li&gt;
        &lt;li&gt;Codebook management practices help in maintaining a diverse set of codebook vectors throughout training, avoiding scenarios where multiple vectors become redundant or unused.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Implementation details for each component:
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;Key Parameters&lt;/strong&gt;: 
          &lt;ul&gt;
            &lt;li&gt;Codebook size should be configured based on the complexity of the dataset (e.g., 1024 or 8192).&lt;/li&gt;
            &lt;li&gt;Commitment loss coefficient (Î²) is typically set within [0.25, 2].&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Input/Output Specifications&lt;/strong&gt;: 
          &lt;ul&gt;
            &lt;li&gt;Input to the encoder is a continuous high-dimensional vector, while the output is a corresponding quantized vector from the codebook.&lt;/li&gt;
            &lt;li&gt;The output for reconstruction is generated using the decoder applied to the transformed codebook vectors.&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Important Constraints&lt;/strong&gt;: 
          &lt;ul&gt;
            &lt;li&gt;Ensure that the codebook is updated correctly with an exponential moving average procedure, and treat both rotation and rescaling during the forward pass as constants with respect to the gradient.&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Step-by-Step Integration of Components:
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;Step 1&lt;/strong&gt;: Input the data vector into the encoder to obtain the continuous representation.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Step 2&lt;/strong&gt;: Identify the nearest codebook vector to the encoder output.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Step 3&lt;/strong&gt;: Compute the rotation matrix that aligns the encoder output to the codebook vector.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Step 4&lt;/strong&gt;: Apply the rotation and rescaling transformation to obtain the modified output for the decoder (i.e., `Ëœ q`).&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Step 5&lt;/strong&gt;: Feed `Ëœ q` into the decoder to produce the reconstructed output.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Step 6&lt;/strong&gt;: Compute the loss using the reconstruction and apply backpropagation.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Step 7&lt;/strong&gt;: During backpropagation, modify the gradient transfer process to maintain the angle using the proposed model, replacing traditional shortcuts in gradient computation.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Critical implementation details affecting performance:
      &lt;ul&gt;
        &lt;li&gt;The choice of rotation matrix calculation should ensure computational efficiencyâ€”using Householder transformations to minimize resource demands.&lt;/li&gt;
        &lt;li&gt;The deployment of the stop-gradient technique effectively turns off the back-propagation through the quantization layer, which is essential to reflect the intended change without inducing undesired noise in the gradient updates.&lt;/li&gt;
        &lt;li&gt;Monitor the codebook usage regularly during training to detect any potential collapse early and adjust the training dynamics (e.g., learning rate) accordingly to maintain effective utilization throughout the training period.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
   &lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;b&gt;Input:Reference Papers&lt;/b&gt;&lt;ol&gt;
    &lt;li&gt;&lt;strong&gt;Neural discrete representation learning&lt;/strong&gt;&lt;/li&gt;...&lt;/ol&gt;&lt;/summary&gt;
&lt;div&gt;
  &lt;ol start=&quot;2&quot;&gt;
    &lt;!-- &lt;li&gt;&lt;strong&gt;Neural discrete representation learning&lt;/strong&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;strong&gt;Straightening out the straight-through estimator: Overcoming optimization challenges in vector quantized networks&lt;/strong&gt;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Estimating or propagating gradients through stochastic neurons for conditional computation&lt;/strong&gt;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;High-resolution image synthesis with latent diffusion models&lt;/strong&gt;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Finite scalar quantization: Vq-vae made simple&lt;/strong&gt;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Elements of information theory&lt;/strong&gt;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Vector-quantized image modeling with improved vqgan&lt;/strong&gt;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Uvim: A unified modeling approach for vision with learned guiding codes&lt;/strong&gt;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Auto-encoding variational bayes&lt;/strong&gt;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Categorical reparameterization with gumbel-softmax&lt;/strong&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;table&gt;
&lt;tr align=&quot;center&quot;&gt;
    &lt;td width=&quot;50%&quot;&gt;
        &lt;a href=&quot;./examples/rotation_vq/paper.pdf&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;./examples/rotation_vq/paper.gif&quot; alt=&quot;PDF Document&quot; width=&quot;100%&quot;/&gt;
    &lt;/a&gt;
    &lt;br&gt;
    &lt;em&gt;Self-Organized Paper (fully-generated by AI-Researcher, click to view).&lt;/em&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot;&gt;
        &lt;a href=&quot;./examples/rotation_vq/project&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;./examples/rotation_vq/scrolling_code.gif&quot; alt=&quot;profiles&quot; width=&quot;100%&quot;/&gt;&lt;/a&gt;
        &lt;br&gt;
        &lt;em&gt;Self-Organized Workplace, &lt;b&gt;take time to load&lt;/b&gt; (fully-generated by AI-Researcher, click to view).&lt;/em&gt;
    &lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;



### Example 2 (Category: Vector Quantized)

&lt;details&gt;
  &lt;summary&gt;&lt;b&gt;Input:Prompt&lt;/b&gt;&lt;br&gt;&lt;p&gt;I have some reference papers, please implement the following idea with these papers:&lt;/p&gt;&lt;ol&gt;
    &lt;li&gt;The proposed model focuses on discrete representation learning for tasks such as image generation, depth estimation, colorization, and segmentation using the proposed approach integrated into architectures like autoregressive transformers.&lt;/li&gt;...&lt;/ol&gt;&lt;/summary&gt;
&lt;div&gt;
  &lt;!-- &lt;p&gt;I have some reference papers, please implement the following idea with these papers:&lt;/p&gt; --&gt;
  &lt;ol start=&quot;2&quot;&gt;
    &lt;li&gt;Core Techniques:
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;Simplified Quantization&lt;/strong&gt;: Use a simplified quantization approach utilizing scalar quantization instead of VQ.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Dimensionality Projection&lt;/strong&gt;: Define a function to project the encoder output to a manageable dimensionality (typically between 3 to 10).&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Gradient Propagation&lt;/strong&gt;: Implement the Straight-Through Estimator (STE) for gradient propagation through the quantization operation.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Technical Components:
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;Bounding Function&lt;/strong&gt;: This compresses data dimensionality and confines values to a desired range. Use a function like \(f(z) = \left\lfloor \frac{L}{2} \right\rfloor \tanh(z)\) to project the data, where \(L\) is the number of quantization levels.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Quantization process&lt;/strong&gt;: Round each bounded dimension to its nearest integer to yield the quantized output.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Loss function&lt;/strong&gt;: Operate under a reconstruction loss paradigm typical in VAEs to optimize the proposed model parameters.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Implementation Details:
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;Key Parameters&lt;/strong&gt;: 
          &lt;ul&gt;
            &lt;li&gt;Number of dimensions \(d\) and levels \(L\) per dimension should be defined based on the codebook size you aim to replicate (e.g., set \(L_i \geq 5\) for all \(i\)).&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Input/Output Specifications&lt;/strong&gt;: 
          &lt;ul&gt;
            &lt;li&gt;The input to the bounding function will be the output from the final encoder layer; the output after quantization will be in the format \(\hat{z}\), with shape matching the original \(z\).&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Constraints&lt;/strong&gt;: 
          &lt;ul&gt;
            &lt;li&gt;Ensure all inputs are preprocessed adequately to be within the functioning range of the bounding function.&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Step-by-Step Integration:
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;Step 1&lt;/strong&gt;: Train a standard VAE model and obtain its encoder output \(z\).&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Step 2&lt;/strong&gt;: Apply the bounding function \(f\) on \(z\) to limit the output dimensions to usable values.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Step 3&lt;/strong&gt;: Quantize the resultant bounded \(z\) using the rounding procedure to generate \( \hat{z} \).&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Step 4&lt;/strong&gt;: Use the original \(z\) and \(\hat{z}\) in conjunctio

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Kludex/uvicorn]]></title>
            <link>https://github.com/Kludex/uvicorn</link>
            <guid>https://github.com/Kludex/uvicorn</guid>
            <pubDate>Wed, 24 Sep 2025 00:04:25 GMT</pubDate>
            <description><![CDATA[An ASGI web server, for Python. ğŸ¦„]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Kludex/uvicorn">Kludex/uvicorn</a></h1>
            <p>An ASGI web server, for Python. ğŸ¦„</p>
            <p>Language: Python</p>
            <p>Stars: 9,734</p>
            <p>Forks: 850</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;320&quot; height=&quot;320&quot; src=&quot;https://raw.githubusercontent.com/tomchristie/uvicorn/main/docs/uvicorn.png&quot; alt=&#039;uvicorn&#039;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;em&gt;An ASGI web server, for Python.&lt;/em&gt;
&lt;/p&gt;

---

[![Build Status](https://github.com/Kludex/uvicorn/workflows/Test%20Suite/badge.svg)](https://github.com/Kludex/uvicorn/actions)
[![Package version](https://badge.fury.io/py/uvicorn.svg)](https://pypi.python.org/pypi/uvicorn)
[![Supported Python Version](https://img.shields.io/pypi/pyversions/uvicorn.svg?color=%2334D058)](https://pypi.org/project/uvicorn)

**Documentation**: [https://uvicorn.dev](https://uvicorn.dev)
**Source Code**: [https://www.github.com/Kludex/uvicorn](https://www.github.com/Kludex/uvicorn)

---

Uvicorn is an ASGI web server implementation for Python.

Until recently Python has lacked a minimal low-level server/application interface for
async frameworks. The [ASGI specification][asgi] fills this gap, and means we&#039;re now able to
start building a common set of tooling usable across all async frameworks.

Uvicorn supports HTTP/1.1 and WebSockets.

## Quickstart

Install using `pip`:

```shell
$ pip install uvicorn
```

This will install uvicorn with minimal (pure Python) dependencies.

```shell
$ pip install &#039;uvicorn[standard]&#039;
```

This will install uvicorn with &quot;Cython-based&quot; dependencies (where possible) and other &quot;optional extras&quot;.

In this context, &quot;Cython-based&quot; means the following:

- the event loop `uvloop` will be installed and used if possible.
- the http protocol will be handled by `httptools` if possible.

Moreover, &quot;optional extras&quot; means that:

- the websocket protocol will be handled by `websockets` (should you want to use `wsproto` you&#039;d need to install it manually) if possible.
- the `--reload` flag in development mode will use `watchfiles`.
- windows users will have `colorama` installed for the colored logs.
- `python-dotenv` will be installed should you want to use the `--env-file` option.
- `PyYAML` will be installed to allow you to provide a `.yaml` file to `--log-config`, if desired.

Create an application, in `example.py`:

```python
async def app(scope, receive, send):
    assert scope[&#039;type&#039;] == &#039;http&#039;

    await send({
        &#039;type&#039;: &#039;http.response.start&#039;,
        &#039;status&#039;: 200,
        &#039;headers&#039;: [
            (b&#039;content-type&#039;, b&#039;text/plain&#039;),
        ],
    })
    await send({
        &#039;type&#039;: &#039;http.response.body&#039;,
        &#039;body&#039;: b&#039;Hello, world!&#039;,
    })
```

Run the server:

```shell
$ uvicorn example:app
```

---

## Why ASGI?

Most well established Python Web frameworks started out as WSGI-based frameworks.

WSGI applications are a single, synchronous callable that takes a request and returns a response.
This doesnâ€™t allow for long-lived connections, like you get with long-poll HTTP or WebSocket connections,
which WSGI doesn&#039;t support well.

Having an async concurrency model also allows for options such as lightweight background tasks,
and can be less of a limiting factor for endpoints that have long periods being blocked on network
I/O such as dealing with slow HTTP requests.

---

## Alternative ASGI servers

A strength of the ASGI protocol is that it decouples the server implementation
from the application framework. This allows for an ecosystem of interoperating
webservers and application frameworks.

### Daphne

The first ASGI server implementation, originally developed to power Django Channels, is [the Daphne webserver][daphne].

It is run widely in production, and supports HTTP/1.1, HTTP/2, and WebSockets.

Any of the example applications given here can equally well be run using `daphne` instead.

```
$ pip install daphne
$ daphne app:App
```

### Hypercorn

[Hypercorn][hypercorn] was initially part of the Quart web framework, before
being separated out into a standalone ASGI server.

Hypercorn supports HTTP/1.1, HTTP/2, and WebSockets.

It also supports [the excellent `trio` async framework][trio], as an alternative to `asyncio`.

```
$ pip install hypercorn
$ hypercorn app:App
```

### Mangum

[Mangum][mangum] is an adapter for using ASGI applications with AWS Lambda &amp; API Gateway.

### Granian

[Granian][granian] is an ASGI compatible Rust HTTP server which supports HTTP/2, TLS and WebSockets.

---

&lt;p align=&quot;center&quot;&gt;&lt;i&gt;Uvicorn is &lt;a href=&quot;https://github.com/Kludex/uvicorn/blob/main/LICENSE.md&quot;&gt;BSD licensed&lt;/a&gt; code.&lt;br/&gt;Designed &amp; crafted with care.&lt;/i&gt;&lt;br/&gt;&amp;mdash; ğŸ¦„  &amp;mdash;&lt;/p&gt;

[asgi]: https://asgi.readthedocs.io/en/latest/
[daphne]: https://github.com/django/daphne
[hypercorn]: https://github.com/pgjones/hypercorn
[trio]: https://trio.readthedocs.io
[mangum]: https://github.com/jordaneremieff/mangum
[granian]: https://github.com/emmett-framework/granian
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[ytdl-org/youtube-dl]]></title>
            <link>https://github.com/ytdl-org/youtube-dl</link>
            <guid>https://github.com/ytdl-org/youtube-dl</guid>
            <pubDate>Wed, 24 Sep 2025 00:04:24 GMT</pubDate>
            <description><![CDATA[Command-line program to download videos from YouTube.com and other video sites]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ytdl-org/youtube-dl">ytdl-org/youtube-dl</a></h1>
            <p>Command-line program to download videos from YouTube.com and other video sites</p>
            <p>Language: Python</p>
            <p>Stars: 137,951</p>
            <p>Forks: 10,492</p>
            <p>Stars today: 274 stars today</p>
            <h2>README</h2><pre>[![Build Status](https://github.com/ytdl-org/youtube-dl/workflows/CI/badge.svg)](https://github.com/ytdl-org/youtube-dl/actions?query=workflow%3ACI)


youtube-dl - download videos from youtube.com or other video platforms

- [INSTALLATION](#installation)
- [DESCRIPTION](#description)
- [OPTIONS](#options)
- [CONFIGURATION](#configuration)
- [OUTPUT TEMPLATE](#output-template)
- [FORMAT SELECTION](#format-selection)
- [VIDEO SELECTION](#video-selection)
- [FAQ](#faq)
- [DEVELOPER INSTRUCTIONS](#developer-instructions)
- [EMBEDDING YOUTUBE-DL](#embedding-youtube-dl)
- [BUGS](#bugs)
- [COPYRIGHT](#copyright)

# INSTALLATION

To install it right away for all UNIX users (Linux, macOS, etc.), type:

    sudo curl -L https://yt-dl.org/downloads/latest/youtube-dl -o /usr/local/bin/youtube-dl
    sudo chmod a+rx /usr/local/bin/youtube-dl

If you do not have curl, you can alternatively use a recent wget:

    sudo wget https://yt-dl.org/downloads/latest/youtube-dl -O /usr/local/bin/youtube-dl
    sudo chmod a+rx /usr/local/bin/youtube-dl

Windows users can [download an .exe file](https://yt-dl.org/latest/youtube-dl.exe) and place it in any location on their [PATH](https://en.wikipedia.org/wiki/PATH_%28variable%29) except for `%SYSTEMROOT%\System32` (e.g. **do not** put in `C:\Windows\System32`).

You can also use pip:

    sudo -H pip install --upgrade youtube-dl

This command will update youtube-dl if you have already installed it. See the [pypi page](https://pypi.python.org/pypi/youtube_dl) for more information.

macOS users can install youtube-dl with [Homebrew](https://brew.sh/):

    brew install youtube-dl

Or with [MacPorts](https://www.macports.org/):

    sudo port install youtube-dl

Alternatively, refer to the [developer instructions](#developer-instructions) for how to check out and work with the git repository. For further options, including PGP signatures, see the [youtube-dl Download Page](https://ytdl-org.github.io/youtube-dl/download.html).

# DESCRIPTION
**youtube-dl** is a command-line program to download videos from YouTube.com and a few more sites. It requires the Python interpreter, version 2.6, 2.7, or 3.2+, and it is not platform specific. It should work on your Unix box, on Windows or on macOS. It is released to the public domain, which means you can modify it, redistribute it or use it however you like.

    youtube-dl [OPTIONS] URL [URL...]

# OPTIONS
    -h, --help                           Print this help text and exit
    --version                            Print program version and exit
    -U, --update                         Update this program to latest version.
                                         Make sure that you have sufficient
                                         permissions (run with sudo if needed)
    -i, --ignore-errors                  Continue on download errors, for
                                         example to skip unavailable videos in a
                                         playlist
    --abort-on-error                     Abort downloading of further videos (in
                                         the playlist or the command line) if an
                                         error occurs
    --dump-user-agent                    Display the current browser
                                         identification
    --list-extractors                    List all supported extractors
    --extractor-descriptions             Output descriptions of all supported
                                         extractors
    --force-generic-extractor            Force extraction to use the generic
                                         extractor
    --default-search PREFIX              Use this prefix for unqualified URLs.
                                         For example &quot;gvsearch2:&quot; downloads two
                                         videos from google videos for youtube-
                                         dl &quot;large apple&quot;. Use the value &quot;auto&quot;
                                         to let youtube-dl guess (&quot;auto_warning&quot;
                                         to emit a warning when guessing).
                                         &quot;error&quot; just throws an error. The
                                         default value &quot;fixup_error&quot; repairs
                                         broken URLs, but emits an error if this
                                         is not possible instead of searching.
    --ignore-config                      Do not read configuration files. When
                                         given in the global configuration file
                                         /etc/youtube-dl.conf: Do not read the
                                         user configuration in
                                         ~/.config/youtube-dl/config
                                         (%APPDATA%/youtube-dl/config.txt on
                                         Windows)
    --config-location PATH               Location of the configuration file;
                                         either the path to the config or its
                                         containing directory.
    --flat-playlist                      Do not extract the videos of a
                                         playlist, only list them.
    --mark-watched                       Mark videos watched (YouTube only)
    --no-mark-watched                    Do not mark videos watched (YouTube
                                         only)
    --no-color                           Do not emit color codes in output

## Network Options:
    --proxy URL                          Use the specified HTTP/HTTPS/SOCKS
                                         proxy. To enable SOCKS proxy, specify a
                                         proper scheme. For example
                                         socks5://127.0.0.1:1080/. Pass in an
                                         empty string (--proxy &quot;&quot;) for direct
                                         connection
    --socket-timeout SECONDS             Time to wait before giving up, in
                                         seconds
    --source-address IP                  Client-side IP address to bind to
    -4, --force-ipv4                     Make all connections via IPv4
    -6, --force-ipv6                     Make all connections via IPv6

## Geo Restriction:
    --geo-verification-proxy URL         Use this proxy to verify the IP address
                                         for some geo-restricted sites. The
                                         default proxy specified by --proxy (or
                                         none, if the option is not present) is
                                         used for the actual downloading.
    --geo-bypass                         Bypass geographic restriction via
                                         faking X-Forwarded-For HTTP header
    --no-geo-bypass                      Do not bypass geographic restriction
                                         via faking X-Forwarded-For HTTP header
    --geo-bypass-country CODE            Force bypass geographic restriction
                                         with explicitly provided two-letter ISO
                                         3166-2 country code
    --geo-bypass-ip-block IP_BLOCK       Force bypass geographic restriction
                                         with explicitly provided IP block in
                                         CIDR notation

## Video Selection:
    --playlist-start NUMBER              Playlist video to start at (default is
                                         1)
    --playlist-end NUMBER                Playlist video to end at (default is
                                         last)
    --playlist-items ITEM_SPEC           Playlist video items to download.
                                         Specify indices of the videos in the
                                         playlist separated by commas like: &quot;--
                                         playlist-items 1,2,5,8&quot; if you want to
                                         download videos indexed 1, 2, 5, 8 in
                                         the playlist. You can specify range: &quot;
                                         --playlist-items 1-3,7,10-13&quot;, it will
                                         download the videos at index 1, 2, 3,
                                         7, 10, 11, 12 and 13.
    --match-title REGEX                  Download only matching titles (regex or
                                         caseless sub-string)
    --reject-title REGEX                 Skip download for matching titles
                                         (regex or caseless sub-string)
    --max-downloads NUMBER               Abort after downloading NUMBER files
    --min-filesize SIZE                  Do not download any videos smaller than
                                         SIZE (e.g. 50k or 44.6m)
    --max-filesize SIZE                  Do not download any videos larger than
                                         SIZE (e.g. 50k or 44.6m)
    --date DATE                          Download only videos uploaded in this
                                         date
    --datebefore DATE                    Download only videos uploaded on or
                                         before this date (i.e. inclusive)
    --dateafter DATE                     Download only videos uploaded on or
                                         after this date (i.e. inclusive)
    --min-views COUNT                    Do not download any videos with less
                                         than COUNT views
    --max-views COUNT                    Do not download any videos with more
                                         than COUNT views
    --match-filter FILTER                Generic video filter. Specify any key
                                         (see the &quot;OUTPUT TEMPLATE&quot; for a list
                                         of available keys) to match if the key
                                         is present, !key to check if the key is
                                         not present, key &gt; NUMBER (like
                                         &quot;comment_count &gt; 12&quot;, also works with
                                         &gt;=, &lt;, &lt;=, !=, =) to compare against a
                                         number, key = &#039;LITERAL&#039; (like &quot;uploader
                                         = &#039;Mike Smith&#039;&quot;, also works with !=) to
                                         match against a string literal and &amp; to
                                         require multiple matches. Values which
                                         are not known are excluded unless you
                                         put a question mark (?) after the
                                         operator. For example, to only match
                                         videos that have been liked more than
                                         100 times and disliked less than 50
                                         times (or the dislike functionality is
                                         not available at the given service),
                                         but who also have a description, use
                                         --match-filter &quot;like_count &gt; 100 &amp;
                                         dislike_count &lt;? 50 &amp; description&quot; .
    --no-playlist                        Download only the video, if the URL
                                         refers to a video and a playlist.
    --yes-playlist                       Download the playlist, if the URL
                                         refers to a video and a playlist.
    --age-limit YEARS                    Download only videos suitable for the
                                         given age
    --download-archive FILE              Download only videos not listed in the
                                         archive file. Record the IDs of all
                                         downloaded videos in it.
    --include-ads                        Download advertisements as well
                                         (experimental)

## Download Options:
    -r, --limit-rate RATE                Maximum download rate in bytes per
                                         second (e.g. 50K or 4.2M)
    -R, --retries RETRIES                Number of retries (default is 10), or
                                         &quot;infinite&quot;.
    --fragment-retries RETRIES           Number of retries for a fragment
                                         (default is 10), or &quot;infinite&quot; (DASH,
                                         hlsnative and ISM)
    --skip-unavailable-fragments         Skip unavailable fragments (DASH,
                                         hlsnative and ISM)
    --abort-on-unavailable-fragment      Abort downloading when some fragment is
                                         not available
    --keep-fragments                     Keep downloaded fragments on disk after
                                         downloading is finished; fragments are
                                         erased by default
    --buffer-size SIZE                   Size of download buffer (e.g. 1024 or
                                         16K) (default is 1024)
    --no-resize-buffer                   Do not automatically adjust the buffer
                                         size. By default, the buffer size is
                                         automatically resized from an initial
                                         value of SIZE.
    --http-chunk-size SIZE               Size of a chunk for chunk-based HTTP
                                         downloading (e.g. 10485760 or 10M)
                                         (default is disabled). May be useful
                                         for bypassing bandwidth throttling
                                         imposed by a webserver (experimental)
    --playlist-reverse                   Download playlist videos in reverse
                                         order
    --playlist-random                    Download playlist videos in random
                                         order
    --xattr-set-filesize                 Set file xattribute ytdl.filesize with
                                         expected file size
    --hls-prefer-native                  Use the native HLS downloader instead
                                         of ffmpeg
    --hls-prefer-ffmpeg                  Use ffmpeg instead of the native HLS
                                         downloader
    --hls-use-mpegts                     Use the mpegts container for HLS
                                         videos, allowing to play the video
                                         while downloading (some players may not
                                         be able to play it)
    --external-downloader COMMAND        Use the specified external downloader.
                                         Currently supports aria2c,avconv,axel,c
                                         url,ffmpeg,httpie,wget
    --external-downloader-args ARGS      Give these arguments to the external
                                         downloader

## Filesystem Options:
    -a, --batch-file FILE                File containing URLs to download (&#039;-&#039;
                                         for stdin), one URL per line. Lines
                                         starting with &#039;#&#039;, &#039;;&#039; or &#039;]&#039; are
                                         considered as comments and ignored.
    --id                                 Use only video ID in file name
    -o, --output TEMPLATE                Output filename template, see the
                                         &quot;OUTPUT TEMPLATE&quot; for all the info
    --output-na-placeholder PLACEHOLDER  Placeholder value for unavailable meta
                                         fields in output filename template
                                         (default is &quot;NA&quot;)
    --autonumber-start NUMBER            Specify the start value for
                                         %(autonumber)s (default is 1)
    --restrict-filenames                 Restrict filenames to only ASCII
                                         characters, and avoid &quot;&amp;&quot; and spaces in
                                         filenames
    -w, --no-overwrites                  Do not overwrite files
    -c, --continue                       Force resume of partially downloaded
                                         files. By default, youtube-dl will
                                         resume downloads if possible.
    --no-continue                        Do not resume partially downloaded
                                         files (restart from beginning)
    --no-part                            Do not use .part files - write directly
                                         into output file
    --no-mtime                           Do not use the Last-modified header to
                                         set the file modification time
    --write-description                  Write video description to a
                                         .description file
    --write-info-json                    Write video metadata to a .info.json
                                         file
    --write-annotations                  Write video annotations to a
                                         .annotations.xml file
    --load-info-json FILE                JSON file containing the video
                                         information (created with the &quot;--write-
                                         info-json&quot; option)
    --cookies FILE                       File to read cookies from and dump
                                         cookie jar in
    --cache-dir DIR                      Location in the filesystem where
                                         youtube-dl can store some downloaded
                                         information permanently. By default
                                         $XDG_CACHE_HOME/youtube-dl or
                                         ~/.cache/youtube-dl . At the moment,
                                         only YouTube player files (for videos
                                         with obfuscated signatures) are cached,
                                         but that may change.
    --no-cache-dir                       Disable filesystem caching
    --rm-cache-dir                       Delete all filesystem cache files

## Thumbnail Options:
    --write-thumbnail                    Write thumbnail image to disk
    --write-all-thumbnails               Write all thumbnail image formats to
                                         disk
    --list-thumbnails                    Simulate and list all available
                                         thumbnail formats

## Verbosity / Simulation Options:
    -q, --quiet                          Activate quiet mode
    --no-warnings                        Ignore warnings
    -s, --simulate                       Do not download the video and do not
                                         write anything to disk
    --skip-download                      Do not download the video
    -g, --get-url                        Simulate, quiet but print URL
    -e, --get-title                      Simulate, quiet but print title
    --get-id                             Simulate, quiet but print id
    --get-thumbnail                      Simulate, quiet but print thumbnail URL
    --get-description                    Simulate, quiet but print video
                                         description
    --get-duration                       Simulate, quiet but print video length
    --get-filename                       Simulate, quiet but prin

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[ansible/ansible]]></title>
            <link>https://github.com/ansible/ansible</link>
            <guid>https://github.com/ansible/ansible</guid>
            <pubDate>Wed, 24 Sep 2025 00:04:23 GMT</pubDate>
            <description><![CDATA[Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ansible/ansible">ansible/ansible</a></h1>
            <p>Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com.</p>
            <p>Language: Python</p>
            <p>Stars: 66,520</p>
            <p>Forks: 24,094</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre>[![PyPI version](https://img.shields.io/pypi/v/ansible-core.svg)](https://pypi.org/project/ansible-core)
[![Docs badge](https://img.shields.io/badge/docs-latest-brightgreen.svg)](https://docs.ansible.com/ansible/latest/)
[![Chat badge](https://img.shields.io/badge/chat-IRC-brightgreen.svg)](https://docs.ansible.com/ansible/devel/community/communication.html)
[![Build Status](https://dev.azure.com/ansible/ansible/_apis/build/status/CI?branchName=devel)](https://dev.azure.com/ansible/ansible/_build/latest?definitionId=20&amp;branchName=devel)
[![Ansible Code of Conduct](https://img.shields.io/badge/code%20of%20conduct-Ansible-silver.svg)](https://docs.ansible.com/ansible/devel/community/code_of_conduct.html)
[![Ansible mailing lists](https://img.shields.io/badge/mailing%20lists-Ansible-orange.svg)](https://docs.ansible.com/ansible/devel/community/communication.html#mailing-list-information)
[![Repository License](https://img.shields.io/badge/license-GPL%20v3.0-brightgreen.svg)](COPYING)
[![Ansible CII Best Practices certification](https://bestpractices.coreinfrastructure.org/projects/2372/badge)](https://bestpractices.coreinfrastructure.org/projects/2372)

# Ansible

Ansible is a radically simple IT automation system. It handles
configuration management, application deployment, cloud provisioning,
ad-hoc task execution, network automation, and multi-node orchestration. Ansible makes complex
changes like zero-downtime rolling updates with load balancers easy. More information on the Ansible [website](https://ansible.com/).

## Design Principles

* Have an extremely simple setup process with a minimal learning curve.
* Manage machines quickly and in parallel.
* Avoid custom-agents and additional open ports, be agentless by
  leveraging the existing SSH daemon.
* Describe infrastructure in a language that is both machine and human
  friendly.
* Focus on security and easy auditability/review/rewriting of content.
* Manage new remote machines instantly, without bootstrapping any
  software.
* Allow module development in any dynamic language, not just Python.
* Be usable as non-root.
* Be the easiest IT automation system to use, ever.

## Use Ansible

You can install a released version of Ansible with `pip` or a package manager. See our
[installation guide](https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html) for details on installing Ansible
on a variety of platforms.

Power users and developers can run the `devel` branch, which has the latest
features and fixes, directly. Although it is reasonably stable, you are more likely to encounter
breaking changes when running the `devel` branch. We recommend getting involved
in the Ansible community if you want to run the `devel` branch.

## Communication

Join the Ansible forum to ask questions, get help, and interact with the
community.

* [Get Help](https://forum.ansible.com/c/help/6): Find help or share your Ansible knowledge to help others.
  Use tags to filter and subscribe to posts, such as the following:
  * Posts tagged with [ansible](https://forum.ansible.com/tag/ansible)
  * Posts tagged with [ansible-core](https://forum.ansible.com/tag/ansible-core)
  * Posts tagged with [playbook](https://forum.ansible.com/tag/playbook)
* [Social Spaces](https://forum.ansible.com/c/chat/4): Meet and interact with fellow enthusiasts.
* [News &amp; Announcements](https://forum.ansible.com/c/news/5): Track project-wide announcements including social events.
* [Bullhorn newsletter](https://docs.ansible.com/ansible/devel/community/communication.html#the-bullhorn): Get release announcements and important changes.

For more ways to get in touch, see [Communicating with the Ansible community](https://docs.ansible.com/ansible/devel/community/communication.html).

## Contribute to Ansible

* Check out the [Contributor&#039;s Guide](./.github/CONTRIBUTING.md).
* Read [Community Information](https://docs.ansible.com/ansible/devel/community) for all
  kinds of ways to contribute to and interact with the project,
  including how to submit bug reports and code to Ansible.
* Submit a proposed code update through a pull request to the `devel` branch.
* Talk to us before making larger changes
  to avoid duplicate efforts. This not only helps everyone
  know what is going on, but it also helps save time and effort if we decide
  some changes are needed.

## Coding Guidelines

We document our Coding Guidelines in the [Developer Guide](https://docs.ansible.com/ansible/devel/dev_guide/). We particularly suggest you review:

* [Contributing your module to Ansible](https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_checklist.html)
* [Conventions, tips, and pitfalls](https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_best_practices.html)

## Branch Info

* The `devel` branch corresponds to the release actively under development.
* The `stable-2.X` branches correspond to stable releases.
* Create a branch based on `devel` and set up a [dev environment](https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_general.html#common-environment-setup) if you want to open a PR.
* See the [Ansible release and maintenance](https://docs.ansible.com/ansible/devel/reference_appendices/release_and_maintenance.html) page for information about active branches.

## Roadmap

Based on team and community feedback, an initial roadmap will be published for a major or minor version (ex: 2.7, 2.8).
The [Ansible Roadmap page](https://docs.ansible.com/ansible/devel/roadmap/) details what is planned and how to influence the roadmap.

## Authors

Ansible was created by [Michael DeHaan](https://github.com/mpdehaan)
and has contributions from over 5000 users (and growing). Thanks everyone!

[Ansible](https://www.ansible.com) is sponsored by [Red Hat, Inc.](https://www.redhat.com)

## License

GNU General Public License v3.0 or later

See [COPYING](COPYING) to see the full text.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[freqtrade/freqtrade]]></title>
            <link>https://github.com/freqtrade/freqtrade</link>
            <guid>https://github.com/freqtrade/freqtrade</guid>
            <pubDate>Wed, 24 Sep 2025 00:04:22 GMT</pubDate>
            <description><![CDATA[Free, open source crypto trading bot]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/freqtrade/freqtrade">freqtrade/freqtrade</a></h1>
            <p>Free, open source crypto trading bot</p>
            <p>Language: Python</p>
            <p>Stars: 42,843</p>
            <p>Forks: 8,688</p>
            <p>Stars today: 346 stars today</p>
            <h2>README</h2><pre># ![freqtrade](https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade_poweredby.svg)

[![Freqtrade CI](https://github.com/freqtrade/freqtrade/actions/workflows/ci.yml/badge.svg?branch=develop)](https://github.com/freqtrade/freqtrade/actions/)
[![DOI](https://joss.theoj.org/papers/10.21105/joss.04864/status.svg)](https://doi.org/10.21105/joss.04864)
[![Coverage Status](https://coveralls.io/repos/github/freqtrade/freqtrade/badge.svg?branch=develop&amp;service=github)](https://coveralls.io/github/freqtrade/freqtrade?branch=develop)
[![Documentation](https://readthedocs.org/projects/freqtrade/badge/)](https://www.freqtrade.io)

Freqtrade is a free and open source crypto trading bot written in Python. It is designed to support all major exchanges and be controlled via Telegram or webUI. It contains backtesting, plotting and money management tools as well as strategy optimization by machine learning.

![freqtrade](https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade-screenshot.png)

## Disclaimer

This software is for educational purposes only. Do not risk money which
you are afraid to lose. USE THE SOFTWARE AT YOUR OWN RISK. THE AUTHORS
AND ALL AFFILIATES ASSUME NO RESPONSIBILITY FOR YOUR TRADING RESULTS.

Always start by running a trading bot in Dry-run and do not engage money
before you understand how it works and what profit/loss you should
expect.

We strongly recommend you to have coding and Python knowledge. Do not
hesitate to read the source code and understand the mechanism of this bot.

## Supported Exchange marketplaces

Please read the [exchange specific notes](docs/exchanges.md) to learn about eventual, special configurations needed for each exchange.

- [X] [Binance](https://www.binance.com/)
- [X] [Bitmart](https://bitmart.com/)
- [X] [BingX](https://bingx.com/invite/0EM9RX)
- [X] [Bybit](https://bybit.com/)
- [X] [Gate.io](https://www.gate.io/ref/6266643)
- [X] [HTX](https://www.htx.com/)
- [X] [Hyperliquid](https://hyperliquid.xyz/) (A decentralized exchange, or DEX)
- [X] [Kraken](https://kraken.com/)
- [X] [OKX](https://okx.com/)
- [X] [MyOKX](https://okx.com/) (OKX EEA)
- [ ] [potentially many others](https://github.com/ccxt/ccxt/). _(We cannot guarantee they will work)_

### Supported Futures Exchanges (experimental)

- [X] [Binance](https://www.binance.com/)
- [X] [Gate.io](https://www.gate.io/ref/6266643)
- [X] [Hyperliquid](https://hyperliquid.xyz/) (A decentralized exchange, or DEX)
- [X] [OKX](https://okx.com/)
- [X] [Bybit](https://bybit.com/)

Please make sure to read the [exchange specific notes](docs/exchanges.md), as well as the [trading with leverage](docs/leverage.md) documentation before diving in.

### Community tested

Exchanges confirmed working by the community:

- [X] [Bitvavo](https://bitvavo.com/)
- [X] [Kucoin](https://www.kucoin.com/)

## Documentation

We invite you to read the bot documentation to ensure you understand how the bot is working.

Please find the complete documentation on the [freqtrade website](https://www.freqtrade.io).

## Features

- [x] **Based on Python 3.11+**: For botting on any operating system - Windows, macOS and Linux.
- [x] **Persistence**: Persistence is achieved through sqlite.
- [x] **Dry-run**: Run the bot without paying money.
- [x] **Backtesting**: Run a simulation of your buy/sell strategy.
- [x] **Strategy Optimization by machine learning**: Use machine learning to optimize your buy/sell strategy parameters with real exchange data.
- [X] **Adaptive prediction modeling**: Build a smart strategy with FreqAI that self-trains to the market via adaptive machine learning methods. [Learn more](https://www.freqtrade.io/en/stable/freqai/)
- [x] **Whitelist crypto-currencies**: Select which crypto-currency you want to trade or use dynamic whitelists.
- [x] **Blacklist crypto-currencies**: Select which crypto-currency you want to avoid.
- [x] **Builtin WebUI**: Builtin web UI to manage your bot.
- [x] **Manageable via Telegram**: Manage the bot with Telegram.
- [x] **Display profit/loss in fiat**: Display your profit/loss in fiat currency.
- [x] **Performance status report**: Provide a performance status of your current trades.

## Quick start

Please refer to the [Docker Quickstart documentation](https://www.freqtrade.io/en/stable/docker_quickstart/) on how to get started quickly.

For further (native) installation methods, please refer to the [Installation documentation page](https://www.freqtrade.io/en/stable/installation/).

## Basic Usage

### Bot commands

```
usage: freqtrade [-h] [-V]
                 {trade,create-userdir,new-config,show-config,new-strategy,download-data,convert-data,convert-trade-data,trades-to-ohlcv,list-data,backtesting,backtesting-show,backtesting-analysis,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-markets,list-pairs,list-strategies,list-hyperoptloss,list-freqaimodels,list-timeframes,show-trades,test-pairlist,convert-db,install-ui,plot-dataframe,plot-profit,webserver,strategy-updater,lookahead-analysis,recursive-analysis}
                 ...

Free, open source crypto trading bot

positional arguments:
  {trade,create-userdir,new-config,show-config,new-strategy,download-data,convert-data,convert-trade-data,trades-to-ohlcv,list-data,backtesting,backtesting-show,backtesting-analysis,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-markets,list-pairs,list-strategies,list-hyperoptloss,list-freqaimodels,list-timeframes,show-trades,test-pairlist,convert-db,install-ui,plot-dataframe,plot-profit,webserver,strategy-updater,lookahead-analysis,recursive-analysis}
    trade               Trade module.
    create-userdir      Create user-data directory.
    new-config          Create new config
    show-config         Show resolved config
    new-strategy        Create new strategy
    download-data       Download backtesting data.
    convert-data        Convert candle (OHLCV) data from one format to
                        another.
    convert-trade-data  Convert trade data from one format to another.
    trades-to-ohlcv     Convert trade data to OHLCV data.
    list-data           List downloaded data.
    backtesting         Backtesting module.
    backtesting-show    Show past Backtest results
    backtesting-analysis
                        Backtest Analysis module.
    hyperopt            Hyperopt module.
    hyperopt-list       List Hyperopt results
    hyperopt-show       Show details of Hyperopt results
    list-exchanges      Print available exchanges.
    list-markets        Print markets on exchange.
    list-pairs          Print pairs on exchange.
    list-strategies     Print available strategies.
    list-hyperoptloss   Print available hyperopt loss functions.
    list-freqaimodels   Print available freqAI models.
    list-timeframes     Print available timeframes for the exchange.
    show-trades         Show trades.
    test-pairlist       Test your pairlist configuration.
    convert-db          Migrate database to different system
    install-ui          Install FreqUI
    plot-dataframe      Plot candles with indicators.
    plot-profit         Generate plot showing profits.
    webserver           Webserver module.
    strategy-updater    updates outdated strategy files to the current version
    lookahead-analysis  Check for potential look ahead bias.
    recursive-analysis  Check for potential recursive formula issue.

options:
  -h, --help            show this help message and exit
  -V, --version         show program&#039;s version number and exit
```

### Telegram RPC commands

Telegram is not mandatory. However, this is a great way to control your bot. More details and the full command list on the [documentation](https://www.freqtrade.io/en/latest/telegram-usage/)

- `/start`: Starts the trader.
- `/stop`: Stops the trader.
- `/stopentry`: Stop entering new trades.
- `/status &lt;trade_id&gt;|[table]`: Lists all or specific open trades.
- `/profit [&lt;n&gt;]`: Lists cumulative profit from all finished trades, over the last n days.
- `/profit_long [&lt;n&gt;]`: Lists cumulative profit from all finished long trades, over the last n days.
- `/profit_short [&lt;n&gt;]`: Lists cumulative profit from all finished short trades, over the last n days.
- `/forceexit &lt;trade_id&gt;|all`: Instantly exits the given trade (Ignoring `minimum_roi`).
- `/fx &lt;trade_id&gt;|all`: Alias to `/forceexit`
- `/performance`: Show performance of each finished trade grouped by pair
- `/balance`: Show account balance per currency.
- `/daily &lt;n&gt;`: Shows profit or loss per day, over the last n days.
- `/help`: Show help message.
- `/version`: Show version.


## Development branches

The project is currently setup in two main branches:

- `develop` - This branch has often new features, but might also contain breaking changes. We try hard to keep this branch as stable as possible.
- `stable` - This branch contains the latest stable release. This branch is generally well tested.
- `feat/*` - These are feature branches, which are being worked on heavily. Please don&#039;t use these unless you want to test a specific feature.

## Support

### Help / Discord

For any questions not covered by the documentation or for further information about the bot, or to simply engage with like-minded individuals, we encourage you to join the Freqtrade [discord server](https://discord.gg/p7nuUNVfP7).

### [Bugs / Issues](https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue)

If you discover a bug in the bot, please
[search the issue tracker](https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue)
first. If it hasn&#039;t been reported, please
[create a new issue](https://github.com/freqtrade/freqtrade/issues/new/choose) and
ensure you follow the template guide so that the team can assist you as
quickly as possible.

For every [issue](https://github.com/freqtrade/freqtrade/issues/new/choose) created, kindly follow up and mark satisfaction or reminder to close issue when equilibrium ground is reached.

--Maintain github&#039;s [community policy](https://docs.github.com/en/site-policy/github-terms/github-community-code-of-conduct)--

### [Feature Requests](https://github.com/freqtrade/freqtrade/labels/enhancement)

Have you a great idea to improve the bot you want to share? Please,
first search if this feature was not [already discussed](https://github.com/freqtrade/freqtrade/labels/enhancement).
If it hasn&#039;t been requested, please
[create a new request](https://github.com/freqtrade/freqtrade/issues/new/choose)
and ensure you follow the template guide so that it does not get lost
in the bug reports.

### [Pull Requests](https://github.com/freqtrade/freqtrade/pulls)

Feel like the bot is missing a feature? We welcome your pull requests!

Please read the
[Contributing document](https://github.com/freqtrade/freqtrade/blob/develop/CONTRIBUTING.md)
to understand the requirements before sending your pull-requests.

Coding is not a necessity to contribute - maybe start with improving the documentation?
Issues labeled [good first issue](https://github.com/freqtrade/freqtrade/labels/good%20first%20issue) can be good first contributions, and will help get you familiar with the codebase.

**Note** before starting any major new feature work, *please open an issue describing what you are planning to do* or talk to us on [discord](https://discord.gg/p7nuUNVfP7) (please use the #dev channel for this). This will ensure that interested parties can give valuable feedback on the feature, and let others know that you are working on it.

**Important:** Always create your PR against the `develop` branch, not `stable`.

## Requirements

### Up-to-date clock

The clock must be accurate, synchronized to a NTP server very frequently to avoid problems with communication to the exchanges.

### Minimum hardware required

To run this bot we recommend you a cloud instance with a minimum of:

- Minimal (advised) system requirements: 2GB RAM, 1GB disk space, 2vCPU

### Software requirements

- [Python &gt;= 3.11](http://docs.python-guide.org/en/latest/starting/installation/)
- [pip](https://pip.pypa.io/en/stable/installing/)
- [git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)
- [TA-Lib](https://ta-lib.github.io/ta-lib-python/)
- [virtualenv](https://virtualenv.pypa.io/en/stable/installation.html) (Recommended)
- [Docker](https://www.docker.com/products/docker) (Recommended)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[OWASP/CheatSheetSeries]]></title>
            <link>https://github.com/OWASP/CheatSheetSeries</link>
            <guid>https://github.com/OWASP/CheatSheetSeries</guid>
            <pubDate>Wed, 24 Sep 2025 00:04:21 GMT</pubDate>
            <description><![CDATA[The OWASP Cheat Sheet Series was created to provide a concise collection of high value information on specific application security topics.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/OWASP/CheatSheetSeries">OWASP/CheatSheetSeries</a></h1>
            <p>The OWASP Cheat Sheet Series was created to provide a concise collection of high value information on specific application security topics.</p>
            <p>Language: Python</p>
            <p>Stars: 30,328</p>
            <p>Forks: 4,249</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># Welcome to the OWASP Cheat Sheet Series

[![OWASP Flagship](https://img.shields.io/badge/owasp-flagship%20project-48A646.svg)](https://www.owasp.org/index.php/OWASP_Project_Inventory#tab=Flagship_Projects)
[![Creative Commons License](https://img.shields.io/github/license/OWASP/CheatSheetSeries)](https://creativecommons.org/licenses/by-sa/4.0/ &quot;CC BY-SA 4.0&quot;)

Welcome to the official repository for the Open Worldwide Application Security ProjectÂ® (OWASP) Cheat Sheet Series project. The project focuses on providing good security practices for builders in order to secure their applications.

In order to read the cheat sheets and **reference** them, use the project [official website](https://cheatsheetseries.owasp.org). The project details can be viewed on the [OWASP main website](https://owasp.org/www-project-cheat-sheets/) without the cheat sheets.

:triangular_flag_on_post: Markdown files are the working sources and aren&#039;t intended to be referenced in any external documentation, books or websites.

## Cheat Sheet Series Team

### Project Leaders

- [Jim Manico](https://github.com/jmanico)
- [Jakub MaÄ‡kowski](https://github.com/mackowski)
- [Shlomo Zalman Heigh](https://github.com/szh)

### Core team

- [Kevin W. Wall](https://github.com/kwwall)

## Chat With Us

We&#039;re easy to find on Slack:

1. Join the OWASP Group Slack with this [invitation link](https://owasp.org/slack/invite).
2. Join the [#cheatsheets channel](https://owasp.slack.com/messages/C073YNUQG).

Feel free to ask questions, suggest ideas, or share your best recipes.

## Contributions, Feature Requests, and Feedback

We are actively inviting new contributors! To start, please read the [contribution guide](CONTRIBUTING.md).

This project is only possible thanks to the work of many dedicated volunteers. Everyone is encouraged to help in ways large and small. Here are a few ways you can help:

- Read the current content and help us fix any spelling mistakes or grammatical errors.
- Choose an existing [issue](https://github.com/OWASP/CheatSheetSeries/issues) on GitHub and submit a pull request to fix it.
- Open a new issue to report an opportunity for improvement.

### Automated Build

This [link](https://cheatsheetseries.owasp.org/bundle.zip) allows you to download a build (ZIP archive) of the offline website.

### Local Build [![pyVersion3x](https://img.shields.io/badge/python-3.x-blue.svg)](https://www.python.org/downloads/)

The OWASP Cheat Sheet Series website can be built and tested locally by issuing the following commands:

```sh
make install-python-requirements
make generate-site
make serve  # Binds port 8000
```

### Container Build

The OWASP Cheat Sheet Series website can be built and tested locally inside a container by issuing the following commands:

#### Docker

```sh
docker build -t cheatsheetseries .
docker run --name cheatsheetseries -p 8000:8000 cheatsheetseries
```

#### Podman

```sh
podman build -t cheatsheetseries .
podman run --name cheatsheetseries -p 8000:8000 localhost/cheatsheetseries
```

## Contributors

- **From 2014 to 2018:** [V1](CONTRIBUTOR-V1.md) - Initial version of the project hosted on the [OWASP WIKI](https://wiki.owasp.org).
- **From 2019:** [V2](https://github.com/OWASP/CheatSheetSeries/graphs/contributors) - Hosted on [GitHub](https://github.com/OWASP/CheatSheetSeries).

## Special thanks

A special thank you to the following people for their help provided during the migration:

- [Dominique Righetto](https://github.com/righettod): For his special leadership and guidance.
- [Elie Saad](https://github.com/ThunderSon): For valuable help in updating the OWASP Wiki links for all the migrated cheat sheets and for years of leadership and other project support.
- [Jakub MaÄ‡kowski](https://github.com/mackowski): For valuable help in updating the OWASP Wiki links for all the migrated cheat sheets.

Open Worldwide Application Security Project and OWASP are registered trademarks of the OWASP Foundation, Inc.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[malmeloo/FindMy.py]]></title>
            <link>https://github.com/malmeloo/FindMy.py</link>
            <guid>https://github.com/malmeloo/FindMy.py</guid>
            <pubDate>Wed, 24 Sep 2025 00:04:20 GMT</pubDate>
            <description><![CDATA[ğŸ + ğŸ¯ + ğŸ = Query Apple's FindMy Network with Python!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/malmeloo/FindMy.py">malmeloo/FindMy.py</a></h1>
            <p>ğŸ + ğŸ¯ + ğŸ = Query Apple's FindMy Network with Python!</p>
            <p>Language: Python</p>
            <p>Stars: 2,464</p>
            <p>Forks: 95</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img alt=&quot;FindMy.py Logo&quot; src=&quot;assets/icon.png&quot; width=&quot;500&quot;&gt;
  &lt;h1&gt;FindMy.py&lt;/h1&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

_Query Apple&#039;s FindMy network with Python!_

  &lt;h5&gt;
      &lt;a href=&quot;https://docs.mikealmel.ooo/FindMy.py&quot;&gt;
        Docs
      &lt;/a&gt;
      &lt;span&gt; | &lt;/span&gt;
      &lt;a href=&quot;examples/&quot;&gt;
        Examples
      &lt;/a&gt;
      &lt;span&gt; | &lt;/span&gt;
      &lt;a href=&quot;https://pypi.org/project/FindMy/&quot;&gt;
        PyPI
      &lt;/a&gt;
      &lt;span&gt; | &lt;/span&gt;
      &lt;a href=&quot;https://discord.gg/EF6UCG2TF6&quot;&gt;
        Discord
      &lt;/a&gt;
&lt;/div&gt;

## ğŸš€ Overview

The current &quot;Find My-scene&quot; is quite fragmented, with code
being all over the place across multiple repositories,
written by [several authors](#Credits). This project aims to
unify this scene, providing common building blocks for any
application wishing to integrate with the Find My network.

&gt; [!IMPORTANT]
&gt; This project is currently in Alpha. While existing functionality
&gt; will likely not change much, the API design is subject to change
&gt; without prior warning.
&gt;
&gt; You are encouraged to report any issues you can find on the
&gt; [issue tracker](https://github.com/malmeloo/FindMy.py/issues/)!

## ğŸ§ª Features

- [x] Cross-platform: no Mac needed
- [x] Fetch and decrypt location reports
  - [x] Official accessories (AirTags, iDevices, etc.)
  - [x] Custom AirTags (OpenHaystack)
- [x] Apple account sign-in
  - [x] SMS 2FA support
  - [x] Trusted Device 2FA support
- [x] Scan for nearby FindMy-devices
  - [x] Decode their info, such as public keys and status bytes
- [x] Import or create your own accessory keys
- [x] Both async and sync APIs

## ğŸ“¥ Installation

The package can be installed from [PyPi](https://pypi.org/project/findmy/):

```shell
pip install findmy
```

For usage examples, see the [examples](examples) directory.
We are also building out a CLI. Try `python -m findmy` to see the current state of it.
Documentation can be found [here](http://docs.mikealmel.ooo/FindMy.py/).

## ğŸ¤ Contributing

Want to contribute code? That&#039;s great! For new features, please open an
[issue](https://github.com/malmeloo/FindMy.py/issues) first so we can discuss.

This project uses [Ruff](https://docs.astral.sh/ruff/) for linting and formatting.
Before opening a pull request, please ensure that your code adheres to these rules.
There are pre-commit hooks included to help you with this, which you can set up as follows:

```shell
pip install uv
uv sync  # this installs ruff &amp; pre-commit into your environment
pre-commit install
```

After following the above steps, your code will be linted and formatted automatically
before committing it.

## ğŸ§  Derivative projects

There are several other cool projects in the FindMy space!
You can check them out [here](http://docs.mikealmel.ooo/FindMy.py/related/index.html).

## ğŸ… Credits

While I designed the library, the vast majority of actual functionality
is made possible by the following wonderful people and organizations:

- @seemo-lab for [OpenHaystack](https://github.com/seemoo-lab/openhaystack/)
  and their [research](https://doi.org/10.2478/popets-2021-0045);
- @JJTech0130 for [Pypush](https://github.com/JJTech0130/pypush), providing the breakthrough necessary
  for getting this to work without a Mac;
- @biemster for [FindMy](https://github.com/biemster/FindMy), which is the main basis of this project;
- @Dadoum for [pyprovision](https://github.com/Dadoum/pyprovision/) and
  [anisette-v3-server](https://github.com/Dadoum/anisette-v3-server);
- @nythepegasus for [GrandSlam](https://github.com/nythepegasus/grandslam/) SMS 2FA;
- And probably more, so let me know! :D
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[frappe/erpnext]]></title>
            <link>https://github.com/frappe/erpnext</link>
            <guid>https://github.com/frappe/erpnext</guid>
            <pubDate>Wed, 24 Sep 2025 00:04:19 GMT</pubDate>
            <description><![CDATA[Free and Open Source Enterprise Resource Planning (ERP)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/frappe/erpnext">frappe/erpnext</a></h1>
            <p>Free and Open Source Enterprise Resource Planning (ERP)</p>
            <p>Language: Python</p>
            <p>Stars: 28,448</p>
            <p>Forks: 9,359</p>
            <p>Stars today: 31 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/frappe/design/blob/master/logos/logo-2019/erpnext-logo.png&quot; height=&quot;128&quot;&gt;
    &lt;h2&gt;ERPNext&lt;/h2&gt;
    &lt;p align=&quot;center&quot;&gt;
        &lt;p&gt;ERP made simple&lt;/p&gt;
    &lt;/p&gt;

[![Build Status](https://travis-ci.com/frappe/erpnext.png)](https://travis-ci.com/frappe/erpnext)
[![Open Source Helpers](https://www.codetriage.com/frappe/erpnext/badges/users.svg)](https://www.codetriage.com/frappe/erpnext)
[![Coverage Status](https://coveralls.io/repos/github/frappe/erpnext/badge.svg?branch=develop)](https://coveralls.io/github/frappe/erpnext?branch=develop)

[https://erpnext.com](https://erpnext.com)

&lt;/div&gt;

Includes: Accounting, Inventory, Manufacturing, CRM, Sales, Purchase, Project Management, HRMS. Requires MariaDB.

ERPNext is built on the [Frappe](https://github.com/frappe/frappe) Framework, a full-stack web app framework in Python &amp; JavaScript.

- [User Guide](https://erpnext.com/docs/user)
- [Discussion Forum](https://discuss.erpnext.com/)

---

### Full Install

The Easy Way: our install script for bench will install all dependencies (e.g. MariaDB). See https://github.com/frappe/bench for more details.

New passwords will be created for the ERPNext &quot;Administrator&quot; user, the MariaDB root user, and the frappe user (the script displays the passwords and saves them to ~/frappe_passwords.txt).

### Virtual Image

You can download a virtual image to run ERPNext in a virtual machine on your local system.

- [ERPNext Download](http://erpnext.com/download)

System and user credentials are listed on the download page.

---

## License

GNU/General Public License (see [license.txt](license.txt))

The ERPNext code is licensed as GNU General Public License (v3) and the Documentation is licensed as Creative Commons (CC-BY-SA-3.0) and the copyright is owned by Frappe Technologies Pvt Ltd (Frappe) and Contributors.

---

## Contributing

1. [Issue Guidelines](https://github.com/frappe/erpnext/wiki/Issue-Guidelines)
1. [Report Security Vulnerabilities](https://erpnext.com/report)
1. [Pull Request Requirements](https://github.com/frappe/erpnext/wiki/Contribution-Guidelines)
1. [Translations](https://translate.erpnext.com)
1. [Chart of Accounts](https://charts.erpnext.com)

---

## Logo and Trademark

The brand name ERPNext and the logo are trademarks of Frappe Technologies Pvt. Ltd.

### Introduction

Frappe Technologies Pvt. Ltd. (Frappe) owns and oversees the trademarks for the ERPNext name and logos. We have developed this trademark usage policy with the following goals in mind:

- Weâ€™d like to make it easy for anyone to use the ERPNext name or logo for community-oriented efforts that help spread and improve ERPNext.
- Weâ€™d like to make it clear how ERPNext-related businesses and projects can (and cannot) use the ERPNext name and logo.
- Weâ€™d like to make it hard for anyone to use the ERPNext name and logo to unfairly profit from, trick or confuse people who are looking for official ERPNext resources.

### Frappe Trademark Usage Policy

Permission from Frappe is required to use the ERPNext name or logo as part of any project, product, service, domain or company name.

We will grant permission to use the ERPNext name and logo for projects that meet the following criteria:

- The primary purpose of your project is to promote the spread and improvement of the ERPNext software.
- Your project is non-commercial in nature (it can make money to cover its costs or contribute to non-profit entities, but it cannot be run as a for-profit project or business).
Your project neither promotes nor is associated with entities that currently fail to comply with the GPL license under which ERPNext is distributed.
- If your project meets these criteria, you will be permitted to use the ERPNext name and logo to promote your project in any way you see fit with one exception: Please do not use ERPNext as part of a domain name.

Use of the ERPNext name and logo is additionally allowed in the following situations:

All other ERPNext-related businesses or projects can use the ERPNext name and logo to refer to and explain their services, but they cannot use them as part of a product, project, service, domain, or company name and they cannot use them in any way that suggests an affiliation with or endorsement by ERPNext or Frappe Technologies or the ERPNext open source project. For example, a consulting company can describe its business as â€œ123 Web Services, offering ERPNext consulting for small businesses,â€ but cannot call its business â€œThe ERPNext Consulting Company.â€

Similarly, itâ€™s OK to use the ERPNext logo as part of a page that describes your products or services, but it is not OK to use it as part of your company or product logo or branding itself. Under no circumstances is it permitted to use ERPNext as part of a top-level domain name.

We do not allow the use of the trademark in advertising, including AdSense/AdWords.

Please note that it is not the goal of this policy to limit commercial activity around ERPNext. We encourage ERPNext-based businesses, and we would love to see hundreds of them.

When in doubt about your use of the ERPNext name or logo, please contact Frappe Technologies for clarification.

(inspired by WordPress)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[pytorch/pytorch]]></title>
            <link>https://github.com/pytorch/pytorch</link>
            <guid>https://github.com/pytorch/pytorch</guid>
            <pubDate>Wed, 24 Sep 2025 00:04:18 GMT</pubDate>
            <description><![CDATA[Tensors and Dynamic neural networks in Python with strong GPU acceleration]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pytorch/pytorch">pytorch/pytorch</a></h1>
            <p>Tensors and Dynamic neural networks in Python with strong GPU acceleration</p>
            <p>Language: Python</p>
            <p>Stars: 93,401</p>
            <p>Forks: 25,383</p>
            <p>Stars today: 44 stars today</p>
            <h2>README</h2><pre>![PyTorch Logo](https://github.com/pytorch/pytorch/blob/9708fcf92db88b80b9010c68662d634434da3106/docs/source/_static/img/pytorch-logo-dark.png)

--------------------------------------------------------------------------------

PyTorch is a Python package that provides two high-level features:
- Tensor computation (like NumPy) with strong GPU acceleration
- Deep neural networks built on a tape-based autograd system

You can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.

Our trunk health (Continuous Integration signals) can be found at [hud.pytorch.org](https://hud.pytorch.org/ci/pytorch/pytorch/main).

&lt;!-- toc --&gt;

- [More About PyTorch](#more-about-pytorch)
  - [A GPU-Ready Tensor Library](#a-gpu-ready-tensor-library)
  - [Dynamic Neural Networks: Tape-Based Autograd](#dynamic-neural-networks-tape-based-autograd)
  - [Python First](#python-first)
  - [Imperative Experiences](#imperative-experiences)
  - [Fast and Lean](#fast-and-lean)
  - [Extensions Without Pain](#extensions-without-pain)
- [Installation](#installation)
  - [Binaries](#binaries)
    - [NVIDIA Jetson Platforms](#nvidia-jetson-platforms)
  - [From Source](#from-source)
    - [Prerequisites](#prerequisites)
      - [NVIDIA CUDA Support](#nvidia-cuda-support)
      - [AMD ROCm Support](#amd-rocm-support)
      - [Intel GPU Support](#intel-gpu-support)
    - [Get the PyTorch Source](#get-the-pytorch-source)
    - [Install Dependencies](#install-dependencies)
    - [Install PyTorch](#install-pytorch)
      - [Adjust Build Options (Optional)](#adjust-build-options-optional)
  - [Docker Image](#docker-image)
    - [Using pre-built images](#using-pre-built-images)
    - [Building the image yourself](#building-the-image-yourself)
  - [Building the Documentation](#building-the-documentation)
    - [Building a PDF](#building-a-pdf)
  - [Previous Versions](#previous-versions)
- [Getting Started](#getting-started)
- [Resources](#resources)
- [Communication](#communication)
- [Releases and Contributing](#releases-and-contributing)
- [The Team](#the-team)
- [License](#license)

&lt;!-- tocstop --&gt;

## More About PyTorch

[Learn the basics of PyTorch](https://pytorch.org/tutorials/beginner/basics/intro.html)

At a granular level, PyTorch is a library that consists of the following components:

| Component | Description |
| ---- | --- |
| [**torch**](https://pytorch.org/docs/stable/torch.html) | A Tensor library like NumPy, with strong GPU support |
| [**torch.autograd**](https://pytorch.org/docs/stable/autograd.html) | A tape-based automatic differentiation library that supports all differentiable Tensor operations in torch |
| [**torch.jit**](https://pytorch.org/docs/stable/jit.html) | A compilation stack (TorchScript) to create serializable and optimizable models from PyTorch code  |
| [**torch.nn**](https://pytorch.org/docs/stable/nn.html) | A neural networks library deeply integrated with autograd designed for maximum flexibility |
| [**torch.multiprocessing**](https://pytorch.org/docs/stable/multiprocessing.html) | Python multiprocessing, but with magical memory sharing of torch Tensors across processes. Useful for data loading and Hogwild training |
| [**torch.utils**](https://pytorch.org/docs/stable/data.html) | DataLoader and other utility functions for convenience |

Usually, PyTorch is used either as:

- A replacement for NumPy to use the power of GPUs.
- A deep learning research platform that provides maximum flexibility and speed.

Elaborating Further:

### A GPU-Ready Tensor Library

If you use NumPy, then you have used Tensors (a.k.a. ndarray).

![Tensor illustration](https://github.com/pytorch/pytorch/blob/9708fcf92db88b80b9010c68662d634434da3106/docs/source/_static/img/tensor_illustration.png)

PyTorch provides Tensors that can live either on the CPU or the GPU and accelerates the
computation by a huge amount.

We provide a wide variety of tensor routines to accelerate and fit your scientific computation needs
such as slicing, indexing, mathematical operations, linear algebra, reductions.
And they are fast!

### Dynamic Neural Networks: Tape-Based Autograd

PyTorch has a unique way of building neural networks: using and replaying a tape recorder.

Most frameworks such as TensorFlow, Theano, Caffe, and CNTK have a static view of the world.
One has to build a neural network and reuse the same structure again and again.
Changing the way the network behaves means that one has to start from scratch.

With PyTorch, we use a technique called reverse-mode auto-differentiation, which allows you to
change the way your network behaves arbitrarily with zero lag or overhead. Our inspiration comes
from several research papers on this topic, as well as current and past work such as
[torch-autograd](https://github.com/twitter/torch-autograd),
[autograd](https://github.com/HIPS/autograd),
[Chainer](https://chainer.org), etc.

While this technique is not unique to PyTorch, it&#039;s one of the fastest implementations of it to date.
You get the best of speed and flexibility for your crazy research.

![Dynamic graph](https://github.com/pytorch/pytorch/blob/9708fcf92db88b80b9010c68662d634434da3106/docs/source/_static/img/dynamic_graph.gif)

### Python First

PyTorch is not a Python binding into a monolithic C++ framework.
It is built to be deeply integrated into Python.
You can use it naturally like you would use [NumPy](https://www.numpy.org/) / [SciPy](https://www.scipy.org/) / [scikit-learn](https://scikit-learn.org) etc.
You can write your new neural network layers in Python itself, using your favorite libraries
and use packages such as [Cython](https://cython.org/) and [Numba](http://numba.pydata.org/).
Our goal is to not reinvent the wheel where appropriate.

### Imperative Experiences

PyTorch is designed to be intuitive, linear in thought, and easy to use.
When you execute a line of code, it gets executed. There isn&#039;t an asynchronous view of the world.
When you drop into a debugger or receive error messages and stack traces, understanding them is straightforward.
The stack trace points to exactly where your code was defined.
We hope you never spend hours debugging your code because of bad stack traces or asynchronous and opaque execution engines.

### Fast and Lean

PyTorch has minimal framework overhead. We integrate acceleration libraries
such as [Intel MKL](https://software.intel.com/mkl) and NVIDIA ([cuDNN](https://developer.nvidia.com/cudnn), [NCCL](https://developer.nvidia.com/nccl)) to maximize speed.
At the core, its CPU and GPU Tensor and neural network backends
are mature and have been tested for years.

Hence, PyTorch is quite fast â€” whether you run small or large neural networks.

The memory usage in PyTorch is extremely efficient compared to Torch or some of the alternatives.
We&#039;ve written custom memory allocators for the GPU to make sure that
your deep learning models are maximally memory efficient.
This enables you to train bigger deep learning models than before.

### Extensions Without Pain

Writing new neural network modules, or interfacing with PyTorch&#039;s Tensor API was designed to be straightforward
and with minimal abstractions.

You can write new neural network layers in Python using the torch API
[or your favorite NumPy-based libraries such as SciPy](https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html).

If you want to write your layers in C/C++, we provide a convenient extension API that is efficient and with minimal boilerplate.
No wrapper code needs to be written. You can see [a tutorial here](https://pytorch.org/tutorials/advanced/cpp_extension.html) and [an example here](https://github.com/pytorch/extension-cpp).


## Installation

### Binaries
Commands to install binaries via Conda or pip wheels are on our website: [https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/)


#### NVIDIA Jetson Platforms

Python wheels for NVIDIA&#039;s Jetson Nano, Jetson TX1/TX2, Jetson Xavier NX/AGX, and Jetson AGX Orin are provided [here](https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048) and the L4T container is published [here](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch)

They require JetPack 4.2 and above, and [@dusty-nv](https://github.com/dusty-nv) and [@ptrblck](https://github.com/ptrblck) are maintaining them.


### From Source

#### Prerequisites
If you are installing from source, you will need:
- Python 3.9 or later
- A compiler that fully supports C++17, such as clang or gcc (gcc 9.4.0 or newer is required, on Linux)
- Visual Studio or Visual Studio Build Tool (Windows only)

\* PyTorch CI uses Visual C++ BuildTools, which come with Visual Studio Enterprise,
Professional, or Community Editions. You can also install the build tools from
https://visualstudio.microsoft.com/visual-cpp-build-tools/. The build tools *do not*
come with Visual Studio Code by default.

An example of environment setup is shown below:

* Linux:

```bash
$ source &lt;CONDA_INSTALL_DIR&gt;/bin/activate
$ conda create -y -n &lt;CONDA_NAME&gt;
$ conda activate &lt;CONDA_NAME&gt;
```

* Windows:

```bash
$ source &lt;CONDA_INSTALL_DIR&gt;\Scripts\activate.bat
$ conda create -y -n &lt;CONDA_NAME&gt;
$ conda activate &lt;CONDA_NAME&gt;
$ call &quot;C:\Program Files\Microsoft Visual Studio\&lt;VERSION&gt;\Community\VC\Auxiliary\Build\vcvarsall.bat&quot; x64
```

A conda environment is not required.  You can also do a PyTorch build in a
standard virtual environment, e.g., created with tools like `uv`, provided
your system has installed all the necessary dependencies unavailable as pip
packages (e.g., CUDA, MKL.)

##### NVIDIA CUDA Support
If you want to compile with CUDA support, [select a supported version of CUDA from our support matrix](https://pytorch.org/get-started/locally/), then install the following:
- [NVIDIA CUDA](https://developer.nvidia.com/cuda-downloads)
- [NVIDIA cuDNN](https://developer.nvidia.com/cudnn) v8.5 or above
- [Compiler](https://gist.github.com/ax3l/9489132) compatible with CUDA

Note: You could refer to the [cuDNN Support Matrix](https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html) for cuDNN versions with the various supported CUDA, CUDA driver, and NVIDIA hardware.

If you want to disable CUDA support, export the environment variable `USE_CUDA=0`.
Other potentially useful environment variables may be found in `setup.py`.  If
CUDA is installed in a non-standard location, set PATH so that the nvcc you
want to use can be found (e.g., `export PATH=/usr/local/cuda-12.8/bin:$PATH`).

If you are building for NVIDIA&#039;s Jetson platforms (Jetson Nano, TX1, TX2, AGX Xavier), Instructions to install PyTorch for Jetson Nano are [available here](https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/)

##### AMD ROCm Support
If you want to compile with ROCm support, install
- [AMD ROCm](https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html) 4.0 and above installation
- ROCm is currently supported only for Linux systems.

By default the build system expects ROCm to be installed in `/opt/rocm`. If ROCm is installed in a different directory, the `ROCM_PATH` environment variable must be set to the ROCm installation directory. The build system automatically detects the AMD GPU architecture. Optionally, the AMD GPU architecture can be explicitly set with the `PYTORCH_ROCM_ARCH` environment variable [AMD GPU architecture](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus)

If you want to disable ROCm support, export the environment variable `USE_ROCM=0`.
Other potentially useful environment variables may be found in `setup.py`.

##### Intel GPU Support
If you want to compile with Intel GPU support, follow these
- [PyTorch Prerequisites for Intel GPUs](https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html) instructions.
- Intel GPU is supported for Linux and Windows.

If you want to disable Intel GPU support, export the environment variable `USE_XPU=0`.
Other potentially useful environment variables may be found in `setup.py`.

#### Get the PyTorch Source

```bash
git clone https://github.com/pytorch/pytorch
cd pytorch
# if you are updating an existing checkout
git submodule sync
git submodule update --init --recursive
```

#### Install Dependencies

**Common**

```bash
# Run this command from the PyTorch directory after cloning the source code using the â€œGet the PyTorch Sourceâ€œ section above
pip install --group dev
```

**On Linux**

```bash
pip install mkl-static mkl-include
# CUDA only: Add LAPACK support for the GPU if needed
# magma installation: run with active conda environment. specify CUDA version to install
.ci/docker/common/install_magma_conda.sh 12.4

# (optional) If using torch.compile with inductor/triton, install the matching version of triton
# Run from the pytorch directory after cloning
# For Intel GPU support, please explicitly `export USE_XPU=1` before running command.
make triton
```

**On MacOS**

```bash
# Add this package on intel x86 processor machines only
pip install mkl-static mkl-include
# Add these packages if torch.distributed is needed
conda install pkg-config libuv
```

**On Windows**

```bash
pip install mkl-static mkl-include
# Add these packages if torch.distributed is needed.
# Distributed package support on Windows is a prototype feature and is subject to changes.
conda install -c conda-forge libuv
```

#### Install PyTorch

**On Linux**

If you&#039;re compiling for AMD ROCm then first run this command:

```bash
# Only run this if you&#039;re compiling for ROCm
python tools/amd_build/build_amd.py
```

Install PyTorch

```bash
export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-&#039;$(dirname $(which conda))/../&#039;}:${CMAKE_PREFIX_PATH}&quot;
python -m pip install --no-build-isolation -v -e .
```

**On macOS**

```bash
python -m pip install --no-build-isolation -v -e .
```

**On Windows**

If you want to build legacy python code, please refer to [Building on legacy code and CUDA](https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda)

**CPU-only builds**

In this mode PyTorch computations will run on your CPU, not your GPU.

```cmd
python -m pip install --no-build-isolation -v -e .
```

Note on OpenMP: The desired OpenMP implementation is Intel OpenMP (iomp). In order to link against iomp, you&#039;ll need to manually download the library and set up the building environment by tweaking `CMAKE_INCLUDE_PATH` and `LIB`. The instruction [here](https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source) is an example for setting up both MKL and Intel OpenMP. Without these configurations for CMake, Microsoft Visual C OpenMP runtime (vcomp) will be used.

**CUDA based build**

In this mode PyTorch computations will leverage your GPU via CUDA for faster number crunching

[NVTX](https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm) is needed to build Pytorch with CUDA.
NVTX is a part of CUDA distributive, where it is called &quot;Nsight Compute&quot;. To install it onto an already installed CUDA run CUDA installation once again and check the corresponding checkbox.
Make sure that CUDA with Nsight Compute is installed after Visual Studio.

Currently, VS 2017 / 2019, and Ninja are supported as the generator of CMake. If `ninja.exe` is detected in `PATH`, then Ninja will be used as the default generator, otherwise, it will use VS 2017 / 2019.
&lt;br/&gt; If Ninja is selected as the generator, the latest MSVC will get selected as the underlying toolchain.

Additional libraries such as
[Magma](https://developer.nvidia.com/magma), [oneDNN, a.k.a. MKLDNN or DNNL](https://github.com/oneapi-src/oneDNN), and [Sccache](https://github.com/mozilla/sccache) are often needed. Please refer to the [installation-helper](https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers) to install them.

You can refer to the [build_pytorch.bat](https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat) script for some other environment variables configurations

```cmd
cmd

:: Set the environment variables after you have downloaded and unzipped the mkl package,
:: else CMake would throw an error as `Could NOT find OpenMP`.
set CMAKE_INCLUDE_PATH={Your directory}\mkl\include
set LIB={Your directory}\mkl\lib;%LIB%

:: Read the content in the previous section carefully before you proceed.
:: [Optional] If you want to override the underlying toolset used by Ninja and Visual Studio with CUDA, please run the following script block.
:: &quot;Visual Studio 2019 Developer Command Prompt&quot; will be run automatically.
:: Make sure you have CMake &gt;= 3.12 before you do this when you use the Visual Studio generator.
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f &quot;usebackq tokens=*&quot; %i in (`&quot;%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe&quot; -version [15^,17^) -products * -latest -property installationPath`) do call &quot;%i\VC\Auxiliary\Build\vcvarsall.bat&quot; x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%

:: [Optional] If you want to override the CUDA host compiler
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe

python -m pip install --no-build-isolation -v -e .
```

**Intel GPU builds**

In this mode PyTorch with Intel GPU support will be built.

Please make sure [the common prerequisites](#prerequisites) as well as [the prerequisites for Intel GPU](#intel-gpu-support) are properly installed and the environment variables are configured prior to starting the build. For build tool support, `Visual Studio 2022` is required.

Then PyTorch can be built with the command:

```cmd
:: CMD Commands:
:: Set the CMAKE_PREFIX_PATH to help find corresponding packages
:: %CONDA_PREFIX% only works after `conda activate custom_env`

if defined CMAKE_PREFIX_PATH (
    set &quot;CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%&quot;
) else (
    set &quot;CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library&quot;
)

python -m pip install --no-build-isolation -v -e .
```

##### Adjust Build Options (Optional)

You can adjust the configuration of cmake variables optionally (without building first), by doing
the following. For example, adjusting the pre-detected directories for CuDNN or BLAS can be done
with such a step.

On Linux

```bash
export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-&#039;$(dirname $(which conda))/../&#039;}:${CMAKE_PREFIX_PATH}&quot;
CMAKE_ONLY=1 python setup.py build
ccmake build  # or cmake-gui build
```

On macOS

```bash
export CMAKE_PREFIX_PATH=&quot;${CONDA_PREFIX:-&#039;$(dirname $(which conda))/../&#039;}:${CMAKE_PREFIX_PATH}&quot;
MACOSX_DEPLOYMENT_TARGET=11.0 CMAKE_ONLY=1 python setup.py build
ccmake build  # or cmake-gui build
```

### Docker Image

#### Using pre-built images

You can also pull a pre-built docker image from Docker Hub and run with docker v19.03+

```bash
docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest
```

Please note that PyTorch uses shared memory to share data between processes, so if torch multiprocessing is used (e.g.
for multithreaded data loaders) the default shared memory segment size that container runs with is not enough, and you
should increase shared memory size either with `--ipc=host` or `--shm-size` command line options to `nvidia-docker run`.

#### Building the image yourself

**NOTE:** Must be built with a docker version &gt; 18.06

The `Dockerfile` is supplied to build images with CUDA 11.1 support and cuDNN v8.
You can pass `PYTHON_VERSION=x.y` make variable to specify which Python version is to be used by Miniconda, or leave it
unset to use the default.

```bash
make -f docker.Makefile
# images are tagged as docker.io/${your_docker_username}/pytorch
```

You can also pass the `CMAKE_VARS=&quot;...&quot;` environment variable to specify additional C

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[public-apis/public-apis]]></title>
            <link>https://github.com/public-apis/public-apis</link>
            <guid>https://github.com/public-apis/public-apis</guid>
            <pubDate>Wed, 24 Sep 2025 00:04:17 GMT</pubDate>
            <description><![CDATA[A collective list of free APIs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/public-apis/public-apis">public-apis/public-apis</a></h1>
            <p>A collective list of free APIs</p>
            <p>Language: Python</p>
            <p>Stars: 366,026</p>
            <p>Forks: 38,453</p>
            <p>Stars today: 210 stars today</p>
            <h2>README</h2><pre># Try Public APIs for free
The Public APIs repository is manually curated by community members like you and folks working at [APILayer](https://apilayer.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo). It includes an extensive list of public APIs from many domains that you can use for your own products. Consider it a treasure trove of APIs well-managed by the community over the years.

&lt;br &gt;

&lt;p&gt;
    &lt;a href=&quot;https://apilayer.com&quot;&gt;
        &lt;div&gt;
            &lt;img src=&quot;.github/cs1586-APILayerLogoUpdate2022-LJ_v2-HighRes.png&quot; width=&quot;100%&quot; alt=&quot;APILayer Logo&quot; /&gt;
        &lt;/div&gt;
    &lt;/a&gt;
  &lt;/p&gt;

APILayer is the fastest way to integrate APIs into any product. Explore [APILayer APIs](https://apilayer.com/products/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo) here for your next project.

Join our [Discord server](https://discord.com/invite/hgjA78638n/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo) to get updates, ask questions, get answers, random community calls, and more.

&lt;br &gt;

## APILayer APIs
| API | Description | Call this API |
|:---|:---|:---|
| [IPstack](https://ipstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Locate and Identify Website Visitors by IP Address | [&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-55145132-244c-448c-8e6f-8780866e4862?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-55145132-244c-448c-8e6f-8780866e4862%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Marketstack](https://marketstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Free, easy-to-use REST API interface delivering worldwide stock market data in JSON format | [&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-9cbac391-3611-4f50-9bfd-d24ae41c97c1?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-9cbac391-3611-4f50-9bfd-d24ae41c97c1%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Weatherstack](https://weatherstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Retrieve instant, accurate weather information for any location in the world in lightweight JSON format | [&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-276c4312-f682-425d-b6b1-0f82c0a7f2b3?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-276c4312-f682-425d-b6b1-0f82c0a7f2b3%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Numverify](https://numverify.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers ) | Global Phone Number Validation &amp; Lookup JSON API |[&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-0760d25e-b802-412e-b0e4-26e5ca3b9ffa?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-0760d25e-b802-412e-b0e4-26e5ca3b9ffa%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Fixer](https://fixer.io/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Fixer is a simple and lightweight API for current and historical foreign exchange (forex) rates. |[&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-0d9c66b3-5f1a-42ed-a5ca-379217bd629d?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-0d9c66b3-5f1a-42ed-a5ca-379217bd629d%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Aviationstack](https://avaitionstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Free, real-time flight status and global Aviation data API |[&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-72ee0d35-018e-4370-a2b6-a66d3ebd5b5a?action=collection/fork)|

&lt;br &gt;

## Learn more about Public APIs

&lt;strong&gt;Get Involved&lt;/strong&gt;

* [Contributing Guide](CONTRIBUTING.md)
* [API for this project](https://github.com/davemachado/public-api)
* [Issues](https://github.com/public-apis/public-apis/issues)
* [Pull Requests](https://github.com/public-apis/public-apis/pulls)
* [LICENSE](LICENSE) 

&lt;br /&gt;

## Index

* [Animals](#animals)
* [Anime](#anime)
* [Anti-Malware](#anti-malware)
* [Art &amp; Design](#art--design)
* [Authentication &amp; Authorization](#authentication--authorization)
* [Blockchain](#blockchain)
* [Books](#books)
* [Business](#business)
* [Calendar](#calendar)
* [Cloud Storage &amp; File Sharing](#cloud-storage--file-sharing)
* [Continuous Integration](#continuous-integration)
* [Cryptocurrency](#cryptocurrency)
* [Currency Exchange](#currency-exchange)
* [Data Validation](#data-validation)
* [Development](#development)
* [Dictionaries](#dictionaries)
* [Documents &amp; Productivity](#documents--productivity)
* [Email](#email)
* [Entertainment](#entertainment)
* [Environment](#environment)
* [Events](#events)
* [Finance](#finance)
* [Food &amp; Drink](#food--drink)
* [Games &amp; Comics](#games--comics)
* [Geocoding](#geocoding)
* [Government](#government)
* [Health](#health)
* [Jobs](#jobs)
* [Machine Learning](#machine-learning)
* [Music](#music)
* [News](#news)
* [Open Data](#open-data)
* [Open Source Projects](#open-source-projects)
* [Patent](#patent)
* [Personality](#personality)
* [Phone](#phone)
* [Photography](#photography)
* [Programming](#programming)
* [Science &amp; Math](#science--math)
* [Security](#security)
* [Shopping](#shopping)
* [Social](#social)
* [Sports &amp; Fitness](#sports--fitness)
* [Test Data](#test-data)
* [Text Analysis](#text-analysis)
* [Tracking](#tracking)
* [Transportation](#transportation)
* [URL Shorteners](#url-shorteners)
* [Vehicle](#vehicle)
* [Video](#video)
* [Weather](#weather)
&lt;br &gt;

### Animals
API | Description | Auth | HTTPS | CORS 
|:---|:---|:---|:---|:---|
| [AdoptAPet](https://www.adoptapet.com/public/apis/pet_list.html) | Resource to help get pets adopted | `apiKey` | Yes | Yes |
| [Axolotl](https://theaxolotlapi.netlify.app/) | Collection of axolotl pictures and facts | No | Yes | No |
| [Cat Facts](https://alexwohlbruck.github.io/cat-facts/) | Daily cat facts | No | Yes | No | |
| [Cataas](https://cataas.com/) | Cat as a service (cats pictures and gifs) | No | Yes | No |
| [Cats](https://docs.thecatapi.com/) | Pictures of cats from Tumblr | `apiKey` | Yes | No |
| [Dog Facts](https://dukengn.github.io/Dog-facts-API/) | Random dog facts | No | Yes | Yes |
| [Dog Facts](https://kinduff.github.io/dog-api/) | Random facts of Dogs | No | Yes | Yes |
| [Dogs](https://dog.ceo/dog-api/) | Based on the Stanford Dogs Dataset | No | Yes | Yes |
| [eBird](https://documenter.getpostman.com/view/664302/S1ENwy59) | Retrieve recent or notable birding observations within a region | `apiKey` | Yes | No |
| [FishWatch](https://www.fishwatch.gov/developers) | Information and pictures about individual fish species | No | Yes | Yes |
| [HTTP Cat](https://http.cat/) | Cat for every HTTP Status | No | Yes | Yes |
| [HTTP Dog](https://http.dog/) | Dogs for every HTTP response status code | No | Yes | Yes |
| [IUCN](http://apiv3.iucnredlist.org/api/v3/docs) | IUCN Red List of Threatened Species | `apiKey` | No | No |
| [MeowFacts](https://github.com/wh-iterabb-it/meowfacts) | Get random cat facts | No | Yes | No |
| [Movebank](https://github.com/movebank/movebank-api-doc) | Movement and Migration data of animals | No | Yes | Yes |
| [Petfinder](https://www.petfinder.com/developers/) | Petfinder is dedicated to helping pets find homes, another resource to get pets adopted | `apiKey` | Yes | Yes |
| [PlaceBear](https://placebear.com/) | Placeholder bear pictures | No | Yes | Yes |
| [PlaceDog](https://place.dog) | Placeholder Dog pictures | No | Yes | Yes |
| [PlaceKitten](https://placekitten.com/) | Placeholder Kitten pictures | No | Yes | Yes |
| [RandomDog](https://random.dog/woof.json) | Random pictures of dogs | No | Yes | Yes |
| [RandomDuck](https://random-d.uk/api) | Random pictures of ducks | No | Yes | No |
| [RandomFox](https://randomfox.ca/floof/) | Random pictures of foxes | No | Yes | No |
| [RescueGroups](https://userguide.rescuegroups.org/display/APIDG/API+Developers+Guide+Home) | Adoption | No | Yes | Unknown |
| [Shibe.Online](http://shibe.online/) | Random pictures of Shiba Inu, cats or birds | No | Yes | Yes |
| [The Dog](https://thedogapi.com/) | A public service all about Dogs, free to use when making your fancy new App, Website or Service | `apiKey` | Yes | No |
| [xeno-canto](https://xeno-canto.org/explore/api) | Bird recordings | No | Yes | Unknown |
| [Zoo Animals](https://zoo-animal-api.herokuapp.com/) | Facts and pictures of zoo animals | No | Yes | Yes |

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;

### Anime
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [AniAPI](https://aniapi.com/docs/) | Anime discovery, streaming &amp; syncing with trackers | `OAuth` | Yes | Yes |
| [AniDB](https://wiki.anidb.net/HTTP_API_Definition) | Anime Database | `apiKey` | No | Unknown |
| [AniList](https://github.com/AniList/ApiV2-GraphQL-Docs) | Anime discovery &amp; tracking | `OAuth` | Yes | Unknown |
| [AnimeChan](https://github.com/RocktimSaikia/anime-chan) | Anime quotes (over 10k+) | No | Yes | No |
| [AnimeFacts](https://chandan-02.github.io/anime-facts-rest-api/) | Anime Facts (over 100+) | No | Yes | Yes |
| [AnimeNewsNetwork](https://www.animenewsnetwork.com/encyclopedia/api.php) | Anime industry news | No | Yes | Yes |
| [Catboy](https://catboys.com/api) | Neko images, funny GIFs &amp; more | No | Yes | Yes |
| [Danbooru Anime](https://danbooru.donmai.us/wiki_pages/help:api) | Thousands of anime artist database to find good anime art | `apiKey` | Yes | Yes |
| [Jikan](https://jikan.moe) | Unofficial MyAnimeList API | No | Yes | Yes |
| [Kitsu](https://kitsu.docs.apiary.io/) | Anime discovery platform | `OAuth` | Yes | Yes |
| [MangaDex](https://api.mangadex.org/docs.html) | Manga Database and Community | `apiKey` | Yes | Unknown |
| [Mangapi](https://rapidapi.com/pierre.carcellermeunier/api/mangapi3/) | Translate manga pages from one language to another | `apiKey` | Yes | Unknown |
| [MyAnimeList](https://myanimelist.net/clubs.php?cid=13727) | Anime and Manga Database and Community | `OAuth` | Yes | Unknown |
| [NekosBest](https://docs.nekos.best) | Neko Images &amp; Anime roleplaying GIFs | No | Yes | Yes |
| [Shikimori](https://shikimori.one/api/doc) | Anime discovery, tracking, forum, rates | `OAuth` | Yes | Unknown |
| [Studio Ghibli](https://ghibliapi.herokuapp.com) | Resources from Studio Ghibli films | No | Yes | Yes |
| [Trace Moe](https://soruly.github.io/trace.moe-api/#/) | A useful tool to get the exact scene of an anime from a screenshot | No | Yes | No |
| [Waifu.im](https://waifu.im/docs) | Get waifu pictures from an archive of over 4000 images and multiple tags | No | Yes | Yes |
| [Waifu.pics](https://waifu.pics/docs) | Image sharing platform for anime images | No | Yes | No |

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;

### Anti-Malware
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [AbuseIPDB](https://docs.abuseipdb.com/) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |
| [AlienVault Open Threat Exchange (OTX)](https://otx.alienvault.com/api) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |
| [CAPEsandbox](https://capev2.readthedocs.io/en/latest/usage/api.html) | Malware execution and analysis | `apiKey` | Yes | Unknown |
| [Google Safe Browsing](https://developers.google.com/safe-browsing/) | Google Link/Domain Flagging | `apiKey` | Yes | Unknown |
| [MalDatabase](https://maldatabase.com/api-doc.html) | Provide malware datasets and threat intelligence feeds | `apiKey` | Yes | Unknown |
| [MalShare](https://malshare.com/doc.php) | Malware Archive / file sourcing | `apiKey` | Yes | No |
| [MalwareBazaar](https://bazaar.abuse.ch/api/) | Collect and share malware samples | `apiKey` | Yes | Unknown |
| [Metacert](https://metacert.com/) | Metacert Link Flagging | `apiKey` | Yes | Unknown |
| [NoPhishy](https://rapidapi.com/Amiichu/api/exerra-phishing-check/) | Check links to see if they&#039;re known phishing attempts | `apiKey` | Yes | Yes |
| [Phisherman](https://phisherman.gg/) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |
| [Scanii](https://docs.scanii.com/) | Simple REST API that can scan submitted documents/files for the presence of threats | `apiKey` | Yes | Yes |
| [URLhaus](https://urlhaus-api.abuse.ch/) | Bulk queries and Download Malware Samples | No | Yes | Yes |
| [URLScan.io](https://urlscan.io/about-api/) | Scan and Analyse URLs | `apiKey` | Yes | Unknown |
| [VirusTotal](https://www.virustotal.com/en/documentation/public-api/) | VirusTotal File/URL Analysis | `apiKey` | Yes | Unknown |
| [Web of Trust](https://support.mywot.com/hc/en-us/sections/360004477734-API-) | IP/domain/URL reputation | `apiKey` | Yes | Unknown | 

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Art &amp; Design
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [AmÃ©thyste](https://api.amethyste.moe/) | Generate images for Discord users | `apiKey` | Yes | Unknown |
| [Art Institute of Chicago](https://api.artic.edu/docs/) | Art | No | Yes | Yes |
| [Colormind](http://colormind.io/api-access/) | Color scheme generator | No | No | Unknown |
| [ColourLovers](http://www.colourlovers.com/api) | Get various patterns, palettes and images | No | No | Unknown |
| [Cooper Hewitt](https://collection.cooperhewitt.org/api) | Smithsonian Design Museum | `apiKey` | Yes | Unknown |
| [Dribbble](https://developer.dribbble.com) | Discover the worldâ€™s top designers &amp; creatives | `OAuth` | Yes | Unknown |
| [EmojiHub](https://github.com/cheatsnake/emojihub) | Get emojis by categories and groups | No | Yes | Yes |
| [Europeana](https://pro.europeana.eu/resources/apis/search) | European Museum and Galleries content | `apiKey` | Yes | Unknown |
| [Harvard Art Museums](https://github.com/harvardartmuseums/api-docs) | Art | `apiKey` | No | Unknown |
| [Icon Horse](https://icon.horse) | Favicons for any website, with fallbacks | No | Yes | Yes |
| [Iconfinder](https://developer.iconfinder.com) | Icons | `apiKey` | Yes | Unknown |
| [Icons8](https://img.icons8.com/) | Icons (find &quot;search icon&quot; hyperlink in page) | No | Yes | Unknown |
| [Lordicon](https://lordicon.com/) | Icons with predone Animations | No | Yes | Yes |
| [Metropolitan Museum of Art](https://metmuseum.github.io/) | Met Museum of Art | No | Yes | No |
| [Noun Project](http://api.thenounproject.com/index.html) | Icons | `OAuth` | No | Unknown |
| [PHP-Noise](https://php-noise.com/) | Noise Background Image Generator | No | Yes | Yes |
| [Pixel Encounter](https://pixelencounter.com/api) | SVG Icon Generator | No | Yes | No |
| [Rijksmuseum](https://data.rijksmuseum.nl/object-metadata/api/) | RijksMuseum Data | `apiKey` | Yes | Unknown |
| [Word Cloud](https://wordcloudapi.com/) | Easily create word clouds | `apiKey` | Yes | Unknown |
| [xColors](https://x-colors.herokuapp.com/) | Generate &amp; convert colors | No | Yes | Yes |

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Authentication &amp; Authorization
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [Auth0](https://auth0.com) | Easy to implement, adaptable authentication and authorization platform | `apiKey` | Yes | Yes |
| [GetOTP](https://otp.dev/en/docs/) | Implement OTP flow quickly | `apiKey` | Yes | No |
| [Micro User Service](https://m3o.com/user) | User management and authentication | `apiKey` | Yes | No |
| [MojoAuth](https://mojoauth.com) | Secure and modern passwordless authentication platform | `apiKey` | Yes | Yes |
| [SAWO Labs](https://sawolabs.com) | Simplify login and improve user experience by integrating passwordless authentication in your app | `apiKey` | Yes | Yes |
| [Stytch](https://stytch.com/) | User infrastructure for modern applications | `apiKey` | Yes | No |
| [Warrant](https://warrant.dev/) | APIs for authorization and access control | `apiKey` | Yes | Yes |

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Blockchain
| API | Description | Auth | HTTPS | CORS |
|---|:---|:---|:---|:---|
| [Bitquery](https://graphql.bitquery.io/ide) | Onchain GraphQL APIs &amp; DEX APIs | `apiKey` | Yes | Yes |
| [Chainlink](https://chain.link/developer-resources) | Build hybrid smart contracts with Chainlink | No | Yes | Unknown |
| [Chainpoint](https://tierion.com/chainpoint/) | Chainpoint is a global network for anchoring data to the Bitcoin blockchain | No | Yes | Unknown |
| [Covalent](https://www.covalenthq.com/docs/api/) | Multi-blockchain data aggregator platform | `apiKey` | Yes | Unknown |
| [Etherscan](https://etherscan.io/apis) | Ethereum explorer API | `apiKey` | Yes | Yes |
| [Helium](https://docs.helium.com/api/blockchain/introduction/) | Helium is a global, distributed network of Hotspots that create public, long-range wireless coverage | No | Yes | Unknown |
| [Nownodes](https://nownodes.io/) | Blockchain-as-a-service solution that provides high-quality connection via API | `apiKey` | Yes | Unknown |
| [Steem](https://developers.steem.io/) | Blockchain-based blogging and social media website | No | No | No |
| [The Graph](https://thegraph.com) | Indexing protocol for querying networks like Ethereum with GraphQL | `apiKey` | Yes | Unknown |
| [Walltime](https://walltime.info/api.html) | To retrieve Walltime&#039;s market info | No | Yes | Unknown |
| [Watchdata](https://docs.watchdata.io) | Provide simple and reliable API access to Ethereum blockchain | `apiKey` | Yes | Unknown |

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Books
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [A BÃ­blia Digital](https://www.abibliadigital.com.br/en) | Do not worry about managing the multiple versions of the Bible | `apiKey` | Yes | No |
| [Bhagavad Gita](https://docs.bhagavadgitaapi.in) | Open Source Shrimad Bhagavad Gita API including 21+ authors translation in Sanskrit/English/Hindi | `apiKey` | Yes | Yes |
| [Bhagavad Gita](https://bhagavadgita.io/api) | Bhagavad Gita text | `OAuth` | Yes | Yes |
| [Bhagavad Gita telugu](https://gita-api.vercel.app) | Bhagavad Gita API in telugu and odia languages | No | Yes | Yes |
| [Bible-api](https://bible-api.com/) | Free Bible API with multiple languages | No | Yes | Yes |
| [British National Bibliography](http://bnb.data.bl.uk/) | Books | No | No | Unknown |
| [Crossref Metadata Search](https://github.com/CrossRef/rest-api-doc) | Books &amp; Articles Metadata | No | Yes | Unknown |
| [Ganjoor](https://api.ganjoor.net) | Classic Persian poetry works including access to related manuscripts, recitations and music tracks | `OAuth` | Yes | Yes |
| [Google Books](https://developers.google.com/books/) | Books | `OAuth` | Yes | Unknown |
| [GurbaniNow](https://github.com/GurbaniNow/api) | Fast and Accurate Gurbani RESTful API | No | Yes | Unknown |
| [Gutendex](https://gutendex.com/) | Web-API for fetching data from Project Gutenberg Books Library | No | Yes | Unknown |
| [Open Library](https://openlibrary.org/developers/api) | Books, book covers and related data | No | Yes | No |
| [Penguin Publishing](http://www.penguinrandomhouse.biz/webservices/rest/) | Books, book covers and related data | No | Yes | Yes |
| [PoetryDB](https://github.com/thundercomb/poetrydb#readme) | Enables you to get instant data from our vast p

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Olow304/memvid]]></title>
            <link>https://github.com/Olow304/memvid</link>
            <guid>https://github.com/Olow304/memvid</guid>
            <pubDate>Wed, 24 Sep 2025 00:04:16 GMT</pubDate>
            <description><![CDATA[Video-based AI memory library. Store millions of text chunks in MP4 files with lightning-fast semantic search. No database needed.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Olow304/memvid">Olow304/memvid</a></h1>
            <p>Video-based AI memory library. Store millions of text chunks in MP4 files with lightning-fast semantic search. No database needed.</p>
            <p>Language: Python</p>
            <p>Stars: 8,527</p>
            <p>Forks: 725</p>
            <p>Stars today: 170 stars today</p>
            <h2>README</h2><pre>## What to expect in v2

&gt; **Early-access notice**  
&gt; Memvid v1 is still experimental. The file format and API may change until we lock in a stable release.
&gt; 
&gt; **Memvid v2 â€“ what&#039;s next**  
&gt; - **Living-Memory Engine** â€“ keep adding new data and let LLMs remember it across sessions.  
&gt; - **Capsule Context** â€“ shareable `.mv2` capsules, each with its own rules and expiry.  
&gt; - **Time-Travel Debugging** â€“ rewind or branch any chat to review or test.  
&gt; - **Smart Recall** â€“ local cache guesses what youâ€™ll need and loads it in under 5 ms.  
&gt; - **Codec Intelligence** â€“ auto-tunes AV1 now and future codecs later, so files keep shrinking.  
&gt; - **CLI &amp; Dashboard** â€“ simple tools for branching, analytics, and one-command cloud publish.  

Sneak peek of Memvid v2 - a living memory engine that can be used to chat with your knowledge base.
![Memvid v2 Preview](assets/mv2.png)


---

## Memvid v1



[![PyPI](https://img.shields.io/pypi/v/memvid)](https://pypi.org/project/memvid/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![GitHub Stars](https://img.shields.io/github/stars/olow304/memvid)](https://github.com/olow304/memvid)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

# Memvid - Turn millions of text chunks into a single, searchable video file

Memvid compresses an entire knowledge base into **MP4** files while keeping millisecond-level semantic search. Think of it as *SQLite for AI memory* portable, efficient, and self-contained. By encoding text as **QR codes in video frames**, we deliver **50-100Ã—** smaller storage than vector databases with **zero infrastructure**.

---

## Why Video Compression Changes Everything ğŸš€

| What it enables | How video codecs make it possible |
|---------|-------------------|
| **50-100Ã— smaller storage** | Modern video codecs compress repetitive visual patterns (QR codes) far better than raw embeddings |
| **Sub-100ms retrieval** | Direct frame seek via index â†’ QR decode â†’ your text. No server round-trips |
| **Zero infrastructure** | Just Python and MP4 files-no DB clusters, no Docker, no ops |
| **True portability** | Copy or stream `memory.mp4`-it works anywhere video plays |
| **Offline-first design** | After encoding, everything runs without internet |

---

## Under the Hood - Memvid v1 ğŸ”

1. **Text â†’ QR â†’ Frame**  
   Each text chunk becomes a QR code, packed into video frames. Modern codecs excel at compressing these repetitive patterns.

2. **Smart indexing**  
   Embeddings map queries â†’ frame numbers. One seek, one decode, millisecond results.

3. **Codec leverage**  
   30 years of video R&amp;D means your text gets compressed better than any custom algorithm could achieve.

4. **Future-proof**  
   Next-gen codecs (AV1, H.266) automatically make your memories smaller and faster-no code changes needed.

---

## Installation
```bash
pip install memvid
# For PDF support
pip install memvid PyPDF2
```

## Quick Start
```python
from memvid import MemvidEncoder, MemvidChat

# Create video memory from text
chunks = [&quot;NASA founded 1958&quot;, &quot;Apollo 11 landed 1969&quot;, &quot;ISS launched 1998&quot;]
encoder = MemvidEncoder()
encoder.add_chunks(chunks)
encoder.build_video(&quot;space.mp4&quot;, &quot;space_index.json&quot;)

# Chat with your memory
chat = MemvidChat(&quot;space.mp4&quot;, &quot;space_index.json&quot;)
response = chat.chat(&quot;When did humans land on the moon?&quot;)
print(response)  # References Apollo 11 in 1969
```

## Real-World Examples

### Documentation Assistant
```python
from memvid import MemvidEncoder
import os

encoder = MemvidEncoder(chunk_size=512)

# Index all markdown files
for file in os.listdir(&quot;docs&quot;):
    if file.endswith(&quot;.md&quot;):
        with open(f&quot;docs/{file}&quot;) as f:
            encoder.add_text(f.read(), metadata={&quot;file&quot;: file})

encoder.build_video(&quot;docs.mp4&quot;, &quot;docs_index.json&quot;)
```

### PDF Library Search
```python
# Index multiple PDFs
encoder = MemvidEncoder()
encoder.add_pdf(&quot;deep_learning.pdf&quot;)
encoder.add_pdf(&quot;machine_learning.pdf&quot;) 
encoder.build_video(&quot;ml_library.mp4&quot;, &quot;ml_index.json&quot;)

# Semantic search across all books
from memvid import MemvidRetriever
retriever = MemvidRetriever(&quot;ml_library.mp4&quot;, &quot;ml_index.json&quot;)
results = retriever.search(&quot;backpropagation&quot;, top_k=5)
```

### Interactive Web UI
```python
from memvid import MemvidInteractive

# Launch at http://localhost:7860
interactive = MemvidInteractive(&quot;knowledge.mp4&quot;, &quot;index.json&quot;)
interactive.run()
```

## Advanced Features

### Scale Optimization
```python
# Maximum compression for huge datasets
encoder.build_video(
    &quot;compressed.mp4&quot;,
    &quot;index.json&quot;, 
    fps=60,              # More frames/second
    frame_size=256,      # Smaller QR codes
    video_codec=&#039;h265&#039;,  # Better compression
    crf=28              # Quality tradeoff
)
```

### Custom Embeddings
```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer(&#039;all-mpnet-base-v2&#039;)
encoder = MemvidEncoder(embedding_model=model)
```

### Parallel Processing
```python
encoder = MemvidEncoder(n_workers=8)
encoder.add_chunks_parallel(million_chunks)
```

## CLI Usage
```bash
# Process documents
python examples/file_chat.py --input-dir /docs --provider openai

# Advanced codecs
python examples/file_chat.py --files doc.pdf --codec h265

# Load existing
python examples/file_chat.py --load-existing output/memory
```

## Performance

- **Indexing**: ~10K chunks/second on modern CPUs
- **Search**: &lt;100ms for 1M chunks (includes decode)
- **Storage**: 100MB text â†’ 1-2MB video
- **Memory**: Constant 500MB RAM regardless of size

## What&#039;s Coming in v2

- **Delta encoding**: Time-travel through knowledge versions
- **Streaming ingest**: Add to videos in real-time
- **Cloud dashboard**: Web UI with API management
- **Smart codecs**: Auto-select AV1/HEVC per content
- **GPU boost**: 100Ã— faster bulk encoding

## Get Involved

Memvid is redefining AI memory. Join us:

- â­ Star on [GitHub](https://github.com/olow304/memvid)
- ğŸ› Report issues or request features
- ğŸ”§ Submit PRs (we review quickly!)
- ğŸ’¬ Discuss video-based AI memory

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>