<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Tue, 28 Oct 2025 00:04:23 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[yeongpin/cursor-free-vip]]></title>
            <link>https://github.com/yeongpin/cursor-free-vip</link>
            <guid>https://github.com/yeongpin/cursor-free-vip</guid>
            <pubDate>Tue, 28 Oct 2025 00:04:23 GMT</pubDate>
            <description><![CDATA[[Support 0.49.x]（Reset Cursor AI MachineID & Bypass Higher Token Limit） Cursor Ai ，自动重置机器ID ， 免费升级使用Pro功能: You've reached your trial request limit. / Too many free trial accounts used on this machine. Please upgrade to pro. We have this limit in place to prevent abuse. Please let us know if you believe this is a mistake.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/yeongpin/cursor-free-vip">yeongpin/cursor-free-vip</a></h1>
            <p>[Support 0.49.x]（Reset Cursor AI MachineID & Bypass Higher Token Limit） Cursor Ai ，自动重置机器ID ， 免费升级使用Pro功能: You've reached your trial request limit. / Too many free trial accounts used on this machine. Please upgrade to pro. We have this limit in place to prevent abuse. Please let us know if you believe this is a mistake.</p>
            <p>Language: Python</p>
            <p>Stars: 38,703</p>
            <p>Forks: 4,708</p>
            <p>Stars today: 1,344 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;
   &lt;sup&gt;Special thanks to:&lt;/sup&gt;
   &lt;br&gt;
   &lt;br&gt;
   &lt;a href=&quot;http://go.warp.dev/cursor-free-vip&quot;&gt;
      &lt;img alt=&quot;Warp sponsorship&quot; width=&quot;400&quot; src=&quot;https://github.com/user-attachments/assets/ab8dd143-b0fd-4904-bdc5-dd7ecac94eae&quot;&gt;
   &lt;/a&gt;

### [Warp, built for coding with multiple agents.](http://go.warp.dev/cursor-free-vip)
[Available for MacOS, Linux, &amp; Windows](http://go.warp.dev/cursor-free-vip)&lt;br&gt;

&lt;/div&gt;

---

# ➤ Cursor Free VIP

&lt;div align=&quot;center&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/logo.png&quot; alt=&quot;Cursor Pro Logo&quot; width=&quot;200&quot; style=&quot;border-radius: 6px;&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;

[![Release](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/release/yeongpin/cursor-free-vip)](https://github.com/yeongpin/cursor-free-vip/releases/latest)
[![License: CC BY-NC-ND 4.0](https://img.shields.io/badge/License-CC_BY--NC--ND_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-nd/4.0/)
[![Stars](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/stars/yeongpin/cursor-free-vip)](https://github.com/yeongpin/cursor-free-vip/stargazers)
[![Downloads](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/yeongpin/cursor-free-vip/total)](https://github.com/yeongpin/cursor-free-vip/releases/latest)
&lt;a href=&quot;https://buymeacoffee.com/yeongpin&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Buy Me a Coffee&quot; src=&quot;https://img.shields.io/badge/Buy%20Me%20a%20Coffee-Support%20Me-FFDA33&quot;&gt;&lt;/a&gt;
 [&lt;img src=&quot;https://devin.ai/assets/deepwiki-badge.png&quot; alt=&quot;Ask DeepWiki.com&quot; height=&quot;20&quot;/&gt;](https://deepwiki.com/yeongpin/cursor-free-vip)

&lt;/p&gt;


&lt;a href=&quot;https://trendshift.io/repositories/13425&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13425&quot; alt=&quot;yeongpin%2Fcursor-free-vip | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;br&gt;

&lt;h4&gt;Support Latest 0.49.x Version | 支持最新 0.49.x 版本&lt;/h4&gt;

This tool is for educational purposes, currently the repo does not violate any laws. Please support the original project.
This tool will not generate any fake email accounts and OAuth access.

Supports Windows, macOS and Linux.

For optimal performance, run with privileges and always stay up to date.

這是一款用於學習和研究的工具，目前 repo 沒有違反任何法律。請支持原作者。
這款工具不會生成任何假的電子郵件帳戶和 OAuth 訪問。

支持 Windows、macOS 和 Linux。

對於最佳性能，請以管理員身份運行並始終保持最新。


&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/product_2025-04-16_10-40-21.png&quot; alt=&quot;new&quot; width=&quot;800&quot; style=&quot;border-radius: 6px;&quot;/&gt;&lt;br&gt;
&lt;/p&gt;

&lt;/div&gt;

## 🔄 Change Log | 更新日志

[Watch Change Log | 查看更新日志](CHANGELOG.md)

## ✨ Features | 功能特點

* Support Windows macOS and Linux systems&lt;br&gt;支持 Windows、macOS 和 Linux 系統&lt;br&gt;

* Reset Cursor&#039;s configuration&lt;br&gt;重置 Cursor 的配置&lt;br&gt;

* Multi-language support (English, 简体中文, 繁體中文, Vietnamese)&lt;br&gt;多語言支持（英文、简体中文、繁體中文、越南語）&lt;br&gt;

## 💻 System Support | 系統支持

| Operating System | Architecture      | Supported |
|------------------|-------------------|-----------|
| Windows          | x64, x86          | ✅         |
| macOS            | Intel, Apple Silicon | ✅      |
| Linux            | x64, x86, ARM64   | ✅         |

## 👀 How to use | 如何使用

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;⭐ Auto Run Script | 腳本自動化運行&lt;/b&gt;&lt;/summary&gt;

### **Linux/macOS**

```bash
curl -fsSL https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.sh -o install.sh &amp;&amp; chmod +x install.sh &amp;&amp; ./install.sh
```

### **Archlinux**

Install via [AUR](https://aur.archlinux.org/packages/cursor-free-vip-git)

```bash
yay -S cursor-free-vip-git
```

### **Windows**

```powershell
irm https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.ps1 | iex
```

&lt;/details&gt;

If you want to stop the script, please press Ctrl+C&lt;br&gt;要停止腳本，請按 Ctrl+C

## ❗ Note | 注意事項

📝 Config | 文件配置
`Win / Macos / Linux Path | 路徑 [Documents/.cursor-free-vip/config.ini]`
&lt;details&gt;
&lt;summary&gt;&lt;b&gt;⭐ Config | 文件配置&lt;/b&gt;&lt;/summary&gt;

```
[Chrome]
# Default Google Chrome Path | 默認Google Chrome 遊覽器路徑
chromepath = C:\Program Files\Google/Chrome/Application/chrome.exe

[Turnstile]
# Handle Turnstile Wait Time | 等待人機驗證時間
handle_turnstile_time = 2
# Handle Turnstile Wait Random Time (must merge 1-3 or 1,3) | 等待人機驗證隨機時間（必須是 1-3 或者 1,3 這樣的組合）
handle_turnstile_random_time = 1-3

[OSPaths]
# Storage Path | 存儲路徑
storage_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/storage.json
# SQLite Path | SQLite路徑
sqlite_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/state.vscdb
# Machine ID Path | 機器ID路徑
machine_id_path = /Users/username/Library/Application Support/Cursor/machineId
# For Linux users: ~/.config/cursor/machineid

[Timing]
# Min Random Time | 最小隨機時間
min_random_time = 0.1
# Max Random Time | 最大隨機時間
max_random_time = 0.8
# Page Load Wait | 頁面加載等待時間
page_load_wait = 0.1-0.8
# Input Wait | 輸入等待時間
input_wait = 0.3-0.8
# Submit Wait | 提交等待時間
submit_wait = 0.5-1.5
# Verification Code Input | 驗證碼輸入等待時間
verification_code_input = 0.1-0.3
# Verification Success Wait | 驗證成功等待時間
verification_success_wait = 2-3
# Verification Retry Wait | 驗證重試等待時間
verification_retry_wait = 2-3
# Email Check Initial Wait | 郵件檢查初始等待時間
email_check_initial_wait = 4-6
# Email Refresh Wait | 郵件刷新等待時間
email_refresh_wait = 2-4
# Settings Page Load Wait | 設置頁面加載等待時間
settings_page_load_wait = 1-2
# Failed Retry Time | 失敗重試時間
failed_retry_time = 0.5-1
# Retry Interval | 重試間隔
retry_interval = 8-12
# Max Timeout | 最大超時時間
max_timeout = 160

[Utils]
# Check Update | 檢查更新
check_update = True
# Show Account Info | 顯示賬號信息
show_account_info = True

[TempMailPlus]
# Enable TempMailPlus | 啓用 TempMailPlus（任何轉發到TempMailPlus的郵件都支持獲取驗證碼，例如cloudflare郵件Catch-all）
enabled = false
# TempMailPlus Email | TempMailPlus 電子郵件
email = xxxxx@mailto.plus
# TempMailPlus pin | TempMailPlus pin碼
epin = 

[WindowsPaths]
storage_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\storage.json
sqlite_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\state.vscdb
machine_id_path = C:\Users\yeongpin\AppData\Roaming\Cursor\machineId
cursor_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app
updater_path = C:\Users\yeongpin\AppData\Local\cursor-updater
update_yml_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app-update.yml
product_json_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app\product.json

[Browser]
default_browser = opera
chrome_path = C:\Program Files\Google\Chrome\Application\chrome.exe
edge_path = C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe
firefox_path = C:\Program Files\Mozilla Firefox\firefox.exe
brave_path = C:\Program Files\BraveSoftware/Brave-Browser/Application/brave.exe
chrome_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe
edge_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\msedgedriver.exe
firefox_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\geckodriver.exe
brave_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe
opera_path = C:\Users\yeongpin\AppData\Local\Programs\Opera\opera.exe
opera_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe

[OAuth]
show_selection_alert = False
timeout = 120
max_attempts = 3
```

&lt;/details&gt;

* Use administrator privileges to run the script &lt;br&gt;請使用管理員身份運行腳本

* Confirm that Cursor is closed before running the script &lt;br&gt;請確保在運行腳本前已經關閉 Cursor&lt;br&gt;

* This tool is only for learning and research purposes &lt;br&gt;此工具僅供學習和研究使用&lt;br&gt;

* Please comply with the relevant software usage terms when using this tool &lt;br&gt;使用本工具時請遵守相關軟件使用條款

## 🚨 Common Issues | 常見問題

|                   如果遇到權限問題，請確保：                    |                   此腳本以管理員身份運行                    |
|:--------------------------------------------------:|:------------------------------------------------:|
| If you encounter permission issues, please ensure: | This script is run with administrator privileges |
| Error &#039;User is not authorized&#039; | This means your account was banned for using temporary (disposal) mail. Ensure using a non-temporary mail service |
## 🤩 Contribution | 貢獻

歡迎提交 Issue 和 Pull Request！


&lt;a href=&quot;https://github.com/yeongpin/cursor-free-vip/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=yeongpin/cursor-free-vip&amp;preview=true&amp;max=&amp;columns=&quot; /&gt;
&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;

## 📩 Disclaimer | 免責聲明

本工具僅供學習和研究使用，使用本工具所產生的任何後果由使用者自行承擔。 &lt;br&gt;

This tool is only for learning and research purposes, and any consequences arising from the use of this tool are borne
by the user.

## 💰 Buy Me a Coffee | 請我喝杯咖啡

&lt;div align=&quot;center&quot;&gt;
  &lt;table&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;img src=&quot;./images/provi-code.jpg&quot; alt=&quot;buy_me_a_coffee&quot; width=&quot;280&quot;/&gt;&lt;br&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;img src=&quot;./images/paypal.png&quot; alt=&quot;buy_me_a_coffee&quot; width=&quot;280&quot;/&gt;&lt;br&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

## ⭐ Star History | 星星數

&lt;div align=&quot;center&quot;&gt;

[![Star History Chart](https://api.star-history.com/svg?repos=yeongpin/cursor-free-vip&amp;type=Date)](https://star-history.com/#yeongpin/cursor-free-vip&amp;Date)

&lt;/div&gt;

## 📝 License | 授權

本項目採用 [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/) 授權。
Please refer to the [LICENSE](LICENSE.md) file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[microsoft/agent-lightning]]></title>
            <link>https://github.com/microsoft/agent-lightning</link>
            <guid>https://github.com/microsoft/agent-lightning</guid>
            <pubDate>Tue, 28 Oct 2025 00:04:22 GMT</pubDate>
            <description><![CDATA[The absolute trainer to light up AI agents.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/agent-lightning">microsoft/agent-lightning</a></h1>
            <p>The absolute trainer to light up AI agents.</p>
            <p>Language: Python</p>
            <p>Stars: 2,837</p>
            <p>Forks: 215</p>
            <p>Stars today: 595 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;docs/assets/readme-banner.svg&quot; alt=&quot;Agent-lightning-banner&quot; style=&quot;width:600px&quot;/&gt;
&lt;/p&gt;

# Agent Lightning⚡

[![Test](https://github.com/microsoft/agent-lightning/actions/workflows/tests-full.yml/badge.svg)](https://github.com/microsoft/agent-lightning/actions/workflows/tests-full.yml)
[![Documentation](https://img.shields.io/badge/GitHub%20Pages-Documentation-blue)](https://microsoft.github.io/agent-lightning/)
[![PyPI version](https://badge.fury.io/py/agentlightning.svg)](https://badge.fury.io/py/agentlightning)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Discord](https://img.shields.io/badge/Discord-Join-5865F2?logo=discord&amp;logoColor=white)](https://discord.gg/RYk7CdvDR7)

**The absolute trainer to light up AI agents.**

Join our [Discord community](https://discord.gg/RYk7CdvDR7) to connect with other users and contributors.

## ⚡ Core Features

- Turn your agent into an optimizable beast with **ZERO CODE CHANGE** (almost)! 💤
- Build with **ANY** agent framework (LangChain, OpenAI Agent SDK, AutoGen, CrewAI, Microsoft Agent Framework...); or even WITHOUT agent framework (Python OpenAI). You name it! 🤖
- **Selectively** optimize one or more agents in a multi-agent system. 🎯
- Embraces **Algorithms** like Reinforcement Learning, Automatic Prompt Optimization, Supervised Fine-tuning and more. 🤗

Read more on our [documentation website](https://microsoft.github.io/agent-lightning/).

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;docs/assets/readme-diff.svg&quot; alt=&quot;Agent-Lightning Core Quickstart&quot; style=&quot;width:100%&quot;/&gt;
&lt;/p&gt;

## ⚡ Installation

```bash
pip install agentlightning
```

Please refer to our [installation guide](https://microsoft.github.io/agent-lightning/stable/tutorials/installation/) for more details.

To start using Agent-lightning, check out our [documentation](https://microsoft.github.io/agent-lightning/) and [examples](./examples).

## ⚡ Articles

- 10/22/2025 [No More Retokenization Drift: Returning Token IDs via the OpenAI Compatible API Matters in Agent RL](https://blog.vllm.ai/2025/10/22/agent-lightning.html) vLLM blog. See also [Zhihu writeup](https://zhuanlan.zhihu.com/p/1965067274642785725).
- 8/11/2025 [Training AI Agents to Write and Self-correct SQL with Reinforcement Learning](https://medium.com/@yugez/training-ai-agents-to-write-and-self-correct-sql-with-reinforcement-learning-571ed31281ad) Medium.
- 8/5/2025 [Agent Lightning: Train ANY AI Agents with Reinforcement Learning](https://arxiv.org/abs/2508.03680) arXiv paper.
- 7/26/2025 [We discovered an approach to train any AI agent with RL, with (almost) zero code changes.](https://www.reddit.com/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/) Reddit.
- 6/6/2025 [Agent Lightning - Microsoft Research](https://www.microsoft.com/en-us/research/project/agent-lightning/) Project page.

## ⚡ Community Projects

- [DeepWerewolf](https://github.com/af-74413592/DeepWerewolf) — A case study of agent RL training for the Chinese Werewolf game built with AgentScope and Agent Lightning.
- [AgentFlow](https://agentflow.stanford.edu/) — A modular multi-agent framework that combines planner, executor, verifier, and generator agents with the Flow-GRPO algorithm to tackle long-horizon, sparse-reward tasks.

## ⚡ Architecture

Agent Lightning keeps the moving parts to a minimum so you can focus on your idea, not the plumbing. Your agent continues to run as usual; you can still use any agent framework you like; you drop in the lightweight `agl.emit_xxx()` helper, or let the tracer collect every prompt, tool call, and reward. Those events become structured spans that flow into the LightningStore, a central hub that keeps tasks, resources, and traces in sync.

On the other side of the store sits the algorithm you choose, or write yourself. The algorithm reads spans, learns from them, and posts updated resources such as refined prompt templates or new policy weights. The Trainer ties it all together: it streams datasets to runners, ferries resources between the store and the algorithm, and updates the inference engine when improvements land. You can either stop there, or simply let the same loop keep turning.

No rewrites, no lock-in, just a clear path from first rollout to steady improvement.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;docs/assets/readme-architecture.svg&quot; alt=&quot;Agent-lightning Architecture&quot; style=&quot;width:100%&quot;/&gt;
&lt;/p&gt;

## ⚡ CI Status

| Workflow | Status |
|----------|--------|
| CPU Tests | [![tests workflow status](https://github.com/microsoft/agent-lightning/actions/workflows/tests.yml/badge.svg)](https://github.com/microsoft/agent-lightning/actions/workflows/tests.yml) |
| GPU Tests | [![tests-full workflow status](https://github.com/microsoft/agent-lightning/actions/workflows/tests-full.yml/badge.svg)](https://github.com/microsoft/agent-lightning/actions/workflows/tests-full.yml) |
| Examples Integration | [![examples summary workflow status](https://github.com/microsoft/agent-lightning/actions/workflows/badge-examples.yml/badge.svg)](https://github.com/microsoft/agent-lightning/actions/workflows/badge-examples.yml) |
| Latest Dependency Compatibility | [![latest summary workflow status](https://github.com/microsoft/agent-lightning/actions/workflows/badge-latest.yml/badge.svg)](https://github.com/microsoft/agent-lightning/actions/workflows/badge-latest.yml) |
| Legacy Examples Compatibility | [![examples compatibility workflow status](https://github.com/microsoft/agent-lightning/actions/workflows/examples-compat.yml/badge.svg)](https://github.com/microsoft/agent-lightning/actions/workflows/examples-compat.yml) |

## ⚡ Citation

If you find Agent Lightning useful in your research or projects, please cite our paper:

```bibtex
@misc{luo2025agentlightningtrainai,
      title={Agent Lightning: Train ANY AI Agents with Reinforcement Learning},
      author={Xufang Luo and Yuge Zhang and Zhiyuan He and Zilong Wang and Siyun Zhao and Dongsheng Li and Luna K. Qiu and Yuqing Yang},
      year={2025},
      eprint={2508.03680},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2508.03680},
}
```

## ⚡ Contributing

This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.

When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## ⚡ Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow [Microsoft&#039;s Trademark &amp; Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general). Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#039;s policies.

## ⚡ Responsible AI

This project has been evaluated and certified to comply with the Microsoft Responsible AI Standard. The team will continue to monitor and maintain the repository, addressing any severe issues, including potential harms, if they arise.

## ⚡ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[public-apis/public-apis]]></title>
            <link>https://github.com/public-apis/public-apis</link>
            <guid>https://github.com/public-apis/public-apis</guid>
            <pubDate>Tue, 28 Oct 2025 00:04:21 GMT</pubDate>
            <description><![CDATA[A collective list of free APIs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/public-apis/public-apis">public-apis/public-apis</a></h1>
            <p>A collective list of free APIs</p>
            <p>Language: Python</p>
            <p>Stars: 373,738</p>
            <p>Forks: 39,444</p>
            <p>Stars today: 617 stars today</p>
            <h2>README</h2><pre># Try Public APIs for free
The Public APIs repository is manually curated by community members like you and folks working at [APILayer](https://apilayer.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo). It includes an extensive list of public APIs from many domains that you can use for your own products. Consider it a treasure trove of APIs well-managed by the community over the years.

&lt;br &gt;

&lt;p&gt;
    &lt;a href=&quot;https://apilayer.com&quot;&gt;
        &lt;div&gt;
            &lt;img src=&quot;.github/cs1586-APILayerLogoUpdate2022-LJ_v2-HighRes.png&quot; width=&quot;100%&quot; alt=&quot;APILayer Logo&quot; /&gt;
        &lt;/div&gt;
    &lt;/a&gt;
  &lt;/p&gt;

APILayer is the fastest way to integrate APIs into any product. Explore [APILayer APIs](https://apilayer.com/products/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo) here for your next project.

Join our [Discord server](https://discord.com/invite/hgjA78638n/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo) to get updates, ask questions, get answers, random community calls, and more.

&lt;br &gt;

## APILayer APIs
| API | Description | Call this API |
|:---|:---|:---|
| [IPstack](https://ipstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Locate and Identify Website Visitors by IP Address | [&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-55145132-244c-448c-8e6f-8780866e4862?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-55145132-244c-448c-8e6f-8780866e4862%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Marketstack](https://marketstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Free, easy-to-use REST API interface delivering worldwide stock market data in JSON format | [&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-9cbac391-3611-4f50-9bfd-d24ae41c97c1?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-9cbac391-3611-4f50-9bfd-d24ae41c97c1%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Weatherstack](https://weatherstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Retrieve instant, accurate weather information for any location in the world in lightweight JSON format | [&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-276c4312-f682-425d-b6b1-0f82c0a7f2b3?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-276c4312-f682-425d-b6b1-0f82c0a7f2b3%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Numverify](https://numverify.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers ) | Global Phone Number Validation &amp; Lookup JSON API |[&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-0760d25e-b802-412e-b0e4-26e5ca3b9ffa?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-0760d25e-b802-412e-b0e4-26e5ca3b9ffa%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Fixer](https://fixer.io/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Fixer is a simple and lightweight API for current and historical foreign exchange (forex) rates. |[&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-0d9c66b3-5f1a-42ed-a5ca-379217bd629d?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-0d9c66b3-5f1a-42ed-a5ca-379217bd629d%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Aviationstack](https://avaitionstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Free, real-time flight status and global Aviation data API |[&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-72ee0d35-018e-4370-a2b6-a66d3ebd5b5a?action=collection/fork)|

&lt;br &gt;

## Learn more about Public APIs

&lt;strong&gt;Get Involved&lt;/strong&gt;

* [Contributing Guide](CONTRIBUTING.md)
* [API for this project](https://github.com/davemachado/public-api)
* [Issues](https://github.com/public-apis/public-apis/issues)
* [Pull Requests](https://github.com/public-apis/public-apis/pulls)
* [LICENSE](LICENSE) 

&lt;br /&gt;

## Index

* [Animals](#animals)
* [Anime](#anime)
* [Anti-Malware](#anti-malware)
* [Art &amp; Design](#art--design)
* [Authentication &amp; Authorization](#authentication--authorization)
* [Blockchain](#blockchain)
* [Books](#books)
* [Business](#business)
* [Calendar](#calendar)
* [Cloud Storage &amp; File Sharing](#cloud-storage--file-sharing)
* [Continuous Integration](#continuous-integration)
* [Cryptocurrency](#cryptocurrency)
* [Currency Exchange](#currency-exchange)
* [Data Validation](#data-validation)
* [Development](#development)
* [Dictionaries](#dictionaries)
* [Documents &amp; Productivity](#documents--productivity)
* [Email](#email)
* [Entertainment](#entertainment)
* [Environment](#environment)
* [Events](#events)
* [Finance](#finance)
* [Food &amp; Drink](#food--drink)
* [Games &amp; Comics](#games--comics)
* [Geocoding](#geocoding)
* [Government](#government)
* [Health](#health)
* [Jobs](#jobs)
* [Machine Learning](#machine-learning)
* [Music](#music)
* [News](#news)
* [Open Data](#open-data)
* [Open Source Projects](#open-source-projects)
* [Patent](#patent)
* [Personality](#personality)
* [Phone](#phone)
* [Photography](#photography)
* [Programming](#programming)
* [Science &amp; Math](#science--math)
* [Security](#security)
* [Shopping](#shopping)
* [Social](#social)
* [Sports &amp; Fitness](#sports--fitness)
* [Test Data](#test-data)
* [Text Analysis](#text-analysis)
* [Tracking](#tracking)
* [Transportation](#transportation)
* [URL Shorteners](#url-shorteners)
* [Vehicle](#vehicle)
* [Video](#video)
* [Weather](#weather)
&lt;br &gt;

### Animals
API | Description | Auth | HTTPS | CORS 
|:---|:---|:---|:---|:---|
| [AdoptAPet](https://www.adoptapet.com/public/apis/pet_list.html) | Resource to help get pets adopted | `apiKey` | Yes | Yes |
| [Axolotl](https://theaxolotlapi.netlify.app/) | Collection of axolotl pictures and facts | No | Yes | No |
| [Cat Facts](https://alexwohlbruck.github.io/cat-facts/) | Daily cat facts | No | Yes | No | |
| [Cataas](https://cataas.com/) | Cat as a service (cats pictures and gifs) | No | Yes | No |
| [Cats](https://docs.thecatapi.com/) | Pictures of cats from Tumblr | `apiKey` | Yes | No |
| [Dog Facts](https://dukengn.github.io/Dog-facts-API/) | Random dog facts | No | Yes | Yes |
| [Dog Facts](https://kinduff.github.io/dog-api/) | Random facts of Dogs | No | Yes | Yes |
| [Dogs](https://dog.ceo/dog-api/) | Based on the Stanford Dogs Dataset | No | Yes | Yes |
| [eBird](https://documenter.getpostman.com/view/664302/S1ENwy59) | Retrieve recent or notable birding observations within a region | `apiKey` | Yes | No |
| [FishWatch](https://www.fishwatch.gov/developers) | Information and pictures about individual fish species | No | Yes | Yes |
| [HTTP Cat](https://http.cat/) | Cat for every HTTP Status | No | Yes | Yes |
| [HTTP Dog](https://http.dog/) | Dogs for every HTTP response status code | No | Yes | Yes |
| [IUCN](http://apiv3.iucnredlist.org/api/v3/docs) | IUCN Red List of Threatened Species | `apiKey` | No | No |
| [MeowFacts](https://github.com/wh-iterabb-it/meowfacts) | Get random cat facts | No | Yes | No |
| [Movebank](https://github.com/movebank/movebank-api-doc) | Movement and Migration data of animals | No | Yes | Yes |
| [Petfinder](https://www.petfinder.com/developers/) | Petfinder is dedicated to helping pets find homes, another resource to get pets adopted | `apiKey` | Yes | Yes |
| [PlaceBear](https://placebear.com/) | Placeholder bear pictures | No | Yes | Yes |
| [PlaceDog](https://place.dog) | Placeholder Dog pictures | No | Yes | Yes |
| [PlaceKitten](https://placekitten.com/) | Placeholder Kitten pictures | No | Yes | Yes |
| [RandomDog](https://random.dog/woof.json) | Random pictures of dogs | No | Yes | Yes |
| [RandomDuck](https://random-d.uk/api) | Random pictures of ducks | No | Yes | No |
| [RandomFox](https://randomfox.ca/floof/) | Random pictures of foxes | No | Yes | No |
| [RescueGroups](https://userguide.rescuegroups.org/display/APIDG/API+Developers+Guide+Home) | Adoption | No | Yes | Unknown |
| [Shibe.Online](http://shibe.online/) | Random pictures of Shiba Inu, cats or birds | No | Yes | Yes |
| [The Dog](https://thedogapi.com/) | A public service all about Dogs, free to use when making your fancy new App, Website or Service | `apiKey` | Yes | No |
| [xeno-canto](https://xeno-canto.org/explore/api) | Bird recordings | No | Yes | Unknown |
| [Zoo Animals](https://zoo-animal-api.herokuapp.com/) | Facts and pictures of zoo animals | No | Yes | Yes |

**[⬆ Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;

### Anime
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [AniAPI](https://aniapi.com/docs/) | Anime discovery, streaming &amp; syncing with trackers | `OAuth` | Yes | Yes |
| [AniDB](https://wiki.anidb.net/HTTP_API_Definition) | Anime Database | `apiKey` | No | Unknown |
| [AniList](https://github.com/AniList/ApiV2-GraphQL-Docs) | Anime discovery &amp; tracking | `OAuth` | Yes | Unknown |
| [AnimeChan](https://github.com/RocktimSaikia/anime-chan) | Anime quotes (over 10k+) | No | Yes | No |
| [AnimeFacts](https://chandan-02.github.io/anime-facts-rest-api/) | Anime Facts (over 100+) | No | Yes | Yes |
| [AnimeNewsNetwork](https://www.animenewsnetwork.com/encyclopedia/api.php) | Anime industry news | No | Yes | Yes |
| [Catboy](https://catboys.com/api) | Neko images, funny GIFs &amp; more | No | Yes | Yes |
| [Danbooru Anime](https://danbooru.donmai.us/wiki_pages/help:api) | Thousands of anime artist database to find good anime art | `apiKey` | Yes | Yes |
| [Jikan](https://jikan.moe) | Unofficial MyAnimeList API | No | Yes | Yes |
| [Kitsu](https://kitsu.docs.apiary.io/) | Anime discovery platform | `OAuth` | Yes | Yes |
| [MangaDex](https://api.mangadex.org/docs.html) | Manga Database and Community | `apiKey` | Yes | Unknown |
| [Mangapi](https://rapidapi.com/pierre.carcellermeunier/api/mangapi3/) | Translate manga pages from one language to another | `apiKey` | Yes | Unknown |
| [MyAnimeList](https://myanimelist.net/clubs.php?cid=13727) | Anime and Manga Database and Community | `OAuth` | Yes | Unknown |
| [NekosBest](https://docs.nekos.best) | Neko Images &amp; Anime roleplaying GIFs | No | Yes | Yes |
| [Shikimori](https://shikimori.one/api/doc) | Anime discovery, tracking, forum, rates | `OAuth` | Yes | Unknown |
| [Studio Ghibli](https://ghibliapi.herokuapp.com) | Resources from Studio Ghibli films | No | Yes | Yes |
| [Trace Moe](https://soruly.github.io/trace.moe-api/#/) | A useful tool to get the exact scene of an anime from a screenshot | No | Yes | No |
| [Waifu.im](https://waifu.im/docs) | Get waifu pictures from an archive of over 4000 images and multiple tags | No | Yes | Yes |
| [Waifu.pics](https://waifu.pics/docs) | Image sharing platform for anime images | No | Yes | No |

**[⬆ Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;

### Anti-Malware
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [AbuseIPDB](https://docs.abuseipdb.com/) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |
| [AlienVault Open Threat Exchange (OTX)](https://otx.alienvault.com/api) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |
| [CAPEsandbox](https://capev2.readthedocs.io/en/latest/usage/api.html) | Malware execution and analysis | `apiKey` | Yes | Unknown |
| [Google Safe Browsing](https://developers.google.com/safe-browsing/) | Google Link/Domain Flagging | `apiKey` | Yes | Unknown |
| [MalDatabase](https://maldatabase.com/api-doc.html) | Provide malware datasets and threat intelligence feeds | `apiKey` | Yes | Unknown |
| [MalShare](https://malshare.com/doc.php) | Malware Archive / file sourcing | `apiKey` | Yes | No |
| [MalwareBazaar](https://bazaar.abuse.ch/api/) | Collect and share malware samples | `apiKey` | Yes | Unknown |
| [Metacert](https://metacert.com/) | Metacert Link Flagging | `apiKey` | Yes | Unknown |
| [NoPhishy](https://rapidapi.com/Amiichu/api/exerra-phishing-check/) | Check links to see if they&#039;re known phishing attempts | `apiKey` | Yes | Yes |
| [Phisherman](https://phisherman.gg/) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |
| [Scanii](https://docs.scanii.com/) | Simple REST API that can scan submitted documents/files for the presence of threats | `apiKey` | Yes | Yes |
| [URLhaus](https://urlhaus-api.abuse.ch/) | Bulk queries and Download Malware Samples | No | Yes | Yes |
| [URLScan.io](https://urlscan.io/about-api/) | Scan and Analyse URLs | `apiKey` | Yes | Unknown |
| [VirusTotal](https://www.virustotal.com/en/documentation/public-api/) | VirusTotal File/URL Analysis | `apiKey` | Yes | Unknown |
| [Web of Trust](https://support.mywot.com/hc/en-us/sections/360004477734-API-) | IP/domain/URL reputation | `apiKey` | Yes | Unknown | 

**[⬆ Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Art &amp; Design
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [Améthyste](https://api.amethyste.moe/) | Generate images for Discord users | `apiKey` | Yes | Unknown |
| [Art Institute of Chicago](https://api.artic.edu/docs/) | Art | No | Yes | Yes |
| [Colormind](http://colormind.io/api-access/) | Color scheme generator | No | No | Unknown |
| [ColourLovers](http://www.colourlovers.com/api) | Get various patterns, palettes and images | No | No | Unknown |
| [Cooper Hewitt](https://collection.cooperhewitt.org/api) | Smithsonian Design Museum | `apiKey` | Yes | Unknown |
| [Dribbble](https://developer.dribbble.com) | Discover the world’s top designers &amp; creatives | `OAuth` | Yes | Unknown |
| [EmojiHub](https://github.com/cheatsnake/emojihub) | Get emojis by categories and groups | No | Yes | Yes |
| [Europeana](https://pro.europeana.eu/resources/apis/search) | European Museum and Galleries content | `apiKey` | Yes | Unknown |
| [Harvard Art Museums](https://github.com/harvardartmuseums/api-docs) | Art | `apiKey` | No | Unknown |
| [Icon Horse](https://icon.horse) | Favicons for any website, with fallbacks | No | Yes | Yes |
| [Iconfinder](https://developer.iconfinder.com) | Icons | `apiKey` | Yes | Unknown |
| [Icons8](https://img.icons8.com/) | Icons (find &quot;search icon&quot; hyperlink in page) | No | Yes | Unknown |
| [Lordicon](https://lordicon.com/) | Icons with predone Animations | No | Yes | Yes |
| [Metropolitan Museum of Art](https://metmuseum.github.io/) | Met Museum of Art | No | Yes | No |
| [Noun Project](http://api.thenounproject.com/index.html) | Icons | `OAuth` | No | Unknown |
| [PHP-Noise](https://php-noise.com/) | Noise Background Image Generator | No | Yes | Yes |
| [Pixel Encounter](https://pixelencounter.com/api) | SVG Icon Generator | No | Yes | No |
| [Rijksmuseum](https://data.rijksmuseum.nl/object-metadata/api/) | RijksMuseum Data | `apiKey` | Yes | Unknown |
| [Word Cloud](https://wordcloudapi.com/) | Easily create word clouds | `apiKey` | Yes | Unknown |
| [xColors](https://x-colors.herokuapp.com/) | Generate &amp; convert colors | No | Yes | Yes |

**[⬆ Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Authentication &amp; Authorization
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [Auth0](https://auth0.com) | Easy to implement, adaptable authentication and authorization platform | `apiKey` | Yes | Yes |
| [GetOTP](https://otp.dev/en/docs/) | Implement OTP flow quickly | `apiKey` | Yes | No |
| [Micro User Service](https://m3o.com/user) | User management and authentication | `apiKey` | Yes | No |
| [MojoAuth](https://mojoauth.com) | Secure and modern passwordless authentication platform | `apiKey` | Yes | Yes |
| [SAWO Labs](https://sawolabs.com) | Simplify login and improve user experience by integrating passwordless authentication in your app | `apiKey` | Yes | Yes |
| [Stytch](https://stytch.com/) | User infrastructure for modern applications | `apiKey` | Yes | No |
| [Warrant](https://warrant.dev/) | APIs for authorization and access control | `apiKey` | Yes | Yes |

**[⬆ Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Blockchain
| API | Description | Auth | HTTPS | CORS |
|---|:---|:---|:---|:---|
| [Bitquery](https://graphql.bitquery.io/ide) | Onchain GraphQL APIs &amp; DEX APIs | `apiKey` | Yes | Yes |
| [Chainlink](https://chain.link/developer-resources) | Build hybrid smart contracts with Chainlink | No | Yes | Unknown |
| [Chainpoint](https://tierion.com/chainpoint/) | Chainpoint is a global network for anchoring data to the Bitcoin blockchain | No | Yes | Unknown |
| [Covalent](https://www.covalenthq.com/docs/api/) | Multi-blockchain data aggregator platform | `apiKey` | Yes | Unknown |
| [Etherscan](https://etherscan.io/apis) | Ethereum explorer API | `apiKey` | Yes | Yes |
| [Helium](https://docs.helium.com/api/blockchain/introduction/) | Helium is a global, distributed network of Hotspots that create public, long-range wireless coverage | No | Yes | Unknown |
| [Nownodes](https://nownodes.io/) | Blockchain-as-a-service solution that provides high-quality connection via API | `apiKey` | Yes | Unknown |
| [Steem](https://developers.steem.io/) | Blockchain-based blogging and social media website | No | No | No |
| [The Graph](https://thegraph.com) | Indexing protocol for querying networks like Ethereum with GraphQL | `apiKey` | Yes | Unknown |
| [Walltime](https://walltime.info/api.html) | To retrieve Walltime&#039;s market info | No | Yes | Unknown |
| [Watchdata](https://docs.watchdata.io) | Provide simple and reliable API access to Ethereum blockchain | `apiKey` | Yes | Unknown |

**[⬆ Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Books
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [A Bíblia Digital](https://www.abibliadigital.com.br/en) | Do not worry about managing the multiple versions of the Bible | `apiKey` | Yes | No |
| [Bhagavad Gita](https://docs.bhagavadgitaapi.in) | Open Source Shrimad Bhagavad Gita API including 21+ authors translation in Sanskrit/English/Hindi | `apiKey` | Yes | Yes |
| [Bhagavad Gita](https://bhagavadgita.io/api) | Bhagavad Gita text | `OAuth` | Yes | Yes |
| [Bhagavad Gita telugu](https://gita-api.vercel.app) | Bhagavad Gita API in telugu and odia languages | No | Yes | Yes |
| [Bible-api](https://bible-api.com/) | Free Bible API with multiple languages | No | Yes | Yes |
| [British National Bibliography](http://bnb.data.bl.uk/) | Books | No | No | Unknown |
| [Crossref Metadata Search](https://github.com/CrossRef/rest-api-doc) | Books &amp; Articles Metadata | No | Yes | Unknown |
| [Ganjoor](https://api.ganjoor.net) | Classic Persian poetry works including access to related manuscripts, recitations and music tracks | `OAuth` | Yes | Yes |
| [Google Books](https://developers.google.com/books/) | Books | `OAuth` | Yes | Unknown |
| [GurbaniNow](https://github.com/GurbaniNow/api) | Fast and Accurate Gurbani RESTful API | No | Yes | Unknown |
| [Gutendex](https://gutendex.com/) | Web-API for fetching data from Project Gutenberg Books Library | No | Yes | Unknown |
| [Open Library](https://openlibrary.org/developers/api) | Books, book covers and related data | No | Yes | No |
| [Penguin Publishing](http://www.penguinrandomhouse.biz/webservices/rest/) | Books, book covers and related data | No | Yes | Yes |
| [PoetryDB](https://github.com/thundercomb/poetrydb#readme) | Enables you to get instant data from our vast p

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Shubhamsaboo/awesome-llm-apps]]></title>
            <link>https://github.com/Shubhamsaboo/awesome-llm-apps</link>
            <guid>https://github.com/Shubhamsaboo/awesome-llm-apps</guid>
            <pubDate>Tue, 28 Oct 2025 00:04:20 GMT</pubDate>
            <description><![CDATA[Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Shubhamsaboo/awesome-llm-apps">Shubhamsaboo/awesome-llm-apps</a></h1>
            <p>Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.</p>
            <p>Language: Python</p>
            <p>Stars: 73,572</p>
            <p>Forks: 9,570</p>
            <p>Stars today: 408 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;http://www.theunwindai.com&quot;&gt;
    &lt;img src=&quot;docs/banner/unwind_black.png&quot; width=&quot;900px&quot; alt=&quot;Unwind AI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.linkedin.com/in/shubhamsaboo/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-Follow%20Shubham%20Saboo-blue?logo=linkedin&amp;style=flat-square&quot; alt=&quot;LinkedIn&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/Saboo_Shubham_&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/twitter/follow/Shubham_Saboo&quot; alt=&quot;Twitter&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=de&quot;&gt;Deutsch&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=es&quot;&gt;Español&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=fr&quot;&gt;français&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ja&quot;&gt;日本語&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ko&quot;&gt;한국어&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=pt&quot;&gt;Português&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ru&quot;&gt;Русский&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=zh&quot;&gt;中文&lt;/a&gt;
&lt;/p&gt;

&lt;hr/&gt;

# 🌟 Awesome LLM Apps

A curated collection of **Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.** This repository features LLM apps that use models from &lt;img src=&quot;https://cdn.simpleicons.org/openai&quot;  alt=&quot;openai logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**OpenAI** , &lt;img src=&quot;https://cdn.simpleicons.org/anthropic&quot;  alt=&quot;anthropic logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**Anthropic**, &lt;img src=&quot;https://cdn.simpleicons.org/googlegemini&quot;  alt=&quot;google logo&quot; width=&quot;25&quot; height=&quot;18&quot;&gt;**Google**, &lt;img src=&quot;https://cdn.simpleicons.org/x&quot;  alt=&quot;X logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**xAI** and open-source models like &lt;img src=&quot;https://cdn.simpleicons.org/alibabacloud&quot;  alt=&quot;alibaba logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**Qwen** or  &lt;img src=&quot;https://cdn.simpleicons.org/meta&quot;  alt=&quot;meta logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**Llama** that you can run locally on your computer.

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/9876&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/9876&quot; alt=&quot;Shubhamsaboo%2Fawesome-llm-apps | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## 🤔 Why Awesome LLM Apps?

- 💡 Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.
- 🔥 Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with AI Agents, Agent Teams, MCP &amp; RAG.
- 🎓 Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.

## 🙏 Thanks to our sponsors

&lt;table align=&quot;center&quot; cellpadding=&quot;16&quot; cellspacing=&quot;12&quot;&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://getunblocked.com/unblocked-mcp/?utm_source=oss&amp;utm_medium=sponsorship&amp;utm_campaign=awesome-llm-apps&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; title=&quot;Unblocked&quot;&gt;
        &lt;img src=&quot;docs/banner/sponsors/unblocked.png&quot; alt=&quot;Unblocked&quot; width=&quot;500&quot;&gt;
      &lt;/a&gt;
      &lt;br&gt;
      &lt;a href=&quot;https://getunblocked.com/unblocked-mcp/?utm_source=oss&amp;utm_medium=sponsorship&amp;utm_campaign=awesome-llm-apps&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; style=&quot;text-decoration: none; color: #333; font-weight: bold; font-size: 18px;&quot;&gt;
        Unblocked
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://sponsorunwindai.com/&quot; title=&quot;Parlant&quot;&gt;
        &lt;img src=&quot;docs/banner/sponsor_awesome_llm_apps.png&quot; alt=&quot;Parlant&quot; width=&quot;500&quot;&gt;
      &lt;/a&gt;
      &lt;br&gt;
      &lt;a href=&quot;https://sponsorunwindai.com/&quot; style=&quot;text-decoration: none; color: #333; font-weight: bold; font-size: 18px;&quot;&gt;
        Become a Sponsor
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## 📂 Featured AI Projects

### AI Agents

### 🌱 Starter AI Agents

*   [🎙️ AI Blog to Podcast Agent](starter_ai_agents/ai_blog_to_podcast_agent/)
*   [❤️‍🩹 AI Breakup Recovery Agent](starter_ai_agents/ai_breakup_recovery_agent/)
*   [📊 AI Data Analysis Agent](starter_ai_agents/ai_data_analysis_agent/)
*   [🩻 AI Medical Imaging Agent](starter_ai_agents/ai_medical_imaging_agent/)
*   [😂 AI Meme Generator Agent (Browser)](starter_ai_agents/ai_meme_generator_agent_browseruse/)
*   [🎵 AI Music Generator Agent](starter_ai_agents/ai_music_generator_agent/)
*   [🛫 AI Travel Agent (Local &amp; Cloud)](starter_ai_agents/ai_travel_agent/)
*   [✨ Gemini Multimodal Agent](starter_ai_agents/gemini_multimodal_agent_demo/)
*   [🌐 Local News Agent (OpenAI Swarm)](starter_ai_agents/local_news_agent_openai_swarm/)
*   [🔄 Mixture of Agents](starter_ai_agents/mixture_of_agents/)
*   [📊 xAI Finance Agent](starter_ai_agents/xai_finance_agent/)
*   [🔍 OpenAI Research Agent](starter_ai_agents/opeani_research_agent/)
*   [🕸️ Web Scrapping AI Agent (Local &amp; Cloud)](starter_ai_agents/web_scrapping_ai_agent/)

### 🚀 Advanced AI Agents
*   [🏚️ 🍌 AI Home Renovation Agent with Nano Banana](advanced_ai_agents/multi_agent_apps/ai_home_renovation_agent)
*   [🔍 AI Deep Research Agent](advanced_ai_agents/single_agent_apps/ai_deep_research_agent/)
*   [🤝 AI Consultant Agent](advanced_ai_agents/single_agent_apps/ai_consultant_agent)
*   [🏗️ AI System Architect Agent](advanced_ai_agents/single_agent_apps/ai_system_architect_r1/)
*   [🎯 AI Lead Generation Agent](advanced_ai_agents/single_agent_apps/ai_lead_generation_agent/)
*   [💰 AI Financial Coach Agent](advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/)
*   [🎬 AI Movie Production Agent](advanced_ai_agents/single_agent_apps/ai_movie_production_agent/)
*   [📈 AI Investment Agent](advanced_ai_agents/single_agent_apps/ai_investment_agent/)
*   [🏋️‍♂️ AI Health &amp; Fitness Agent](advanced_ai_agents/single_agent_apps/ai_health_fitness_agent/)
*   [🚀 AI Product Launch Intelligence Agent](advanced_ai_agents/multi_agent_apps/product_launch_intelligence_agent)
*   [🗞️ AI Journalist Agent](advanced_ai_agents/single_agent_apps/ai_journalist_agent/)
*   [🧠 AI Mental Wellbeing Agent](advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/)
*   [📑 AI Meeting Agent](advanced_ai_agents/single_agent_apps/ai_meeting_agent/)
*   [🧬 AI Self-Evolving Agent](advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/)
*   [🎧 AI Social Media News and Podcast Agent](advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/)

### 🎮 Autonomous Game Playing Agents

*   [🎮 AI 3D Pygame Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/)
*   [♜ AI Chess Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/)
*   [🎲 AI Tic-Tac-Toe Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/)

### 🤝 Multi-agent Teams

*   [🧲 AI Competitor Intelligence Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/)
*   [💲 AI Finance Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/)
*   [🎨 AI Game Design Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/)
*   [👨‍⚖️ AI Legal Agent Team (Cloud &amp; Local)](advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/)
*   [💼 AI Recruitment Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/)
*   [🏠 AI Real Estate Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_real_estate_agent_team)
*   [👨‍💼 AI Services Agency (CrewAI)](advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/)
*   [👨‍🏫 AI Teaching Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/)
*   [💻 Multimodal Coding Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/)
*   [✨ Multimodal Design Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/)
*   [🎨 🍌 Multimodal UI/UX Feedback Agent Team with Nano Banana](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_uiux_feedback_agent_team/)
*   [🌏 AI Travel Planner Agent Team](/advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/)

### 🗣️ Voice AI Agents

*   [🗣️ AI Audio Tour Agent](voice_ai_agents/ai_audio_tour_agent/)
*   [📞 Customer Support Voice Agent](voice_ai_agents/customer_support_voice_agent/)
*   [🔊 Voice RAG Agent (OpenAI SDK)](voice_ai_agents/voice_rag_openaisdk/)


### &lt;img src=&quot;https://cdn.simpleicons.org/modelcontextprotocol&quot;  alt=&quot;mcp logo&quot; width=&quot;25&quot; height=&quot;20&quot;&gt; MCP AI Agents 

*   [♾️ Browser MCP Agent](mcp_ai_agents/browser_mcp_agent/)
*   [🐙 GitHub MCP Agent](mcp_ai_agents/github_mcp_agent/)
*   [📑 Notion MCP Agent](mcp_ai_agents/notion_mcp_agent) 
*   [🌍 AI Travel Planner MCP Agent](mcp_ai_agents/ai_travel_planner_mcp_agent_team)

### 📀 RAG (Retrieval Augmented Generation)
*   [🔥 Agentic RAG with Embedding Gemma](rag_tutorials/agentic_rag_embedding_gemma)
*   [🧐 Agentic RAG with Reasoning](rag_tutorials/agentic_rag_with_reasoning/)
*   [📰 AI Blog Search (RAG)](rag_tutorials/ai_blog_search/)
*   [🔍 Autonomous RAG](rag_tutorials/autonomous_rag/)
*   [🔄 Contextual AI RAG Agent](rag_tutorials/contextualai_rag_agent/)
*   [🔄 Corrective RAG (CRAG)](rag_tutorials/corrective_rag/)
*   [🐋 Deepseek Local RAG Agent](rag_tutorials/deepseek_local_rag_agent/)
*   [🤔 Gemini Agentic RAG](rag_tutorials/gemini_agentic_rag/)
*   [👀 Hybrid Search RAG (Cloud)](rag_tutorials/hybrid_search_rag/)
*   [🔄 Llama 3.1 Local RAG](rag_tutorials/llama3.1_local_rag/)
*   [🖥️ Local Hybrid Search RAG](rag_tutorials/local_hybrid_search_rag/)
*   [🦙 Local RAG Agent](rag_tutorials/local_rag_agent/)
*   [🧩 RAG-as-a-Service](rag_tutorials/rag-as-a-service/)
*   [✨ RAG Agent with Cohere](rag_tutorials/rag_agent_cohere/)
*   [⛓️ Basic RAG Chain](rag_tutorials/rag_chain/)
*   [📠 RAG with Database Routing](rag_tutorials/rag_database_routing/)
*   [🖼️ Vision RAG](rag_tutorials/vision_rag/)

### 💾 LLM Apps with Memory Tutorials

*   [💾 AI ArXiv Agent with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/ai_arxiv_agent_memory/)
*   [🛩️ AI Travel Agent with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/ai_travel_agent_memory/)
*   [💬 Llama3 Stateful Chat](advanced_llm_apps/llm_apps_with_memory_tutorials/llama3_stateful_chat/)
*   [📝 LLM App with Personalized Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/llm_app_personalized_memory/)
*   [🗄️ Local ChatGPT Clone with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/local_chatgpt_with_memory/)
*   [🧠 Multi-LLM Application with Shared Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/multi_llm_memory/)


### 💬 Chat with X Tutorials

*   [💬 Chat with GitHub (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_github/)
*   [📨 Chat with Gmail](advanced_llm_apps/chat_with_X_tutorials/chat_with_gmail/)
*   [📄 Chat with PDF (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_pdf/)
*   [📚 Chat with Research Papers (ArXiv) (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_research_papers/)
*   [📝 Chat with Substack](advanced_llm_apps/chat_with_X_tutorials/chat_with_substack/)
*   [📽️ Chat with YouTube Videos](advanced_llm_apps/chat_with_X_tutorials/chat_with_youtube_videos/)

### 🔧 LLM Fine-tuning Tutorials

* &lt;img src=&quot;https://cdn.simpleicons.org/google&quot;  alt=&quot;google logo&quot; width=&quot;20&quot; height=&quot;15&quot;&gt; [Gemma 3 Fine-tuning](advanced_llm_apps/llm_finetuning_tutorials/gemma3_finetuning/)
* &lt;img src=&quot;https://cdn.simpleicons.org/meta&quot;  alt=&quot;meta logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt; [Llama 3.2 Fine-tuning](advanced_llm_apps/llm_finetuning_tutorials/llama3.2_finetuning/)


### 🧑‍🏫 AI Agent Framework Crash Course

&lt;img src=&quot;https://cdn.simpleicons.org/google&quot;  alt=&quot;google logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt; [Google ADK Crash Course](ai_agent_framework_crash_course/google_adk_crash_course/)
  - Starter agent; model‑agnostic (OpenAI, Claude)
  - Structured outputs (Pydantic)
  - Tools: built‑in, function, third‑party, MCP tools
  - Memory; callbacks; Plugins
  - Simple multi‑agent; Multi‑agent patterns

&lt;img src=&quot;https://cdn.simpleicons.org/openai&quot;  alt=&quot;openai logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt; [OpenAI Agents SDK Crash Course](ai_agent_framework_crash_course/openai_sdk_crash_course/)
  - Starter agent; function calling; structured outputs
  - Tools: built‑in, function, third‑party integrations
  - Memory; callbacks; evaluation
  - Multi‑agent patterns; agent handoffs
  - Swarm orchestration; routing logic

## 🚀 Getting Started

1. **Clone the repository** 

    ```bash 
    git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git 
    ```

2. **Navigate to the desired project directory**

    ```bash 
    cd awesome-llm-apps/starter_ai_agents/ai_travel_agent
    ```

3. **Install the required dependencies**

    ```bash
    pip install -r requirements.txt
    ```

4. **Follow the project-specific instructions** in each project&#039;s `README.md` file to set up and run the app.


### &lt;img src=&quot;https://cdn.simpleicons.org/github&quot;  alt=&quot;github logo&quot; width=&quot;25&quot; height=&quot;20&quot;&gt; Thank You, Community, for the Support! 🙏

[![Star History Chart](https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&amp;type=Date)](https://star-history.com/#Shubhamsaboo/awesome-llm-apps&amp;Date)

🌟 **Don’t miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.**
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[harvard-edge/cs249r_book]]></title>
            <link>https://github.com/harvard-edge/cs249r_book</link>
            <guid>https://github.com/harvard-edge/cs249r_book</guid>
            <pubDate>Tue, 28 Oct 2025 00:04:19 GMT</pubDate>
            <description><![CDATA[Introduction to Machine Learning Systems]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/harvard-edge/cs249r_book">harvard-edge/cs249r_book</a></h1>
            <p>Introduction to Machine Learning Systems</p>
            <p>Language: Python</p>
            <p>Stars: 6,667</p>
            <p>Forks: 664</p>
            <p>Stars today: 1,036 stars today</p>
            <h2>README</h2><pre># Machine Learning Systems
*Principles and Practices of Engineering Artificially Intelligent Systems*

&lt;div align=&quot;center&quot;&gt;
  
&lt;p align=&quot;center&quot;&gt;

  &lt;!-- Row 1: Project Health --&gt;
  [![Build](https://img.shields.io/github/actions/workflow/status/harvard-edge/cs249r_book/validate-dev.yml?branch=dev&amp;label=Build&amp;logo=githubactions&amp;cacheSeconds=300)](https://github.com/harvard-edge/cs249r_book/actions/workflows/validate-dev.yml)
  ![Last Commit](https://img.shields.io/github/last-commit/harvard-edge/cs249r_book/dev?label=Last%20Commit&amp;logo=git&amp;cacheSeconds=300)

&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;

  &lt;!-- Row 2: Access &amp; Ecosystem --&gt;
  [![Website](https://img.shields.io/website?url=https%3A%2F%2Fmlsysbook.ai&amp;label=Website&amp;logo=readthedocs)](https://mlsysbook.ai)
  [![Ecosystem](https://img.shields.io/website?url=https%3A%2F%2Fmlsysbook.org&amp;label=Ecosystem&amp;logo=internet-explorer)](https://mlsysbook.org)
  [![Citation](https://img.shields.io/badge/Cite-IEEE%20CODES%2B%20ISSS%202024-blue?logo=academia)](https://mlsysbook.org)

&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;

  &lt;!-- Row 3: Support --&gt;
  [![Funding](https://img.shields.io/badge/Fund%20Us-Open%20Collective-blue.svg?logo=open-collective)](https://opencollective.com/mlsysbook)
  [![License](https://img.shields.io/badge/License-CC--BY--NC--SA%204.0-blue.svg)](https://github.com/harvard-edge/cs249r_book/blob/dev/LICENSE)
  [![Powered by Netlify](https://img.shields.io/badge/Powered%20by-Netlify-00C7B7?logo=netlify&amp;logoColor=white)](https://www.netlify.com)

&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;

  &lt;!-- Reader Navigation --&gt;
  **[📖 Read Online](https://mlsysbook.ai)** • 
  **[💾 Download PDF](https://mlsysbook.ai/pdf)** • 
  **[💾 Download ePub](https://mlsysbook.ai/epub)** • 
  **[🌐 Explore Ecosystem](https://mlsysbook.org)**

&lt;/p&gt;

📚 **Hardcopy edition coming 2026 via MIT Press!**

&lt;/div&gt;

---

## About This Book

The **open-source textbook** that teaches you to build real-world AI systems — from edge devices to cloud deployment. Originally developed as Harvard University&#039;s CS249r course by [Prof. Vijay Janapa Reddi](https://github.com/profvjreddi/homepage), now used by universities and students worldwide.

&gt; **Our mission:** Expand access to AI systems education worldwide — empowering learners, one chapter and one lab at a time.

### Why This Book Exists

*&quot;This grew out of a concern that while students could train AI models, few understood how to build the systems that actually make them work. As AI becomes more capable and autonomous, the critical bottleneck won&#039;t be the algorithms - it will be the engineers who can build efficient, scalable, and sustainable systems that safely harness that intelligence.&quot;*

**— Vijay Janapa Reddi**

---

## 📚 What You&#039;ll Learn

Go beyond training models — master the **full stack** of real-world ML systems.

| Topic | What You&#039;ll Build |
|-------|------------------|
| **System Design** | Scalable, maintainable ML architectures |
| **Data Engineering** | Robust pipelines for collection, labeling, and processing |
| **Model Deployment** | Production-ready systems from prototypes |
| **MLOps &amp; Monitoring** | Reliable, continuously operating systems |
| **Edge AI** | Resource-efficient deployment on mobile, embedded, and IoT |

---

## ⭐ Support This Work

&lt;div align=&quot;center&quot;&gt;

### Show Your Support
**Star this repository** to help us demonstrate the value of open AI education to funders and institutions.

[![Stars](https://img.shields.io/github/stars/harvard-edge/cs249r_book?style=for-the-badge&amp;logo=github&amp;color=gold)](https://github.com/harvard-edge/cs249r_book/stargazers)

**Goal:** 10,000 stars = $100,000 in additional education funding

[**⭐ Star Now**](https://github.com/harvard-edge/cs249r_book) — *takes 2 seconds!*

### Fund the Mission (New!)
We&#039;ve graduated this project from Harvard to enable global access and expand AI systems education worldwide. Please help us support educators globally, especially in the Global South, by providing TinyML kits for students, funding workshops, and sustaining our open-source infrastructure.

[![Open Collective](https://img.shields.io/badge/💝%20Support%20AI%20Education-Open%20Collective-blue.svg?style=for-the-badge)](https://opencollective.com/mlsysbook)

*From $15/month to sponsor a learner to $250 for workshops — every contribution democratizes AI education.*

&lt;/div&gt;

---

## 🌐 Community &amp; Resources

| Resource | Description |
|----------|-------------|
| [📚 **Main Site**](https://mlsysbook.org) | Complete learning platform |
| [🔥 **TinyTorch**](https://mlsysbook.org/tinytorch) | Educational ML framework |
| [💬 **Discussions**](https://github.com/harvard-edge/cs249r_book/discussions) | Ask questions, share insights |
| [👥 **Community**](https://mlsysbook.org/community) | Join our global learning community |

---

## 🎯 For Different Audiences

### 🎓 Students
- [📖 Read online](https://mlsysbook.ai)
- [📄 Download PDF](https://mlsysbook.ai/Machine-Learning-Systems.pdf)
- [🧪 Try hands-on labs](https://mlsysbook.org)

### 👩‍🏫 Educators
- [📋 Course materials](https://mlsysbook.org)
- [🎯 Instructor resources](https://mlsysbook.org)
- [💡 Teaching guides](https://mlsysbook.org)

### 🛠️ Contributors
- [🤝 Contribution guide](docs/contribute.md)
- [⚡ Development setup](#development)
- [💬 Join discussions](https://github.com/harvard-edge/cs249r_book/discussions)

---

## 🚀 Quick Start

### For Readers
```bash
# Read online (continuously updated)
open https://mlsysbook.ai

# Or download PDF for offline access
curl -O https://mlsysbook.ai/Machine-Learning-Systems.pdf
```

### For Contributors
```bash
git clone https://github.com/harvard-edge/cs249r_book.git
cd cs249r_book

# Quick setup (recommended)
./binder setup      # Setup environment and dependencies
./binder doctor     # Check system health

# Fast development workflow
./binder preview intro    # Fast chapter development
./binder build intro      # Build specific chapter
./binder build            # Build complete book (HTML)
./binder help            # See all commands
```

---

## 🤝 Contributing

We welcome contributions from the global community! Here&#039;s how you can help:

### Ways to Contribute
- **📝 Content** — Suggest edits, improvements, or new examples
- **🛠️ Tools** — Enhance development scripts and automation  
- **🎨 Design** — Improve figures, diagrams, and visual elements
- **🌍 Localization** — Translate content for global accessibility
- **🔧 Infrastructure** — Help with build systems and deployment

### Quality Standards
All contributions benefit from automated quality assurance:
- ✅ **Pre-commit validation** — Automatic cleanup and checks
- 📋 **Content review** — Formatting and style validation
- 🧪 **Testing** — Build and link verification
- 👥 **Peer review** — Community feedback

[**Start Contributing →**](docs/contribute.md)

---

## 🛠️ Development

### Book Binder CLI (Recommended)

The **Book Binder** is our lightning-fast development CLI for streamlined building and iteration:

```bash
# Chapter development (fast iteration)
./binder preview intro                # Build and preview single chapter
./binder preview intro,ml_systems     # Build and preview multiple chapters

# Complete book building
./binder build                        # Build complete website (HTML)
./binder pdf                          # Build complete PDF
./binder epub                         # Build complete EPUB

# Management
./binder clean                        # Clean artifacts
./binder status                       # Show current status
./binder doctor                       # Run health check
./binder help                         # Show all commands
```

### Development Commands
```bash
# Book Binder CLI (Recommended)
./binder setup            # First-time setup
./binder build            # Build complete HTML book
./binder pdf              # Build complete PDF book  
./binder epub             # Build complete EPUB book
./binder preview intro    # Preview chapter development

# Traditional setup (if needed)
python3 -m venv .venv
source .venv/bin/activate
pip install -r tools/dependencies/requirements.txt
pre-commit install
```

### Project Structure
```
MLSysBook/
├── binder                   # ⚡ Fast development CLI (recommended)
├── quarto/                  # Main book content (Quarto)
│   ├── contents/            # Chapter content
│   │   ├── core/            # Core chapters
│   │   ├── labs/            # Hands-on labs
│   │   ├── frontmatter/     # Preface, acknowledgments
│   │   ├── backmatter/      # References and resources
│   │   └── parts/           # Book parts and sections
│   ├── _extensions/         # Quarto extensions
│   ├── config/              # Build configurations
│   │   ├── _quarto-html.yml # Website build configuration
│   │   └── _quarto-pdf.yml  # PDF build configuration
│   ├── data/                # Cross-reference and metadata files
│   ├── assets/              # Images, styles, media
│   ├── filters/             # Lua filters
│   ├── scripts/             # Build scripts
│   └── _quarto.yml          # Active config (symlink)
├── tools/                   # Development automation
│   ├── scripts/             # Organized development scripts
│   │   ├── content/         # Content management tools
│   │   ├── cross_refs/      # Cross-reference management
│   │   ├── genai/           # AI-assisted content tools
│   │   ├── maintenance/     # System maintenance scripts
│   │   ├── testing/         # Test and validation scripts
│   │   └── utilities/       # General utility scripts
│   ├── dependencies/        # Package requirements  
│   └── setup/               # Setup and configuration
├── config/                  # Project configuration
│   ├── dev/                 # Development configurations
│   ├── linting/             # Code quality configurations
│   └── quarto/              # Quarto publishing settings
├── docs/                    # Documentation
│   ├── BINDER.md            # Binder CLI guide
│   ├── BUILD.md             # Build instructions
│   ├── DEVELOPMENT.md       # Development guide
│   └── contribute.md        # Contribution guidelines
├── CHANGELOG.md             # Project changelog
├── CITATION.bib             # Citation information
├── pyproject.toml           # Python project configuration
└── README.md                # This file
```

### Documentation
- [⚡ Binder CLI Guide](docs/BINDER.md) — Fast development with the Book Binder
- [📋 Development Guide](docs/DEVELOPMENT.md) — Comprehensive setup and workflow
- [🛠️ Maintenance Guide](docs/MAINTENANCE_GUIDE.md) — Daily tasks and troubleshooting  
- [🔨 Build Instructions](docs/BUILD.md) — Detailed build process
- [🤝 Contribution Guidelines](docs/contribute.md) — How to contribute effectively

### Publishing

Publishing is handled through GitHub Actions workflows for consistent, automated deployment:

```bash
# Build locally to test before publishing
./binder build        # Build HTML
./binder pdf          # Build PDF  
./binder epub         # Build EPUB

# Publishing happens via GitHub Actions
# See docs/PUBLISH_LIVE_WORKFLOW.md for details
```

**Publishing Workflow:**
- **Automated Deployment** — GitHub Actions workflows handle all publishing
- **Quality Checks** — Automated validation before deployment
- **Multiple Formats** — HTML, PDF, and EPUB published simultaneously
- **Preview Deployments** — Pull requests get automatic preview deployments

See [Publishing Documentation](docs/PUBLISH_LIVE_WORKFLOW.md) for detailed instructions.

### Getting Started
```bash
# First time setup
./binder setup

# Check system health
./binder doctor

# Quick preview
./binder preview intro
```

---

## 📋 Citation &amp; License

### Citation
```bibtex
@inproceedings{reddi2024mlsysbook,
  title        = {MLSysBook.AI: Principles and Practices of Machine Learning Systems Engineering},
  author       = {Reddi, Vijay Janapa},
  booktitle    = {2024 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ ISSS)},
  pages        = {41--42},
  year         = {2024},
  organization = {IEEE},
  url          = {https://mlsysbook.org}
}
```

### License
This work is licensed under **Creative Commons Attribution–NonCommercial–ShareAlike 4.0 International** (CC BY-NC-SA 4.0). You may share and adapt the material for non-commercial purposes with appropriate credit.

---

## 🙏 Contributors

Thanks goes to these wonderful people who have contributed to making this resource better for everyone:

&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt;
&lt;!-- prettier-ignore-start --&gt;
&lt;!-- markdownlint-disable --&gt;
&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/profvjreddi&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/profvjreddi?s=100&quot; width=&quot;100px;&quot; alt=&quot;Vijay Janapa Reddi&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Vijay Janapa Reddi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/hzeljko&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/hzeljko?s=100&quot; width=&quot;100px;&quot; alt=&quot;Zeljko Hrcek&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Zeljko Hrcek&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/Mjrovai&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/Mjrovai?s=100&quot; width=&quot;100px;&quot; alt=&quot;Marcelo Rovai&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Marcelo Rovai&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/jasonjabbour&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/jasonjabbour?s=100&quot; width=&quot;100px;&quot; alt=&quot;Jason Jabbour&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jason Jabbour&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/uchendui&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/uchendui?s=100&quot; width=&quot;100px;&quot; alt=&quot;Ikechukwu Uchendu&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ikechukwu Uchendu&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/kai4avaya&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/kai4avaya?s=100&quot; width=&quot;100px;&quot; alt=&quot;Kai Kleinbard&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Kai Kleinbard&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/Naeemkh&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/Naeemkh?s=100&quot; width=&quot;100px;&quot; alt=&quot;Naeem Khoshnevis&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Naeem Khoshnevis&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/Sara-Khosravi&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/Sara-Khosravi?s=100&quot; width=&quot;100px;&quot; alt=&quot;Sara Khosravi&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sara Khosravi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/V0XNIHILI&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/V0XNIHILI?s=100&quot; width=&quot;100px;&quot; alt=&quot;Douwe den Blanken&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Douwe den Blanken&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/18jeffreyma&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/18jeffreyma?s=100&quot; width=&quot;100px;&quot; alt=&quot;Jeffrey Ma&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jeffrey Ma&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/shanzehbatool&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/shanzehbatool?s=100&quot; width=&quot;100px;&quot; alt=&quot;shanzehbatool&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;shanzehbatool&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/eliasab16&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/eliasab16?s=100&quot; width=&quot;100px;&quot; alt=&quot;Elias&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Elias&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/JaredP94&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/JaredP94?s=100&quot; width=&quot;100px;&quot; alt=&quot;Jared Ping&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jared Ping&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/ishapira1&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/ishapira1?s=100&quot; width=&quot;100px;&quot; alt=&quot;Itai Shapira&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Itai Shapira&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/harvard-edge/cs249r_book/graphs/contributors&quot;&gt;&lt;img src=&quot;https://www.gravatar.com/avatar/8863743b4f26c1a20e730fcf7ebc3bc0?d=identicon&amp;s=100?s=100&quot; width=&quot;100px;&quot; alt=&quot;Maximilian Lam&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Maximilian Lam&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/jaysonzlin&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/jaysonzlin?s=100&quot; width=&quot;100px;&quot; alt=&quot;Jayson Lin&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jayson Lin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/sophiacho1&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/sophiacho1?s=100&quot; width=&quot;100px;&quot; alt=&quot;Sophia Cho&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sophia Cho&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/andreamurillomtz&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/andreamurillomtz?s=100&quot; width=&quot;100px;&quot; alt=&quot;Andrea&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Andrea&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/alxrod&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/alxrod?s=100&quot; width=&quot;100px;&quot; alt=&quot;Alex Rodriguez&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Alex Rodriguez&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/korneelf1&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/korneelf1?s=100&quot; width=&quot;100px;&quot; alt=&quot;Korneel Van den Berghe&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Korneel Van den Berghe&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/colbybanbury&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/colbybanbury?s=100&quot; width=&quot;100px;&quot; alt=&quot;Colby Banbury&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Colby Banbury&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/zishenwan&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/zishenwan?s=100&quot; width=&quot;100px;&quot; alt=&quot;Zishen Wan&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Zishen Wan&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/mmaz&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/mmaz?s=100&quot; width=&quot;100px;&quot; alt=&quot;Mark Mazumder&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Mark Mazumder&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/DivyaAmirtharaj&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/DivyaAmirtharaj?s=100&quot; width=&quot;100px;&quot; alt=&quot;Divya Amirtharaj&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Divya Amirtharaj&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/ma3mool&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/ma3mool?s=100&quot; width=&quot;100px;&quot; alt=&quot;Abdulrahman Mahmoud&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Abdulrahman Mahmoud&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/srivatsankrishnan&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/srivatsankrishnan?s=100&quot; width=&quot;100px;&quot; alt=&quot;Srivatsan Krishnan&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Srivatsan Krishnan&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/James-QiuHaoran&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/James-QiuHaoran?s=100&quot; width=&quot;100px;&quot; alt=&quot;Haoran Qiu&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Haoran Qiu&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/aptl26&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/aptl26?s=100&quot; width=&quot;100px;&quot; alt=&quot;Aghyad Deeb&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Aghyad Deeb&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/arnaumarin&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/arnaumarin?s=100&quot; width=&quot;100px;&quot; alt=&quot;marin-llobet&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;marin-llobet&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;20%&quot;&gt;&lt;a href=&quot;https://github.com/jared-ni&quot;&gt;&lt;img sr

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[hsliuping/TradingAgents-CN]]></title>
            <link>https://github.com/hsliuping/TradingAgents-CN</link>
            <guid>https://github.com/hsliuping/TradingAgents-CN</guid>
            <pubDate>Tue, 28 Oct 2025 00:04:18 GMT</pubDate>
            <description><![CDATA[基于多智能体LLM的中文金融交易框架 - TradingAgents中文增强版]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hsliuping/TradingAgents-CN">hsliuping/TradingAgents-CN</a></h1>
            <p>基于多智能体LLM的中文金融交易框架 - TradingAgents中文增强版</p>
            <p>Language: Python</p>
            <p>Stars: 11,595</p>
            <p>Forks: 2,487</p>
            <p>Stars today: 205 stars today</p>
            <h2>README</h2><pre># TradingAgents 中文增强版

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/)
[![Version](https://img.shields.io/badge/Version-cn--0.1.15-green.svg)](./VERSION)
[![Documentation](https://img.shields.io/badge/docs-中文文档-green.svg)](./docs/)
[![Original](https://img.shields.io/badge/基于-TauricResearch/TradingAgents-orange.svg)](https://github.com/TauricResearch/TradingAgents)

&gt;
&gt; 🎯 **核心功能**: 原生OpenAI支持 | Google AI全面集成 | 自定义端点配置 | 智能模型选择 | 多LLM提供商支持 | 模型选择持久化 | Docker容器化部署 | 专业报告导出 | 完整A股支持 | 中文本地化

基于多智能体大语言模型的**中文金融交易决策框架**。专为中文用户优化，提供完整的A股/港股/美股分析能力。

## 🙏 致敬源项目

感谢 [Tauric Research](https://github.com/TauricResearch) 团队创造的革命性多智能体交易框架 [TradingAgents](https://github.com/TauricResearch/TradingAgents)！

**🎯 我们的使命**: 为中国用户提供完整的中文化体验，支持A股/港股市场，集成国产大模型，推动AI金融技术在中文社区的普及应用。

## 🎉 v1.0.0-preview 内测版本 - 全新架构升级

&gt; 🚀 **重磅发布**: v1.0.0-preview 版本现已开启内测！全新的 FastAPI + Vue 3 架构，带来企业级的性能和体验！

### ✨ 核心特性

#### 🏗️ **全新技术架构**
- **后端升级**: 从 Streamlit 迁移到 FastAPI，提供更强大的 RESTful API
- **前端重构**: 采用 Vue 3 + Element Plus，打造现代化的单页应用
- **数据库优化**: MongoDB + Redis 双数据库架构，性能提升 10 倍
- **容器化部署**: 完整的 Docker 多架构支持（amd64 + arm64）

#### 🎯 **企业级功能**
- **用户权限管理**: 完整的用户认证、角色管理、操作日志系统
- **配置管理中心**: 可视化的大模型配置、数据源管理、系统设置
- **缓存管理系统**: 智能缓存策略，支持 MongoDB/Redis/文件多级缓存
- **实时通知系统**: SSE 推送，实时跟踪分析进度和系统状态

#### 🤖 **智能分析增强**
- **动态供应商管理**: 支持动态添加和配置 LLM 供应商
- **模型能力管理**: 智能模型选择，根据任务自动匹配最佳模型
- **多数据源同步**: 统一的数据源管理，支持 Tushare、AkShare、BaoStock
- **报告导出功能**: 支持 Markdown/Word/PDF 多格式专业报告导出

#### 🐳 **Docker 多架构支持**
- **跨平台部署**: 支持 x86_64 和 ARM64 架构（Apple Silicon、树莓派、AWS Graviton）
- **GitHub Actions**: 自动化构建和发布 Docker 镜像
- **一键部署**: 完整的 Docker Compose 配置，5 分钟快速启动

### 📊 技术栈升级

| 组件 | v0.1.x | v1.0.0-preview |
|------|--------|----------------|
| **后端框架** | Streamlit | FastAPI + Uvicorn |
| **前端框架** | Streamlit | Vue 3 + Vite + Element Plus |
| **数据库** | 可选 MongoDB | MongoDB + Redis |
| **API 架构** | 单体应用 | RESTful API + WebSocket |
| **部署方式** | 本地/Docker | Docker 多架构 + GitHub Actions |

### 🎯 内测申请

v1.0.0-preview 版本目前处于**内测阶段**，我们诚邀您参与体验和测试！

####  使用指南

在申请试用前，建议先阅读详细的使用指南：

**[📘 TradingAgents-CN v1.0.0-preview 使用指南](https://mp.weixin.qq.com/s/ppsYiBncynxlsfKFG8uEbw)**

使用指南包含：
- ✅ 完整的功能介绍和操作演示
- ✅ 详细的配置说明和最佳实践
- ✅ 常见问题解答和故障排除
- ✅ 实际使用案例和效果展示

#### 如何申请试用

1. **关注公众号**: 微信搜索 **&quot;TradingAgents-CN&quot;** 并关注
2. **提交申请**: 通过公众号私信发送以下信息：
   - 您的姓名/昵称
   - 使用场景（个人学习/企业应用/学术研究）
   - 技术背景（可选）
   - 期望的功能或建议（可选）
3. **获取权限**: 我们会在 1-2 个工作日内回复，并提供：
   - 内测版本访问地址
   - 详细的使用文档
   - 技术支持和交流群

#### 🎁 内测用户福利

- ✅ **优先体验**: 第一时间体验最新功能
- ✅ **技术支持**: 专属技术支持和问题解答
- ✅ **功能定制**: 您的需求将优先纳入开发计划
- ✅ **社区荣誉**: 内测贡献者将在项目中特别致谢

#### 📱 联系方式

- **微信公众号**: TradingAgents-CN（推荐）

  &lt;img src=&quot;assets/weixin.png&quot; alt=&quot;微信公众号&quot; width=&quot;200&quot;/&gt;

---

## 🆕 v0.1.15 重大更新

### 🤖 LLM生态系统大升级

- **千帆大模型支持**: 新增百度千帆(ERNIE)大模型完整集成
- **LLM适配器重构**: 统一的OpenAI兼容适配器架构
- **多厂商支持**: 支持更多国产大模型提供商
- **集成指南**: 完整的LLM集成开发文档和测试工具

### 📚 学术研究支持

- **TradingAgents论文**: 完整的中文翻译版本和深度解读
- **技术博客**: 详细的技术分析和实现原理解读
- **学术资料**: PDF论文和相关研究资料
- **引用支持**: 标准的学术引用格式和参考文献

### 🛠️ 开发者体验升级

- **开发工作流**: 标准化的开发流程和分支管理规范
- **安装验证**: 完整的安装测试和验证脚本
- **文档重构**: 结构化的文档系统和快速开始指南
- **PR模板**: 标准化的Pull Request模板和代码审查流程

### 🔧 企业级工具链

- **分支保护**: GitHub分支保护策略和安全规则
- **紧急程序**: 完整的紧急处理和故障恢复程序
- **测试框架**: 增强的测试覆盖和验证工具
- **部署指南**: 企业级部署和配置管理

## 📋 v0.1.14 功能回顾

### 👥 用户权限管理系统

- **完整用户管理**: 新增用户注册、登录、权限控制功能
- **角色权限**: 支持多级用户角色和权限管理
- **会话管理**: 安全的用户会话和状态管理
- **用户活动日志**: 完整的用户操作记录和审计功能

### 🔐 Web用户认证系统

- **登录组件**: 现代化的用户登录界面
- **认证管理器**: 统一的用户认证和授权管理
- **安全增强**: 密码加密、会话安全等安全机制
- **用户仪表板**: 个性化的用户活动仪表板

### 🗄️ 数据管理优化

- **MongoDB集成增强**: 改进的MongoDB连接和数据管理
- **数据目录重组**: 优化的数据存储结构和管理
- **数据迁移脚本**: 完整的数据迁移和备份工具
- **缓存优化**: 提升数据加载和分析结果缓存性能

### 🧪 测试覆盖增强

- **功能测试脚本**: 新增6个专项功能测试脚本
- **工具处理器测试**: Google工具处理器修复验证
- **引导自动隐藏测试**: UI交互功能测试
- **在线工具配置测试**: 工具配置和选择逻辑测试
- **真实场景测试**: 实际使用场景的端到端测试
- **美股独立性测试**: 美股分析功能独立性验证

---

## 🆕 v0.1.13 重大更新

### 🤖 原生OpenAI端点支持

- **自定义OpenAI端点**: 支持配置任意OpenAI兼容的API端点
- **灵活模型选择**: 可以使用任何OpenAI格式的模型，不限于官方模型
- **智能适配器**: 新增原生OpenAI适配器，提供更好的兼容性和性能
- **配置管理**: 统一的端点和模型配置管理系统

### 🧠 Google AI生态系统全面集成

- **三大Google AI包支持**: langchain-google-genai、google-generativeai、google-genai
- **9个验证模型**: gemini-2.5-pro, gemini-2.5-flash, gemini-2.0-flash等最新模型
- **Google工具处理器**: 专门的Google AI工具调用处理器
- **智能降级机制**: 高级功能失败时自动降级到基础功能

### 🔧 LLM适配器架构优化

- **GoogleOpenAIAdapter**: 新增Google AI的OpenAI兼容适配器
- **统一接口**: 所有LLM提供商使用统一的调用接口
- **错误处理增强**: 改进的异常处理和自动重试机制
- **性能监控**: 添加LLM调用性能监控和统计

### 🎨 Web界面智能优化

- **智能模型选择**: 根据可用性自动选择最佳模型
- **KeyError修复**: 彻底解决模型选择中的KeyError问题
- **UI响应优化**: 改进模型切换的响应速度和用户体验
- **错误提示**: 更友好的错误提示和解决建议

## 🆕 v0.1.12 重大更新

### 🧠 智能新闻分析模块

- **智能新闻过滤器**: 基于AI的新闻相关性评分和质量评估
- **多层次过滤机制**: 基础过滤、增强过滤、集成过滤三级处理
- **新闻质量评估**: 自动识别和过滤低质量、重复、无关新闻
- **统一新闻工具**: 整合多个新闻源，提供统一的新闻获取接口

### 🔧 技术修复和优化

- **DashScope适配器修复**: 解决工具调用兼容性问题
- **DeepSeek死循环修复**: 修复新闻分析师的无限循环问题
- **LLM工具调用增强**: 提升工具调用的可靠性和稳定性
- **新闻检索器优化**: 增强新闻数据获取和处理能力

### 📚 完善测试和文档

- **全面测试覆盖**: 新增15+个测试文件，覆盖所有新功能
- **详细技术文档**: 新增8个技术分析报告和修复文档
- **用户指南完善**: 新增新闻过滤使用指南和最佳实践
- **演示脚本**: 提供完整的新闻过滤功能演示

### 🗂️ 项目结构优化

- **文档分类整理**: 按功能将文档分类到docs子目录
- **示例代码归位**: 演示脚本统一到examples目录
- **根目录整洁**: 保持根目录简洁，提升项目专业度

## 🎯 核心特性

### 🤖 多智能体协作架构

- **专业分工**: 基本面、技术面、新闻面、社交媒体四大分析师
- **结构化辩论**: 看涨/看跌研究员进行深度分析
- **智能决策**: 交易员基于所有输入做出最终投资建议
- **风险管理**: 多层次风险评估和管理机制

## 🖥️ Web界面展示

### 📸 界面截图

&gt; 🎨 **现代化Web界面**: 基于Streamlit构建的响应式Web应用，提供直观的股票分析体验

#### 🏠 主界面 - 分析配置

![1755003162925](images/README/1755003162925.png)

![1755002619976](images/README/1755002619976.png)

*智能配置面板，支持多市场股票分析，5级研究深度选择*

#### 📊 实时分析进度

![1755002731483](images/README/1755002731483.png)

*实时进度跟踪，可视化分析过程，智能时间预估*

#### 📈 分析结果展示

![1755002901204](images/README/1755002901204.png)

![1755002924844](images/README/1755002924844.png)

![1755002939905](images/README/1755002939905.png)

![1755002968608](images/README/1755002968608.png)

![1755002985903](images/README/1755002985903.png)

![1755003004403](images/README/1755003004403.png)

![1755003019759](images/README/1755003019759.png)

![1755003033939](images/README/1755003033939.png)

![1755003048242](images/README/1755003048242.png)

![1755003064598](images/README/1755003064598.png)

![1755003090603](images/README/1755003090603.png)

*专业投资报告，多维度分析结果，一键导出功能*

### 🎯 核心功能特色

#### 📋 **智能分析配置**

- **🌍 多市场支持**: 美股、A股、港股一站式分析
- **🎯 5级研究深度**: 从2分钟快速分析到25分钟全面研究
- **🤖 智能体选择**: 市场技术、基本面、新闻、社交媒体分析师
- **📅 灵活时间设置**: 支持历史任意时间点分析

#### 🚀 **实时进度跟踪**

- **📊 可视化进度**: 实时显示分析进展和剩余时间
- **🔄 智能步骤识别**: 自动识别当前分析阶段
- **⏱️ 准确时间预估**: 基于历史数据的智能时间计算
- **💾 状态持久化**: 页面刷新不丢失分析进度

#### 📈 **专业结果展示**

- **🎯 投资决策**: 明确的买入/持有/卖出建议
- **📊 多维分析**: 技术面、基本面、新闻面综合评估
- **🔢 量化指标**: 置信度、风险评分、目标价位
- **📄 专业报告**: 支持Markdown/Word/PDF格式导出

#### 🤖 **多LLM模型管理**

- **🌐 4大提供商**: DashScope、DeepSeek、Google AI、OpenRouter
- **🎯 60+模型选择**: 从经济型到旗舰级模型全覆盖
- **💾 配置持久化**: URL参数存储，刷新保持设置
- **⚡ 快速切换**: 5个热门模型一键选择按钮

### 🎮 Web界面操作指南

#### 🚀 **快速开始流程**

1. **启动应用**: `python start_web.py` 或 `docker-compose up -d`
2. **访问界面**: 浏览器打开 `http://localhost:8501`
3. **配置模型**: 侧边栏选择LLM提供商和模型
4. **输入股票**: 输入股票代码（如 AAPL、000001、0700.HK）
5. **选择深度**: 根据需求选择1-5级研究深度
6. **开始分析**: 点击&quot;🚀 开始分析&quot;按钮
7. **查看结果**: 实时跟踪进度，查看分析报告
8. **导出报告**: 一键导出专业格式报告

#### 📊 **支持的股票代码格式**

- **🇺🇸 美股**: `AAPL`, `TSLA`, `MSFT`, `NVDA`, `GOOGL`
- **🇨🇳 A股**: `000001`, `600519`, `300750`, `002415`
- **🇭🇰 港股**: `0700.HK`, `9988.HK`, `3690.HK`, `1810.HK`

#### 🎯 **研究深度说明**

- **1级 (2-4分钟)**: 快速概览，基础技术指标
- **2级 (4-6分钟)**: 标准分析，技术+基本面
- **3级 (6-10分钟)**: 深度分析，加入新闻情绪 ⭐ **推荐**
- **4级 (10-15分钟)**: 全面分析，多轮智能体辩论
- **5级 (15-25分钟)**: 最深度分析，完整研究报告

#### 💡 **使用技巧**

- **🔄 实时刷新**: 分析过程中可随时刷新页面，进度不丢失
- **📱 移动适配**: 支持手机和平板设备访问
- **🎨 深色模式**: 自动适配系统主题设置
- **⌨️ 快捷键**: 支持Enter键快速提交分析
- **📋 历史记录**: 自动保存最近的分析配置

&gt; 📖 **详细指南**: 完整的Web界面使用说明请参考 [🖥️ Web界面详细使用指南](docs/usage/web-interface-detailed-guide.md)

## 🎯 功能特性

### 🚀  智能新闻分析✨ **v0.1.12重大升级**


| 功能特性               | 状态        | 详细说明                                 |
| ---------------------- | ----------- | ---------------------------------------- |
| **🧠 智能新闻分析**    | 🆕 v0.1.12  | AI新闻过滤，质量评估，相关性分析         |
| **🔧 新闻过滤器**      | 🆕 v0.1.12  | 多层次过滤，基础/增强/集成三级处理       |
| **📰 统一新闻工具**    | 🆕 v0.1.12  | 整合多源新闻，统一接口，智能检索         |
| **🤖 多LLM提供商**     | 🆕 v0.1.11  | 4大提供商，60+模型，智能分类管理         |
| **💾 模型选择持久化**  | 🆕 v0.1.11  | URL参数存储，刷新保持，配置分享          |
| **🎯 快速选择按钮**    | 🆕 v0.1.11  | 一键切换热门模型，提升操作效率           |
| **📊 实时进度显示**    | ✅ v0.1.10  | 异步进度跟踪，智能步骤识别，准确时间计算 |
| **💾 智能会话管理**    | ✅ v0.1.10  | 状态持久化，自动降级，跨页面恢复         |
| **🎯 一键查看报告**    | ✅ v0.1.10  | 分析完成后一键查看，智能结果恢复         |
| **🖥️ Streamlit界面** | ✅ 完整支持 | 现代化响应式界面，实时交互和数据可视化   |
| **⚙️ 配置管理**      | ✅ 完整支持 | Web端API密钥管理，模型选择，参数配置     |

### 🎨 CLI用户体验 ✨ **v0.1.9优化**


| 功能特性                | 状态        | 详细说明                             |
| ----------------------- | ----------- | ------------------------------------ |
| **🖥️ 界面与日志分离** | ✅ 完整支持 | 用户界面清爽美观，技术日志独立管理   |
| **🔄 智能进度显示**     | ✅ 完整支持 | 多阶段进度跟踪，防止重复提示         |
| **⏱️ 时间预估功能**   | ✅ 完整支持 | 智能分析阶段显示预计耗时             |
| **🌈 Rich彩色输出**     | ✅ 完整支持 | 彩色进度指示，状态图标，视觉效果提升 |

### 🧠 LLM模型支持 ✨ **v0.1.13全面升级**


| 模型提供商        | 支持模型                     | 特色功能                | 新增功能 |
| ----------------- | ---------------------------- | ----------------------- | -------- |
| **🇨🇳 阿里百炼** | qwen-turbo/plus/max          | 中文优化，成本效益高    | ✅ 集成  |
| **🇨🇳 DeepSeek** | deepseek-chat                | 工具调用，性价比极高    | ✅ 集成  |
| **🌍 Google AI**  | **9个验证模型**              | 最新Gemini 2.5系列      | 🆕 升级  |
| ├─**最新旗舰**  | gemini-2.5-pro/flash         | 最新旗舰，超快响应      | 🆕 新增  |
| ├─**稳定推荐**  | gemini-2.0-flash             | 推荐使用，平衡性能      | 🆕 新增  |
| ├─**经典强大**  | gemini-1.5-pro/flash         | 经典稳定，高质量分析    | ✅ 集成  |
| └─**轻量快速**  | gemini-2.5-flash-lite        | 轻量级任务，快速响应    | 🆕 新增  |
| **🌐 原生OpenAI** | **自定义端点支持**           | 任意OpenAI兼容端点      | 🆕 新增  |
| **🌐 OpenRouter** | **60+模型聚合平台**          | 一个API访问所有主流模型 | ✅ 集成  |
| ├─**OpenAI**    | o4-mini-high, o3-pro, GPT-4o | 最新o系列，推理专业版   | ✅ 集成  |
| ├─**Anthropic** | Claude 4 Opus/Sonnet/Haiku   | 顶级性能，平衡版本      | ✅ 集成  |
| ├─**Meta**      | Llama 4 Maverick/Scout       | 最新Llama 4系列         | ✅ 集成  |
| └─**自定义**    | 任意OpenRouter模型ID         | 无限扩展，个性化选择    | ✅ 集成  |

**🎯 快速选择**: 5个热门模型快速按钮 | **💾 持久化**: URL参数存储，刷新保持 | **🔄 智能切换**: 一键切换不同提供商

### 📊 数据源与市场


| 市场类型      | 数据源                   | 覆盖范围                     |
| ------------- | ------------------------ | ---------------------------- |
| **🇨🇳 A股**  | Tushare, AkShare, 通达信 | 沪深两市，实时行情，财报数据 |
| **🇭🇰 港股** | AkShare, Yahoo Finance   | 港交所，实时行情，基本面     |
| **🇺🇸 美股** | FinnHub, Yahoo Finance   | NYSE, NASDAQ，实时数据       |
| **📰 新闻**   | Google News              | 实时新闻，多语言支持         |

### 🤖 智能体团队

**分析师团队**: 📈市场分析 | 💰基本面分析 | 📰新闻分析 | 💬情绪分析
**研究团队**: 🐂看涨研究员 | 🐻看跌研究员 | 🎯交易决策员
**管理层**: 🛡️风险管理员 | 👔研究主管

## 🚀 快速开始

### 🐳 Docker部署 (推荐)

```bash
# 1. 克隆项目
git clone https://github.com/hsliuping/TradingAgents-CN.git
cd TradingAgents-CN

# 2. 配置环境变量
cp .env.example .env
# 编辑 .env 文件，填入API密钥

# 3. 启动服务
# 首次启动或代码变更时（需要构建镜像）
docker-compose up -d --build

# 日常启动（镜像已存在，无代码变更）
docker-compose up -d

# 智能启动（自动判断是否需要构建）
# Windows环境
powershell -ExecutionPolicy Bypass -File scripts\smart_start.ps1

# Linux/Mac环境
chmod +x scripts/smart_start.sh &amp;&amp; ./scripts/smart_start.sh

# 4. 访问应用
# Web界面: http://localhost:8501
```

### 💻 本地部署

```bash
# 1. 升级pip (重要！避免安装错误)
python -m pip install --upgrade pip

# 2. 安装依赖（推荐使用锁定版本，安装速度最快）
pip install -r requirements-lock.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
pip install -e . --no-deps

# 或一步安装（会重新解析依赖，速度较慢）
# pip install -e . -i https://pypi.tuna.tsinghua.edu.cn/simple

# 💡 国内用户推荐使用镜像加速（详见 docs/installation-mirror.md）
# ⚠️ Windows 用户如遇到 PyYAML 编译错误，使用锁定版本可避免此问题

# 3. 启动应用
python start_web.py

# 4. 访问 http://localhost:8501
```

### 📊 开始分析

1. **选择模型**: DeepSeek V3 / 通义千问 / Gemini
2. **输入股票**: `000001` (A股) / `AAPL` (美股) / `0700.HK` (港股)
3. **开始分析**: 点击&quot;🚀 开始分析&quot;按钮
4. **实时跟踪**: 观察实时进度和分析步骤
5. **查看报告**: 点击&quot;📊 查看分析报告&quot;按钮
6. **导出报告**: 支持Word/PDF/Markdown格式

## 🔐 用户权限管理

### 🔑 默认账号信息

系统提供以下默认账号，首次启动时自动创建：

| 用户名 | 密码 | 角色 | 权限说明 |
|--------|------|------|----------|
| **admin** | **admin123** | 管理员 | 完整系统权限，用户管理，系统配置 |
| **user** | **user123** | 普通用户 | 股票分析，报告查看，基础功能 |

&gt; ⚠️ **安全提醒**: 首次登录后请立即修改默认密码！

### 🛡️ 权限控制体系

- **🔐 登录认证**: 基于用户名密码的安全认证
- **👥 角色管理**: 管理员、普通用户等多级权限
- **⏰ 会话管理**: 自动超时保护，安全登出
- **📊 操作日志**: 完整的用户活动记录

### 🛠️ 用户管理工具

系统提供完整的命令行用户管理工具：

#### Windows 用户
```powershell
# 使用 PowerShell 脚本
.\scripts\user_manager.ps1 list                    # 列出所有用户
.\scripts\user_manager.ps1 change-password admin   # 修改密码
.\scripts\user_manager.ps1 create newuser trader  # 创建新用户
.\scripts\user_manager.ps1 delete olduser         # 删除用户

# 或使用批处理文件
.\scripts\user_manager.bat list
```

#### Python 脚本（跨平台）
```bash
# 直接使用 Python 脚本
python scripts/user_password_manager.py list
python scripts/user_password_manager.py change-password admin
python scripts/user_password_manager.py create newuser --role trader
python scripts/user_password_manager.py delete olduser
python scripts/user_password_manager.py reset  # 重置为默认配置
```

### 📋 支持的用户操作

- **📝 列出用户**: 查看所有用户及其角色权限
- **🔑 修改密码**: 安全的密码更新机制
- **👤 创建用户**: 支持自定义角色和权限
- **🗑️ 删除用户**: 安全的用户删除功能
- **🔄 重置配置**: 恢复默认用户设置

### 📁 配置文件位置

用户配置存储在：`web/config/users.json`

&gt; 📚 **详细文档**: 完整的用户管理指南请参考 [scripts/USER_MANAGEMENT.md](scripts/USER_MANAGEMENT.md)

### 🚧 当前版本限制

- ❌ 暂不支持在线用户注册
- ❌ 暂不支持Web界面的角色管理
- ✅ 支持完整的命令行用户管理
- ✅ 支持完整的权限控制框架

---

## 🎯 核心优势

- **🧠 智能新闻分析**: v0.1.12新增AI驱动的新闻过滤和质量评估系统
- **🔧 多层次过滤**: 基础、增强、集成三级新闻过滤机制
- **📰 统一新闻工具**: 整合多源新闻，提供统一的智能检索接口
- **🆕 多LLM集成**: v0.1.11新增4大提供商，60+模型，一站式AI体验
- **💾 配置持久化**: 模型选择真正持久化，URL参数存储，刷新保持
- **🎯 快速切换**: 5个热门模型快速按钮，一键切换不同AI
- **🆕 实时进度**: v0.1.10异步进度跟踪，告别黑盒等待
- **💾 智能会话**: 状态持久化，页面刷新不丢失分析结果
- **🔐 用户权限**: v0.1.14新增完整的用户认证和权限管理体系
- **🇨🇳 中国优化**: A股/港股数据 + 国产LLM + 中文界面
- **🐳 容器化**: Docker一键部署，环境隔离，快速扩展
- **📄 专业报告**: 多格式导出，自动生成投资建议
- **🛡️ 稳定可靠**: 多层数据源，智能降级，错误恢复

## 🔧 技术架构

**核心技术**: Python 3.10+ | LangChain | Streamlit | MongoDB | Redis
**AI模型**: DeepSeek V3 | 阿里百炼 | Google AI | OpenRouter(60+模型) | OpenAI
**数据源**: Tushare | AkShare | FinnHub | Yahoo Finance
**部署**: Docker | Docker Compose | 本地部署

## 📚 文档和支持

- **📖 完整文档**: [docs/](./docs/) - 安装指南、使用教程、API文档
- **🚨 故障排除**: [troubleshooting/](./docs/troubleshooting/) - 常见问题解决方案
- **🔄 更新日志**: [CHANGELOG.md](./docs/releases/CHANGELOG.md) - 详细版本历史
- **🚀 快速开始**: [QUICKSTART.md](./QUICKSTART.md) - 5分钟快速部署指南

## 🆚 中文增强特色

**相比原版新增**: 智能新闻分析 | 多层次新闻过滤 | 新闻质量评估 | 统一新闻工具 | 多LLM提供商集成 | 模型选择持久化 | 快速切换按钮 | | 实时进度显示 | 智能会话管理 | 中文界面 | A股数据 | 国产LLM | Docker部署 | 专业报告导出 | 统一日志管理 | Web配置界面 | 成本优化

**Docker部署包含的服务**:

- 🌐 **Web应用**: TradingAgents-CN主程序
- 🗄️ **MongoDB**: 数据持久化存储
- ⚡ **Redis**: 高速缓存
- 📊 **MongoDB Express**: 数据库管理界面
- 🎛️ **Redis Commander**: 缓存管理界面

#### 💻 方式二：本地部署

**适用场景**: 开发环境、自定义配置、离线使用

### 环境要求

- Python 3.10+ (推荐 3.11)
- 4GB+ RAM (推荐 8GB+)
- 稳定的网络连接

### 安装步骤

```bash
# 1. 克隆项目
git clone https://github.com/hsliuping/TradingAgents-CN.git
cd TradingAgents-CN

# 2. 创建虚拟环境
python -m venv env
# Windows
env\Scripts\activate
# Linux/macOS
source env/bin/activate

# 3. 升级pip
python -m pip install --upgrade pip

# 4. 安装所有依赖
pip install -e .

# 💡 国内用户推荐使用镜像加速（详见 docs/installation-mirror.md）
# pip install -e . -i https://pypi.tuna.tsinghua.edu.cn/simple

# 注意：requirements.txt已包含所有必需依赖：
# - 数据库支持 (MongoDB + Redis)
# - 多市场数据源 (Tushare, AKShare, FinnHub等)
# - Web界面和报告导出功能
```

### 配置API密钥

#### 🇨🇳 推荐：使用阿里百炼（国产大模型）

```bash
# 复制配置模板
cp .env.example .env

# 编辑 .env 文件，配置以下必需的API密钥：
DASHSCOPE_API_KEY=your_dashscope_api_key_here
FINNHUB_API_KEY=your_finnhub_api_key_here

# 推荐：Tushare API（专业A股数据）
TUSHARE_TOKEN=your_tushare_token_here
TUSHARE_ENABLED=true

# 可选：其他AI模型API
GOOGLE_API_KEY=your_google_api_key_here
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# 数据库配置（可选，提升性能）
# 本地部署使用标准端口
MONGODB_ENABLED=false  # 设为true启用MongoDB
REDIS_ENABLED=false    # 设为true启用Redis
MONGODB_HOST=localhost
MONGODB_PORT=27017     # 标准MongoDB端口
REDIS_HOST=localhost
REDIS_PORT=6379        # 标准Redis端口

# Docker部署时需要修改主机名
# MONGODB_HOST=mongodb
# REDIS_HOST=redis
```

#### 📋 部署模式配置说明

**本地部署模式**：

```bash
# 数据库配置（本地部署）
MONGODB_ENABLED=true
REDIS_ENABLED=true
MONGODB_HOST=localhost      # 本地主机
MONGODB_PORT=27017         # 标准端口
REDIS_HOST=localhost       # 本地主机
REDIS_PORT=6379           # 标准端口
```

**Docker部署模式**：

```bash
# 数据库配置（Docker部署）
MONGODB_ENABLED=true
REDIS_ENABLED=true
MONGODB_HOST=mongodb       # Docker容器服务名
MONGODB_PORT=27017        # 标准端口
REDIS_HOST=redis          # Docker容器服务名
REDIS_PORT=6379          # 标准端口
```

&gt; 💡 **配置提示**：
&gt;
&gt; - 本地部署：需要手动启动MongoDB和Redis服务
&gt; - Docker部署：数据库服务通过docker-compose自动启动
&gt; - 端口冲突：如果本地已有数据库服务，可修改docker-compose.yml中的端口映射

#### 🌍 可选：使用国外模型

```bash
# OpenAI (需要科学上网)
OPENAI_API_KEY=your_openai_api_key

# Anthropic (需要科学上网)
ANTHROPIC_API_KEY=your_anthropic_api_key
```

### 🗄️ 数据库配置（MongoDB + Redis）

#### 高性能数据存储支持

本项目支持 **MongoDB** 和 **Redis** 数据库，提供：

- **📊 股票数据缓存**: 减少API调用，提升响应速度
- **🔄 智能降级机制**: MongoDB → API → 本地缓存的多层数据源
- **⚡ 高性能缓存**: Redis缓存热点数据，毫秒级响应
- **🛡️ 数据持久化**: MongoDB存储历史数据，支持离线分析

#### 数据库部署方式

**🐳 Docker部署（推荐）**

如果您使用Docker部署，数据库已自动包含在内：

```bash
# Docker部署会自动启动所有服务，包括：
docker-compose up -d --build
# - Web应用 (端口8501)
# - MongoDB (端口27017)
# - Redis (端口6379)
# - 数据库管理界面 (端口8081, 8082)
```

**💻 本地部署 - 数据库配置**

如果您使用本地部署，可以选择以下方式：

**方式一：仅启动数据库服务**

```bash
# 仅启动 MongoDB + Redis 服务（不启动Web应用）
docker-compose up -d mongodb redis mongo-express redis-commander

# 查看服务状态
docker-compose ps

# 停止服务
docker-compose down
```

**方式二：完全本地安装**

```bash
# 数据库依赖已包含在requirements.txt中，无需额外安装

# 启动 MongoDB (默认端口 27017)
mongod --dbpath ./data/mongodb

# 启动 Redis (默认端口 6379)
redis-server
```

&gt; ⚠️ **重要说明**:
&gt;
&gt; - **🐳 Docker部署**: 数据库自动包含，无需额外配置
&gt; - **💻 本地部署**: 可选择仅启动数据库服务或完全本地安装
&gt; - **📋 推荐**: 使用Docker部署以获得最佳体验和一致性

#### 数据库配置选项

**环境变量配置**（推荐）：

```bash
# MongoDB 配置
MONGODB_HOST=localhost
MONGODB_PORT=27017
MONGODB_DATABASE=trading_agents
MONGODB_USERNAME=admin
MONGODB_PASSWORD=your_password

# Redis 配置
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password
REDIS_DB=0
```

**配置文件方式**：

```python
# config/database_config.py
DATABASE_CONFIG = {
    &#039;mongodb&#039;: {
        &#039;host&#039;: &#039;localhost&#039;,
        &#039;port&#039;: 27017,
        &#039;database&#039;: &#039;trading_agents&#039;,
        &#039;username&#039;: &#039;admin&#039;,
        &#039;password&#039;: &#039;your_password&#039;
    },
    &#039;redis&#039;: {
        &#039;host&#039;: &#039;localhost&#039;,
        &#039;port&#039;: 6379,
        &#039;password&#039;: &#039;your_redis_password&#039;,
        &#039;db&#039;: 0
    }
}
```

#### 数据库功能特性

**MongoDB 功能**：

- ✅ 股票基础信息存储
- ✅ 历史价格数据缓存
- ✅ 分析结果持久化
- ✅ 用户配置管理
- ✅ 自动数据同步

**Redis 功能**：

- ⚡ 实时价格数据缓存
- ⚡ API响应结果缓存
- ⚡ 会话状态管理
- ⚡ 热点数据预加载
- ⚡ 分布式锁支持

#### 智能降级机制

系统采用多层数据源降级策略，确保高可用性：

```
📊 数据获取流程：
1. 🔍 检查 Redis 缓存 (毫秒级)
2. 📚 查询 MongoDB 存储 (秒级)
3. 🌐 调用通达信API (秒级)
4. 💾 本地文件缓存 (备用)
5. ❌ 返回错误信息
```

**配置降级策略**：

```python
# 在 .env 文件中配置
ENABLE_MONGODB=true
ENABLE_REDIS=true
ENABLE_FALLBACK=true

# 缓存过期时间（秒）
REDIS_CACHE_TTL=300
MONGODB_CACHE_TTL=3600
```

#### 性能优化建议

**生产环境配置**：

```bash
# MongoDB 优化
MONGODB_MAX_POOL_SIZE=50
MONGODB_MIN_POOL_SIZE=5
MONGODB_MAX_IDLE_TIME=30000

# Redis 优化
REDIS_MAX_CONNECTIONS=20
REDIS_CONNECTION_POOL_SIZE=10
REDIS_SOCKET_TIMEOUT=5
```

#### 数据库管理工具

```bash
# 初始化数据库
python scripts/setup/init_database.py

# 系统状态检查
python scripts/validation/check_system_status.py

# 清理缓存工具
python scripts/maintenance/cleanup_cache.py --days 7
```

#### 故障排除

**常见问题解决**：

1. **🪟 Windows 10 ChromaDB兼容性问题**

   **问题现象**：在Windows 10上出现 `Configuration error: An instance of Chroma already exists for ephemeral with different settings` 错误，而Windows 11正常。

   **快速解决方案**：

   ```bash
   # 方案1：禁用内存功能（推荐）
   # 在 .env 文件中添加：
   MEMORY_ENABLED=false

   # 方案2：使用专用修复脚本
   powershell -ExecutionPolicy Bypass -File scripts\fix_chromadb_win10.ps1

   #

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[shiyu-coder/Kronos]]></title>
            <link>https://github.com/shiyu-coder/Kronos</link>
            <guid>https://github.com/shiyu-coder/Kronos</guid>
            <pubDate>Tue, 28 Oct 2025 00:04:17 GMT</pubDate>
            <description><![CDATA[Kronos: A Foundation Model for the Language of Financial Markets]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/shiyu-coder/Kronos">shiyu-coder/Kronos</a></h1>
            <p>Kronos: A Foundation Model for the Language of Financial Markets</p>
            <p>Language: Python</p>
            <p>Stars: 8,397</p>
            <p>Forks: 1,746</p>
            <p>Stars today: 88 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;h2&gt;&lt;b&gt;Kronos: A Foundation Model for the Language of Financial Markets &lt;/b&gt;&lt;/h2&gt;
&lt;/div&gt;


&lt;div align=&quot;center&quot;&gt;

&lt;/a&gt; 
&lt;a href=&quot;https://huggingface.co/NeoQuasar&quot;&gt; 
&lt;img src=&quot;https://img.shields.io/badge/🤗-Hugging_Face-yellow&quot; alt=&quot;Hugging Face&quot;&gt; 
&lt;/a&gt; 
&lt;a href=&quot;https://shiyu-coder.github.io/Kronos-demo/&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/🚀-Live_Demo-brightgreen&quot; alt=&quot;Live Demo&quot;&gt; &lt;/a&gt;
&lt;a href=&quot;https://github.com/shiyu-coder/Kronos/graphs/commit-activity&quot;&gt; 
&lt;img src=&quot;https://img.shields.io/github/last-commit/shiyu-coder/Kronos?color=blue&quot; alt=&quot;Last Commit&quot;&gt; 
&lt;/a&gt; 
&lt;a href=&quot;https://github.com/shiyu-coder/Kronos/stargazers&quot;&gt; 
&lt;img src=&quot;https://img.shields.io/github/stars/shiyu-coder/Kronos?color=lightblue&quot; alt=&quot;GitHub Stars&quot;&gt; 
&lt;/a&gt; 
&lt;a href=&quot;https://github.com/shiyu-coder/Kronos/network/members&quot;&gt; 
&lt;img src=&quot;https://img.shields.io/github/forks/shiyu-coder/Kronos?color=yellow&quot; alt=&quot;GitHub Forks&quot;&gt; 
&lt;/a&gt; 
&lt;a href=&quot;./LICENSE&quot;&gt; 
&lt;img src=&quot;https://img.shields.io/github/license/shiyu-coder/Kronos?color=green&quot; alt=&quot;License&quot;&gt; 
&lt;/a&gt;

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
  &lt;a href=&quot;https://zdoc.app/de/shiyu-coder/Kronos&quot;&gt;Deutsch&lt;/a&gt; | 
  &lt;a href=&quot;https://zdoc.app/es/shiyu-coder/Kronos&quot;&gt;Español&lt;/a&gt; | 
  &lt;a href=&quot;https://zdoc.app/fr/shiyu-coder/Kronos&quot;&gt;Français&lt;/a&gt; | 
  &lt;a href=&quot;https://zdoc.app/ja/shiyu-coder/Kronos&quot;&gt;日本語&lt;/a&gt; | 
  &lt;a href=&quot;https://zdoc.app/ko/shiyu-coder/Kronos&quot;&gt;한국어&lt;/a&gt; | 
  &lt;a href=&quot;https://zdoc.app/pt/shiyu-coder/Kronos&quot;&gt;Português&lt;/a&gt; | 
  &lt;a href=&quot;https://zdoc.app/ru/shiyu-coder/Kronos&quot;&gt;Русский&lt;/a&gt; | 
  &lt;a href=&quot;https://zdoc.app/zh/shiyu-coder/Kronos&quot;&gt;中文&lt;/a&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;

&lt;img src=&quot;./figures/logo.png&quot; width=&quot;100&quot;&gt;

&lt;/p&gt;

&gt; Kronos is the **first open-source foundation model** for financial candlesticks (K-lines), 
&gt; trained on data from over **45 global exchanges**.


&lt;/div&gt;

## 📰 News
*   🚩 **[2025.08.17]** We have released the scripts for fine-tuning! Check them out to adapt Kronos to your own tasks.
*   🚩 **[2025.08.02]** Our paper is now available on [arXiv](https://arxiv.org/abs/2508.02739)!

&lt;p align=&quot;center&quot;&gt;

## 📜 Introduction

**Kronos** is a family of decoder-only foundation models, pre-trained specifically for the &quot;language&quot; of financial markets—K-line sequences. Unlike general-purpose TSFMs, Kronos is designed to handle the unique, high-noise characteristics of financial data. It leverages a novel two-stage framework: 
1. A specialized tokenizer first quantizes continuous, multi-dimensional K-line data (OHLCV) into **hierarchical discrete tokens**. 
2. A large, autoregressive Transformer is then pre-trained on these tokens, enabling it to serve as a unified model for diverse quantitative tasks.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;figures/overview.png&quot; alt=&quot;&quot; align=&quot;center&quot; width=&quot;700px&quot; /&gt;
&lt;/p&gt;

## ✨ Live Demo 
We have set up a live demo to visualize Kronos&#039;s forecasting results. The webpage showcases a forecast for the **BTC/USDT** trading pair over the next 24 hours. 

**👉 [Access the Live Demo Here](https://shiyu-coder.github.io/Kronos-demo/)** 

## 📦 Model Zoo 
We release a family of pre-trained models with varying capacities to suit different computational and application needs. All models are readily accessible from the Hugging Face Hub.

| Model        | Tokenizer                                                                       | Context length | Params  | Open-source                                                               |
|--------------|---------------------------------------------------------------------------------| -------------- | ------ |---------------------------------------------------------------------------|
| Kronos-mini  | [Kronos-Tokenizer-2k](https://huggingface.co/NeoQuasar/Kronos-Tokenizer-2k)     | 2048           | 4.1M   | ✅ [NeoQuasar/Kronos-mini](https://huggingface.co/NeoQuasar/Kronos-mini)  |
| Kronos-small | [Kronos-Tokenizer-base](https://huggingface.co/NeoQuasar/Kronos-Tokenizer-base) | 512            | 24.7M  | ✅ [NeoQuasar/Kronos-small](https://huggingface.co/NeoQuasar/Kronos-small) |
| Kronos-base  | [Kronos-Tokenizer-base](https://huggingface.co/NeoQuasar/Kronos-Tokenizer-base) | 512            | 102.3M | ✅ [NeoQuasar/Kronos-base](https://huggingface.co/NeoQuasar/Kronos-base)   |
| Kronos-large | [Kronos-Tokenizer-base](https://huggingface.co/NeoQuasar/Kronos-Tokenizer-base) | 512            | 499.2M | ❌                                                                         |


## 🚀 Getting Started

### Installation

1. Install Python 3.10+, and then install the dependencies:

```shell
pip install -r requirements.txt
```

### 📈 Making Forecasts

Forecasting with Kronos is straightforward using the `KronosPredictor` class. It handles data preprocessing, normalization, prediction, and inverse normalization, allowing you to get from raw data to forecasts in just a few lines of code.

**Important Note**: The `max_context` for `Kronos-small` and `Kronos-base` is **512**. This is the maximum sequence length the model can process. For optimal performance, it is recommended that your input data length (i.e., `lookback`) does not exceed this limit. The `KronosPredictor` will automatically handle truncation for longer contexts.

Here is a step-by-step guide to making your first forecast.

#### 1. Load the Tokenizer and Model

First, load a pre-trained Kronos model and its corresponding tokenizer from the Hugging Face Hub.

```python
from model import Kronos, KronosTokenizer, KronosPredictor

# Load from Hugging Face Hub
tokenizer = KronosTokenizer.from_pretrained(&quot;NeoQuasar/Kronos-Tokenizer-base&quot;)
model = Kronos.from_pretrained(&quot;NeoQuasar/Kronos-small&quot;)
```

#### 2. Instantiate the Predictor

Create an instance of `KronosPredictor`, passing the model, tokenizer, and desired device.

```python
# Initialize the predictor
predictor = KronosPredictor(model, tokenizer, device=&quot;cuda:0&quot;, max_context=512)
```

#### 3. Prepare Input Data

The `predict` method requires three main inputs:
-   `df`: A pandas DataFrame containing the historical K-line data. It must include columns `[&#039;open&#039;, &#039;high&#039;, &#039;low&#039;, &#039;close&#039;]`. `volume` and `amount` are optional.
-   `x_timestamp`: A pandas Series of timestamps corresponding to the historical data in `df`.
-   `y_timestamp`: A pandas Series of timestamps for the future periods you want to predict.

```python
import pandas as pd

# Load your data
df = pd.read_csv(&quot;./data/XSHG_5min_600977.csv&quot;)
df[&#039;timestamps&#039;] = pd.to_datetime(df[&#039;timestamps&#039;])

# Define context window and prediction length
lookback = 400
pred_len = 120

# Prepare inputs for the predictor
x_df = df.loc[:lookback-1, [&#039;open&#039;, &#039;high&#039;, &#039;low&#039;, &#039;close&#039;, &#039;volume&#039;, &#039;amount&#039;]]
x_timestamp = df.loc[:lookback-1, &#039;timestamps&#039;]
y_timestamp = df.loc[lookback:lookback+pred_len-1, &#039;timestamps&#039;]
```

#### 4. Generate Forecasts 

Call the `predict` method to generate forecasts. You can control the sampling process with parameters like `T`, `top_p`, and `sample_count` for probabilistic forecasting.

```python
# Generate predictions
pred_df = predictor.predict(
    df=x_df,
    x_timestamp=x_timestamp,
    y_timestamp=y_timestamp,
    pred_len=pred_len,
    T=1.0,          # Temperature for sampling
    top_p=0.9,      # Nucleus sampling probability
    sample_count=1  # Number of forecast paths to generate and average
)

print(&quot;Forecasted Data Head:&quot;)
print(pred_df.head())
```

The `predict` method returns a pandas DataFrame containing the forecasted values for `open`, `high`, `low`, `close`, `volume`, and `amount`, indexed by the `y_timestamp` you provided.

For efficient processing of multiple time series, Kronos provides a `predict_batch` method that enables parallel prediction on multiple datasets simultaneously. This is particularly useful when you need to forecast multiple assets or time periods at once.

```python
# Prepare multiple datasets for batch prediction
df_list = [df1, df2, df3]  # List of DataFrames
x_timestamp_list = [x_ts1, x_ts2, x_ts3]  # List of historical timestamps
y_timestamp_list = [y_ts1, y_ts2, y_ts3]  # List of future timestamps

# Generate batch predictions
pred_df_list = predictor.predict_batch(
    df_list=df_list,
    x_timestamp_list=x_timestamp_list,
    y_timestamp_list=y_timestamp_list,
    pred_len=pred_len,
    T=1.0,
    top_p=0.9,
    sample_count=1,
    verbose=True
)

# pred_df_list contains prediction results in the same order as input
for i, pred_df in enumerate(pred_df_list):
    print(f&quot;Predictions for series {i}:&quot;)
    print(pred_df.head())
```

**Important Requirements for Batch Prediction:**
- All series must have the same historical length (lookback window)
- All series must have the same prediction length (`pred_len`)
- Each DataFrame must contain the required columns: `[&#039;open&#039;, &#039;high&#039;, &#039;low&#039;, &#039;close&#039;]`
- `volume` and `amount` columns are optional and will be filled with zeros if missing

The `predict_batch` method leverages GPU parallelism for efficient processing and automatically handles normalization and denormalization for each series independently.

#### 5. Example and Visualization

For a complete, runnable script that includes data loading, prediction, and plotting, please see [`examples/prediction_example.py`](examples/prediction_example.py).

Running this script will generate a plot comparing the ground truth data against the model&#039;s forecast, similar to the one shown below:

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;figures/prediction_example.png&quot; alt=&quot;Forecast Example&quot; align=&quot;center&quot; width=&quot;600px&quot; /&gt;
&lt;/p&gt;

Additionally, we provide a script that makes predictions without Volume and Amount data, which can be found in [`examples/prediction_wo_vol_example.py`](examples/prediction_wo_vol_example.py).


## 🔧 Finetuning on Your Own Data (A-Share Market Example)

We provide a complete pipeline for finetuning Kronos on your own datasets. As an example, we demonstrate how to use [Qlib](https://github.com/microsoft/qlib) to prepare data from the Chinese A-share market and conduct a simple backtest.

&gt; **Disclaimer:** This pipeline is intended as a demonstration to illustrate the finetuning process. It is a simplified example and not a production-ready quantitative trading system. A robust quantitative strategy requires more sophisticated techniques, such as portfolio optimization and risk factor neutralization, to achieve stable alpha.

The finetuning process is divided into four main steps:

1.  **Configuration**: Set up paths and hyperparameters.
2.  **Data Preparation**: Process and split your data using Qlib.
3.  **Model Finetuning**: Finetune the Tokenizer and the Predictor models.
4.  **Backtesting**: Evaluate the finetuned model&#039;s performance.

### Prerequisites

1.  First, ensure you have all dependencies from `requirements.txt` installed.
2.  This pipeline relies on `qlib`. Please install it:
    ```shell
      pip install pyqlib
    ```
3.  You will need to prepare your Qlib data. Follow the [official Qlib guide](https://github.com/microsoft/qlib) to download and set up your data locally. The example scripts assume you are using daily frequency data.

### Step 1: Configure Your Experiment

All settings for data, training, and model paths are centralized in `finetune/config.py`. Before running any scripts, please **modify the following paths** according to your environment:

*   `qlib_data_path`: Path to your local Qlib data directory.
*   `dataset_path`: Directory where the processed train/validation/test pickle files will be saved.
*   `save_path`: Base directory for saving model checkpoints.
*   `backtest_result_path`: Directory for saving backtesting results.
*   `pretrained_tokenizer_path` and `pretrained_predictor_path`: Paths to the pre-trained models you want to start from (can be local paths or Hugging Face model names).

You can also adjust other parameters like `instrument`, `train_time_range`, `epochs`, and `batch_size` to fit your specific task. If you don&#039;t use [Comet.ml](https://www.comet.com/), set `use_comet = False`.

### Step 2: Prepare the Dataset

Run the data preprocessing script. This script will load raw market data from your Qlib directory, process it, split it into training, validation, and test sets, and save them as pickle files.

```shell
python finetune/qlib_data_preprocess.py
```

After running, you will find `train_data.pkl`, `val_data.pkl`, and `test_data.pkl` in the directory specified by `dataset_path` in your config.

### Step 3: Run the Finetuning

The finetuning process consists of two stages: finetuning the tokenizer and then the predictor. Both training scripts are designed for multi-GPU training using `torchrun`.

#### 3.1 Finetune the Tokenizer

This step adjusts the tokenizer to the data distribution of your specific domain.

```shell
# Replace NUM_GPUS with the number of GPUs you want to use (e.g., 2)
torchrun --standalone --nproc_per_node=NUM_GPUS finetune/train_tokenizer.py
```

The best tokenizer checkpoint will be saved to the path configured in `config.py` (derived from `save_path` and `tokenizer_save_folder_name`).

#### 3.2 Finetune the Predictor

This step finetunes the main Kronos model for the forecasting task.

```shell
# Replace NUM_GPUS with the number of GPUs you want to use (e.g., 2)
torchrun --standalone --nproc_per_node=NUM_GPUS finetune/train_predictor.py
```

The best predictor checkpoint will be saved to the path configured in `config.py`.

### Step 4: Evaluate with Backtesting

Finally, run the backtesting script to evaluate your finetuned model. This script loads the models, performs inference on the test set, generates prediction signals (e.g., forecasted price change), and runs a simple top-K strategy backtest.

```shell
# Specify the GPU for inference
python finetune/qlib_test.py --device cuda:0
```

The script will output a detailed performance analysis in your console and generate a plot showing the cumulative return curves of your strategy against the benchmark, similar to the one below:

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;figures/backtest_result_example.png&quot; alt=&quot;Backtest Example&quot; align=&quot;center&quot; width=&quot;700px&quot; /&gt;
&lt;/p&gt;

### 💡 From Demo to Production: Important Considerations

*   **Raw Signals vs. Pure Alpha**: The signals generated by the model in this demo are raw predictions. In a real-world quantitative workflow, these signals would typically be fed into a portfolio optimization model. This model would apply constraints to neutralize exposure to common risk factors (e.g., market beta, style factors like size and value), thereby isolating the **&quot;pure alpha&quot;** and improving the strategy&#039;s robustness.
*   **Data Handling**: The provided `QlibDataset` is an example. For different data sources or formats, you will need to adapt the data loading and preprocessing logic.
*   **Strategy and Backtesting Complexity**: The simple top-K strategy used here is a basic starting point. Production-level strategies often incorporate more complex logic for portfolio construction, dynamic position sizing, and risk management (e.g., stop-loss/take-profit rules). Furthermore, a high-fidelity backtest should meticulously model transaction costs, slippage, and market impact to provide a more accurate estimate of real-world performance.

&gt; **📝 AI-Generated Comments**: Please note that many of the code comments within the `finetune/` directory were generated by an AI assistant (Gemini 2.5 Pro) for explanatory purposes. While they aim to be helpful, they may contain inaccuracies. We recommend treating the code itself as the definitive source of logic.

## 📖 Citation

If you use Kronos in your research, we would appreciate a citation to our [paper](https://arxiv.org/abs/2508.02739):

```
@misc{shi2025kronos,
      title={Kronos: A Foundation Model for the Language of Financial Markets}, 
      author={Yu Shi and Zongliang Fu and Shuo Chen and Bohan Zhao and Wei Xu and Changshui Zhang and Jian Li},
      year={2025},
      eprint={2508.02739},
      archivePrefix={arXiv},
      primaryClass={q-fin.ST},
      url={https://arxiv.org/abs/2508.02739}, 
}
```

## 📜 License 
This project is licensed under the [MIT License](./LICENSE).









</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[ahujasid/blender-mcp]]></title>
            <link>https://github.com/ahujasid/blender-mcp</link>
            <guid>https://github.com/ahujasid/blender-mcp</guid>
            <pubDate>Tue, 28 Oct 2025 00:04:16 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ahujasid/blender-mcp">ahujasid/blender-mcp</a></h1>
            <p></p>
            <p>Language: Python</p>
            <p>Stars: 13,965</p>
            <p>Forks: 1,322</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre>

# BlenderMCP - Blender Model Context Protocol Integration

BlenderMCP connects Blender to Claude AI through the Model Context Protocol (MCP), allowing Claude to directly interact with and control Blender. This integration enables prompt assisted 3D modeling, scene creation, and manipulation.

**We have no official website. Any website you see online is unofficial and has no affiliation with this project. Use them at your own risk.**

[Full tutorial](https://www.youtube.com/watch?v=lCyQ717DuzQ)

### Join the Community

Give feedback, get inspired, and build on top of the MCP: [Discord](https://discord.gg/z5apgR8TFU)

### Supporters

[CodeRabbit](https://www.coderabbit.ai/)

[Satish Goda](https://github.com/satishgoda)

**All supporters:**

[Support this project](https://github.com/sponsors/ahujasid)

## Release notes (1.2.0)
- View screenshots for Blender viewport to better understand the scene
- Search and download Sketchfab models


### Previously added features:
- Support for Poly Haven assets through their API
- Support to generate 3D models using Hyper3D Rodin
- For newcomers, you can go straight to Installation. For existing users, see the points below
- Download the latest addon.py file and replace the older one, then add it to Blender
- Delete the MCP server from Claude and add it back again, and you should be good to go!

## Features

- **Two-way communication**: Connect Claude AI to Blender through a socket-based server
- **Object manipulation**: Create, modify, and delete 3D objects in Blender
- **Material control**: Apply and modify materials and colors
- **Scene inspection**: Get detailed information about the current Blender scene
- **Code execution**: Run arbitrary Python code in Blender from Claude

## Components

The system consists of two main components:

1. **Blender Addon (`addon.py`)**: A Blender addon that creates a socket server within Blender to receive and execute commands
2. **MCP Server (`src/blender_mcp/server.py`)**: A Python server that implements the Model Context Protocol and connects to the Blender addon

## Installation


### Prerequisites

- Blender 3.0 or newer
- Python 3.10 or newer
- uv package manager: 

**If you&#039;re on Mac, please install uv as**
```bash
brew install uv
```
**On Windows**
```bash
powershell -c &quot;irm https://astral.sh/uv/install.ps1 | iex&quot; 
```
and then
```bash
set Path=C:\Users\nntra\.local\bin;%Path%
```

Otherwise installation instructions are on their website: [Install uv](https://docs.astral.sh/uv/getting-started/installation/)

**⚠️ Do not proceed before installing UV**

### Environment Variables

The following environment variables can be used to configure the Blender connection:

- `BLENDER_HOST`: Host address for Blender socket server (default: &quot;localhost&quot;)
- `BLENDER_PORT`: Port number for Blender socket server (default: 9876)

Example:
```bash
export BLENDER_HOST=&#039;host.docker.internal&#039;
export BLENDER_PORT=9876
```

### Claude for Desktop Integration

[Watch the setup instruction video](https://www.youtube.com/watch?v=neoK_WMq92g) (Assuming you have already installed uv)

Go to Claude &gt; Settings &gt; Developer &gt; Edit Config &gt; claude_desktop_config.json to include the following:

```json
{
    &quot;mcpServers&quot;: {
        &quot;blender&quot;: {
            &quot;command&quot;: &quot;uvx&quot;,
            &quot;args&quot;: [
                &quot;blender-mcp&quot;
            ]
        }
    }
}
```

### Cursor integration

[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/install-mcp?name=blender&amp;config=eyJjb21tYW5kIjoidXZ4IGJsZW5kZXItbWNwIn0%3D)

For Mac users, go to Settings &gt; MCP and paste the following 

- To use as a global server, use &quot;add new global MCP server&quot; button and paste
- To use as a project specific server, create `.cursor/mcp.json` in the root of the project and paste


```json
{
    &quot;mcpServers&quot;: {
        &quot;blender&quot;: {
            &quot;command&quot;: &quot;uvx&quot;,
            &quot;args&quot;: [
                &quot;blender-mcp&quot;
            ]
        }
    }
}
```

For Windows users, go to Settings &gt; MCP &gt; Add Server, add a new server with the following settings:

```json
{
    &quot;mcpServers&quot;: {
        &quot;blender&quot;: {
            &quot;command&quot;: &quot;cmd&quot;,
            &quot;args&quot;: [
                &quot;/c&quot;,
                &quot;uvx&quot;,
                &quot;blender-mcp&quot;
            ]
        }
    }
}
```

[Cursor setup video](https://www.youtube.com/watch?v=wgWsJshecac)

**⚠️ Only run one instance of the MCP server (either on Cursor or Claude Desktop), not both**

### Visual Studio Code Integration

_Prerequisites_: Make sure you have [Visual Studio Code](https://code.visualstudio.com/) installed before proceeding.

[![Install in VS Code](https://img.shields.io/badge/VS_Code-Install_blender--mcp_server-0098FF?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=ffffff)](vscode:mcp/install?%7B%22name%22%3A%22blender-mcp%22%2C%22type%22%3A%22stdio%22%2C%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22blender-mcp%22%5D%7D)

### Installing the Blender Addon

1. Download the `addon.py` file from this repo
1. Open Blender
2. Go to Edit &gt; Preferences &gt; Add-ons
3. Click &quot;Install...&quot; and select the `addon.py` file
4. Enable the addon by checking the box next to &quot;Interface: Blender MCP&quot;


## Usage

### Starting the Connection
![BlenderMCP in the sidebar](assets/addon-instructions.png)

1. In Blender, go to the 3D View sidebar (press N if not visible)
2. Find the &quot;BlenderMCP&quot; tab
3. Turn on the Poly Haven checkbox if you want assets from their API (optional)
4. Click &quot;Connect to Claude&quot;
5. Make sure the MCP server is running in your terminal

### Using with Claude

Once the config file has been set on Claude, and the addon is running on Blender, you will see a hammer icon with tools for the Blender MCP.

![BlenderMCP in the sidebar](assets/hammer-icon.png)

#### Capabilities

- Get scene and object information 
- Create, delete and modify shapes
- Apply or create materials for objects
- Execute any Python code in Blender
- Download the right models, assets and HDRIs through [Poly Haven](https://polyhaven.com/)
- AI generated 3D models through [Hyper3D Rodin](https://hyper3d.ai/)


### Example Commands

Here are some examples of what you can ask Claude to do:

- &quot;Create a low poly scene in a dungeon, with a dragon guarding a pot of gold&quot; [Demo](https://www.youtube.com/watch?v=DqgKuLYUv00)
- &quot;Create a beach vibe using HDRIs, textures, and models like rocks and vegetation from Poly Haven&quot; [Demo](https://www.youtube.com/watch?v=I29rn92gkC4)
- Give a reference image, and create a Blender scene out of it [Demo](https://www.youtube.com/watch?v=FDRb03XPiRo)
- &quot;Generate a 3D model of a garden gnome through Hyper3D&quot;
- &quot;Get information about the current scene, and make a threejs sketch from it&quot; [Demo](https://www.youtube.com/watch?v=jxbNI5L7AH8)
- &quot;Make this car red and metallic&quot; 
- &quot;Create a sphere and place it above the cube&quot;
- &quot;Make the lighting like a studio&quot;
- &quot;Point the camera at the scene, and make it isometric&quot;

## Hyper3D integration

Hyper3D&#039;s free trial key allows you to generate a limited number of models per day. If the daily limit is reached, you can wait for the next day&#039;s reset or obtain your own key from hyper3d.ai and fal.ai.

## Troubleshooting

- **Connection issues**: Make sure the Blender addon server is running, and the MCP server is configured on Claude, DO NOT run the uvx command in the terminal. Sometimes, the first command won&#039;t go through but after that it starts working.
- **Timeout errors**: Try simplifying your requests or breaking them into smaller steps
- **Poly Haven integration**: Claude is sometimes erratic with its behaviour
- **Have you tried turning it off and on again?**: If you&#039;re still having connection errors, try restarting both Claude and the Blender server


## Technical Details

### Communication Protocol

The system uses a simple JSON-based protocol over TCP sockets:

- **Commands** are sent as JSON objects with a `type` and optional `params`
- **Responses** are JSON objects with a `status` and `result` or `message`

## Limitations &amp; Security Considerations

- The `execute_blender_code` tool allows running arbitrary Python code in Blender, which can be powerful but potentially dangerous. Use with caution in production environments. ALWAYS save your work before using it.
- Poly Haven requires downloading models, textures, and HDRI images. If you do not want to use it, please turn it off in the checkbox in Blender. 
- Complex operations might need to be broken down into smaller steps


## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## Disclaimer

This is a third-party integration and not made by Blender. Made by [Siddharth](https://x.com/sidahuj)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[vanna-ai/vanna]]></title>
            <link>https://github.com/vanna-ai/vanna</link>
            <guid>https://github.com/vanna-ai/vanna</guid>
            <pubDate>Tue, 28 Oct 2025 00:04:15 GMT</pubDate>
            <description><![CDATA[🤖 Chat with your SQL database 📊. Accurate Text-to-SQL Generation via LLMs using RAG 🔄.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vanna-ai/vanna">vanna-ai/vanna</a></h1>
            <p>🤖 Chat with your SQL database 📊. Accurate Text-to-SQL Generation via LLMs using RAG 🔄.</p>
            <p>Language: Python</p>
            <p>Stars: 21,199</p>
            <p>Forks: 1,976</p>
            <p>Stars today: 61 stars today</p>
            <h2>README</h2><pre>

| GitHub | PyPI | Documentation | Gurubase |
| ------ | ---- | ------------- | -------- |
| [![GitHub](https://img.shields.io/badge/GitHub-vanna-blue?logo=github)](https://github.com/vanna-ai/vanna) | [![PyPI](https://img.shields.io/pypi/v/vanna?logo=pypi)](https://pypi.org/project/vanna/) | [![Documentation](https://img.shields.io/badge/Documentation-vanna-blue?logo=read-the-docs)](https://vanna.ai/docs/) | [![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Vanna%20Guru-006BFF)](https://gurubase.io/g/vanna) |

# Vanna
Vanna is an MIT-licensed open-source Python RAG (Retrieval-Augmented Generation) framework for SQL generation and related functionality.

https://github.com/vanna-ai/vanna/assets/7146154/1901f47a-515d-4982-af50-f12761a3b2ce

![vanna-quadrants](https://github.com/vanna-ai/vanna/assets/7146154/1c7c88ba-c144-4ecf-a028-cf5ba7344ca2)

## How Vanna works

![Screen Recording 2024-01-24 at 11 21 37 AM](https://github.com/vanna-ai/vanna/assets/7146154/1d2718ad-12a8-4a76-afa2-c61754462f93)


Vanna works in two easy steps - train a RAG &quot;model&quot; on your data, and then ask questions which will return SQL queries that can be set up to automatically run on your database.

1. **Train a RAG &quot;model&quot; on your data**.
2. **Ask questions**.

![](img/vanna-readme-diagram.png)

If you don&#039;t know what RAG is, don&#039;t worry -- you don&#039;t need to know how this works under the hood to use it. You just need to know that you &quot;train&quot; a model, which stores some metadata and then use it to &quot;ask&quot; questions.

See the [base class](https://github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py) for more details on how this works under the hood.

## User Interfaces
These are some of the user interfaces that we&#039;ve built using Vanna. You can use these as-is or as a starting point for your own custom interface.

- [Jupyter Notebook](https://vanna.ai/docs/postgres-openai-vanna-vannadb/)
- [vanna-ai/vanna-streamlit](https://github.com/vanna-ai/vanna-streamlit)
- [vanna-ai/vanna-flask](https://github.com/vanna-ai/vanna-flask)
- [vanna-ai/vanna-slack](https://github.com/vanna-ai/vanna-slack)

## Supported LLMs

- [OpenAI](https://github.com/vanna-ai/vanna/tree/main/src/vanna/openai)
- [Anthropic](https://github.com/vanna-ai/vanna/tree/main/src/vanna/anthropic)
- [Gemini](https://github.com/vanna-ai/vanna/blob/main/src/vanna/google/gemini_chat.py)
- [HuggingFace](https://github.com/vanna-ai/vanna/blob/main/src/vanna/hf/hf.py)
- [AWS Bedrock](https://github.com/vanna-ai/vanna/tree/main/src/vanna/bedrock)
- [Ollama](https://github.com/vanna-ai/vanna/tree/main/src/vanna/ollama)
- [Qianwen](https://github.com/vanna-ai/vanna/tree/main/src/vanna/qianwen)
- [Qianfan](https://github.com/vanna-ai/vanna/tree/main/src/vanna/qianfan)
- [Zhipu](https://github.com/vanna-ai/vanna/tree/main/src/vanna/ZhipuAI)

## Supported VectorStores

- [AzureSearch](https://github.com/vanna-ai/vanna/tree/main/src/vanna/azuresearch)
- [Opensearch](https://github.com/vanna-ai/vanna/tree/main/src/vanna/opensearch)
- [PgVector](https://github.com/vanna-ai/vanna/tree/main/src/vanna/pgvector)
- [PineCone](https://github.com/vanna-ai/vanna/tree/main/src/vanna/pinecone)
- [ChromaDB](https://github.com/vanna-ai/vanna/tree/main/src/vanna/chromadb)
- [FAISS](https://github.com/vanna-ai/vanna/tree/main/src/vanna/faiss)
- [Marqo](https://github.com/vanna-ai/vanna/tree/main/src/vanna/marqo)
- [Milvus](https://github.com/vanna-ai/vanna/tree/main/src/vanna/milvus)
- [Qdrant](https://github.com/vanna-ai/vanna/tree/main/src/vanna/qdrant)
- [Weaviate](https://github.com/vanna-ai/vanna/tree/main/src/vanna/weaviate)
- [Oracle](https://github.com/vanna-ai/vanna/tree/main/src/vanna/oracle)

## Supported Databases

- [PostgreSQL](https://www.postgresql.org/)
- [MySQL](https://www.mysql.com/)
- [PrestoDB](https://prestodb.io/)
- [Apache Hive](https://hive.apache.org/)
- [ClickHouse](https://clickhouse.com/)
- [Snowflake](https://www.snowflake.com/en/)
- [Oracle](https://www.oracle.com/)
- [Microsoft SQL Server](https://www.microsoft.com/en-us/sql-server/sql-server-downloads)
- [BigQuery](https://cloud.google.com/bigquery)
- [SQLite](https://www.sqlite.org/)
- [DuckDB](https://duckdb.org/)


## Getting started
See the [documentation](https://vanna.ai/docs/) for specifics on your desired database, LLM, etc.

If you want to get a feel for how it works after training, you can try this [Colab notebook](https://vanna.ai/docs/app/).


### Install
```bash
pip install vanna
```

There are a number of optional packages that can be installed so see the [documentation](https://vanna.ai/docs/) for more details.

### Import
See the [documentation](https://vanna.ai/docs/) if you&#039;re customizing the LLM or vector database.

```python
# The import statement will vary depending on your LLM and vector database. This is an example for OpenAI + ChromaDB

from vanna.openai.openai_chat import OpenAI_Chat
from vanna.chromadb.chromadb_vector import ChromaDB_VectorStore

class MyVanna(ChromaDB_VectorStore, OpenAI_Chat):
    def __init__(self, config=None):
        ChromaDB_VectorStore.__init__(self, config=config)
        OpenAI_Chat.__init__(self, config=config)

vn = MyVanna(config={&#039;api_key&#039;: &#039;sk-...&#039;, &#039;model&#039;: &#039;gpt-4-...&#039;})

# See the documentation for other options

```


## Training
You may or may not need to run these `vn.train` commands depending on your use case. See the [documentation](https://vanna.ai/docs/) for more details.

These statements are shown to give you a feel for how it works.

### Train with DDL Statements
DDL statements contain information about the table names, columns, data types, and relationships in your database.

```python
vn.train(ddl=&quot;&quot;&quot;
    CREATE TABLE IF NOT EXISTS my-table (
        id INT PRIMARY KEY,
        name VARCHAR(100),
        age INT
    )
&quot;&quot;&quot;)
```

### Train with Documentation
Sometimes you may want to add documentation about your business terminology or definitions.

```python
vn.train(documentation=&quot;Our business defines XYZ as ...&quot;)
```

### Train with SQL
You can also add SQL queries to your training data. This is useful if you have some queries already laying around. You can just copy and paste those from your editor to begin generating new SQL.

```python
vn.train(sql=&quot;SELECT name, age FROM my-table WHERE name = &#039;John Doe&#039;&quot;)
```


## Asking questions
```python
vn.ask(&quot;What are the top 10 customers by sales?&quot;)
```

You&#039;ll get SQL
```sql
SELECT c.c_name as customer_name,
        sum(l.l_extendedprice * (1 - l.l_discount)) as total_sales
FROM   snowflake_sample_data.tpch_sf1.lineitem l join snowflake_sample_data.tpch_sf1.orders o
        ON l.l_orderkey = o.o_orderkey join snowflake_sample_data.tpch_sf1.customer c
        ON o.o_custkey = c.c_custkey
GROUP BY customer_name
ORDER BY total_sales desc limit 10;
```

If you&#039;ve connected to a database, you&#039;ll get the table:
&lt;div&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;CUSTOMER_NAME&lt;/th&gt;
      &lt;th&gt;TOTAL_SALES&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Customer#000143500&lt;/td&gt;
      &lt;td&gt;6757566.0218&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Customer#000095257&lt;/td&gt;
      &lt;td&gt;6294115.3340&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Customer#000087115&lt;/td&gt;
      &lt;td&gt;6184649.5176&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Customer#000131113&lt;/td&gt;
      &lt;td&gt;6080943.8305&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;Customer#000134380&lt;/td&gt;
      &lt;td&gt;6075141.9635&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;Customer#000103834&lt;/td&gt;
      &lt;td&gt;6059770.3232&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;Customer#000069682&lt;/td&gt;
      &lt;td&gt;6057779.0348&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;Customer#000102022&lt;/td&gt;
      &lt;td&gt;6039653.6335&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;td&gt;Customer#000098587&lt;/td&gt;
      &lt;td&gt;6027021.5855&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;9&lt;/th&gt;
      &lt;td&gt;Customer#000064660&lt;/td&gt;
      &lt;td&gt;5905659.6159&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

You&#039;ll also get an automated Plotly chart:
![](img/top-10-customers.png)

## RAG vs. Fine-Tuning
RAG
- Portable across LLMs
- Easy to remove training data if any of it becomes obsolete
- Much cheaper to run than fine-tuning
- More future-proof -- if a better LLM comes out, you can just swap it out

Fine-Tuning
- Good if you need to minimize tokens in the prompt
- Slow to get started
- Expensive to train and run (generally)

## Why Vanna?

1. **High accuracy on complex datasets.**
    - Vanna’s capabilities are tied to the training data you give it
    - More training data means better accuracy for large and complex datasets
2. **Secure and private.**
    - Your database contents are never sent to the LLM or the vector database
    - SQL execution happens in your local environment
3. **Self learning.**
    - If using via Jupyter, you can choose to &quot;auto-train&quot; it on the queries that were successfully executed
    - If using via other interfaces, you can have the interface prompt the user to provide feedback on the results
    - Correct question to SQL pairs are stored for future reference and make the future results more accurate
4. **Supports any SQL database.**
    - The package allows you to connect to any SQL database that you can otherwise connect to with Python
5. **Choose your front end.**
    - Most people start in a Jupyter Notebook.
    - Expose to your end users via Slackbot, web app, Streamlit app, or a custom front end.

## Extending Vanna
Vanna is designed to connect to any database, LLM, and vector database. There&#039;s a [VannaBase](https://github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py) abstract base class that defines some basic functionality. The package provides implementations for use with OpenAI and ChromaDB. You can easily extend Vanna to use your own LLM or vector database. See the [documentation](https://vanna.ai/docs/) for more details.

## Vanna in 100 Seconds

https://github.com/vanna-ai/vanna/assets/7146154/eb90ee1e-aa05-4740-891a-4fc10e611cab

## More resources
 - [Full Documentation](https://vanna.ai/docs/)
 - [Website](https://vanna.ai)
 - [Discord group for support](https://discord.gg/qUZYKHremx)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[paperless-ngx/paperless-ngx]]></title>
            <link>https://github.com/paperless-ngx/paperless-ngx</link>
            <guid>https://github.com/paperless-ngx/paperless-ngx</guid>
            <pubDate>Tue, 28 Oct 2025 00:04:14 GMT</pubDate>
            <description><![CDATA[A community-supported supercharged document management system: scan, index and archive all your documents]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/paperless-ngx/paperless-ngx">paperless-ngx/paperless-ngx</a></h1>
            <p>A community-supported supercharged document management system: scan, index and archive all your documents</p>
            <p>Language: Python</p>
            <p>Stars: 33,823</p>
            <p>Forks: 2,109</p>
            <p>Stars today: 201 stars today</p>
            <h2>README</h2><pre>[![ci](https://github.com/paperless-ngx/paperless-ngx/workflows/ci/badge.svg)](https://github.com/paperless-ngx/paperless-ngx/actions)
[![Crowdin](https://badges.crowdin.net/paperless-ngx/localized.svg)](https://crowdin.com/project/paperless-ngx)
[![Documentation Status](https://img.shields.io/github/deployments/paperless-ngx/paperless-ngx/github-pages?label=docs)](https://docs.paperless-ngx.com)
[![codecov](https://codecov.io/gh/paperless-ngx/paperless-ngx/branch/main/graph/badge.svg?token=VK6OUPJ3TY)](https://codecov.io/gh/paperless-ngx/paperless-ngx)
[![Chat on Matrix](https://matrix.to/img/matrix-badge.svg)](https://matrix.to/#/%23paperlessngx%3Amatrix.org)
[![demo](https://cronitor.io/badges/ve7ItY/production/W5E_B9jkelG9ZbDiNHUPQEVH3MY.svg)](https://demo.paperless-ngx.com)

&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/paperless-ngx/paperless-ngx/blob/main/resources/logo/web/png/White%20logo%20-%20no%20background.png&quot; width=&quot;50%&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/paperless-ngx/paperless-ngx/raw/main/resources/logo/web/png/Black%20logo%20-%20no%20background.png&quot; width=&quot;50%&quot;&gt;
    &lt;img src=&quot;https://github.com/paperless-ngx/paperless-ngx/raw/main/resources/logo/web/png/Black%20logo%20-%20no%20background.png&quot; width=&quot;50%&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;!-- omit in toc --&gt;

# Paperless-ngx

Paperless-ngx is a document management system that transforms your physical documents into a searchable online archive so you can keep, well, _less paper_.

Paperless-ngx is the official successor to the original [Paperless](https://github.com/the-paperless-project/paperless) &amp; [Paperless-ng](https://github.com/jonaswinkler/paperless-ng) projects and is designed to distribute the responsibility of advancing and supporting the project among a team of people. [Consider joining us!](#community-support)

Thanks to the generous folks at [DigitalOcean](https://m.do.co/c/8d70b916d462), a demo is available at [demo.paperless-ngx.com](https://demo.paperless-ngx.com) using login `demo` / `demo`. _Note: demo content is reset frequently and confidential information should not be uploaded._

- [Features](#features)
- [Getting started](#getting-started)
- [Contributing](#contributing)
  - [Community Support](#community-support)
  - [Translation](#translation)
  - [Feature Requests](#feature-requests)
  - [Bugs](#bugs)
- [Related Projects](#related-projects)
- [Important Note](#important-note)

&lt;p align=&quot;right&quot;&gt;This project is supported by:&lt;br/&gt;
  &lt;a href=&quot;https://m.do.co/c/8d70b916d462&quot; style=&quot;padding-top: 4px; display: block;&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_white.svg&quot; width=&quot;140px&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_blue.svg&quot; width=&quot;140px&quot;&gt;
      &lt;img src=&quot;https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_black_.svg&quot; width=&quot;140px&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

# Features

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/docs/assets/screenshots/documents-smallcards-dark.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/docs/assets/screenshots/documents-smallcards.png&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/docs/assets/screenshots/documents-smallcards.png&quot;&gt;
&lt;/picture&gt;

A full list of [features](https://docs.paperless-ngx.com/#features) and [screenshots](https://docs.paperless-ngx.com/#screenshots) are available in the [documentation](https://docs.paperless-ngx.com/).

# Getting started

The easiest way to deploy paperless is `docker compose`. The files in the [`/docker/compose` directory](https://github.com/paperless-ngx/paperless-ngx/tree/main/docker/compose) are configured to pull the image from the GitHub container registry.

If you&#039;d like to jump right in, you can configure a `docker compose` environment with our install script:

```bash
bash -c &quot;$(curl -L https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/install-paperless-ngx.sh)&quot;
```

More details and step-by-step guides for alternative installation methods can be found in [the documentation](https://docs.paperless-ngx.com/setup/#installation).

Migrating from Paperless-ng is easy, just drop in the new docker image! See the [documentation on migrating](https://docs.paperless-ngx.com/setup/#migrating-to-paperless-ngx) for more details.

&lt;!-- omit in toc --&gt;

### Documentation

The documentation for Paperless-ngx is available at [https://docs.paperless-ngx.com](https://docs.paperless-ngx.com/).

# Contributing

If you feel like contributing to the project, please do! Bug fixes, enhancements, visual fixes etc. are always welcome. If you want to implement something big: Please start a discussion about that! The [documentation](https://docs.paperless-ngx.com/development/) has some basic information on how to get started.

## Community Support

People interested in continuing the work on paperless-ngx are encouraged to reach out here on github and in the [Matrix Room](https://matrix.to/#/#paperless:matrix.org). If you would like to contribute to the project on an ongoing basis there are multiple [teams](https://github.com/orgs/paperless-ngx/people) (frontend, ci/cd, etc) that could use your help so please reach out!

## Translation

Paperless-ngx is available in many languages that are coordinated on Crowdin. If you want to help out by translating paperless-ngx into your language, please head over to https://crowdin.com/project/paperless-ngx, and thank you! More details can be found in [CONTRIBUTING.md](https://github.com/paperless-ngx/paperless-ngx/blob/main/CONTRIBUTING.md#translating-paperless-ngx).

## Feature Requests

Feature requests can be submitted via [GitHub Discussions](https://github.com/paperless-ngx/paperless-ngx/discussions/categories/feature-requests), you can search for existing ideas, add your own and vote for the ones you care about.

## Bugs

For bugs please [open an issue](https://github.com/paperless-ngx/paperless-ngx/issues) or [start a discussion](https://github.com/paperless-ngx/paperless-ngx/discussions) if you have questions.

# Related Projects

Please see [the wiki](https://github.com/paperless-ngx/paperless-ngx/wiki/Related-Projects) for a user-maintained list of related projects and software that is compatible with Paperless-ngx.

# Important Note

&gt; Document scanners are typically used to scan sensitive documents like your social insurance number, tax records, invoices, etc. **Paperless-ngx should never be run on an untrusted host** because information is stored in clear text without encryption. No guarantees are made regarding security (but we do try!) and you use the app at your own risk.
&gt; **The safest way to run Paperless-ngx is on a local server in your own home with backups in place**.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[microsoft/qlib]]></title>
            <link>https://github.com/microsoft/qlib</link>
            <guid>https://github.com/microsoft/qlib</guid>
            <pubDate>Tue, 28 Oct 2025 00:04:13 GMT</pubDate>
            <description><![CDATA[Qlib is an AI-oriented Quant investment platform that aims to use AI tech to empower Quant Research, from exploring ideas to implementing productions. Qlib supports diverse ML modeling paradigms, including supervised learning, market dynamics modeling, and RL, and is now equipped with https://github.com/microsoft/RD-Agent to automate R&D process.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/qlib">microsoft/qlib</a></h1>
            <p>Qlib is an AI-oriented Quant investment platform that aims to use AI tech to empower Quant Research, from exploring ideas to implementing productions. Qlib supports diverse ML modeling paradigms, including supervised learning, market dynamics modeling, and RL, and is now equipped with https://github.com/microsoft/RD-Agent to automate R&D process.</p>
            <p>Language: Python</p>
            <p>Stars: 32,753</p>
            <p>Forks: 5,055</p>
            <p>Stars today: 65 stars today</p>
            <h2>README</h2><pre>[![Python Versions](https://img.shields.io/pypi/pyversions/pyqlib.svg?logo=python&amp;logoColor=white)](https://pypi.org/project/pyqlib/#files)
[![Platform](https://img.shields.io/badge/platform-linux%20%7C%20windows%20%7C%20macos-lightgrey)](https://pypi.org/project/pyqlib/#files)
[![PypI Versions](https://img.shields.io/pypi/v/pyqlib)](https://pypi.org/project/pyqlib/#history)
[![Upload Python Package](https://github.com/microsoft/qlib/workflows/Upload%20Python%20Package/badge.svg)](https://pypi.org/project/pyqlib/)
[![Github Actions Test Status](https://github.com/microsoft/qlib/workflows/Test/badge.svg?branch=main)](https://github.com/microsoft/qlib/actions)
[![Documentation Status](https://readthedocs.org/projects/qlib/badge/?version=latest)](https://qlib.readthedocs.io/en/latest/?badge=latest)
[![License](https://img.shields.io/pypi/l/pyqlib)](LICENSE)
[![Join the chat at https://gitter.im/Microsoft/qlib](https://badges.gitter.im/Microsoft/qlib.svg)](https://gitter.im/Microsoft/qlib?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge)

## :newspaper: **What&#039;s NEW!** &amp;nbsp;   :sparkling_heart: 

Recent released features

### Introducing &lt;a href=&quot;https://github.com/microsoft/RD-Agent&quot;&gt;&lt;img src=&quot;docs/_static/img/rdagent_logo.png&quot; alt=&quot;RD_Agent&quot; style=&quot;height: 2em&quot;&gt;&lt;/a&gt;: LLM-Based Autonomous Evolving Agents for Industrial Data-Driven R&amp;D

We are excited to announce the release of **RD-Agent**📢, a powerful tool that supports automated factor mining and model optimization in quant investment R&amp;D.

RD-Agent is now available on [GitHub](https://github.com/microsoft/RD-Agent), and we welcome your star🌟!

To learn more, please visit our [♾️Demo page](https://rdagent.azurewebsites.net/). Here, you will find demo videos in both English and Chinese to help you better understand the scenario and usage of RD-Agent.

We have prepared several demo videos for you:
| Scenario | Demo video (English) | Demo video (中文) |
| --                      | ------    | ------    |
| Quant Factor Mining | [Link](https://rdagent.azurewebsites.net/factor_loop?lang=en) | [Link](https://rdagent.azurewebsites.net/factor_loop?lang=zh) |
| Quant Factor Mining from reports | [Link](https://rdagent.azurewebsites.net/report_factor?lang=en) | [Link](https://rdagent.azurewebsites.net/report_factor?lang=zh) |
| Quant Model Optimization | [Link](https://rdagent.azurewebsites.net/model_loop?lang=en) | [Link](https://rdagent.azurewebsites.net/model_loop?lang=zh) |

- 📃**Paper**: [R&amp;D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization](https://arxiv.org/abs/2505.15155)
- 👾**Code**: https://github.com/microsoft/RD-Agent/
```BibTeX
@misc{li2025rdagentquant,
    title={R\&amp;D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization},
    author={Yuante Li and Xu Yang and Xiao Yang and Minrui Xu and Xisen Wang and Weiqing Liu and Jiang Bian},
    year={2025},
    eprint={2505.15155},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}
```
![image](https://github.com/user-attachments/assets/3198bc10-47ba-4ee0-8a8e-46d5ce44f45d)

***

| Feature | Status |
| --                      | ------    |
| [R&amp;D-Agent-Quant](https://arxiv.org/abs/2505.15155) Published | Apply R&amp;D-Agent to Qlib for quant trading | 
| BPQP for End-to-end learning | 📈Coming soon!([Under review](https://github.com/microsoft/qlib/pull/1863)) |
| 🔥LLM-driven Auto Quant Factory🔥 | 🚀 Released in [♾️RD-Agent](https://github.com/microsoft/RD-Agent) on Aug 8, 2024 |
| KRNN and Sandwich models | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/1414/) on May 26, 2023 |
| Release Qlib v0.9.0 | :octocat: [Released](https://github.com/microsoft/qlib/releases/tag/v0.9.0) on Dec 9, 2022 |
| RL Learning Framework | :hammer: :chart_with_upwards_trend: Released on Nov 10, 2022. [#1332](https://github.com/microsoft/qlib/pull/1332), [#1322](https://github.com/microsoft/qlib/pull/1322), [#1316](https://github.com/microsoft/qlib/pull/1316),[#1299](https://github.com/microsoft/qlib/pull/1299),[#1263](https://github.com/microsoft/qlib/pull/1263), [#1244](https://github.com/microsoft/qlib/pull/1244), [#1169](https://github.com/microsoft/qlib/pull/1169), [#1125](https://github.com/microsoft/qlib/pull/1125), [#1076](https://github.com/microsoft/qlib/pull/1076)|
| HIST and IGMTF models | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/1040) on Apr 10, 2022 |
| Qlib [notebook tutorial](https://github.com/microsoft/qlib/tree/main/examples/tutorial) | 📖 [Released](https://github.com/microsoft/qlib/pull/1037) on Apr 7, 2022 | 
| Ibovespa index data | :rice: [Released](https://github.com/microsoft/qlib/pull/990) on Apr 6, 2022 |
| Point-in-Time database | :hammer: [Released](https://github.com/microsoft/qlib/pull/343) on Mar 10, 2022 |
| Arctic Provider Backend &amp; Orderbook data example | :hammer: [Released](https://github.com/microsoft/qlib/pull/744) on Jan 17, 2022 |
| Meta-Learning-based framework &amp; DDG-DA  | :chart_with_upwards_trend:  :hammer: [Released](https://github.com/microsoft/qlib/pull/743) on Jan 10, 2022 | 
| Planning-based portfolio optimization | :hammer: [Released](https://github.com/microsoft/qlib/pull/754) on Dec 28, 2021 | 
| Release Qlib v0.8.0 | :octocat: [Released](https://github.com/microsoft/qlib/releases/tag/v0.8.0) on Dec 8, 2021 |
| ADD model | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/704) on Nov 22, 2021 |
| ADARNN  model | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/689) on Nov 14, 2021 |
| TCN  model | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/668) on Nov 4, 2021 |
| Nested Decision Framework | :hammer: [Released](https://github.com/microsoft/qlib/pull/438) on Oct 1, 2021. [Example](https://github.com/microsoft/qlib/blob/main/examples/nested_decision_execution/workflow.py) and [Doc](https://qlib.readthedocs.io/en/latest/component/highfreq.html) |
| Temporal Routing Adaptor (TRA) | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/531) on July 30, 2021 |
| Transformer &amp; Localformer | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/508) on July 22, 2021 |
| Release Qlib v0.7.0 | :octocat: [Released](https://github.com/microsoft/qlib/releases/tag/v0.7.0) on July 12, 2021 |
| TCTS Model | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/491) on July 1, 2021 |
| Online serving and automatic model rolling | :hammer:  [Released](https://github.com/microsoft/qlib/pull/290) on May 17, 2021 | 
| DoubleEnsemble Model | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/286) on Mar 2, 2021 | 
| High-frequency data processing example | :hammer: [Released](https://github.com/microsoft/qlib/pull/257) on Feb 5, 2021  |
| High-frequency trading example | :chart_with_upwards_trend: [Part of code released](https://github.com/microsoft/qlib/pull/227) on Jan 28, 2021  | 
| High-frequency data(1min) | :rice: [Released](https://github.com/microsoft/qlib/pull/221) on Jan 27, 2021 |
| Tabnet Model | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/205) on Jan 22, 2021 |

Features released before 2021 are not listed here.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;docs/_static/img/logo/1.png&quot; /&gt;
&lt;/p&gt;

Qlib is an open-source, AI-oriented quantitative investment platform that aims to realize the potential, empower research, and create value using AI technologies in quantitative investment, from exploring ideas to implementing productions. Qlib supports diverse machine learning modeling paradigms, including supervised learning, market dynamics modeling, and reinforcement learning.

An increasing number of SOTA Quant research works/papers in diverse paradigms are being released in Qlib to collaboratively solve key challenges in quantitative investment. For example, 1) using supervised learning to mine the market&#039;s complex non-linear patterns from rich and heterogeneous financial data, 2) modeling the dynamic nature of the financial market using adaptive concept drift technology, and 3) using reinforcement learning to model continuous investment decisions and assist investors in optimizing their trading strategies.

It contains the full ML pipeline of data processing, model training, back-testing; and covers the entire chain of quantitative investment: alpha seeking, risk modeling, portfolio optimization, and order execution. 
For more details, please refer to our paper [&quot;Qlib: An AI-oriented Quantitative Investment Platform&quot;](https://arxiv.org/abs/2009.11189).


&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Frameworks, Tutorial, Data &amp; DevOps&lt;/th&gt;
      &lt;th&gt;Main Challenges &amp; Solutions in Quant Research&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;li&gt;&lt;a href=&quot;#plans&quot;&gt;&lt;strong&gt;Plans&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;#framework-of-qlib&quot;&gt;Framework of Qlib&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;#quick-start&quot;&gt;Quick Start&lt;/a&gt;&lt;/li&gt;
          &lt;ul dir=&quot;auto&quot;&gt;
            &lt;li type=&quot;circle&quot;&gt;&lt;a href=&quot;#installation&quot;&gt;Installation&lt;/a&gt; &lt;/li&gt;
            &lt;li type=&quot;circle&quot;&gt;&lt;a href=&quot;#data-preparation&quot;&gt;Data Preparation&lt;/a&gt;&lt;/li&gt;
            &lt;li type=&quot;circle&quot;&gt;&lt;a href=&quot;#auto-quant-research-workflow&quot;&gt;Auto Quant Research Workflow&lt;/a&gt;&lt;/li&gt;
            &lt;li type=&quot;circle&quot;&gt;&lt;a href=&quot;#building-customized-quant-research-workflow-by-code&quot;&gt;Building Customized Quant Research Workflow by Code&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
        &lt;li&gt;&lt;a href=&quot;#quant-dataset-zoo&quot;&gt;&lt;strong&gt;Quant Dataset Zoo&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;#learning-framework&quot;&gt;Learning Framework&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;#more-about-qlib&quot;&gt;More About Qlib&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;#offline-mode-and-online-mode&quot;&gt;Offline Mode and Online Mode&lt;/a&gt;
        &lt;ul&gt;
          &lt;li type=&quot;circle&quot;&gt;&lt;a href=&quot;#performance-of-qlib-data-server&quot;&gt;Performance of Qlib Data Server&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
        &lt;li&gt;&lt;a href=&quot;#related-reports&quot;&gt;Related Reports&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;#contact-us&quot;&gt;Contact Us&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;#contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt;
      &lt;/td&gt;
      &lt;td valign=&quot;baseline&quot;&gt;
        &lt;li&gt;&lt;a href=&quot;#main-challenges--solutions-in-quant-research&quot;&gt;Main Challenges &amp;amp; Solutions in Quant Research&lt;/a&gt;
          &lt;ul&gt;
            &lt;li type=&quot;circle&quot;&gt;&lt;a href=&quot;#forecasting-finding-valuable-signalspatterns&quot;&gt;Forecasting: Finding Valuable Signals/Patterns&lt;/a&gt;
              &lt;ul&gt;
                &lt;li type=&quot;disc&quot;&gt;&lt;a href=&quot;#quant-model-paper-zoo&quot;&gt;&lt;strong&gt;Quant Model (Paper) Zoo&lt;/strong&gt;&lt;/a&gt;
                  &lt;ul&gt;
                    &lt;li type=&quot;circle&quot;&gt;&lt;a href=&quot;#run-a-single-model&quot;&gt;Run a Single Model&lt;/a&gt;&lt;/li&gt;
                    &lt;li type=&quot;circle&quot;&gt;&lt;a href=&quot;#run-multiple-models&quot;&gt;Run Multiple Models&lt;/a&gt;&lt;/li&gt;
                  &lt;/ul&gt;
                &lt;/li&gt;
              &lt;/ul&gt;
            &lt;/li&gt;
          &lt;li type=&quot;circle&quot;&gt;&lt;a href=&quot;#adapting-to-market-dynamics&quot;&gt;Adapting to Market Dynamics&lt;/a&gt;&lt;/li&gt;
          &lt;li type=&quot;circle&quot;&gt;&lt;a href=&quot;#reinforcement-learning-modeling-continuous-decisions&quot;&gt;Reinforcement Learning: modeling continuous decisions&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

# Plans
New features under development(order by estimated release time).
Your feedbacks about the features are very important.
&lt;!-- | Feature                        | Status      | --&gt;
&lt;!-- | --                      | ------    | --&gt;

# Framework of Qlib

&lt;div style=&quot;align: center&quot;&gt;
&lt;img src=&quot;docs/_static/img/framework-abstract.jpg&quot; /&gt;
&lt;/div&gt;

The high-level framework of Qlib can be found above(users can find the [detailed framework](https://qlib.readthedocs.io/en/latest/introduction/introduction.html#framework) of Qlib&#039;s design when getting into nitty gritty).
The components are designed as loose-coupled modules, and each component could be used stand-alone.

Qlib provides a strong infrastructure to support Quant research. [Data](https://qlib.readthedocs.io/en/latest/component/data.html) is always an important part.
A strong learning framework is designed to support diverse learning paradigms (e.g. [reinforcement learning](https://qlib.readthedocs.io/en/latest/component/rl.html), [supervised learning](https://qlib.readthedocs.io/en/latest/component/workflow.html#model-section)) and patterns at different levels(e.g. [market dynamic modeling](https://qlib.readthedocs.io/en/latest/component/meta.html)).
By modeling the market, [trading strategies](https://qlib.readthedocs.io/en/latest/component/strategy.html) will generate trade decisions that will be executed. Multiple trading strategies and executors in different levels or granularities can be [nested to be optimized and run together](https://qlib.readthedocs.io/en/latest/component/highfreq.html).
At last, a comprehensive [analysis](https://qlib.readthedocs.io/en/latest/component/report.html) will be provided and the model can be [served online](https://qlib.readthedocs.io/en/latest/component/online.html) in a low cost.


# Quick Start

This quick start guide tries to demonstrate
1. It&#039;s very easy to build a complete Quant research workflow and try your ideas with _Qlib_.
2. Though with *public data* and *simple models*, machine learning technologies **work very well** in practical Quant investment.

Here is a quick **[demo](https://terminalizer.com/view/3f24561a4470)** shows how to install ``Qlib``, and run LightGBM with ``qrun``. **But**, please make sure you have already prepared the data following the [instruction](#data-preparation).


## Installation

This table demonstrates the supported Python version of `Qlib`:
|               | install with pip      | install from source  |        plot        |
| ------------- |:---------------------:|:--------------------:|:------------------:|
| Python 3.8    | :heavy_check_mark:    | :heavy_check_mark:   | :heavy_check_mark: |
| Python 3.9    | :heavy_check_mark:    | :heavy_check_mark:   | :heavy_check_mark: |
| Python 3.10   | :heavy_check_mark:    | :heavy_check_mark:   | :heavy_check_mark: |
| Python 3.11   | :heavy_check_mark:    | :heavy_check_mark:   | :heavy_check_mark: |
| Python 3.12   | :heavy_check_mark:    | :heavy_check_mark:   | :heavy_check_mark: |

**Note**: 
1. **Conda** is suggested for managing your Python environment. In some cases, using Python outside of a `conda` environment may result in missing header files, causing the installation failure of certain packages.
2. Please pay attention that installing cython in Python 3.6 will raise some error when installing ``Qlib`` from source. If users use Python 3.6 on their machines, it is recommended to *upgrade* Python to version 3.8 or higher, or use `conda`&#039;s Python to install ``Qlib`` from source.

### Install with pip
Users can easily install ``Qlib`` by pip according to the following command.

```bash
  pip install pyqlib
```

**Note**: pip will install the latest stable qlib. However, the main branch of qlib is in active development. If you want to test the latest scripts or functions in the main branch. Please install qlib with the methods below.

### Install from source
Also, users can install the latest dev version ``Qlib`` by the source code according to the following steps:

* Before installing ``Qlib`` from source, users need to install some dependencies:

  ```bash
  pip install numpy
  pip install --upgrade cython
  ```

* Clone the repository and install ``Qlib`` as follows.
    ```bash
    git clone https://github.com/microsoft/qlib.git &amp;&amp; cd qlib
    pip install .  # `pip install -e .[dev]` is recommended for development. check details in docs/developer/code_standard_and_dev_guide.rst
    ```

**Tips**: If you fail to install `Qlib` or run the examples in your environment,  comparing your steps and the [CI workflow](.github/workflows/test_qlib_from_source.yml) may help you find the problem.

**Tips for Mac**: If you are using Mac with M1, you might encounter issues in building the wheel for LightGBM, which is due to missing dependencies from OpenMP. To solve the problem, install openmp first with ``brew install libomp`` and then run ``pip install .`` to build it successfully. 

## Data Preparation
❗ Due to more restrict data security policy. The official dataset is disabled temporarily. You can try [this data source](https://github.com/chenditc/investment_data/releases) contributed by the community.
Here is an example to download the latest data.
```bash
wget https://github.com/chenditc/investment_data/releases/latest/download/qlib_bin.tar.gz
mkdir -p ~/.qlib/qlib_data/cn_data
tar -zxvf qlib_bin.tar.gz -C ~/.qlib/qlib_data/cn_data --strip-components=1
rm -f qlib_bin.tar.gz
```

The official dataset below will resume in short future.


----

Load and prepare data by running the following code:

### Get with module
  ```bash
  # get 1d data
  python -m qlib.cli.data qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn

  # get 1min data
  python -m qlib.cli.data qlib_data --target_dir ~/.qlib/qlib_data/cn_data_1min --region cn --interval 1min

  ```

### Get from source

  ```bash
  # get 1d data
  python scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn

  # get 1min data
  python scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data_1min --region cn --interval 1min

  ```

This dataset is created by public data collected by [crawler scripts](scripts/data_collector/), which have been released in
the same repository.
Users could create the same dataset with it. [Description of dataset](https://github.com/microsoft/qlib/tree/main/scripts/data_collector#description-of-dataset)

*Please pay **ATTENTION** that the data is collected from [Yahoo Finance](https://finance.yahoo.com/lookup), and the data might not be perfect.
We recommend users to prepare their own data if they have a high-quality dataset. For more information, users can refer to the [related document](https://qlib.readthedocs.io/en/latest/component/data.html#converting-csv-format-into-qlib-format)*.

### Automatic update of daily frequency data (from yahoo finance)
  &gt; This step is *Optional* if users only want to try their models and strategies on history data.
  &gt; 
  &gt; It is recommended that users update the data manually once (--trading_date 2021-05-25) and then set it to update automatically.
  &gt;
  &gt; **NOTE**: Users can&#039;t incrementally  update data based on the offline data provided by Qlib(some fields are removed to reduce the data size). Users should use [yahoo collector](https://github.com/microsoft/qlib/tree/main/scripts/data_collector/yahoo#automatic-update-of-daily-frequency-datafrom-yahoo-finance) to download Yahoo data from scratch and then incrementally update it.
  &gt; 
  &gt; For more information, please refer to: [yahoo collector](https://github.com/microsoft/qlib/tree/main/scripts/data_collector/yahoo#automatic-update-of-daily-frequency-datafrom-yahoo-finance)

  * Automatic update of data to the &quot;qlib&quot; directory each trading day(Linux)
      * use *crontab*: `crontab -e`
      * set up timed tasks:

        ```
        * * * * 1-5 python &lt;script path&gt; update_data_to_bin --qlib_data_1d_dir &lt;user data dir&gt;
        ```
        * **script path**: *scripts/data_collector/yahoo/collector.py*

  * Manual update of data
      ```
      python scripts/data_collector/yahoo/collector.py update_data_to_bin --qlib_data_1d_dir &lt;user data dir&gt; --trading_date &lt;start date&gt; --end_date &lt;end date&gt;
      ```
      * *trading_date*: start of trading day
      * *end_date*: end of trading day(not included)

### Checking the health of the data
  * We provide a script to check the health of the data, you can run the following commands to check whether the data is healthy or not.
    ```
    python scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_data
    ```
  * Of course, you can also add some parameters to adjust the test results, such as this.
    ```
    python scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_dat

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>