<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Mon, 07 Apr 2025 00:04:31 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[meta-llama/llama-models]]></title>
            <link>https://github.com/meta-llama/llama-models</link>
            <guid>https://github.com/meta-llama/llama-models</guid>
            <pubDate>Mon, 07 Apr 2025 00:04:31 GMT</pubDate>
            <description><![CDATA[Utilities intended for use with Llama models.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/meta-llama/llama-models">meta-llama/llama-models</a></h1>
            <p>Utilities intended for use with Llama models.</p>
            <p>Language: Python</p>
            <p>Stars: 6,317</p>
            <p>Forks: 1,053</p>
            <p>Stars today: 206 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/Llama_Repo.jpeg&quot; width=&quot;400&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
        🤗 &lt;a href=&quot;https://huggingface.co/meta-Llama&quot;&gt; Models on Hugging Face&lt;/a&gt;&amp;nbsp | &lt;a href=&quot;https://ai.meta.com/blog/&quot;&gt; Blog&lt;/a&gt;&amp;nbsp |  &lt;a href=&quot;https://llama.meta.com/&quot;&gt;Website&lt;/a&gt;&amp;nbsp | &lt;a href=&quot;https://llama.meta.com/get-started/&quot;&gt;Get Started&lt;/a&gt;&amp;nbsp | &lt;a href=&quot;https://github.com/meta-llama/llama-cookbook&quot;&gt;Llama Cookbook&lt;/a&gt;&amp;nbsp
&lt;br&gt;

---

# Llama Models

Llama is an accessible, open large language model (LLM) designed for developers, researchers, and businesses to build, experiment, and responsibly scale their generative AI ideas. Part of a foundational system, it serves as a bedrock for innovation in the global community. A few key aspects:
1. **Open access**: Easy accessibility to cutting-edge large language models, fostering collaboration and advancements among developers, researchers, and organizations
2. **Broad ecosystem**: Llama models have been downloaded hundreds of millions of times, there are thousands of community projects built on Llama and platform support is broad from cloud providers to startups - the world is building with Llama!
3. **Trust &amp; safety**: Llama models are part of a comprehensive approach to trust and safety, releasing models and tools that are designed to enable community collaboration and encourage the standardization of the development and usage of trust and safety tools for generative AI

Our mission is to empower individuals and industry through this opportunity while fostering an environment of discovery and ethical AI advancements. The model weights are licensed for researchers and commercial entities, upholding the principles of openness.

## Llama Models

[![PyPI - Downloads](https://img.shields.io/pypi/dm/llama-models)](https://pypi.org/project/llama-models/)
[![Discord](https://img.shields.io/discord/1257833999603335178)](https://discord.gg/TZAAYNVtrU)

|  **Model** | **Launch date** | **Model sizes** | **Context Length** | **Tokenizer** | **Acceptable use policy**  |  **License** | **Model Card** |
| :----: | :----: | :----: | :----:|:----:|:----:|:----:|:----:|
| Llama 2 | 7/18/2023 | 7B, 13B, 70B | 4K | Sentencepiece | [Use Policy](models/llama2/USE_POLICY.md) | [License](models/llama2/LICENSE) | [Model Card](models/llama2/MODEL_CARD.md) |
| Llama 3 | 4/18/2024 | 8B, 70B | 8K | TikToken-based | [Use Policy](models/llama3/USE_POLICY.md) | [License](models/llama3/LICENSE) | [Model Card](models/llama3/MODEL_CARD.md) |
| Llama 3.1 | 7/23/2024 | 8B, 70B, 405B | 128K | TikToken-based | [Use Policy](models/llama3_1/USE_POLICY.md) | [License](models/llama3_1/LICENSE) | [Model Card](models/llama3_1/MODEL_CARD.md) |
| Llama 3.2 | 9/25/2024 | 1B, 3B | 128K | TikToken-based | [Use Policy](models/llama3_2/USE_POLICY.md) | [License](models/llama3_2/LICENSE) | [Model Card](models/llama3_2/MODEL_CARD.md) |
| Llama 3.2-Vision | 9/25/2024 | 11B, 90B | 128K | TikToken-based | [Use Policy](models/llama3_2/USE_POLICY.md) | [License](models/llama3_2/LICENSE) | [Model Card](models/llama3_2/MODEL_CARD_VISION.md) |
| Llama 3.3 | 12/04/2024 | 11B, 90B | 128K | TikToken-based | [Use Policy](models/llama3_3/USE_POLICY.md) | [License](models/llama3_3/LICENSE) | [Model Card](models/llama3_3/MODEL_CARD.md) |
| Llama 4 | 4/5/2025 | Scout-17B-16E, Maverick-17B-128E | 10M, 1M | TikToken-based | [Use Policy](models/llama4/USE_POLICY.md) | [License](models/llama4/LICENSE) | [Model Card](models/llama4/MODEL_CARD.md) |

## Download

To download the model weights and tokenizer:

1. Visit the [Meta Llama website](https://llama.meta.com/llama-downloads/).
2. Read and accept the license.
3. Once your request is approved you will receive a signed URL via email.
4. Install the [Llama CLI](https://github.com/meta-llama/llama-stack): `pip install llama-stack`. (**&lt;-- Start Here if you have received an email already.**)
5. Run `llama model list` to show the latest available models and determine the model ID you wish to download. **NOTE**:
If you want older versions of models, run `llama model list --show-all` to show all the available Llama models.

6. Run: `llama download --source meta --model-id CHOSEN_MODEL_ID`
7. Pass the URL provided when prompted to start the download.

Remember that the links expire after 24 hours and a certain amount of downloads. You can always re-request a link if you start seeing errors such as `403: Forbidden`.

## Running the models

In order to run the models, you will need to install dependencies after checking out the repository.

```bash
# Run this within a suitable Python environment (uv, conda, or virtualenv)
pip install -e .[torch]
```

Example scripts are available in `models/{ llama3, llama4 }/scripts/` sub-directory. Note that the Llama4 series of models require at least 4 GPUs to run inference at full (bf16) precision.

```bash
#!/bin/bash

NGPUS=4
CHECKPOINT_DIR=~/.llama/checkpoints/Llama-4-Scout-17B-16E-Instruct
PYTHONPATH=$(git rev-parse --show-toplevel) \
  torchrun --nproc_per_node=$NGPUS \
  -m models.llama4.scripts.chat_completion $CHECKPOINT_DIR \
  --world_size $NGPUS
```

The above script should be used with an Instruct (Chat) model. For a Base model, update the `CHECKPOINT_DIR` path and use the script `models.llama4.scripts.completion`.


## Running inference with FP8 and Int4 Quantization

You can reduce the memory footprint of the models at the cost of minimal loss in accuracy by running inference with FP8 or Int4 quantization. Use the `--quantization-mode` flag to specify the quantization mode. There are two modes:
- `fp8_mixed`: Mixed precision inference with FP8 for some weights and bfloat16 for activations.
- `int4_mixed`: Mixed precision inference with Int4 for some weights and bfloat16 for activations.

Using FP8, running Llama-4-Scout-17B-16E-Instruct requires 2 GPUs with 80GB of memory. Using Int4, you need a single GPU with 80GB of memory.

```bash
MODE=fp8_mixed  # or int4_mixed
if [ $MODE == &quot;fp8_mixed&quot; ]; then
  NGPUS=2
else
  NGPUS=1
fi
CHECKPOINT_DIR=~/.llama/checkpoints/Llama-4-Scout-17B-16E-Instruct
PYTHONPATH=$(git rev-parse --show-toplevel) \
  torchrun --nproc_per_node=$NGPUS \
  -m models.llama4.scripts.chat_completion $CHECKPOINT_DIR \
  --world_size $NGPUS \
  --quantization-mode $MODE
```


For more flexibility in running inference (including using other providers), please see the [`Llama Stack`](https://github.com/meta-llama/llama-stack) toolset.


## Access to Hugging Face

We also provide downloads on [Hugging Face](https://huggingface.co/meta-llama), in both transformers and native `llama4` formats. To download the weights from Hugging Face, please follow these steps:

- Visit one of the repos, for example [meta-llama/Llama-4-Scout-17B-16E](https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E).
- Read and accept the license. Once your request is approved, you&#039;ll be granted access to all Llama 3.1 models as well as previous versions. Note that requests used to take up to one hour to get processed.
- To download the original native weights to use with this repo, click on the &quot;Files and versions&quot; tab and download the contents of the `original` folder. You can also download them from the command line if you `pip install huggingface-hub`:

```bash
huggingface-cli download meta-llama/Llama-4-Scout-17B-16E-Instruct-Original --local-dir meta-llama/Llama-4-Scout-17B-16E-Instruct-Original
```

- To use with transformers, the following snippet will download and cache the weights:

  ```python
  #inference.py
  from transformers import AutoTokenizer, Llama4ForConditionalGeneration
  import torch

  model_id = &quot;meta-llama/Llama-4-Scout-17B-16E-Instruct&quot;

  tokenizer = AutoTokenizer.from_pretrained(model_id)

  messages = [
      {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Who are you?&quot;},
  ]
  inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=&quot;pt&quot;, return_dict=True)

  model = Llama4ForConditionalGeneration.from_pretrained(
      model_id,
      device_map=&quot;auto&quot;,
      torch_dtype=torch.bfloat16
  )

  outputs = model.generate(**inputs.to(model.device), max_new_tokens=100)
  outputs = tokenizer.batch_decode(outputs[:, inputs[&quot;input_ids&quot;].shape[-1]:])
  print(outputs[0])
  ```
  ```bash
   torchrun --nnodes=1 --nproc_per_node=8 inference.py
   ```

## Installations

You can install this repository as a [package](https://pypi.org/project/llama-models/) by just doing `pip install llama-models`

## Responsible Use

Llama models are a new technology that carries potential risks with use. Testing conducted to date has not — and could not — cover all scenarios.
To help developers address these risks, we have created the [Responsible Use Guide](https://ai.meta.com/static-resource/responsible-use-guide/).

## Issues

Please report any software “bug” or other problems with the models through one of the following means:
- Reporting issues with the model: [https://github.com/meta-llama/llama-models/issues](https://github.com/meta-llama/llama-models/issues)
- Reporting risky content generated by the model: [developers.facebook.com/llama_output_feedback](http://developers.facebook.com/llama_output_feedback)
- Reporting bugs and security concerns: [facebook.com/whitehat/info](http://facebook.com/whitehat/info)


## Questions

For common questions, the FAQ can be found [here](https://llama.meta.com/faq), which will be updated over time as new questions arise.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[microsoft/markitdown]]></title>
            <link>https://github.com/microsoft/markitdown</link>
            <guid>https://github.com/microsoft/markitdown</guid>
            <pubDate>Mon, 07 Apr 2025 00:04:30 GMT</pubDate>
            <description><![CDATA[Python tool for converting files and office documents to Markdown.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/markitdown">microsoft/markitdown</a></h1>
            <p>Python tool for converting files and office documents to Markdown.</p>
            <p>Language: Python</p>
            <p>Stars: 42,820</p>
            <p>Forks: 2,041</p>
            <p>Stars today: 548 stars today</p>
            <h2>README</h2><pre># MarkItDown

[![PyPI](https://img.shields.io/pypi/v/markitdown.svg)](https://pypi.org/project/markitdown/)
![PyPI - Downloads](https://img.shields.io/pypi/dd/markitdown)
[![Built by AutoGen Team](https://img.shields.io/badge/Built%20by-AutoGen%20Team-blue)](https://github.com/microsoft/autogen)

&gt; [!TIP]
&gt; MarkItDown now offers an MCP (Model Context Protocol) server for integration with LLM applications like Claude Desktop. See [markitdown-mcp](https://github.com/microsoft/markitdown/tree/main/packages/markitdown-mcp) for more information.

&gt; [!IMPORTANT]
&gt; Breaking changes between 0.0.1 to 0.1.0:
&gt; * Dependencies are now organized into optional feature-groups (further details below). Use `pip install &#039;markitdown[all]&#039;` to have backward-compatible behavior. 
&gt; * convert\_stream() now requires a binary file-like object (e.g., a file opened in binary mode, or an io.BytesIO object). This is a breaking change from the previous version, where it previously also accepted text file-like objects, like io.StringIO.
&gt; * The DocumentConverter class interface has changed to read from file-like streams rather than file paths. *No temporary files are created anymore*. If you are the maintainer of a plugin, or custom DocumentConverter, you likely need to update your code. Otherwise, if only using the MarkItDown class or CLI (as in these examples), you should not need to change anything.

MarkItDown is a lightweight Python utility for converting various files to Markdown for use with LLMs and related text analysis pipelines. To this end, it is most comparable to [textract](https://github.com/deanmalmgren/textract), but with a focus on preserving important document structure and content as Markdown (including: headings, lists, tables, links, etc.) While the output is often reasonably presentable and human-friendly, it is meant to be consumed by text analysis tools -- and may not be the best option for high-fidelity document conversions for human consumption.

At present, MarkItDown supports:

- PDF
- PowerPoint
- Word
- Excel
- Images (EXIF metadata and OCR)
- Audio (EXIF metadata and speech transcription)
- HTML
- Text-based formats (CSV, JSON, XML)
- ZIP files (iterates over contents)
- Youtube URLs
- EPubs
- ... and more!

## Why Markdown?

Markdown is extremely close to plain text, with minimal markup or formatting, but still
provides a way to represent important document structure. Mainstream LLMs, such as
OpenAI&#039;s GPT-4o, natively &quot;_speak_&quot; Markdown, and often incorporate Markdown into their
responses unprompted. This suggests that they have been trained on vast amounts of
Markdown-formatted text, and understand it well. As a side benefit, Markdown conventions
are also highly token-efficient.

## Installation

To install MarkItDown, use pip: `pip install &#039;markitdown[all]&#039;`. Alternatively, you can install it from the source:

```bash
git clone git@github.com:microsoft/markitdown.git
cd markitdown
pip install -e packages/markitdown[all]
```

## Usage

### Command-Line

```bash
markitdown path-to-file.pdf &gt; document.md
```

Or use `-o` to specify the output file:

```bash
markitdown path-to-file.pdf -o document.md
```

You can also pipe content:

```bash
cat path-to-file.pdf | markitdown
```

### Optional Dependencies
MarkItDown has optional dependencies for activating various file formats. Earlier in this document, we installed all optional dependencies with the `[all]` option. However, you can also install them individually for more control. For example:

```bash
pip install markitdown[pdf, docx, pptx]
```

will install only the dependencies for PDF, DOCX, and PPTX files.

At the moment, the following optional dependencies are available:

* `[all]` Installs all optional dependencies
* `[pptx]` Installs dependencies for PowerPoint files
* `[docx]` Installs dependencies for Word files
* `[xlsx]` Installs dependencies for Excel files
* `[xls]` Installs dependencies for older Excel files
* `[pdf]` Installs dependencies for PDF files
* `[outlook]` Installs dependencies for Outlook messages
* `[az-doc-intel]` Installs dependencies for Azure Document Intelligence
* `[audio-transcription]` Installs dependencies for audio transcription of wav and mp3 files
* `[youtube-transcription]` Installs dependencies for fetching YouTube video transcription

### Plugins

MarkItDown also supports 3rd-party plugins. Plugins are disabled by default. To list installed plugins:

```bash
markitdown --list-plugins
```

To enable plugins use:

```bash
markitdown --use-plugins path-to-file.pdf
```

To find available plugins, search GitHub for the hashtag `#markitdown-plugin`. To develop a plugin, see `packages/markitdown-sample-plugin`.

### Azure Document Intelligence

To use Microsoft Document Intelligence for conversion:

```bash
markitdown path-to-file.pdf -o document.md -d -e &quot;&lt;document_intelligence_endpoint&gt;&quot;
```

More information about how to set up an Azure Document Intelligence Resource can be found [here](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/create-document-intelligence-resource?view=doc-intel-4.0.0)

### Python API

Basic usage in Python:

```python
from markitdown import MarkItDown

md = MarkItDown(enable_plugins=False) # Set to True to enable plugins
result = md.convert(&quot;test.xlsx&quot;)
print(result.text_content)
```

Document Intelligence conversion in Python:

```python
from markitdown import MarkItDown

md = MarkItDown(docintel_endpoint=&quot;&lt;document_intelligence_endpoint&gt;&quot;)
result = md.convert(&quot;test.pdf&quot;)
print(result.text_content)
```

To use Large Language Models for image descriptions, provide `llm_client` and `llm_model`:

```python
from markitdown import MarkItDown
from openai import OpenAI

client = OpenAI()
md = MarkItDown(llm_client=client, llm_model=&quot;gpt-4o&quot;)
result = md.convert(&quot;example.jpg&quot;)
print(result.text_content)
```

### Docker

```sh
docker build -t markitdown:latest .
docker run --rm -i markitdown:latest &lt; ~/your-file.pdf &gt; output.md
```

## Contributing

This project welcomes contributions and suggestions. Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

### How to Contribute

You can help by looking at issues or helping review PRs. Any issue or PR is welcome, but we have also marked some as &#039;open for contribution&#039; and &#039;open for reviewing&#039; to help facilitate community contributions. These are ofcourse just suggestions and you are welcome to contribute in any way you like.

&lt;div align=&quot;center&quot;&gt;

|            | All                                                          | Especially Needs Help from Community                                                                                                      |
| ---------- | ------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------- |
| **Issues** | [All Issues](https://github.com/microsoft/markitdown/issues) | [Issues open for contribution](https://github.com/microsoft/markitdown/issues?q=is%3Aissue+is%3Aopen+label%3A%22open+for+contribution%22) |
| **PRs**    | [All PRs](https://github.com/microsoft/markitdown/pulls)     | [PRs open for reviewing](https://github.com/microsoft/markitdown/pulls?q=is%3Apr+is%3Aopen+label%3A%22open+for+reviewing%22)              |

&lt;/div&gt;

### Running Tests and Checks

- Navigate to the MarkItDown package:

  ```sh
  cd packages/markitdown
  ```

- Install `hatch` in your environment and run tests:

  ```sh
  pip install hatch  # Other ways of installing hatch: https://hatch.pypa.io/dev/install/
  hatch shell
  hatch test
  ```

  (Alternative) Use the Devcontainer which has all the dependencies installed:

  ```sh
  # Reopen the project in Devcontainer and run:
  hatch test
  ```

- Run pre-commit checks before submitting a PR: `pre-commit run --all-files`

### Contributing 3rd-party Plugins

You can also contribute by creating and sharing 3rd party plugins. See `packages/markitdown-sample-plugin` for more details.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
trademarks or logos is subject to and must follow
[Microsoft&#039;s Trademark &amp; Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party&#039;s policies.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[funstory-ai/BabelDOC]]></title>
            <link>https://github.com/funstory-ai/BabelDOC</link>
            <guid>https://github.com/funstory-ai/BabelDOC</guid>
            <pubDate>Mon, 07 Apr 2025 00:04:29 GMT</pubDate>
            <description><![CDATA[Yet Another Document Translator]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/funstory-ai/BabelDOC">funstory-ai/BabelDOC</a></h1>
            <p>Yet Another Document Translator</p>
            <p>Language: Python</p>
            <p>Stars: 876</p>
            <p>Forks: 46</p>
            <p>Stars today: 182 stars today</p>
            <h2>README</h2><pre>&lt;!-- # Yet Another Document Translator --&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;!-- &lt;img src=&quot;https://s.immersivetranslate.com/assets/r2-uploads/images/babeldoc-banner.png&quot; width=&quot;320px&quot;  alt=&quot;YADT&quot;/&gt; --&gt;

&lt;br/&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://s.immersivetranslate.com/assets/uploads/babeldoc-big-logo-darkmode-with-transparent-background-IKuNO1.svg&quot; width=&quot;320px&quot; alt=&quot;BabelDOC&quot;/&gt;
  &lt;img src=&quot;https://s.immersivetranslate.com/assets/uploads/babeldoc-big-logo-with-transparent-background-2xweBr.svg&quot; width=&quot;320px&quot; alt=&quot;BabelDOC&quot;/&gt;
&lt;/picture&gt;

&lt;!-- &lt;h2 id=&quot;title&quot;&gt;BabelDOC&lt;/h2&gt; --&gt;

&lt;p&gt;
  &lt;!-- PyPI --&gt;
  &lt;a href=&quot;https://pypi.org/project/BabelDOC/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/pypi/v/BabelDOC&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://pepy.tech/projects/BabelDOC&quot;&gt;
    &lt;img src=&quot;https://static.pepy.tech/badge/BabelDOC&quot;&gt;&lt;/a&gt;
  &lt;!-- &lt;a href=&quot;https://github.com/funstory-ai/BabelDOC/pulls&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/contributions-welcome-green&quot;&gt;&lt;/a&gt; --&gt;
  &lt;!-- License --&gt;
  &lt;a href=&quot;./LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/funstory-ai/BabelDOC&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://t.me/+Z9_SgnxmsmA5NzBl&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Telegram-2CA5E0?style=flat-squeare&amp;logo=telegram&amp;logoColor=white&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;a href=&quot;https://trendshift.io/repositories/13358&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13358&quot; alt=&quot;funstory-ai%2FBabelDOC | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

PDF scientific paper translation and bilingual comparison library.

- **Online Service**: Beta version launched [Immersive Translate - BabelDOC](https://app.immersivetranslate.com/babel-doc/) 1000 free pages per month.
- **Self-deployment**: [PDFMathTranslate](https://github.com/Byaidu/PDFMathTranslate) 1.9.3+ Experimental support for BabelDOC, available for self-deployment + WebUI with more translation services.
- Provides a simple [command line interface](#getting-started).
- Provides a [Python API](#python-api).
- Mainly designed to be embedded into other programs, but can also be used directly for simple translation tasks.

## Preview

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://s.immersivetranslate.com/assets/r2-uploads/images/babeldoc-preview.png&quot; width=&quot;80%&quot;/&gt;
&lt;/div&gt;

## We are hiring

See details: [EN](https://github.com/funstory-ai/jobs) | [ZH](https://github.com/funstory-ai/jobs/blob/main/README_ZH.md)

## Getting Started

### Install from PyPI

We recommend using the Tool feature of [uv](https://github.com/astral-sh/uv) to install yadt.

1. First, you need to refer to [uv installation](https://github.com/astral-sh/uv#installation) to install uv and set up the `PATH` environment variable as prompted.

2. Use the following command to install yadt:

```bash
uv tool install --python 3.12 BabelDOC

babeldoc --help
```

3. Use the `babeldoc` command. For example:

```bash
babeldoc --bing  --files example.pdf

# multiple files
babeldoc --bing  --files example1.pdf --files example2.pdf
```

### Install from Source

We still recommend using [uv](https://github.com/astral-sh/uv) to manage virtual environments.

1. First, you need to refer to [uv installation](https://github.com/astral-sh/uv#installation) to install uv and set up the `PATH` environment variable as prompted.

2. Use the following command to install yadt:

```bash
# clone the project
git clone https://github.com/funstory-ai/BabelDOC

# enter the project directory
cd BabelDOC

# install dependencies and run babeldoc
uv run babeldoc --help
```

3. Use the `uv run babeldoc` command. For example:

```bash
uv run babeldoc --files example.pdf --openai --openai-model &quot;gpt-4o-mini&quot; --openai-base-url &quot;https://api.openai.com/v1&quot; --openai-api-key &quot;your-api-key-here&quot;

# multiple files
uv run babeldoc --files example.pdf --files example2.pdf --openai --openai-model &quot;gpt-4o-mini&quot; --openai-base-url &quot;https://api.openai.com/v1&quot; --openai-api-key &quot;your-api-key-here&quot;
```

&gt; [!TIP]
&gt; The absolute path is recommended.

## Advanced Options

&gt; [!NOTE]
&gt; This CLI is mainly for debugging purposes. Although end users can use this CLI to translate files, we do not provide any technical support for this purpose.
&gt;
&gt; End users should directly use **Online Service**: Beta version launched [Immersive Translate - BabelDOC](https://app.immersivetranslate.com/babel-doc/) 1000 free pages per month.
&gt;
&gt; End users who need self-deployment should use [PDFMathTranslate](https://github.com/Byaidu/PDFMathTranslate)
&gt; 
&gt; If you find that an option is not listed below, it means that this option is a debugging option for maintainers. Please do not use these options.


### Language Options

- `--lang-in`, `-li`: Source language code (default: en)
- `--lang-out`, `-lo`: Target language code (default: zh)

&gt; [!TIP]
&gt; Currently, this project mainly focuses on English-to-Chinese translation, and other scenarios have not been tested yet.
&gt; 
&gt; (2025.3.1 update): Basic English target language support has been added, primarily to minimize line breaks within words([0-9A-Za-z]+).
&gt; 
&gt; [HELP WANTED: Collecting word regular expressions for more languages](https://github.com/funstory-ai/BabelDOC/issues/129)

### PDF Processing Options

- `--files`: One or more file paths to input PDF documents.
- `--pages`, `-p`: Specify pages to translate (e.g., &quot;1,2,1-,-3,3-5&quot;). If not set, translate all pages
- `--split-short-lines`: Force split short lines into different paragraphs (may cause poor typesetting &amp; bugs)
- `--short-line-split-factor`: Split threshold factor (default: 0.8). The actual threshold is the median length of all lines on the current page \* this factor
- `--skip-clean`: Skip PDF cleaning step
- `--dual-translate-first`: Put translated pages first in dual PDF mode (default: original pages first)
- `--disable-rich-text-translate`: Disable rich text translation (may help improve compatibility with some PDFs)
- `--enhance-compatibility`: Enable all compatibility enhancement options (equivalent to --skip-clean --dual-translate-first --disable-rich-text-translate)
- `--use-alternating-pages-dual`: Use alternating pages mode for dual PDF. When enabled, original and translated pages are arranged in alternate order. When disabled (default), original and translated pages are shown side by side on the same page.
- `--watermark-output-mode`: Control watermark output mode: &#039;watermarked&#039; (default) adds watermark to translated PDF, &#039;no_watermark&#039; doesn&#039;t add watermark, &#039;both&#039; outputs both versions.
- `--max-pages-per-part`: Maximum number of pages per part for split translation. If not set, no splitting will be performed.
- `--no-watermark`: [DEPRECATED] Use --watermark-output-mode=no_watermark instead.
- `--translate-table-text`: Translate table text (experimental, default: False)
- `--skip-scanned-detection`: Skip scanned document detection (default: False). When using split translation, only the first part performs detection if not skipped.

&gt; [!TIP]
&gt; - Both `--skip-clean` and `--dual-translate-first` may help improve compatibility with some PDF readers
&gt; - `--disable-rich-text-translate` can also help with compatibility by simplifying translation input
&gt; - However, using `--skip-clean` will result in larger file sizes
&gt; - If you encounter any compatibility issues, try using `--enhance-compatibility` first
&gt; - Use `--max-pages-per-part` for large documents to split them into smaller parts for translation and automatically merge them back.
&gt; - Use `--skip-scanned-detection` to speed up processing when you know your document is not a scanned PDF.

### Translation Service Options

- `--qps`: QPS (Queries Per Second) limit for translation service (default: 4)
- `--ignore-cache`: Ignore translation cache and force retranslation
- `--no-dual`: Do not output bilingual PDF files
- `--no-mono`: Do not output monolingual PDF files
- `--min-text-length`: Minimum text length to translate (default: 5)
- `--openai`: Use OpenAI for translation (default: False)

&gt; [!TIP]
&gt;
&gt; 1. Currently, only OpenAI-compatible LLM is supported. For more translator support, please use [PDFMathTranslate](https://github.com/Byaidu/PDFMathTranslate).
&gt; 2. It is recommended to use models with strong compatibility with OpenAI, such as: `glm-4-flash`, `deepseek-chat`, etc.
&gt; 3. Currently, it has not been optimized for traditional translation engines like Bing/Google, it is recommended to use LLMs.
&gt; 4. You can use [litellm](https://github.com/BerriAI/litellm) to access multiple models.

### OpenAI Specific Options

- `--openai-model`: OpenAI model to use (default: gpt-4o-mini)
- `--openai-base-url`: Base URL for OpenAI API
- `--openai-api-key`: API key for OpenAI service

&gt; [!TIP]
&gt;
&gt; 1. This tool supports any OpenAI-compatible API endpoints. Just set the correct base URL and API key. (e.g. `https://xxx.custom.xxx/v1`)
&gt; 2. For local models like Ollama, you can use any value as the API key (e.g. `--openai-api-key a`).

### Output Control

- `--output`, `-o`: Output directory for translated files. If not set, use current working directory.
- `--debug`, `-d`: Enable debug logging level and export detailed intermediate results in `~/.cache/yadt/working`.
- `--report-interval`: Progress report interval in seconds (default: 0.1).

### Offline Assets Management

- `--generate-offline-assets`: Generate an offline assets package in the specified directory. This creates a zip file containing all required models and fonts.
- `--restore-offline-assets`: Restore an offline assets package from the specified file. This extracts models and fonts from a previously generated package.

&gt; [!TIP]
&gt; 
&gt; 1. Offline assets packages are useful for environments without internet access or to speed up installation on multiple machines.
&gt; 2. Generate a package once with `babeldoc --generate-offline-assets /path/to/output/dir` and then distribute it.
&gt; 3. Restore the package on target machines with `babeldoc --restore-offline-assets /path/to/offline_assets_*.zip`.
&gt; 4. The offline assets package name cannot be modified because the file list hash is encoded in the name.
&gt; 5. If you provide a directory path to `--restore-offline-assets`, the tool will automatically look for the correct offline assets package file in that directory.
&gt; 6. The package contains all necessary fonts and models required for document processing, ensuring consistent results across different environments.
&gt; 7. The integrity of all assets is verified using SHA3-256 hashes during both packaging and restoration.
&gt; 8. If you&#039;re deploying in an air-gapped environment, make sure to generate the package on a machine with internet access first.

### Configuration File

- `--config`, `-c`: Configuration file path. Use the TOML format.

Example Configuration:

```toml
[babeldoc]
# Basic settings
debug = true
lang-in = &quot;en-US&quot;
lang-out = &quot;zh-CN&quot;
qps = 10
output = &quot;/path/to/output/dir&quot;

# PDF processing options
split-short-lines = false
short-line-split-factor = 0.8
skip-clean = false
dual-translate-first = false
disable-rich-text-translate = false
use-alternating-pages-dual = false
watermark-output-mode = &quot;watermarked&quot;  # Choices: &quot;watermarked&quot;, &quot;no_watermark&quot;, &quot;both&quot;
max-pages-per-part = 50  # Automatically split the document for translation and merge it back.
# no-watermark = false  # DEPRECATED: Use watermark-output-mode instead
skip-scanned-detection = false  # Skip scanned document detection for faster processing

# Translation service
openai = true
openai-model = &quot;gpt-4o-mini&quot;
openai-base-url = &quot;https://api.openai.com/v1&quot;
openai-api-key = &quot;your-api-key-here&quot;

# Output control
no-dual = false
no-mono = false
min-text-length = 5
report-interval = 0.5

# Offline assets management
# Uncomment one of these options as needed:
# generate-offline-assets = &quot;/path/to/output/dir&quot;
# restore-offline-assets = &quot;/path/to/offline_assets_package.zip&quot;
```

## Python API

&gt; [!TIP]
&gt;
&gt; 1. Before pdf2zh 2.0 is released, you can temporarily use BabelDOC&#039;s Python API. However, after pdf2zh 2.0 is released, please directly use pdf2zh&#039;s Python API.
&gt;
&gt; 2. This project&#039;s Python API does not guarantee any compatibility. However, the Python API from pdf2zh will guarantee a certain level of compatibility.

You can refer to the example in [main.py](https://github.com/funstory-ai/yadt/blob/main/babeldoc/main.py) to use BabelDOC&#039;s Python API.

Please note:

1. Make sure call `babeldoc.high_level.init()` before using the API

2. The current `TranslationConfig` does not fully validate input parameters, so you need to ensure the validity of input parameters

3. For offline assets management, you can use the following functions:
   ```python
   # Generate an offline assets package
   from pathlib import Path
   import babeldoc.assets.assets
   
   # Generate package to a specific directory
   # path is optional, default is ~/.cache/babeldoc/assets/offline_assets_{hash}.zip
   babeldoc.assets.assets.generate_offline_assets_package(Path(&quot;/path/to/output/dir&quot;))
   
   # Restore from a package file
   # path is optional, default is ~/.cache/babeldoc/assets/offline_assets_{hash}.zip
   babeldoc.assets.assets.restore_offline_assets_package(Path(&quot;/path/to/offline_assets_package.zip&quot;))
   
   # You can also restore from a directory containing the offline assets package
   # The tool will automatically find the correct package file based on the hash
   babeldoc.assets.assets.restore_offline_assets_package(Path(&quot;/path/to/directory&quot;))
   ```

&gt; [!TIP]
&gt; 
&gt; 1. The offline assets package name cannot be modified because the file list hash is encoded in the name.
&gt; 2. When using in production environments, it&#039;s recommended to pre-generate the assets package and include it with your application distribution.
&gt; 3. The package verification ensures that all required assets are intact and match their expected checksums.

## Background

There are a lot projects and teams working on to make document editing and translating easier like:

- [mathpix](https://mathpix.com/)
- [Doc2X](https://doc2x.noedgeai.com/)
- [minerU](https://github.com/opendatalab/MinerU)
- [PDFMathTranslate](https://github.com/funstory-ai/yadt)

There are also some solutions to solve specific parts of the problem like:

- [layoutreader](https://github.com/microsoft/unilm/tree/master/layoutreader): the read order of the text block in a pdf
- [Surya](https://github.com/surya-is/surya): the structure of the pdf

This project hopes to promote a standard pipeline and interface to solve the problem.

In fact, there are two main stages of a PDF parser or translator:

- **Parsing**: A stage of parsing means to get the structure of the pdf such as text blocks, images, tables, etc.
- **Rendering**: A stage of rendering means to render the structure into a new pdf or other format.

For a service like mathpix, it will parse the pdf into a structure may be in a XML format, and then render them using a single column reader order as [layoutreader](https://github.com/microsoft/unilm/tree/master/layoutreader) does. The bad news is that the original structure lost.

Some people will use Adobe PDF Parser because it will generate a Word document and it keeps the original structure. But it is somewhat expensive.
And you know, a pdf or word document is not a good format for reading in mobile devices.

We offer an intermediate representation of the results from parser and can be rendered into a new pdf or other format. The pipeline is also a plugin-based system which everybody can add their new model, ocr, renderer, etc.

## Roadmap

- [ ] Add line support
- [ ] Add table support
- [ ] Add cross-page/cross-column paragraph support
- [ ] More advanced typesetting features
- [ ] Outline support
- [ ] ...

Our first 1.0 version goal is to finish a translation from [PDF Reference, Version 1.7](https://opensource.adobe.com/dc-acrobat-sdk-docs/pdfstandards/pdfreference1.7old.pdf) to the following language version:

- Simplified Chinese
- Traditional Chinese
- Japanese
- Spanish

And meet the following requirements:

- layout error less than 1%
- content loss less than 1%

## Known Issues

1. Parsing errors in the author and reference sections; they get merged into one paragraph after translation.
2. Lines are not supported.
3. Does not support drop caps.
4. Large pages will be skipped.

## How to Contribute

We encourage you to contribute to YADT! Please check out the [CONTRIBUTING](https://github.com/funstory-ai/yadt/blob/main/docs/CONTRIBUTING.md) guide.

Everyone interacting in YADT and its sub-projects&#039; codebases, issue trackers, chat rooms, and mailing lists is expected to follow the YADT [Code of Conduct](https://github.com/funstory-ai/yadt/blob/main/docs/CODE_OF_CONDUCT.md).

[Immersive Translation](https://immersivetranslate.com) sponsors monthly Pro membership redemption codes for active contributors to this project, see details at: [CONTRIBUTOR_REWARD.md](https://github.com/funstory-ai/BabelDOC/blob/main/docs/CONTRIBUTOR_REWARD.md)

## Acknowledgements

- [PDFMathTranslate](https://github.com/Byaidu/PDFMathTranslate)
- [DocLayout-YOLO](https://github.com/opendatalab/DocLayout-YOLO)
- [pdfminer](https://github.com/pdfminer/pdfminer.six)
- [PyMuPDF](https://github.com/pymupdf/PyMuPDF)
- [Asynchronize](https://github.com/multimeric/Asynchronize/tree/master?tab=readme-ov-file)
- [PriorityThreadPoolExecutor](https://github.com/oleglpts/PriorityThreadPoolExecutor)

&lt;h2 id=&quot;star_hist&quot;&gt;Star History&lt;/h2&gt;

&lt;a href=&quot;https://star-history.com/#funstory-ai/babeldoc&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=funstory-ai/babeldoc&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=funstory-ai/babeldoc&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=funstory-ai/babeldoc&amp;type=Date&quot;/&gt;
 &lt;/picture&gt;
&lt;/a&gt;</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[dortania/OpenCore-Legacy-Patcher]]></title>
            <link>https://github.com/dortania/OpenCore-Legacy-Patcher</link>
            <guid>https://github.com/dortania/OpenCore-Legacy-Patcher</guid>
            <pubDate>Mon, 07 Apr 2025 00:04:28 GMT</pubDate>
            <description><![CDATA[Experience macOS just like before]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dortania/OpenCore-Legacy-Patcher">dortania/OpenCore-Legacy-Patcher</a></h1>
            <p>Experience macOS just like before</p>
            <p>Language: Python</p>
            <p>Stars: 14,205</p>
            <p>Forks: 1,391</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
             &lt;img src=&quot;docs/images/OC-Patcher.png&quot; alt=&quot;OpenCore Patcher Logo&quot; width=&quot;256&quot; /&gt;
             &lt;h1&gt;OpenCore Legacy Patcher&lt;/h1&gt;
&lt;/div&gt;

A Python-based project revolving around [Acidanthera&#039;s OpenCorePkg](https://github.com/acidanthera/OpenCorePkg) and [Lilu](https://github.com/acidanthera/Lilu) for both running and unlocking features in macOS on supported and unsupported Macs.

Our project&#039;s main goal is to breathe new life into Macs no longer supported by Apple, allowing for the installation and usage of macOS Big Sur and newer on machines as old as 2007.

----------

![GitHub all releases](https://img.shields.io/github/downloads/dortania/OpenCore-Legacy-Patcher/total?color=white&amp;style=plastic) ![GitHub top language](https://img.shields.io/github/languages/top/dortania/OpenCore-Legacy-Patcher?color=4B8BBE&amp;style=plastic) ![Discord](https://img.shields.io/discord/417165963327176704?color=7289da&amp;label=discord&amp;style=plastic)

----------

Noteworthy features of OpenCore Legacy Patcher:

* Support for macOS Big Sur, Monterey, Ventura, Sonoma and Sequoia
* Native Over the Air (OTA) System Updates
* Supports Penryn and newer Macs
* Full support for WPA Wi-Fi and Personal Hotspot on BCM943224 and newer wireless chipsets
* System Integrity Protection, FileVault 2, .im4m Secure Boot and Vaulting
* Recovery OS, Safe Mode and Single-user Mode booting on non-native OSes
* Unlocks features such as Sidecar and AirPlay to Mac even on native Macs
* Enables enhanced SATA and NVMe power management on non-Apple storage devices
* Zero firmware patching required (ie. APFS ROM patching)
* Graphics acceleration for both Metal and non-Metal GPUs

----------

Note: Only clean-installs and upgrades are supported. macOS Big Sur installs already patched with other patchers, such as [Patched Sur](https://github.com/BenSova/Patched-Sur) or [bigmac](https://github.com/StarPlayrX/bigmac), cannot be used due to broken file integrity with APFS snapshots and SIP.

* You can, however, reinstall macOS with this patcher and retain your original data

Note 2: Currently, OpenCore Legacy Patcher officially supports patching to run macOS Big Sur through Sonoma installs. For older OSes, OpenCore may function; however, support is currently not provided from Dortania.

* For macOS Mojave and Catalina support, we recommend the use of [dosdude1&#039;s patchers](http://dosdude1.com)

## Getting Started

To start using the project, please see our in-depth guide:

* [OpenCore Legacy Patcher Guide](https://dortania.github.io/OpenCore-Legacy-Patcher/)

## Support

This project is offered on an AS-IS basis, we do not guarantee support for any issues that may arise. However, there is a community server with other passionate users and developers that can aid you:

* [OpenCore Patcher Paradise Discord Server](https://discord.gg/rqdPgH8xSN)
  * Keep in mind that the Discord server is maintained by the community, so we ask everyone to be respectful.
  * Please review our docs on [how to debug with OpenCore](https://dortania.github.io/OpenCore-Legacy-Patcher/DEBUG.html) to gather important information to help others with troubleshooting.

## Running from source

To run the project from source, see here: [Build and run from source](./SOURCE.md)

## Credits

* [Acidanthera](https://github.com/Acidanthera)
  * OpenCorePkg, as well as many of the core kexts and tools
* [DhinakG](https://github.com/DhinakG)
  * Main co-author
* [Khronokernel](https://github.com/Khronokernel)
  * Main co-author
* [Ausdauersportler](https://github.com/Ausdauersportler)
  * iMacs Metal GPUs Upgrade Patch set and documentation
  * Great amounts of help with debugging, and code suggestions
* [vit9696](https://github.com/vit9696)
  * Endless amount of help troubleshooting, determining fixes and writing patches
* [EduCovas](https://github.com/covasedu)
  * [non-Metal patch set](https://github.com/moraea/non-metal-frameworks) for nVidia Tesla/Fermi/Maxwell/Pascal, AMD TeraScale 1/2, and Intel Core 1st/2nd Generation GPUs
  * [3802 Metal patch set](https://github.com/moraea/misc-patches/tree/main/3802-Metal-15) and [MetallibSupportPkg](https://github.com/dortania/MetallibSupportPkg) for nVidia Kepler and Intel Core 3rd/4th Generation GPUs
  * Metal bundle patches and shims for [nVidia Kepler](https://github.com/moraea/misc-patches/tree/main/Kepler%2013%2B), [AMD GCN 1 - 4](https://github.com/moraea/misc-patches/tree/main/GCN%2013%2B), and [AMD GCN 5 (Vega)](https://github.com/moraea/misc-patches/tree/main/vega%2013%2B)
  * [IOSurface offset patches](https://github.com/moraea/misc-patches/tree/main/Sonoma%2014.4%20IOSurface) for nVidia Kepler, AMD GCN 1 - 5, and Intel Core 3rd - 6th Generation GPUs
  * [legacy Wi-Fi patch set](https://github.com/moraea/unsupported-wifi-patches) restores functionality for Wi-Fi cards in all 2007 - 2017 models
  * [T1 patch set](https://github.com/moraea/misc-patches/tree/main/T1-Patch) restores Touch ID, Apple Pay, and other secure functionality in 2016 - 2017 models
  * AppleGVA downgrade for accelerated video decoding on 2012 - 2016 models
  * OpenCL and OpenGL downgrade for AMD GCN
  * [USB 1 patch](https://github.com/moraea/misc-patches/tree/main/IOUSBHostFamily-14.4)
* [ASentientHedgehog](https://github.com/moosethegoose2213)
  * [non-Metal patch set](https://github.com/moraea/non-metal-frameworks) for nVidia Tesla/Fermi/Maxwell/Pascal, AMD TeraScale 1/2, and Intel Core 1st/2nd Generation GPUs
* [ASentientBot](https://github.com/ASentientBot)
  * [non-Metal patch set](https://github.com/moraea/non-metal-frameworks) for nVidia Tesla/Fermi/Maxwell/Pascal, AMD TeraScale 1/2, and Intel Core 1st/2nd Generation GPUs
  * [Metal bundle interposer](https://github.com/moraea/misc-patches/tree/main/sequoia%2031001%20interposer) for AMD GCN 1 - 5 and Intel Core 5th/6th Generation GPUs
  * [dsce](https://github.com/moraea/dsce) and [shared code](https://github.com/moraea/moraea-common) used by some other patches
* [cdf](https://github.com/cdf)
  * Mac Pro on OpenCore Patch set and documentation
  * [Innie](https://github.com/cdf/Innie) and [NightShiftEnabler](https://github.com/cdf/NightShiftEnabler)
* [Syncretic](https://forums.macrumors.com/members/syncretic.1173816/)
  * [AAAMouSSE](https://forums.macrumors.com/threads/mp3-1-others-sse-4-2-emulation-to-enable-amd-metal-driver.2206682/), [telemetrap](https://forums.macrumors.com/threads/mp3-1-others-sse-4-2-emulation-to-enable-amd-metal-driver.2206682/post-28447707) and [SurPlus](https://github.com/reenigneorcim/SurPlus)
* [dosdude1](https://github.com/dosdude1)
  * Main author of the [original GUI](https://github.com/dortania/OCLP-GUI)
  * Development of previous patchers, laying out much of what needs to be patched
* [parrotgeek1](https://github.com/parrotgeek1)
  * [VMM Patch Set](https://github.com/dortania/OpenCore-Legacy-Patcher/blob/4a8f61a01da72b38a4b2250386cc4b497a31a839/payloads/Config/config.plist#L1222-L1281)
* [BarryKN](https://github.com/BarryKN)
  * Development of previous patchers, laying out much of what needs to be patched
* [mario_bros_tech](https://github.com/mariobrostech) and the rest of the Unsupported Mac Discord
  * Catalyst that started OpenCore Legacy Patcher
* [arter97](https://github.com/arter97/)
  * [SimpleMSR](https://github.com/arter97/SimpleMSR/) to disable firmware throttling in Nehalem+ MacBooks without batteries
* [Mr.Macintosh](https://mrmacintosh.com)
  * Endless hours helping architect and troubleshoot many portions of the project
* [flagers](https://github.com/flagersgit)
  * Aid with Nvidia Web Driver research and development
  * [non-Metal patch set](https://github.com/moraea/non-metal-frameworks) for nVidia Tesla/Fermi/Maxwell/Pascal, AMD TeraScale 1/2, and Intel Core 1st/2nd Generation GPUs
  * [Metal bundle interposer](https://github.com/moraea/misc-patches/tree/main/sequoia%2031001%20interposer) for AMD GCN 1 - 5 and Intel Core 5th/6th Generation GPUs
  * LegacyRVPL, SnapshotIsKill, etc. to aid in rapid testing and development
* [joevt](https://github.com/joevt)
  * [FixPCIeLinkrate](https://github.com/joevt/joevtApps)
* [Jazzzny](https://github.com/Jazzzny)
  * Research and various contributions to the project
  * UEFI Legacy XHCI research and development
  * NVIDIA OpenCL research and development
  * `MacBook5,2` research and development
    * LegacyKeyboardInjector
  * Pre-Ivy Bridge Aquantia Ethernet Patch
  * Non-Metal Photo Booth Patch for Monterey+
  * GUI and Backend Development
    * Updater UI
    * macOS Downloader UI
    * Downloader UI
    * USB Top Case probing
    * Developer root patching
  * Vaulting implementation
  * macOS 15 3802 Helios Research
  * UEFI bootx64.efi research
  * universal2 build research
  * Various documentation contributions
* Amazing users who&#039;ve graciously donate hardware:
  * [JohnD](https://forums.macrumors.com/members/johnd.53633/) - 2013 Mac Pro
  * [SpiGAndromeda](https://github.com/SpiGAndromeda) - AMD Vega 64
  * [turbomacs](https://github.com/turbomacs) - 2014 5k iMac
  * [vinaypundith](https://forums.macrumors.com/members/vinaypundith.1212357/) - MacBook7,1
   * [ThatStella7922](https://github.com/ThatStella7922) - 2017 13&quot; MacBook Pro (A1708)
  * zephar - 2008 Mac Pro
  * jazo97 - 2011 15&quot; MacBook Pro
  * And others (reach out if we forgot you!)
* MacRumors and Unsupported Mac Communities
  * Endless testing and reporting issues
* Apple
  * for macOS and many of the kexts, frameworks and other binaries we reimplemented into newer OSes
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[dgtlmoon/changedetection.io]]></title>
            <link>https://github.com/dgtlmoon/changedetection.io</link>
            <guid>https://github.com/dgtlmoon/changedetection.io</guid>
            <pubDate>Mon, 07 Apr 2025 00:04:27 GMT</pubDate>
            <description><![CDATA[The best and simplest free open source web page change detection, website watcher, restock monitor and notification service. Restock Monitor, change detection. Designed for simplicity - Simply monitor which websites had a text change for free. Free Open source web page change detection, Website defacement monitoring, Price change notification]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dgtlmoon/changedetection.io">dgtlmoon/changedetection.io</a></h1>
            <p>The best and simplest free open source web page change detection, website watcher, restock monitor and notification service. Restock Monitor, change detection. Designed for simplicity - Simply monitor which websites had a text change for free. Free Open source web page change detection, Website defacement monitoring, Price change notification</p>
            <p>Language: Python</p>
            <p>Stars: 23,153</p>
            <p>Forks: 1,263</p>
            <p>Stars today: 103 stars today</p>
            <h2>README</h2><pre>## Web Site Change Detection, Restock monitoring and notifications.

**_Detect website content changes and perform meaningful actions - trigger notifications via Discord, Email, Slack, Telegram, API calls and many more._**

_Live your data-life pro-actively._ 


[&lt;img src=&quot;https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/screenshot.png&quot; style=&quot;max-width:100%;&quot; alt=&quot;Self-hosted web site page change monitoring&quot;  title=&quot;Self-hosted web site page change monitoring&quot;  /&gt;](https://changedetection.io?src=github)

[![Release Version][release-shield]][release-link] [![Docker Pulls][docker-pulls]][docker-link] [![License][license-shield]](LICENSE.md)

![changedetection.io](https://github.com/dgtlmoon/changedetection.io/actions/workflows/test-only.yml/badge.svg?branch=master)

[**Get started with website page change monitoring straight away. Don&#039;t have time? Try our $8.99/month subscription, use our proxies and support!**](https://changedetection.io) , _half the price of other website change monitoring services!_

- Chrome browser included.
- Nothing to install, access via browser login after signup.
- Super fast, no registration needed setup.
- Get started watching and receiving website change notifications straight away.
- See our [tutorials and how-to page for more inspiration](https://changedetection.io/tutorials) 

### Target specific parts of the webpage using the Visual Selector tool.

Available when connected to a &lt;a href=&quot;https://github.com/dgtlmoon/changedetection.io/wiki/Playwright-content-fetcher&quot;&gt;playwright content fetcher&lt;/a&gt; (included as part of our subscription service)

[&lt;img src=&quot;https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/visualselector-anim.gif&quot; style=&quot;max-width:100%;&quot; alt=&quot;Select parts and elements of a web page to monitor for changes&quot;  title=&quot;Select parts and elements of a web page to monitor for changes&quot; /&gt;](https://changedetection.io?src=github)

### Easily see what changed, examine by word, line, or individual character.

[&lt;img src=&quot;https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/screenshot-diff.png&quot; style=&quot;max-width:100%;&quot; alt=&quot;Self-hosted web page change monitoring context difference &quot;  title=&quot;Self-hosted web page change monitoring context difference &quot; /&gt;](https://changedetection.io?src=github)


### Perform interactive browser steps

Fill in text boxes, click buttons and more, setup your changedetection scenario. 

Using the **Browser Steps** configuration, add basic steps before performing change detection, such as logging into websites, adding a product to a cart, accept cookie logins, entering dates and refining searches.

[&lt;img src=&quot;docs/browsersteps-anim.gif&quot; style=&quot;max-width:100%;&quot; alt=&quot;Website change detection with interactive browser steps, detect changes behind login and password, search queries and more&quot;  title=&quot;Website change detection with interactive browser steps, detect changes behind login and password, search queries and more&quot; /&gt;](https://changedetection.io?src=github)

After **Browser Steps** have been run, then visit the **Visual Selector** tab to refine the content you&#039;re interested in.
Requires Playwright to be enabled.

### Awesome restock and price change notifications

Enable the _&quot;Re-stock &amp; Price detection for single product pages&quot;_ option to activate the best way to monitor product pricing, this will extract any meta-data in the HTML page and give you many options to follow the pricing of the product.

Easily organise and monitor prices for products from the dashboard, get alerts and notifications when the price of a product changes or comes back in stock again!

[&lt;img src=&quot;docs/restock-overview.png&quot; style=&quot;max-width:100%;&quot; alt=&quot;Easily keep an eye on product price changes directly from the UI&quot;  title=&quot;Easily keep an eye on product price changes directly from the UI&quot; /&gt;](https://changedetection.io?src=github)

Set price change notification parameters, upper and lower price, price change percentage and more.
Always know when a product for sale drops in price.

[&lt;img src=&quot;docs/restock-settings.png&quot; style=&quot;max-width:100%;&quot; alt=&quot;Set upper lower and percentage price change notification values&quot;  title=&quot;Set upper lower and percentage price change notification values&quot; /&gt;](https://changedetection.io?src=github)



### Example use cases

- Products and services have a change in pricing
- _Out of stock notification_ and _Back In stock notification_
- Monitor and track PDF file changes, know when a PDF file has text changes.
- Governmental department updates (changes are often only on their websites)
- New software releases, security advisories when you&#039;re not on their mailing list.
- Festivals with changes
- Discogs restock alerts and monitoring
- Realestate listing changes
- Know when your favourite whiskey is on sale, or other special deals are announced before anyone else
- COVID related news from government websites
- University/organisation news from their website
- Detect and monitor changes in JSON API responses 
- JSON API monitoring and alerting
- Changes in legal and other documents
- Trigger API calls via notifications when text appears on a website
- Glue together APIs using the JSON filter and JSON notifications
- Create RSS feeds based on changes in web content
- Monitor HTML source code for unexpected changes, strengthen your PCI compliance
- You have a very sensitive list of URLs to watch and you do _not_ want to use the paid alternatives. (Remember, _you_ are the product)
- Get notified when certain keywords appear in Twitter search results
- Proactively search for jobs, get notified when companies update their careers page, search job portals for keywords.
- Get alerts when new job positions are open on Bamboo HR and other job platforms
- Website defacement monitoring
- Pokémon Card Restock Tracker / Pokémon TCG Tracker
- RegTech - stay ahead of regulatory changes, regulatory compliance

_Need an actual Chrome runner with Javascript support? We support fetching via WebDriver and Playwright!&lt;/a&gt;_

#### Key Features

- Lots of trigger filters, such as &quot;Trigger on text&quot;, &quot;Remove text by selector&quot;, &quot;Ignore text&quot;, &quot;Extract text&quot;, also using regular-expressions!
- Target elements with xPath 1 and xPath 2, CSS Selectors, Easily monitor complex JSON with JSONPath or jq
- Switch between fast non-JS and Chrome JS based &quot;fetchers&quot;
- Track changes in PDF files (Monitor text changed in the PDF, Also monitor PDF filesize and checksums)
- Easily specify how often a site should be checked
- Execute JS before extracting text (Good for logging in, see examples in the UI!)
- Override Request Headers, Specify `POST` or `GET` and other methods
- Use the &quot;Visual Selector&quot; to help target specific elements
- Configurable [proxy per watch](https://github.com/dgtlmoon/changedetection.io/wiki/Proxy-configuration)
- Send a screenshot with the notification when a change is detected in the web page

We [recommend and use Bright Data](https://brightdata.grsm.io/n0r16zf7eivq) global proxy services, Bright Data will match any first deposit up to $100 using our signup link.

[Oxylabs](https://oxylabs.go2cloud.org/SH2d) is also an excellent proxy provider and well worth using, they offer Residental, ISP, Rotating and many other proxy types to suit your project. 

Please :star: star :star: this project and help it grow! https://github.com/dgtlmoon/changedetection.io/

### Schedule web page watches in any timezone, limit by day of week and time.

Easily set a re-check schedule, for example you could limit the web page change detection to only operate during business hours.
Or perhaps based on a foreign timezone (for example, you want to check for the latest news-headlines in a foreign country at 0900 AM),

&lt;img src=&quot;./docs/scheduler.png&quot; style=&quot;max-width:80%;&quot; alt=&quot;How to monitor web page changes according to a schedule&quot;  title=&quot;How to monitor web page changes according to a schedule&quot;  /&gt;

Includes quick short-cut buttons to setup a schedule for **business hours only**, or **weekends**.

### We have a Chrome extension!

Easily add the current web page to your changedetection.io tool, simply install the extension and click &quot;Sync&quot; to connect it to your existing changedetection.io install.

[&lt;img src=&quot;./docs/chrome-extension-screenshot.png&quot; style=&quot;max-width:80%;&quot; alt=&quot;Chrome Extension to easily add the current web-page to detect a change.&quot;  title=&quot;Chrome Extension to easily add the current web-page to detect a change.&quot;  /&gt;](https://chromewebstore.google.com/detail/changedetectionio-website/kefcfmgmlhmankjmnbijimhofdjekbop)

[Goto the Chrome Webstore to download the extension.](https://chromewebstore.google.com/detail/changedetectionio-website/kefcfmgmlhmankjmnbijimhofdjekbop) ( Or check out the [GitHub repo](https://github.com/dgtlmoon/changedetection.io-browser-extension) ) 

## Installation

### Docker

With Docker composer, just clone this repository and..

```bash
$ docker compose up -d
```

Docker standalone
```bash
$ docker run -d --restart always -p &quot;127.0.0.1:5000:5000&quot; -v datastore-volume:/datastore --name changedetection.io dgtlmoon/changedetection.io
```

`:latest` tag is our latest stable release, `:dev` tag is our bleeding edge `master` branch.

Alternative docker repository over at ghcr - [ghcr.io/dgtlmoon/changedetection.io](https://ghcr.io/dgtlmoon/changedetection.io)

### Windows

See the install instructions at the wiki https://github.com/dgtlmoon/changedetection.io/wiki/Microsoft-Windows

### Python Pip

Check out our pypi page https://pypi.org/project/changedetection.io/

```bash
$ pip3 install changedetection.io
$ changedetection.io -d /path/to/empty/data/dir -p 5000
```

Then visit http://127.0.0.1:5000 , You should now be able to access the UI.

_Now with per-site configurable support for using a fast built in HTTP fetcher or use a Chrome based fetcher for monitoring of JavaScript websites!_

## Updating changedetection.io

### Docker
```
docker pull dgtlmoon/changedetection.io
docker kill $(docker ps -a -f name=changedetection.io -q)
docker rm $(docker ps -a -f name=changedetection.io -q)
docker run -d --restart always -p &quot;127.0.0.1:5000:5000&quot; -v datastore-volume:/datastore --name changedetection.io dgtlmoon/changedetection.io
```

### docker compose

```bash
docker compose pull &amp;&amp; docker compose up -d
```

See the wiki for more information https://github.com/dgtlmoon/changedetection.io/wiki


## Filters

XPath(1.0), JSONPath, jq, and CSS support comes baked in! You can be as specific as you need, use XPath exported from various XPath element query creation tools. 
(We support LXML `re:test`, `re:match` and `re:replace`.)

## Notifications

ChangeDetection.io supports a massive amount of notifications (including email, office365, custom APIs, etc) when a web-page has a change detected thanks to the &lt;a href=&quot;https://github.com/caronc/apprise&quot;&gt;apprise&lt;/a&gt; library.
Simply set one or more notification URL&#039;s in the _[edit]_ tab of that watch.

Just some examples

    discord://webhook_id/webhook_token
    flock://app_token/g:channel_id
    gitter://token/room
    gchat://workspace/key/token
    msteams://TokenA/TokenB/TokenC/
    o365://TenantID:AccountEmail/ClientID/ClientSecret/TargetEmail
    rocket://user:password@hostname/#Channel
    mailto://user:pass@example.com?to=receivingAddress@example.com
    json://someserver.com/custom-api
    syslog://
 
&lt;a href=&quot;https://github.com/caronc/apprise#popular-notification-services&quot;&gt;And everything else in this list!&lt;/a&gt;

&lt;img src=&quot;https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/screenshot-notifications.png&quot; style=&quot;max-width:100%;&quot; alt=&quot;Self-hosted web page change monitoring notifications&quot;  title=&quot;Self-hosted web page change monitoring notifications&quot;  /&gt;

Now you can also customise your notification content and use &lt;a target=&quot;_new&quot; href=&quot;https://jinja.palletsprojects.com/en/3.0.x/templates/&quot;&gt;Jinja2 templating&lt;/a&gt; for their title and body!

## JSON API Monitoring

Detect changes and monitor data in JSON API&#039;s by using either JSONPath or jq to filter, parse, and restructure JSON as needed.

![image](https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/json-filter-field-example.png)

This will re-parse the JSON and apply formatting to the text, making it super easy to monitor and detect changes in JSON API results

![image](https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/json-diff-example.png)

### JSONPath or jq?

For more complex parsing, filtering, and modifying of JSON data, jq is recommended due to the built-in operators and functions. Refer to the [documentation](https://stedolan.github.io/jq/manual/) for more specific information on jq.

One big advantage of `jq` is that you can use logic in your JSON filter, such as filters to only show items that have a value greater than/less than etc.

See the wiki https://github.com/dgtlmoon/changedetection.io/wiki/JSON-Selector-Filter-help for more information and examples

### Parse JSON embedded in HTML!

When you enable a `json:` or `jq:` filter, you can even automatically extract and parse embedded JSON inside a HTML page! Amazingly handy for sites that build content based on JSON, such as many e-commerce websites. 

```
&lt;html&gt;
...
&lt;script type=&quot;application/ld+json&quot;&gt;

{
   &quot;@context&quot;:&quot;http://schema.org/&quot;,
   &quot;@type&quot;:&quot;Product&quot;,
   &quot;offers&quot;:{
      &quot;@type&quot;:&quot;Offer&quot;,
      &quot;availability&quot;:&quot;http://schema.org/InStock&quot;,
      &quot;price&quot;:&quot;3949.99&quot;,
      &quot;priceCurrency&quot;:&quot;USD&quot;,
      &quot;url&quot;:&quot;https://www.newegg.com/p/3D5-000D-001T1&quot;
   },
   &quot;description&quot;:&quot;Cobratype King Cobra Hero Desktop Gaming PC&quot;,
   &quot;name&quot;:&quot;Cobratype King Cobra Hero Desktop Gaming PC&quot;,
   &quot;sku&quot;:&quot;3D5-000D-001T1&quot;,
   &quot;itemCondition&quot;:&quot;NewCondition&quot;
}
&lt;/script&gt;
```  

`json:$..price` or `jq:..price` would give `3949.99`, or you can extract the whole structure (use a JSONpath test website to validate with)

The application also supports notifying you that it can follow this information automatically


## Proxy Configuration

See the wiki https://github.com/dgtlmoon/changedetection.io/wiki/Proxy-configuration , we also support using [Bright Data proxy services where possible](https://github.com/dgtlmoon/changedetection.io/wiki/Proxy-configuration#brightdata-proxy-support) and [Oxylabs](https://oxylabs.go2cloud.org/SH2d) proxy services.

## Raspberry Pi support?

Raspberry Pi and linux/arm/v6 linux/arm/v7 arm64 devices are supported! See the wiki for [details](https://github.com/dgtlmoon/changedetection.io/wiki/Fetching-pages-with-WebDriver)

## Import support

Easily [import your list of websites to watch for changes in Excel .xslx file format](https://changedetection.io/tutorial/how-import-your-website-change-detection-lists-excel), or paste in lists of website URLs as plaintext. 

Excel import is recommended - that way you can better organise tags/groups of websites and other features.


## API Support

Supports managing the website watch list [via our API](https://changedetection.io/docs/api_v1/index.html)

## Support us

Do you use changedetection.io to make money? does it save you time or money? Does it make your life easier? less stressful? Remember, we write this software when we should be doing actual paid work, we have to buy food and pay rent just like you.


Consider taking out an officially supported [website change detection subscription](https://changedetection.io?src=github) , even if you don&#039;t use it, you still get the warm fuzzy feeling of helping out the project. (And who knows, you might just use it!)

## Commercial Support

I offer commercial support, this software is depended on by network security, aerospace , data-science and data-journalist professionals just to name a few, please reach out at dgtlmoon@gmail.com for any enquiries, I am more than glad to work with your organisation to further the possibilities of what can be done with changedetection.io


[release-shield]: https://img.shields.io:/github/v/release/dgtlmoon/changedetection.io?style=for-the-badge
[docker-pulls]: https://img.shields.io/docker/pulls/dgtlmoon/changedetection.io?style=for-the-badge
[test-shield]: https://github.com/dgtlmoon/changedetection.io/actions/workflows/test-only.yml/badge.svg?branch=master

[license-shield]: https://img.shields.io/github/license/dgtlmoon/changedetection.io.svg?style=for-the-badge
[release-link]: https://github.com/dgtlmoon/changedetection.io/releases
[docker-link]: https://hub.docker.com/r/dgtlmoon/changedetection.io

## Commercial Licencing

If you are reselling this software either in part or full as part of any commercial arrangement, you must abide by our COMMERCIAL_LICENCE.md found in our code repository, please contact dgtlmoon@gmail.com and contact@changedetection.io .

## Third-party licenses

changedetectionio.html_tools.elementpath_tostring: Copyright (c), 2018-2021, SISSA (Scuola Internazionale Superiore di Studi Avanzati), Licensed under [MIT license](https://github.com/sissaschool/elementpath/blob/master/LICENSE)

## Contributors

Recognition of fantastic contributors to the project

- Constantin Hong https://github.com/Constantin1489
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[home-assistant/core]]></title>
            <link>https://github.com/home-assistant/core</link>
            <guid>https://github.com/home-assistant/core</guid>
            <pubDate>Mon, 07 Apr 2025 00:04:26 GMT</pubDate>
            <description><![CDATA[🏡 Open source home automation that puts local control and privacy first.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/home-assistant/core">home-assistant/core</a></h1>
            <p>🏡 Open source home automation that puts local control and privacy first.</p>
            <p>Language: Python</p>
            <p>Stars: 77,902</p>
            <p>Forks: 33,175</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[stephengpope/no-code-architects-toolkit]]></title>
            <link>https://github.com/stephengpope/no-code-architects-toolkit</link>
            <guid>https://github.com/stephengpope/no-code-architects-toolkit</guid>
            <pubDate>Mon, 07 Apr 2025 00:04:25 GMT</pubDate>
            <description><![CDATA[The NCA Toolkit API eliminates monthly subscription fees by consolidating common API functionalities into a single FREE API. Designed for businesses, creators, and developers, it streamlines advanced media processing, including video editing and captioning, image transformations, cloud storage, and Python code execution.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stephengpope/no-code-architects-toolkit">stephengpope/no-code-architects-toolkit</a></h1>
            <p>The NCA Toolkit API eliminates monthly subscription fees by consolidating common API functionalities into a single FREE API. Designed for businesses, creators, and developers, it streamlines advanced media processing, including video editing and captioning, image transformations, cloud storage, and Python code execution.</p>
            <p>Language: Python</p>
            <p>Stars: 572</p>
            <p>Forks: 252</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>
![Original Logo Symbol](https://github.com/user-attachments/assets/75173cf4-2502-4710-998b-6b81740ae1bd)

# No-Code Architects Toolkit API 

Tired of wasting thousands of dollars on API subscriptions to support all your automations? What if there was a free alternative?

The 100% FREE No-Code Architects Toolkit API processes different types of media. It is built in Python using Flask.

## What Can It Do?

The API can convert audio files. It creates transcriptions of content. It translates content between languages. It adds captions to videos. It can do very complicated media processing for content creation. The API can also manage files across multiple cloud services like Google Drive, Amazon S3, Google Cloud Storage, and Dropbox.

You can deploy this toolkit in several ways. It works with Docker. It runs on Google Cloud Platform. It functions on Digital Ocean. You can use it with any system that hosts Docker.

Easily replace services like ChatGPT Whisper, Cloud Convert, Createomate, JSON2Video, PDF(dot)co, Placid and OCodeKit.

## 👥 No-Code Architects Community

Want help? Join a supportive community and get dedicated tech support.

Join the ONLY community where you learn to leverage AI automation and content to grow your business (and streamline your biz).

Who&#039;s this for?
- Coaches and consultants
- AI Automation agencies
- SMMA &amp; Content agencies
- SaaS Startup Founders

Get courses, community, support, daily calls and more.

Join the **[No-Code Architects Community](https://www.skool.com/no-code-architects)** today!

---

## Features of the No-Code Architects Toolkit API

Each feature is supported by robust payload validation and detailed API documentation to facilitate easy integration and usage.

### Advanced Media Manipulation

#### 1. `/v1/ffmpeg/compose`
- **Description**: Provides a flexible way to compose and manipulate media files using FFmpeg. Supports complex media operations like transcoding, concatenation, and filtering.
- **Documentation Link**: [FFmpeg Compose Documentation](https://github.com/stephengpope/no-code-architects-toolkit/blob/main/docs/ffmpeg/ffmpeg_compose.md)

---

### Video Processing

#### 2. `/v1/video/caption`
- **Description**: Adds captions to a video file, including options for font, position, and styling. It also supports automated language detection and custom replacements in captions.
- **Documentation Link**: [Video Caption Documentation](https://github.com/stephengpope/no-code-architects-toolkit/blob/main/docs/video/caption_video.md)

#### 3. `/v1/video/concatenate`
- **Description**: Combines multiple video files into a single video file. The input files are concatenated in the specified order, and the final video is uploaded to cloud storage.
- **Documentation Link**: [Video Concatenate Documentation](https://github.com/stephengpope/no-code-architects-toolkit/blob/main/docs/video/concatenate.md)

---

### Code Execution

#### 4. `/v1/code/execute/python`
- **Description**: Executes Python code on the server in a controlled environment. Useful for scripting, prototyping, or dynamically running Python scripts with secure execution.
- **Documentation Link**: [Execute Python Documentation](https://github.com/stephengpope/no-code-architects-toolkit/blob/main/docs/code/execute/execute_python.md)

---

### Image Processing

#### 5. `/v1/image/convert/video`
- **Description**: Converts an image into a video file with configurable options like duration, frame rate, and zoom effects. Ideal for creating video slideshows or transitions.
- **Documentation Link**: [Image to Video Documentation](https://github.com/stephengpope/no-code-architects-toolkit/blob/main/docs/image/convert/image_to_video.md)

---

### Media Transformation

#### 6. `/v1/media/convert/mp3`
- **Description**: Converts various media files (audio or video) to MP3 format with configurable bitrate and quality settings.
- **Documentation Link**: [Media to MP3 Documentation](https://github.com/stephengpope/no-code-architects-toolkit/blob/main/docs/media/convert/media_to_mp3.md)

#### 7. `/v1/media/transcribe`
- **Description**: Transcribes audio files to text using advanced speech-to-text processing. Supports various languages and audio formats.
- **Documentation Link**: [Audio Transcribe Documentation](https://github.com/stephengpope/no-code-architects-toolkit/blob/main/docs/media/media_transcribe.md)


---

### Core Features

#### 8. `/v1/toolkit/test`
- **Description**: A basic endpoint to verify the availability and functionality of the API. Useful for initial setup and connection tests.
- **Documentation Link**: [Test Endpoint Documentation](https://github.com/stephengpope/no-code-architects-toolkit/blob/main/docs/toolkit/test.md)

#### 9. `/v1/toolkit/authenticate`
- **Description**: Verifies the provided API key and authenticates the user. Returns a success message if the API key is valid.
- **Documentation Link**: [Authenticate Endpoint Documentation](https://github.com/stephengpope/no-code-architects-toolkit/blob/main/docs/toolkit/authenticate.md)

---

## Docker Build and Run

### Build the Docker Image

   ```bash
   docker build -t no-code-architects-toolkit .
   ```

### General Environment Variables

#### `API_KEY`
- **Purpose**: Used for API authentication.
- **Requirement**: Mandatory.

---

### Google Cloud Platform (GCP) Environment Variables

#### `GCP_SA_CREDENTIALS`
- **Purpose**: The JSON credentials for the GCP Service Account.
- **Requirement**: Mandatory if using GCP storage.

#### `GCP_BUCKET_NAME`
- **Purpose**: The name of the GCP storage bucket.
- **Requirement**: Mandatory if using GCP storage.

---

### S3-Compatible Storage Environment Variable

#### `S3_ENDPOINT_URL`
- **Purpose**: Endpoint URL for the S3-compatible service.
- **Requirement**: Mandatory if using S3-compatible storage.

#### `S3_ACCESS_KEY`
- **Purpose**: The access key for the S3-compatible storage service.
- **Requirement**: Mandatory if using S3-compatible storage.

#### `S3_SECRET_KEY`
- **Purpose**: The secret key for the S3-compatible storage service.
- **Requirement**: Mandatory if using S3-compatible storage.

#### `S3_BUCKET_NAME`
- **Purpose**: The bucket name for the S3-compatible storage service.
- **Requirement**: Mandatory if using S3-compatible storage.

#### `S3_REGION`
- **Purpose**: The region for the S3-compatible storage service.
- **Requirement**: Mandatory if using S3-compatible storage, &quot;None&quot; is acceptible for some s3 providers.

---

### Notes
- Ensure all required environment variables are set based on the storage provider in use (GCP or S3-compatible). 
- Missing any required variables will result in errors during runtime.

### Run the Docker Container:

   ```bash
   docker run -d -p 8080:8080 \
     -e API_KEY=your_api_key \
     -e GCP_SA_CREDENTIALS=&#039;{&quot;your&quot;:&quot;service_account_json&quot;}&#039; \
     -e GCP_BUCKET_NAME=your_gcs_bucket_name \
     no-code-architects-toolkit
   ```

---

# Installing on the Google Cloud Platform (GCP)

## 🎥 Video Instructions

Watch **[Detailed Video Instructions](https://youtu.be/6bC93sek9v8)** to set up the No-Code Architects Toolkit API.

- Use the **Docker Image** below:

  ```
  stephengpope/no-code-architects-toolkit:latest
  ```

### Video Resources

- **[Postman Template](https://bit.ly/49Gkh61)**
- **[NCA Toolkit API GPT](https://bit.ly/4feDDk4)** 

Or use the guide below walks you through the steps to install the NCA Toolkit API on GCP.

---

## **Prerequisites**
- A Google Cloud account. [Sign up here](https://cloud.google.com/) if you don&#039;t already have one.
  - New users receive $300 in free credits.
- Basic knowledge of GCP services such as Cloud Run and Cloud Storage.
- A terminal or code editor for managing files.

---

## **Step 1: Create a Google Cloud Project**
1. Log into the [GCP Console](https://console.cloud.google.com/).
2. Click on the **Project Selector** in the top navigation bar and select **New Project**.
3. Enter a project name, such as `NCA Toolkit Project`.
4. Click **Create**.

---

## **Step 2: Enable Required APIs**
Enable the following APIs:
- **Cloud Storage API**
- **Cloud Storage JSON API**
- **Cloud Run API**

### **How to Enable APIs:**
1. In the GCP Console, navigate to **APIs &amp; Services** &gt; **Enable APIs and Services**.
2. Search for each API, click on it, and enable it.

---

## **Step 3: Create a Service Account**
1. Navigate to **IAM &amp; Admin** &gt; **Service Accounts** in the GCP Console.
2. Click **+ Create Service Account**.
   - Enter a name (e.g., `NCA Toolkit Service Account`).
3. Assign the following roles to the service account:
   - **Storage Admin**
   - **Viewer**
4. Click **Done** to create the service account.
5. Open the service account details and navigate to the **Keys** tab.
   - Click **Add Key** &gt; **Create New Key**.
   - Choose **JSON** format, download the file, and store it securely.

---

## **Step 4: Create a Cloud Storage Bucket**
1. Navigate to **Storage** &gt; **Buckets** in the GCP Console.
2. Click **+ Create Bucket**.
   - Choose a unique bucket name (e.g., `nca-toolkit-bucket`).
   - Leave default settings, but:
     - Uncheck **Enforce public access prevention**.
     - Set **Access Control** to **Uniform**.
3. Click **Create** to finish.
4. Go to the bucket permissions, and add **allUsers** as a principal with the role:
   - **Storage Object Viewer**.
5. Save changes.

---

## **Step 5: Deploy on Google Cloud Run**

### 1. Navigate to Cloud Run
- Open the **Cloud Run** service in the **Google Cloud Console**.

### 2. Create a New Service
- Click **Create Service**.
- Then **Deploy one revision from Docker Hub using the image below**:

  ```
  stephengpope/no-code-architects-toolkit:latest
  ```

### 3. Allow Unauthenticated Invocations
- Check the box to **allow unauthenticated invocations**.

### 4. Configure Resource Allocation
- Set **Memory**: `16 GB`.
- Set **CPU**: `4 CPUs`.
- Set **CPU Allocation**: **Always Allocated**.

### 5. Adjust Scaling Settings
- **Minimum Instances**: `0` (to minimize cost during idle times).
- **Maximum Instances**: `5` (adjustable based on expected load).

### 6. Use Second-Generation Servers
- Scroll to **Platform Version** and select **Second Generation**.
- Second-generation servers offer better performance and feature support for advanced use cases.

### 7. Add Environment Variables
- Add the following environment variables:
- `API_KEY`: Your API key (e.g., `Test123`).
- `GCP_BUCKET_NAME`: The name of your Cloud Storage bucket.
- `GCP_SA_CREDENTIALS`: The JSON key of your service account.
  - Paste the **entire contents** of the downloaded JSON key file into this field.
  - Ensure:
    - Proper JSON formatting.
    - No leading or trailing spaces.

### 8. Configure Advanced Settings
- Set the **Container Port**: Default to `8080`.
- **Request Timeout**: `300 seconds` (to handle long-running requests).
- Enable **Startup Boost** to improve performance for the first request after a cold start.

### 9. Deploy the Service
- Verify all settings and click **Create**.
- The deployment process might take a few minutes. Once completed, a green checkmark should appear in the Cloud Run dashboard.

By following these steps, the NCA Toolkit will be successfully deployed and accessible via Google Cloud Run with second-generation servers for optimal performance.

---

## **Step 6: Test the Deployment**

1. Install **[Postman Template](https://bit.ly/49Gkh61)** on your computer.
2. Import the API example requests from the NCA Toolkit GitHub repository.
3. Configure two environment variables in Postman:
   - `base_url`: Your deployed Cloud Run service URL.
   - `x-api-key`: The API key you configured in **Step 5**.
4. Use the example requests to validate that the API is functioning correctly.
5. Use the **[NCA Toolkit API GPT](https://bit.ly/4feDDk4)** to learn more.

By following these steps, your NCA Toolkit API should be successfully deployed on Google Cloud Platform.

---

## Contributing To the NCA Toolkit API

We welcome contributions from the public! If you&#039;d like to contribute to this project, please follow these steps:

1. Fork the repository
2. Create a new branch for your feature or bug fix
3. Make your changes
4. Submit a pull request to the &quot;build&quot; branch

### Pull Request Process

1. Ensure any install or build dependencies are removed before the end of the layer when doing a build.
2. Update the README.md with details of changes to the interface, this includes new environment variables, exposed ports, useful file locations and container parameters.

Thank you for your contributions!

---

## How To Get Support

Get courses, community, support daily calls and more.

Join the **[No-Code Architects Community](https://www.skool.com/no-code-architects)** today!

## License

This project is licensed under the [MIT License](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[nautechsystems/nautilus_trader]]></title>
            <link>https://github.com/nautechsystems/nautilus_trader</link>
            <guid>https://github.com/nautechsystems/nautilus_trader</guid>
            <pubDate>Mon, 07 Apr 2025 00:04:24 GMT</pubDate>
            <description><![CDATA[A high-performance algorithmic trading platform and event-driven backtester]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nautechsystems/nautilus_trader">nautechsystems/nautilus_trader</a></h1>
            <p>A high-performance algorithmic trading platform and event-driven backtester</p>
            <p>Language: Python</p>
            <p>Stars: 4,914</p>
            <p>Forks: 748</p>
            <p>Stars today: 39 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;https://github.com/nautechsystems/nautilus_trader/raw/develop/docs/_images/nautilus-trader-logo.png&quot; width=&quot;500&quot;&gt;

[![codecov](https://codecov.io/gh/nautechsystems/nautilus_trader/branch/master/graph/badge.svg?token=DXO9QQI40H)](https://codecov.io/gh/nautechsystems/nautilus_trader)
[![codspeed](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/nautechsystems/nautilus_trader)
![pythons](https://img.shields.io/pypi/pyversions/nautilus_trader)
![pypi-version](https://img.shields.io/pypi/v/nautilus_trader)
![pypi-format](https://img.shields.io/pypi/format/nautilus_trader?color=blue)
[![Downloads](https://pepy.tech/badge/nautilus-trader)](https://pepy.tech/project/nautilus-trader)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/NautilusTrader)

| Branch    | Version                                                                                                                                                                                                                     | Status                                                                                                                                                                                            |
| :-------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `master`  | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fmaster%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html)  | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)  |
| `nightly` | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fnightly%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html) | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |
| `develop` | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fdevelop%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html) | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=develop)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |

| Platform           | Rust    | Python      |
| :----------------- | :------ | :---------- |
| `Linux (x86_64)`   | 1.86.0+ | 3.11, 3.12  |
| `macOS (arm64)`    | 1.86.0+ | 3.11, 3.12  |
| `Windows (x86_64)` | 1.86.0+ | 3.11, 3.12  |

- **Docs**: https://nautilustrader.io/docs/
- **Website**: https://nautilustrader.io
- **Support**: [support@nautilustrader.io](mailto:support@nautilustrader.io)

## Introduction

NautilusTrader is an open-source, high-performance, production-grade algorithmic trading platform,
providing quantitative traders with the ability to backtest portfolios of automated trading strategies
on historical data with an event-driven engine, and also deploy those same strategies live, with no code changes.

The platform is *AI-first*, designed to develop and deploy algorithmic trading strategies within a highly performant
and robust Python-native environment. This helps to address the parity challenge of keeping the Python research/backtest
environment consistent with the production live trading environment.

NautilusTrader&#039;s design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting Python-native, mission-critical, trading system backtesting
and live deployment workloads.

The platform is also universal, and asset-class-agnostic —  with any REST API or WebSocket feed able to be integrated via modular
adapters. It supports high-frequency trading across a wide range of asset classes and instrument types
including FX, Equities, Futures, Options, Crypto and Betting, enabling seamless operations across multiple venues simultaneously.

![nautilus-trader](https://github.com/nautechsystems/nautilus_trader/raw/develop/docs/_images/nautilus-trader.png &quot;nautilus-trader&quot;)

## Features

- **Fast**: Core is written in Rust with asynchronous networking using [tokio](https://crates.io/crates/tokio).
- **Reliable**: Type safety and thread safety through Rust. [Redis](https://redis.io)-backed performant state persistence (optional).
- **Portable**: OS independent, runs on Linux, macOS, and Windows. Deploy using Docker.
- **Flexible**: Modular adapters mean any REST API or WebSocket feed can be integrated.
- **Advanced**: Time in force `IOC`, `FOK`, `GTC`, `GTD`, `DAY`, `AT_THE_OPEN`, `AT_THE_CLOSE`, advanced order types and conditional triggers. Execution instructions `post-only`, `reduce-only`, and icebergs. Contingency orders including `OCO`, `OUO`, `OTO`.
- **Customizable**: Add user-defined custom components, or assemble entire systems from scratch leveraging the [cache](https://nautilustrader.io/docs/latest/concepts/cache) and [message bus](https://nautilustrader.io/docs/latest/concepts/message_bus).
- **Backtesting**: Run with multiple venues, instruments and strategies simultaneously using historical quote tick, trade tick, bar, order book and custom data with nanosecond resolution.
- **Live**: Use identical strategy implementations between backtesting and live deployments.
- **Multi-venue**: Multiple venue capabilities facilitate market-making and statistical arbitrage strategies.
- **AI Training**: Backtest engine fast enough to be used to train AI trading agents (RL/ES).

![Alt text](https://github.com/nautechsystems/nautilus_trader/raw/develop/docs/_images/nautilus-art.png &quot;nautilus&quot;)

&gt; _nautilus - from ancient Greek &#039;sailor&#039; and naus &#039;ship&#039;._
&gt;
&gt; _The nautilus shell consists of modular chambers with a growth factor which approximates a logarithmic spiral.
&gt; The idea is that this can be translated to the aesthetics of design and architecture._

## Why NautilusTrader?

- **Highly performant event-driven Python**: Native binary core components.
- **Parity between backtesting and live trading**: Identical strategy code.
- **Reduced operational risk**: Enhanced risk management functionality, logical accuracy, and type safety.
- **Highly extendable**: Message bus, custom components and actors, custom data, custom adapters.

Traditionally, trading strategy research and backtesting might be conducted in Python
using vectorized methods, with the strategy then needing to be reimplemented in a more event-driven way
using C++, C#, Java or other statically typed language(s). The reasoning here is that vectorized backtesting code cannot
express the granular time and event dependent complexity of real-time trading, where compiled languages have
proven to be more suitable due to their inherently higher performance, and type safety.

One of the key advantages of NautilusTrader here, is that this reimplementation step is now circumvented - as the critical core components of the platform
have all been written entirely in [Rust](https://www.rust-lang.org/) or [Cython](https://cython.org/).
This means we&#039;re using the right tools for the job, where systems programming languages compile performant binaries,
with CPython C extension modules then able to offer a Python-native environment, suitable for professional quantitative traders and trading firms.

## Why Python?

Python was originally created decades ago as a simple scripting language with a clean straightforward syntax.
It has since evolved into a fully fledged general purpose object-oriented programming language.
Based on the TIOBE index, Python is currently the most popular programming language in the world.
Not only that, Python has become the _de facto lingua franca_ of data science, machine learning, and artificial intelligence.

The language out of the box is not without its drawbacks however, especially in the context of
implementing large performance-critical systems. Cython has addressed a lot of these issues, offering all the advantages
of a statically typed language, embedded into Python&#039;s rich ecosystem of software libraries and
developer/user communities.

## What is Rust?

[Rust](https://www.rust-lang.org/) is a multi-paradigm programming language designed for performance and safety, especially safe
concurrency. Rust is &quot;blazingly fast&quot; and memory-efficient (comparable to C and C++) with no garbage collector.
It can power mission-critical systems, run on embedded devices, and easily integrates with other languages.

Rust’s rich type system and ownership model guarantees memory-safety and thread-safety deterministically —
eliminating many classes of bugs at compile-time.

The project increasingly utilizes Rust for core performance-critical components. Python language binding is handled through
Cython and [PyO3](https://pyo3.rs), with static libraries linked at compile-time before the wheel binaries are packaged, so a user
does not need to have Rust installed to run NautilusTrader.

This project makes the [Soundness Pledge](https://raphlinus.github.io/rust/2020/01/18/soundness-pledge.html):

&gt; “The intent of this project is to be free of soundness bugs.
&gt; The developers will do their best to avoid them, and welcome help in analyzing and fixing them.”

&gt; [!NOTE]
&gt;
&gt; **MSRV:** NautilusTrader relies heavily on improvements in the Rust language and compiler.
&gt; As a result, the Minimum Supported Rust Version (MSRV) is generally equal to the latest stable release of Rust.

## Integrations

NautilusTrader is modularly designed to work with _adapters_, enabling connectivity to trading venues
and data providers by translating their raw APIs into a unified interface and normalized domain model.

The following integrations are currently supported:

| Name                                                                         | ID                    | Type                    | Status                                                  | Docs                                                                            |
| :--------------------------------------------------------------------------- | :-------------------- | :---------------------- | :------------------------------------------------------ | :------------------------------------------------------------------------------ |
| [Betfair](https://betfair.com)                                               | `BETFAIR`             | Sports Betting Exchange | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/betfair.html)       |
| [Binance](https://binance.com)                                               | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/binance.html)       |
| [Binance US](https://binance.us)                                             | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/binance.html)       |
| [Binance Futures](https://www.binance.com/en/futures)                        | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/binance.html)       |
| [Bybit](https://www.bybit.com)                                               | `BYBIT`               | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/bybit.html)         |
| [Coinbase International](https://www.coinbase.com/en/international-exchange) | `COINBASE_INTX`       | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/beta-yellow)     | [Guide](https://nautilustrader.io/docs/nightly/integrations/coinbase_intx.html) |
| [Databento](https://databento.com)                                           | `DATABENTO`           | Data Provider           | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/databento.html)     |
| [dYdX](https://dydx.exchange/)                                               | `DYDX`                | Crypto Exchange (DEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/dydx.html)          |
| [Interactive Brokers](https://www.interactivebrokers.com)                    | `INTERACTIVE_BROKERS` | Brokerage (multi-venue) | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/ib.html)            |
| [OKX](https://okx.com)                                                       | `OKX`                 | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/building-orange) | [Guide](https://nautilustrader.io/docs/nightly/integrations/okx.html)           |
| [Polymarket](https://polymarket.com)                                         | `POLYMARKET`          | Prediction Market (DEX) | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/polymarket.html)    |
| [Tardis](https://tardis.dev)                                                 | `TARDIS`              | Crypto Data Provider    | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/tardis.html)        |

- **ID**: The default client ID for the integrations adapter clients.
- **Type**: The type of integration (often the venue type).

### Status
- `building`: Under construction and likely not in a usable state.
- `beta`: Completed to a minimally working state and in a beta testing phase.
- `stable`: Stabilized feature set and API, the integration has been tested by both developers and users to a reasonable level (some bugs may still remain).

See the [Integrations](https://nautilustrader.io/docs/latest/integrations/index.html) documentation for further details.

## Versioning and releases

**NautilusTrader is still under active development**. Some features may be incomplete, and while
the API is becoming more stable, breaking changes can occur between releases.
We strive to document these changes in the release notes on a **best-effort basis**.

We aim to follow a **bi-weekly release schedule**, though experimental or larger features may cause delays.

### Branches

We aim to maintain a stable, passing build across all branches.

- `master`: Reflects the source code for the latest released version.
- `nightly`: Includes experimental and in-progress features, merged from the `develop` branch daily at **14:00 UTC** and also when required.
- `develop`: The most active branch, frequently updated with new commits, including experimental and in-progress features.

&gt; [!NOTE]
&gt;
&gt; Our [roadmap](/ROADMAP.md) aims to achieve a **stable API for version 2.x** (likely after the Rust port).
&gt; Once this milestone is reached, we plan to implement a formal deprecation process for any API changes.
&gt; This approach allows us to maintain a rapid development pace for now.

## Precision mode

NautilusTrader supports two precision modes for its core value types (`Price`, `Quantity`, `Money`),
which differ in their internal bit-width and maximum decimal precision.

- **High-precision**: 128-bit integers with up to 16 decimals of precision, and a larger value range.
- **Standard-precision**: 64-bit integers with up to 9 decimals of precision, and a smaller value range.

&gt; [!NOTE]
&gt;
&gt; By default, the official Python wheels **ship** in high-precision (128-bit) mode on Linux and macOS.
&gt; On Windows, only standard-precision (64-bit) is available due to the lack of native 128-bit integer support.
&gt; For the Rust crates, the default is standard-precision unless you explicitly enable the `high-precision` feature flag.

See the [Installation Guide](https://nautilustrader.io/docs/latest/getting_started/installation) for further details.

## Installation

### From PyPI

We recommend using the latest supported version of Python and setting up [nautilus_trader](https://pypi.org/project/nautilus_trader/) in a virtual environment to isolate dependencies.

To install the latest binary wheel (or sdist package) from PyPI using Python&#039;s pip package manager:

    pip install -U nautilus_trader

### From the Nautech Systems package index

The Nautech Systems package index (`packages.nautechsystems.io`) is [PEP-503](https://peps.python.org/pep-0503/) compliant and hosts both stable and development binary wheels for `nautilus_trader`.
This enables users to install either the latest stable release or pre-release versions for testing.

#### Stable wheels

Stable wheels correspond to official releases of `nautilus_trader` on PyPI, and use standard versioning.

To install the latest stable release:

    pip install -U nautilus_trader --index-url=https://packages.nautechsystems.io/simple

#### Development wheels

Development wheels are published from both the `develop` and `nightly` branches for Linux and macOS,
allowing users to test features and fixes ahead of stable releases.

This process also helps preserve compute resources and ensures easy access to the exact binaries tested in CI pipelines,
while adhering to [PEP-440](https://peps.python.org/pep-0440/) versioning standards:

- `develop` wheels use the version format `dev{date}+{build_number}` (e.g., `1.208.0.dev20241212+7001`).
- `nightly` wheels use the version format `a{date}` (alpha) (e.g., `1.208.0a20241212`).

&gt; [!WARNING]
&gt;
&gt; We don&#039;t recommend using development wheels in production environments, such as live trading controlling real capital.

#### Installation commands

By default, pip installs the latest stable release. Adding the `--pre` flag ensures that pre-release versions, including development wheels, are considered.

To install the latest available pre-release (including development wheels):

    pip install -U nautilus_trader --pre --index-url=https://packages.nautechsystems.io/simple

To install a specific development wheel (e.g., `1.208.0a20241212` for December 12, 2024):

    pip install nautilus_trader==1.208.0a20241212 --index-url=https://packages.nautechsystems.io/simple

#### Available versions

You can view all available versions of `nautilus_trader` on the [package index](https://packages.nautechsystems.io/simple/nautilus-trader/index.html).

To programmatically fetch and list available versions:

    curl -s https://packages.nautechsystems.io/simple/nautilus-trader/index.html | grep -oP &#039;(?&lt;=&lt;a href=&quot;)[^&quot;]+(?=&quot;)&#039; | awk -F&#039;#&#039; &#039;{print $1}&#039; | sort

#### Branch updates

- `develop` branch wheels (`.dev`): Are built and published continuously with every merged commit.
- `nightly` branch wheels (`a`): Are built and published daily when `develop` branch is automatically merged at **14:00 UTC** (if there are changes).

#### Retention policies

- `develop` branch wheels (`.dev`): Only the most recent wheel build is retained.
- `nightly` branch wheels (`a`): Only the 10 most recent wheel builds are retained.

### From Source

It&#039;s possible to install from source using pip if you first install the build dependencies
as specified in t

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[iam-veeramalla/aws-devops-zero-to-hero]]></title>
            <link>https://github.com/iam-veeramalla/aws-devops-zero-to-hero</link>
            <guid>https://github.com/iam-veeramalla/aws-devops-zero-to-hero</guid>
            <pubDate>Mon, 07 Apr 2025 00:04:23 GMT</pubDate>
            <description><![CDATA[AWS zero to hero repo for devops engineers to learn AWS in 30 Days. This repo includes projects, presentations, interview questions and real time examples.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/iam-veeramalla/aws-devops-zero-to-hero">iam-veeramalla/aws-devops-zero-to-hero</a></h1>
            <p>AWS zero to hero repo for devops engineers to learn AWS in 30 Days. This repo includes projects, presentations, interview questions and real time examples.</p>
            <p>Language: Python</p>
            <p>Stars: 7,727</p>
            <p>Forks: 10,948</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># aws-devops-zero-to-hero

Complete YouTube playlist - https://www.youtube.com/playlist?list=PLdpzxOOAlwvLNOxX0RfndiYSt1Le9azze

AWS zero to hero repo for devops engineers to learn AWS in 30 Days. This repo includes projects, presentations, interview questions and real time examples. Each day&#039;s class will provide real-time knowledge on AWS services, allowing you to apply what you&#039;ve learned and gain practical skills in working with AWS in a DevOps context.

## Day 1: Introduction to AWS

You will learn what is private and public cloud. Why companies are moving to public cloud, what are the advantages of moving to cloud.

Also, you will be introduced to the basics of AWS, including the core services and their significance in DevOps practices. Finally learn how to set up an AWS account and navigate the AWS Management Console.

## Day 2: IAM (Identity and Access Management)

You will explore IAM, which is used for managing access to AWS resources. You&#039;ll learn how to create IAM users, groups, and roles, and how to apply permissions and security best practices to ensure proper access control.

## Day 3: EC2 Instances

You&#039;ll dive into EC2, which provides virtual servers in the cloud. You&#039;ll learn how to launch EC2 instances, connect to them using SSH, and understand key concepts such as instance types, security groups, and key pairs.

**Your First AWS Project**: Deploy a simple web application(such as jenkins) on the ec2 instance and access the application from outside AWS.

## Day 4: AWS Networking (VPC)

You&#039;ll explore AWS networking concepts, with a specific focus on VPC (Virtual Private Cloud). You&#039;ll learn how to create and configure VPCs, subnets, and route tables, enabling you to design and manage the network infrastructure for your applications.

## Day 5: AWS Security

This day emphasizes security best practices in AWS. You&#039;ll learn how to implement security measures such as security groups, network ACLs (Access Control Lists), and IAM policies to ensure the confidentiality, integrity, and availability of your AWS resources.

## Day 6: AWS Route 53

**Project:** Configure and manage a domain name using Route 53. You&#039;ll register a domain, set up DNS records, and explore advanced features such as health checks, routing policies, and DNS-based failover.

## Day 7: Secure VPC Setup with EC2 Instances

**Project:**

- Design and configure a VPC:
    Create a VPC with custom IP ranges.
    Set up public and private subnets.
    Configure route tables and associate subnets.

- Implement network security:
    Set up network access control lists (ACLs) to control inbound and outbound traffic.
    Configure security groups for EC2 instances to allow specific ports and protocols.

- Provision EC2 instances:
    Launch EC2 instances in both the public and private subnets.
    Configure security groups for the instances to allow necessary traffic.
    Create and assign IAM roles to the instances with appropriate permissions.

- Networking and routing:
    Set up an internet gateway to allow internet access for instances in the public subnet.
    Configure NAT gateway or NAT instance to enable outbound internet access for instances in the private subnet.
    Create appropriate route tables and associate them with the subnets.

- SSH key pair and access control:
    Generate an SSH key pair and securely store the private key.
    Configure the instances to allow SSH access only with the generated key pair.
    Implement IAM policies and roles to control access and permissions to AWS resources.

- Test and validate the setup:
    SSH into the EC2 instances using the private key and verify connectivity.
    Test network connectivity between instances in different subnets.
    Validate security group rules and network ACL settings.

By implementing this project, you&#039;ll gain hands-on experience in setting up a secure VPC with EC2 instances, implementing networking and routing, configuring security groups and IAM roles, and ensuring proper access control. This project will provide a practical understanding of how these AWS services work together to create a secure and scalable infrastructure for your applications.

## Day 8: AWS Interview Questions on EC2, IAM and VPC

## Day 9: Amazon S3

This day focuses on Amazon S3, a scalable object storage service. You&#039;ll learn how to create S3 buckets, upload and download objects, and organize data using S3 features like versioning, lifecycle policies, and access control.

## Day 10: AWS CLI

## Day 11: AWS CloudFormation

This day introduces Infrastructure as Code (IaC) using AWS CloudFormation. You&#039;ll learn how to create CloudFormation templates to automate the provisioning of resources, manage stacks, and ensure consistent infrastructure across deployments.

**Project:** You&#039;ll work on creating a CloudFormation template that provisions a fully configured application stack, including EC2 instances, networking components, and security groups.

## Day 12: AWS CodeCommit

This day focuses on AWS CodeCommit, a managed source control service. You&#039;ll learn how to set up a Git repository in CodeCommit, collaborate with team members, and manage version control of your codebase.

**Project:** You&#039;ll configure a CodeCommit repository for a team project, including setting up access control and collaboration workflows.

## Day 13: AWS CodePipeline

You&#039;ll dive into AWS CodePipeline, a fully managed continuous delivery service. You&#039;ll learn how to build end-to-end CI/CD pipelines by configuring source, build, and deployment stages, automating the entire software release process.

**Project:** You&#039;ll create a CI/CD pipeline using CodePipeline for an application deployment, including source code integration, build, and automatic deployment to a target environment.

## Day 14: AWS CodeBuild

This day focuses on AWS CodeBuild, a fully managed build service. You&#039;ll learn how to configure build projects in CodeBuild, define build specifications, and perform build and testing processes.

**Project:** You&#039;ll configure and run CodeBuild for a project, including defining build specifications and integrating with other AWS services.

## Day 15: AWS CodeDeploy

You&#039;ll explore AWS CodeDeploy, a service for automating application deployments to various compute environments. You&#039;ll learn how to create deployment groups, configure deployment strategies, and perform automatic rollbacks if necessary.

**Project:** You&#039;ll implement a Blue/Green deployment strategy for a sample application using CodeDeploy, ensuring zero-downtime deployments and easy rollback options.

## Day 16: AWS CloudWatch

This day focuses on monitoring AWS resources using AWS CloudWatch. You&#039;ll learn how to create alarms, set up notifications, and collect metrics to gain insights into the health and performance of your applications and infrastructure.

**Project:** You&#039;ll set up CloudWatch alarms for critical metrics of an application, define appropriate threshold conditions, and configure notification actions.

## Day 17: AWS Lambda

This day introduces serverless computing with AWS Lambda. You&#039;ll learn how to create and deploy serverless functions, trigger them based on events, and leverage Lambda to build scalable and event-driven architectures.

## Day 18: AWS CloudWatch Events and EventBridge

This day focuses on AWS CloudWatch Events and EventBridge, services for event-driven architectures. You&#039;ll learn how to create event rules, configure event targets, and build serverless event-driven workflows.

**Project:** You&#039;ll build a serverless event-driven workflow using CloudWatch Events and EventBridge, demonstrating the integration and automation of different AWS services based on events.

## Day 19: AWS CloudFront

 If you&#039;ve never heard of CDN or CloudFront before, don&#039;t worry, we will start from scratch and gradually build up your understanding. By the end, you&#039;ll be well-versed in these technologies.

**Project:** You&#039;ll configure a s3 bucket to host a static website and learn how to serve the requests to this website through CDN that is AWS Cloud Front.

## Day 20: AWS ECR (Elastic Container Registry)

You&#039;ll explore AWS ECR, a fully managed container registry for storing and managing container images. You&#039;ll learn how to push and pull Docker images to and from ECR, enabling seamless integration with ECS and other container services.

**Project:** You&#039;ll build a CI/CD pipeline that automatically builds, pushes, and deploys Docker images to ECR, ensuring streamlined container image management.

## Day 21: AWS ECS (Elastic Container Service)

This day focuses on AWS ECS, a fully managed container orchestration service. You&#039;ll learn how to run and manage containers using ECS, including creating task definitions, managing services, and scaling with auto-scaling capabilities.

**Project:** You&#039;ll deploy a multi-container application using ECS, configure auto-scaling policies, and ensure high availability and efficient resource utilization.

## Day 22: AWS EKS (Elastic Kubernetes Service)

This day introduces AWS EKS, a fully managed Kubernetes service. You&#039;ll learn how to deploy and manage Kubernetes clusters using EKS, including launching worker nodes, configuring networking, and deploying applications using Kubernetes manifests.

**Project:** You&#039;ll deploy a sample application on EKS using Kubernetes manifests, demonstrating the capabilities of running containerized applications on a managed Kubernetes service.

## Day 23: AWS Systems Manager

This day focuses on AWS Secrets Manager, a service for storing and managing secrets such as database credentials, API keys, and other sensitive information. You&#039;ll learn how to store, retrieve, and rotate secrets securely in your applications.

**Project:** You&#039;ll configure Secrets Manager to store and manage secrets, integrate secret retrieval in an application, and implement secret rotation policies.

## Day 24: Create Infrastructure using Terraform

This day focusses on creating infrastructure using Terraform with real time example.

**Project:** You&#039;ll create a VPC and deploy 2 applications in different availability zones. We will also create a load balancer to balance the load between the instances automatically.

## Day 25: AWS CloudTrail and Config

You&#039;ll explore AWS CloudTrail and AWS Config, which provide auditing and compliance capabilities. You&#039;ll learn how to track API calls using CloudTrail and ensure compliance with AWS Config rules.

**Project:** You&#039;ll configure CloudTrail to log API activities and set up AWS Config rules to enforce compliance policies for your AWS resources.

## Day 26: AWS Elastic Load Balancer

You&#039;ll explore AWS Elastic Load Balancer, a service for distributing incoming application traffic across multiple targets. You&#039;ll learn how to configure and manage load balancers to ensure high availability, fault tolerance, and scalability.

**Project:** You&#039;ll configure an Elastic Load Balancer for an application, define target groups, and observe the load balancing behavior across instances.

## Day 27: 500 AWS interview questions and answers topic wise for interviews.

This day focuses on learning how to migrate applications to AWS cloud. What are the most popular strategies and tools used to achieve the cloud migration.

## Day 28: AWS Cloud Migration Strategies and Tools

This day focuses on learning how to migrate applications to AWS cloud. What are the most popular strategies and tools used to achieve the cloud migration.

## Day 29: AWS Best Practices and Job Preparation

On the final day, you&#039;ll review best practices for AWS services, including security, cost optimization and performance.

## Day 30: AWS Project with RDS

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[yt-dlp/yt-dlp]]></title>
            <link>https://github.com/yt-dlp/yt-dlp</link>
            <guid>https://github.com/yt-dlp/yt-dlp</guid>
            <pubDate>Mon, 07 Apr 2025 00:04:22 GMT</pubDate>
            <description><![CDATA[A feature-rich command-line audio/video downloader]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/yt-dlp/yt-dlp">yt-dlp/yt-dlp</a></h1>
            <p>A feature-rich command-line audio/video downloader</p>
            <p>Language: Python</p>
            <p>Stars: 106,776</p>
            <p>Forks: 8,389</p>
            <p>Stars today: 121 stars today</p>
            <h2>README</h2><pre>&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt;
&lt;div align=&quot;center&quot;&gt;

[![YT-DLP](https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/banner.svg)](#readme)

[![Release version](https://img.shields.io/github/v/release/yt-dlp/yt-dlp?color=brightgreen&amp;label=Download&amp;style=for-the-badge)](#installation &quot;Installation&quot;)
[![PyPI](https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;labelColor=555555&amp;style=for-the-badge)](https://pypi.org/project/yt-dlp &quot;PyPI&quot;)
[![Donate](https://img.shields.io/badge/_-Donate-red.svg?logo=githubsponsors&amp;labelColor=555555&amp;style=for-the-badge)](Collaborators.md#collaborators &quot;Donate&quot;)
[![Discord](https://img.shields.io/discord/807245652072857610?color=blue&amp;labelColor=555555&amp;label=&amp;logo=discord&amp;style=for-the-badge)](https://discord.gg/H5MNcFW63r &quot;Discord&quot;)
[![Supported Sites](https://img.shields.io/badge/-Supported_Sites-brightgreen.svg?style=for-the-badge)](supportedsites.md &quot;Supported Sites&quot;)
[![License: Unlicense](https://img.shields.io/badge/-Unlicense-blue.svg?style=for-the-badge)](LICENSE &quot;License&quot;)
[![CI Status](https://img.shields.io/github/actions/workflow/status/yt-dlp/yt-dlp/core.yml?branch=master&amp;label=Tests&amp;style=for-the-badge)](https://github.com/yt-dlp/yt-dlp/actions &quot;CI Status&quot;)
[![Commits](https://img.shields.io/github/commit-activity/m/yt-dlp/yt-dlp?label=commits&amp;style=for-the-badge)](https://github.com/yt-dlp/yt-dlp/commits &quot;Commit History&quot;)
[![Last Commit](https://img.shields.io/github/last-commit/yt-dlp/yt-dlp/master?label=&amp;style=for-the-badge&amp;display_timestamp=committer)](https://github.com/yt-dlp/yt-dlp/pulse/monthly &quot;Last activity&quot;)

&lt;/div&gt;
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt;

yt-dlp is a feature-rich command-line audio/video downloader with support for [thousands of sites](supportedsites.md). The project is a fork of [youtube-dl](https://github.com/ytdl-org/youtube-dl) based on the now inactive [youtube-dlc](https://github.com/blackjack4494/yt-dlc).

&lt;!-- MANPAGE: MOVE &quot;USAGE AND OPTIONS&quot; SECTION HERE --&gt;

&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt;
* [INSTALLATION](#installation)
    * [Detailed instructions](https://github.com/yt-dlp/yt-dlp/wiki/Installation)
    * [Release Files](#release-files)
    * [Update](#update)
    * [Dependencies](#dependencies)
    * [Compile](#compile)
* [USAGE AND OPTIONS](#usage-and-options)
    * [General Options](#general-options)
    * [Network Options](#network-options)
    * [Geo-restriction](#geo-restriction)
    * [Video Selection](#video-selection)
    * [Download Options](#download-options)
    * [Filesystem Options](#filesystem-options)
    * [Thumbnail Options](#thumbnail-options)
    * [Internet Shortcut Options](#internet-shortcut-options)
    * [Verbosity and Simulation Options](#verbosity-and-simulation-options)
    * [Workarounds](#workarounds)
    * [Video Format Options](#video-format-options)
    * [Subtitle Options](#subtitle-options)
    * [Authentication Options](#authentication-options)
    * [Post-processing Options](#post-processing-options)
    * [SponsorBlock Options](#sponsorblock-options)
    * [Extractor Options](#extractor-options)
* [CONFIGURATION](#configuration)
    * [Configuration file encoding](#configuration-file-encoding)
    * [Authentication with netrc](#authentication-with-netrc)
    * [Notes about environment variables](#notes-about-environment-variables)
* [OUTPUT TEMPLATE](#output-template)
    * [Output template examples](#output-template-examples)
* [FORMAT SELECTION](#format-selection)
    * [Filtering Formats](#filtering-formats)
    * [Sorting Formats](#sorting-formats)
    * [Format Selection examples](#format-selection-examples)
* [MODIFYING METADATA](#modifying-metadata)
    * [Modifying metadata examples](#modifying-metadata-examples)
* [EXTRACTOR ARGUMENTS](#extractor-arguments)
* [PLUGINS](#plugins)
    * [Installing Plugins](#installing-plugins)
    * [Developing Plugins](#developing-plugins)
* [EMBEDDING YT-DLP](#embedding-yt-dlp)
    * [Embedding examples](#embedding-examples)
* [CHANGES FROM YOUTUBE-DL](#changes-from-youtube-dl)
    * [New features](#new-features)
    * [Differences in default behavior](#differences-in-default-behavior)
    * [Deprecated options](#deprecated-options)
* [CONTRIBUTING](CONTRIBUTING.md#contributing-to-yt-dlp)
    * [Opening an Issue](CONTRIBUTING.md#opening-an-issue)
    * [Developer Instructions](CONTRIBUTING.md#developer-instructions)
* [WIKI](https://github.com/yt-dlp/yt-dlp/wiki)
    * [FAQ](https://github.com/yt-dlp/yt-dlp/wiki/FAQ)
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt;


# INSTALLATION

&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt;
[![Windows](https://img.shields.io/badge/-Windows_x64-blue.svg?style=for-the-badge&amp;logo=windows)](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe)
[![Unix](https://img.shields.io/badge/-Linux/BSD-red.svg?style=for-the-badge&amp;logo=linux)](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp)
[![MacOS](https://img.shields.io/badge/-MacOS-lightblue.svg?style=for-the-badge&amp;logo=apple)](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos)
[![PyPI](https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;labelColor=555555&amp;style=for-the-badge)](https://pypi.org/project/yt-dlp)
[![Source Tarball](https://img.shields.io/badge/-Source_tar-green.svg?style=for-the-badge)](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz)
[![Other variants](https://img.shields.io/badge/-Other-grey.svg?style=for-the-badge)](#release-files)
[![All versions](https://img.shields.io/badge/-All_Versions-lightgrey.svg?style=for-the-badge)](https://github.com/yt-dlp/yt-dlp/releases)
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt;

You can install yt-dlp using [the binaries](#release-files), [pip](https://pypi.org/project/yt-dlp) or one using a third-party package manager. See [the wiki](https://github.com/yt-dlp/yt-dlp/wiki/Installation) for detailed instructions


&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt;
## RELEASE FILES

#### Recommended

File|Description
:---|:---
[yt-dlp](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp)|Platform-independent [zipimport](https://docs.python.org/3/library/zipimport.html) binary. Needs Python (recommended for **Linux/BSD**)
[yt-dlp.exe](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe)|Windows (Win8+) standalone x64 binary (recommended for **Windows**)
[yt-dlp_macos](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos)|Universal MacOS (10.15+) standalone executable (recommended for **MacOS**)

#### Alternatives

File|Description
:---|:---
[yt-dlp_x86.exe](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_x86.exe)|Windows (Win8+) standalone x86 (32-bit) binary
[yt-dlp_linux](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux)|Linux standalone x64 binary
[yt-dlp_linux_armv7l](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_armv7l)|Linux standalone armv7l (32-bit) binary
[yt-dlp_linux_aarch64](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_aarch64)|Linux standalone aarch64 (64-bit) binary
[yt-dlp_win.zip](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win.zip)|Unpackaged Windows executable (no auto-update)
[yt-dlp_macos.zip](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos.zip)|Unpackaged MacOS (10.15+) executable (no auto-update)
[yt-dlp_macos_legacy](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos_legacy)|MacOS (10.9+) standalone x64 executable

#### Misc

File|Description
:---|:---
[yt-dlp.tar.gz](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz)|Source tarball
[SHA2-512SUMS](https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS)|GNU-style SHA512 sums
[SHA2-512SUMS.sig](https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS.sig)|GPG signature file for SHA512 sums
[SHA2-256SUMS](https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS)|GNU-style SHA256 sums
[SHA2-256SUMS.sig](https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS.sig)|GPG signature file for SHA256 sums

The public key that can be used to verify the GPG signatures is [available here](https://github.com/yt-dlp/yt-dlp/blob/master/public.key)
Example usage:
```
curl -L https://github.com/yt-dlp/yt-dlp/raw/master/public.key | gpg --import
gpg --verify SHA2-256SUMS.sig SHA2-256SUMS
gpg --verify SHA2-512SUMS.sig SHA2-512SUMS
```
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt;

**Note**: The manpages, shell completion (autocomplete) files etc. are available inside the [source tarball](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz)


## UPDATE
You can use `yt-dlp -U` to update if you are using the [release binaries](#release-files)

If you [installed with pip](https://github.com/yt-dlp/yt-dlp/wiki/Installation#with-pip), simply re-run the same command that was used to install the program

For other third-party package managers, see [the wiki](https://github.com/yt-dlp/yt-dlp/wiki/Installation#third-party-package-managers) or refer to their documentation

&lt;a id=&quot;update-channels&quot;&gt;&lt;/a&gt;

There are currently three release channels for binaries: `stable`, `nightly` and `master`.

* `stable` is the default channel, and many of its changes have been tested by users of the `nightly` and `master` channels.
* The `nightly` channel has releases scheduled to build every day around midnight UTC, for a snapshot of the project&#039;s new patches and changes. This is the **recommended channel for regular users** of yt-dlp. The `nightly` releases are available from [yt-dlp/yt-dlp-nightly-builds](https://github.com/yt-dlp/yt-dlp-nightly-builds/releases) or as development releases of the `yt-dlp` PyPI package (which can be installed with pip&#039;s `--pre` flag).
* The `master` channel features releases that are built after each push to the master branch, and these will have the very latest fixes and additions, but may also be more prone to regressions. They are available from [yt-dlp/yt-dlp-master-builds](https://github.com/yt-dlp/yt-dlp-master-builds/releases).

When using `--update`/`-U`, a release binary will only update to its current channel.
`--update-to CHANNEL` can be used to switch to a different channel when a newer version is available. `--update-to [CHANNEL@]TAG` can also be used to upgrade or downgrade to specific tags from a channel.

You may also use `--update-to &lt;repository&gt;` (`&lt;owner&gt;/&lt;repository&gt;`) to update to a channel on a completely different repository. Be careful with what repository you are updating to though, there is no verification done for binaries from different repositories.

Example usage:

* `yt-dlp --update-to master` switch to the `master` channel and update to its latest release
* `yt-dlp --update-to stable@2023.07.06` upgrade/downgrade to release to `stable` channel tag `2023.07.06`
* `yt-dlp --update-to 2023.10.07` upgrade/downgrade to tag `2023.10.07` if it exists on the current channel
* `yt-dlp --update-to example/yt-dlp@2023.09.24` upgrade/downgrade to the release from the `example/yt-dlp` repository, tag `2023.09.24`

**Important**: Any user experiencing an issue with the `stable` release should install or update to the `nightly` release before submitting a bug report:
```
# To update to nightly from stable executable/binary:
yt-dlp --update-to nightly

# To install nightly with pip:
python3 -m pip install -U --pre &quot;yt-dlp[default]&quot;
```

## DEPENDENCIES
Python versions 3.9+ (CPython) and 3.10+ (PyPy) are supported. Other versions and implementations may or may not work correctly.

&lt;!-- Python 3.5+ uses VC++14 and it is already embedded in the binary created
&lt;!x-- https://www.microsoft.com/en-us/download/details.aspx?id=26999 --x&gt;
On Windows, [Microsoft Visual C++ 2010 SP1 Redistributable Package (x86)](https://download.microsoft.com/download/1/6/5/165255E7-1014-4D0A-B094-B6A430A6BFFC/vcredist_x86.exe) is also necessary to run yt-dlp. You probably already have this, but if the executable throws an error due to missing `MSVCR100.dll` you need to install it manually.
--&gt;

While all the other dependencies are optional, `ffmpeg` and `ffprobe` are highly recommended

### Strongly recommended

* [**ffmpeg** and **ffprobe**](https://www.ffmpeg.org) - Required for [merging separate video and audio files](#format-selection), as well as for various [post-processing](#post-processing-options) tasks. License [depends on the build](https://www.ffmpeg.org/legal.html)

    There are bugs in ffmpeg that cause various issues when used alongside yt-dlp. Since ffmpeg is such an important dependency, we provide [custom builds](https://github.com/yt-dlp/FFmpeg-Builds#ffmpeg-static-auto-builds) with patches for some of these issues at [yt-dlp/FFmpeg-Builds](https://github.com/yt-dlp/FFmpeg-Builds). See [the readme](https://github.com/yt-dlp/FFmpeg-Builds#patches-applied) for details on the specific issues solved by these builds

    **Important**: What you need is ffmpeg *binary*, **NOT** [the Python package of the same name](https://pypi.org/project/ffmpeg)

### Networking
* [**certifi**](https://github.com/certifi/python-certifi)\* - Provides Mozilla&#039;s root certificate bundle. Licensed under [MPLv2](https://github.com/certifi/python-certifi/blob/master/LICENSE)
* [**brotli**](https://github.com/google/brotli)\* or [**brotlicffi**](https://github.com/python-hyper/brotlicffi) - [Brotli](https://en.wikipedia.org/wiki/Brotli) content encoding support. Both licensed under MIT &lt;sup&gt;[1](https://github.com/google/brotli/blob/master/LICENSE) [2](https://github.com/python-hyper/brotlicffi/blob/master/LICENSE) &lt;/sup&gt;
* [**websockets**](https://github.com/aaugustin/websockets)\* - For downloading over websocket. Licensed under [BSD-3-Clause](https://github.com/aaugustin/websockets/blob/main/LICENSE)
* [**requests**](https://github.com/psf/requests)\* - HTTP library. For HTTPS proxy and persistent connections support. Licensed under [Apache-2.0](https://github.com/psf/requests/blob/main/LICENSE)

#### Impersonation

The following provide support for impersonating browser requests. This may be required for some sites that employ TLS fingerprinting.

* [**curl_cffi**](https://github.com/lexiforest/curl_cffi) (recommended) - Python binding for [curl-impersonate](https://github.com/lexiforest/curl-impersonate). Provides impersonation targets for Chrome, Edge and Safari. Licensed under [MIT](https://github.com/lexiforest/curl_cffi/blob/main/LICENSE)
  * Can be installed with the `curl-cffi` group, e.g. `pip install &quot;yt-dlp[default,curl-cffi]&quot;`
  * Currently included in `yt-dlp.exe`, `yt-dlp_linux` and `yt-dlp_macos` builds


### Metadata

* [**mutagen**](https://github.com/quodlibet/mutagen)\* - For `--embed-thumbnail` in certain formats. Licensed under [GPLv2+](https://github.com/quodlibet/mutagen/blob/master/COPYING)
* [**AtomicParsley**](https://github.com/wez/atomicparsley) - For `--embed-thumbnail` in `mp4`/`m4a` files when `mutagen`/`ffmpeg` cannot. Licensed under [GPLv2+](https://github.com/wez/atomicparsley/blob/master/COPYING)
* [**xattr**](https://github.com/xattr/xattr), [**pyxattr**](https://github.com/iustin/pyxattr) or [**setfattr**](http://savannah.nongnu.org/projects/attr) - For writing xattr metadata (`--xattr`) on **Mac** and **BSD**. Licensed under [MIT](https://github.com/xattr/xattr/blob/master/LICENSE.txt), [LGPL2.1](https://github.com/iustin/pyxattr/blob/master/COPYING) and [GPLv2+](http://git.savannah.nongnu.org/cgit/attr.git/tree/doc/COPYING) respectively

### Misc

* [**pycryptodomex**](https://github.com/Legrandin/pycryptodome)\* - For decrypting AES-128 HLS streams and various other data. Licensed under [BSD-2-Clause](https://github.com/Legrandin/pycryptodome/blob/master/LICENSE.rst)
* [**phantomjs**](https://github.com/ariya/phantomjs) - Used in extractors where javascript needs to be run. Licensed under [BSD-3-Clause](https://github.com/ariya/phantomjs/blob/master/LICENSE.BSD)
* [**secretstorage**](https://github.com/mitya57/secretstorage)\* - For `--cookies-from-browser` to access the **Gnome** keyring while decrypting cookies of **Chromium**-based browsers on **Linux**. Licensed under [BSD-3-Clause](https://github.com/mitya57/secretstorage/blob/master/LICENSE)
* Any external downloader that you want to use with `--downloader`

### Deprecated

* [**avconv** and **avprobe**](https://www.libav.org) - Now **deprecated** alternative to ffmpeg. License [depends on the build](https://libav.org/legal)
* [**sponskrub**](https://github.com/faissaloo/SponSkrub) - For using the now **deprecated** [sponskrub options](#sponskrub-options). Licensed under [GPLv3+](https://github.com/faissaloo/SponSkrub/blob/master/LICENCE.md)
* [**rtmpdump**](http://rtmpdump.mplayerhq.hu) - For downloading `rtmp` streams. ffmpeg can be used instead with `--downloader ffmpeg`. Licensed under [GPLv2+](http://rtmpdump.mplayerhq.hu)
* [**mplayer**](http://mplayerhq.hu/design7/info.html) or [**mpv**](https://mpv.io) - For downloading `rstp`/`mms` streams. ffmpeg can be used instead with `--downloader ffmpeg`. Licensed under [GPLv2+](https://github.com/mpv-player/mpv/blob/master/Copyright)

To use or redistribute the dependencies, you must agree to their respective licensing terms.

The standalone release binaries are built with the Python interpreter and the packages marked with **\*** included.

If you do not have the necessary dependencies for a task you are attempting, yt-dlp will warn you. All the currently available dependencies are visible at the top of the `--verbose` output


## COMPILE

### Standalone PyInstaller Builds
To build the standalone executable, you must have Python and `pyinstaller` (plus any of yt-dlp&#039;s [optional dependencies](#dependencies) if needed). The executable will be built for the same CPU architecture as the Python used.

You can run the following commands:

```
python3 devscripts/install_deps.py --include pyinstaller
python3 devscripts/make_lazy_extractors.py
python3 -m bundle.pyinstaller
```

On some systems, you may need to use `py` or `python` instead of `python3`.

`python -m bundle.pyinstaller` accepts any arguments that can be passed to `pyinstaller`, such as `--onefile/-F` or `--onedir/-D`, which is further [documented here](https://pyinstaller.org/en/stable/usage.html#what-to-generate).

**Note**: Pyinstaller versions below 4.4 [do not support](https://github.com/pyinstaller/pyinstaller#requirements-and-tested-platforms) Python installed from the Windows store without using a virtual environment.

**Important**: Running `pyinstaller` directly **instead of** using `python -m bundle.pyinstaller` is **not** officially supported. This may or may not work correctly.

### Platform-independent Binary (UNIX)
You will need the build tools `python` (3.9+), `zip`, `make` (GNU), `pandoc`\* and `pytest`\*.

After installing these, simply run `make`.

You can also run `make yt-dlp` instead to compile only the binary without updating any of the additional files. (The build tools marked with **\*** are not needed for this)

### Related scripts

* **`devscripts/install_deps.py`** - Install dependencies for yt-dlp.
* **`devscripts/update-version.py`** - Update the version number based on the current date.
* **`devscripts/set-variant.py`** - Set the build variant of the executable.
* **`devscripts/make_changelog.py`** - Create a markdown changelog using short commit messages and update `CONTRIBUTORS` file.
* **`devscripts/make_lazy_extractors.py`** - Create lazy extractors. Running this before building the binaries (any variant) will improve their startup performance. Set the environment variable `YTDLP_NO_LAZY_EXTRACTORS` to something nonempty to forcefully disable lazy extractor loading.

Note: See their `--help` for more info.

### Forking the project
If you fork the project on GitHub, you can run your fork&#039;s [build workflow](.github/workflows/build.yml) to automatically build the selected version(s) as ar

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[camel-ai/oasis]]></title>
            <link>https://github.com/camel-ai/oasis</link>
            <guid>https://github.com/camel-ai/oasis</guid>
            <pubDate>Mon, 07 Apr 2025 00:04:21 GMT</pubDate>
            <description><![CDATA[🏝️ OASIS: Open Agent Social Interaction Simulations with One Million Agents. https://oasis.camel-ai.org]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/camel-ai/oasis">camel-ai/oasis</a></h1>
            <p>🏝️ OASIS: Open Agent Social Interaction Simulations with One Million Agents. https://oasis.camel-ai.org</p>
            <p>Language: Python</p>
            <p>Stars: 1,216</p>
            <p>Forks: 118</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.camel-ai.org/&quot;&gt;
    &lt;img src=&quot;assets/banner.png&quot; alt=banner&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;/br&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;h1&gt; OASIS: Open Agent Social Interaction Simulations with One Million Agents
&lt;/h1&gt;

[![Discord][discord-image]][discord-url]
[![X][x-image]][x-url]
[![Reddit][reddit-image]][reddit-url]
[![Wechat][wechat-image]][wechat-url]
[![Wechat][oasis-image]][oasis-url]
[![Hugging Face][huggingface-image]][huggingface-url]
[![Star][star-image]][star-url]
[![Package License][package-license-image]][package-license-url]

&lt;h4 align=&quot;center&quot;&gt;

[Community](https://github.com/camel-ai/camel#community) |
[Paper](https://arxiv.org/abs/2411.11581) |
[Examples](https://github.com/camel-ai/oasis/tree/main/scripts) |
[Dataset](https://huggingface.co/datasets/oasis-agent/oasis-dataset) |
[Citation](https://github.com/camel-ai/oasis#-citation) |
[Contributing](https://github.com/camel-ai/oasis#-contributing-to-oasis) |
[CAMEL-AI](https://www.camel-ai.org/)

&lt;/h4&gt;

&lt;/div&gt;

&lt;br&gt;

&lt;p align=&quot;left&quot;&gt;
  &lt;img src=&#039;assets/intro.png&#039;&gt;

🏝️ OASIS is a scalable, open-source social media simulator that integrates large language models with rule-based agents to realistically mimic the behavior of up to one million users on platforms like Twitter and Reddit. It&#039;s designed to facilitate the study of complex social phenomena such as information spread, group polarization, and herd behavior, offering a versatile tool for exploring diverse social dynamics and user interactions in digital environments.

&lt;/p&gt;

&lt;br&gt;

&lt;div align=&quot;center&quot;&gt;
🌟 Star OASIS on GitHub and be instantly notified of new releases.
&lt;/div&gt;

&lt;br&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;assets/star.gif&quot; alt=&quot;Star&quot; width=&quot;196&quot; height=&quot;52&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;br&gt;

## ✨ Key Features

### 📈 Scalability

OASIS supports simulations of up to ***one million agents***, enabling studies of social media dynamics at a scale comparable to real-world platforms.

### 📲 Dynamic Environments

Adapts to real-time changes in social networks and content, mirroring the fluid dynamics of platforms like **Twitter** and **Reddit** for authentic simulation experiences.

### 👍🏼 Diverse Action Spaces

Agents can perform **23 actions**, such as following, commenting, and reposting, allowing for rich, multi-faceted interactions.

### 🔥 Integrated Recommendation Systems

Features **interest-based** and **hot-score-based recommendation algorithms**, simulating how users discover content and interact within social media platforms.

&lt;br&gt;

## 📺 Demo Video

### Introducing OASIS: Open Agent Social Interaction Simulations with One Million Agents

https://github.com/user-attachments/assets/3bd2553c-d25d-4d8c-a739-1af51354b15a

&lt;br&gt;

For more showcaes:

- Can 1,000,000 AI agents simulate social media?
  [→Watch demo](https://www.youtube.com/watch?v=lprGHqkApus&amp;t=2s)

&lt;br&gt;

## 🎯 Usecase

&lt;div align=&quot;left&quot;&gt;
    &lt;img src=&quot;assets/research_simulation.png&quot; alt=usecase1&gt;
    &lt;img src=&quot;assets/interaction.png&quot; alt=usecase2&gt;
   &lt;a href=&quot;http://www.matrix.eigent.ai&quot;&gt;
    &lt;img src=&quot;assets/content_creation.png&quot; alt=usecase3&gt;
   &lt;/a&gt;
    &lt;img src=&quot;assets/prediction.png&quot; alt=usecase4&gt;
&lt;/div&gt;

## ⚙️ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/camel-ai/oasis.git

cd oasis
```

### 2. Create and Activate a Virtual Environment

Please choose one of the following methods to set up your environment. You only need to follow one of these methods.

- Option 1: Using Conda (Linux &amp; macOS &amp; windows)

```bash
conda create --name oasis python=3.10
conda activate oasis
```

- Option 2: Using venv (Linux &amp; macOS)

```bash
python -m venv oasis-venv
source oasis-venv/bin/activate
```

- Option 3: Using venv (Windows)

```bash
python -m venv oasis-venv
oasis-venv\Scripts\activate
```

### 3. Install Necessary Packages

```bash
pip install --upgrade pip setuptools

pip install -e .  # This will install dependencies as specified in pyproject.toml
```

&lt;br&gt;

&gt; \[!TIP\]
&gt; For more detailed instructions and additional configuration options, check out the [installation section](tutorials/installation.md).

### More Tutorials

To discover how to create profiles for large-scale users, as well as how to visualize and analyze social simulation data once your experiment concludes, please refer to [More Tutorials](tutorials/tutorial.md) for detailed guidance.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/tutorial.png&quot; alt=&quot;Tutorial Overview&quot;&gt;
&lt;/div&gt;

## 📢 News

### Upcoming Features &amp; Contributions

&gt; We welcome community contributions! Join us in building these exciting features.

- [OASIS Refactor: First Release on PyPI](https://github.com/camel-ai/oasis/issues/57)
- [Write More Documents for OASIS](https://github.com/camel-ai/oasis/issues/60)

&lt;!-- - Public release of our dataset on Hugging Face (November 05, 2024) --&gt;

### Latest Updates

- Support OPENAI Embedding model for Twhin-Bert Recommendation System. - 📆 March 25, 2025
- Updated social media links and QR codes in the README! Join OASIS &amp; CAMEL on WeChat, X, Reddit, and Discord. - 📆 March 24, 2025
- Add multi-threading support to speed up LLM inference by 13x - 📆 March 4, 2025
- Slightly refactoring the database to add Quote Action and modify Repost Action - 📆 January 13, 2025
- Added the demo video and oasis&#039;s star history in the README - 📆 January 5, 2025
- Introduced an Electronic Mall on the Reddit platform - 📆 December 5, 2024
- OASIS initially released on arXiv - 📆 November 19, 2024
- OASIS GitHub repository initially launched - 📆 November 19, 2024

## 🥂 Contributing to OASIS🏝️

&gt; We greatly appreciate your interest in contributing to our open-source initiative. To ensure a smooth collaboration and the success of contributions, we adhere to a set of contributing guidelines similar to those established by CAMEL. For a comprehensive understanding of the steps involved in contributing to our project, please refer to the CAMEL [contributing guidelines](https://github.com/camel-ai/camel/blob/master/CONTRIBUTING.md). 🤝🚀
&gt;
&gt; An essential part of contributing involves not only submitting new features with accompanying tests (and, ideally, examples) but also ensuring that these contributions pass our automated pytest suite. This approach helps us maintain the project&#039;s quality and reliability by verifying compatibility and functionality.

## 📬 Community &amp; Contact

If you&#039;re keen on exploring new research opportunities or discoveries with our platform and wish to dive deeper or suggest new features, we&#039;re here to talk. Feel free to get in touch for more details at camel.ai.team@gmail.com.

&lt;br&gt;

- Join us ([*Discord*](https://discord.camel-ai.org/) or [*WeChat*](https://ghli.org/camel/wechat.png)) in pushing the boundaries of finding the scaling laws of agents.

- Join WechatGroup for further discussions!

&lt;div align=&quot;&quot;&gt;
  &lt;img src=&quot;assets/wechatgroup.png&quot; alt=&quot;WeChat Group QR Code&quot; width=&quot;600&quot;&gt;
&lt;/div&gt;

## 🌟 Star History

[![Star History Chart](https://api.star-history.com/svg?repos=camel-ai/oasis&amp;type=Date)](https://star-history.com/#camel-ai/oasis&amp;Date)

## 🔗 Citation

```
@misc{yang2024oasisopenagentsocial,
      title={OASIS: Open Agent Social Interaction Simulations with One Million Agents},
      author={Ziyi Yang and Zaibin Zhang and Zirui Zheng and Yuxian Jiang and Ziyue Gan and Zhiyu Wang and Zijian Ling and Jinsong Chen and Martz Ma and Bowen Dong and Prateek Gupta and Shuyue Hu and Zhenfei Yin and Guohao Li and Xu Jia and Lijun Wang and Bernard Ghanem and Huchuan Lu and Chaochao Lu and Wanli Ouyang and Yu Qiao and Philip Torr and Jing Shao},
      year={2024},
      eprint={2411.11581},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.11581},
}
```

## 🙌 Acknowledgment

We would like to thank Douglas for designing the logo of our project.

## 🖺 License

The source code is licensed under Apache 2.0.

[discord-image]: https://img.shields.io/discord/1082486657678311454?logo=discord&amp;labelColor=%20%235462eb&amp;logoColor=%20%23f5f5f5&amp;color=%20%235462eb
[discord-url]: https://discord.camel-ai.org/
[huggingface-image]: https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-CAMEL--AI-ffc107?color=ffc107&amp;logoColor=white
[huggingface-url]: https://huggingface.co/camel-ai
[oasis-image]: https://img.shields.io/badge/WeChat-OASISProject-brightgreen?logo=wechat&amp;logoColor=white
[oasis-url]: ./assets/wechatgroup.png
[package-license-image]: https://img.shields.io/badge/License-Apache_2.0-blue.svg
[package-license-url]: https://github.com/camel-ai/oasis/blob/main/licenses/LICENSE
[reddit-image]: https://img.shields.io/reddit/subreddit-subscribers/CamelAI?style=plastic&amp;logo=reddit&amp;label=r%2FCAMEL&amp;labelColor=white
[reddit-url]: https://www.reddit.com/r/CamelAI/
[star-image]: https://img.shields.io/github/stars/camel-ai/oasis?label=stars&amp;logo=github&amp;color=brightgreen
[star-url]: https://github.com/camel-ai/oasis/stargazers
[wechat-image]: https://img.shields.io/badge/WeChat-CamelAIOrg-brightgreen?logo=wechat&amp;logoColor=white
[wechat-url]: ./assets/wechat.JPGwechat.jpg
[x-image]: https://img.shields.io/twitter/follow/CamelAIOrg?style=social
[x-url]: https://x.com/CamelAIOrg
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[browser-use/web-ui]]></title>
            <link>https://github.com/browser-use/web-ui</link>
            <guid>https://github.com/browser-use/web-ui</guid>
            <pubDate>Mon, 07 Apr 2025 00:04:20 GMT</pubDate>
            <description><![CDATA[Run AI Agent in your browser.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/browser-use/web-ui">browser-use/web-ui</a></h1>
            <p>Run AI Agent in your browser.</p>
            <p>Language: Python</p>
            <p>Stars: 11,304</p>
            <p>Forks: 1,827</p>
            <p>Stars today: 183 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;./assets/web-ui.png&quot; alt=&quot;Browser Use Web UI&quot; width=&quot;full&quot;/&gt;

&lt;br/&gt;

[![GitHub stars](https://img.shields.io/github/stars/browser-use/web-ui?style=social)](https://github.com/browser-use/web-ui/stargazers)
[![Discord](https://img.shields.io/discord/1303749220842340412?color=7289DA&amp;label=Discord&amp;logo=discord&amp;logoColor=white)](https://link.browser-use.com/discord)
[![Documentation](https://img.shields.io/badge/Documentation-📕-blue)](https://docs.browser-use.com)
[![WarmShao](https://img.shields.io/twitter/follow/warmshao?style=social)](https://x.com/warmshao)

This project builds upon the foundation of the [browser-use](https://github.com/browser-use/browser-use), which is designed to make websites accessible for AI agents.

We would like to officially thank [WarmShao](https://github.com/warmshao) for his contribution to this project.

**WebUI:** is built on Gradio and supports most of `browser-use` functionalities. This UI is designed to be user-friendly and enables easy interaction with the browser agent.

**Expanded LLM Support:** We&#039;ve integrated support for various Large Language Models (LLMs), including: Google, OpenAI, Azure OpenAI, Anthropic, DeepSeek, Ollama etc. And we plan to add support for even more models in the future.

**Custom Browser Support:** You can use your own browser with our tool, eliminating the need to re-login to sites or deal with other authentication challenges. This feature also supports high-definition screen recording.

**Persistent Browser Sessions:** You can choose to keep the browser window open between AI tasks, allowing you to see the complete history and state of AI interactions.

&lt;video src=&quot;https://github.com/user-attachments/assets/56bc7080-f2e3-4367-af22-6bf2245ff6cb&quot; controls=&quot;controls&quot;&gt;Your browser does not support playing this video!&lt;/video&gt;

## Installation Guide

### Prerequisites
- Python 3.11 or higher
- Git (for cloning the repository)

### Option 1: Local Installation

Read the [quickstart guide](https://docs.browser-use.com/quickstart#prepare-the-environment) or follow the steps below to get started.

#### Step 1: Clone the Repository
```bash
git clone https://github.com/browser-use/web-ui.git
cd web-ui
```

#### Step 2: Set Up Python Environment
We recommend using [uv](https://docs.astral.sh/uv/) for managing the Python environment.

Using uv (recommended):
```bash
uv venv --python 3.11
```

Activate the virtual environment:
- Windows (Command Prompt):
```cmd
.venv\Scripts\activate
```
- Windows (PowerShell):
```powershell
.\.venv\Scripts\Activate.ps1
```
- macOS/Linux:
```bash
source .venv/bin/activate
```

#### Step 3: Install Dependencies
Install Python packages:
```bash
uv pip install -r requirements.txt
```

Install Browsers in Playwright:
You can install specific browsers by running:
```bash
playwright install --with-deps chromium
```

To install all browsers:
```bash
playwright install
```

#### Step 4: Configure Environment
1. Create a copy of the example environment file:
- Windows (Command Prompt):
```bash
copy .env.example .env
```
- macOS/Linux/Windows (PowerShell):
```bash
cp .env.example .env
```
2. Open `.env` in your preferred text editor and add your API keys and other settings

### Option 2: Docker Installation

#### Prerequisites
- Docker and Docker Compose installed
  - [Docker Desktop](https://www.docker.com/products/docker-desktop/) (For Windows/macOS)
  - [Docker Engine](https://docs.docker.com/engine/install/) and [Docker Compose](https://docs.docker.com/compose/install/) (For Linux)

#### Installation Steps
1. Clone the repository:
```bash
git clone https://github.com/browser-use/web-ui.git
cd web-ui
```

2. Create and configure environment file:
- Windows (Command Prompt):
```bash
copy .env.example .env
```
- macOS/Linux/Windows (PowerShell):
```bash
cp .env.example .env
```
Edit `.env` with your preferred text editor and add your API keys

3. Run with Docker:
```bash
# Build and start the container with default settings (browser closes after AI tasks)
docker compose up --build
```
```bash
# Or run with persistent browser (browser stays open between AI tasks)
CHROME_PERSISTENT_SESSION=true docker compose up --build
```


4. Access the Application:
- Web Interface: Open `http://localhost:7788` in your browser
- VNC Viewer (for watching browser interactions): Open `http://localhost:6080/vnc.html`
  - Default VNC password: &quot;youvncpassword&quot;
  - Can be changed by setting `VNC_PASSWORD` in your `.env` file

## Usage

### Local Setup
1.  **Run the WebUI:**
    After completing the installation steps above, start the application:
    ```bash
    python webui.py --ip 127.0.0.1 --port 7788
    ```
2. WebUI options:
   - `--ip`: The IP address to bind the WebUI to. Default is `127.0.0.1`.
   - `--port`: The port to bind the WebUI to. Default is `7788`.
   - `--theme`: The theme for the user interface. Default is `Ocean`.
     - **Default**: The standard theme with a balanced design.
     - **Soft**: A gentle, muted color scheme for a relaxed viewing experience.
     - **Monochrome**: A grayscale theme with minimal color for simplicity and focus.
     - **Glass**: A sleek, semi-transparent design for a modern appearance.
     - **Origin**: A classic, retro-inspired theme for a nostalgic feel.
     - **Citrus**: A vibrant, citrus-inspired palette with bright and fresh colors.
     - **Ocean** (default): A blue, ocean-inspired theme providing a calming effect.
   - `--dark-mode`: Enables dark mode for the user interface.
3.  **Access the WebUI:** Open your web browser and navigate to `http://127.0.0.1:7788`.
4.  **Using Your Own Browser(Optional):**
    - Set `CHROME_PATH` to the executable path of your browser and `CHROME_USER_DATA` to the user data directory of your browser. Leave `CHROME_USER_DATA` empty if you want to use local user data.
      - Windows
        ```env
         CHROME_PATH=&quot;C:\Program Files\Google\Chrome\Application\chrome.exe&quot;
         CHROME_USER_DATA=&quot;C:\Users\YourUsername\AppData\Local\Google\Chrome\User Data&quot;
        ```
        &gt; Note: Replace `YourUsername` with your actual Windows username for Windows systems.
      - Mac
        ```env
         CHROME_PATH=&quot;/Applications/Google Chrome.app/Contents/MacOS/Google Chrome&quot;
         CHROME_USER_DATA=&quot;/Users/YourUsername/Library/Application Support/Google/Chrome&quot;
        ```
    - Close all Chrome windows
    - Open the WebUI in a non-Chrome browser, such as Firefox or Edge. This is important because the persistent browser context will use the Chrome data when running the agent.
    - Check the &quot;Use Own Browser&quot; option within the Browser Settings.
5. **Keep Browser Open(Optional):**
    - Set `CHROME_PERSISTENT_SESSION=true` in the `.env` file.

### Docker Setup
1. **Environment Variables:**
   - All configuration is done through the `.env` file
   - Available environment variables:
     ```
     # LLM API Keys
     OPENAI_API_KEY=your_key_here
     ANTHROPIC_API_KEY=your_key_here
     GOOGLE_API_KEY=your_key_here

     # Browser Settings
     CHROME_PERSISTENT_SESSION=true   # Set to true to keep browser open between AI tasks
     RESOLUTION=1920x1080x24         # Custom resolution format: WIDTHxHEIGHTxDEPTH
     RESOLUTION_WIDTH=1920           # Custom width in pixels
     RESOLUTION_HEIGHT=1080          # Custom height in pixels

     # VNC Settings
     VNC_PASSWORD=your_vnc_password  # Optional, defaults to &quot;vncpassword&quot;
     ```

2. **Platform Support:**
   - Supports both AMD64 and ARM64 architectures
   - For ARM64 systems (e.g., Apple Silicon Macs), the container will automatically use the appropriate image

3. **Browser Persistence Modes:**
   - **Default Mode (CHROME_PERSISTENT_SESSION=false):**
     - Browser opens and closes with each AI task
     - Clean state for each interaction
     - Lower resource usage

   - **Persistent Mode (CHROME_PERSISTENT_SESSION=true):**
     - Browser stays open between AI tasks
     - Maintains history and state
     - Allows viewing previous AI interactions
     - Set in `.env` file or via environment variable when starting container

4. **Viewing Browser Interactions:**
   - Access the noVNC viewer at `http://localhost:6080/vnc.html`
   - Enter the VNC password (default: &quot;vncpassword&quot; or what you set in VNC_PASSWORD)
   - Direct VNC access available on port 5900 (mapped to container port 5901)
   - You can now see all browser interactions in real-time

5. **Container Management:**
   ```bash
   # Start with persistent browser
   CHROME_PERSISTENT_SESSION=true docker compose up -d

   # Start with default mode (browser closes after tasks)
   docker compose up -d

   # View logs
   docker compose logs -f

   # Stop the container
   docker compose down
   ```

## Changelog
- [x] **2025/01/26:** Thanks to @vvincent1234. Now browser-use-webui can combine with DeepSeek-r1 to engage in deep thinking!
- [x] **2025/01/10:** Thanks to @casistack. Now we have Docker Setup option and also Support keep browser open between tasks.[Video tutorial demo](https://github.com/browser-use/web-ui/issues/1#issuecomment-2582511750).
- [x] **2025/01/06:** Thanks to @richard-devbot. A New and Well-Designed WebUI is released. [Video tutorial demo](https://github.com/warmshao/browser-use-webui/issues/1#issuecomment-2573393113).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[NVIDIA/cuda-python]]></title>
            <link>https://github.com/NVIDIA/cuda-python</link>
            <guid>https://github.com/NVIDIA/cuda-python</guid>
            <pubDate>Mon, 07 Apr 2025 00:04:19 GMT</pubDate>
            <description><![CDATA[CUDA Python: Performance meets Productivity]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NVIDIA/cuda-python">NVIDIA/cuda-python</a></h1>
            <p>CUDA Python: Performance meets Productivity</p>
            <p>Language: Python</p>
            <p>Stars: 1,452</p>
            <p>Forks: 107</p>
            <p>Stars today: 76 stars today</p>
            <h2>README</h2><pre># cuda-python

CUDA Python is the home for accessing NVIDIA’s CUDA platform from Python. It consists of multiple components:

* [cuda.core](https://nvidia.github.io/cuda-python/cuda-core/latest): Pythonic access to CUDA Runtime and other core functionalities
* [cuda.bindings](https://nvidia.github.io/cuda-python/cuda-bindings/latest): Low-level Python bindings to CUDA C APIs
* [cuda.cooperative](https://nvidia.github.io/cccl/cuda_cooperative/): A Python package for easy access to highly efficient and customizable parallel algorithms, like `sort`, `scan`, `reduce`, `transform`, etc.
* [cuda.parallel](https://nvidia.github.io/cccl/cuda_parallel/): A Python package providing CUB&#039;s reusable block-wide and warp-wide primitives for use within Numba CUDA kernels

For access to NVIDIA CPU &amp; GPU Math Libraries, please refer to [nvmath-python](https://docs.nvidia.com/cuda/nvmath-python/latest).

CUDA Python is currently undergoing an overhaul to improve existing and bring up new components. All of the previously available functionalities from the cuda-python package will continue to be available, please refer to the [cuda.bindings](https://nvidia.github.io/cuda-python/cuda-bindings/latest) documentation for installation guide and further detail.

## cuda-python as a metapackage

`cuda-python` is being re-structured to become a metapackage that contains a collection of subpackages. Each subpackage is versioned independently, allowing installation of each component as needed.

### Subpackage: `cuda.core`

The `cuda.core` package offers idiomatic, pythonic access to CUDA Runtime and other functionalities.

The goals are to

1. Provide **idiomatic (&quot;pythonic&quot;)** access to CUDA Driver, Runtime, and JIT compiler toolchain
2. Focus on **developer productivity** by ensuring end-to-end CUDA development can be performed quickly and entirely in Python
3. **Avoid homegrown** Python abstractions for CUDA for new Python GPU libraries starting from scratch
4. **Ease** developer **burden of maintaining** and catching up with latest CUDA features
5. **Flatten the learning curve** for current and future generations of CUDA developers

### Subpackage: `cuda.bindings`

The `cuda.bindings` package is a standard set of low-level interfaces, providing full coverage of and access to the CUDA host APIs from Python.

The list of available interfaces are:

* CUDA Driver
* CUDA Runtime
* NVRTC
* nvJitLink

## Supported Python Versions

All `cuda-python` subpackages follows CPython [End-Of-Life](https://devguide.python.org/versions/) schedule for supported Python version guarantee.

Before dropping support there will be an issue raised as a notice.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Free-TV/IPTV]]></title>
            <link>https://github.com/Free-TV/IPTV</link>
            <guid>https://github.com/Free-TV/IPTV</guid>
            <pubDate>Mon, 07 Apr 2025 00:04:18 GMT</pubDate>
            <description><![CDATA[M3U Playlist for free TV channels]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Free-TV/IPTV">Free-TV/IPTV</a></h1>
            <p>M3U Playlist for free TV channels</p>
            <p>Language: Python</p>
            <p>Stars: 6,010</p>
            <p>Forks: 1,040</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>Free TV
=======

This is an M3U playlist for free TV channels around the World.

Either free locally (over the air):

[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/us.svg&quot; width=&quot;24&quot;&gt;](lists/usa.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ca.svg&quot; width=&quot;24&quot;&gt;](lists/canada.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/gb.svg&quot; width=&quot;24&quot;&gt;](lists/uk.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ie.svg&quot; width=&quot;24&quot;&gt;](lists/ireland.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/au.svg&quot; width=&quot;24&quot;&gt;](lists/australia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/in.svg&quot; width=&quot;24&quot;&gt;](lists/india.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/jp.svg&quot; width=&quot;24&quot;&gt;](lists/japan.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/cn.svg&quot; width=&quot;24&quot;&gt;](lists/china.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/hk.svg&quot; width=&quot;24&quot;&gt;](lists/hong_kong.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/mo.svg&quot; width=&quot;24&quot;&gt;](lists/macau.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/tw.svg&quot; width=&quot;24&quot;&gt;](lists/taiwan.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/kp.svg&quot; width=&quot;24&quot;&gt;](lists/north_korea.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/kr.svg&quot; width=&quot;24&quot;&gt;](lists/korea.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/dk.svg&quot; width=&quot;24&quot;&gt;](lists/denmark.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/fo.svg&quot; width=&quot;24&quot;&gt;](lists/faroe_islands.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/gl.svg&quot; width=&quot;24&quot;&gt;](lists/greenland.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/fi.svg&quot; width=&quot;24&quot;&gt;](lists/finland.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/is.svg&quot; width=&quot;24&quot;&gt;](lists/iceland.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/no.svg&quot; width=&quot;24&quot;&gt;](lists/norway.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/se.svg&quot; width=&quot;24&quot;&gt;](lists/sweden.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ee.svg&quot; width=&quot;24&quot;&gt;](lists/estonia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/lv.svg&quot; width=&quot;24&quot;&gt;](lists/latvia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/lt.svg&quot; width=&quot;24&quot;&gt;](lists/lithuania.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/be.svg&quot; width=&quot;24&quot;&gt;](lists/belgium.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/nl.svg&quot; width=&quot;24&quot;&gt;](lists/netherlands.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/lu.svg&quot; width=&quot;24&quot;&gt;](lists/luxembourg.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/de.svg&quot; width=&quot;24&quot;&gt;](lists/germany.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/at.svg&quot; width=&quot;24&quot;&gt;](lists/austria.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ch.svg&quot; width=&quot;24&quot;&gt;](lists/switzerland.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/pl.svg&quot; width=&quot;24&quot;&gt;](lists/poland.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/cz.svg&quot; width=&quot;24&quot;&gt;](lists/czech_republic.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/sk.svg&quot; width=&quot;24&quot;&gt;](lists/slovakia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/hu.svg&quot; width=&quot;24&quot;&gt;](lists/hungary.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ro.svg&quot; width=&quot;24&quot;&gt;](lists/romania.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/md.svg&quot; width=&quot;24&quot;&gt;](lists/moldova.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/bg.svg&quot; width=&quot;24&quot;&gt;](lists/bulgaria.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/fr.svg&quot; width=&quot;24&quot;&gt;](lists/france.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/it.svg&quot; width=&quot;24&quot;&gt;](lists/italy.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/pt.svg&quot; width=&quot;24&quot;&gt;](lists/portugal.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/es.svg&quot; width=&quot;24&quot;&gt;](lists/spain.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ru.svg&quot; width=&quot;24&quot;&gt;](lists/russia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/by.svg&quot; width=&quot;24&quot;&gt;](lists/belarus.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ua.svg&quot; width=&quot;24&quot;&gt;](lists/ukraine.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/am.svg&quot; width=&quot;24&quot;&gt;](lists/armenia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/az.svg&quot; width=&quot;24&quot;&gt;](lists/azerbaijan.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ge.svg&quot; width=&quot;24&quot;&gt;](lists/georgia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ba.svg&quot; width=&quot;24&quot;&gt;](lists/bosnia_and_herzegovina.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/hr.svg&quot; width=&quot;24&quot;&gt;](lists/croatia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/me.svg&quot; width=&quot;24&quot;&gt;](lists/montenegro.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/mk.svg&quot; width=&quot;24&quot;&gt;](lists/north_macedonia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/rs.svg&quot; width=&quot;24&quot;&gt;](lists/serbia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/si.svg&quot; width=&quot;24&quot;&gt;](lists/slovenia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/al.svg&quot; width=&quot;24&quot;&gt;](lists/albania.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/xk.svg&quot; width=&quot;24&quot;&gt;](lists/kosovo.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/gr.svg&quot; width=&quot;24&quot;&gt;](lists/greece.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/cy.svg&quot; width=&quot;24&quot;&gt;](lists/cyprus.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ad.svg&quot; width=&quot;24&quot;&gt;](lists/andorra.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/mt.svg&quot; width=&quot;24&quot;&gt;](lists/malta.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/mc.svg&quot; width=&quot;24&quot;&gt;](lists/monaco.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/sm.svg&quot; width=&quot;24&quot;&gt;](lists/san_marino.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ir.svg&quot; width=&quot;24&quot;&gt;](lists/iran.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/iq.svg&quot; width=&quot;24&quot;&gt;](lists/iraq.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/il.svg&quot; width=&quot;24&quot;&gt;](lists/israel.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/qa.svg&quot; width=&quot;24&quot;&gt;](lists/qatar.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/tr.svg&quot; width=&quot;24&quot;&gt;](lists/turkey.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ae.svg&quot; width=&quot;24&quot;&gt;](lists/united_arab_emirates.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ar.svg&quot; width=&quot;24&quot;&gt;](lists/argentina.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/cr.svg&quot; width=&quot;24&quot;&gt;](lists/costa_rica.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/do.svg&quot; width=&quot;24&quot;&gt;](lists/dominican_republic.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/mx.svg&quot; width=&quot;24&quot;&gt;](lists/mexico.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/py.svg&quot; width=&quot;24&quot;&gt;](lists/paraguay.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/pe.svg&quot; width=&quot;24&quot;&gt;](lists/peru.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/ve.svg&quot; width=&quot;24&quot;&gt;](lists/venezuela.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/br.svg&quot; width=&quot;24&quot;&gt;](lists/brazil.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/tt.svg&quot; width=&quot;24&quot;&gt;](lists/trinidad.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/td.svg&quot; width=&quot;24&quot;&gt;](lists/chad.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/so.svg&quot; width=&quot;24&quot;&gt;](lists/somalia.md)
[&lt;img src=&quot;https://hatscripts.github.io/circle-flags/flags/id.svg&quot; width=&quot;24&quot;&gt;](lists/indonesia.md)

Or free on the Internet:

- Plex TV
- Pluto TV (English, Spanish, French, Italian)
- Redbox Live TV
- Roku TV
- Samsung TV Plus
- Youtube live channels

To use it point your IPTV player to https://raw.githubusercontent.com/Free-TV/IPTV/master/playlist.m3u8.

Philosophy
==========

The main goals for this playlist are listed below.

**Quality over quantity**

The less channels we support the better.

- All channels should work well.
- As much as possible channels should be in HD, not SD.
- Only one URL per channel (no +1, no alternate feeds, no regional declinations)

**Only free channels**

If a channel is normally only available via commercial subscriptions it has nothing to do in this playlist. If on the other hand it is provided for free to everybody in a particular country, then it should be in this playlist.

- No paid channels
- Only channels which are officially provided for free (via DVB-S, DVB-T, analog, etc..)

**Only mainstream channels**

This is a playlist for everybody.

- No adult channels
- No channels dedicated to any particular religion
- No channels dedicated to any particular political party
- No channels made for a country and funded by a different country

Feed sources
============

It can be quite hard to find up to date URLs, here&#039;s a list of sources:

- https://github.com/iptv-org/iptv/tree/master/streams
- Youtube: As long as the channel is live and its URL doesn&#039;t change (check the age of the stream, the number of viewers..)
- Dailymotion: Same criteria as for youtube

Format
======

The m3u8 playlist is generated by `make_playlist.py`, using the `.md` files located in `lists`.

Each .md file represesnts a group. The `&lt;h1&gt;` line is used as the group title.

Only channels which URL column starts with `[&gt;]` are included in the playlist.

Channels which are not in HD are marked with an `Ⓢ`.

Channels which use GeoIP blocking are marked with a `Ⓖ`.

Channels which are live Youtube channels are marked with a `Ⓨ`.

Issues
======

Only create issues for bugs and feature requests.

Do not create issues to add/edit or to remove channels. If you want to add/edit/remove channels, create a pull request directly.

Pull Requests
=============

**Only modify .md files**

If your Pull Request modifies channels, only modify .md files. Do not modify m3u8 files in your pull request.

**Adding a new Channel**

To add a new channel, make a Pull Request.

- In your Pull Request you need to provide information to show that the channel is free.
- Use imgur.com to host the channel logo and point to it.
- If you have a valid stream, add it and put `[&gt;]` in front of it.
- If you don&#039;t have an stream for the channel, add `[x]()` in the url column and place your channel in the Invalid category.
- If you have a stream but it doesn&#039;t work well, put the channel in the Invalid category and put `[x]` in front of the url.
- If you&#039;re adding geoblocked URLs specify it in your PR and specify which country they&#039;re working in. The PR will only be merged if these URLs can be tested.

**Removing a Channel**

To remove a channel, make a Pull Request.

In your Pull Request you need to provide information to show that the channel is only available via a private paid subscription.

Note: Public taxes (whether national or regional, whether called TV License or not) do not constitute a private paid subscription.

If a stream is broken, simply move the channel to the invalid category and replace `[&gt;]` with `[x]` in the url column.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>