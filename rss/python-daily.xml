<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Tue, 15 Apr 2025 00:04:40 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[yeongpin/cursor-free-vip]]></title>
            <link>https://github.com/yeongpin/cursor-free-vip</link>
            <guid>https://github.com/yeongpin/cursor-free-vip</guid>
            <pubDate>Tue, 15 Apr 2025 00:04:40 GMT</pubDate>
            <description><![CDATA[[Support 0.48.x]ï¼ˆReset Cursor AI MachineID & Auto Sign Up / In & Bypass Higher Token Limitï¼‰è‡ªåŠ¨æ³¨å†Œ Cursor Ai ï¼Œè‡ªåŠ¨é‡ç½®æœºå™¨ID ï¼Œ å…è´¹å‡çº§ä½¿ç”¨ProåŠŸèƒ½: You've reached your trial request limit. / Too many free trial accounts used on this machine. Please upgrade to pro. We have this limit in place to prevent abuse. Please let us know if you believe this is a mistake.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/yeongpin/cursor-free-vip">yeongpin/cursor-free-vip</a></h1>
            <p>[Support 0.48.x]ï¼ˆReset Cursor AI MachineID & Auto Sign Up / In & Bypass Higher Token Limitï¼‰è‡ªåŠ¨æ³¨å†Œ Cursor Ai ï¼Œè‡ªåŠ¨é‡ç½®æœºå™¨ID ï¼Œ å…è´¹å‡çº§ä½¿ç”¨ProåŠŸèƒ½: You've reached your trial request limit. / Too many free trial accounts used on this machine. Please upgrade to pro. We have this limit in place to prevent abuse. Please let us know if you believe this is a mistake.</p>
            <p>Language: Python</p>
            <p>Stars: 15,194</p>
            <p>Forks: 1,815</p>
            <p>Stars today: 2,563 stars today</p>
            <h2>README</h2><pre># â¤ Cursor Free VIP

&lt;div align=&quot;center&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/logo.png&quot; alt=&quot;Cursor Pro Logo&quot; width=&quot;200&quot; style=&quot;border-radius: 6px;&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;

[![Release](https://img.shields.io/endpoint?url=https://www.pinnumber.rr.nu/badges/release/yeongpin/cursor-free-vip)](https://github.com/yeongpin/cursor-free-vip/releases/latest)
[![License: CC BY-NC-ND 4.0](https://img.shields.io/badge/License-CC_BY--NC--ND_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-nd/4.0/)
[![Stars](https://img.shields.io/endpoint?url=https://www.pinnumber.rr.nu/badges/stars/yeongpin/cursor-free-vip)](https://github.com/yeongpin/cursor-free-vip/stargazers)
[![Downloads](https://img.shields.io/endpoint?url=https://www.pinnumber.rr.nu/badges/downloads/yeongpin/cursor-free-vip/total)](https://github.com/yeongpin/cursor-free-vip/releases/latest)
&lt;a href=&quot;https://buymeacoffee.com/yeongpin&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Buy Me a Coffee&quot; src=&quot;https://img.shields.io/badge/Buy%20Me%20a%20Coffee-Support%20Me-FFDA33&quot;&gt;&lt;/a&gt;

&lt;/p&gt;

&lt;a href=&quot;https://trendshift.io/repositories/13425&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13425&quot; alt=&quot;yeongpin%2Fcursor-free-vip | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;br&gt;
&lt;a href=&quot;https://www.buymeacoffee.com/yeongpin&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://img.buymeacoffee.com/button-api/?text=buy me a coffee&amp;emoji=â˜•&amp;slug=yeongpin&amp;button_colour=ffda33&amp;font_colour=000000&amp;font_family=Bree&amp;outline_colour=000000&amp;coffee_colour=FFDD00&amp;latest=2&quot; width=&quot;160&quot; height=&#039;55&#039; alt=&quot;Buy Me a Coffee&quot;/&gt;
&lt;/a&gt;


&lt;h4&gt;Support Latest 0.48.x Version | æ”¯æŒæœ€æ–° 0.48.x ç‰ˆæœ¬&lt;/h4&gt;

This tool registers accounts with custom emails, support Google and GitHub account registrations, temporary GitHub account registration, kills all Cursor&#039;s running processes, resets and wipes Cursor data and hardware info.

Supports Windows, macOS and Linux.

For optimal performance, run with privileges and always stay up to date.

Always clean your browser&#039;s cache and cookies. If possible, use a VPN to create new accounts.


é€™æ˜¯ä¸€å€‹è‡ªå‹•åŒ–å·¥å…·ï¼Œè‡ªå‹•è¨»å†Šï¼Œæ”¯æŒ Windows macOS å’Œ Linux ç³»çµ±ï¼Œå®Œæˆ Auth é©—è­‰ï¼Œé‡ç½® Cursor çš„é…ç½®ã€‚

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pro_2025-04-05_18-47-56.png&quot; alt=&quot;new&quot; width=&quot;800&quot; style=&quot;border-radius: 6px;&quot;/&gt;&lt;br&gt;
&lt;/p&gt;

##### If you don&#039;t have browser, you can download it from 
[Google Chrome](https://www.google.com/intl/en_pk/chrome/) or [Opera](https://www.opera.com/download) or [Edge](https://www.microsoft.com/en-us/edge) or [Firefox](https://www.mozilla.org/en-US/firefox/new/) or [Brave](https://www.brave.com/download/)

##### å¦‚æœæ²’æœ‰ç€è¦½å™¨ï¼Œå¯ä»¥å¾
[Google Chrome](https://www.google.com/intl/en_pk/chrome/) æˆ– [Opera](https://www.opera.com/download) æˆ– [Edge](https://www.microsoft.com/en-us/edge) æˆ– [Firefox](https://www.mozilla.org/en-US/firefox/new/) æˆ– [Brave](https://www.brave.com/download/) ä¸‹è¼‰

&lt;/div&gt;

## ğŸ”„ Change Log | æ›´æ–°æ—¥å¿—

[Watch Change Log | æŸ¥çœ‹æ›´æ–°æ—¥å¿—](CHANGELOG.md)

## âœ¨ Features | åŠŸèƒ½ç‰¹é»

* ğŸŒŸ Google OAuth Authentication with Lifetime Access&lt;br&gt;ä½¿ç”¨ Google OAuth èªè­‰ï¼ˆçµ‚èº«è¨ªå•ï¼‰&lt;br&gt;

* â­ GitHub OAuth Authentication with Lifetime Access&lt;br&gt;ä½¿ç”¨ GitHub OAuth èªè­‰ï¼ˆçµ‚èº«è¨ªå•ï¼‰&lt;br&gt;

* Automatically register Cursor membership&lt;br&gt;è‡ªå‹•è¨»å†Š Cursor æœƒå“¡&lt;br&gt;

* Support Windows macOS and Linux systems&lt;br&gt;æ”¯æŒ Windowsã€macOS å’Œ Linux ç³»çµ±&lt;br&gt;

* Complete Auth verification&lt;br&gt;å®Œæˆ Auth é©—è­‰&lt;br&gt;

* Reset Cursor&#039;s configuration&lt;br&gt;é‡ç½® Cursor çš„é…ç½®&lt;br&gt;

* Delete Cursor Google Account&lt;br&gt;åˆ é™¤ Cursor Google è´¦å·&lt;br&gt;

* Multi-language support (English, ç®€ä½“ä¸­æ–‡, ç¹é«”ä¸­æ–‡, Vietnamese)&lt;br&gt;å¤šèªè¨€æ”¯æŒï¼ˆè‹±æ–‡ã€ç®€ä½“ä¸­æ–‡ã€ç¹é«”ä¸­æ–‡ã€è¶Šå—èªï¼‰&lt;br&gt;

## ğŸ’» System Support | ç³»çµ±æ”¯æŒ

| Windows |  x64  | âœ… | macOS |     Intel     | âœ… |
|:-------:|:-----:|:-:|:-----:|:-------------:|:-:|
| Windows |  x86  | âœ… | macOS | Apple Silicon | âœ… |
|  Linux  |  x64  | âœ… | Linux |      x86      | âœ… |
|  Linux  | ARM64 | âœ… | Linux |     ARM64     | âœ… |

## ğŸ‘€ How to use | å¦‚ä½•ä½¿ç”¨

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;â­ Auto Run Script | è…³æœ¬è‡ªå‹•åŒ–é‹è¡Œ&lt;/b&gt;&lt;/summary&gt;

### **Linux/macOS**

```bash
curl -fsSL https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.sh -o install.sh &amp;&amp; chmod +x install.sh &amp;&amp; ./install.sh
```

### **Archlinux**

Install via [AUR](https://aur.archlinux.org/packages/cursor-free-vip-git)

```bash
yay -S cursor-free-vip-git
```

### **Windows**

```powershell
irm https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.ps1 | iex
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;â­ Manual Reset Machine | æ‰‹å‹•é‹è¡Œé‡ç½®æ©Ÿå™¨&lt;/b&gt;&lt;/summary&gt;

### **Linux/macOS**

```bash
curl -fsSL https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/reset.sh | sudo bash
```

### **Windows**

```powershell
irm https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/reset.ps1 | iex
```

&lt;/details&gt;

If you want to stop the script, please press Ctrl+C&lt;br&gt;è¦åœæ­¢è…³æœ¬ï¼Œè«‹æŒ‰ Ctrl+C

## â— Note | æ³¨æ„äº‹é …

ğŸ“ Config | æ–‡ä»¶é…ç½®
`Win / Macos / Linux Path | è·¯å¾‘ [Documents/.cursor-free-vip/config.ini]`
&lt;details&gt;
&lt;summary&gt;&lt;b&gt;â­ Config | æ–‡ä»¶é…ç½®&lt;/b&gt;&lt;/summary&gt;

```
[Chrome]
# Default Google Chrome Path | é»˜èªGoogle Chrome éŠè¦½å™¨è·¯å¾‘
chromepath = C:\Program Files\Google/Chrome/Application/chrome.exe

[Turnstile]
# Handle Turnstile Wait Time | ç­‰å¾…äººæ©Ÿé©—è­‰æ™‚é–“
handle_turnstile_time = 2
# Handle Turnstile Wait Random Time (must merge 1-3 or 1,3) | ç­‰å¾…äººæ©Ÿé©—è­‰éš¨æ©Ÿæ™‚é–“ï¼ˆå¿…é ˆæ˜¯ 1-3 æˆ–è€… 1,3 é€™æ¨£çš„çµ„åˆï¼‰
handle_turnstile_random_time = 1-3

[OSPaths]
# Storage Path | å­˜å„²è·¯å¾‘
storage_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/storage.json
# SQLite Path | SQLiteè·¯å¾‘
sqlite_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/state.vscdb
# Machine ID Path | æ©Ÿå™¨IDè·¯å¾‘
machine_id_path = /Users/username/Library/Application Support/Cursor/machineId
# For Linux users: ~/.config/cursor/machineid

[Timing]
# Min Random Time | æœ€å°éš¨æ©Ÿæ™‚é–“
min_random_time = 0.1
# Max Random Time | æœ€å¤§éš¨æ©Ÿæ™‚é–“
max_random_time = 0.8
# Page Load Wait | é é¢åŠ è¼‰ç­‰å¾…æ™‚é–“
page_load_wait = 0.1-0.8
# Input Wait | è¼¸å…¥ç­‰å¾…æ™‚é–“
input_wait = 0.3-0.8
# Submit Wait | æäº¤ç­‰å¾…æ™‚é–“
submit_wait = 0.5-1.5
# Verification Code Input | é©—è­‰ç¢¼è¼¸å…¥ç­‰å¾…æ™‚é–“
verification_code_input = 0.1-0.3
# Verification Success Wait | é©—è­‰æˆåŠŸç­‰å¾…æ™‚é–“
verification_success_wait = 2-3
# Verification Retry Wait | é©—è­‰é‡è©¦ç­‰å¾…æ™‚é–“
verification_retry_wait = 2-3
# Email Check Initial Wait | éƒµä»¶æª¢æŸ¥åˆå§‹ç­‰å¾…æ™‚é–“
email_check_initial_wait = 4-6
# Email Refresh Wait | éƒµä»¶åˆ·æ–°ç­‰å¾…æ™‚é–“
email_refresh_wait = 2-4
# Settings Page Load Wait | è¨­ç½®é é¢åŠ è¼‰ç­‰å¾…æ™‚é–“
settings_page_load_wait = 1-2
# Failed Retry Time | å¤±æ•—é‡è©¦æ™‚é–“
failed_retry_time = 0.5-1
# Retry Interval | é‡è©¦é–“éš”
retry_interval = 8-12
# Max Timeout | æœ€å¤§è¶…æ™‚æ™‚é–“
max_timeout = 160

[Utils]
# Check Update | æª¢æŸ¥æ›´æ–°
check_update = True
# Show Account Info | é¡¯ç¤ºè³¬è™Ÿä¿¡æ¯
show_account_info = True

[WindowsPaths]
storage_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\storage.json
sqlite_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\state.vscdb
machine_id_path = C:\Users\yeongpin\AppData\Roaming\Cursor\machineId
cursor_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app
updater_path = C:\Users\yeongpin\AppData\Local\cursor-updater
update_yml_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app-update.yml
product_json_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app\product.json

[Browser]
default_browser = opera
chrome_path = C:\Program Files\Google\Chrome\Application\chrome.exe
edge_path = C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe
firefox_path = C:\Program Files\Mozilla Firefox\firefox.exe
brave_path = C:\Program Files\BraveSoftware/Brave-Browser/Application/brave.exe
chrome_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe
edge_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\msedgedriver.exe
firefox_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\geckodriver.exe
brave_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe
opera_path = C:\Users\yeongpin\AppData\Local\Programs\Opera\opera.exe
opera_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe

[OAuth]
show_selection_alert = False
timeout = 120
max_attempts = 3
```

&lt;/details&gt;

* Use administrator privileges to run the script &lt;br&gt;è«‹ä½¿ç”¨ç®¡ç†å“¡èº«ä»½é‹è¡Œè…³æœ¬

* Confirm that Cursor is closed before running the script &lt;br&gt;è«‹ç¢ºä¿åœ¨é‹è¡Œè…³æœ¬å‰å·²ç¶“é—œé–‰ Cursor&lt;br&gt;

* This tool is only for learning and research purposes &lt;br&gt;æ­¤å·¥å…·åƒ…ä¾›å­¸ç¿’å’Œç ”ç©¶ä½¿ç”¨&lt;br&gt;

* Please comply with the relevant software usage terms when using this tool &lt;br&gt;ä½¿ç”¨æœ¬å·¥å…·æ™‚è«‹éµå®ˆç›¸é—œè»Ÿä»¶ä½¿ç”¨æ¢æ¬¾

## ğŸš¨ Common Issues | å¸¸è¦‹å•é¡Œ

|                   å¦‚æœé‡åˆ°æ¬Šé™å•é¡Œï¼Œè«‹ç¢ºä¿ï¼š                    |                   æ­¤è…³æœ¬ä»¥ç®¡ç†å“¡èº«ä»½é‹è¡Œ                    |
|:--------------------------------------------------:|:------------------------------------------------:|
| If you encounter permission issues, please ensure: | This script is run with administrator privileges |
| Error &#039;User is not authorized&#039; | This means your account was banned for using temporary (disposal) mail. Ensure using a non-temporary mail service |
## ğŸ¤© Contribution | è²¢ç»

æ­¡è¿æäº¤ Issue å’Œ Pull Requestï¼


&lt;a href=&quot;https://github.com/yeongpin/cursor-free-vip/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=yeongpin/cursor-free-vip&amp;preview=true&amp;max=&amp;columns=&quot; /&gt;
&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;

## ğŸ“© Disclaimer | å…è²¬è²æ˜

æœ¬å·¥å…·åƒ…ä¾›å­¸ç¿’å’Œç ”ç©¶ä½¿ç”¨ï¼Œä½¿ç”¨æœ¬å·¥å…·æ‰€ç”¢ç”Ÿçš„ä»»ä½•å¾Œæœç”±ä½¿ç”¨è€…è‡ªè¡Œæ‰¿æ“”ã€‚ &lt;br&gt;

This tool is only for learning and research purposes, and any consequences arising from the use of this tool are borne
by the user.

## ğŸ’° Buy Me a Coffee | è«‹æˆ‘å–æ¯å’–å•¡

&lt;div align=&quot;center&quot;&gt;
  &lt;table&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;img src=&quot;./images/provi-code.jpg&quot; alt=&quot;buy_me_a_coffee&quot; width=&quot;280&quot;/&gt;&lt;br&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;img src=&quot;./images/paypal.png&quot; alt=&quot;buy_me_a_coffee&quot; width=&quot;280&quot;/&gt;&lt;br&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

## â­ Star History | æ˜Ÿæ˜Ÿæ•¸

&lt;div align=&quot;center&quot;&gt;

[![Star History Chart](https://api.star-history.com/svg?repos=yeongpin/cursor-free-vip&amp;type=Date)](https://star-history.com/#yeongpin/cursor-free-vip&amp;Date)

&lt;/div&gt;

## ğŸ“ License | æˆæ¬Š

æœ¬é …ç›®æ¡ç”¨ [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/) æˆæ¬Šã€‚
Please refer to the [LICENSE](LICENSE.md) file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[virattt/ai-hedge-fund]]></title>
            <link>https://github.com/virattt/ai-hedge-fund</link>
            <guid>https://github.com/virattt/ai-hedge-fund</guid>
            <pubDate>Tue, 15 Apr 2025 00:04:39 GMT</pubDate>
            <description><![CDATA[An AI Hedge Fund Team]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/virattt/ai-hedge-fund">virattt/ai-hedge-fund</a></h1>
            <p>An AI Hedge Fund Team</p>
            <p>Language: Python</p>
            <p>Stars: 21,597</p>
            <p>Forks: 3,886</p>
            <p>Stars today: 381 stars today</p>
            <h2>README</h2><pre># AI Hedge Fund

This is a proof of concept for an AI-powered hedge fund.  The goal of this project is to explore the use of AI to make trading decisions.  This project is for **educational** purposes only and is not intended for real trading or investment.

This system employs several agents working together:

1. Ben Graham Agent - The godfather of value investing, only buys hidden gems with a margin of safety
2. Bill Ackman Agent - An activist investors, takes bold positions and pushes for change
3. Cathie Wood Agent - The queen of growth investing, believes in the power of innovation and disruption
4. Charlie Munger Agent - Warren Buffett&#039;s partner, only buys wonderful businesses at fair prices
5. Michael Burry Agent - The Big Short contrarian who hunts for deep value
6. Peter Lynch Agent - Practical investor who seeks &quot;ten-baggers&quot; in everyday businesses
7. Phil Fisher Agent - Meticulous growth investor who uses deep &quot;scuttlebutt&quot; research 
8. Stanley Druckenmiller Agent - Macro legend who hunts for asymmetric opportunities with growth potential
9. Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price
10. Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals
11. Sentiment Agent - Analyzes market sentiment and generates trading signals
12. Fundamentals Agent - Analyzes fundamental data and generates trading signals
13. Technicals Agent - Analyzes technical indicators and generates trading signals
14. Risk Manager - Calculates risk metrics and sets position limits
15. Portfolio Manager - Makes final trading decisions and generates orders
    
&lt;img width=&quot;1042&quot; alt=&quot;Screenshot 2025-03-22 at 6 19 07â€¯PM&quot; src=&quot;https://github.com/user-attachments/assets/cbae3dcf-b571-490d-b0ad-3f0f035ac0d4&quot; /&gt;


**Note**: the system simulates trading decisions, it does not actually trade.

[![Twitter Follow](https://img.shields.io/twitter/follow/virattt?style=social)](https://twitter.com/virattt)

## Disclaimer

This project is for **educational and research purposes only**.

- Not intended for real trading or investment
- No warranties or guarantees provided
- Past performance does not indicate future results
- Creator assumes no liability for financial losses
- Consult a financial advisor for investment decisions

By using this software, you agree to use it solely for learning purposes.

## Table of Contents
- [Setup](#setup)
- [Usage](#usage)
  - [Running the Hedge Fund](#running-the-hedge-fund)
  - [Running the Backtester](#running-the-backtester)
- [Project Structure](#project-structure)
- [Contributing](#contributing)
- [Feature Requests](#feature-requests)
- [License](#license)

## Setup

Clone the repository:
```bash
git clone https://github.com/virattt/ai-hedge-fund.git
cd ai-hedge-fund
```

1. Install Poetry (if not already installed):
```bash
curl -sSL https://install.python-poetry.org | python3 -
```

2. Install dependencies:
```bash
poetry install
```

3. Set up your environment variables:
```bash
# Create .env file for your API keys
cp .env.example .env
```

4. Set your API keys:
```bash
# For running LLMs hosted by openai (gpt-4o, gpt-4o-mini, etc.)
# Get your OpenAI API key from https://platform.openai.com/
OPENAI_API_KEY=your-openai-api-key

# For running LLMs hosted by groq (deepseek, llama3, etc.)
# Get your Groq API key from https://groq.com/
GROQ_API_KEY=your-groq-api-key

# For getting financial data to power the hedge fund
# Get your Financial Datasets API key from https://financialdatasets.ai/
FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key
```

**Important**: You must set `OPENAI_API_KEY`, `GROQ_API_KEY`, `ANTHROPIC_API_KEY`, or `DEEPSEEK_API_KEY` for the hedge fund to work.  If you want to use LLMs from all providers, you will need to set all API keys.

Financial data for AAPL, GOOGL, MSFT, NVDA, and TSLA is free and does not require an API key.

For any other ticker, you will need to set the `FINANCIAL_DATASETS_API_KEY` in the .env file.

## Usage

### Running the Hedge Fund
```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA
```

**Example Output:**
&lt;img width=&quot;992&quot; alt=&quot;Screenshot 2025-01-06 at 5 50 17â€¯PM&quot; src=&quot;https://github.com/user-attachments/assets/e8ca04bf-9989-4a7d-a8b4-34e04666663b&quot; /&gt;

You can also specify a `--ollama` flag to run the AI hedge fund using local LLMs.

```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --ollama
```

You can also specify a `--show-reasoning` flag to print the reasoning of each agent to the console.

```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --show-reasoning
```
You can optionally specify the start and end dates to make decisions for a specific time period.

```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 
```

### Running the Backtester

```bash
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA
```

**Example Output:**
&lt;img width=&quot;941&quot; alt=&quot;Screenshot 2025-01-06 at 5 47 52â€¯PM&quot; src=&quot;https://github.com/user-attachments/assets/00e794ea-8628-44e6-9a84-8f8a31ad3b47&quot; /&gt;


You can optionally specify the start and end dates to backtest over a specific time period.

```bash
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01
```

You can also specify a `--ollama` flag to run the backtester using local LLMs.
```bash
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA --ollama
```


## Project Structure 
```
ai-hedge-fund/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                   # Agent definitions and workflow
â”‚   â”‚   â”œâ”€â”€ bill_ackman.py        # Bill Ackman agent
â”‚   â”‚   â”œâ”€â”€ fundamentals.py       # Fundamental analysis agent
â”‚   â”‚   â”œâ”€â”€ portfolio_manager.py  # Portfolio management agent
â”‚   â”‚   â”œâ”€â”€ risk_manager.py       # Risk management agent
â”‚   â”‚   â”œâ”€â”€ sentiment.py          # Sentiment analysis agent
â”‚   â”‚   â”œâ”€â”€ technicals.py         # Technical analysis agent
â”‚   â”‚   â”œâ”€â”€ valuation.py          # Valuation analysis agent
â”‚   â”‚   â”œâ”€â”€ warren_buffett.py     # Warren Buffett agent
â”‚   â”œâ”€â”€ tools/                    # Agent tools
â”‚   â”‚   â”œâ”€â”€ api.py                # API tools
â”‚   â”œâ”€â”€ backtester.py             # Backtesting tools
â”‚   â”œâ”€â”€ main.py # Main entry point
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ ...
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

**Important**: Please keep your pull requests small and focused.  This will make it easier to review and merge.

## Feature Requests

If you have a feature request, please open an [issue](https://github.com/virattt/ai-hedge-fund/issues) and make sure it is tagged with `enhancement`.

## License

This project is licensed under the MIT License - see the LICENSE file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[funstory-ai/BabelDOC]]></title>
            <link>https://github.com/funstory-ai/BabelDOC</link>
            <guid>https://github.com/funstory-ai/BabelDOC</guid>
            <pubDate>Tue, 15 Apr 2025 00:04:38 GMT</pubDate>
            <description><![CDATA[Yet Another Document Translator]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/funstory-ai/BabelDOC">funstory-ai/BabelDOC</a></h1>
            <p>Yet Another Document Translator</p>
            <p>Language: Python</p>
            <p>Stars: 2,222</p>
            <p>Forks: 126</p>
            <p>Stars today: 177 stars today</p>
            <h2>README</h2><pre>&lt;!-- # Yet Another Document Translator --&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;!-- &lt;img src=&quot;https://s.immersivetranslate.com/assets/r2-uploads/images/babeldoc-banner.png&quot; width=&quot;320px&quot;  alt=&quot;YADT&quot;/&gt; --&gt;

&lt;br/&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://s.immersivetranslate.com/assets/uploads/babeldoc-big-logo-darkmode-with-transparent-background-IKuNO1.svg&quot; width=&quot;320px&quot; alt=&quot;BabelDOC&quot;/&gt;
  &lt;img src=&quot;https://s.immersivetranslate.com/assets/uploads/babeldoc-big-logo-with-transparent-background-2xweBr.svg&quot; width=&quot;320px&quot; alt=&quot;BabelDOC&quot;/&gt;
&lt;/picture&gt;

&lt;!-- &lt;h2 id=&quot;title&quot;&gt;BabelDOC&lt;/h2&gt; --&gt;

&lt;p&gt;
  &lt;!-- PyPI --&gt;
  &lt;a href=&quot;https://pypi.org/project/BabelDOC/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/pypi/v/BabelDOC&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://pepy.tech/projects/BabelDOC&quot;&gt;
    &lt;img src=&quot;https://static.pepy.tech/badge/BabelDOC&quot;&gt;&lt;/a&gt;
  &lt;!-- &lt;a href=&quot;https://github.com/funstory-ai/BabelDOC/pulls&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/contributions-welcome-green&quot;&gt;&lt;/a&gt; --&gt;
  &lt;!-- License --&gt;
  &lt;a href=&quot;./LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/funstory-ai/BabelDOC&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://t.me/+Z9_SgnxmsmA5NzBl&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Telegram-2CA5E0?style=flat-squeare&amp;logo=telegram&amp;logoColor=white&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;a href=&quot;https://trendshift.io/repositories/13358&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13358&quot; alt=&quot;funstory-ai%2FBabelDOC | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

PDF scientific paper translation and bilingual comparison library.

- **Online Service**: Beta version launched [Immersive Translate - BabelDOC](https://app.immersivetranslate.com/babel-doc/) 1000 free pages per month.
- **Self-deployment**: [PDFMathTranslate](https://github.com/Byaidu/PDFMathTranslate) 1.9.3+ Experimental support for BabelDOC, available for self-deployment + WebUI with more translation services.
- Provides a simple [command line interface](#getting-started).
- Provides a [Python API](#python-api).
- Mainly designed to be embedded into other programs, but can also be used directly for simple translation tasks.

## Preview

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://s.immersivetranslate.com/assets/r2-uploads/images/babeldoc-preview.png&quot; width=&quot;80%&quot;/&gt;
&lt;/div&gt;

## We are hiring

See details: [EN](https://github.com/funstory-ai/jobs) | [ZH](https://github.com/funstory-ai/jobs/blob/main/README_ZH.md)

## Getting Started

### Install from PyPI

We recommend using the Tool feature of [uv](https://github.com/astral-sh/uv) to install yadt.

1. First, you need to refer to [uv installation](https://github.com/astral-sh/uv#installation) to install uv and set up the `PATH` environment variable as prompted.

2. Use the following command to install yadt:

```bash
uv tool install --python 3.12 BabelDOC

babeldoc --help
```

3. Use the `babeldoc` command. For example:

```bash
babeldoc --bing  --files example.pdf

# multiple files
babeldoc --bing  --files example1.pdf --files example2.pdf
```

### Install from Source

We still recommend using [uv](https://github.com/astral-sh/uv) to manage virtual environments.

1. First, you need to refer to [uv installation](https://github.com/astral-sh/uv#installation) to install uv and set up the `PATH` environment variable as prompted.

2. Use the following command to install yadt:

```bash
# clone the project
git clone https://github.com/funstory-ai/BabelDOC

# enter the project directory
cd BabelDOC

# install dependencies and run babeldoc
uv run babeldoc --help
```

3. Use the `uv run babeldoc` command. For example:

```bash
uv run babeldoc --files example.pdf --openai --openai-model &quot;gpt-4o-mini&quot; --openai-base-url &quot;https://api.openai.com/v1&quot; --openai-api-key &quot;your-api-key-here&quot;

# multiple files
uv run babeldoc --files example.pdf --files example2.pdf --openai --openai-model &quot;gpt-4o-mini&quot; --openai-base-url &quot;https://api.openai.com/v1&quot; --openai-api-key &quot;your-api-key-here&quot;
```

&gt; [!TIP]
&gt; The absolute path is recommended.

## Advanced Options

&gt; [!NOTE]
&gt; This CLI is mainly for debugging purposes. Although end users can use this CLI to translate files, we do not provide any technical support for this purpose.
&gt;
&gt; End users should directly use **Online Service**: Beta version launched [Immersive Translate - BabelDOC](https://app.immersivetranslate.com/babel-doc/) 1000 free pages per month.
&gt;
&gt; End users who need self-deployment should use [PDFMathTranslate](https://github.com/Byaidu/PDFMathTranslate)
&gt; 
&gt; If you find that an option is not listed below, it means that this option is a debugging option for maintainers. Please do not use these options.


### Language Options

- `--lang-in`, `-li`: Source language code (default: en)
- `--lang-out`, `-lo`: Target language code (default: zh)

&gt; [!TIP]
&gt; Currently, this project mainly focuses on English-to-Chinese translation, and other scenarios have not been tested yet.
&gt; 
&gt; (2025.3.1 update): Basic English target language support has been added, primarily to minimize line breaks within words([0-9A-Za-z]+).
&gt; 
&gt; [HELP WANTED: Collecting word regular expressions for more languages](https://github.com/funstory-ai/BabelDOC/issues/129)

### PDF Processing Options

- `--files`: One or more file paths to input PDF documents.
- `--pages`, `-p`: Specify pages to translate (e.g., &quot;1,2,1-,-3,3-5&quot;). If not set, translate all pages
- `--split-short-lines`: Force split short lines into different paragraphs (may cause poor typesetting &amp; bugs)
- `--short-line-split-factor`: Split threshold factor (default: 0.8). The actual threshold is the median length of all lines on the current page \* this factor
- `--skip-clean`: Skip PDF cleaning step
- `--dual-translate-first`: Put translated pages first in dual PDF mode (default: original pages first)
- `--disable-rich-text-translate`: Disable rich text translation (may help improve compatibility with some PDFs)
- `--enhance-compatibility`: Enable all compatibility enhancement options (equivalent to --skip-clean --dual-translate-first --disable-rich-text-translate)
- `--use-alternating-pages-dual`: Use alternating pages mode for dual PDF. When enabled, original and translated pages are arranged in alternate order. When disabled (default), original and translated pages are shown side by side on the same page.
- `--watermark-output-mode`: Control watermark output mode: &#039;watermarked&#039; (default) adds watermark to translated PDF, &#039;no_watermark&#039; doesn&#039;t add watermark, &#039;both&#039; outputs both versions.
- `--max-pages-per-part`: Maximum number of pages per part for split translation. If not set, no splitting will be performed.
- `--no-watermark`: [DEPRECATED] Use --watermark-output-mode=no_watermark instead.
- `--translate-table-text`: Translate table text (experimental, default: False)
- `--skip-scanned-detection`: Skip scanned document detection (default: False). When using split translation, only the first part performs detection if not skipped.

&gt; [!TIP]
&gt; - Both `--skip-clean` and `--dual-translate-first` may help improve compatibility with some PDF readers
&gt; - `--disable-rich-text-translate` can also help with compatibility by simplifying translation input
&gt; - However, using `--skip-clean` will result in larger file sizes
&gt; - If you encounter any compatibility issues, try using `--enhance-compatibility` first
&gt; - Use `--max-pages-per-part` for large documents to split them into smaller parts for translation and automatically merge them back.
&gt; - Use `--skip-scanned-detection` to speed up processing when you know your document is not a scanned PDF.

### Translation Service Options

- `--qps`: QPS (Queries Per Second) limit for translation service (default: 4)
- `--ignore-cache`: Ignore translation cache and force retranslation
- `--no-dual`: Do not output bilingual PDF files
- `--no-mono`: Do not output monolingual PDF files
- `--min-text-length`: Minimum text length to translate (default: 5)
- `--openai`: Use OpenAI for translation (default: False)

&gt; [!TIP]
&gt;
&gt; 1. Currently, only OpenAI-compatible LLM is supported. For more translator support, please use [PDFMathTranslate](https://github.com/Byaidu/PDFMathTranslate).
&gt; 2. It is recommended to use models with strong compatibility with OpenAI, such as: `glm-4-flash`, `deepseek-chat`, etc.
&gt; 3. Currently, it has not been optimized for traditional translation engines like Bing/Google, it is recommended to use LLMs.
&gt; 4. You can use [litellm](https://github.com/BerriAI/litellm) to access multiple models.

### OpenAI Specific Options

- `--openai-model`: OpenAI model to use (default: gpt-4o-mini)
- `--openai-base-url`: Base URL for OpenAI API
- `--openai-api-key`: API key for OpenAI service

&gt; [!TIP]
&gt;
&gt; 1. This tool supports any OpenAI-compatible API endpoints. Just set the correct base URL and API key. (e.g. `https://xxx.custom.xxx/v1`)
&gt; 2. For local models like Ollama, you can use any value as the API key (e.g. `--openai-api-key a`).

### Output Control

- `--output`, `-o`: Output directory for translated files. If not set, use current working directory.
- `--debug`, `-d`: Enable debug logging level and export detailed intermediate results in `~/.cache/yadt/working`.
- `--report-interval`: Progress report interval in seconds (default: 0.1).

### Offline Assets Management

- `--generate-offline-assets`: Generate an offline assets package in the specified directory. This creates a zip file containing all required models and fonts.
- `--restore-offline-assets`: Restore an offline assets package from the specified file. This extracts models and fonts from a previously generated package.

&gt; [!TIP]
&gt; 
&gt; 1. Offline assets packages are useful for environments without internet access or to speed up installation on multiple machines.
&gt; 2. Generate a package once with `babeldoc --generate-offline-assets /path/to/output/dir` and then distribute it.
&gt; 3. Restore the package on target machines with `babeldoc --restore-offline-assets /path/to/offline_assets_*.zip`.
&gt; 4. The offline assets package name cannot be modified because the file list hash is encoded in the name.
&gt; 5. If you provide a directory path to `--restore-offline-assets`, the tool will automatically look for the correct offline assets package file in that directory.
&gt; 6. The package contains all necessary fonts and models required for document processing, ensuring consistent results across different environments.
&gt; 7. The integrity of all assets is verified using SHA3-256 hashes during both packaging and restoration.
&gt; 8. If you&#039;re deploying in an air-gapped environment, make sure to generate the package on a machine with internet access first.

### Configuration File

- `--config`, `-c`: Configuration file path. Use the TOML format.

Example Configuration:

```toml
[babeldoc]
# Basic settings
debug = true
lang-in = &quot;en-US&quot;
lang-out = &quot;zh-CN&quot;
qps = 10
output = &quot;/path/to/output/dir&quot;

# PDF processing options
split-short-lines = false
short-line-split-factor = 0.8
skip-clean = false
dual-translate-first = false
disable-rich-text-translate = false
use-alternating-pages-dual = false
watermark-output-mode = &quot;watermarked&quot;  # Choices: &quot;watermarked&quot;, &quot;no_watermark&quot;, &quot;both&quot;
max-pages-per-part = 50  # Automatically split the document for translation and merge it back.
# no-watermark = false  # DEPRECATED: Use watermark-output-mode instead
skip-scanned-detection = false  # Skip scanned document detection for faster processing

# Translation service
openai = true
openai-model = &quot;gpt-4o-mini&quot;
openai-base-url = &quot;https://api.openai.com/v1&quot;
openai-api-key = &quot;your-api-key-here&quot;

# Output control
no-dual = false
no-mono = false
min-text-length = 5
report-interval = 0.5

# Offline assets management
# Uncomment one of these options as needed:
# generate-offline-assets = &quot;/path/to/output/dir&quot;
# restore-offline-assets = &quot;/path/to/offline_assets_package.zip&quot;
```

## Python API

&gt; [!TIP]
&gt;
&gt; 1. Before pdf2zh 2.0 is released, you can temporarily use BabelDOC&#039;s Python API. However, after pdf2zh 2.0 is released, please directly use pdf2zh&#039;s Python API.
&gt;
&gt; 2. This project&#039;s Python API does not guarantee any compatibility. However, the Python API from pdf2zh will guarantee a certain level of compatibility.

You can refer to the example in [main.py](https://github.com/funstory-ai/yadt/blob/main/babeldoc/main.py) to use BabelDOC&#039;s Python API.

Please note:

1. Make sure call `babeldoc.high_level.init()` before using the API

2. The current `TranslationConfig` does not fully validate input parameters, so you need to ensure the validity of input parameters

3. For offline assets management, you can use the following functions:
   ```python
   # Generate an offline assets package
   from pathlib import Path
   import babeldoc.assets.assets
   
   # Generate package to a specific directory
   # path is optional, default is ~/.cache/babeldoc/assets/offline_assets_{hash}.zip
   babeldoc.assets.assets.generate_offline_assets_package(Path(&quot;/path/to/output/dir&quot;))
   
   # Restore from a package file
   # path is optional, default is ~/.cache/babeldoc/assets/offline_assets_{hash}.zip
   babeldoc.assets.assets.restore_offline_assets_package(Path(&quot;/path/to/offline_assets_package.zip&quot;))
   
   # You can also restore from a directory containing the offline assets package
   # The tool will automatically find the correct package file based on the hash
   babeldoc.assets.assets.restore_offline_assets_package(Path(&quot;/path/to/directory&quot;))
   ```

&gt; [!TIP]
&gt; 
&gt; 1. The offline assets package name cannot be modified because the file list hash is encoded in the name.
&gt; 2. When using in production environments, it&#039;s recommended to pre-generate the assets package and include it with your application distribution.
&gt; 3. The package verification ensures that all required assets are intact and match their expected checksums.

## Background

There are a lot projects and teams working on to make document editing and translating easier like:

- [mathpix](https://mathpix.com/)
- [Doc2X](https://doc2x.noedgeai.com/)
- [minerU](https://github.com/opendatalab/MinerU)
- [PDFMathTranslate](https://github.com/funstory-ai/yadt)

There are also some solutions to solve specific parts of the problem like:

- [layoutreader](https://github.com/microsoft/unilm/tree/master/layoutreader): the read order of the text block in a pdf
- [Surya](https://github.com/surya-is/surya): the structure of the pdf

This project hopes to promote a standard pipeline and interface to solve the problem.

In fact, there are two main stages of a PDF parser or translator:

- **Parsing**: A stage of parsing means to get the structure of the pdf such as text blocks, images, tables, etc.
- **Rendering**: A stage of rendering means to render the structure into a new pdf or other format.

For a service like mathpix, it will parse the pdf into a structure may be in a XML format, and then render them using a single column reader order as [layoutreader](https://github.com/microsoft/unilm/tree/master/layoutreader) does. The bad news is that the original structure lost.

Some people will use Adobe PDF Parser because it will generate a Word document and it keeps the original structure. But it is somewhat expensive.
And you know, a pdf or word document is not a good format for reading in mobile devices.

We offer an intermediate representation of the results from parser and can be rendered into a new pdf or other format. The pipeline is also a plugin-based system which everybody can add their new model, ocr, renderer, etc.

## Roadmap

- [ ] Add line support
- [ ] Add table support
- [ ] Add cross-page/cross-column paragraph support
- [ ] More advanced typesetting features
- [ ] Outline support
- [ ] ...

Our first 1.0 version goal is to finish a translation from [PDF Reference, Version 1.7](https://opensource.adobe.com/dc-acrobat-sdk-docs/pdfstandards/pdfreference1.7old.pdf) to the following language version:

- Simplified Chinese
- Traditional Chinese
- Japanese
- Spanish

And meet the following requirements:

- layout error less than 1%
- content loss less than 1%

## Known Issues

1. Parsing errors in the author and reference sections; they get merged into one paragraph after translation.
2. Lines are not supported.
3. Does not support drop caps.
4. Large pages will be skipped.

## How to Contribute

We encourage you to contribute to YADT! Please check out the [CONTRIBUTING](https://github.com/funstory-ai/yadt/blob/main/docs/CONTRIBUTING.md) guide.

Everyone interacting in YADT and its sub-projects&#039; codebases, issue trackers, chat rooms, and mailing lists is expected to follow the YADT [Code of Conduct](https://github.com/funstory-ai/yadt/blob/main/docs/CODE_OF_CONDUCT.md).

[Immersive Translation](https://immersivetranslate.com) sponsors monthly Pro membership redemption codes for active contributors to this project, see details at: [CONTRIBUTOR_REWARD.md](https://github.com/funstory-ai/BabelDOC/blob/main/docs/CONTRIBUTOR_REWARD.md)

## Acknowledgements

- [PDFMathTranslate](https://github.com/Byaidu/PDFMathTranslate)
- [DocLayout-YOLO](https://github.com/opendatalab/DocLayout-YOLO)
- [pdfminer](https://github.com/pdfminer/pdfminer.six)
- [PyMuPDF](https://github.com/pymupdf/PyMuPDF)
- [Asynchronize](https://github.com/multimeric/Asynchronize/tree/master?tab=readme-ov-file)
- [PriorityThreadPoolExecutor](https://github.com/oleglpts/PriorityThreadPoolExecutor)

&lt;h2 id=&quot;star_hist&quot;&gt;Star History&lt;/h2&gt;

&lt;a href=&quot;https://star-history.com/#funstory-ai/babeldoc&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=funstory-ai/babeldoc&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=funstory-ai/babeldoc&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=funstory-ai/babeldoc&amp;type=Date&quot;/&gt;
 &lt;/picture&gt;
&lt;/a&gt;</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Pennyw0rth/NetExec]]></title>
            <link>https://github.com/Pennyw0rth/NetExec</link>
            <guid>https://github.com/Pennyw0rth/NetExec</guid>
            <pubDate>Tue, 15 Apr 2025 00:04:37 GMT</pubDate>
            <description><![CDATA[The Network Execution Tool]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Pennyw0rth/NetExec">Pennyw0rth/NetExec</a></h1>
            <p>The Network Execution Tool</p>
            <p>Language: Python</p>
            <p>Stars: 3,904</p>
            <p>Forks: 443</p>
            <p>Stars today: 58 stars today</p>
            <h2>README</h2><pre>![Supported Python versions](https://img.shields.io/badge/python-3.10+-blue.svg)
[![Twitter](https://img.shields.io/twitter/follow/al3xn3ff?label=al3x_n3ff&amp;style=social)](https://twitter.com/intent/follow?screen_name=al3x_n3ff)
[![Twitter](https://img.shields.io/twitter/follow/_zblurx?label=_zblurx&amp;style=social)](https://twitter.com/intent/follow?screen_name=_zblurx)
[![Twitter](https://img.shields.io/twitter/follow/MJHallenbeck?label=MJHallenbeck&amp;style=social)](https://twitter.com/intent/follow?screen_name=MJHallenbeck)
[![Twitter](https://img.shields.io/twitter/follow/mpgn_x64?label=mpgn_x64&amp;style=social)](https://twitter.com/intent/follow?screen_name=mpgn_x64)


ğŸš© This is the open source repository of NetExec maintained by a community of passionate people
# NetExec - The Network Execution Tool

This project was initially created in 2015 by @byt3bl33d3r, known as CrackMapExec. In 2019 @mpgn_x64 started maintaining the project for the next 4 years, adding a lot of great tools and features. In September 2023 he retired from maintaining the project.

Along with many other contributors, we (NeffIsBack, Marshall-Hallenbeck, and zblurx) developed new features, bug fixes, and helped maintain the original project CrackMapExec.
During this time, with both a private and public repository, community contributions were not easily merged into the project. The 6-8 month discrepancy between the code bases caused many development issues and heavily reduced community-driven development.
With the end of mpgn&#039;s maintainer role, we (the remaining most active contributors) decided to maintain the project together as a fully free and open source project under the new name **NetExec** ğŸš€
Going forward, our intent is to maintain a community-driven and maintained project with regular updates for everyone to use.

&lt;p align=&quot;center&quot;&gt;
  &lt;!-- placeholder for nxc logo--&gt;
&lt;/p&gt;

You are on the **latest up-to-date** repository of the project NetExec (nxc) ! ğŸ‰

- ğŸš§ If you want to report a problem, open an [Issue](https://github.com/Pennyw0rth/NetExec/issues) 
- ğŸ”€ If you want to contribute, open a [Pull Request](https://github.com/Pennyw0rth/NetExec/pulls)
- ğŸ’¬ If you want to discuss, open a [Discussion](https://github.com/Pennyw0rth/NetExec/discussions)

## Official Discord Channel

If you don&#039;t have a Github account, you can ask your questions on Discord!

[![NetExec](https://discordapp.com/api/guilds/1148685154601160794/widget.png?style=banner3)](https://discord.gg/pjwUTQzg8R)

# Documentation, Tutorials, Examples
See the project&#039;s [wiki](https://netexec.wiki/) (in development) for documentation and usage examples

# Installation
Please see the installation instructions on the [wiki](https://netexec.wiki/getting-started/installation) (in development)

## Linux
```
sudo apt install pipx git
pipx ensurepath
pipx install git+https://github.com/Pennyw0rth/NetExec
```

## Availability on Unix distributions

[![Packaging status](https://repology.org/badge/vertical-allrepos/netexec.svg)](https://repology.org/project/netexec/versions)

# Development
Development guidelines and recommendations in development

# Acknowledgments
All the hard work and development over the years from everyone in the CrackMapExec project

# Code Contributors
Awesome code contributors of NetExec:

[![](https://github.com/mpgn.png?size=50)](https://github.com/mpgn)
[![](https://github.com/Marshall-Hallenbeck.png?size=50)](https://github.com/Marshall-Hallenbeck)
[![](https://github.com/zblurx.png?size=50)](https://github.com/zblurx)
[![](https://github.com/NeffIsBack.png?size=50)](https://github.com/NeffIsBack)
[![](https://github.com/Hackndo.png?size=50)](https://github.com/Hackndo)
[![](https://github.com/XiaoliChan.png?size=50)](https://github.com/XiaoliChan)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[freqtrade/freqtrade]]></title>
            <link>https://github.com/freqtrade/freqtrade</link>
            <guid>https://github.com/freqtrade/freqtrade</guid>
            <pubDate>Tue, 15 Apr 2025 00:04:36 GMT</pubDate>
            <description><![CDATA[Free, open source crypto trading bot]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/freqtrade/freqtrade">freqtrade/freqtrade</a></h1>
            <p>Free, open source crypto trading bot</p>
            <p>Language: Python</p>
            <p>Stars: 38,236</p>
            <p>Forks: 7,537</p>
            <p>Stars today: 234 stars today</p>
            <h2>README</h2><pre># ![freqtrade](https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade_poweredby.svg)

[![Freqtrade CI](https://github.com/freqtrade/freqtrade/actions/workflows/ci.yml/badge.svg?branch=develop)](https://github.com/freqtrade/freqtrade/actions/)
[![DOI](https://joss.theoj.org/papers/10.21105/joss.04864/status.svg)](https://doi.org/10.21105/joss.04864)
[![Coverage Status](https://coveralls.io/repos/github/freqtrade/freqtrade/badge.svg?branch=develop&amp;service=github)](https://coveralls.io/github/freqtrade/freqtrade?branch=develop)
[![Documentation](https://readthedocs.org/projects/freqtrade/badge/)](https://www.freqtrade.io)
[![Maintainability](https://api.codeclimate.com/v1/badges/5737e6d668200b7518ff/maintainability)](https://codeclimate.com/github/freqtrade/freqtrade/maintainability)

Freqtrade is a free and open source crypto trading bot written in Python. It is designed to support all major exchanges and be controlled via Telegram or webUI. It contains backtesting, plotting and money management tools as well as strategy optimization by machine learning.

![freqtrade](https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade-screenshot.png)

## Disclaimer

This software is for educational purposes only. Do not risk money which
you are afraid to lose. USE THE SOFTWARE AT YOUR OWN RISK. THE AUTHORS
AND ALL AFFILIATES ASSUME NO RESPONSIBILITY FOR YOUR TRADING RESULTS.

Always start by running a trading bot in Dry-run and do not engage money
before you understand how it works and what profit/loss you should
expect.

We strongly recommend you to have coding and Python knowledge. Do not
hesitate to read the source code and understand the mechanism of this bot.

## Supported Exchange marketplaces

Please read the [exchange specific notes](docs/exchanges.md) to learn about eventual, special configurations needed for each exchange.

- [X] [Binance](https://www.binance.com/)
- [X] [Bitmart](https://bitmart.com/)
- [X] [BingX](https://bingx.com/invite/0EM9RX)
- [X] [Bybit](https://bybit.com/)
- [X] [Gate.io](https://www.gate.io/ref/6266643)
- [X] [HTX](https://www.htx.com/)
- [X] [Hyperliquid](https://hyperliquid.xyz/) (A decentralized exchange, or DEX)
- [X] [Kraken](https://kraken.com/)
- [X] [OKX](https://okx.com/)
- [X] [MyOKX](https://okx.com/) (OKX EEA)
- [ ] [potentially many others](https://github.com/ccxt/ccxt/). _(We cannot guarantee they will work)_

### Supported Futures Exchanges (experimental)

- [X] [Binance](https://www.binance.com/)
- [X] [Gate.io](https://www.gate.io/ref/6266643)
- [X] [Hyperliquid](https://hyperliquid.xyz/) (A decentralized exchange, or DEX)
- [X] [OKX](https://okx.com/)
- [X] [Bybit](https://bybit.com/)

Please make sure to read the [exchange specific notes](docs/exchanges.md), as well as the [trading with leverage](docs/leverage.md) documentation before diving in.

### Community tested

Exchanges confirmed working by the community:

- [X] [Bitvavo](https://bitvavo.com/)
- [X] [Kucoin](https://www.kucoin.com/)

## Documentation

We invite you to read the bot documentation to ensure you understand how the bot is working.

Please find the complete documentation on the [freqtrade website](https://www.freqtrade.io).

## Features

- [x] **Based on Python 3.10+**: For botting on any operating system - Windows, macOS and Linux.
- [x] **Persistence**: Persistence is achieved through sqlite.
- [x] **Dry-run**: Run the bot without paying money.
- [x] **Backtesting**: Run a simulation of your buy/sell strategy.
- [x] **Strategy Optimization by machine learning**: Use machine learning to optimize your buy/sell strategy parameters with real exchange data.
- [X] **Adaptive prediction modeling**: Build a smart strategy with FreqAI that self-trains to the market via adaptive machine learning methods. [Learn more](https://www.freqtrade.io/en/stable/freqai/)
- [x] **Edge position sizing** Calculate your win rate, risk reward ratio, the best stoploss and adjust your position size before taking a position for each specific market. [Learn more](https://www.freqtrade.io/en/stable/edge/).
- [x] **Whitelist crypto-currencies**: Select which crypto-currency you want to trade or use dynamic whitelists.
- [x] **Blacklist crypto-currencies**: Select which crypto-currency you want to avoid.
- [x] **Builtin WebUI**: Builtin web UI to manage your bot.
- [x] **Manageable via Telegram**: Manage the bot with Telegram.
- [x] **Display profit/loss in fiat**: Display your profit/loss in fiat currency.
- [x] **Performance status report**: Provide a performance status of your current trades.

## Quick start

Please refer to the [Docker Quickstart documentation](https://www.freqtrade.io/en/stable/docker_quickstart/) on how to get started quickly.

For further (native) installation methods, please refer to the [Installation documentation page](https://www.freqtrade.io/en/stable/installation/).

## Basic Usage

### Bot commands

```
usage: freqtrade [-h] [-V]
                 {trade,create-userdir,new-config,show-config,new-strategy,download-data,convert-data,convert-trade-data,trades-to-ohlcv,list-data,backtesting,backtesting-show,backtesting-analysis,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-markets,list-pairs,list-strategies,list-hyperoptloss,list-freqaimodels,list-timeframes,show-trades,test-pairlist,convert-db,install-ui,plot-dataframe,plot-profit,webserver,strategy-updater,lookahead-analysis,recursive-analysis}
                 ...

Free, open source crypto trading bot

positional arguments:
  {trade,create-userdir,new-config,show-config,new-strategy,download-data,convert-data,convert-trade-data,trades-to-ohlcv,list-data,backtesting,backtesting-show,backtesting-analysis,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-markets,list-pairs,list-strategies,list-hyperoptloss,list-freqaimodels,list-timeframes,show-trades,test-pairlist,convert-db,install-ui,plot-dataframe,plot-profit,webserver,strategy-updater,lookahead-analysis,recursive-analysis}
    trade               Trade module.
    create-userdir      Create user-data directory.
    new-config          Create new config
    show-config         Show resolved config
    new-strategy        Create new strategy
    download-data       Download backtesting data.
    convert-data        Convert candle (OHLCV) data from one format to
                        another.
    convert-trade-data  Convert trade data from one format to another.
    trades-to-ohlcv     Convert trade data to OHLCV data.
    list-data           List downloaded data.
    backtesting         Backtesting module.
    backtesting-show    Show past Backtest results
    backtesting-analysis
                        Backtest Analysis module.
    edge                Edge module.
    hyperopt            Hyperopt module.
    hyperopt-list       List Hyperopt results
    hyperopt-show       Show details of Hyperopt results
    list-exchanges      Print available exchanges.
    list-markets        Print markets on exchange.
    list-pairs          Print pairs on exchange.
    list-strategies     Print available strategies.
    list-hyperoptloss   Print available hyperopt loss functions.
    list-freqaimodels   Print available freqAI models.
    list-timeframes     Print available timeframes for the exchange.
    show-trades         Show trades.
    test-pairlist       Test your pairlist configuration.
    convert-db          Migrate database to different system
    install-ui          Install FreqUI
    plot-dataframe      Plot candles with indicators.
    plot-profit         Generate plot showing profits.
    webserver           Webserver module.
    strategy-updater    updates outdated strategy files to the current version
    lookahead-analysis  Check for potential look ahead bias.
    recursive-analysis  Check for potential recursive formula issue.

options:
  -h, --help            show this help message and exit
  -V, --version         show program&#039;s version number and exit
```

### Telegram RPC commands

Telegram is not mandatory. However, this is a great way to control your bot. More details and the full command list on the [documentation](https://www.freqtrade.io/en/latest/telegram-usage/)

- `/start`: Starts the trader.
- `/stop`: Stops the trader.
- `/stopentry`: Stop entering new trades.
- `/status &lt;trade_id&gt;|[table]`: Lists all or specific open trades.
- `/profit [&lt;n&gt;]`: Lists cumulative profit from all finished trades, over the last n days.
- `/forceexit &lt;trade_id&gt;|all`: Instantly exits the given trade (Ignoring `minimum_roi`).
- `/fx &lt;trade_id&gt;|all`: Alias to `/forceexit`
- `/performance`: Show performance of each finished trade grouped by pair
- `/balance`: Show account balance per currency.
- `/daily &lt;n&gt;`: Shows profit or loss per day, over the last n days.
- `/help`: Show help message.
- `/version`: Show version.

## Development branches

The project is currently setup in two main branches:

- `develop` - This branch has often new features, but might also contain breaking changes. We try hard to keep this branch as stable as possible.
- `stable` - This branch contains the latest stable release. This branch is generally well tested.
- `feat/*` - These are feature branches, which are being worked on heavily. Please don&#039;t use these unless you want to test a specific feature.

## Support

### Help / Discord

For any questions not covered by the documentation or for further information about the bot, or to simply engage with like-minded individuals, we encourage you to join the Freqtrade [discord server](https://discord.gg/p7nuUNVfP7).

### [Bugs / Issues](https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue)

If you discover a bug in the bot, please
[search the issue tracker](https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue)
first. If it hasn&#039;t been reported, please
[create a new issue](https://github.com/freqtrade/freqtrade/issues/new/choose) and
ensure you follow the template guide so that the team can assist you as
quickly as possible.

For every [issue](https://github.com/freqtrade/freqtrade/issues/new/choose) created, kindly follow up and mark satisfaction or reminder to close issue when equilibrium ground is reached.

--Maintain github&#039;s [community policy](https://docs.github.com/en/site-policy/github-terms/github-community-code-of-conduct)--

### [Feature Requests](https://github.com/freqtrade/freqtrade/labels/enhancement)

Have you a great idea to improve the bot you want to share? Please,
first search if this feature was not [already discussed](https://github.com/freqtrade/freqtrade/labels/enhancement).
If it hasn&#039;t been requested, please
[create a new request](https://github.com/freqtrade/freqtrade/issues/new/choose)
and ensure you follow the template guide so that it does not get lost
in the bug reports.

### [Pull Requests](https://github.com/freqtrade/freqtrade/pulls)

Feel like the bot is missing a feature? We welcome your pull requests!

Please read the
[Contributing document](https://github.com/freqtrade/freqtrade/blob/develop/CONTRIBUTING.md)
to understand the requirements before sending your pull-requests.

Coding is not a necessity to contribute - maybe start with improving the documentation?
Issues labeled [good first issue](https://github.com/freqtrade/freqtrade/labels/good%20first%20issue) can be good first contributions, and will help get you familiar with the codebase.

**Note** before starting any major new feature work, *please open an issue describing what you are planning to do* or talk to us on [discord](https://discord.gg/p7nuUNVfP7) (please use the #dev channel for this). This will ensure that interested parties can give valuable feedback on the feature, and let others know that you are working on it.

**Important:** Always create your PR against the `develop` branch, not `stable`.

## Requirements

### Up-to-date clock

The clock must be accurate, synchronized to a NTP server very frequently to avoid problems with communication to the exchanges.

### Minimum hardware required

To run this bot we recommend you a cloud instance with a minimum of:

- Minimal (advised) system requirements: 2GB RAM, 1GB disk space, 2vCPU

### Software requirements

- [Python &gt;= 3.10](http://docs.python-guide.org/en/latest/starting/installation/)
- [pip](https://pip.pypa.io/en/stable/installing/)
- [git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)
- [TA-Lib](https://ta-lib.github.io/ta-lib-python/)
- [virtualenv](https://virtualenv.pypa.io/en/stable/installation.html) (Recommended)
- [Docker](https://www.docker.com/products/docker) (Recommended)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[bregman-arie/devops-exercises]]></title>
            <link>https://github.com/bregman-arie/devops-exercises</link>
            <guid>https://github.com/bregman-arie/devops-exercises</guid>
            <pubDate>Tue, 15 Apr 2025 00:04:35 GMT</pubDate>
            <description><![CDATA[Linux, Jenkins, AWS, SRE, Prometheus, Docker, Python, Ansible, Git, Kubernetes, Terraform, OpenStack, SQL, NoSQL, Azure, GCP, DNS, Elastic, Network, Virtualization. DevOps Interview Questions]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bregman-arie/devops-exercises">bregman-arie/devops-exercises</a></h1>
            <p>Linux, Jenkins, AWS, SRE, Prometheus, Docker, Python, Ansible, Git, Kubernetes, Terraform, OpenStack, SQL, NoSQL, Azure, GCP, DNS, Elastic, Network, Virtualization. DevOps Interview Questions</p>
            <p>Language: Python</p>
            <p>Stars: 73,731</p>
            <p>Forks: 16,399</p>
            <p>Stars today: 237 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;images/devops_exercises.png&quot;/&gt;&lt;/p&gt;

:information_source: &amp;nbsp;This repo contains questions and exercises on various technical topics, sometimes related to DevOps and SRE

:bar_chart: &amp;nbsp;There are currently **2624** exercises and questions

:warning: &amp;nbsp;You can use these for preparing for an interview but most of the questions and exercises don&#039;t represent an actual interview. Please read [FAQ page](faq.md) for more details

:stop_sign: &amp;nbsp;If you are interested in pursuing a career as DevOps engineer, learning some of the concepts mentioned here would be useful, but you should know it&#039;s not about learning all the topics and technologies mentioned in this repository

:pencil: &amp;nbsp;You can add more exercises by submitting pull requests :) Read about contribution guidelines [here](CONTRIBUTING.md)

****

&lt;!-- ALL-TOPICS-LIST:START --&gt;
&lt;!-- prettier-ignore-start --&gt;
&lt;!-- markdownlint-disable --&gt;
&lt;center&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/devops/README.md&quot;&gt;&lt;img src=&quot;images/devops.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;DevOps&quot; /&gt;&lt;br /&gt;&lt;b&gt;DevOps&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/git/README.md&quot;&gt;&lt;img src=&quot;images/git.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Git&quot;/&gt;&lt;br /&gt;&lt;b&gt;Git&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#network&quot;&gt;&lt;img src=&quot;images/network.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Network&quot;/&gt;&lt;br /&gt;&lt;b&gt;Network&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#hardware&quot;&gt;&lt;img src=&quot;images/hardware.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Hardware&quot;/&gt;&lt;br /&gt;&lt;b&gt;Hardware&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/kubernetes/README.md&quot;&gt;&lt;img src=&quot;images/kubernetes.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;kubernetes&quot;/&gt;&lt;br /&gt;&lt;b&gt;Kubernetes&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/software_development/README.md&quot;&gt;&lt;img src=&quot;images/programming.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;programming&quot;/&gt;&lt;br /&gt;&lt;b&gt;Software Development&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/bregman-arie/python-exercises&quot;&gt;&lt;img src=&quot;images/python.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Python&quot;/&gt;&lt;br /&gt;&lt;b&gt;Python&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/bregman-arie/go-exercises&quot;&gt;&lt;img src=&quot;images/Go.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;go&quot;/&gt;&lt;br /&gt;&lt;b&gt;Go&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/perl/README.md&quot;&gt;&lt;img src=&quot;images/perl.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;perl&quot;/&gt;&lt;br /&gt;&lt;b&gt;Perl&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#regex&quot;&gt;&lt;img src=&quot;images/regex.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;RegEx&quot;/&gt;&lt;br /&gt;&lt;b&gt;Regex&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/cloud/README.md&quot;&gt;&lt;img src=&quot;images/cloud.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Cloud&quot;/&gt;&lt;br /&gt;&lt;b&gt;Cloud&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/aws/README.md&quot;&gt;&lt;img src=&quot;images/aws.png&quot; width=&quot;100px;&quot; height=&quot;75px;&quot; alt=&quot;aws&quot;/&gt;&lt;br /&gt;&lt;b&gt;AWS&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/azure/README.md&quot;&gt;&lt;img src=&quot;images/azure.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;azure&quot;/&gt;&lt;br /&gt;&lt;b&gt;Azure&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/gcp/README.md&quot;&gt;&lt;img src=&quot;images/googlecloud.png&quot; width=&quot;70px;&quot; height=&quot;70px;&quot; alt=&quot;Google Cloud Platform&quot;/&gt;&lt;br /&gt;&lt;b&gt;Google Cloud Platform&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#openstack/README.md&quot;&gt;&lt;img src=&quot;images/openstack.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;openstack&quot;/&gt;&lt;br /&gt;&lt;b&gt;OpenStack&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#operating-system&quot;&gt;&lt;img src=&quot;images/os.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Operating System&quot;/&gt;&lt;br /&gt;&lt;b&gt;Operating System&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/linux/README.md&quot;&gt;&lt;img src=&quot;images/logos/linux.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Linux&quot;/&gt;&lt;br /&gt;&lt;b&gt;Linux&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#virtualization&quot;&gt;&lt;img src=&quot;images/virtualization.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Virtualization&quot;/&gt;&lt;br /&gt;&lt;b&gt;Virtualization&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/dns/README.md&quot;&gt;&lt;img src=&quot;images/dns.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;DNS&quot;/&gt;&lt;br /&gt;&lt;b&gt;DNS&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/shell/README.md&quot;&gt;&lt;img src=&quot;images/bash.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Bash&quot;/&gt;&lt;br /&gt;&lt;b&gt;Shell Scripting&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/databases/README.md&quot;&gt;&lt;img src=&quot;images/databases.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Databases&quot;/&gt;&lt;br /&gt;&lt;b&gt;Databases&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#sql&quot;&gt;&lt;img src=&quot;images/sql.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;sql&quot;/&gt;&lt;br /&gt;&lt;b&gt;SQL&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#mongo&quot;&gt;&lt;img src=&quot;images/mongo.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Mongo&quot;/&gt;&lt;br /&gt;&lt;b&gt;Mongo&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#testing&quot;&gt;&lt;img src=&quot;images/testing.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Testing&quot;/&gt;&lt;br /&gt;&lt;b&gt;Testing&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#big-data&quot;&gt;&lt;img src=&quot;images/big-data.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Big Data&quot;/&gt;&lt;br /&gt;&lt;b&gt;Big Data&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;

  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/cicd/README.md&quot;&gt;&lt;img src=&quot;images/cicd.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;cicd&quot;/&gt;&lt;br /&gt;&lt;b&gt;CI/CD&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#certificates&quot;&gt;&lt;img src=&quot;images/certificates.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Certificates&quot;/&gt;&lt;br /&gt;&lt;b&gt;Certificates&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/containers/README.md&quot;&gt;&lt;img src=&quot;images/containers.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Containers&quot;/&gt;&lt;br /&gt;&lt;b&gt;Containers&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/openshift/README.md&quot;&gt;&lt;img src=&quot;images/openshift.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;OpenShift&quot;/&gt;&lt;br /&gt;&lt;b&gt;OpenShift&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#storage&quot;&gt;&lt;img src=&quot;images/storage.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Storage&quot;/&gt;&lt;br /&gt;&lt;b&gt;Storage&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/terraform/README.md&quot;&gt;&lt;img src=&quot;images/terraform.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Terraform&quot;/&gt;&lt;br /&gt;&lt;b&gt;Terraform&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#puppet&quot;&gt;&lt;img src=&quot;images/puppet.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;puppet&quot;/&gt;&lt;br /&gt;&lt;b&gt;Puppet&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#distributed&quot;&gt;&lt;img src=&quot;images/distributed.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Distributed&quot;/&gt;&lt;br /&gt;&lt;b&gt;Distributed&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#questions-you-ask&quot;&gt;&lt;img src=&quot;images/you.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;you&quot;/&gt;&lt;br /&gt;&lt;b&gt;Questions you can ask&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/ansible/README.md&quot;&gt;&lt;img src=&quot;images/ansible.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;ansible&quot;/&gt;&lt;br /&gt;&lt;b&gt;Ansible&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/observability/README.md&quot;&gt;&lt;img src=&quot;images/observability.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;observability&quot;/&gt;&lt;br /&gt;&lt;b&gt;Observability&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#prometheus&quot;&gt;&lt;img src=&quot;images/prometheus.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Prometheus&quot;/&gt;&lt;br /&gt;&lt;b&gt;Prometheus&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/circleci/README.md&quot;&gt;&lt;img src=&quot;images/logos/circleci.png&quot; width=&quot;70px;&quot; height=&quot;70px;&quot; alt=&quot;Circle CI&quot;/&gt;&lt;br /&gt;&lt;b&gt;Circle CI&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/datadog/README.md&quot;&gt;&lt;img src=&quot;images/logos/datadog.png&quot; width=&quot;80px;&quot; height=&quot;80px;&quot; alt=&quot;DataDog&quot;/&gt;&lt;br /&gt;&lt;b&gt;&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/grafana/README.md&quot;&gt;&lt;img src=&quot;images/logos/grafana.png&quot; width=&quot;80px;&quot; height=&quot;80px;&quot; alt=&quot;Grafana&quot;/&gt;&lt;br /&gt;&lt;b&gt;Grafana&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/argo/README.md&quot;&gt;&lt;img src=&quot;images/logos/argo.png&quot; width=&quot;80px;&quot; height=&quot;80px;&quot; alt=&quot;Argo&quot;/&gt;&lt;br /&gt;&lt;b&gt;Argo&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/soft_skills/README.md&quot;&gt;&lt;img src=&quot;images/HR.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;HR&quot;/&gt;&lt;br /&gt;&lt;b&gt;Soft Skills&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/security/README.md&quot;&gt;&lt;img src=&quot;images/security.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;security&quot;/&gt;&lt;br /&gt;&lt;b&gt;Security&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#system-design&quot;&gt;&lt;img src=&quot;images/design.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Design&quot;/&gt;&lt;br /&gt;&lt;b&gt;System Design&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
   &lt;/tr&gt;

   &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/chaos_engineering/README.md&quot;&gt;&lt;img src=&quot;images/logos/chaos_engineering.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Chaos Engineering&quot;/&gt;&lt;br /&gt;&lt;b&gt;Chaos Engineering&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#Misc&quot;&gt;&lt;img src=&quot;images/general.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Misc&quot;/&gt;&lt;br /&gt;&lt;b&gt;Misc&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#elastic&quot;&gt;&lt;img src=&quot;images/elastic.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Elastic&quot;/&gt;&lt;br /&gt;&lt;b&gt;Elastic&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/kafka/README.md&quot;&gt;&lt;img src=&quot;images/logos/kafka.png&quot; width=&quot;85px;&quot; height=&quot;80px;&quot; alt=&quot;Kafka&quot;/&gt;&lt;br /&gt;&lt;b&gt;Kafka&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/node/node_questions_basic.md&quot;&gt;&lt;img src=&quot;images/nodejs.png&quot; width=&quot;85px;&quot; height=&quot;80px;&quot; alt=&quot;NodeJs&quot;/&gt;&lt;br /&gt;&lt;b&gt;NodeJs&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
   &lt;/tr&gt;
   
&lt;/table&gt;
&lt;/center&gt;
&lt;!-- markdownlint-enable --&gt;
&lt;!-- prettier-ignore-end --&gt;
&lt;!-- ALL-TOPICS-LIST:END --&gt;

## DevOps Applications

&lt;table&gt;
&lt;tr&gt;
  &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://play.google.com/store/apps/details?id=com.codingshell.kubeprep&quot;&gt;&lt;img src=&quot;images/apps/kubeprep.png&quot; width=&quot;200px;&quot; height=&quot;300px;&quot; alt=&quot;KubePrep&quot;/&gt;&lt;br /&gt;&lt;b&gt;KubePrep&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://play.google.com/store/apps/details?id=com.codingshell.linuxmaster&quot;&gt;&lt;img src=&quot;images/apps/linux_master.png&quot; width=&quot;200px;&quot; height=&quot;300px;&quot; alt=&quot;Linux Master&quot;/&gt;&lt;br /&gt;&lt;b&gt;Linux Master&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://play.google.com/store/apps/details?id=com.codingshell.system_design_hero&quot;&gt;&lt;img src=&quot;images/apps/system_design_hero.png&quot; width=&quot;200px;&quot; height=&quot;300px;&quot; alt=&quot;Sytem Design Hero&quot;/&gt;&lt;br /&gt;&lt;b&gt;System Design Hero&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;


## Network

&lt;details&gt;
&lt;summary&gt;In general, what do you need in order to communicate?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

  - A common language (for the two ends to understand)
  - A way to address who you want to communicate with
  - A Connection (so the content of the communication can reach the recipients)

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is TCP/IP?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

A set of protocols that define how two or more devices can communicate with each other.

To learn more about TCP/IP, read [here](http://www.penguintutor.com/linux/basic-network-reference)

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is Ethernet?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

Ethernet simply refers to the most common type of Local Area Network (LAN) used today. A LANâ€”in contrast to a WAN (Wide Area Network), which spans a larger geographical areaâ€”is a connected network of computers in a small area, like your office, college campus, or even home.

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is a MAC address? What is it used for?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

A MAC address is a unique identification number or code used to identify individual devices on the network.

Packets that are sent on the ethernet are always coming from a MAC address and sent to a MAC address. If a network adapter is receiving a packet, it is comparing the packetâ€™s destination MAC address to the adapterâ€™s own MAC address.

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;When is this MAC address used?: ff:ff:ff:ff:ff:ff&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

When a device sends a packet to the broadcast MAC address (FF:FF:FF:FF:FF:FFâ€‹), it is delivered to all stations on the local network. Ethernet broadcasts are used to resolve IP addresses to MAC addresses (by ARP) at the data link layer.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is an IP address?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

An Internet Protocol address (IP address) is a numerical label assigned to each device connected to a computer network that uses the Internet Protocol for communication.An IP address serves two main functions: host or network interface identification and location addressing.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Explain the subnet mask and give an example&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

A Subnet mask is a 32-bit number that masks an IP address and divides the IP addresses into network addresses and host addresses. Subnet Mask is made by setting network bits to all &quot;1&quot;s and setting host bits to all &quot;0&quot;s. Within a given network, out of the total usable host addresses, two are always reserved for specific purposes and cannot be allocated to any host. These are the first address, which is reserved as a network address (a.k.a network ID), and the last address used for network broadcast.

[Example](https://github.com/philemonnwanne/projects/tree/main/exercises/exe-09)

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is a private IP address? In which scenarios/system designs, one should use it?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;
Private IP addresses are assigned to the hosts in the same network to communicate with one another. As the name &quot;private&quot; suggests, the devices having the private IP addresses assigned can&#039;t be reached by the devices from any external network. For example, if I am living in a hostel and I want my hostel mates to join the game server I have hosted, I will ask them to join via my server&#039;s private IP address, since the network is local to the hostel.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is a public IP address? In which scenarios/system designs, one should use it?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;
A public IP address is a public-facing IP address. In the event that you were hosting a game server that you want your friends to join, you will give your friends your public IP address to allow their computers to identify and locate your network and server in order for the connection to take place. One time that you would not need to use a public-facing IP address is in the event that you were playing with friends who were connected to the same network as you, in that case, you would use a private IP address. In order for someone to be able to connect to your server that is located internally, you will have to set up a port forward to tell your router to allow traffic from the public domain into your network and vice versa.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Explain the OSI model. What layers there are? What each layer is responsible for?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

- Application: user end (HTTP is here)
- Presentation: establishes context between application-layer entities (Encryption is here)
- Session: establishes, manages, and terminates the connections
- Transport: transfers variable-length data sequences from a source to a destination host (TCP &amp; UDP are here)
- Network: transfers datagrams from one network to another (IP is here)
- Data link: provides a link between two directly connected nodes (MAC is here)
- Physical: the electrical and physical spec of the data connection (Bits are here)

You can read more about the OSI model in [penguintutor.com](http://www.penguintutor.com/linux/basic-network-reference)
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;For each of the following determines to which OSI layer it belongs:

  * Error correction
  * Packets routing
  * Cables and electrical signals
  * MAC address
  * IP address
  * Terminate connections
  * 3 way handshake&lt;/summary&gt;&lt;br&gt;&lt;b&gt;
  * Error correction - Data link
  * Packets routing - Network
  * Cables and electrical signals - Physical
  * MAC address - Data link
  * IP address - Network
  * Terminate connections - Session
  * 3-way handshake - Transport
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What delivery schemes are you familiar with?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

Unicast: One-to-one communication where there is one sender and one receiver.

Broadcast: Sending a message to everyone in the network. The address ff:ff:ff:ff:ff:ff is used for broadcasting.
           Two common protocols which use broadcast are ARP and DHCP.

Multicast: Sending a message to a group of subscribers. It can be one-to-many or many-to-many.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is CSMA/CD? Is it used in modern ethernet networks?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

CSMA/CD stands for Carrier Sense Multiple Access / Collision Detection.
Its primary focus is to manage access to a shared medium/bus where only one host can transmit at a given point in time.

CSMA/CD algorithm:

1. Before sending a frame, it checks whether another host is already transmitting a frame.
2. If no one is transmitting, it starts transmitting the frame.
3. If two hosts transmit at the same time, we have a collision.
4. Both hosts stop sending the frame and they send everyone a &#039;jam signal&#039; notifying everyone that a collision occurred
5. They are waiting for a random time before sending it again
6. Once each host waited for a random time, they try to send the frame again and so the cycle starts again
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Describe the following network devices and the difference between them:

  * router
  * switch
  * hub&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

A router, switch, and hub are all network devices used to connect devices in a local area network (LAN). However, each device operates differently and has its specific use cases. Here is a brief description of each device and the differences between them:

1. Router: a network device that connects multiple network segments together. It operates at theÂ network layer (Layer 3)Â of the OSI model and uses routing protocols to direct data between networks. Routers use IP addresses to identify devices and route data packets to the correct destination.
2. Switch: a network device that connects multiple devices on a LAN. It operates at theÂ data link layer (Layer 2)Â of the OSI model and uses MAC addresses to identify devices and direct data packets to the correct destination. Switches allow devices on the same network to communicate with each other more efficiently and can prevent data collisions that can occur when multiple devices send data simultaneously.
3. Hub: a network device that connects multiple devices through a single cable and is used to connect multiple devices without segmenting a network. However, unlike a switch, it operates at theÂ physical layer (Layer 1)Â of the OSI model and simply broadcasts data packets to all devices connected to it, regardless of whether the device is the intended recipient or not. This means that data collisions can occur, and the network&#039;s efficiency can suffer as a result. Hubs are generally not used in modern network setups, as switches are more efficient and provide better network performance.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is a &quot;Collision Domain&quot;?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;
A collision domain is a network segment in which devices can potentially interfere with each other by attempting to transmit data at the same time. When two devices transmit data at the same time, it can cause a collision, resulting in lost or corrupted data. In a collision domain, all devices share the same bandwidth, and any device can potentially interfere with the transmission of data by other devices.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is a &quot;Broadcast Domain&quot;?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;
A broadcast domain is a network segment in which all devices can communicate with each other by sending broadcast messages. A broadcast message is a message that is sent to all devices in a network rather than a specific device. In a broadcast domain, all devices can receive and process broadcast messages, regardless of whether the message was intended for them or not.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;three computers connected to a switch. How many collision domains are there? How many broadcast domains?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

Three collision domains and one broadcast domain
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;How does a router work?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

A router is a physical or virtual appliance that passes information between two or more packet-switched computer networks. A router inspects a given data packet&#039;s destination Internet Protocol address (IP address), calculates the best way for it to reach its destination, and then forwards it accordingly.

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is NAT?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

 Netw

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[nautechsystems/nautilus_trader]]></title>
            <link>https://github.com/nautechsystems/nautilus_trader</link>
            <guid>https://github.com/nautechsystems/nautilus_trader</guid>
            <pubDate>Tue, 15 Apr 2025 00:04:34 GMT</pubDate>
            <description><![CDATA[A high-performance algorithmic trading platform and event-driven backtester]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nautechsystems/nautilus_trader">nautechsystems/nautilus_trader</a></h1>
            <p>A high-performance algorithmic trading platform and event-driven backtester</p>
            <p>Language: Python</p>
            <p>Stars: 5,152</p>
            <p>Forks: 772</p>
            <p>Stars today: 55 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader-logo.png&quot; width=&quot;500&quot;&gt;

[![codecov](https://codecov.io/gh/nautechsystems/nautilus_trader/branch/master/graph/badge.svg?token=DXO9QQI40H)](https://codecov.io/gh/nautechsystems/nautilus_trader)
[![codspeed](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/nautechsystems/nautilus_trader)
![pythons](https://img.shields.io/pypi/pyversions/nautilus_trader)
![pypi-version](https://img.shields.io/pypi/v/nautilus_trader)
![pypi-format](https://img.shields.io/pypi/format/nautilus_trader?color=blue)
[![Downloads](https://pepy.tech/badge/nautilus-trader)](https://pepy.tech/project/nautilus-trader)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/NautilusTrader)

| Branch    | Version                                                                                                                                                                                                                     | Status                                                                                                                                                                                            |
| :-------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `master`  | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fmaster%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html)  | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)  |
| `nightly` | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fnightly%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html) | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |
| `develop` | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fdevelop%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html) | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=develop)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |

| Platform           | Rust    | Python     |
| :----------------- | :------ | :--------- |
| `Linux (x86_64)`   | 1.86.0+ | 3.11-3.13  |
| `Linux (ARM64)`    | 1.86.0+ | 3.11-3.13  |
| `macOS (ARM64)`    | 1.86.0+ | 3.11-3.13  |
| `Windows (x86_64)` | 1.86.0+ | 3.11-3.13  |

- **Docs**: https://nautilustrader.io/docs/
- **Website**: https://nautilustrader.io
- **Support**: [support@nautilustrader.io](mailto:support@nautilustrader.io)

## Introduction

NautilusTrader is an open-source, high-performance, production-grade algorithmic trading platform,
providing quantitative traders with the ability to backtest portfolios of automated trading strategies
on historical data with an event-driven engine, and also deploy those same strategies live, with no code changes.

The platform is *AI-first*, designed to develop and deploy algorithmic trading strategies within a highly performant
and robust Python-native environment. This helps to address the parity challenge of keeping the Python research/backtest
environment consistent with the production live trading environment.

NautilusTrader&#039;s design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting Python-native, mission-critical, trading system backtesting
and live deployment workloads.

The platform is also universal, and asset-class-agnostic â€”  with any REST API or WebSocket feed able to be integrated via modular
adapters. It supports high-frequency trading across a wide range of asset classes and instrument types
including FX, Equities, Futures, Options, Crypto and Betting, enabling seamless operations across multiple venues simultaneously.

![nautilus-trader](https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader.png &quot;nautilus-trader&quot;)

## Features

- **Fast**: Core is written in Rust with asynchronous networking using [tokio](https://crates.io/crates/tokio).
- **Reliable**: Type safety and thread safety through Rust. [Redis](https://redis.io)-backed performant state persistence (optional).
- **Portable**: OS independent, runs on Linux, macOS, and Windows. Deploy using Docker.
- **Flexible**: Modular adapters mean any REST API or WebSocket feed can be integrated.
- **Advanced**: Time in force `IOC`, `FOK`, `GTC`, `GTD`, `DAY`, `AT_THE_OPEN`, `AT_THE_CLOSE`, advanced order types and conditional triggers. Execution instructions `post-only`, `reduce-only`, and icebergs. Contingency orders including `OCO`, `OUO`, `OTO`.
- **Customizable**: Add user-defined custom components, or assemble entire systems from scratch leveraging the [cache](https://nautilustrader.io/docs/latest/concepts/cache) and [message bus](https://nautilustrader.io/docs/latest/concepts/message_bus).
- **Backtesting**: Run with multiple venues, instruments and strategies simultaneously using historical quote tick, trade tick, bar, order book and custom data with nanosecond resolution.
- **Live**: Use identical strategy implementations between backtesting and live deployments.
- **Multi-venue**: Multiple venue capabilities facilitate market-making and statistical arbitrage strategies.
- **AI Training**: Backtest engine fast enough to be used to train AI trading agents (RL/ES).

![Alt text](https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-art.png &quot;nautilus&quot;)

&gt; _nautilus - from ancient Greek &#039;sailor&#039; and naus &#039;ship&#039;._
&gt;
&gt; _The nautilus shell consists of modular chambers with a growth factor which approximates a logarithmic spiral.
&gt; The idea is that this can be translated to the aesthetics of design and architecture._

## Why NautilusTrader?

- **Highly performant event-driven Python**: Native binary core components.
- **Parity between backtesting and live trading**: Identical strategy code.
- **Reduced operational risk**: Enhanced risk management functionality, logical accuracy, and type safety.
- **Highly extendable**: Message bus, custom components and actors, custom data, custom adapters.

Traditionally, trading strategy research and backtesting might be conducted in Python
using vectorized methods, with the strategy then needing to be reimplemented in a more event-driven way
using C++, C#, Java or other statically typed language(s). The reasoning here is that vectorized backtesting code cannot
express the granular time and event dependent complexity of real-time trading, where compiled languages have
proven to be more suitable due to their inherently higher performance, and type safety.

One of the key advantages of NautilusTrader here, is that this reimplementation step is now circumvented - as the critical core components of the platform
have all been written entirely in [Rust](https://www.rust-lang.org/) or [Cython](https://cython.org/).
This means we&#039;re using the right tools for the job, where systems programming languages compile performant binaries,
with CPython C extension modules then able to offer a Python-native environment, suitable for professional quantitative traders and trading firms.

## Why Python?

Python was originally created decades ago as a simple scripting language with a clean straightforward syntax.
It has since evolved into a fully fledged general purpose object-oriented programming language.
Based on the TIOBE index, Python is currently the most popular programming language in the world.
Not only that, Python has become the _de facto lingua franca_ of data science, machine learning, and artificial intelligence.

The language out of the box is not without its drawbacks however, especially in the context of
implementing large performance-critical systems. Cython has addressed a lot of these issues, offering all the advantages
of a statically typed language, embedded into Python&#039;s rich ecosystem of software libraries and
developer/user communities.

## What is Rust?

[Rust](https://www.rust-lang.org/) is a multi-paradigm programming language designed for performance and safety, especially safe
concurrency. Rust is &quot;blazingly fast&quot; and memory-efficient (comparable to C and C++) with no garbage collector.
It can power mission-critical systems, run on embedded devices, and easily integrates with other languages.

Rustâ€™s rich type system and ownership model guarantees memory-safety and thread-safety deterministically â€”
eliminating many classes of bugs at compile-time.

The project increasingly utilizes Rust for core performance-critical components. Python language binding is handled through
Cython and [PyO3](https://pyo3.rs), with static libraries linked at compile-time before the wheel binaries are packaged, so a user
does not need to have Rust installed to run NautilusTrader.

This project makes the [Soundness Pledge](https://raphlinus.github.io/rust/2020/01/18/soundness-pledge.html):

&gt; â€œThe intent of this project is to be free of soundness bugs.
&gt; The developers will do their best to avoid them, and welcome help in analyzing and fixing them.â€

&gt; [!NOTE]
&gt;
&gt; **MSRV:** NautilusTrader relies heavily on improvements in the Rust language and compiler.
&gt; As a result, the Minimum Supported Rust Version (MSRV) is generally equal to the latest stable release of Rust.

## Integrations

NautilusTrader is modularly designed to work with _adapters_, enabling connectivity to trading venues
and data providers by translating their raw APIs into a unified interface and normalized domain model.

The following integrations are currently supported:

| Name                                                                         | ID                    | Type                    | Status                                                  | Docs                                                                            |
| :--------------------------------------------------------------------------- | :-------------------- | :---------------------- | :------------------------------------------------------ | :------------------------------------------------------------------------------ |
| [Betfair](https://betfair.com)                                               | `BETFAIR`             | Sports Betting Exchange | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/betfair.html)       |
| [Binance](https://binance.com)                                               | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/binance.html)       |
| [Binance US](https://binance.us)                                             | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/binance.html)       |
| [Binance Futures](https://www.binance.com/en/futures)                        | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/binance.html)       |
| [Bybit](https://www.bybit.com)                                               | `BYBIT`               | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/bybit.html)         |
| [Coinbase International](https://www.coinbase.com/en/international-exchange) | `COINBASE_INTX`       | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/beta-yellow)     | [Guide](https://nautilustrader.io/docs/nightly/integrations/coinbase_intx.html) |
| [Databento](https://databento.com)                                           | `DATABENTO`           | Data Provider           | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/databento.html)     |
| [dYdX](https://dydx.exchange/)                                               | `DYDX`                | Crypto Exchange (DEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/dydx.html)          |
| [Interactive Brokers](https://www.interactivebrokers.com)                    | `INTERACTIVE_BROKERS` | Brokerage (multi-venue) | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/ib.html)            |
| [OKX](https://okx.com)                                                       | `OKX`                 | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/building-orange) | [Guide](https://nautilustrader.io/docs/nightly/integrations/okx.html)           |
| [Polymarket](https://polymarket.com)                                         | `POLYMARKET`          | Prediction Market (DEX) | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/polymarket.html)    |
| [Tardis](https://tardis.dev)                                                 | `TARDIS`              | Crypto Data Provider    | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/tardis.html)        |

- **ID**: The default client ID for the integrations adapter clients.
- **Type**: The type of integration (often the venue type).

### Status
- `building`: Under construction and likely not in a usable state.
- `beta`: Completed to a minimally working state and in a beta testing phase.
- `stable`: Stabilized feature set and API, the integration has been tested by both developers and users to a reasonable level (some bugs may still remain).

See the [Integrations](https://nautilustrader.io/docs/latest/integrations/index.html) documentation for further details.

## Versioning and releases

**NautilusTrader is still under active development**. Some features may be incomplete, and while
the API is becoming more stable, breaking changes can occur between releases.
We strive to document these changes in the release notes on a **best-effort basis**.

We aim to follow a **bi-weekly release schedule**, though experimental or larger features may cause delays.

### Branches

We aim to maintain a stable, passing build across all branches.

- `master`: Reflects the source code for the latest released version.
- `nightly`: Includes experimental and in-progress features, merged from the `develop` branch daily at **14:00 UTC** and also when required.
- `develop`: The most active branch, frequently updated with new commits, including experimental and in-progress features.

&gt; [!NOTE]
&gt;
&gt; Our [roadmap](/ROADMAP.md) aims to achieve a **stable API for version 2.x** (likely after the Rust port).
&gt; Once this milestone is reached, we plan to implement a formal deprecation process for any API changes.
&gt; This approach allows us to maintain a rapid development pace for now.

## Precision mode

NautilusTrader supports two precision modes for its core value types (`Price`, `Quantity`, `Money`),
which differ in their internal bit-width and maximum decimal precision.

- **High-precision**: 128-bit integers with up to 16 decimals of precision, and a larger value range.
- **Standard-precision**: 64-bit integers with up to 9 decimals of precision, and a smaller value range.

&gt; [!NOTE]
&gt;
&gt; By default, the official Python wheels **ship** in high-precision (128-bit) mode on Linux and macOS.
&gt; On Windows, only standard-precision (64-bit) is available due to the lack of native 128-bit integer support.
&gt; For the Rust crates, the default is standard-precision unless you explicitly enable the `high-precision` feature flag.

See the [Installation Guide](https://nautilustrader.io/docs/latest/getting_started/installation) for further details.

## Installation

### From PyPI

We recommend using the latest supported version of Python and setting up [nautilus_trader](https://pypi.org/project/nautilus_trader/) in a virtual environment to isolate dependencies.

To install the latest binary wheel (or sdist package) from PyPI using Python&#039;s pip package manager:

    pip install -U nautilus_trader

### From the Nautech Systems package index

The Nautech Systems package index (`packages.nautechsystems.io`) is [PEP-503](https://peps.python.org/pep-0503/) compliant and hosts both stable and development binary wheels for `nautilus_trader`.
This enables users to install either the latest stable release or pre-release versions for testing.

#### Stable wheels

Stable wheels correspond to official releases of `nautilus_trader` on PyPI, and use standard versioning.

To install the latest stable release:

    pip install -U nautilus_trader --index-url=https://packages.nautechsystems.io/simple

#### Development wheels

Development wheels are published from both the `nightly` and `develop` branches,
allowing users to test features and fixes ahead of stable releases.

**Note**: Wheels from the `develop` branch are only built for the Linux x86_64 platform to save time
and compute resources, while `nightly` wheels support additional platforms as shown below.

| Platform           | Nightly | Develop |
| :----------------- | :------ | :------ |
| `Linux (x86_64)`   | âœ“       | âœ“       |
| `Linux (ARM64)`    | âœ“       | -       |
| `macOS (ARM64)`    | âœ“       | -       |
| `Windows (x86_64)` | âœ“       | -       |

This process also helps preserve compute resources and ensures easy access to the exact binaries tested in CI pipelines,
while adhering to [PEP-440](https://peps.python.org/pep-0440/) versioning standards:

- `develop` wheels use the version format `dev{date}+{build_number}` (e.g., `1.208.0.dev20241212+7001`).
- `nightly` wheels use the version format `a{date}` (alpha) (e.g., `1.208.0a20241212`).

&gt; [!WARNING]
&gt;
&gt; We don&#039;t recommend using development wheels in production environments, such as live trading controlling real capital.

#### Installation commands

By default, pip installs the latest stable release. Adding the `--pre` flag ensures that pre-release versions, including development wheels, are considered.

To install the latest available pre-release (including development wheels):

    pip install -U nautilus_trader --pre --index-url=https://packages.nautechsystems.io/simple

To install a specific development wheel (e.g., `1.208.0a20241212` for December 12, 2024):

    pip install nautilus_trader==1.208.0a20241212 --index-url=https://packages.nautechsystems.io/simple

#### Available versions

You can view all available versions of `nautilus_trader` on the [package index](https://packages.nautechsystems.io/simple/nautilus-trader/index.html).

To programmatically fetch and list available versions:

    curl -s https://packages.nautechsystems.io/simple/nautilus-trader/index.html | grep -oP &#039;(?&lt;=&lt;a href=&quot;)[^&quot;]+(?=&quot;)&#039; | awk -F&#039;#&#039; &#039;{print $1}&#039; | sort

#### Branch updates

- `develop` branch wheels (`.dev`): Are built and published continuously with every merged commit.
- `nightly` b

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[xaoyaoo/PyWxDump]]></title>
            <link>https://github.com/xaoyaoo/PyWxDump</link>
            <guid>https://github.com/xaoyaoo/PyWxDump</guid>
            <pubDate>Tue, 15 Apr 2025 00:04:33 GMT</pubDate>
            <description><![CDATA[è·å–å¾®ä¿¡ä¿¡æ¯ï¼›è¯»å–æ•°æ®åº“ï¼Œæœ¬åœ°æŸ¥çœ‹èŠå¤©è®°å½•å¹¶å¯¼å‡ºä¸ºcsvã€htmlç­‰æ ¼å¼ç”¨äºAIè®­ç»ƒï¼Œè‡ªåŠ¨å›å¤ç­‰ã€‚æ”¯æŒå¤šè´¦æˆ·ä¿¡æ¯è·å–ï¼Œæ”¯æŒæ‰€æœ‰å¾®ä¿¡ç‰ˆæœ¬ã€‚]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/xaoyaoo/PyWxDump">xaoyaoo/PyWxDump</a></h1>
            <p>è·å–å¾®ä¿¡ä¿¡æ¯ï¼›è¯»å–æ•°æ®åº“ï¼Œæœ¬åœ°æŸ¥çœ‹èŠå¤©è®°å½•å¹¶å¯¼å‡ºä¸ºcsvã€htmlç­‰æ ¼å¼ç”¨äºAIè®­ç»ƒï¼Œè‡ªåŠ¨å›å¤ç­‰ã€‚æ”¯æŒå¤šè´¦æˆ·ä¿¡æ¯è·å–ï¼Œæ”¯æŒæ‰€æœ‰å¾®ä¿¡ç‰ˆæœ¬ã€‚</p>
            <p>Language: Python</p>
            <p>Stars: 6,859</p>
            <p>Forks: 1,086</p>
            <p>Stars today: 36 stars today</p>
            <h2>README</h2><pre>[![ä¸­æ–‡](https://img.shields.io/badge/README-ä¸­æ–‡-494cad.svg)](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/README_CN.md) [![English](https://img.shields.io/badge/README-English-494cad.svg)](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/README_EN.md)

# &lt;center&gt;PyWxDump&lt;/center&gt;

[![Python](https://img.shields.io/badge/Python-3-blue.svg)](https://www.python.org/)
[![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/xaoyaoo/pywxdump)](https://github.com/xaoyaoo/PyWxDump)
[![GitHub all releases](https://img.shields.io/github/downloads/xaoyaoo/pywxdump/total)](https://github.com/xaoyaoo/PyWxDump)
[![GitHub stars](https://img.shields.io/github/stars/xaoyaoo/PyWxDump.svg)](https://github.com/xaoyaoo/PyWxDump)
[![GitHub forks](https://img.shields.io/github/forks/xaoyaoo/PyWxDump.svg)](https://github.com/xaoyaoo/PyWxDump/fork)
[![GitHub issues](https://img.shields.io/github/issues/xaoyaoo/PyWxDump)](https://github.com/xaoyaoo/PyWxDump/issues)

[![PyPI](https://img.shields.io/pypi/v/pywxdump)](https://pypi.org/project/pywxdump/)
[![Wheel](https://img.shields.io/pypi/wheel/pywxdump)](https://pypi.org/project/pywxdump/)
[![PyPI-Downloads](https://img.shields.io/pypi/dm/pywxdump)](https://pypistats.org/packages/pywxdump)
[![GitHub license](https://img.shields.io/pypi/l/pywxdump)](https://github.com/xaoyaoo/PyWxDump/blob/master/LICENSE)

* Welcome to provide more ideas or code to improve this project together.

### If you are a novice, please pay attention to the Official Accounts: `é€é¥ä¹‹èŠ¯` (the QR code is below), and reply: `PyWxDump` to get a picture text tutorial.

### If you have any questions, please check first: [FAQ](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/FAQ.md) Whether there is an answer, or follow the Official Accounts to reply: `FAQ`.

QQ GROUPï¼š[276392799](https://s.xaoyo.top/gOLUDl) or [276392799](https://s.xaoyo.top/bgNcRa)ï¼ˆPASSWORD,please read:[UserGuide.md](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/UserGuide.md)ï¼‰.

&lt;div&gt;
  &lt;img align=&quot;&quot; width=&quot;200&quot;  src=&quot;https://github.com/xaoyaoo/PyWxDump/blob/master/doc/img/qrcode_gh.jpg&quot; alt=&quot;the Official Accounts&quot; title=&quot;the Official Accounts&quot; height=&quot;200&quot;/&gt;
&lt;/div&gt;

# I. Project Introduction

## 1. Brief Introduction

[PyWxDump](https://github.com/xaoyaoo/PyWxDump) is a tool for obtaining wx account information (nicknames/accounts/phones/emails/database keys), decrypting databases, viewing wx chat, and exporting chat as html backups.

* &lt;strong&gt;&lt;big&gt;Super eager for stars, if you&#039;ve come across this project, please give me a [![Star](https://img.shields.io/github/stars/xaoyaoo/PyWxDump.svg?style=social&amp;label=Star)](https://github.com/xaoyaoo/PyWxDump/)! Thank you so much~ &lt;/big&gt;&lt;/strong&gt;

## 2. Feature

#### 2.1 Core

* (1) Get the **base address offset
  ** of WeChat nickname, WeChat account, WeChat phone number, WeChat email, and WeChat KEY
* (2) Get the WeChat nickname, WeChat account, WeChat phone number, WeChat email, WeChat KEY, WeChat original ID (wxid_******), and WeChat folder path of the currently logged-in WeChat
* (3) Decrypt WeChat database based on key
* (4) Combine multiple types of databases for unified viewing

#### 2.2 Extend Function

* (1) View chat history through the web
* (2) Support exporting chat logs as html, csv, and backing up WeChat chat logs
* (3) Remote viewing of WeChat chat history (must be network accessible, such as a local area network)

#### 2.3 Document Class

* (1) Provide descriptions of some fields in the database
* (2) Provide CE to obtain the base address offset method
* (3) Provide a decryption method for MAC database

#### 2.4 Other functions

* (1) Added a minimalist version of [pywxdumpmini](https://github.com/xaoyaoo/pywxdumpmini), which provides only the ability to obtain database keys and database locations
* (2) Support multiple WeChat opening scenarios, obtain multiple user information, etc.

**Utilize the scene**

1. Network security...
2. Daily backup archiving
3. View chat history remotely (view chat history through the web)
4. Wait...............

## 3. Update plan

* 1.Analyze chat logs of each person and generate word clouds.
* ~~2.Analyze the number of chats per person per day and generate a line chart (day-number of chats)~~
* ~~3.Analyze the monthly and annual chat volume of different people and generate a line chart~~
* ~~4.Generate annual visualization reports~~
* 8.Increase support for enterprise WeChat
* 12.Viewing and backing up of the circle of friends
* ~~13.Clean up WeChat storage space and reduce the space occupied by WeChat (hopefully by selecting a person or group and finding out the media files involved in the chat logs of this group, such as pictures, videos, files, voice recordings, etc., and selectively (such as time periods) or batch-wise clearing them from the computer&#039;s cache by group conversation.)~~
* 14.Automatically send messages to specified people through UI control

## 4. Other

[PyWxDump](https://github.com/xaoyaoo/PyWxDump) is a refactored python language version of [SharpWxDump](https://github.com/AdminTest0/SharpWxDump), with many new features added.

* Project address: https://github.com/xaoyaoo/PyWxDump
* Currently tested only under Windows, there may be issues under mac and Linux.
* If you find any missing or incorrect information, bugs, or suggestions for improvement in the [WX_OFFS.json](https://github.com/xaoyaoo/PyWxDump/tree/master/pywxdump/WX_OFFS.json), please submit an issue on GitHub.
* For common issues, please refer to [FAQ](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/FAQ.md), and for the update log, please refer to [CHANGELOG](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/CHANGELOG.md)
* Web UI repository location [wxdump_web](https://github.com/xaoyaoo/wxdump_web )
* If you are interested in the implementation principle of wxdump, please pay attention to the Official Accounts: `é€é¥ä¹‹èŠ¯`, reply: `åŸç†` to get the principle analysis.
* [:sparkling\_heart: Support Me]( https://github.com/xaoyaoo/xaoyaoo/blob/main/donate.md)

## 5. Star History

&lt;details&gt;
&lt;summary&gt;click to expand&lt;/summary&gt;

[![Star History Chart](https://api.star-history.com/svg?repos=xaoyaoo/pywxdump&amp;type=Date)](https://star-history.com/#xaoyaoo/pywxdump&amp;Date)

&lt;/details&gt;

# â…¡. Instructions For Use

* Detailed instructions, see: [UserGuide.md](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/UserGuide.md)

* the minimalist version, see: [pywxdumpmini](https://github.com/xaoyaoo/pywxdumpmini)

* If you want to modify the UI, clone the [wx_dump_web](https://github.com/xaoyaoo/wxdump_web) and modify it as needed (the UI is developed using VUE+ElementUI)

ã€æ³¨ã€‘:

* For obtaining the base address using cheat engine, refer to [CE obtaining base address.md](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/CEè·å–åŸºå€.md)
  (This method can be replaced by the `wxdump bias` command, and is only used for learning principles.)
* For database parsing, refer to [wx database brief.md](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/wxæ•°æ®åº“ç®€è¿°.md)

# â…¢. Disclaimer (VERY VERY VERY IMPORTANT ! ! ! ! ! !)

### 1. Purpose of use

* This project is only for learning and communication purposes, **please do not use it for illegal purposes**, **please
  do not use it for illegal purposes**, **please do not use it for illegal purposes
  **, otherwise the consequences will be borne by yourself.
* Users understand and agree that any violation of laws and regulations, infringement of the legitimate rights and interests of others, is unrelated to this project and its developers, and the consequences are borne by the user themselves.

### 2. Usage Period

* You should delete the source code and (compiled) program of this project within 24 hours of downloading, saving, compiling, and using it; any use beyond this period is not related to this project or its developer.

### 3. Operation specifications

* This project only allows backup and viewing of the database under authorization. It is strictly prohibited for illegal purposes, otherwise all related responsibilities will be borne by the user. Any legal liability incurred by the user due to violation of this regulation will be borne by the user, and is unrelated to this project and its developer.
* It is strictly prohibited to use it to steal others&#039; privacy. Otherwise, all relevant responsibilities shall be borne by yourself.
* It is strictly prohibited to conduct secondary development, otherwise all related responsibilities shall be borne by yourself.

### 4. Acceptance of Disclaimer

* Downloading, saving, further browsing the source code, or downloading, installing, compiling, and using this program indicates that you agree with this warning and promise to abide by it;

### 5. Forbidden for illegal testing or penetration

* It is prohibited to use the relevant technologies of this project to engage in illegal testing or penetration, and it is prohibited to use the relevant codes or related technologies of this project to engage in any illegal work. Any adverse consequences arising therefrom are not related to this project and its developers.
* Any resulting adverse consequences, including but not limited to data leakage, system failure, and privacy infringement, are not related to this project or its developers and are the responsibility of the user.

### 6. Modification of disclaimer

* This disclaimer may be modified and adjusted based on the project&#039;s operating conditions and changes in laws and regulations. Users should regularly check this page for the latest version of the disclaimer, and should comply with the latest version of the disclaimer when using this project.

### 7. Others

* In addition to the provisions of this disclaimer, users should comply with relevant laws, regulations, and ethical norms during the use of this project. The project and its developers will not be held responsible for any disputes or losses caused by users&#039; violation of relevant regulations.

* Users are requested to carefully read and understand all contents of this disclaimer, and ensure that they strictly comply with relevant regulations when using this project.

# â…£. å…è´£å£°æ˜ï¼ˆéå¸¸é‡è¦ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼‰

### 1. ä½¿ç”¨ç›®çš„

* æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ äº¤æµä½¿ç”¨ï¼Œ**è¯·å‹¿ç”¨äºéæ³•ç”¨é€”**ï¼Œ**è¯·å‹¿ç”¨äºéæ³•ç”¨é€”**ï¼Œ**è¯·å‹¿ç”¨äºéæ³•ç”¨é€”**ï¼Œå¦åˆ™åæœè‡ªè´Ÿã€‚
* ç”¨æˆ·ç†è§£å¹¶åŒæ„ï¼Œä»»ä½•è¿åæ³•å¾‹æ³•è§„ã€ä¾µçŠ¯ä»–äººåˆæ³•æƒç›Šçš„è¡Œä¸ºï¼Œå‡ä¸æœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…æ— å…³ï¼Œåæœç”±ç”¨æˆ·è‡ªè¡Œæ‰¿æ‹…ã€‚

### 2. ä½¿ç”¨æœŸé™

* æ‚¨åº”è¯¥åœ¨ä¸‹è½½ä¿å­˜ï¼Œç¼–è¯‘ä½¿ç”¨æœ¬é¡¹ç›®çš„24å°æ—¶å†…ï¼Œåˆ é™¤æœ¬é¡¹ç›®çš„æºä»£ç å’Œï¼ˆç¼–è¯‘å‡ºçš„ï¼‰ç¨‹åºï¼›è¶…å‡ºæ­¤æœŸé™çš„ä»»ä½•ä½¿ç”¨è¡Œä¸ºï¼Œä¸€æ¦‚ä¸æœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…æ— å…³ã€‚

### 3. æ“ä½œè§„èŒƒ

* æœ¬é¡¹ç›®ä»…å…è®¸åœ¨æˆæƒæƒ…å†µä¸‹å¯¹æ•°æ®åº“è¿›è¡Œå¤‡ä»½ä¸æŸ¥çœ‹ï¼Œä¸¥ç¦ç”¨äºéæ³•ç›®çš„ï¼Œå¦åˆ™è‡ªè¡Œæ‰¿æ‹…æ‰€æœ‰ç›¸å…³è´£ä»»ï¼›ç”¨æˆ·å¦‚å› è¿åæ­¤è§„å®šè€Œå¼•å‘çš„ä»»ä½•æ³•å¾‹è´£ä»»ï¼Œå°†ç”±ç”¨æˆ·è‡ªè¡Œæ‰¿æ‹…ï¼Œä¸æœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…æ— å…³ã€‚
* ä¸¥ç¦ç”¨äºçªƒå–ä»–äººéšç§ï¼Œä¸¥ç¦ç”¨äºçªƒå–ä»–äººéšç§ï¼Œä¸¥ç¦ç”¨äºçªƒå–ä»–äººéšç§ï¼Œå¦åˆ™è‡ªè¡Œæ‰¿æ‹…æ‰€æœ‰ç›¸å…³è´£ä»»ã€‚
* ä¸¥ç¦è¿›è¡ŒäºŒæ¬¡å¼€å‘ï¼Œä¸¥ç¦è¿›è¡ŒäºŒæ¬¡å¼€å‘ï¼Œä¸¥ç¦è¿›è¡ŒäºŒæ¬¡å¼€å‘ï¼Œå¦åˆ™è‡ªè¡Œæ‰¿æ‹…æ‰€æœ‰ç›¸å…³è´£ä»»ã€‚

### 4. å…è´£å£°æ˜æ¥å—

* ä¸‹è½½ã€ä¿å­˜ã€è¿›ä¸€æ­¥æµè§ˆæºä»£ç æˆ–è€…ä¸‹è½½å®‰è£…ã€ç¼–è¯‘ä½¿ç”¨æœ¬ç¨‹åºï¼Œè¡¨ç¤ºä½ åŒæ„æœ¬è­¦å‘Šï¼Œå¹¶æ‰¿è¯ºéµå®ˆå®ƒ;

### 5. ç¦æ­¢ç”¨äºéæ³•æµ‹è¯•æˆ–æ¸—é€

* ç¦æ­¢åˆ©ç”¨æœ¬é¡¹ç›®çš„ç›¸å…³æŠ€æœ¯ä»äº‹éæ³•æµ‹è¯•æˆ–æ¸—é€ï¼Œç¦æ­¢åˆ©ç”¨æœ¬é¡¹ç›®çš„ç›¸å…³ä»£ç æˆ–ç›¸å…³æŠ€æœ¯ä»äº‹ä»»ä½•éæ³•å·¥ä½œï¼Œå¦‚å› æ­¤äº§ç”Ÿçš„ä¸€åˆ‡ä¸è‰¯åæœä¸æœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…æ— å…³ã€‚
* ä»»ä½•å› æ­¤äº§ç”Ÿçš„ä¸è‰¯åæœï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®æ³„éœ²ã€ç³»ç»Ÿç˜«ç—ªã€ä¾µçŠ¯éšç§ç­‰ï¼Œå‡ä¸æœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…æ— å…³ï¼Œè´£ä»»ç”±ç”¨æˆ·è‡ªè¡Œæ‰¿æ‹…ã€‚

### 6. å…è´£å£°æ˜ä¿®æ”¹

* æœ¬å…è´£å£°æ˜å¯èƒ½æ ¹æ®é¡¹ç›®è¿è¡Œæƒ…å†µå’Œæ³•å¾‹æ³•è§„çš„å˜åŒ–è¿›è¡Œä¿®æ”¹å’Œè°ƒæ•´ã€‚ç”¨æˆ·åº”å®šæœŸæŸ¥é˜…æœ¬é¡µé¢ä»¥è·å–æœ€æ–°ç‰ˆæœ¬çš„å…è´£å£°æ˜ï¼Œä½¿ç”¨æœ¬é¡¹ç›®æ—¶åº”éµå®ˆæœ€æ–°ç‰ˆæœ¬çš„å…è´£å£°æ˜ã€‚

### 7. å…¶ä»–

* é™¤æœ¬å…è´£å£°æ˜è§„å®šå¤–ï¼Œç”¨æˆ·åœ¨ä½¿ç”¨æœ¬é¡¹ç›®è¿‡ç¨‹ä¸­åº”éµå®ˆç›¸å…³çš„æ³•å¾‹æ³•è§„å’Œé“å¾·è§„èŒƒã€‚å¯¹äºå› ç”¨æˆ·è¿åç›¸å…³è§„å®šè€Œå¼•å‘çš„ä»»ä½•çº çº·æˆ–æŸå¤±ï¼Œæœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚

* è¯·ç”¨æˆ·æ…é‡é˜…è¯»å¹¶ç†è§£æœ¬å…è´£å£°æ˜çš„æ‰€æœ‰å†…å®¹ï¼Œç¡®ä¿åœ¨ä½¿ç”¨æœ¬é¡¹ç›®æ—¶ä¸¥æ ¼éµå®ˆç›¸å…³è§„å®šã€‚

# â…¤. Acknowledgments

[![PyWxDump CONTRIBUTORS](https://contrib.rocks/image?repo=xaoyaoo/PyWxDump)](https://github.com/xaoyaoo/PyWxDump/graphs/contributors)[![UI CONTRIBUTORS](https://contrib.rocks/image?repo=xaoyaoo/wxdump_web)](https://github.com/xaoyaoo/wxdump_web/graphs/contributors)

otherContributors:

[643104191](https://github.com/643104191) (add [ctypes_utils](https://github.com/xaoyaoo/PyWxDump/blob/9e3e4cb5aec2b9b445c8283d61c58863f4129c6e/pywxdump/wx_info/ctypes_utils.py), Accelerated the acquisition of wxinfo; [9e3e4cb](https://github.com/xaoyaoo/PyWxDump/commit/9e3e4cb5aec2b9b445c8283d61c58863f4129c6e))

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[AUTOMATIC1111/stable-diffusion-webui]]></title>
            <link>https://github.com/AUTOMATIC1111/stable-diffusion-webui</link>
            <guid>https://github.com/AUTOMATIC1111/stable-diffusion-webui</guid>
            <pubDate>Tue, 15 Apr 2025 00:04:32 GMT</pubDate>
            <description><![CDATA[Stable Diffusion web UI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">AUTOMATIC1111/stable-diffusion-webui</a></h1>
            <p>Stable Diffusion web UI</p>
            <p>Language: Python</p>
            <p>Stars: 151,214</p>
            <p>Forks: 28,138</p>
            <p>Stars today: 147 stars today</p>
            <h2>README</h2><pre># Stable Diffusion web UI
A web interface for Stable Diffusion, implemented using Gradio library.

![](screenshot.png)

## Features
[Detailed feature showcase with images](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features):
- Original txt2img and img2img modes
- One click install and run script (but you still must install python and git)
- Outpainting
- Inpainting
- Color Sketch
- Prompt Matrix
- Stable Diffusion Upscale
- Attention, specify parts of text that the model should pay more attention to
    - a man in a `((tuxedo))` - will pay more attention to tuxedo
    - a man in a `(tuxedo:1.21)` - alternative syntax
    - select text and press `Ctrl+Up` or `Ctrl+Down` (or `Command+Up` or `Command+Down` if you&#039;re on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)
- Loopback, run img2img processing multiple times
- X/Y/Z plot, a way to draw a 3 dimensional plot of images with different parameters
- Textual Inversion
    - have as many embeddings as you want and use any names you like for them
    - use multiple embeddings with different numbers of vectors per token
    - works with half precision floating point numbers
    - train embeddings on 8GB (also reports of 6GB working)
- Extras tab with:
    - GFPGAN, neural network that fixes faces
    - CodeFormer, face restoration tool as an alternative to GFPGAN
    - RealESRGAN, neural network upscaler
    - ESRGAN, neural network upscaler with a lot of third party models
    - SwinIR and Swin2SR ([see here](https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/2092)), neural network upscalers
    - LDSR, Latent diffusion super resolution upscaling
- Resizing aspect ratio options
- Sampling method selection
    - Adjust sampler eta values (noise multiplier)
    - More advanced noise setting options
- Interrupt processing at any time
- 4GB video card support (also reports of 2GB working)
- Correct seeds for batches
- Live prompt token length validation
- Generation parameters
     - parameters you used to generate images are saved with that image
     - in PNG chunks for PNG, in EXIF for JPEG
     - can drag the image to PNG info tab to restore generation parameters and automatically copy them into UI
     - can be disabled in settings
     - drag and drop an image/text-parameters to promptbox
- Read Generation Parameters Button, loads parameters in promptbox to UI
- Settings page
- Running arbitrary python code from UI (must run with `--allow-code` to enable)
- Mouseover hints for most UI elements
- Possible to change defaults/mix/max/step values for UI elements via text config
- Tiling support, a checkbox to create images that can be tiled like textures
- Progress bar and live image generation preview
    - Can use a separate neural network to produce previews with almost none VRAM or compute requirement
- Negative prompt, an extra text field that allows you to list what you don&#039;t want to see in generated image
- Styles, a way to save part of prompt and easily apply them via dropdown later
- Variations, a way to generate same image but with tiny differences
- Seed resizing, a way to generate same image but at slightly different resolution
- CLIP interrogator, a button that tries to guess prompt from an image
- Prompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midway
- Batch Processing, process a group of files using img2img
- Img2img Alternative, reverse Euler method of cross attention control
- Highres Fix, a convenience option to produce high resolution pictures in one click without usual distortions
- Reloading checkpoints on the fly
- Checkpoint Merger, a tab that allows you to merge up to 3 checkpoints into one
- [Custom scripts](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts) with many extensions from community
- [Composable-Diffusion](https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/), a way to use multiple prompts at once
     - separate prompts using uppercase `AND`
     - also supports weights for prompts: `a cat :1.2 AND a dog AND a penguin :2.2`
- No token limit for prompts (original stable diffusion lets you use up to 75 tokens)
- DeepDanbooru integration, creates danbooru style tags for anime prompts
- [xformers](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers), major speed increase for select cards: (add `--xformers` to commandline args)
- via extension: [History tab](https://github.com/yfszzx/stable-diffusion-webui-images-browser): view, direct and delete images conveniently within the UI
- Generate forever option
- Training tab
     - hypernetworks and embeddings options
     - Preprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)
- Clip skip
- Hypernetworks
- Loras (same as Hypernetworks but more pretty)
- A separate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your prompt
- Can select to load a different VAE from settings screen
- Estimated completion time in progress bar
- API
- Support for dedicated [inpainting model](https://github.com/runwayml/stable-diffusion#inpainting-with-stable-diffusion) by RunwayML
- via extension: [Aesthetic Gradients](https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients), a way to generate images with a specific aesthetic by using clip images embeds (implementation of [https://github.com/vicgalle/stable-diffusion-aesthetic-gradients](https://github.com/vicgalle/stable-diffusion-aesthetic-gradients))
- [Stable Diffusion 2.0](https://github.com/Stability-AI/stablediffusion) support - see [wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#stable-diffusion-20) for instructions
- [Alt-Diffusion](https://arxiv.org/abs/2211.06679) support - see [wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#alt-diffusion) for instructions
- Now without any bad letters!
- Load checkpoints in safetensors format
- Eased resolution restriction: generated image&#039;s dimensions must be a multiple of 8 rather than 64
- Now with a license!
- Reorder elements in the UI from settings screen
- [Segmind Stable Diffusion](https://huggingface.co/segmind/SSD-1B) support

## Installation and Running
Make sure the required [dependencies](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Dependencies) are met and follow the instructions available for:
- [NVidia](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs) (recommended)
- [AMD](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs) GPUs.
- [Intel CPUs, Intel GPUs (both integrated and discrete)](https://github.com/openvinotoolkit/stable-diffusion-webui/wiki/Installation-on-Intel-Silicon) (external wiki page)
- [Ascend NPUs](https://github.com/wangshuai09/stable-diffusion-webui/wiki/Install-and-run-on-Ascend-NPUs) (external wiki page)

Alternatively, use online services (like Google Colab):

- [List of Online Services](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Online-Services)

### Installation on Windows 10/11 with NVidia-GPUs using release package
1. Download `sd.webui.zip` from [v1.0.0-pre](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.0.0-pre) and extract its contents.
2. Run `update.bat`.
3. Run `run.bat`.
&gt; For more details see [Install-and-Run-on-NVidia-GPUs](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs)

### Automatic Installation on Windows
1. Install [Python 3.10.6](https://www.python.org/downloads/release/python-3106/) (Newer version of Python does not support torch), checking &quot;Add Python to PATH&quot;.
2. Install [git](https://git-scm.com/download/win).
3. Download the stable-diffusion-webui repository, for example by running `git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git`.
4. Run `webui-user.bat` from Windows Explorer as normal, non-administrator, user.

### Automatic Installation on Linux
1. Install the dependencies:
```bash
# Debian-based:
sudo apt install wget git python3 python3-venv libgl1 libglib2.0-0
# Red Hat-based:
sudo dnf install wget git python3 gperftools-libs libglvnd-glx
# openSUSE-based:
sudo zypper install wget git python3 libtcmalloc4 libglvnd
# Arch-based:
sudo pacman -S wget git python3
```
If your system is very new, you need to install python3.11 or python3.10:
```bash
# Ubuntu 24.04
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.11

# Manjaro/Arch
sudo pacman -S yay
yay -S python311 # do not confuse with python3.11 package

# Only for 3.11
# Then set up env variable in launch script
export python_cmd=&quot;python3.11&quot;
# or in webui-user.sh
python_cmd=&quot;python3.11&quot;
```
2. Navigate to the directory you would like the webui to be installed and execute the following command:
```bash
wget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh
```
Or just clone the repo wherever you want:
```bash
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
```

3. Run `webui.sh`.
4. Check `webui-user.sh` for options.
### Installation on Apple Silicon

Find the instructions [here](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon).

## Contributing
Here&#039;s how to add code to this repo: [Contributing](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)

## Documentation

The documentation was moved from this README over to the project&#039;s [wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki).

For the purposes of getting Google and other search engines to crawl the wiki, here&#039;s a link to the (not for humans) [crawlable wiki](https://github-wiki-see.page/m/AUTOMATIC1111/stable-diffusion-webui/wiki).

## Credits
Licenses for borrowed code can be found in `Settings -&gt; Licenses` screen, and also in `html/licenses.html` file.

- Stable Diffusion - https://github.com/Stability-AI/stablediffusion, https://github.com/CompVis/taming-transformers, https://github.com/mcmonkey4eva/sd3-ref
- k-diffusion - https://github.com/crowsonkb/k-diffusion.git
- Spandrel - https://github.com/chaiNNer-org/spandrel implementing
  - GFPGAN - https://github.com/TencentARC/GFPGAN.git
  - CodeFormer - https://github.com/sczhou/CodeFormer
  - ESRGAN - https://github.com/xinntao/ESRGAN
  - SwinIR - https://github.com/JingyunLiang/SwinIR
  - Swin2SR - https://github.com/mv-lab/swin2sr
- LDSR - https://github.com/Hafiidz/latent-diffusion
- MiDaS - https://github.com/isl-org/MiDaS
- Ideas for optimizations - https://github.com/basujindal/stable-diffusion
- Cross Attention layer optimization - Doggettx - https://github.com/Doggettx/stable-diffusion, original idea for prompt editing.
- Cross Attention layer optimization - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (originally http://github.com/lstein/stable-diffusion)
- Sub-quadratic Cross Attention layer optimization - Alex Birch (https://github.com/Birch-san/diffusers/pull/1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)
- Textual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (we&#039;re not using his code, but we are using his ideas).
- Idea for SD upscale - https://github.com/jquesnelle/txt2imghd
- Noise generation for outpainting mk2 - https://github.com/parlance-zz/g-diffuser-bot
- CLIP interrogator idea and borrowing some code - https://github.com/pharmapsychotic/clip-interrogator
- Idea for Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch
- xformers - https://github.com/facebookresearch/xformers
- DeepDanbooru - interrogator for anime diffusers https://github.com/KichangKim/DeepDanbooru
- Sampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (https://github.com/Birch-san/diffusers-play/tree/92feee6)
- Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - https://github.com/timothybrooks/instruct-pix2pix
- Security advice - RyotaK
- UniPC sampler - Wenliang Zhao - https://github.com/wl-zhao/UniPC
- TAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesd
- LyCORIS - KohakuBlueleaf
- Restart sampling - lambertae - https://github.com/Newbeeer/diffusion_restart_sampling
- Hypertile - tfernd - https://github.com/tfernd/HyperTile
- Initial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.
- (You)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[jingyaogong/minimind-v]]></title>
            <link>https://github.com/jingyaogong/minimind-v</link>
            <guid>https://github.com/jingyaogong/minimind-v</guid>
            <pubDate>Tue, 15 Apr 2025 00:04:31 GMT</pubDate>
            <description><![CDATA[ğŸš€ ã€Œå¤§æ¨¡å‹ã€1å°æ—¶ä»0è®­ç»ƒ26Må‚æ•°çš„è§†è§‰å¤šæ¨¡æ€VLMï¼ğŸŒ Train a 26M-parameter VLM from scratch in just 1 hours!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jingyaogong/minimind-v">jingyaogong/minimind-v</a></h1>
            <p>ğŸš€ ã€Œå¤§æ¨¡å‹ã€1å°æ—¶ä»0è®­ç»ƒ26Må‚æ•°çš„è§†è§‰å¤šæ¨¡æ€VLMï¼ğŸŒ Train a 26M-parameter VLM from scratch in just 1 hours!</p>
            <p>Language: Python</p>
            <p>Stars: 2,573</p>
            <p>Forks: 266</p>
            <p>Stars today: 54 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

![logo](./images/logo.png)

&lt;/div&gt;


&lt;div align=&quot;center&quot;&gt;

![visitors](https://visitor-badge.laobi.icu/badge?page_id=jingyaogong/minimind-v)
[![GitHub Repo stars](https://img.shields.io/github/stars/jingyaogong/minimind-v?style=social)](https://github.com/jingyaogong/minimind-v/stargazers)
[![GitHub Code License](https://img.shields.io/github/license/jingyaogong/minimind-v?v=1)](LICENSE)
[![GitHub last commit](https://img.shields.io/github/last-commit/jingyaogong/minimind-v)](https://github.com/jingyaogong/minimind-v/commits/master)
[![GitHub pull request](https://img.shields.io/badge/PRs-welcome-blue)](https://github.com/jingyaogong/minimind-v/pulls)
[![Collection](https://img.shields.io/badge/ğŸ¤—-MiniMindV%20%20Collection-blue)](https://huggingface.co/collections/jingyaogong/minimind-v-67000833fb60b3a2e1f3597d)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;h3&gt;&quot;å¤§é“è‡³ç®€&quot;&lt;/h3&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

ä¸­æ–‡ | [English](./README_en.md)

&lt;/div&gt;

* æ­¤é¡¹ç›®æ—¨åœ¨ä»0å¼€å§‹ï¼Œä»…ç”¨1.3å—é’±æˆæœ¬ + 1å°æ—¶ï¼å³å¯è®­ç»ƒå‡º26Må‚æ•°çš„è¶…å°å¤šæ¨¡æ€è§†è§‰è¯­è¨€æ¨¡å‹**MiniMind-V**ã€‚
* **MiniMind-V**æœ€å°ç‰ˆæœ¬ä½“ç§¯ä»…ä¸º GPT3 çš„çº¦ $\frac{1}{7000}$ï¼ŒåŠ›æ±‚åšåˆ°ä¸ªäººGPUä¹Ÿå¯å¿«é€Ÿæ¨ç†ç”šè‡³è®­ç»ƒã€‚
* **MiniMind-V**æ˜¯[MiniMind](https://github.com/jingyaogong/minimind)çº¯è¯­è¨€æ¨¡å‹çš„è§†è§‰èƒ½åŠ›é¢å¤–æ‹“å±•ã€‚
* é¡¹ç›®åŒæ—¶åŒ…å«äº†VLMå¤§æ¨¡å‹çš„æç®€ç»“æ„ã€æ•°æ®é›†æ¸…æ´—ã€é¢„è®­ç»ƒ(Pretrain)ã€ç›‘ç£å¾®è°ƒ(SFT)ç­‰å…¨è¿‡ç¨‹ä»£ç ã€‚
* è¿™ä¸ä»…æ˜¯ä¸€ä¸ªå¼€æºVLMæ¨¡å‹çš„æœ€å°å®ç°ï¼Œä¹Ÿæ˜¯å…¥é—¨è§†è§‰è¯­è¨€æ¨¡å‹çš„ç®€æ˜æ•™ç¨‹ã€‚
* å¸Œæœ›æ­¤é¡¹ç›®èƒ½ä¸ºæ‰€æœ‰äººæä¾›ä¸€ä¸ªæŠ›ç –å¼•ç‰çš„ç¤ºä¾‹ï¼Œä¸€èµ·æ„Ÿå—åˆ›é€ çš„ä¹è¶£ï¼æ¨åŠ¨æ›´å¹¿æ³›AIç¤¾åŒºçš„è¿›æ­¥ï¼

&gt; ä¸ºé˜²æ­¢è¯¯è§£ï¼Œâ€œ1å°æ—¶â€ åŸºäºNVIDIA 3090ç¡¬ä»¶è®¾å¤‡ï¼ˆå•å¡ï¼‰æµ‹è¯•`1 epoch`ï¼Œâ€œ1.3å—é’±â€ æŒ‡GPUæœåŠ¡å™¨ç§Ÿç”¨æˆæœ¬ã€‚



&lt;div align=&quot;center&quot;&gt;

![minimind2-v](./images/minimind2-v.gif)

[ğŸ”—ğŸ¤–åœ¨çº¿ä½“éªŒ](https://www.modelscope.cn/studios/gongjy/MiniMind-V) | [ğŸ”—ğŸï¸è§†é¢‘ä»‹ç»](https://www.bilibili.com/video/BV1Sh1vYBEzY)

&lt;/div&gt;

# ğŸ“Œ Introduction

â€œç”¨ä¹é«˜æ‹¼å‡ºä¸€æ¶é£æœºï¼Œè¿œæ¯”ååœ¨å¤´ç­‰èˆ±é‡Œé£è¡Œæ›´è®©äººå…´å¥‹ï¼â€
æ„å»ºVLMèŒƒå¼çš„å¤šæ¨¡æ€å¤§æ¨¡å‹æ˜¯å¦çœŸçš„å¦‚æƒ³è±¡ä¸­é‚£æ ·å¤æ‚ï¼Ÿå®ƒçš„ä»£ç å®ç°åˆ°åº•å¦‚ä½•ï¼Ÿ
è®­ç»ƒè¿‡ç¨‹ç©¶ç«Ÿéš¾ä¸éš¾ï¼Ÿé‚£ä¹ˆç°åœ¨ï¼Œæ¢ç´¢å®ƒä»¬çš„ç­”æ¡ˆï¼Œä¸€èµ·æ„Ÿå—åˆ›é€ çš„ä¹è¶£å§ï¼

&gt; [!TIP]
&gt; ï¼ˆæˆªè‡³2025-02-20ï¼‰MiniMind-V ç³»åˆ—å·²å®Œæˆäº†ä»¥ä¸‹å‹å·æ¨¡å‹è®­ç»ƒï¼Œæœ€å°ä»…éœ€26M (0.026B)ï¼Œå³å¯å…·å¤‡è¯†å›¾å’Œå¯¹è¯çš„èƒ½åŠ›ï¼

| æ¨¡å‹ (å¤§å°)                   | æ¨ç†å ç”¨   | release    | 
|---------------------------|--------|------------|
| MiniMind2-V (104M)        | 0.6 GB | 2025.02.20 |
| MiniMind2-Small-V (26M)   | 1.1 GB | 2025.02.20 |
| minimind-v-v1-small (27M) | 0.6 GB | 2024.10.04 |
| minimind-v-v1 (109M)      | 1.1 GB | 2024.10.04 |

### ğŸ‘‰**æœ€è¿‘æ›´æ–°**

&lt;details close&gt; 
&lt;summary&gt; &lt;b&gt;2025-02-20 (newest ğŸ‰)&lt;/b&gt; &lt;/summary&gt;

- MiniMind2-Vä¼´éšMiniMind2åŒæ­¥æ›´æ–°
- å¤§å¹…å‡å°‘æ‰€æœ‰å†—ä½™ä»£ç ï¼Œè§„èŒƒä»£ç æ ¼å¼
- å¤§å¹…ç²¾ç®€æ¨¡å‹å†—ä½™ç»“æ„
- æ›´æ–°æ•°æ®é›†æ ¼å¼ï¼Œæ‹“å±•æ–°çš„SFTæ•°æ®é›†
- æ¯”å‰ä»£VLMæ›´ä¼˜ç§€çš„æ•ˆæœï¼

&lt;/details&gt;

&lt;details close&gt; 
&lt;summary&gt; &lt;b&gt;2024-10-05&lt;/b&gt; &lt;/summary&gt;

- MiniMind-Vå¦‚æœŸè€Œè‡³ï¼Œé¦–æ¬¡å¼€æº

&lt;/details&gt;

# ğŸ“Œ å¿«é€Ÿå¼€å§‹

&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt;
&lt;summary&gt;åˆ†äº«æœ¬äººçš„è½¯ç¡¬ä»¶é…ç½®ï¼ˆä»…ä¾›å‚è€ƒï¼‰&lt;/summary&gt;

* CPU: Intel(R) Core(TM) i9-10980XE CPU @ 3.00GHz
* RAM: 128 GB
* GPU: NVIDIA GeForce RTX 3090(24GB) * 8
* Ubuntu==20.04
* CUDA==12.2
* Python==3.10.16
* [requirements.txt](./requirements.txt)

&lt;/details&gt;

### ç¬¬0æ­¥

```bash
# å…‹éš†ä»£ç ä»“åº“
git clone https://github.com/jingyaogong/minimind-v
```

```bash
# ä¸‹è½½clipæ¨¡å‹åˆ° ./model/vision_model ç›®å½•ä¸‹
git clone https://huggingface.co/openai/clip-vit-base-patch16
# or
git clone https://www.modelscope.cn/models/openai-mirror/clip-vit-base-patch16
```

```bash
# ä¸‹è½½çº¯è¯­è¨€æ¨¡å‹æƒé‡åˆ° ./out ç›®å½•ä¸‹ï¼ˆä½œä¸ºè®­ç»ƒVLMçš„åŸºåº§è¯­è¨€æ¨¡å‹ï¼‰
https://huggingface.co/jingyaogong/MiniMind2-V-PyTorch/blob/main/lm_512.pth
# or
https://huggingface.co/jingyaogong/MiniMind2-V-PyTorch/blob/main/lm_768.pth
```

## â…  æµ‹è¯•å·²æœ‰æ¨¡å‹æ•ˆæœ

### 1.ç¯å¢ƒå‡†å¤‡

```bash
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

### 2.ä¸‹è½½æ¨¡å‹

```bash
git clone https://huggingface.co/jingyaogong/MiniMind2-V
```

### 3.å‘½ä»¤è¡Œé—®ç­”

```bash
# load=0: load from pytorch model, load=1: load from transformers-hf model
python eval_vlm.py --load 1
```

### 4.æˆ–å¯åŠ¨WebUI

```bash
python web_demo_vlm.py
```

## â…¡ ä»0å¼€å§‹è‡ªå·±è®­ç»ƒ

### 1.ç¯å¢ƒå‡†å¤‡

```bash
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt;
&lt;summary&gt;æ³¨ï¼šæå‰æµ‹è¯•Torchæ˜¯å¦å¯ç”¨cuda&lt;/summary&gt;

```bash
import torch
print(torch.cuda.is_available())
```

å¦‚æœä¸å¯ç”¨ï¼Œè¯·è‡ªè¡Œå»[torch_stable](https://download.pytorch.org/whl/torch_stable.html)
ä¸‹è½½whlæ–‡ä»¶å®‰è£…ã€‚å‚è€ƒ[é“¾æ¥](https://blog.csdn.net/weixin_45456738/article/details/141029610?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E5%AE%89%E8%A3%85torch&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-2-141029610.nonecase&amp;spm=1018.2226.3001.4187)

&lt;/details&gt;

### 2.æ•°æ®ä¸‹è½½

ä»ä¸‹æ–‡æä¾›çš„[æ•°æ®é›†ä¸‹è½½é“¾æ¥](https://huggingface.co/datasets/jingyaogong/minimind-v_dataset)
ä¸‹è½½éœ€è¦çš„æ•°æ®æ–‡ä»¶ï¼ˆåˆ›å»º`./dataset`ç›®å½•ï¼‰å¹¶æ”¾åˆ°`./dataset`ä¸‹ã€‚

`*.jsonl`ä¸ºé—®ç­”æ•°æ®é›†ï¼Œ`*images`ä¸ºé…å¥—çš„å›¾ç‰‡æ•°æ®ï¼Œä¸‹è½½å®Œæˆåéœ€è¦è§£å‹å›¾åƒæ•°æ®ã€‚

&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt;
&lt;summary&gt;æ³¨ï¼šæ•°æ®é›†é¡»çŸ¥&lt;/summary&gt;

è¯·é¢„ç•™~5GBç©ºé—´å­˜æ”¾æ•°æ®é›†ï¼Œè‹¥æ— å¤šä½™ç©ºé—´å­˜æ”¾pretrainæ•°æ®ï¼Œ
å¯å°è¯•è·³è¿‡pretrainè®­ç»ƒæ­¥éª¤ç›´æ¥è¿›è¡Œsftè®­ç»ƒã€‚

&lt;/details&gt;

### 3.å¼€å§‹è®­ç»ƒ

**3.1 é¢„è®­ç»ƒï¼ˆå­¦å›¾åƒæè¿°ï¼‰**

```bash
python train_pretrain_vlm.py --epochs 4
```

&gt; æ‰§è¡Œé¢„è®­ç»ƒï¼Œå¾—åˆ° `pretrain_vlm_*.pth` ä½œä¸ºé¢„è®­ç»ƒçš„è¾“å‡ºæƒé‡ï¼ˆå…¶ä¸­*ä¸ºæ¨¡å‹çš„dimensionï¼Œé»˜è®¤ä¸º512ï¼‰


**3.2 ç›‘ç£å¾®è°ƒï¼ˆå­¦çœ‹å›¾å¯¹è¯æ–¹å¼ï¼‰**

```bash
python train_sft_vlm.py --epochs 4
```

&gt; æ‰§è¡Œç›‘ç£å¾®è°ƒï¼Œå¾—åˆ° `sft_vlm_*.pth` ä½œä¸ºæŒ‡ä»¤å¾®è°ƒçš„è¾“å‡ºæƒé‡

&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt;
&lt;summary&gt;æ³¨ï¼šè®­ç»ƒé¡»çŸ¥&lt;/summary&gt;

æ‰€æœ‰è®­ç»ƒè¿‡ç¨‹é»˜è®¤æ¯éš”100æ­¥ä¿å­˜1æ¬¡å‚æ•°åˆ°æ–‡ä»¶`./out/***.pth`ï¼ˆæ¯æ¬¡ä¼šè¦†ç›–æ‰æ—§æƒé‡æ–‡ä»¶ï¼‰ã€‚

&lt;/details&gt;


---

### 4.æµ‹è¯•æ¨¡å‹æ•ˆæœ

ç¡®ä¿éœ€è¦æµ‹è¯•çš„æ¨¡å‹`*.pth`æ–‡ä»¶ä½äº`./out/`ç›®å½•ä¸‹ã€‚
ä¹Ÿå¯ä»¥ç›´æ¥å»[æ­¤å¤„](https://huggingface.co/jingyaogong/MiniMind2-V-PyTorch)ä¸‹è½½ä½¿ç”¨æˆ‘è®­ç»ƒçš„`*.pth`æ–‡ä»¶ã€‚

```bash
python eval_vlm.py --model_mode 1 # é»˜è®¤ä¸º0ï¼šæµ‹è¯•pretrainæ¨¡å‹æ•ˆæœï¼Œè®¾ç½®ä¸º1ï¼šæµ‹è¯•sftæ¨¡å‹æ•ˆæœ
```

---

&gt; [!TIP]
&gt; è®­ç»ƒè„šæœ¬å‡ä¸ºPytorchåŸç”Ÿæ¡†æ¶ï¼Œå‡æ”¯æŒå¤šå¡åŠ é€Ÿï¼Œå‡è®¾ä½ çš„è®¾å¤‡æœ‰N (Nï¼1) å¼ æ˜¾å¡ï¼š

å•æœºNå¡å¯åŠ¨è®­ç»ƒæ–¹å¼ (DDP, æ”¯æŒå¤šæœºå¤šå¡é›†ç¾¤)

```bash
torchrun --nproc_per_node N train_xxx.py
```

&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt;
&lt;summary&gt;æ³¨ï¼šå…¶å®ƒé¡»çŸ¥&lt;/summary&gt;

å•æœºNå¡å¯åŠ¨è®­ç»ƒ (DeepSpeed)

```bash
deepspeed --master_port 29500 --num_gpus=N train_xxx.py
```

å¯æ ¹æ®éœ€è¦å¼€å¯wandbè®°å½•è®­ç»ƒè¿‡ç¨‹

```bash
# éœ€è¦ç™»å½•: wandb login
torchrun --nproc_per_node N train_xxx.py --use_wandb
# and
python train_xxx.py --use_wandb
```

é€šè¿‡æ·»åŠ `--use_wandb`å‚æ•°ï¼Œå¯ä»¥è®°å½•è®­ç»ƒè¿‡ç¨‹ï¼Œè®­ç»ƒå®Œæˆåï¼Œå¯ä»¥åœ¨wandbç½‘ç«™ä¸ŠæŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹ã€‚é€šè¿‡ä¿®æ”¹`wandb_project`
å’Œ`wandb_run_name`å‚æ•°ï¼Œå¯ä»¥æŒ‡å®šé¡¹ç›®åç§°å’Œè¿è¡Œåç§°ã€‚

&lt;/details&gt;

# ğŸ“Œ VLM Detail

MiniMind-V (VLM)çš„åŸºåº§è¯­è¨€æ¨¡å‹MiniMind (LLM)æ¥è‡ªå­ªç”Ÿé¡¹ç›®[minimind](https://github.com/jingyaogong/minimind)ï¼Œ
å…·ä½“çš„æ¨¡å‹ç»“æ„ã€è®­ç»ƒç»†èŠ‚ã€åŸç†ã€æµ‹è¯•æ•ˆæœç­‰å‡å¯ç§»æ­¥[minimind](https://github.com/jingyaogong/minimind)é¡¹ç›®æŸ¥é˜…ã€‚
æ­¤å¤„ä¸ºå‡å°‘å†—ä½™ï¼Œçœç•¥è®¨è®ºLLMçš„ç›¸å…³éƒ¨åˆ†ï¼Œé»˜è®¤æ‚¨å·²å¯¹MiniMind (LLM)çš„ç»†èŠ‚æœ‰åŸºæœ¬çš„äº†è§£ã€‚

&gt; å³ä½¿æ‚¨ä¸å¤ªäº†è§£LLMçš„ç»†èŠ‚ï¼Œä¹Ÿå¯å‚è€ƒâ€œå¿«é€Ÿå¼€å§‹â€æµç¨‹è®­ç»ƒä¸€ä¸ªMiniMind-Vï¼Œ
&gt; è¿™å¹¶ä¸å—åˆ°å½±å“ï¼Œä»“åº“è‡´åŠ›äºæœ€ä½æˆæœ¬çš„å¼€ç®±å³ç”¨ï¼

MiniMind-Vçš„ç»“æ„ä»…å¢åŠ Visual Encoderå’Œç‰¹å¾æŠ•å½±ä¸¤ä¸ªå­æ¨¡å—ï¼Œå¢åŠ æ¨¡æ€æ··åˆåˆ†æ”¯ï¼Œä»¥æ”¯æŒå¤šç§æ¨¡æ€ä¿¡æ¯çš„è¾“å…¥ï¼š
![LLM-structure](./images/VLM-structure.png)
![LLM-structure](./images/VLM-structure-moe.png)


&lt;details&gt;
&lt;summary&gt; ã€é‡è¦ã€‘ä¸€äº›æœ‰è¶£çš„æ€è€ƒ &lt;/summary&gt;

æ­¤å¤„ä¸å¦¨å±•å¼€æƒ³ä¸€æƒ³ä¸¤ä¸ªé—®é¢˜ï¼š

* ä»€ä¹ˆå«åš**L**arge **L**anguage **M**odel (LLM)ï¼Ÿ
* ä»€ä¹ˆå«åšå¤šæ¨¡æ€æ¨¡å‹ï¼Ÿ

[è¿™ç¯‡æ–‡ç« ](https://www.jiqizhixin.com/articles/2024-09-15-3)å®Œç¾å»åˆæœ¬äººçš„æƒ³æ³•ï¼š
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åå­—è™½ç„¶å¸¦æœ‰è¯­è¨€äºŒå­—ï¼Œä½†å®ƒä»¬å…¶å®ä¸è¯­è¨€å…³ç³»ä¸å¤§ï¼Œè¿™åªæ˜¯å†å²é—®é¢˜ï¼Œæ›´ç¡®åˆ‡çš„åå­—åº”è¯¥æ˜¯è‡ªå›å½’ Transformer
æˆ–è€…å…¶ä»–ã€‚LLM æ›´å¤šæ˜¯ä¸€ç§ç»Ÿè®¡å»ºæ¨¡çš„é€šç”¨æŠ€æœ¯ï¼Œå®ƒä»¬ä¸»è¦é€šè¿‡è‡ªå›å½’ Transformer æ¥æ¨¡æ‹Ÿ token æµï¼Œè€Œè¿™äº› token
å¯ä»¥ä»£è¡¨æ–‡æœ¬ã€å›¾ç‰‡ã€éŸ³é¢‘ã€åŠ¨ä½œé€‰æ‹©ã€ç”šè‡³æ˜¯åˆ†å­ç­‰ä»»ä½•ä¸œè¥¿ã€‚
å› æ­¤ï¼Œåªè¦èƒ½å°†é—®é¢˜è½¬åŒ–ä¸ºæ¨¡æ‹Ÿä¸€ç³»åˆ—ç¦»æ•£ token çš„æµç¨‹ï¼Œç†è®ºä¸Šéƒ½å¯ä»¥åº”ç”¨ LLM æ¥è§£å†³ã€‚
å®é™…ä¸Šï¼Œéšç€å¤§å‹è¯­è¨€æ¨¡å‹æŠ€æœ¯æ ˆçš„æ—¥ç›Šæˆç†Ÿï¼Œæˆ‘ä»¬å¯èƒ½ä¼šçœ‹åˆ°è¶Šæ¥è¶Šå¤šçš„é—®é¢˜è¢«çº³å…¥è¿™ç§å»ºæ¨¡èŒƒå¼ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œé—®é¢˜å›ºå®šåœ¨ä½¿ç”¨ LLM
è¿›è¡Œã€ä¸‹ä¸€ä¸ª token çš„é¢„æµ‹ã€ï¼Œåªæ˜¯æ¯ä¸ªé¢†åŸŸä¸­ token çš„ç”¨é€”å’Œå«ä¹‰æœ‰æ‰€ä¸åŒã€‚

[ZJU-LiXiè€å¸ˆ](https://person.zju.edu.cn/xilics#694283)åŒæ ·è°ˆåŠè¿‡ç±»ä¼¼è§‚ç‚¹ï¼ˆåŸè¯å¤§æ„å¦‚ä¸‹ï¼‰ï¼š
æ–‡æœ¬ã€è§†é¢‘ã€è¯­éŸ³ã€åŠ¨ä½œç­‰åœ¨äººç±»çœ‹æ¥å±äºã€Œå¤šæ¨¡æ€ã€ä¿¡å·ï¼Œä½†æ‰€è°“çš„ã€Œæ¨¡æ€ã€å…¶å®åªæ˜¯äººç±»åœ¨ä¿¡æ¯å­˜å‚¨æ–¹å¼ä¸Šçš„ä¸€ç§åˆ†ç±»æ¦‚å¿µã€‚
å°±åƒ`.txt`å’Œ`.png`æ–‡ä»¶ï¼Œè™½ç„¶åœ¨è§†è§‰å‘ˆç°å’Œé«˜çº§è¡¨ç°å½¢å¼ä¸Šæœ‰æ‰€ä¸åŒï¼Œä½†å®ƒä»¬æœ¬è´¨ä¸Šå¹¶æ²¡æœ‰æ ¹æœ¬åŒºåˆ«ã€‚
ä¹‹æ‰€ä»¥å‡ºç°ã€Œå¤šæ¨¡æ€ã€è¿™ä¸ªæ¦‚å¿µï¼Œä»…ä»…æ˜¯å› ä¸ºäººç±»åœ¨ä¸åŒçš„æ„ŸçŸ¥å±‚é¢ä¸Šå¯¹è¿™äº›ä¿¡å·çš„åˆ†ç±»éœ€æ±‚ã€‚
ç„¶è€Œï¼Œå¯¹äºæœºå™¨æ¥è¯´ï¼Œæ— è®ºä¿¡å·æ¥è‡ªä½•ç§ã€Œæ¨¡æ€ã€ï¼Œæœ€ç»ˆå®ƒä»¬éƒ½åªæ˜¯ä»¥ä¸€ä¸²äºŒè¿›åˆ¶çš„ã€Œå•æ¨¡æ€ã€æ•°å­—åºåˆ—æ¥å‘ˆç°ã€‚
æœºå™¨å¹¶ä¸ä¼šåŒºåˆ†è¿™äº›ä¿¡å·çš„æ¨¡æ€æ¥æºï¼Œè€Œåªæ˜¯å¤„ç†å’Œåˆ†æè¿™äº›åºåˆ—èƒŒåæ‰€æ‰¿è½½çš„ä¿¡æ¯å†…å®¹ã€‚

ä¸ªäººè®¤ä¸º**G**enerative **P**retrained **T**ransformer (GPT) æ¯” **L**arge **L**anguage **M**odel (LLM)æ›´ä¸ºè´´åˆ‡ï¼Œ
å› æ­¤æœ¬äººè¡¨è¾¾ä¸Šæ›´ä¹ æƒ¯ç”¨&quot;GPT&quot;å»ä»£è¡¨LLM/VLM/ç±»GPTæ¶æ„çš„ç³»åˆ—æ¨¡å‹ï¼Œè€Œéä¸ºäº†è¹­OpenAIçš„çƒ­åº¦ã€‚

è‡³æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€å¥è¯æ€»ç»“GPTçš„æ‰€ä½œæ‰€ä¸ºï¼š

GPTæ¨¡å‹æ ¹æ®ç°æœ‰tokené¢„æµ‹è¾“å‡ºä¸‹ä¸€ä¸ªä¸‹ä¸‹ä¸€ä¸ªä¸‹ä¸‹ä¸‹ä¸€ä¸ªtoken ...ï¼Œç›´åˆ°æ¨¡å‹è¾“å‡ºç»“æŸç¬¦ï¼›æ­¤å¤„çš„&quot;token&quot;å…¶å®å¹¶ä¸éœ€è¦ä¸€å®šæ˜¯æ–‡æœ¬ï¼

```text
&gt; å¯¹äºLLMæ¨¡å‹ï¼Œå¦‚æœéœ€è¦ç†è§£&quot;å›¾ç‰‡&quot;ï¼Œæˆ‘ä»¬åªè¦æŠŠ&quot;å›¾ç‰‡&quot;ä½œä¸ºå¯¹ä¸€ç§ç‰¹æ®Šçš„ä»æ¥æ²¡è§è¿‡çš„&quot;å¤–å›½è¯­è¨€&quot;ï¼Œé€šè¿‡&quot;å¤–è¯­è¯å…¸&quot;ç¿»è¯‘åå³å¯ä½œä¸ºç‰¹æ®Šçš„è¯­è¨€è¾“å…¥LLM
&gt; å¯¹äºLLMæ¨¡å‹ï¼Œå¦‚æœéœ€è¦ç†è§£&quot;éŸ³é¢‘&quot;ï¼Œæˆ‘ä»¬åªè¦æŠŠ&quot;éŸ³é¢‘&quot;ä½œä¸ºå¯¹ä¸€ç§ç‰¹æ®Šçš„ä»æ¥æ²¡è§è¿‡çš„&quot;å¤–å›½è¯­è¨€&quot;ï¼Œé€šè¿‡&quot;å¤–è¯­è¯å…¸&quot;ç¿»è¯‘åå³å¯ä½œä¸ºç‰¹æ®Šçš„è¯­è¨€è¾“å…¥LLM
&gt; ...
```

&lt;u&gt;**ä¸ºäº†å¾—åˆ°MiniMind-Vï¼Œæˆ‘ä»¬åªéœ€è¦å®Œæˆè¿™2ä»¶äº‹å³å¯ï¼š**&lt;/u&gt;

1. å€ŸåŠ©æ“…é•¿ç¿»è¯‘å›¾ç‰‡çš„ **&quot;å¤–è¯­è¯å…¸&quot;** ï¼ŒæŠŠå›¾ç‰‡ä» **&quot;å¤–å›½è¯­è¨€&quot;** ç¿»è¯‘ä¸ºæ¨¡å‹ä¾¿äºç†è§£çš„ **&quot;LLMè¯­è¨€&quot;**
2. è®­ç»ƒå¾®è°ƒLLMï¼Œä½¿å…¶å’Œ **&quot;å¤–è¯­è¯å…¸&quot;** åº¦è¿‡ç£¨åˆæœŸï¼Œä»è€Œæ›´å¥½çš„ç†è§£å›¾ç‰‡

&quot;å¤–è¯­è¯å…¸&quot; ç§°ä¹‹ä¸ºVisual Encoderæ¨¡å‹ã€‚
å’ŒLlaVAã€Qwen-VLç­‰è§†è§‰è¯­è¨€æ¨¡å‹ç±»ä¼¼ï¼ŒMiniMind-VåŒæ ·é€‰ç”¨å¼€æºClipç³»åˆ—æ¨¡å‹ä½œä¸ºVisual Encoderã€‚
å…·ä½“ä½¿ç”¨[clip-vit-base-patch16](https://huggingface.co/openai/clip-vit-base-patch16)ï¼Œ
ä¸€ç§åŸºäº ViT-B/16 æ¶æ„çš„ç»å…¸Visual Encoderç”¨äºæè¿°å›¾åƒæ–‡æœ¬ä¿¡æ¯ã€‚
è¾“å…¥çš„å›¾åƒå°ºå¯¸ä¸º224x224ï¼Œå› ä¸ºåˆ’åˆ†çš„Patchæ˜¯16Ã—16ï¼Œæ‰€ä»¥ä¼šäº§ç”Ÿ14*14=196ä¸ªtokenä½œä¸ºencoderç¼–ç å±‚çš„è¾“å…¥ï¼Œ
æœ€ç»ˆäº§ç”Ÿ1Ã—768ç»´çš„åµŒå…¥å‘é‡ç”¨äºå’Œæ–‡æœ¬å¯¹è®¡ç®—è¯¯å·®ã€‚
æˆ‘ä»¬å¹¶ä¸éœ€è¦æœ€ç»ˆåµŒå…¥è¡¨ç¤ºï¼Œå› æ­¤åªå–encoderå±‚çš„è¾“å‡ºï¼Œä¹Ÿå°±æ˜¯VITæ ¸å¿ƒä¸»å¹²çš„è¾“å‡ºç‰¹å¾å³å¯ã€‚
å®ƒæ‹¿åˆ°å‰ä¸€å±‚ç»´åº¦196Ã—768å¤§å°çš„ç‰¹å¾ï¼Œæˆ‘ä»¬æŠŠå®ƒä½œä¸º196ä¸ªvisual tokenè¾“å…¥MiniMind-Vã€‚
ä¸LLMçš„ç»“åˆåœ¨è·å–å›¾åƒencoderç‰¹å¾åï¼Œä¸€æ–¹é¢éœ€è¦æŠŠ768ç»´åº¦çš„visual tokenå¯¹é½åˆ°LLMçš„æ–‡æœ¬tokenï¼Œ
å¦ä¸€æ–¹é¢ï¼Œè¦å°†å›¾åƒç‰¹å¾æ˜ å°„åˆ°ä¸æ–‡æœ¬embeddingç›¸åŒçš„ç©ºé—´ï¼Œå³æ–‡æœ¬tokenå’ŒåŸç”Ÿçš„è§†è§‰tokenéœ€è¦ç£¨åˆå¹¶ä¸èƒ½ç›´æ¥åœ°ä¸€è§†åŒä»ï¼Œ
å¯ä»¥ç§°ä¹‹ä¸ºè·¨æ¨¡æ€çš„ç‰¹å¾å¯¹é½ã€‚
[LlaVA-1](https://arxiv.org/pdf/2304.08485)ä½¿ç”¨ç®€å•çš„æ— åçº¿æ€§å˜æ¢å®Œæˆäº†è¿™ä¸€æ“ä½œï¼Œæ•ˆæœå¾ˆä¸é”™ï¼ŒMiniMind-VåŒæ ·å¦‚æ­¤ã€‚

![llava-structure](./images/llava-structure.png)

è‡³æ­¤ï¼ŒMiniMind-Vçš„å†…éƒ¨ç»“æ„å˜åŒ–å·²ç»å‘ˆç°å®Œæ¯•ã€‚

&lt;/details&gt;


---

ä¸‹é¢ï¼Œæˆ‘ä»¬ç®€å•è®¨è®ºMiniMind-Vçš„å¤–éƒ¨è¾“å…¥è¾“å‡ºçš„å˜åŒ–ã€‚

VLMçš„è¾“å…¥ä¾ç„¶æ˜¯ä¸€æ®µæ–‡æœ¬ï¼Œå…¶ä¸­åŒ…å«ç‰¹æ®Šçš„&lt;image&gt;å ä½ç¬¦ã€‚
åœ¨è®¡ç®—æ–‡æœ¬åµŒå…¥åï¼Œå¯ä»¥å°†å›¾åƒç¼–ç å™¨ç”Ÿæˆçš„å‘é‡æŠ•å½±åˆ°è¯¥å ä½ç¬¦å¯¹åº”çš„åµŒå…¥éƒ¨åˆ†ï¼Œæ›¿æ¢æ‰åŸå…ˆçš„å ä½ç¬¦embeddingã€‚
ä¾‹å¦‚ï¼š

```text
&lt;image&gt;\nè¿™ä¸ªå›¾åƒä¸­æœ‰ä»€ä¹ˆå†…å®¹ï¼Ÿ
```

åœ¨`minimind-v`ä¸­ï¼Œä½¿ç”¨196ä¸ªå­—ç¬¦ç»„æˆçš„ `@@@...@@@`
å ä½ç¬¦ä»£æ›¿å›¾åƒï¼Œä¹‹æ‰€ä»¥æ˜¯196ä¸ªå­—ç¬¦ï¼Œå‰é¢æœ‰æ‰€æåŠï¼š
ä»»ä½•å›¾åƒéƒ½è¢«clipæ¨¡å‹encoderä¸º196Ã—768ç»´çš„tokenï¼Œ
å› æ­¤`minimind-v`çš„promptä¸ºï¼š

```text
@@@......@@@\nè¿™ä¸ªå›¾ç‰‡æè¿°çš„æ˜¯ä»€ä¹ˆå†…å®¹ï¼Ÿ
```

è®¡ç®—å®Œembeddingå’Œprojectionï¼Œå¹¶å¯¹å›¾åƒéƒ¨åˆ†tokenæ›¿æ¢åæ•´ä¸ªè®¡ç®—è¿‡ç¨‹åˆ°è¾“å‡ºåˆ™å’ŒLLMéƒ¨åˆ†æ²¡æœ‰ä»»ä½•åŒºåˆ«ã€‚

![input](./images/minimind-v-input.png)

ä¸€æ¬¡æ€§å¤šå›¾çš„å®ç°æ–¹æ³•å°±æ˜¯é€šè¿‡æ³¨å…¥å¤šä¸ª`&lt;image&gt;`å›¾åƒå ä½ç¬¦è¿›è¡Œå®ç°ï¼Œä¸éœ€è¦ä¿®æ”¹ä»»ä½•æ¡†æ¶ã€‚

&lt;details&gt;
&lt;summary&gt; è§†é¢‘ç†è§£çš„æ‹“å±•æ€è·¯ &lt;/summary&gt;

write by [@xinyanghuang7](https://github.com/xinyanghuang7)

å¯¹äºå¤šæ¨¡æ€å¤§æ¨¡å‹çš„è§†é¢‘ç†è§£èƒ½åŠ›ï¼Œä¸€ä¸ªå¯è¡Œçš„æ€è·¯æ˜¯å‚è€ƒç°æœ‰MiniCPM-V 2.6 è¿›è¡Œè§†é¢‘ç†è§£çš„Pythonç¤ºä¾‹ã€‚
ä¸»è¦æ€æƒ³æ˜¯é€šè¿‡æå–è§†é¢‘å…³é”®å¸§ï¼Œè€Œåè¿›è¡Œå¤šå›¾æ¨ç†ã€‚
å› æ­¤ï¼Œå¦‚æœå¸Œæœ›åœ¨MiniMind-Vä¸­æ·»åŠ è§†é¢‘ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥åœ¨ç°æœ‰å¤šå›¾è®­ç»ƒçš„åŸºç¡€ä¸Šï¼Œå‚è€ƒæ­¤pythonè„šæœ¬ä¸­å¯¹äºå…³é”®å¸§çš„æå–æ–¹æ³•ï¼Œè€ŒååŠ å¤§è®­ç»ƒæ–‡ä»¶ä¸­æ”¯æŒå›¾ç‰‡çš„æ•°é‡ã€‚
æ‰€æ”¯æŒçš„MAX_NUM_FRAMESè¶Šå¤šï¼Œæ‰€æ¶ˆè€—çš„æ˜¾å­˜è¶Šå¤§ã€‚

```text
import torch
from PIL import Image
from transformers import AutoModel, AutoTokenizer
from decord import VideoReader, cpu  # pip install decord

model = AutoModel.from_pretrained(&#039;openbmb/MiniCPM-V-2_6&#039;, trust_remote_code=True,
                                  attn_implementation=&#039;sdpa&#039;,
                                  torch_dtype=torch.bfloat16)  # sdpa or flash_attention_2, no eager
model = model.eval().cuda()
tokenizer = AutoTokenizer.from_pretrained(&#039;openbmb/MiniCPM-V-2_6&#039;, trust_remote_code=True)

MAX_NUM_FRAMES = 64  # if cuda OOM set a smaller number


def encode_video(video_path):
    def uniform_sample(l, n):
        gap = len(l) / n
        idxs = [int(i * gap + gap / 2) for i in range(n)]
        return [l[i] for i in idxs]

    vr = VideoReader(video_path, ctx=cpu(0))
    sample_fps = round(vr.get_avg_fps() / 1)  # FPS
    frame_idx = [i for i in range(0, len(vr), sample_fps)]
    if len(frame_idx) &gt; MAX_NUM_FRAMES:
        frame_idx = uniform_sample(frame_idx, MAX_NUM_FRAMES)
    frames = vr.get_batch(frame_idx).asnumpy()
    frames = [Image.fromarray(v.astype(&#039;uint8&#039;)) for v in frames]
    print(&#039;num frames:&#039;, len(frames))
    return frames


video_path = &quot;video_test.mp4&quot;
frames = encode_video(video_path)
question = &quot;Describe the video&quot;
msgs = [
    {&#039;role&#039;: &#039;user&#039;, &#039;content&#039;: frames + [question]},
]

# Set decode params for video
params = {}
params[&quot;use_image_id&quot;] = False
params[&quot;max_slice_nums&quot;] = 2  # å¦‚æœcuda OOMä¸”è§†é¢‘åˆ†è¾¨ç‡å¤§äº448*448å¯è®¾ä¸º1

answer = model.chat(
    image=None,
    msgs=msgs,
    tokenizer=tokenizer,
    **params
)
print(answer)
```

&lt;/details&gt;

è‡³æ­¤ï¼Œ`MiniMind-V`çš„æ‰€æœ‰ç»†èŠ‚å·²ç»å‘ˆç°å®Œæ¯•ã€‚
`MiniMind-V`çš„æ¨¡å‹å­ç±»å®Œå…¨ç»§æ‰¿è‡ª`MiniMind`ï¼Œ
ä»…åŸºäºåè€…åš**æœ€å°**å˜æ›´è€Œäº§ç”Ÿï¼Œ
å…¶æ ¸å¿ƒç®—æ³•æ”¹åŠ¨`&lt; 50è¡Œ`ï¼Œè¿ç§»éš¾åº¦æä½ã€‚
å› æ­¤å¯èƒ½å’Œ`LlAVA`ç­‰æ¨¡å‹ç»†èŠ‚å¯èƒ½å­˜åœ¨åŒºåˆ«ï¼Œä½†æ€è·¯å®Œå…¨ç»Ÿä¸€ã€‚

# ğŸ“Œ Experiment

## â…  æ•°æ®é›†

æ¥æºï¼š[Chinese-LLaVA-Vision](https://huggingface.co/datasets/LinkSoul/Chinese-LLaVA-Vision-Instructions)
åŒ…å«çº¦57ä¸‡å¼ é¢„è®­ç»ƒå›¾åƒï¼Œæ¥è‡ªCC-3Må’ŒCOCO 2014ï¼›
[llava-en-zh-300k](https://huggingface.co/datasets/BUAADreamer/llava-en-zh-300k)
åŒ…å«300kæ¡æŒ‡ä»¤å¾®è°ƒæ•°æ®å’Œ15ä¸‡å¼ å›¾åƒã€‚
é—®ç­”å†…å®¹ç»è¿‡ç¿»è¯‘ï¼Œ
å¯¹ä¸­æ–‡æ”¯æŒæ›´å‹å¥½ï¼Œè¿›ä¸€æ­¥ç»è¿‡æ•´ç†å¹¶`resize`ã€‚

(pretrain_vlm_data.jsonl) é¢„è®­ç»ƒæ•°æ®é›†æ ¼å¼ï¼š

```json lines
{
  &quot;conversations&quot;: [
    {
      &quot;role&quot;: &quot;user&quot;,
      &quot;content&quot;: &quot;æä¾›ç»™å®šå›¾åƒçš„ç®€è¦æè¿°ã€‚\n&lt;image&gt;&quot;
    },
    {
      &quot;role&quot;: &quot;assistant&quot;,
      &quot;content&quot;: &quot;æ©„æ¦„æ²¹æ˜¯è‡ªç”±ä½¿ç”¨çš„å¥åº·æˆåˆ†ã€‚&quot;
    }
  ],
  &quot;image&quot;: &quot;GCC_train_002582585.jpg&quot;
}
```

(sft_vlm_data.jsonl) å•å›¾æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†æ ¼å¼ï¼š

```json lines
{
  &quot;conversations&quot;: [
    {
      &quot;role&quot;: &quot;user&quot;,
      &quot;content&quot;: &quot;é—¹é’Ÿçš„ä½ç½®å¯¹ç¡çœ è´¨é‡æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ&lt;image&gt;&quot;
    },
    {
      &quot;role&quot;: &quot;assistant&quot;,
      &quot;content&quot;: &quot;æŠŠæ•°å­—é—¹é’Ÿæ”¾åœ¨åºŠå¤´æŸœ...&quot;
    }
  ],
  &quot;image&quot;: &quot;train-00000-of-00001_image_0_0.jpg&quot;
}
```

(sft_vlm_data_multi.jsonl) å¤šå›¾æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†æ ¼å¼ï¼š

```json lines
{
  &quot;conversations&quot;: [
    {
      &quot;role&quot;: &quot;user&quot;,
      &quot;content&quot;: &quot;context: Source Image: &lt;image&gt; Target Image: &lt;image&gt; Instruction: What is the correct image edit instruction that can transfrom the source image to target image?&lt;image&gt;&quot;
    },
    {
      &quot;role&quot;: &quot;assistant&quot;,
      &quot;content&quot;: &quot;take the people out of the back in the photo. Remove the two people behind the woman in the white dress and the man in the blue suit. remove people behind the couple in the centre&quot;
    }
  ],
  &quot;image&quot;: &quot;0.jpg, 1.jpg&quot;
}
```

&lt;details&gt;
&lt;summary&gt; æ•°æ®è¯´æ˜ &lt;/summary&gt;

* å¤šå›¾æ•°æ®é›†è§„æ¨¡ç›¸å¯¹è¾ƒå°ä¸”ä¸ºè‹±æ–‡å¯¹è¯ï¼Œæ•°æ®é›†ä»…åŒ…å«ä¸¤å›¾å¯¹æ¯”çš„åœºæ™¯ï¼Œå› æ­¤å¾®è°ƒæ•ˆæœæœ‰é™ï¼Œè¿™é‡Œåªæä¾›ä¸€ç§å‚è€ƒæ€è·¯ã€‚


* `jsonl`å‡ä¸ºæ–‡æœ¬æŒ‡ä»¤ï¼Œ`images.zip`å‡ä¸ºé…å¥—çš„å›¾åƒæ•°æ®ï¼ˆä¸‹è½½åéœ€è¦è§£å‹ï¼‰

&lt;/details&gt;

æ•°æ®é›†ä¸‹è½½åœ°å€ï¼š([ModelScope](https://www.modelscope.cn/datasets/gongjy/minimind-v_dataset) | [HuggingFace](https://huggingface.co/datasets/jingyaogong/minimind-v_dataset))

## â…¡ è®­ç»ƒ

&gt; train_pretrain_vlm

é¢„è®­ç»ƒä»595Kæ¡æ•°æ®é›†ä¸­å­¦ä¹ å›¾ç‰‡çš„é€šç”¨çŸ¥è¯†ï¼Œæ¯”å¦‚é¹¿æ˜¯é¹¿ï¼Œç‹—æ˜¯ç‹—ã€‚

&gt; train_sft_vlm

æŒ‡ä»¤å¾®è°ƒä»300Kæ¡çœŸå®å¯¹è¯æ•°æ®é›†ä¸­å­¦ä¹ å¯¹å›¾ç‰‡æé—®çš„çœŸå®é—®ç­”æ ¼å¼ï¼Œæ›´ç¬¦åˆä¸äººç±»çš„äº¤æµä¹ æƒ¯ã€‚

&gt; train_sft_vlm

å¤šå›¾å¾®è°ƒæä¾›demoï¼šé¸Ÿç±»å¯¹æ¯”æ•°æ®é›†ï¼Œé•¿åº¦ä¸º13.6kçš„çœŸå®é—®ç­”æ ¼å¼ã€‚

è®­ç»ƒæ—¶å‡å†»ç»“visual encoderä¹Ÿå°±æ˜¯clipæ¨¡å‹æ¢¯åº¦ï¼Œ
åªè®­ç»ƒProjectionå’ŒLLMä¸¤éƒ¨åˆ†ã€‚
é¢„è®­ç»ƒä¸­ï¼Œåªè®¾ç½®Projectionå’ŒLLMçš„æœ€åä¸€å±‚å‚æ•°å¯å­¦ä¹ ã€‚
æŒ‡ä»¤å¾®è°ƒä¸­ï¼Œè®¾ç½®Projectionå’ŒLLMçš„å…¨éƒ¨å‚æ•°å¯å­¦ä¹ ã€‚

&gt; è®­ç»ƒæ—¶é—´å’ŒLossèµ°åŠ¿ï¼ˆä»…ä¾›å‚è€ƒï¼‰

Pretrain [512+8] &amp; [768+16]
![input](./images/pretrain_loss.png)

SFT [512+8] &amp; [768+16]
![input](./images/sft_loss.png)

## â…¢ æ¨¡å‹æƒé‡

(åŸç”ŸPyTorch`*.pth`æƒé‡æ–‡ä»¶) ä¸‹è½½åœ°å€ï¼š
([ModelScope](https://www.modelscope.cn/models/gongjy/MiniMind2-V-PyTorch) | [HuggingFace](https://huggingface.co/jingyaogong/MiniMind2-V-PyTorch))

(`Transformers`æ ¼å¼æ¨¡å‹)
ä¸‹è½½åœ°å€ï¼š
([ModelScope](https://www.modelscope.cn/profile/gongjy) | [HuggingFace](https://huggingface.co/collections/jingyaogong/minimind-v-67000833fb60b3a2e1f3597d))

&gt; æ³¨ï¼šTransformersç‰ˆæœ¬å‡ä¸ºå•å›¾æŒ‡ä»¤å¾®è°ƒåçš„`MiniMind-V`æ¨¡å‹

# ğŸ“Œ Test

### æ•ˆæœæµ‹è¯•

#### å•å›¾å¯¹è¯

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;å›¾ç‰‡&lt;/th&gt;
      &lt;th&gt;MiniMind2-V&lt;/th&gt;
      &lt;th&gt;MiniMind2-V-Small&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;img src=&quot;./dataset/eval_images/åŸå¸‚è½¦æ°´é©¬é¾™-city-traffic.jpg&quot; alt=&quot;city-traffic&quot;&gt;
        &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
      &lt;/td&gt;
      &lt;td&gt;å›¾ä¸­æ˜¯ä¸€ä¸ªç¹å¿™çš„åŸå¸‚è¡—é“ï¼Œä¸€æ¡é•¿é•¿çš„è¡—é“ä¸¤æ—éƒ½æ˜¯é«˜æ¥¼å¤§å¦ã€‚è¿™æ¡è¡—ä¸ŠæŒ¤æ»¡äº†æ±½è½¦ã€å¡è½¦å’Œå…¬å…±æ±½è½¦ï¼Œè¿˜æœ‰è®¸å¤šå…¶ä»–è½¦è¾†åœ¨è·¯ä¸Šè¡Œé©¶ã€‚åœ¨è¡—é“ä¸Šï¼Œå¯ä»¥çœ‹åˆ°è®¸å¤šæ±½è½¦ï¼Œæœ‰çš„åœ¨é«˜é€Ÿè¡Œé©¶ï¼Œè€Œå…¶ä»–çš„åˆ™åœåœ¨è¡—é“ä¸€ä¾§ã€‚æ­¤å¤–è¿˜æœ‰ä¸€è¾†å…¬äº¤è½¦ä¹Ÿåœåœ¨è¡—é“çš„å³ä¾§ã€‚è¡—é“ä¸Šå¯ä»¥çœ‹åˆ°äº¤é€šç¯ï¼Œè¡¨æ˜è¿™æ˜¯ä¸€ä¸ªç¹å¿™çš„åŸå¸‚ç¯å¢ƒã€‚&lt;/td&gt;
      &lt;td&gt;å›¾ä¸­æ˜¯ä¸€ä¸ªç¹å¿™çš„åŸå¸‚æ™¯è±¡ï¼Œæœ‰å‡ è¾†æ±½è½¦å’Œä¸€è¾†å¡è½¦è¡Œé©¶åœ¨åŸå¸‚è¡—é“ä¸Šã€‚å¯ä»¥çœ‹åˆ°è®¸å¤šäº¤é€šä¿¡å·ç¯ï¼Œå…¶ä¸­ä¸€äº›ä½äºè¡—é“å·¦ä¾§ï¼Œå¦ä¸€äº›åˆ™åœ¨å³ä¾§ã€‚å¯ä»¥çœ‹åˆ°æœ‰å‡ ä¸ªäººåœ¨è¡—ä¸Šè¡Œèµ°ï¼Œå…¶ä¸­ä¸€äº›äººç«™å¾—ç¦»è¡—é“æ›´è¿‘ä¸€äº›ï¼Œè€Œå¦ä¸€äº›åˆ™è·ç¦»è¾ƒè¿œã€‚è¿˜æœ‰ä¸€ä¸ªåœè½¦æ ‡å¿—ä½äºç”»é¢çš„å·¦ä¾§ï¼Œæš—ç¤ºç€åŸå¸‚ç¯å¢ƒã€‚å¯ä»¥çœ‹åˆ°è¡—é“ä¸Šæœ‰ä¸¤è¾†æ±½è½¦ï¼Œä¸€è¾†åœ¨å³è¾¹ï¼Œå¦ä¸€è¾†åœ¨å·¦è¾¹ï¼Œè¿˜æœ‰ä¸€è¾†åœ¨å·¦è¾¹ã€‚è¿™å¹…å›¾åƒæ•æ‰åˆ°äº†éƒ½å¸‚ç¯å¢ƒä¸­å…¸å‹çš„ä¸€å¤©ã€‚&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;img src=&quot;./dataset/eval_images/å¤ªç©ºå®‡èˆªå‘˜-Astronaut-Space.jpg&quot; alt=&quot;astronaut&quot;&gt;
        &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
      &lt;/td&gt;
      &lt;td&gt;å›¾ç‰‡æ˜¾ç¤ºäº†ä¸€ä¸ªå®‡èˆªå‘˜çš„å®‡èˆªå‘˜èº«ç©¿å®‡èˆªæœï¼Œååœ¨ä¸€æ¶å¤§å‹èˆªå¤©é£æœºä¸Šã€‚ä»–ä»¬ä¼¼ä¹æ­£åœ¨è¿›è¡Œä¸€æ¬¡å®‡èˆªå‘˜ç™»æœºæˆ–ä¸‹æœºçš„æ—…ç¨‹ã€‚åœ¨å®‡èˆªå‘˜çš„èº«åï¼Œæœ‰ä¸€ä¸ªç«ç®­å‘å°„æ¶ï¼Œå¯èƒ½æ˜¯ç”¨æ¥æ”¯æ’‘å®‡èˆªå‘˜åœ¨æ—…ç¨‹ä¸­çš„ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€æ¶é£æœºåœåœ¨æœºåº“é™„è¿‘ï¼Œè¿›ä¸€æ­¥è¡¨æ˜è¿™æ˜¯ä¸€æ¬¡èˆªç©ºå±•ã€‚åœ¨é£æœºçš„å‘¨å›´ï¼Œè¿˜æœ‰ä¸€äº›äººï¼Œä½†ä»–ä»¬çœ‹èµ·æ¥ç¦»é£æœºå¾ˆè¿‘ã€‚å¯ä»¥çœ‹åˆ°ä¸€ä¸ªäººç«™åœ¨é£æœºé™„è¿‘ï¼Œå¯èƒ½æ­£åœ¨è§‚å¯Ÿæˆ–ç­‰å¾…èˆªå¤©é£æœºå‡†å¤‡èµ·é£ã€‚&lt;/td&gt;
      &lt;td&gt;åœºæ™¯ä¸­ï¼Œä¸€åå£«å…µæˆ´ç€å¤´ç›”ç«™åœ¨ä¸€æ¶å¤§å‹é£æœºä¸Šã€‚è¿™æ¶é£æœºä¼¼ä¹æ˜¯ä¸€æ¶å†›ç”¨å†›ç”¨é£æœºï¼Œä¼¼ä¹æ­£å‡†å¤‡ç™»ä¸Šä¸€æ¶é£æœºã€‚å¦ä¸€ä¸ªäººåˆ™ç«™åœ¨å‰é¢ï¼Œå¯èƒ½æ­£åœ¨è§‚å¯Ÿé£è¡Œè¿‡ç¨‹ã€‚åœ¨é£æœºå‘¨å›´ï¼Œæœ‰å‡ ä¸ªäººï¼Œå…¶ä¸­ä¸€äº›ç«™åœ¨å·¦ä¾§ï¼Œå¦ä¸€äº›åˆ™ç«™åœ¨å³ä¾§ã€‚ä»–ä»¬ä¼¼ä¹æ­£åœ¨è§‚çœ‹é£è¡Œå‘˜çš„è¡¨ç°ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€è¾†å¡è½¦åœåœ¨é è¿‘å·¦ä¾§çš„ä½ç½®ï¼Œå¯èƒ½æ˜¯ä¸ºäº†æ›´å…·ä½“åœ°è§‚å¯Ÿé£è¡Œè¿‡ç¨‹ã€‚&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;img src=&quot;./dataset/eval_images/å°ç‹—ç¾å¥³æµ·è¾¹-Dog-Woman-Sea.jpg&quot; alt=&quot;dog-woman-sea&quot;&gt;
        &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
      &lt;/td&gt;
      &lt;td&gt;å›¾ç‰‡ä¸­ï¼Œä¸€ä¸ªå¥³äººååœ¨æ²™æ»©ä¸Šï¼Œæ‰‹é‡Œæ‹¿ç€ä¸€åªç™½è‰²çš„ç‹—ã€‚å¥¹çœ‹èµ·æ¥åƒæ˜¯ä¸ªå¥³äººï¼Œååœ¨æ²™åœ°ä¸Šï¼Œçœ‹ç€å¥¹ã€‚ä¸€åªç‹—ä¹Ÿååœ¨å¥¹æ—è¾¹ï¼Œçœ‹èµ·æ¥å¾ˆæ”¾æ¾å’Œèˆ’é€‚ã€‚æµ·æ»©ä¸Šæ•£å¸ƒç€å…¶ä»–æ²™æ»©æ¸¸å®¢ï¼Œæœ‰äº›äººåç€ï¼Œè€Œå¦ä¸€äº›äººåˆ™ååœ¨æ›´è¿œçš„åœ°æ–¹ã€‚èƒŒæ™¯ä¸­å¯ä»¥çœ‹åˆ°ä¸€è‰˜èˆ¹ï¼Œè¿™è¡¨æ˜è¿™æ˜¯ä¸€ä¸ªå—æ¬¢è¿çš„æµ·æ»©æ—…æ¸¸ç›®çš„åœ°ã€‚&lt;/td&gt;
      &lt;td&gt;ä¸¤ä¸ªäººååœ¨æµ·æ»©ä¸Šï¼Œä¸€è¾¹æ‡’æ´‹æ´‹åœ°èººåœ¨æ²™æ»©ä¸Šï¼Œå¦ä¸€è¾¹åˆ™åç€ã€‚ä»–ä»¬ä¼¼ä¹æ­£åœ¨äº«å—æµ·è¾¹æ—¶å…‰ã€‚æµ·æ»©ä¸Šæœ‰å‡ æŠŠæ¤…å­ï¼Œå…¶ä¸­ä¸€æŠŠé è¿‘æ²™æ»©çš„å·¦ä¾§ï¼Œå¦ä¸€æŠŠåœ¨ä¸­é—´ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€åªç‹—èººåœ¨æ²™åœ°ä¸Šï¼Œä¸ºè¿™ä¸ªåœºæ™¯å¢æ·»äº†ä¸€ç§æ”¾æ¾çš„æ°”æ°›ã€‚&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;img src=&quot;./dataset/eval_images/å½©è™¹ç€‘å¸ƒ-Rainbow-Falls.jpg&quot; alt=&quot;rainbow-falls&quot;&gt;
        &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
      &lt;/td&gt;
      &lt;td&gt;ç…§ç‰‡æ•æ‰åˆ°ä¸€å¹…ç¾ä¸½å¦‚ç”»çš„å¤§è‡ªç„¶åœºæ™¯ï¼ŒèƒŒæ™¯æ˜¯é«˜å±±å³¦å´–ã€‚åœ¨æ°´è¾¹ï¼Œä¸€åº§å·¨å¤§çš„å–·æ³‰æ¨ªè·¨ç€æ°´é¢ï¼Œå¸å¼•ç€è®¸å¤šæ¸¸å®¢ã€‚æ°´é¢ä¸Šæœ‰å‡ ä¸ªäººï¼Œä»–ä»¬æˆ–ç«™æˆ–ååœ¨å–·æ³‰å‘¨å›´ï¼Œæˆ–ç«™æˆ–åã€‚æœ‰äº›äººå¯ä»¥çœ‹åˆ°ä»–ä»¬åœ¨æ°´ä¸­è¡Œèµ°ï¼Œè€Œå…¶ä»–äººåˆ™ç«™åœ¨æ°´è¾¹ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™å¹…ç”»æç»˜çš„æ˜¯ä¸€ä¸ªç¾ä¸½è€Œå®é™çš„ç¯å¢ƒï¼Œåœ¨é‚£é‡Œäººä»¬å¯ä»¥æ¬£èµåˆ°å¦‚ç”»èˆ¬çš„ç¾æ™¯ã€‚&lt;/td&gt;
      &lt;td&gt;åœ¨ä¸€ä¸ªç¾ä¸½çš„è“è‰²å¤©ç©ºä¸‹ï¼Œä¸€åº§å·¨å¤§è€Œå·¨å¤§çš„ç™½è‰²ç€‘å¸ƒä¸Šæ–¹æ‚¬æŒ‚ç€ä¸€åªå·¨å¤§çš„æ¹¿æµæ°´ã€‚è¿™åªç€‘å¸ƒä½äºä¸€åº§å±±ä¸Šï¼Œä¸ºæ•´ä¸ªåœºæ™¯å¢æ·»äº†ä¸€ç§è¿·äººè€Œåˆå®é™çš„æ°”æ°›ã€‚åœ¨è¿™å¹…å›¾åƒçš„èƒŒæ™¯ä¸­ï¼Œå¯ä»¥çœ‹åˆ°å‡ è‰˜èˆ¹ï¼Œå…¶ä¸­ä¸€äº›é è¿‘æ°´è¾¹ï¼Œå…¶ä»–çš„åˆ™ç¦»å¾—è¾ƒè¿œã€‚è¿™äº›èˆ¹åªä¼¼ä¹æ­£åœ¨ä¸ºé£æ™¯æˆ–æˆ·å¤–æ´»åŠ¨åšå‡†å¤‡ã€‚&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;img src=&quot;./dataset/eval_images/æ¤…å­è€äººçœ‹ä¹¦-Chair-Elderly-Reading.jpg&quot; alt=&quot;elderly-reading&quot;&gt;
        &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
      &lt;/td&gt;
      &lt;td&gt;å›¾ä¸­ï¼Œä¸€ä¸ªç”·äººååœ¨å…¬å›­çš„é•¿æ¤…ä¸Šï¼Œæ—è¾¹æ˜¯ä¸€æŠŠç»¿è‰²æ¤…å­ã€‚ä»–èº«è¾¹æœ‰ä¸€æœ¬æ‰“å¼€çš„ä¹¦ï¼Œä¸Šé¢å†™ç€&quot;è¯»ä¹¦&quot;ä¸€å¥è¯ï¼Œæš—ç¤ºä»–å¯èƒ½æ­£åœ¨é˜…è¯»ã€‚å…¬å›­é‡Œæœ‰ä¸€å¼ é•¿æ¤…å’Œä¸€å¼ å…¬å›­é•¿æ¤…ï¼Œä¸ºå‘¨å›´çš„ç¯å¢ƒå¢æ·»äº†å‡ åˆ†ç”Ÿæ°”ã€‚åœ¨å…¬å›­çš„å‘¨å›´ï¼Œæœ‰å‡ è¾†æ±½è½¦å’Œä¸€è¾†å¡è½¦ï¼Œè¡¨æ˜è¿™æ˜¯ä¸€ä¸ªå…¬å…±åŒºåŸŸã€‚æ­¤å¤–ï¼Œè¿˜å¯ä»¥çœ‹åˆ°ä¸€ä¸ªäººç«™åœ¨å…¬å›­çš„ä¸åŒä½ç½®ä¸Šï¼Œå¯èƒ½æ˜¯ç­‰ç€ä¸Šè·¯æˆ–è¿‡é©¬è·¯ã€‚&lt;/td&gt;
      &lt;td&gt;ä¸€ä¸ªç©¿ç€çŸ­è£¤çš„è€äººååœ¨å…¬å›­é•¿æ¤…ä¸Šï¼Œå‘¨å›´æ˜¯æ ‘æœ¨ã€‚ä»–ä¼¼ä¹æ­£åœ¨è¯»ä¸€æœ¬ä¹¦ï¼Œå¯èƒ½æ˜¯åœ¨è¯»ä¹¦ã€‚èƒŒæ™¯ä¸­æœ‰ä¸€åº§é•¿å‡³ï¼Œä¸ºè¿™ä¸ªåœºæ™¯æä¾›äº†å……è¶³çš„åº§ä½ã€‚åœ¨èƒŒæ™¯ä¸­ï¼Œå¯ä»¥çœ‹åˆ°ä¸€æŠŠæ¤…å­å’Œä¸€å¼ é¤æ¡Œï¼Œè¿™è¯´æ˜è¿™ä¸ªåœºæ™¯å¯èƒ½æ˜¯åœ¨ä¸€ä¸ªæˆ·å¤–åº§ä½åŒºï¼Œé‚£é‡Œæœ‰æ¤…å­ä¾›äººä»¬åä¸‹æ¥æ”¾æ¾ã€‚&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;img src=&quot;./dataset/eval_images/ç†ŠçŒ«è‰åœ°-Panda-Grassland.jpg&quot; alt=&quot;panda-grassland&quot;&gt;
        &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
      &lt;/td&gt;
      &lt;td&gt;å›¾ä¸­ï¼Œä¸€åªç™½è‰²çš„æ£•ç†Šååœ¨è‰åœ°ä¸Šï¼Œæ—è¾¹æ˜¯ä¸€åªé•¿ç€æ£•è‰²æ–‘ç‚¹çš„å¤§ç†Šã€‚è¿™åªç†Šçœ‹èµ·æ¥å¾ˆå®³ç¾æˆ–é¡½çš®ï¼Œå› ä¸ºå®ƒæ­£èººåœ¨è‰åœ°ä¸Šä¼‘æ¯ï¼Œçœ‹ä¸Šå»å¾ˆæ”¾æ¾ã€‚&lt;/td&gt;
      &lt;td&gt;åœ¨è¿™å¹…å›¾åƒä¸­ï¼Œä¸€åªæ£•è‰²çš„ç†Šæ­£åœ¨è‰åœ°ä¸Šæ¼«æ­¥ã€‚è¿™åªç†Šè¢«æ”¾ç½®åœ¨è‰åœ°ä¸Šï¼Œå æ®äº†ç”»é¢çš„å¤§éƒ¨åˆ†ç©ºé—´ã€‚å®ƒä¼¼ä¹æ­£åœ¨è‡ªç„¶ç¯å¢ƒä¸­è¡Œèµ°ï¼Œå¯èƒ½æ˜¯åœ¨è‰åœ°ä¸Šã€‚åœ¨èƒŒæ™¯ä¸­ï¼Œæœ‰å‡ æ£µæ ‘ï¼Œä¸ºç”»é¢å¢æ·»äº†è‡ªç„¶å…ƒç´ ã€‚ä¸€åªé¸Ÿåœ¨åœºæ™¯çš„ä¸­é—´é™„è¿‘é£ç¿”ï¼Œä¸ºç”»é¢å¢æ·»äº†ç”Ÿæ°”å‹ƒå‹ƒçš„æ°”æ°›ã€‚&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;img src=&quot;./dataset/eval_images/è‡ªè¡Œè½¦é²œèŠ±-Bicycle-Flowers.jpg&quot; alt=&quot;bicycle-flowers&quot;&gt;
        &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
      &lt;/td&gt;
      &lt;td&gt;å›¾ç‰‡å±•ç¤ºäº†ä¸€ä¸ªæ¼‚äº®çš„èŠ±ç“¶ï¼Œé‡Œé¢æ’æ»¡äº†äº”é¢œå…­è‰²çš„é²œèŠ±å’ŒèŠ±æŸã€‚è¿™äº›èŠ±æŸæ•£è½åœ¨æ•´ä¸ªèŠ±ç“¶ä¸­ï¼Œç»™äººä¸€ç§èµå¿ƒæ‚¦ç›®çš„æ„Ÿè§‰ã€‚èŠ±ç“¶é‡Œæ’ç€äº”é¢œå…­è‰²é²œèŠ±ï¼Œåˆ›é€ å‡ºä¸€ç§ä»¤äººèµå¿ƒæ‚¦ç›®çš„æ™¯è±¡ã€‚è¿™äº›é²œèŠ±è¢«æ‘†æ”¾åœ¨ä¸€å¼ æ¡Œå­ä¸Šï¼Œå¾ˆå¯èƒ½æ˜¯ä¸ºäº†å±•ç¤ºå®ƒä»¬çš„ç¾ä¸½è€Œæ‘†æ”¾çš„ã€‚&lt;/td&gt;
      &lt;td&gt;åœºæ™¯ä¸­ï¼Œä¸€è¾†ç»¿è‰²å’Œç´«è‰²ç›¸é—´çš„è‡ªè¡Œè½¦åœåœ¨ä¸€æ ‹å»ºç­‘æ—è¾¹ï¼Œå®ƒè¢«æ”¾ç½®åœ¨ä¸€æ£µå¤§æ ‘æ—ã€‚è¿™è¾†è‡ªè¡Œè½¦è¢«æ‘†æ”¾åœ¨é™„è¿‘ï¼Œä¸ºè¿™ä¸ªåœºæ™¯å¢æ·»äº†å‡ åˆ†è‰²å½©ã€‚é™¤äº†è‡ªè¡Œè½¦å¤–ï¼Œè¿˜æœ‰ä¸€äº›å…¶ä»–çš„è‡ªè¡Œè½¦ï¼ŒåŒ…æ‹¬ä¸¤ä¸ªä½äºå‰æ™¯ä¸­çš„ä¸€ä¸ªå’Œä½äºèƒŒæ™¯ä¸­é è¿‘ä¸­å¿ƒä½ç½®çš„å¦ä¸€ä¸ªã€‚è‡ªè¡Œè½¦çš„å­˜åœ¨è¡¨æ˜å®ƒå¯èƒ½æ˜¯åœåœ¨é‚£é‡Œçš„ã€‚&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;img src=&quot;./dataset/eval_images/èˆè¹ˆ-dance.jpg&quot; alt=&quot;dance&quot;&gt;
        &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
      &lt;/td&gt;
      &lt;td&gt;å›¾ç‰‡ä¸­çš„å¥³äººç©¿ç€ä¸€ä»¶ç™½è‰²è¿è¡£è£™ï¼Œè„šä¸Šè¿˜ç³»ç€ä¸€æ¡é»‘è‰²ç½‘çƒè£™ã€‚å¥¹æ­£åœ¨è¡¨æ¼”ä¸€ä¸ªç½‘çƒæ¯”èµ›ï¼Œå¾ˆå¯èƒ½æ˜¯åœ¨æ¯”èµ›ä¸­ã€‚åœ¨èƒŒæ™¯ä¸­å¯ä»¥çœ‹åˆ°å‡ æŠŠæ¤…å­ï¼Œå¯èƒ½æ˜¯ä¸ºäº†è§‚ä¼—æˆ–å…¶ä»–è§‚ä¼—çš„åº§ä½å®‰æ’è€Œæ‘†æ”¾çš„ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªé•¿å‡³æ”¾åœ¨åœºæ™¯å·¦ä¾§ï¼Œä¸ºäººä»¬æä¾›äº†ä¸€ä¸ªä¼‘æ¯çš„åœ°æ–¹ã€‚&lt;/td&gt;
      &lt;td&gt;ä¸€åèº«ç©¿ç™½è‰²è¡£æœçš„å¥³å­ç«™åœ¨èˆå°ä¸Šï¼Œæ‰‹é‡Œæ‹¿ç€ä¸€åªæ‰‹æ‹¿ç€ç™½è‰²é£ç›˜ã€‚å¥¹ä¼¼ä¹æ­£åœ¨å‚åŠ ä¸€ä¸ªèˆå°èˆä¼šæˆ–æ¯”èµ›ã€‚åœºæ™¯ä¸­è¿˜æœ‰å…¶ä»–å‡ ä¸ªäººï¼Œå…¶ä¸­ä¸€ä¸ªç«™åœ¨èˆå°å·¦ä¾§ï¼Œå¦ä¸€ä¸ªç«™åœ¨å³ä¾§ï¼Œç¬¬ä¸‰ä¸ªäººåˆ™ç«™åœ¨åœºåœ°å³ä¾§ã€‚èˆå°ä¸Šæœ‰å‡ ä¸ªè§‚ä¼—ï¼Œæœ‰çš„ç«™ç€ï¼Œæœ‰çš„åç€ï¼Œè¿˜æœ‰ä¸€äº›ç«™ç€ã€‚è¿™çœ‹èµ·æ¥åƒæ˜¯ä¸€åœºæ¬¢ä¹çš„èŠ‚æ—¥æˆ–æ´»åŠ¨ã€‚&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

#### å¤šå›¾å¯¹è¯ï¼ˆæ•ˆæœååˆ†æœ‰é™ï¼‰

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;å›¾ç‰‡1&lt;/th&gt;
      &lt;th&gt;å›¾ç‰‡2&lt;/th&gt;
      &lt;th&gt;512_sft_multi&lt;/th&gt;
      &lt;th&gt;768_sft_multi&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;./dataset/eval_multi_images/bird/0.jpg&quot; alt=&quot;a-bird.png&quot;&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;./dataset/eval_multi_images/bird/1.jpg&quot; alt=&quot;a-bird.png&quot;&gt;&lt;/td&gt;
      &lt;td&gt;è¿™å¹…å›¾åƒæ˜¾ç¤ºäº†ä¸€ç§é¸Ÿç°¸æˆ®çš„åœºæ™¯ï¼šä¸€ä¸ªå¥³äººç«™åœ¨çº¢ç»¿ç›¸é—´çš„çº¢ç»¿ç›¸é—´çš„ç´«è‰²é¸Ÿç°¸æˆ´åœ¨å¥¹èº«ä¸Šã€‚å¥³äººç«™åœ¨çº¢è‰²çš„é¸Ÿç°¸æˆ´åœ¨å¥¹èº«ä¸Šï¼Œè€Œå¥¹çš„ç¿»é¢†ä¸Šçš„é‚£åªçº¢é¸Ÿåˆ™ç«™åœ¨å¥¹èº«åã€‚&lt;/td&gt;
      &lt;td&gt;è¿™ä¸¤åªé¸Ÿåœ¨åŒä¸€ç‰‡æ ‘æ—ä¸­é£ç¿”ï¼Œæœ‰çš„ä½äºç”»é¢ä¸­å¿ƒï¼Œè€Œå¦ä¸€äº›åˆ™è¾ƒå°ï¼Œå½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚è¿™ç§é¸Ÿç±»çš„å‡ºç°çªå‡ºäº†å…¶é£è¡Œèƒ½åŠ›å’Œé€‚åº”æ€§ï¼Œå› ä¸ºå®ƒä»¬èƒ½å¤Ÿåœ¨æ ‘æ—ä¸­å¿«é€Ÿè¿…é€Ÿç§»åŠ¨ã€‚æ­¤å¤–ï¼Œä¸¤åªé¸Ÿçš„ä½ç½®ä¸åŒï¼Œä¸€ä¸ªåœ¨å›¾åƒçš„å·¦è¾¹ï¼Œå¦ä¸€ä¸ªåœ¨å³è¾¹ï¼Œè¿™è¡¨æ˜å®ƒä»¬åœ¨åŒä¸€ç‰‡æ ‘æ—ä¸­ç§»åŠ¨å¾—å¾ˆè¿‘ã€‚è¿™ç§é¸Ÿç±»çš„è‡ªç„¶è¡Œä¸ºä¹Ÿæœ‰åŠ©äºåŒºåˆ†è¿™ä¸¤ç§é¸Ÿç±»ç‰©ç§ã€‚&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

### æ•ˆæœå°ç»“ï¼š

è§†è§‰ä¿¡å·å¯¹äºLLMè§†ä½œä¸€ç§ç‰¹æ®Šçš„å¤–è¯­ï¼Œ
å› æ­¤â€œå­¦ä¹ å¤–è¯­â€çš„èƒ½åŠ›é«˜ä½ï¼Œ
å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºLLMçš„èƒ½åŠ›ã€‚
LLMæ€§èƒ½è¶Šå¼ºï¼Œå¯¹åº”çš„VLMå¿…ç„¶è¶Šå¼ºï¼Œæ­¤æ—¶æ•ˆæœå¢ç›Šä¼šå¾ˆæ˜æ˜¾ã€‚

#### æœªæ¥å€¼å¾—æ”¹è¿›çš„æ–¹é¢ï¼š

```text
&gt; æ›´ç®€å•çš„Projectionçš„è·¨æ¨¡æ€ç‰¹å¾å¯¹é½æ–¹å¼ï¼Œç›¸è¾ƒäºCross-Attentionå¯èƒ½å¤„äºåŠ£åŠ¿ã€‚
&gt; Clipæ¨¡å‹å¯ä»¥å°è¯•æ›´å¤§æ€§èƒ½æ›´å¼ºçš„largeç³»åˆ—ï¼Œç”¨æ›´å…·ç»†ç²’åº¦çš„tokenè¡¨å¾å›¾åƒç‰¹å¾ï¼Œç›®å‰ä»ç²—ç³™ã€‚
&gt; åˆ†è¾¨ç‡ä¸é«˜ï¼Œç†è®ºä¸Šåªæœ‰224Ã—224ï¼ˆminimind-væ•°æ®é›†ä¸ºèŠ‚çœç©ºé—´ï¼Œä»…è®¾å®šä¸º128Ã—128ï¼‰ã€‚
&gt; ...
```

# ğŸ“Œ Acknowledge

&gt; [!TIP]
&gt; å¦‚æœæ‚¨è§‰å¾— `MiniMind-V`å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼Œå¯ä»¥åœ¨ GitHub ä¸ŠåŠ ä¸€ä¸ªâ­&lt;br/&gt;
&gt; æ°´å¹³æœ‰é™éš¾å…å­˜åœ¨æœªçŸ¥çš„çº°æ¼ï¼Œæ¬¢è¿æ‰€æœ‰äººåœ¨Issuesäº¤æµæŒ‡æ­£æˆ–æäº¤PRæ”¹è¿›é¡¹ç›®&lt;br/&gt;
&gt; æ‚¨çš„æ”¯æŒå°±æ˜¯æŒç»­æ”¹è¿›é¡¹ç›®çš„åŠ¨åŠ›ï¼Œè°¢è°¢ï¼

## ğŸ¤[è´¡çŒ®è€…](https://github.com/jingyaogong/minimind/graphs/contributors)

&lt;a href=&quot;https://github.com/jingyaogong&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/62287848&quot; width=&quot;70px&quot; height=&quot;70px&quot;/&gt;&lt;/a&gt;
&amp;nbsp;
&lt;a href=&quot;https://github.com/xinyanghuang7&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/7503252&quot; width=&quot;70px&quot; height=&quot;70px&quot;/&gt;&lt;/a&gt;
&amp;nbsp;
&lt;a href=&quot;https://github.com/chuanzhubin&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/2813798&quot; width=&quot;70px&quot; height=&quot;70px&quot;/&gt;&lt;/

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[RVC-Project/Retrieval-based-Voice-Conversion-WebUI]]></title>
            <link>https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI</link>
            <guid>https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI</guid>
            <pubDate>Tue, 15 Apr 2025 00:04:30 GMT</pubDate>
            <description><![CDATA[Easily train a good VC model with voice data <= 10 mins!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI">RVC-Project/Retrieval-based-Voice-Conversion-WebUI</a></h1>
            <p>Easily train a good VC model with voice data <= 10 mins!</p>
            <p>Language: Python</p>
            <p>Stars: 28,685</p>
            <p>Forks: 4,046</p>
            <p>Stars today: 43 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;h1&gt;Retrieval-based-Voice-Conversion-WebUI&lt;/h1&gt;
ä¸€ä¸ªåŸºäºVITSçš„ç®€å•æ˜“ç”¨çš„å˜å£°æ¡†æ¶&lt;br&gt;&lt;br&gt;

[![madewithlove](https://img.shields.io/badge/made_with-%E2%9D%A4-red?style=for-the-badge&amp;labelColor=orange
)](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI)

&lt;img src=&quot;https://counter.seku.su/cmoe?name=rvc&amp;theme=r34&quot; /&gt;&lt;br&gt;

[![Open In Colab](https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&amp;logo=googlecolab&amp;color=525252)](https://colab.research.google.com/github/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/blob/main/Retrieval_based_Voice_Conversion_WebUI.ipynb)
[![Licence](https://img.shields.io/badge/LICENSE-MIT-green.svg?style=for-the-badge)](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/blob/main/LICENSE)
[![Huggingface](https://img.shields.io/badge/ğŸ¤—%20-Spaces-yellow.svg?style=for-the-badge)](https://huggingface.co/lj1995/VoiceConversionWebUI/tree/main/)

[![Discord](https://img.shields.io/badge/RVC%20Developers-Discord-7289DA?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.gg/HcsmBBGyVk)

[**æ›´æ–°æ—¥å¿—**](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/blob/main/docs/Changelog_CN.md) | [**å¸¸è§é—®é¢˜è§£ç­”**](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%A7%A3%E7%AD%94) | [**AutoDLÂ·5æ¯›é’±è®­ç»ƒAIæ­Œæ‰‹**](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/Autodl%E8%AE%AD%E7%BB%83RVC%C2%B7AI%E6%AD%8C%E6%89%8B%E6%95%99%E7%A8%8B) | [**å¯¹ç…§å®éªŒè®°å½•**](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/Autodl%E8%AE%AD%E7%BB%83RVC%C2%B7AI%E6%AD%8C%E6%89%8B%E6%95%99%E7%A8%8B](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/%E5%AF%B9%E7%85%A7%E5%AE%9E%E9%AA%8C%C2%B7%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%95)) | [**åœ¨çº¿æ¼”ç¤º**](https://modelscope.cn/studios/FlowerCry/RVCv2demo)

[**English**](./docs/en/README.en.md) | [**ä¸­æ–‡ç®€ä½“**](./README.md) | [**æ—¥æœ¬èª**](./docs/jp/README.ja.md) | [**í•œêµ­ì–´**](./docs/kr/README.ko.md) ([**éŸ“åœ‹èª**](./docs/kr/README.ko.han.md)) | [**FranÃ§ais**](./docs/fr/README.fr.md) | [**TÃ¼rkÃ§e**](./docs/tr/README.tr.md) | [**PortuguÃªs**](./docs/pt/README.pt.md)

&lt;/div&gt;

&gt; åº•æ¨¡ä½¿ç”¨æ¥è¿‘50å°æ—¶çš„å¼€æºé«˜è´¨é‡VCTKè®­ç»ƒé›†è®­ç»ƒï¼Œæ— ç‰ˆæƒæ–¹é¢çš„é¡¾è™‘ï¼Œè¯·å¤§å®¶æ”¾å¿ƒä½¿ç”¨

&gt; è¯·æœŸå¾…RVCv3çš„åº•æ¨¡ï¼Œå‚æ•°æ›´å¤§ï¼Œæ•°æ®æ›´å¤§ï¼Œæ•ˆæœæ›´å¥½ï¼ŒåŸºæœ¬æŒå¹³çš„æ¨ç†é€Ÿåº¦ï¼Œéœ€è¦è®­ç»ƒæ•°æ®é‡æ›´å°‘ã€‚

&lt;table&gt;
   &lt;tr&gt;
		&lt;td align=&quot;center&quot;&gt;è®­ç»ƒæ¨ç†ç•Œé¢&lt;/td&gt;
		&lt;td align=&quot;center&quot;&gt;å®æ—¶å˜å£°ç•Œé¢&lt;/td&gt;
	&lt;/tr&gt;
  &lt;tr&gt;
		&lt;td align=&quot;center&quot;&gt;&lt;img src=&quot;https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/assets/129054828/092e5c12-0d49-4168-a590-0b0ef6a4f630&quot;&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;img src=&quot;https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/assets/129054828/730b4114-8805-44a1-ab1a-04668f3c30a6&quot;&gt;&lt;/td&gt;
	&lt;/tr&gt;
	&lt;tr&gt;
		&lt;td align=&quot;center&quot;&gt;go-web.bat&lt;/td&gt;
		&lt;td align=&quot;center&quot;&gt;go-realtime-gui.bat&lt;/td&gt;
	&lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;å¯ä»¥è‡ªç”±é€‰æ‹©æƒ³è¦æ‰§è¡Œçš„æ“ä½œã€‚&lt;/td&gt;
		&lt;td align=&quot;center&quot;&gt;æˆ‘ä»¬å·²ç»å®ç°ç«¯åˆ°ç«¯170mså»¶è¿Ÿã€‚å¦‚ä½¿ç”¨ASIOè¾“å…¥è¾“å‡ºè®¾å¤‡ï¼Œå·²èƒ½å®ç°ç«¯åˆ°ç«¯90mså»¶è¿Ÿï¼Œä½†éå¸¸ä¾èµ–ç¡¬ä»¶é©±åŠ¨æ”¯æŒã€‚&lt;/td&gt;
	&lt;/tr&gt;
&lt;/table&gt;

## ç®€ä»‹
æœ¬ä»“åº“å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹
+ ä½¿ç”¨top1æ£€ç´¢æ›¿æ¢è¾“å…¥æºç‰¹å¾ä¸ºè®­ç»ƒé›†ç‰¹å¾æ¥æœç»éŸ³è‰²æ³„æ¼
+ å³ä¾¿åœ¨ç›¸å¯¹è¾ƒå·®çš„æ˜¾å¡ä¸Šä¹Ÿèƒ½å¿«é€Ÿè®­ç»ƒ
+ ä½¿ç”¨å°‘é‡æ•°æ®è¿›è¡Œè®­ç»ƒä¹Ÿèƒ½å¾—åˆ°è¾ƒå¥½ç»“æœ(æ¨èè‡³å°‘æ”¶é›†10åˆ†é’Ÿä½åº•å™ªè¯­éŸ³æ•°æ®)
+ å¯ä»¥é€šè¿‡æ¨¡å‹èåˆæ¥æ”¹å˜éŸ³è‰²(å€ŸåŠ©ckptå¤„ç†é€‰é¡¹å¡ä¸­çš„ckpt-merge)
+ ç®€å•æ˜“ç”¨çš„ç½‘é¡µç•Œé¢
+ å¯è°ƒç”¨UVR5æ¨¡å‹æ¥å¿«é€Ÿåˆ†ç¦»äººå£°å’Œä¼´å¥
+ ä½¿ç”¨æœ€å…ˆè¿›çš„[äººå£°éŸ³é«˜æå–ç®—æ³•InterSpeech2023-RMVPE](#å‚è€ƒé¡¹ç›®)æ ¹ç»å“‘éŸ³é—®é¢˜ã€‚æ•ˆæœæœ€å¥½ï¼ˆæ˜¾è‘—åœ°ï¼‰ä½†æ¯”crepe_fullæ›´å¿«ã€èµ„æºå ç”¨æ›´å°
+ Aå¡Iå¡åŠ é€Ÿæ”¯æŒ

ç‚¹æ­¤æŸ¥çœ‹æˆ‘ä»¬çš„[æ¼”ç¤ºè§†é¢‘](https://www.bilibili.com/video/BV1pm4y1z7Gm/) !

## ç¯å¢ƒé…ç½®
ä»¥ä¸‹æŒ‡ä»¤éœ€åœ¨ Python ç‰ˆæœ¬å¤§äº3.8çš„ç¯å¢ƒä¸­æ‰§è¡Œã€‚  

### Windows/Linux/MacOSç­‰å¹³å°é€šç”¨æ–¹æ³•
ä¸‹åˆ—æ–¹æ³•ä»»é€‰å…¶ä¸€ã€‚
#### 1. é€šè¿‡ pip å®‰è£…ä¾èµ–
1. å®‰è£…PytorchåŠå…¶æ ¸å¿ƒä¾èµ–ï¼Œè‹¥å·²å®‰è£…åˆ™è·³è¿‡ã€‚å‚è€ƒè‡ª: https://pytorch.org/get-started/locally/
```bash
pip install torch torchvision torchaudio
```
2. å¦‚æœæ˜¯ win ç³»ç»Ÿ + Nvidia Ampere æ¶æ„(RTX30xx)ï¼Œæ ¹æ® #21 çš„ç»éªŒï¼Œéœ€è¦æŒ‡å®š pytorch å¯¹åº”çš„ cuda ç‰ˆæœ¬
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117
```
3. æ ¹æ®è‡ªå·±çš„æ˜¾å¡å®‰è£…å¯¹åº”ä¾èµ–
- Nå¡
```bash
pip install -r requirements.txt
```
- Aå¡/Iå¡
```bash
pip install -r requirements-dml.txt
```
- Aå¡ROCM(Linux)
```bash
pip install -r requirements-amd.txt
```
- Iå¡IPEX(Linux)
```bash
pip install -r requirements-ipex.txt
```

#### 2. é€šè¿‡ poetry æ¥å®‰è£…ä¾èµ–
å®‰è£… Poetry ä¾èµ–ç®¡ç†å·¥å…·ï¼Œè‹¥å·²å®‰è£…åˆ™è·³è¿‡ã€‚å‚è€ƒè‡ª: https://python-poetry.org/docs/#installation
```bash
curl -sSL https://install.python-poetry.org | python3 -
```

é€šè¿‡ Poetry å®‰è£…ä¾èµ–æ—¶ï¼Œpython å»ºè®®ä½¿ç”¨ 3.7-3.10 ç‰ˆæœ¬ï¼Œå…¶ä½™ç‰ˆæœ¬åœ¨å®‰è£… llvmlite==0.39.0 æ—¶ä¼šå‡ºç°å†²çª
```bash
poetry init -n
poetry env use &quot;path to your python.exe&quot;
poetry run pip install -r requirments.txt
```

### MacOS
å¯ä»¥é€šè¿‡ `run.sh` æ¥å®‰è£…ä¾èµ–
```bash
sh ./run.sh
```

## å…¶ä»–é¢„æ¨¡å‹å‡†å¤‡
RVCéœ€è¦å…¶ä»–ä¸€äº›é¢„æ¨¡å‹æ¥æ¨ç†å’Œè®­ç»ƒã€‚

ä½ å¯ä»¥ä»æˆ‘ä»¬çš„[Hugging Face space](https://huggingface.co/lj1995/VoiceConversionWebUI/tree/main/)ä¸‹è½½åˆ°è¿™äº›æ¨¡å‹ã€‚

### 1. ä¸‹è½½ assets
ä»¥ä¸‹æ˜¯ä¸€ä»½æ¸…å•ï¼ŒåŒ…æ‹¬äº†æ‰€æœ‰RVCæ‰€éœ€çš„é¢„æ¨¡å‹å’Œå…¶ä»–æ–‡ä»¶çš„åç§°ã€‚ä½ å¯ä»¥åœ¨`tools`æ–‡ä»¶å¤¹æ‰¾åˆ°ä¸‹è½½å®ƒä»¬çš„è„šæœ¬ã€‚

- ./assets/hubert/hubert_base.pt

- ./assets/pretrained 

- ./assets/uvr5_weights

æƒ³ä½¿ç”¨v2ç‰ˆæœ¬æ¨¡å‹çš„è¯ï¼Œéœ€è¦é¢å¤–ä¸‹è½½

- ./assets/pretrained_v2

### 2. å®‰è£… ffmpeg
è‹¥ffmpegå’Œffprobeå·²å®‰è£…åˆ™è·³è¿‡ã€‚

#### Ubuntu/Debian ç”¨æˆ·
```bash
sudo apt install ffmpeg
```
#### MacOS ç”¨æˆ·
```bash
brew install ffmpeg
```
#### Windows ç”¨æˆ·
ä¸‹è½½åæ”¾ç½®åœ¨æ ¹ç›®å½•ã€‚
- ä¸‹è½½[ffmpeg.exe](https://huggingface.co/lj1995/VoiceConversionWebUI/blob/main/ffmpeg.exe)

- ä¸‹è½½[ffprobe.exe](https://huggingface.co/lj1995/VoiceConversionWebUI/blob/main/ffprobe.exe)

### 3. ä¸‹è½½ rmvpe äººå£°éŸ³é«˜æå–ç®—æ³•æ‰€éœ€æ–‡ä»¶

å¦‚æœä½ æƒ³ä½¿ç”¨æœ€æ–°çš„RMVPEäººå£°éŸ³é«˜æå–ç®—æ³•ï¼Œåˆ™ä½ éœ€è¦ä¸‹è½½éŸ³é«˜æå–æ¨¡å‹å‚æ•°å¹¶æ”¾ç½®äºRVCæ ¹ç›®å½•ã€‚

- ä¸‹è½½[rmvpe.pt](https://huggingface.co/lj1995/VoiceConversionWebUI/blob/main/rmvpe.pt)

#### ä¸‹è½½ rmvpe çš„ dml ç¯å¢ƒ(å¯é€‰, Aå¡/Iå¡ç”¨æˆ·)

- ä¸‹è½½[rmvpe.onnx](https://huggingface.co/lj1995/VoiceConversionWebUI/blob/main/rmvpe.onnx)

### 4. AMDæ˜¾å¡Rocm(å¯é€‰, ä»…Linux)

å¦‚æœä½ æƒ³åŸºäºAMDçš„RocmæŠ€æœ¯åœ¨Linuxç³»ç»Ÿä¸Šè¿è¡ŒRVCï¼Œè¯·å…ˆåœ¨[è¿™é‡Œ](https://rocm.docs.amd.com/en/latest/deploy/linux/os-native/install.html)å®‰è£…æ‰€éœ€çš„é©±åŠ¨ã€‚

è‹¥ä½ ä½¿ç”¨çš„æ˜¯Arch Linuxï¼Œå¯ä»¥ä½¿ç”¨pacmanæ¥å®‰è£…æ‰€éœ€é©±åŠ¨ï¼š
````
pacman -S rocm-hip-sdk rocm-opencl-sdk
````
å¯¹äºæŸäº›å‹å·çš„æ˜¾å¡ï¼Œä½ å¯èƒ½éœ€è¦é¢å¤–é…ç½®å¦‚ä¸‹çš„ç¯å¢ƒå˜é‡ï¼ˆå¦‚ï¼šRX6700XTï¼‰ï¼š
````
export ROCM_PATH=/opt/rocm
export HSA_OVERRIDE_GFX_VERSION=10.3.0
````
åŒæ—¶ç¡®ä¿ä½ çš„å½“å‰ç”¨æˆ·å¤„äº`render`ä¸`video`ç”¨æˆ·ç»„å†…ï¼š
````
sudo usermod -aG render $USERNAME
sudo usermod -aG video $USERNAME
````

## å¼€å§‹ä½¿ç”¨
### ç›´æ¥å¯åŠ¨
ä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤æ¥å¯åŠ¨ WebUI
```bash
python infer-web.py
```

è‹¥å…ˆå‰ä½¿ç”¨ Poetry å®‰è£…ä¾èµ–ï¼Œåˆ™å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å¯åŠ¨WebUI
```bash
poetry run python infer-web.py
```

### ä½¿ç”¨æ•´åˆåŒ…
ä¸‹è½½å¹¶è§£å‹`RVC-beta.7z`
#### Windows ç”¨æˆ·
åŒå‡»`go-web.bat`
#### MacOS ç”¨æˆ·
```bash
sh ./run.sh
```
### å¯¹äºéœ€è¦ä½¿ç”¨IPEXæŠ€æœ¯çš„Iå¡ç”¨æˆ·(ä»…Linux)
```bash
source /opt/intel/oneapi/setvars.sh
```

## å‚è€ƒé¡¹ç›®
+ [ContentVec](https://github.com/auspicious3000/contentvec/)
+ [VITS](https://github.com/jaywalnut310/vits)
+ [HIFIGAN](https://github.com/jik876/hifi-gan)
+ [Gradio](https://github.com/gradio-app/gradio)
+ [FFmpeg](https://github.com/FFmpeg/FFmpeg)
+ [Ultimate Vocal Remover](https://github.com/Anjok07/ultimatevocalremovergui)
+ [audio-slicer](https://github.com/openvpi/audio-slicer)
+ [Vocal pitch extraction:RMVPE](https://github.com/Dream-High/RMVPE)
  + The pretrained model is trained and tested by [yxlllc](https://github.com/yxlllc/RMVPE) and [RVC-Boss](https://github.com/RVC-Boss).

## æ„Ÿè°¢æ‰€æœ‰è´¡çŒ®è€…ä½œå‡ºçš„åŠªåŠ›
&lt;a href=&quot;https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/graphs/contributors&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=RVC-Project/Retrieval-based-Voice-Conversion-WebUI&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[vanna-ai/vanna]]></title>
            <link>https://github.com/vanna-ai/vanna</link>
            <guid>https://github.com/vanna-ai/vanna</guid>
            <pubDate>Tue, 15 Apr 2025 00:04:29 GMT</pubDate>
            <description><![CDATA[ğŸ¤– Chat with your SQL database ğŸ“Š. Accurate Text-to-SQL Generation via LLMs using RAG ğŸ”„.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vanna-ai/vanna">vanna-ai/vanna</a></h1>
            <p>ğŸ¤– Chat with your SQL database ğŸ“Š. Accurate Text-to-SQL Generation via LLMs using RAG ğŸ”„.</p>
            <p>Language: Python</p>
            <p>Stars: 15,321</p>
            <p>Forks: 1,383</p>
            <p>Stars today: 216 stars today</p>
            <h2>README</h2><pre>

| GitHub | PyPI | Documentation | Gurubase |
| ------ | ---- | ------------- | -------- |
| [![GitHub](https://img.shields.io/badge/GitHub-vanna-blue?logo=github)](https://github.com/vanna-ai/vanna) | [![PyPI](https://img.shields.io/pypi/v/vanna?logo=pypi)](https://pypi.org/project/vanna/) | [![Documentation](https://img.shields.io/badge/Documentation-vanna-blue?logo=read-the-docs)](https://vanna.ai/docs/) | [![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Vanna%20Guru-006BFF)](https://gurubase.io/g/vanna) |

# Vanna
Vanna is an MIT-licensed open-source Python RAG (Retrieval-Augmented Generation) framework for SQL generation and related functionality.

https://github.com/vanna-ai/vanna/assets/7146154/1901f47a-515d-4982-af50-f12761a3b2ce

![vanna-quadrants](https://github.com/vanna-ai/vanna/assets/7146154/1c7c88ba-c144-4ecf-a028-cf5ba7344ca2)

## How Vanna works

![Screen Recording 2024-01-24 at 11 21 37â€¯AM](https://github.com/vanna-ai/vanna/assets/7146154/1d2718ad-12a8-4a76-afa2-c61754462f93)


Vanna works in two easy steps - train a RAG &quot;model&quot; on your data, and then ask questions which will return SQL queries that can be set up to automatically run on your database.

1. **Train a RAG &quot;model&quot; on your data**.
2. **Ask questions**.

![](img/vanna-readme-diagram.png)

If you don&#039;t know what RAG is, don&#039;t worry -- you don&#039;t need to know how this works under the hood to use it. You just need to know that you &quot;train&quot; a model, which stores some metadata and then use it to &quot;ask&quot; questions.

See the [base class](https://github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py) for more details on how this works under the hood.

## User Interfaces
These are some of the user interfaces that we&#039;ve built using Vanna. You can use these as-is or as a starting point for your own custom interface.

- [Jupyter Notebook](https://vanna.ai/docs/postgres-openai-vanna-vannadb/)
- [vanna-ai/vanna-streamlit](https://github.com/vanna-ai/vanna-streamlit)
- [vanna-ai/vanna-flask](https://github.com/vanna-ai/vanna-flask)
- [vanna-ai/vanna-slack](https://github.com/vanna-ai/vanna-slack)

## Supported LLMs

- [OpenAI](https://github.com/vanna-ai/vanna/tree/main/src/vanna/openai)
- [Anthropic](https://github.com/vanna-ai/vanna/tree/main/src/vanna/anthropic)
- [Gemini](https://github.com/vanna-ai/vanna/blob/main/src/vanna/google/gemini_chat.py)
- [HuggingFace](https://github.com/vanna-ai/vanna/blob/main/src/vanna/hf/hf.py)
- [AWS Bedrock](https://github.com/vanna-ai/vanna/tree/main/src/vanna/bedrock)
- [Ollama](https://github.com/vanna-ai/vanna/tree/main/src/vanna/ollama)
- [Qianwen](https://github.com/vanna-ai/vanna/tree/main/src/vanna/qianwen)
- [Qianfan](https://github.com/vanna-ai/vanna/tree/main/src/vanna/qianfan)
- [Zhipu](https://github.com/vanna-ai/vanna/tree/main/src/vanna/ZhipuAI)

## Supported VectorStores

- [AzureSearch](https://github.com/vanna-ai/vanna/tree/main/src/vanna/azuresearch)
- [Opensearch](https://github.com/vanna-ai/vanna/tree/main/src/vanna/opensearch)
- [PgVector](https://github.com/vanna-ai/vanna/tree/main/src/vanna/pgvector)
- [PineCone](https://github.com/vanna-ai/vanna/tree/main/src/vanna/pinecone)
- [ChromaDB](https://github.com/vanna-ai/vanna/tree/main/src/vanna/chromadb)
- [FAISS](https://github.com/vanna-ai/vanna/tree/main/src/vanna/faiss)
- [Marqo](https://github.com/vanna-ai/vanna/tree/main/src/vanna/marqo)
- [Milvus](https://github.com/vanna-ai/vanna/tree/main/src/vanna/milvus)
- [Qdrant](https://github.com/vanna-ai/vanna/tree/main/src/vanna/qdrant)
- [Weaviate](https://github.com/vanna-ai/vanna/tree/main/src/vanna/weaviate)
- [Oracle](https://github.com/vanna-ai/vanna/tree/main/src/vanna/oracle)

## Supported Databases

- [PostgreSQL](https://www.postgresql.org/)
- [MySQL](https://www.mysql.com/)
- [PrestoDB](https://prestodb.io/)
- [Apache Hive](https://hive.apache.org/)
- [ClickHouse](https://clickhouse.com/)
- [Snowflake](https://www.snowflake.com/en/)
- [Oracle](https://www.oracle.com/)
- [Microsoft SQL Server](https://www.microsoft.com/en-us/sql-server/sql-server-downloads)
- [BigQuery](https://cloud.google.com/bigquery)
- [SQLite](https://www.sqlite.org/)
- [DuckDB](https://duckdb.org/)


## Getting started
See the [documentation](https://vanna.ai/docs/) for specifics on your desired database, LLM, etc.

If you want to get a feel for how it works after training, you can try this [Colab notebook](https://vanna.ai/docs/app/).


### Install
```bash
pip install vanna
```

There are a number of optional packages that can be installed so see the [documentation](https://vanna.ai/docs/) for more details.

### Import
See the [documentation](https://vanna.ai/docs/) if you&#039;re customizing the LLM or vector database.

```python
# The import statement will vary depending on your LLM and vector database. This is an example for OpenAI + ChromaDB

from vanna.openai.openai_chat import OpenAI_Chat
from vanna.chromadb.chromadb_vector import ChromaDB_VectorStore

class MyVanna(ChromaDB_VectorStore, OpenAI_Chat):
    def __init__(self, config=None):
        ChromaDB_VectorStore.__init__(self, config=config)
        OpenAI_Chat.__init__(self, config=config)

vn = MyVanna(config={&#039;api_key&#039;: &#039;sk-...&#039;, &#039;model&#039;: &#039;gpt-4-...&#039;})

# See the documentation for other options

```


## Training
You may or may not need to run these `vn.train` commands depending on your use case. See the [documentation](https://vanna.ai/docs/) for more details.

These statements are shown to give you a feel for how it works.

### Train with DDL Statements
DDL statements contain information about the table names, columns, data types, and relationships in your database.

```python
vn.train(ddl=&quot;&quot;&quot;
    CREATE TABLE IF NOT EXISTS my-table (
        id INT PRIMARY KEY,
        name VARCHAR(100),
        age INT
    )
&quot;&quot;&quot;)
```

### Train with Documentation
Sometimes you may want to add documentation about your business terminology or definitions.

```python
vn.train(documentation=&quot;Our business defines XYZ as ...&quot;)
```

### Train with SQL
You can also add SQL queries to your training data. This is useful if you have some queries already laying around. You can just copy and paste those from your editor to begin generating new SQL.

```python
vn.train(sql=&quot;SELECT name, age FROM my-table WHERE name = &#039;John Doe&#039;&quot;)
```


## Asking questions
```python
vn.ask(&quot;What are the top 10 customers by sales?&quot;)
```

You&#039;ll get SQL
```sql
SELECT c.c_name as customer_name,
        sum(l.l_extendedprice * (1 - l.l_discount)) as total_sales
FROM   snowflake_sample_data.tpch_sf1.lineitem l join snowflake_sample_data.tpch_sf1.orders o
        ON l.l_orderkey = o.o_orderkey join snowflake_sample_data.tpch_sf1.customer c
        ON o.o_custkey = c.c_custkey
GROUP BY customer_name
ORDER BY total_sales desc limit 10;
```

If you&#039;ve connected to a database, you&#039;ll get the table:
&lt;div&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;CUSTOMER_NAME&lt;/th&gt;
      &lt;th&gt;TOTAL_SALES&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Customer#000143500&lt;/td&gt;
      &lt;td&gt;6757566.0218&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Customer#000095257&lt;/td&gt;
      &lt;td&gt;6294115.3340&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Customer#000087115&lt;/td&gt;
      &lt;td&gt;6184649.5176&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Customer#000131113&lt;/td&gt;
      &lt;td&gt;6080943.8305&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;Customer#000134380&lt;/td&gt;
      &lt;td&gt;6075141.9635&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;Customer#000103834&lt;/td&gt;
      &lt;td&gt;6059770.3232&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;Customer#000069682&lt;/td&gt;
      &lt;td&gt;6057779.0348&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;Customer#000102022&lt;/td&gt;
      &lt;td&gt;6039653.6335&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;td&gt;Customer#000098587&lt;/td&gt;
      &lt;td&gt;6027021.5855&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;9&lt;/th&gt;
      &lt;td&gt;Customer#000064660&lt;/td&gt;
      &lt;td&gt;5905659.6159&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

You&#039;ll also get an automated Plotly chart:
![](img/top-10-customers.png)

## RAG vs. Fine-Tuning
RAG
- Portable across LLMs
- Easy to remove training data if any of it becomes obsolete
- Much cheaper to run than fine-tuning
- More future-proof -- if a better LLM comes out, you can just swap it out

Fine-Tuning
- Good if you need to minimize tokens in the prompt
- Slow to get started
- Expensive to train and run (generally)

## Why Vanna?

1. **High accuracy on complex datasets.**
    - Vannaâ€™s capabilities are tied to the training data you give it
    - More training data means better accuracy for large and complex datasets
2. **Secure and private.**
    - Your database contents are never sent to the LLM or the vector database
    - SQL execution happens in your local environment
3. **Self learning.**
    - If using via Jupyter, you can choose to &quot;auto-train&quot; it on the queries that were successfully executed
    - If using via other interfaces, you can have the interface prompt the user to provide feedback on the results
    - Correct question to SQL pairs are stored for future reference and make the future results more accurate
4. **Supports any SQL database.**
    - The package allows you to connect to any SQL database that you can otherwise connect to with Python
5. **Choose your front end.**
    - Most people start in a Jupyter Notebook.
    - Expose to your end users via Slackbot, web app, Streamlit app, or a custom front end.

## Extending Vanna
Vanna is designed to connect to any database, LLM, and vector database. There&#039;s a [VannaBase](https://github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py) abstract base class that defines some basic functionality. The package provides implementations for use with OpenAI and ChromaDB. You can easily extend Vanna to use your own LLM or vector database. See the [documentation](https://vanna.ai/docs/) for more details.

## Vanna in 100 Seconds

https://github.com/vanna-ai/vanna/assets/7146154/eb90ee1e-aa05-4740-891a-4fc10e611cab

## More resources
 - [Full Documentation](https://vanna.ai/docs/)
 - [Website](https://vanna.ai)
 - [Discord group for support](https://discord.gg/qUZYKHremx)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>