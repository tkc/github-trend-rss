<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Mon, 06 Oct 2025 00:04:30 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[microsoft/BitNet]]></title>
            <link>https://github.com/microsoft/BitNet</link>
            <guid>https://github.com/microsoft/BitNet</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:30 GMT</pubDate>
            <description><![CDATA[Official inference framework for 1-bit LLMs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/BitNet">microsoft/BitNet</a></h1>
            <p>Official inference framework for 1-bit LLMs</p>
            <p>Language: Python</p>
            <p>Stars: 23,233</p>
            <p>Forks: 1,804</p>
            <p>Stars today: 256 stars today</p>
            <h2>README</h2><pre># bitnet.cpp
[![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT)
![version](https://img.shields.io/badge/version-1.0-blue)

[&lt;img src=&quot;./assets/header_model_release.png&quot; alt=&quot;BitNet Model on Hugging Face&quot; width=&quot;800&quot;/&gt;](https://huggingface.co/microsoft/BitNet-b1.58-2B-4T)

Try it out via this [demo](https://bitnet-demo.azurewebsites.net/), or build and run it on your own [CPU](https://github.com/microsoft/BitNet?tab=readme-ov-file#build-from-source) or [GPU](https://github.com/microsoft/BitNet/blob/main/gpu/README.md).

bitnet.cpp is the official inference framework for 1-bit LLMs (e.g., BitNet b1.58). It offers a suite of optimized kernels, that support **fast** and **lossless** inference of 1.58-bit models on CPU and GPU (NPU support will coming next).

The first release of bitnet.cpp is to support inference on CPUs. bitnet.cpp achieves speedups of **1.37x** to **5.07x** on ARM CPUs, with larger models experiencing greater performance gains. Additionally, it reduces energy consumption by **55.4%** to **70.0%**, further boosting overall efficiency. On x86 CPUs, speedups range from **2.37x** to **6.17x** with energy reductions between **71.9%** to **82.2%**. Furthermore, bitnet.cpp can run a 100B BitNet b1.58 model on a single CPU, achieving speeds comparable to human reading (5-7 tokens per second), significantly enhancing the potential for running LLMs on local devices. Please refer to the [technical report](https://arxiv.org/abs/2410.16144) for more details.

&lt;img src=&quot;./assets/m2_performance.jpg&quot; alt=&quot;m2_performance&quot; width=&quot;800&quot;/&gt;
&lt;img src=&quot;./assets/intel_performance.jpg&quot; alt=&quot;m2_performance&quot; width=&quot;800&quot;/&gt;

&gt;The tested models are dummy setups used in a research context to demonstrate the inference performance of bitnet.cpp.

## Demo

A demo of bitnet.cpp running a BitNet b1.58 3B model on Apple M2:

https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1

## What&#039;s New:
- 05/20/2025 [BitNet Official GPU inference kernel](https://github.com/microsoft/BitNet/blob/main/gpu/README.md) ![NEW](https://img.shields.io/badge/NEW-red)
- 04/14/2025 [BitNet Official 2B Parameter Model on Hugging Face](https://huggingface.co/microsoft/BitNet-b1.58-2B-4T)
- 02/18/2025 [Bitnet.cpp: Efficient Edge Inference for Ternary LLMs](https://arxiv.org/abs/2502.11880)
- 11/08/2024 [BitNet a4.8: 4-bit Activations for 1-bit LLMs](https://arxiv.org/abs/2411.04965)
- 10/21/2024 [1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs](https://arxiv.org/abs/2410.16144)
- 10/17/2024 bitnet.cpp 1.0 released.
- 03/21/2024 [The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ](https://github.com/microsoft/unilm/blob/master/bitnet/The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ.pdf)
- 02/27/2024 [The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits](https://arxiv.org/abs/2402.17764)
- 10/17/2023 [BitNet: Scaling 1-bit Transformers for Large Language Models](https://arxiv.org/abs/2310.11453)

## Acknowledgements

This project is based on the [llama.cpp](https://github.com/ggerganov/llama.cpp) framework. We would like to thank all the authors for their contributions to the open-source community. Also, bitnet.cpp&#039;s kernels are built on top of the Lookup Table methodologies pioneered in [T-MAC](https://github.com/microsoft/T-MAC/). For inference of general low-bit LLMs beyond ternary models, we recommend using T-MAC.
## Official Models
&lt;table&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th rowspan=&quot;2&quot;&gt;Model&lt;/th&gt;
        &lt;th rowspan=&quot;2&quot;&gt;Parameters&lt;/th&gt;
        &lt;th rowspan=&quot;2&quot;&gt;CPU&lt;/th&gt;
        &lt;th colspan=&quot;3&quot;&gt;Kernel&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;I2_S&lt;/th&gt;
        &lt;th&gt;TL1&lt;/th&gt;
        &lt;th&gt;TL2&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td rowspan=&quot;2&quot;&gt;&lt;a href=&quot;https://huggingface.co/microsoft/BitNet-b1.58-2B-4T&quot;&gt;BitNet-b1.58-2B-4T&lt;/a&gt;&lt;/td&gt;
        &lt;td rowspan=&quot;2&quot;&gt;2.4B&lt;/td&gt;
        &lt;td&gt;x86&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
        &lt;td&gt;&amp;#10060;&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;ARM&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
        &lt;td&gt;&amp;#10060;&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

## Supported Models
❗️**We use existing 1-bit LLMs available on [Hugging Face](https://huggingface.co/) to demonstrate the inference capabilities of bitnet.cpp. We hope the release of bitnet.cpp will inspire the development of 1-bit LLMs in large-scale settings in terms of model size and training tokens.**

&lt;table&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th rowspan=&quot;2&quot;&gt;Model&lt;/th&gt;
        &lt;th rowspan=&quot;2&quot;&gt;Parameters&lt;/th&gt;
        &lt;th rowspan=&quot;2&quot;&gt;CPU&lt;/th&gt;
        &lt;th colspan=&quot;3&quot;&gt;Kernel&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;I2_S&lt;/th&gt;
        &lt;th&gt;TL1&lt;/th&gt;
        &lt;th&gt;TL2&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td rowspan=&quot;2&quot;&gt;&lt;a href=&quot;https://huggingface.co/1bitLLM/bitnet_b1_58-large&quot;&gt;bitnet_b1_58-large&lt;/a&gt;&lt;/td&gt;
        &lt;td rowspan=&quot;2&quot;&gt;0.7B&lt;/td&gt;
        &lt;td&gt;x86&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
        &lt;td&gt;&amp;#10060;&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;ARM&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
        &lt;td&gt;&amp;#10060;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td rowspan=&quot;2&quot;&gt;&lt;a href=&quot;https://huggingface.co/1bitLLM/bitnet_b1_58-3B&quot;&gt;bitnet_b1_58-3B&lt;/a&gt;&lt;/td&gt;
        &lt;td rowspan=&quot;2&quot;&gt;3.3B&lt;/td&gt;
        &lt;td&gt;x86&lt;/td&gt;
        &lt;td&gt;&amp;#10060;&lt;/td&gt;
        &lt;td&gt;&amp;#10060;&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;ARM&lt;/td&gt;
        &lt;td&gt;&amp;#10060;&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
        &lt;td&gt;&amp;#10060;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td rowspan=&quot;2&quot;&gt;&lt;a href=&quot;https://huggingface.co/HF1BitLLM/Llama3-8B-1.58-100B-tokens&quot;&gt;Llama3-8B-1.58-100B-tokens&lt;/a&gt;&lt;/td&gt;
        &lt;td rowspan=&quot;2&quot;&gt;8.0B&lt;/td&gt;
        &lt;td&gt;x86&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
        &lt;td&gt;&amp;#10060;&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;ARM&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
        &lt;td&gt;&amp;#10060;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td rowspan=&quot;2&quot;&gt;&lt;a href=&quot;https://huggingface.co/collections/tiiuae/falcon3-67605ae03578be86e4e87026&quot;&gt;Falcon3 Family&lt;/a&gt;&lt;/td&gt;
        &lt;td rowspan=&quot;2&quot;&gt;1B-10B&lt;/td&gt;
        &lt;td&gt;x86&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
        &lt;td&gt;&amp;#10060;&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;ARM&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
        &lt;td&gt;&amp;#10060;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td rowspan=&quot;2&quot;&gt;&lt;a href=&quot;https://huggingface.co/collections/tiiuae/falcon-edge-series-6804fd13344d6d8a8fa71130&quot;&gt;Falcon-E Family&lt;/a&gt;&lt;/td&gt;
        &lt;td rowspan=&quot;2&quot;&gt;1B-3B&lt;/td&gt;
        &lt;td&gt;x86&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
        &lt;td&gt;&amp;#10060;&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;ARM&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
        &lt;td&gt;&amp;#9989;&lt;/td&gt;
        &lt;td&gt;&amp;#10060;&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;



## Installation

### Requirements
- python&gt;=3.9
- cmake&gt;=3.22
- clang&gt;=18
    - For Windows users, install [Visual Studio 2022](https://visualstudio.microsoft.com/downloads/). In the installer, toggle on at least the following options(this also automatically installs the required additional tools like CMake):
        -  Desktop-development with C++
        -  C++-CMake Tools for Windows
        -  Git for Windows
        -  C++-Clang Compiler for Windows
        -  MS-Build Support for LLVM-Toolset (clang)
    - For Debian/Ubuntu users, you can download with [Automatic installation script](https://apt.llvm.org/)

        `bash -c &quot;$(wget -O - https://apt.llvm.org/llvm.sh)&quot;`
- conda (highly recommend)

### Build from source

&gt; [!IMPORTANT]
&gt; If you are using Windows, please remember to always use a Developer Command Prompt / PowerShell for VS2022 for the following commands. Please refer to the FAQs below if you see any issues.

1. Clone the repo
```bash
git clone --recursive https://github.com/microsoft/BitNet.git
cd BitNet
```
2. Install the dependencies
```bash
# (Recommended) Create a new conda environment
conda create -n bitnet-cpp python=3.9
conda activate bitnet-cpp

pip install -r requirements.txt
```
3. Build the project
```bash
# Manually download the model and run with local path
huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T
python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s

```
&lt;pre&gt;
usage: setup_env.py [-h] [--hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}] [--model-dir MODEL_DIR] [--log-dir LOG_DIR] [--quant-type {i2_s,tl1}] [--quant-embd]
                    [--use-pretuned]

Setup the environment for running inference

optional arguments:
  -h, --help            show this help message and exit
  --hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}, -hr {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}
                        Model used for inference
  --model-dir MODEL_DIR, -md MODEL_DIR
                        Directory to save/load the model
  --log-dir LOG_DIR, -ld LOG_DIR
                        Directory to save the logging info
  --quant-type {i2_s,tl1}, -q {i2_s,tl1}
                        Quantization type
  --quant-embd          Quantize the embeddings to f16
  --use-pretuned, -p    Use the pretuned kernel parameters
&lt;/pre&gt;
## Usage
### Basic usage
```bash
# Run inference with the quantized model
python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p &quot;You are a helpful assistant&quot; -cnv
```
&lt;pre&gt;
usage: run_inference.py [-h] [-m MODEL] [-n N_PREDICT] -p PROMPT [-t THREADS] [-c CTX_SIZE] [-temp TEMPERATURE] [-cnv]

Run inference

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        Path to model file
  -n N_PREDICT, --n-predict N_PREDICT
                        Number of tokens to predict when generating text
  -p PROMPT, --prompt PROMPT
                        Prompt to generate text from
  -t THREADS, --threads THREADS
                        Number of threads to use
  -c CTX_SIZE, --ctx-size CTX_SIZE
                        Size of the prompt context
  -temp TEMPERATURE, --temperature TEMPERATURE
                        Temperature, a hyperparameter that controls the randomness of the generated text
  -cnv, --conversation  Whether to enable chat mode or not (for instruct models.)
                        (When this option is turned on, the prompt specified by -p will be used as the system prompt.)
&lt;/pre&gt;

### Benchmark
We provide scripts to run the inference benchmark providing a model.

```  
usage: e2e_benchmark.py -m MODEL [-n N_TOKEN] [-p N_PROMPT] [-t THREADS]  
   
Setup the environment for running the inference  
   
required arguments:  
  -m MODEL, --model MODEL  
                        Path to the model file. 
   
optional arguments:  
  -h, --help  
                        Show this help message and exit. 
  -n N_TOKEN, --n-token N_TOKEN  
                        Number of generated tokens. 
  -p N_PROMPT, --n-prompt N_PROMPT  
                        Prompt to generate text from. 
  -t THREADS, --threads THREADS  
                        Number of threads to use. 
```  
   
Here&#039;s a brief explanation of each argument:  
   
- `-m`, `--model`: The path to the model file. This is a required argument that must be provided when running the script.  
- `-n`, `--n-token`: The number of tokens to generate during the inference. It is an optional argument with a default value of 128.  
- `-p`, `--n-prompt`: The number of prompt tokens to use for generating text. This is an optional argument with a default value of 512.  
- `-t`, `--threads`: The number of threads to use for running the inference. It is an optional argument with a default value of 2.  
- `-h`, `--help`: Show the help message and exit. Use this argument to display usage information.  
   
For example:  
   
```sh  
python utils/e2e_benchmark.py -m /path/to/model -n 200 -p 256 -t 4  
```  
   
This command would run the inference benchmark using the model located at `/path/to/model`, generating 200 tokens from a 256 token prompt, utilizing 4 threads.  

For the model layout that do not supported by any public model, we provide scripts to generate a dummy model with the given model layout, and run the benchmark on your machine:

```bash
python utils/generate-dummy-bitnet-model.py models/bitnet_b1_58-large --outfile models/dummy-bitnet-125m.tl1.gguf --outtype tl1 --model-size 125M

# Run benchmark with the generated model, use -m to specify the model path, -p to specify the prompt processed, -n to specify the number of token to generate
python utils/e2e_benchmark.py -m models/dummy-bitnet-125m.tl1.gguf -p 512 -n 128
```

### Convert from `.safetensors` Checkpoints

```sh
# Prepare the .safetensors model file
huggingface-cli download microsoft/bitnet-b1.58-2B-4T-bf16 --local-dir ./models/bitnet-b1.58-2B-4T-bf16

# Convert to gguf model
python ./utils/convert-helper-bitnet.py ./models/bitnet-b1.58-2B-4T-bf16
```

### FAQ (Frequently Asked Questions)📌 

#### Q1: The build dies with errors building llama.cpp due to issues with std::chrono in log.cpp?

**A:**
This is an issue introduced in recent version of llama.cpp. Please refer to this [commit](https://github.com/tinglou/llama.cpp/commit/4e3db1e3d78cc1bcd22bcb3af54bd2a4628dd323) in the [discussion](https://github.com/abetlen/llama-cpp-python/issues/1942) to fix this issue.

#### Q2: How to build with clang in conda environment on windows?

**A:** 
Before building the project, verify your clang installation and access to Visual Studio tools by running:
```
clang -v
```

This command checks that you are using the correct version of clang and that the Visual Studio tools are available. If you see an error message such as:
```
&#039;clang&#039; is not recognized as an internal or external command, operable program or batch file.
```

It indicates that your command line window is not properly initialized for Visual Studio tools.

• If you are using Command Prompt, run:
```
&quot;C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\VsDevCmd.bat&quot; -startdir=none -arch=x64 -host_arch=x64
```

• If you are using Windows PowerShell, run the following commands:
```
Import-Module &quot;C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\Microsoft.VisualStudio.DevShell.dll&quot; Enter-VsDevShell 3f0e31ad -SkipAutomaticLocation -DevCmdArguments &quot;-arch=x64 -host_arch=x64&quot;
```

These steps will initialize your environment and allow you to use the correct Visual Studio tools.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[comfyanonymous/ComfyUI]]></title>
            <link>https://github.com/comfyanonymous/ComfyUI</link>
            <guid>https://github.com/comfyanonymous/ComfyUI</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:29 GMT</pubDate>
            <description><![CDATA[The most powerful and modular diffusion model GUI, api and backend with a graph/nodes interface.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/comfyanonymous/ComfyUI">comfyanonymous/ComfyUI</a></h1>
            <p>The most powerful and modular diffusion model GUI, api and backend with a graph/nodes interface.</p>
            <p>Language: Python</p>
            <p>Stars: 90,144</p>
            <p>Forks: 10,075</p>
            <p>Stars today: 65 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# ComfyUI
**The most powerful and modular visual AI engine and application.**


[![Website][website-shield]][website-url]
[![Dynamic JSON Badge][discord-shield]][discord-url]
[![Twitter][twitter-shield]][twitter-url]
[![Matrix][matrix-shield]][matrix-url]
&lt;br&gt;
[![][github-release-shield]][github-release-link]
[![][github-release-date-shield]][github-release-link]
[![][github-downloads-shield]][github-downloads-link]
[![][github-downloads-latest-shield]][github-downloads-link]

[matrix-shield]: https://img.shields.io/badge/Matrix-000000?style=flat&amp;logo=matrix&amp;logoColor=white
[matrix-url]: https://app.element.io/#/room/%23comfyui_space%3Amatrix.org
[website-shield]: https://img.shields.io/badge/ComfyOrg-4285F4?style=flat
[website-url]: https://www.comfy.org/
&lt;!-- Workaround to display total user from https://github.com/badges/shields/issues/4500#issuecomment-2060079995 --&gt;
[discord-shield]: https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2Fcomfyorg%3Fwith_counts%3Dtrue&amp;query=%24.approximate_member_count&amp;logo=discord&amp;logoColor=white&amp;label=Discord&amp;color=green&amp;suffix=%20total
[discord-url]: https://www.comfy.org/discord
[twitter-shield]: https://img.shields.io/twitter/follow/ComfyUI
[twitter-url]: https://x.com/ComfyUI

[github-release-shield]: https://img.shields.io/github/v/release/comfyanonymous/ComfyUI?style=flat&amp;sort=semver
[github-release-link]: https://github.com/comfyanonymous/ComfyUI/releases
[github-release-date-shield]: https://img.shields.io/github/release-date/comfyanonymous/ComfyUI?style=flat
[github-downloads-shield]: https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/total?style=flat
[github-downloads-latest-shield]: https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/latest/total?style=flat&amp;label=downloads%40latest
[github-downloads-link]: https://github.com/comfyanonymous/ComfyUI/releases

![ComfyUI Screenshot](https://github.com/user-attachments/assets/7ccaf2c1-9b72-41ae-9a89-5688c94b7abe)
&lt;/div&gt;

ComfyUI lets you design and execute advanced stable diffusion pipelines using a graph/nodes/flowchart based interface. Available on Windows, Linux, and macOS.

## Get Started

#### [Desktop Application](https://www.comfy.org/download)
- The easiest way to get started.
- Available on Windows &amp; macOS.

#### [Windows Portable Package](#installing)
- Get the latest commits and completely portable.
- Available on Windows.

#### [Manual Install](#manual-install-windows-linux)
Supports all operating systems and GPU types (NVIDIA, AMD, Intel, Apple Silicon, Ascend).

## [Examples](https://comfyanonymous.github.io/ComfyUI_examples/)
See what ComfyUI can do with the [example workflows](https://comfyanonymous.github.io/ComfyUI_examples/).

## Features
- Nodes/graph/flowchart interface to experiment and create complex Stable Diffusion workflows without needing to code anything.
- Image Models
   - SD1.x, SD2.x ([unCLIP](https://comfyanonymous.github.io/ComfyUI_examples/unclip/))
   - [SDXL](https://comfyanonymous.github.io/ComfyUI_examples/sdxl/), [SDXL Turbo](https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/)
   - [Stable Cascade](https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/)
   - [SD3 and SD3.5](https://comfyanonymous.github.io/ComfyUI_examples/sd3/)
   - Pixart Alpha and Sigma
   - [AuraFlow](https://comfyanonymous.github.io/ComfyUI_examples/aura_flow/)
   - [HunyuanDiT](https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_dit/)
   - [Flux](https://comfyanonymous.github.io/ComfyUI_examples/flux/)
   - [Lumina Image 2.0](https://comfyanonymous.github.io/ComfyUI_examples/lumina2/)
   - [HiDream](https://comfyanonymous.github.io/ComfyUI_examples/hidream/)
   - [Qwen Image](https://comfyanonymous.github.io/ComfyUI_examples/qwen_image/)
   - [Hunyuan Image 2.1](https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_image/)
- Image Editing Models
   - [Omnigen 2](https://comfyanonymous.github.io/ComfyUI_examples/omnigen/)
   - [Flux Kontext](https://comfyanonymous.github.io/ComfyUI_examples/flux/#flux-kontext-image-editing-model)
   - [HiDream E1.1](https://comfyanonymous.github.io/ComfyUI_examples/hidream/#hidream-e11)
   - [Qwen Image Edit](https://comfyanonymous.github.io/ComfyUI_examples/qwen_image/#edit-model)
- Video Models
   - [Stable Video Diffusion](https://comfyanonymous.github.io/ComfyUI_examples/video/)
   - [Mochi](https://comfyanonymous.github.io/ComfyUI_examples/mochi/)
   - [LTX-Video](https://comfyanonymous.github.io/ComfyUI_examples/ltxv/)
   - [Hunyuan Video](https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_video/)
   - [Wan 2.1](https://comfyanonymous.github.io/ComfyUI_examples/wan/)
   - [Wan 2.2](https://comfyanonymous.github.io/ComfyUI_examples/wan22/)
- Audio Models
   - [Stable Audio](https://comfyanonymous.github.io/ComfyUI_examples/audio/)
   - [ACE Step](https://comfyanonymous.github.io/ComfyUI_examples/audio/)
- 3D Models
   - [Hunyuan3D 2.0](https://docs.comfy.org/tutorials/3d/hunyuan3D-2)
- Asynchronous Queue system
- Many optimizations: Only re-executes the parts of the workflow that changes between executions.
- Smart memory management: can automatically run large models on GPUs with as low as 1GB vram with smart offloading.
- Works even if you don&#039;t have a GPU with: ```--cpu``` (slow)
- Can load ckpt and safetensors: All in one checkpoints or standalone diffusion models, VAEs and CLIP models.
- Safe loading of ckpt, pt, pth, etc.. files.
- Embeddings/Textual inversion
- [Loras (regular, locon and loha)](https://comfyanonymous.github.io/ComfyUI_examples/lora/)
- [Hypernetworks](https://comfyanonymous.github.io/ComfyUI_examples/hypernetworks/)
- Loading full workflows (with seeds) from generated PNG, WebP and FLAC files.
- Saving/Loading workflows as Json files.
- Nodes interface can be used to create complex workflows like one for [Hires fix](https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/) or much more advanced ones.
- [Area Composition](https://comfyanonymous.github.io/ComfyUI_examples/area_composition/)
- [Inpainting](https://comfyanonymous.github.io/ComfyUI_examples/inpaint/) with both regular and inpainting models.
- [ControlNet and T2I-Adapter](https://comfyanonymous.github.io/ComfyUI_examples/controlnet/)
- [Upscale Models (ESRGAN, ESRGAN variants, SwinIR, Swin2SR, etc...)](https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/)
- [GLIGEN](https://comfyanonymous.github.io/ComfyUI_examples/gligen/)
- [Model Merging](https://comfyanonymous.github.io/ComfyUI_examples/model_merging/)
- [LCM models and Loras](https://comfyanonymous.github.io/ComfyUI_examples/lcm/)
- Latent previews with [TAESD](#how-to-show-high-quality-previews)
- Works fully offline: core will never download anything unless you want to.
- Optional API nodes to use paid models from external providers through the online [Comfy API](https://docs.comfy.org/tutorials/api-nodes/overview).
- [Config file](extra_model_paths.yaml.example) to set the search paths for models.

Workflow examples can be found on the [Examples page](https://comfyanonymous.github.io/ComfyUI_examples/)

## Release Process

ComfyUI follows a weekly release cycle targeting Friday but this regularly changes because of model releases or large changes to the codebase. There are three interconnected repositories:

1. **[ComfyUI Core](https://github.com/comfyanonymous/ComfyUI)**
   - Releases a new stable version (e.g., v0.7.0)
   - Serves as the foundation for the desktop release

2. **[ComfyUI Desktop](https://github.com/Comfy-Org/desktop)**
   - Builds a new release using the latest stable core version

3. **[ComfyUI Frontend](https://github.com/Comfy-Org/ComfyUI_frontend)**
   - Weekly frontend updates are merged into the core repository
   - Features are frozen for the upcoming core release
   - Development continues for the next release cycle

## Shortcuts

| Keybind                            | Explanation                                                                                                        |
|------------------------------------|--------------------------------------------------------------------------------------------------------------------|
| `Ctrl` + `Enter`                      | Queue up current graph for generation                                                                              |
| `Ctrl` + `Shift` + `Enter`              | Queue up current graph as first for generation                                                                     |
| `Ctrl` + `Alt` + `Enter`                | Cancel current generation                                                                                          |
| `Ctrl` + `Z`/`Ctrl` + `Y`                 | Undo/Redo                                                                                                          |
| `Ctrl` + `S`                          | Save workflow                                                                                                      |
| `Ctrl` + `O`                          | Load workflow                                                                                                      |
| `Ctrl` + `A`                          | Select all nodes                                                                                                   |
| `Alt `+ `C`                           | Collapse/uncollapse selected nodes                                                                                 |
| `Ctrl` + `M`                          | Mute/unmute selected nodes                                                                                         |
| `Ctrl` + `B`                           | Bypass selected nodes (acts like the node was removed from the graph and the wires reconnected through)            |
| `Delete`/`Backspace`                   | Delete selected nodes                                                                                              |
| `Ctrl` + `Backspace`                   | Delete the current graph                                                                                           |
| `Space`                              | Move the canvas around when held and moving the cursor                                                             |
| `Ctrl`/`Shift` + `Click`                 | Add clicked node to selection                                                                                      |
| `Ctrl` + `C`/`Ctrl` + `V`                  | Copy and paste selected nodes (without maintaining connections to outputs of unselected nodes)                     |
| `Ctrl` + `C`/`Ctrl` + `Shift` + `V`          | Copy and paste selected nodes (maintaining connections from outputs of unselected nodes to inputs of pasted nodes) |
| `Shift` + `Drag`                       | Move multiple selected nodes at the same time                                                                      |
| `Ctrl` + `D`                           | Load default graph                                                                                                 |
| `Alt` + `+`                          | Canvas Zoom in                                                                                                     |
| `Alt` + `-`                          | Canvas Zoom out                                                                                                    |
| `Ctrl` + `Shift` + LMB + Vertical drag | Canvas Zoom in/out                                                                                                 |
| `P`                                  | Pin/Unpin selected nodes                                                                                           |
| `Ctrl` + `G`                           | Group selected nodes                                                                                               |
| `Q`                                 | Toggle visibility of the queue                                                                                     |
| `H`                                  | Toggle visibility of history                                                                                       |
| `R`                                  | Refresh graph                                                                                                      |
| `F`                                  | Show/Hide menu                                                                                                      |
| `.`                                  | Fit view to selection (Whole graph when nothing is selected)                                                        |
| Double-Click LMB                   | Open node quick search palette                                                                                     |
| `Shift` + Drag                       | Move multiple wires at once                                                                                        |
| `Ctrl` + `Alt` + LMB                   | Disconnect all wires from clicked slot                                                                             |

`Ctrl` can also be replaced with `Cmd` instead for macOS users

# Installing

## Windows Portable

There is a portable standalone build for Windows that should work for running on Nvidia GPUs or for running on your CPU only on the [releases page](https://github.com/comfyanonymous/ComfyUI/releases).

### [Direct link to download](https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_nvidia.7z)

Simply download, extract with [7-Zip](https://7-zip.org) and run. Make sure you put your Stable Diffusion checkpoints/models (the huge ckpt/safetensors files) in: ComfyUI\models\checkpoints

If you have trouble extracting it, right click the file -&gt; properties -&gt; unblock

#### Alternative Downloads:

[Experimental portable for AMD GPUs](https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_amd.7z)

[Portable with pytorch cuda 12.8 and python 3.12](https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_nvidia_cu128.7z) (Supports Nvidia 10 series and older GPUs).

#### How do I share models between another UI and ComfyUI?

See the [Config file](extra_model_paths.yaml.example) to set the search paths for models. In the standalone windows build you can find this file in the ComfyUI directory. Rename this file to extra_model_paths.yaml and edit it with your favorite text editor.


## [comfy-cli](https://docs.comfy.org/comfy-cli/getting-started)

You can install and start ComfyUI using comfy-cli:
```bash
pip install comfy-cli
comfy install
```

## Manual Install (Windows, Linux)

Python 3.13 is very well supported. If you have trouble with some custom node dependencies you can try 3.12

Git clone this repo.

Put your SD checkpoints (the huge ckpt/safetensors files) in: models/checkpoints

Put your VAE in: models/vae


### AMD GPUs (Linux)

AMD users can install rocm and pytorch with pip if you don&#039;t have it already installed, this is the command to install the stable version:

```pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.4```

This is the command to install the nightly with ROCm 7.0 which might have some performance improvements:

```pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm7.0```


### AMD GPUs (Experimental: Windows and Linux), RDNA 3, 3.5 and 4 only.

These have less hardware support than the builds above but they work on windows. You also need to install the pytorch version specific to your hardware.

RDNA 3 (RX 7000 series):

```pip install --pre torch torchvision torchaudio --index-url https://rocm.nightlies.amd.com/v2/gfx110X-dgpu/```

RDNA 3.5 (Strix halo/Ryzen AI Max+ 365):

```pip install --pre torch torchvision torchaudio --index-url https://rocm.nightlies.amd.com/v2/gfx1151/```

RDNA 4 (RX 9000 series):

```pip install --pre torch torchvision torchaudio --index-url https://rocm.nightlies.amd.com/v2/gfx120X-all/```

### Intel GPUs (Windows and Linux)

(Option 1) Intel Arc GPU users can install native PyTorch with torch.xpu support using pip. More information can be found [here](https://pytorch.org/docs/main/notes/get_start_xpu.html)

1. To install PyTorch xpu, use the following command:

```pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/xpu```

This is the command to install the Pytorch xpu nightly which might have some performance improvements:

```pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/xpu```

(Option 2) Alternatively, Intel GPUs supported by Intel Extension for PyTorch (IPEX) can leverage IPEX for improved performance.

1. visit [Installation](https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=gpu) for more information.

### NVIDIA

Nvidia users should install stable pytorch using this command:

```pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu129```

This is the command to install pytorch nightly instead which might have performance improvements.

```pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu130```

#### Troubleshooting

If you get the &quot;Torch not compiled with CUDA enabled&quot; error, uninstall torch with:

```pip uninstall torch```

And install it again with the command above.

### Dependencies

Install the dependencies by opening your terminal inside the ComfyUI folder and:

```pip install -r requirements.txt```

After this you should have everything installed and can proceed to running ComfyUI.

### Others:

#### Apple Mac silicon

You can install ComfyUI in Apple Mac silicon (M1 or M2) with any recent macOS version.

1. Install pytorch nightly. For instructions, read the [Accelerated PyTorch training on Mac](https://developer.apple.com/metal/pytorch/) Apple Developer guide (make sure to install the latest pytorch nightly).
1. Follow the [ComfyUI manual installation](#manual-install-windows-linux) instructions for Windows and Linux.
1. Install the ComfyUI [dependencies](#dependencies). If you have another Stable Diffusion UI [you might be able to reuse the dependencies](#i-already-have-another-ui-for-stable-diffusion-installed-do-i-really-have-to-install-all-of-these-dependencies).
1. Launch ComfyUI by running `python main.py`

&gt; **Note**: Remember to add your models, VAE, LoRAs etc. to the corresponding Comfy folders, as discussed in [ComfyUI manual installation](#manual-install-windows-linux).

#### Ascend NPUs

For models compatible with Ascend Extension for PyTorch (torch_npu). To get started, ensure your environment meets the prerequisites outlined on the [installation](https://ascend.github.io/docs/sources/ascend/quick_install.html) page. Here&#039;s a step-by-step guide tailored to your platform and installation method:

1. Begin by installing the recommended or newer kernel version for Linux as specified in the Installation page of torch-npu, if necessary.
2. Proceed with the installation of Ascend Basekit, which includes the driver, firmware, and CANN, following the instructions provided for your specific platform.
3. Next, install the necessary packages for torch-npu by adhering to the platform-specific instructions on the [Installation](https://ascend.github.io/docs/sources/pytorch/install.html#pytorch) page.
4. Finally, adhere to the [ComfyUI manual installation](#manual-install-windows-linux) guide for Linux. Once all components are installed, you can run ComfyUI as described earlier.

#### Cambricon MLUs

For models compatible with Cambricon Extension for PyTorch (torch_mlu). Here&#039;s a step-by-step guide tailored to your platform and installation method:

1. Install the Cambricon CNToolkit by adhering to the platform-

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[hsliuping/TradingAgents-CN]]></title>
            <link>https://github.com/hsliuping/TradingAgents-CN</link>
            <guid>https://github.com/hsliuping/TradingAgents-CN</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:28 GMT</pubDate>
            <description><![CDATA[基于多智能体LLM的中文金融交易框架 - TradingAgents中文增强版]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hsliuping/TradingAgents-CN">hsliuping/TradingAgents-CN</a></h1>
            <p>基于多智能体LLM的中文金融交易框架 - TradingAgents中文增强版</p>
            <p>Language: Python</p>
            <p>Stars: 9,250</p>
            <p>Forks: 2,054</p>
            <p>Stars today: 198 stars today</p>
            <h2>README</h2><pre># TradingAgents 中文增强版

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/)
[![Version](https://img.shields.io/badge/Version-cn--0.1.15-green.svg)](./VERSION)
[![Documentation](https://img.shields.io/badge/docs-中文文档-green.svg)](./docs/)
[![Original](https://img.shields.io/badge/基于-TauricResearch/TradingAgents-orange.svg)](https://github.com/TauricResearch/TradingAgents)

&gt; 🚀 **最新版本 cn-0.1.15**: 开发者体验与LLM生态系统大升级！新增千帆大模型支持、完整开发工具链、学术研究资料、企业级工作流规范！
&gt;
&gt; 🎯 **核心功能**: 原生OpenAI支持 | Google AI全面集成 | 自定义端点配置 | 智能模型选择 | 多LLM提供商支持 | 模型选择持久化 | Docker容器化部署 | 专业报告导出 | 完整A股支持 | 中文本地化

基于多智能体大语言模型的**中文金融交易决策框架**。专为中文用户优化，提供完整的A股/港股/美股分析能力。

## 🙏 致敬源项目

感谢 [Tauric Research](https://github.com/TauricResearch) 团队创造的革命性多智能体交易框架 [TradingAgents](https://github.com/TauricResearch/TradingAgents)！

**🎯 我们的使命**: 为中国用户提供完整的中文化体验，支持A股/港股市场，集成国产大模型，推动AI金融技术在中文社区的普及应用。

## 🆕 v0.1.15 重大更新

### 🤖 LLM生态系统大升级

- **千帆大模型支持**: 新增百度千帆(ERNIE)大模型完整集成
- **LLM适配器重构**: 统一的OpenAI兼容适配器架构
- **多厂商支持**: 支持更多国产大模型提供商
- **集成指南**: 完整的LLM集成开发文档和测试工具

### 📚 学术研究支持

- **TradingAgents论文**: 完整的中文翻译版本和深度解读
- **技术博客**: 详细的技术分析和实现原理解读
- **学术资料**: PDF论文和相关研究资料
- **引用支持**: 标准的学术引用格式和参考文献

### 🛠️ 开发者体验升级

- **开发工作流**: 标准化的开发流程和分支管理规范
- **安装验证**: 完整的安装测试和验证脚本
- **文档重构**: 结构化的文档系统和快速开始指南
- **PR模板**: 标准化的Pull Request模板和代码审查流程

### 🔧 企业级工具链

- **分支保护**: GitHub分支保护策略和安全规则
- **紧急程序**: 完整的紧急处理和故障恢复程序
- **测试框架**: 增强的测试覆盖和验证工具
- **部署指南**: 企业级部署和配置管理

## 📋 v0.1.14 功能回顾

### 👥 用户权限管理系统

- **完整用户管理**: 新增用户注册、登录、权限控制功能
- **角色权限**: 支持多级用户角色和权限管理
- **会话管理**: 安全的用户会话和状态管理
- **用户活动日志**: 完整的用户操作记录和审计功能

### 🔐 Web用户认证系统

- **登录组件**: 现代化的用户登录界面
- **认证管理器**: 统一的用户认证和授权管理
- **安全增强**: 密码加密、会话安全等安全机制
- **用户仪表板**: 个性化的用户活动仪表板

### 🗄️ 数据管理优化

- **MongoDB集成增强**: 改进的MongoDB连接和数据管理
- **数据目录重组**: 优化的数据存储结构和管理
- **数据迁移脚本**: 完整的数据迁移和备份工具
- **缓存优化**: 提升数据加载和分析结果缓存性能

### 🧪 测试覆盖增强

- **功能测试脚本**: 新增6个专项功能测试脚本
- **工具处理器测试**: Google工具处理器修复验证
- **引导自动隐藏测试**: UI交互功能测试
- **在线工具配置测试**: 工具配置和选择逻辑测试
- **真实场景测试**: 实际使用场景的端到端测试
- **美股独立性测试**: 美股分析功能独立性验证

---

## 🆕 v0.1.13 重大更新

### 🤖 原生OpenAI端点支持

- **自定义OpenAI端点**: 支持配置任意OpenAI兼容的API端点
- **灵活模型选择**: 可以使用任何OpenAI格式的模型，不限于官方模型
- **智能适配器**: 新增原生OpenAI适配器，提供更好的兼容性和性能
- **配置管理**: 统一的端点和模型配置管理系统

### 🧠 Google AI生态系统全面集成

- **三大Google AI包支持**: langchain-google-genai、google-generativeai、google-genai
- **9个验证模型**: gemini-2.5-pro, gemini-2.5-flash, gemini-2.0-flash等最新模型
- **Google工具处理器**: 专门的Google AI工具调用处理器
- **智能降级机制**: 高级功能失败时自动降级到基础功能

### 🔧 LLM适配器架构优化

- **GoogleOpenAIAdapter**: 新增Google AI的OpenAI兼容适配器
- **统一接口**: 所有LLM提供商使用统一的调用接口
- **错误处理增强**: 改进的异常处理和自动重试机制
- **性能监控**: 添加LLM调用性能监控和统计

### 🎨 Web界面智能优化

- **智能模型选择**: 根据可用性自动选择最佳模型
- **KeyError修复**: 彻底解决模型选择中的KeyError问题
- **UI响应优化**: 改进模型切换的响应速度和用户体验
- **错误提示**: 更友好的错误提示和解决建议

## 🆕 v0.1.12 重大更新

### 🧠 智能新闻分析模块

- **智能新闻过滤器**: 基于AI的新闻相关性评分和质量评估
- **多层次过滤机制**: 基础过滤、增强过滤、集成过滤三级处理
- **新闻质量评估**: 自动识别和过滤低质量、重复、无关新闻
- **统一新闻工具**: 整合多个新闻源，提供统一的新闻获取接口

### 🔧 技术修复和优化

- **DashScope适配器修复**: 解决工具调用兼容性问题
- **DeepSeek死循环修复**: 修复新闻分析师的无限循环问题
- **LLM工具调用增强**: 提升工具调用的可靠性和稳定性
- **新闻检索器优化**: 增强新闻数据获取和处理能力

### 📚 完善测试和文档

- **全面测试覆盖**: 新增15+个测试文件，覆盖所有新功能
- **详细技术文档**: 新增8个技术分析报告和修复文档
- **用户指南完善**: 新增新闻过滤使用指南和最佳实践
- **演示脚本**: 提供完整的新闻过滤功能演示

### 🗂️ 项目结构优化

- **文档分类整理**: 按功能将文档分类到docs子目录
- **示例代码归位**: 演示脚本统一到examples目录
- **根目录整洁**: 保持根目录简洁，提升项目专业度

## 🎯 核心特性

### 🤖 多智能体协作架构

- **专业分工**: 基本面、技术面、新闻面、社交媒体四大分析师
- **结构化辩论**: 看涨/看跌研究员进行深度分析
- **智能决策**: 交易员基于所有输入做出最终投资建议
- **风险管理**: 多层次风险评估和管理机制

## 🖥️ Web界面展示

### 📸 界面截图

&gt; 🎨 **现代化Web界面**: 基于Streamlit构建的响应式Web应用，提供直观的股票分析体验

#### 🏠 主界面 - 分析配置

![1755003162925](images/README/1755003162925.png)

![1755002619976](images/README/1755002619976.png)

*智能配置面板，支持多市场股票分析，5级研究深度选择*

#### 📊 实时分析进度

![1755002731483](images/README/1755002731483.png)

*实时进度跟踪，可视化分析过程，智能时间预估*

#### 📈 分析结果展示

![1755002901204](images/README/1755002901204.png)

![1755002924844](images/README/1755002924844.png)

![1755002939905](images/README/1755002939905.png)

![1755002968608](images/README/1755002968608.png)

![1755002985903](images/README/1755002985903.png)

![1755003004403](images/README/1755003004403.png)

![1755003019759](images/README/1755003019759.png)

![1755003033939](images/README/1755003033939.png)

![1755003048242](images/README/1755003048242.png)

![1755003064598](images/README/1755003064598.png)

![1755003090603](images/README/1755003090603.png)

*专业投资报告，多维度分析结果，一键导出功能*

### 🎯 核心功能特色

#### 📋 **智能分析配置**

- **🌍 多市场支持**: 美股、A股、港股一站式分析
- **🎯 5级研究深度**: 从2分钟快速分析到25分钟全面研究
- **🤖 智能体选择**: 市场技术、基本面、新闻、社交媒体分析师
- **📅 灵活时间设置**: 支持历史任意时间点分析

#### 🚀 **实时进度跟踪**

- **📊 可视化进度**: 实时显示分析进展和剩余时间
- **🔄 智能步骤识别**: 自动识别当前分析阶段
- **⏱️ 准确时间预估**: 基于历史数据的智能时间计算
- **💾 状态持久化**: 页面刷新不丢失分析进度

#### 📈 **专业结果展示**

- **🎯 投资决策**: 明确的买入/持有/卖出建议
- **📊 多维分析**: 技术面、基本面、新闻面综合评估
- **🔢 量化指标**: 置信度、风险评分、目标价位
- **📄 专业报告**: 支持Markdown/Word/PDF格式导出

#### 🤖 **多LLM模型管理**

- **🌐 4大提供商**: DashScope、DeepSeek、Google AI、OpenRouter
- **🎯 60+模型选择**: 从经济型到旗舰级模型全覆盖
- **💾 配置持久化**: URL参数存储，刷新保持设置
- **⚡ 快速切换**: 5个热门模型一键选择按钮

### 🎮 Web界面操作指南

#### 🚀 **快速开始流程**

1. **启动应用**: `python start_web.py` 或 `docker-compose up -d`
2. **访问界面**: 浏览器打开 `http://localhost:8501`
3. **配置模型**: 侧边栏选择LLM提供商和模型
4. **输入股票**: 输入股票代码（如 AAPL、000001、0700.HK）
5. **选择深度**: 根据需求选择1-5级研究深度
6. **开始分析**: 点击&quot;🚀 开始分析&quot;按钮
7. **查看结果**: 实时跟踪进度，查看分析报告
8. **导出报告**: 一键导出专业格式报告

#### 📊 **支持的股票代码格式**

- **🇺🇸 美股**: `AAPL`, `TSLA`, `MSFT`, `NVDA`, `GOOGL`
- **🇨🇳 A股**: `000001`, `600519`, `300750`, `002415`
- **🇭🇰 港股**: `0700.HK`, `9988.HK`, `3690.HK`, `1810.HK`

#### 🎯 **研究深度说明**

- **1级 (2-4分钟)**: 快速概览，基础技术指标
- **2级 (4-6分钟)**: 标准分析，技术+基本面
- **3级 (6-10分钟)**: 深度分析，加入新闻情绪 ⭐ **推荐**
- **4级 (10-15分钟)**: 全面分析，多轮智能体辩论
- **5级 (15-25分钟)**: 最深度分析，完整研究报告

#### 💡 **使用技巧**

- **🔄 实时刷新**: 分析过程中可随时刷新页面，进度不丢失
- **📱 移动适配**: 支持手机和平板设备访问
- **🎨 深色模式**: 自动适配系统主题设置
- **⌨️ 快捷键**: 支持Enter键快速提交分析
- **📋 历史记录**: 自动保存最近的分析配置

&gt; 📖 **详细指南**: 完整的Web界面使用说明请参考 [🖥️ Web界面详细使用指南](docs/usage/web-interface-detailed-guide.md)

## 🎯 功能特性

### 🚀  智能新闻分析✨ **v0.1.12重大升级**


| 功能特性               | 状态        | 详细说明                                 |
| ---------------------- | ----------- | ---------------------------------------- |
| **🧠 智能新闻分析**    | 🆕 v0.1.12  | AI新闻过滤，质量评估，相关性分析         |
| **🔧 新闻过滤器**      | 🆕 v0.1.12  | 多层次过滤，基础/增强/集成三级处理       |
| **📰 统一新闻工具**    | 🆕 v0.1.12  | 整合多源新闻，统一接口，智能检索         |
| **🤖 多LLM提供商**     | 🆕 v0.1.11  | 4大提供商，60+模型，智能分类管理         |
| **💾 模型选择持久化**  | 🆕 v0.1.11  | URL参数存储，刷新保持，配置分享          |
| **🎯 快速选择按钮**    | 🆕 v0.1.11  | 一键切换热门模型，提升操作效率           |
| **📊 实时进度显示**    | ✅ v0.1.10  | 异步进度跟踪，智能步骤识别，准确时间计算 |
| **💾 智能会话管理**    | ✅ v0.1.10  | 状态持久化，自动降级，跨页面恢复         |
| **🎯 一键查看报告**    | ✅ v0.1.10  | 分析完成后一键查看，智能结果恢复         |
| **🖥️ Streamlit界面** | ✅ 完整支持 | 现代化响应式界面，实时交互和数据可视化   |
| **⚙️ 配置管理**      | ✅ 完整支持 | Web端API密钥管理，模型选择，参数配置     |

### 🎨 CLI用户体验 ✨ **v0.1.9优化**


| 功能特性                | 状态        | 详细说明                             |
| ----------------------- | ----------- | ------------------------------------ |
| **🖥️ 界面与日志分离** | ✅ 完整支持 | 用户界面清爽美观，技术日志独立管理   |
| **🔄 智能进度显示**     | ✅ 完整支持 | 多阶段进度跟踪，防止重复提示         |
| **⏱️ 时间预估功能**   | ✅ 完整支持 | 智能分析阶段显示预计耗时             |
| **🌈 Rich彩色输出**     | ✅ 完整支持 | 彩色进度指示，状态图标，视觉效果提升 |

### 🧠 LLM模型支持 ✨ **v0.1.13全面升级**


| 模型提供商        | 支持模型                     | 特色功能                | 新增功能 |
| ----------------- | ---------------------------- | ----------------------- | -------- |
| **🇨🇳 阿里百炼** | qwen-turbo/plus/max          | 中文优化，成本效益高    | ✅ 集成  |
| **🇨🇳 DeepSeek** | deepseek-chat                | 工具调用，性价比极高    | ✅ 集成  |
| **🌍 Google AI**  | **9个验证模型**              | 最新Gemini 2.5系列      | 🆕 升级  |
| ├─**最新旗舰**  | gemini-2.5-pro/flash         | 最新旗舰，超快响应      | 🆕 新增  |
| ├─**稳定推荐**  | gemini-2.0-flash             | 推荐使用，平衡性能      | 🆕 新增  |
| ├─**经典强大**  | gemini-1.5-pro/flash         | 经典稳定，高质量分析    | ✅ 集成  |
| └─**轻量快速**  | gemini-2.5-flash-lite        | 轻量级任务，快速响应    | 🆕 新增  |
| **🌐 原生OpenAI** | **自定义端点支持**           | 任意OpenAI兼容端点      | 🆕 新增  |
| **🌐 OpenRouter** | **60+模型聚合平台**          | 一个API访问所有主流模型 | ✅ 集成  |
| ├─**OpenAI**    | o4-mini-high, o3-pro, GPT-4o | 最新o系列，推理专业版   | ✅ 集成  |
| ├─**Anthropic** | Claude 4 Opus/Sonnet/Haiku   | 顶级性能，平衡版本      | ✅ 集成  |
| ├─**Meta**      | Llama 4 Maverick/Scout       | 最新Llama 4系列         | ✅ 集成  |
| └─**自定义**    | 任意OpenRouter模型ID         | 无限扩展，个性化选择    | ✅ 集成  |

**🎯 快速选择**: 5个热门模型快速按钮 | **💾 持久化**: URL参数存储，刷新保持 | **🔄 智能切换**: 一键切换不同提供商

### 📊 数据源与市场


| 市场类型      | 数据源                   | 覆盖范围                     |
| ------------- | ------------------------ | ---------------------------- |
| **🇨🇳 A股**  | Tushare, AkShare, 通达信 | 沪深两市，实时行情，财报数据 |
| **🇭🇰 港股** | AkShare, Yahoo Finance   | 港交所，实时行情，基本面     |
| **🇺🇸 美股** | FinnHub, Yahoo Finance   | NYSE, NASDAQ，实时数据       |
| **📰 新闻**   | Google News              | 实时新闻，多语言支持         |

### 🤖 智能体团队

**分析师团队**: 📈市场分析 | 💰基本面分析 | 📰新闻分析 | 💬情绪分析
**研究团队**: 🐂看涨研究员 | 🐻看跌研究员 | 🎯交易决策员
**管理层**: 🛡️风险管理员 | 👔研究主管

## 🚀 快速开始

### 🐳 Docker部署 (推荐)

```bash
# 1. 克隆项目
git clone https://github.com/hsliuping/TradingAgents-CN.git
cd TradingAgents-CN

# 2. 配置环境变量
cp .env.example .env
# 编辑 .env 文件，填入API密钥

# 3. 启动服务
# 首次启动或代码变更时（需要构建镜像）
docker-compose up -d --build

# 日常启动（镜像已存在，无代码变更）
docker-compose up -d

# 智能启动（自动判断是否需要构建）
# Windows环境
powershell -ExecutionPolicy Bypass -File scripts\smart_start.ps1

# Linux/Mac环境
chmod +x scripts/smart_start.sh &amp;&amp; ./scripts/smart_start.sh

# 4. 访问应用
# Web界面: http://localhost:8501
```

### 💻 本地部署

```bash
# 1. 升级pip (重要！避免安装错误)
python -m pip install --upgrade pip

# 2. 安装依赖
pip install -e .

# 3. 启动应用
python start_web.py

# 4. 访问 http://localhost:8501
```

### 📊 开始分析

1. **选择模型**: DeepSeek V3 / 通义千问 / Gemini
2. **输入股票**: `000001` (A股) / `AAPL` (美股) / `0700.HK` (港股)
3. **开始分析**: 点击&quot;🚀 开始分析&quot;按钮
4. **实时跟踪**: 观察实时进度和分析步骤
5. **查看报告**: 点击&quot;📊 查看分析报告&quot;按钮
6. **导出报告**: 支持Word/PDF/Markdown格式

## 🔐 用户权限管理

### 🔑 默认账号信息

系统提供以下默认账号，首次启动时自动创建：

| 用户名 | 密码 | 角色 | 权限说明 |
|--------|------|------|----------|
| **admin** | **admin123** | 管理员 | 完整系统权限，用户管理，系统配置 |
| **user** | **user123** | 普通用户 | 股票分析，报告查看，基础功能 |

&gt; ⚠️ **安全提醒**: 首次登录后请立即修改默认密码！

### 🛡️ 权限控制体系

- **🔐 登录认证**: 基于用户名密码的安全认证
- **👥 角色管理**: 管理员、普通用户等多级权限
- **⏰ 会话管理**: 自动超时保护，安全登出
- **📊 操作日志**: 完整的用户活动记录

### 🛠️ 用户管理工具

系统提供完整的命令行用户管理工具：

#### Windows 用户
```powershell
# 使用 PowerShell 脚本
.\scripts\user_manager.ps1 list                    # 列出所有用户
.\scripts\user_manager.ps1 change-password admin   # 修改密码
.\scripts\user_manager.ps1 create newuser trader  # 创建新用户
.\scripts\user_manager.ps1 delete olduser         # 删除用户

# 或使用批处理文件
.\scripts\user_manager.bat list
```

#### Python 脚本（跨平台）
```bash
# 直接使用 Python 脚本
python scripts/user_password_manager.py list
python scripts/user_password_manager.py change-password admin
python scripts/user_password_manager.py create newuser --role trader
python scripts/user_password_manager.py delete olduser
python scripts/user_password_manager.py reset  # 重置为默认配置
```

### 📋 支持的用户操作

- **📝 列出用户**: 查看所有用户及其角色权限
- **🔑 修改密码**: 安全的密码更新机制
- **👤 创建用户**: 支持自定义角色和权限
- **🗑️ 删除用户**: 安全的用户删除功能
- **🔄 重置配置**: 恢复默认用户设置

### 📁 配置文件位置

用户配置存储在：`web/config/users.json`

&gt; 📚 **详细文档**: 完整的用户管理指南请参考 [scripts/USER_MANAGEMENT.md](scripts/USER_MANAGEMENT.md)

### 🚧 当前版本限制

- ❌ 暂不支持在线用户注册
- ❌ 暂不支持Web界面的角色管理
- ✅ 支持完整的命令行用户管理
- ✅ 支持完整的权限控制框架

---

## 🎯 核心优势

- **🧠 智能新闻分析**: v0.1.12新增AI驱动的新闻过滤和质量评估系统
- **🔧 多层次过滤**: 基础、增强、集成三级新闻过滤机制
- **📰 统一新闻工具**: 整合多源新闻，提供统一的智能检索接口
- **🆕 多LLM集成**: v0.1.11新增4大提供商，60+模型，一站式AI体验
- **💾 配置持久化**: 模型选择真正持久化，URL参数存储，刷新保持
- **🎯 快速切换**: 5个热门模型快速按钮，一键切换不同AI
- **🆕 实时进度**: v0.1.10异步进度跟踪，告别黑盒等待
- **💾 智能会话**: 状态持久化，页面刷新不丢失分析结果
- **🔐 用户权限**: v0.1.14新增完整的用户认证和权限管理体系
- **🇨🇳 中国优化**: A股/港股数据 + 国产LLM + 中文界面
- **🐳 容器化**: Docker一键部署，环境隔离，快速扩展
- **📄 专业报告**: 多格式导出，自动生成投资建议
- **🛡️ 稳定可靠**: 多层数据源，智能降级，错误恢复

## 🔧 技术架构

**核心技术**: Python 3.10+ | LangChain | Streamlit | MongoDB | Redis
**AI模型**: DeepSeek V3 | 阿里百炼 | Google AI | OpenRouter(60+模型) | OpenAI
**数据源**: Tushare | AkShare | FinnHub | Yahoo Finance
**部署**: Docker | Docker Compose | 本地部署

## 📚 文档和支持

- **📖 完整文档**: [docs/](./docs/) - 安装指南、使用教程、API文档
- **🚨 故障排除**: [troubleshooting/](./docs/troubleshooting/) - 常见问题解决方案
- **🔄 更新日志**: [CHANGELOG.md](./docs/releases/CHANGELOG.md) - 详细版本历史
- **🚀 快速开始**: [QUICKSTART.md](./QUICKSTART.md) - 5分钟快速部署指南

## 🆚 中文增强特色

**相比原版新增**: 智能新闻分析 | 多层次新闻过滤 | 新闻质量评估 | 统一新闻工具 | 多LLM提供商集成 | 模型选择持久化 | 快速切换按钮 | | 实时进度显示 | 智能会话管理 | 中文界面 | A股数据 | 国产LLM | Docker部署 | 专业报告导出 | 统一日志管理 | Web配置界面 | 成本优化

**Docker部署包含的服务**:

- 🌐 **Web应用**: TradingAgents-CN主程序
- 🗄️ **MongoDB**: 数据持久化存储
- ⚡ **Redis**: 高速缓存
- 📊 **MongoDB Express**: 数据库管理界面
- 🎛️ **Redis Commander**: 缓存管理界面

#### 💻 方式二：本地部署

**适用场景**: 开发环境、自定义配置、离线使用

### 环境要求

- Python 3.10+ (推荐 3.11)
- 4GB+ RAM (推荐 8GB+)
- 稳定的网络连接

### 安装步骤

```bash
# 1. 克隆项目
git clone https://github.com/hsliuping/TradingAgents-CN.git
cd TradingAgents-CN

# 2. 创建虚拟环境
python -m venv env
# Windows
env\Scripts\activate
# Linux/macOS
source env/bin/activate

# 3. 升级pip
python -m pip install --upgrade pip

# 4. 安装所有依赖
pip install -r requirements.txt
#或者使用pip install -e .
pip install -e .

# 注意：requirements.txt已包含所有必需依赖：
# - 数据库支持 (MongoDB + Redis)
# - 多市场数据源 (Tushare, AKShare, FinnHub等)
# - Web界面和报告导出功能
```

### 配置API密钥

#### 🇨🇳 推荐：使用阿里百炼（国产大模型）

```bash
# 复制配置模板
cp .env.example .env

# 编辑 .env 文件，配置以下必需的API密钥：
DASHSCOPE_API_KEY=your_dashscope_api_key_here
FINNHUB_API_KEY=your_finnhub_api_key_here

# 推荐：Tushare API（专业A股数据）
TUSHARE_TOKEN=your_tushare_token_here
TUSHARE_ENABLED=true

# 可选：其他AI模型API
GOOGLE_API_KEY=your_google_api_key_here
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# 数据库配置（可选，提升性能）
# 本地部署使用标准端口
MONGODB_ENABLED=false  # 设为true启用MongoDB
REDIS_ENABLED=false    # 设为true启用Redis
MONGODB_HOST=localhost
MONGODB_PORT=27017     # 标准MongoDB端口
REDIS_HOST=localhost
REDIS_PORT=6379        # 标准Redis端口

# Docker部署时需要修改主机名
# MONGODB_HOST=mongodb
# REDIS_HOST=redis
```

#### 📋 部署模式配置说明

**本地部署模式**：

```bash
# 数据库配置（本地部署）
MONGODB_ENABLED=true
REDIS_ENABLED=true
MONGODB_HOST=localhost      # 本地主机
MONGODB_PORT=27017         # 标准端口
REDIS_HOST=localhost       # 本地主机
REDIS_PORT=6379           # 标准端口
```

**Docker部署模式**：

```bash
# 数据库配置（Docker部署）
MONGODB_ENABLED=true
REDIS_ENABLED=true
MONGODB_HOST=mongodb       # Docker容器服务名
MONGODB_PORT=27017        # 标准端口
REDIS_HOST=redis          # Docker容器服务名
REDIS_PORT=6379          # 标准端口
```

&gt; 💡 **配置提示**：
&gt;
&gt; - 本地部署：需要手动启动MongoDB和Redis服务
&gt; - Docker部署：数据库服务通过docker-compose自动启动
&gt; - 端口冲突：如果本地已有数据库服务，可修改docker-compose.yml中的端口映射

#### 🌍 可选：使用国外模型

```bash
# OpenAI (需要科学上网)
OPENAI_API_KEY=your_openai_api_key

# Anthropic (需要科学上网)
ANTHROPIC_API_KEY=your_anthropic_api_key
```

### 🗄️ 数据库配置（MongoDB + Redis）

#### 高性能数据存储支持

本项目支持 **MongoDB** 和 **Redis** 数据库，提供：

- **📊 股票数据缓存**: 减少API调用，提升响应速度
- **🔄 智能降级机制**: MongoDB → API → 本地缓存的多层数据源
- **⚡ 高性能缓存**: Redis缓存热点数据，毫秒级响应
- **🛡️ 数据持久化**: MongoDB存储历史数据，支持离线分析

#### 数据库部署方式

**🐳 Docker部署（推荐）**

如果您使用Docker部署，数据库已自动包含在内：

```bash
# Docker部署会自动启动所有服务，包括：
docker-compose up -d --build
# - Web应用 (端口8501)
# - MongoDB (端口27017)
# - Redis (端口6379)
# - 数据库管理界面 (端口8081, 8082)
```

**💻 本地部署 - 数据库配置**

如果您使用本地部署，可以选择以下方式：

**方式一：仅启动数据库服务**

```bash
# 仅启动 MongoDB + Redis 服务（不启动Web应用）
docker-compose up -d mongodb redis mongo-express redis-commander

# 查看服务状态
docker-compose ps

# 停止服务
docker-compose down
```

**方式二：完全本地安装**

```bash
# 数据库依赖已包含在requirements.txt中，无需额外安装

# 启动 MongoDB (默认端口 27017)
mongod --dbpath ./data/mongodb

# 启动 Redis (默认端口 6379)
redis-server
```

&gt; ⚠️ **重要说明**:
&gt;
&gt; - **🐳 Docker部署**: 数据库自动包含，无需额外配置
&gt; - **💻 本地部署**: 可选择仅启动数据库服务或完全本地安装
&gt; - **📋 推荐**: 使用Docker部署以获得最佳体验和一致性

#### 数据库配置选项

**环境变量配置**（推荐）：

```bash
# MongoDB 配置
MONGODB_HOST=localhost
MONGODB_PORT=27017
MONGODB_DATABASE=trading_agents
MONGODB_USERNAME=admin
MONGODB_PASSWORD=your_password

# Redis 配置
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password
REDIS_DB=0
```

**配置文件方式**：

```python
# config/database_config.py
DATABASE_CONFIG = {
    &#039;mongodb&#039;: {
        &#039;host&#039;: &#039;localhost&#039;,
        &#039;port&#039;: 27017,
        &#039;database&#039;: &#039;trading_agents&#039;,
        &#039;username&#039;: &#039;admin&#039;,
        &#039;password&#039;: &#039;your_password&#039;
    },
    &#039;redis&#039;: {
        &#039;host&#039;: &#039;localhost&#039;,
        &#039;port&#039;: 6379,
        &#039;password&#039;: &#039;your_redis_password&#039;,
        &#039;db&#039;: 0
    }
}
```

#### 数据库功能特性

**MongoDB 功能**：

- ✅ 股票基础信息存储
- ✅ 历史价格数据缓存
- ✅ 分析结果持久化
- ✅ 用户配置管理
- ✅ 自动数据同步

**Redis 功能**：

- ⚡ 实时价格数据缓存
- ⚡ API响应结果缓存
- ⚡ 会话状态管理
- ⚡ 热点数据预加载
- ⚡ 分布式锁支持

#### 智能降级机制

系统采用多层数据源降级策略，确保高可用性：

```
📊 数据获取流程：
1. 🔍 检查 Redis 缓存 (毫秒级)
2. 📚 查询 MongoDB 存储 (秒级)
3. 🌐 调用通达信API (秒级)
4. 💾 本地文件缓存 (备用)
5. ❌ 返回错误信息
```

**配置降级策略**：

```python
# 在 .env 文件中配置
ENABLE_MONGODB=true
ENABLE_REDIS=true
ENABLE_FALLBACK=true

# 缓存过期时间（秒）
REDIS_CACHE_TTL=300
MONGODB_CACHE_TTL=3600
```

#### 性能优化建议

**生产环境配置**：

```bash
# MongoDB 优化
MONGODB_MAX_POOL_SIZE=50
MONGODB_MIN_POOL_SIZE=5
MONGODB_MAX_IDLE_TIME=30000

# Redis 优化
REDIS_MAX_CONNECTIONS=20
REDIS_CONNECTION_POOL_SIZE=10
REDIS_SOCKET_TIMEOUT=5
```

#### 数据库管理工具

```bash
# 初始化数据库
python scripts/setup/init_database.py

# 系统状态检查
python scripts/validation/check_system_status.py

# 清理缓存工具
python scripts/maintenance/cleanup_cache.py --days 7
```

#### 故障排除

**常见问题解决**：

1. **🪟 Windows 10 ChromaDB兼容性问题**

   **问题现象**：在Windows 10上出现 `Configuration error: An instance of Chroma already exists for ephemeral with different settings` 错误，而Windows 11正常。

   **快速解决方案**：

   ```bash
   # 方案1：禁用内存功能（推荐）
   # 在 .env 文件中添加：
   MEMORY_ENABLED=false

   # 方案2：使用专用修复脚本
   powershell -ExecutionPolicy Bypass -File scripts\fix_chromadb_win10.ps1

   # 方案3：管理员权限运行
   # 右键PowerShell -&gt; &quot;以管理员身份运行&quot;
   ```

   **详细解决方案**：参考 [Windows 10兼容性指南](docs/troubleshooting/windows10-chromadb-fix.md)
2. **MongoDB连接失败**

   **Docker部署**：

   ```bash
   # 检查服务状态
   docker-compose logs mongodb

   # 重启服务
   docker-compose restart mongodb
   ```

   **本地部署**：

   ```bash
   # 检查MongoDB进程
   ps aux | grep mongod

   # 重启MongoDB
   sudo systemctl restart mongod  # Linux
   brew services restart mongodb  # macOS
   ```
3. **Redis连接超时**

   ```bash
   # 检查Redis状态
   redis-cli ping

   # 清理Redis缓存
   redis-cli flushdb
   ```
4. **缓存问题**

   ```bash
   # 检查系统状态和缓存
   python scripts/validation/check_system_status.py

   # 清理过期缓存
   python scripts/maintenance/cleanup_cache.py --days 7
   ```

&gt; 💡 **提示**: 即使不配置数据库，系统仍可正常运行，会自动降级到API直接调用模式。数据库配置是可选的性能优化功能。

&gt; 📚 **详细文档**: 更多数据库配置信息请参考 [数据库架构文档](docs/architecture/database-architecture.md)

### 📤 报告导出功能

#### 新增功能：专业分析报告导出

本项目现已支持将股票分析结果导出为多种专业格式：

**支持的导出格式**：

- **📄 Markdown (.md)** - 轻量级标记语言，适合技术用户和版本控制
- **📝 Word (.docx)** - Microsoft Word文档，适合商务报告和进一步编辑
- **📊 PDF (.pdf)** - 便携式文档格式，适合正式分享和打印

**报告内容结构**：

- 🎯 **投资决策摘要** - 买入/持有/卖出建议，置信度，风险评分
- 📊 **详细分析报告** - 技术分析，基本面分析，市场情绪，新闻事件
- ⚠️ **风险提示** - 完整的投资风险声明和免责条款
- 📋 **配置信息** - 分析参数，模型信息，生成时间

**使用方法**：

1. 完成股票分析后，在结果页面底部找到&quot;📤 导出报告&quot;部分
2. 选择需要的格式：Markdown、Word或PDF
3. 点击导出按钮，系统自动生成并提供下载

**安装导出依赖**：

```bash
# 安装Python依赖
pip install markdown pypandoc

# 安装系统工具（用于PDF导出）
# Windows: choco install pandoc wkhtmltopdf
# macOS: brew install pandoc wkhtmltopdf
# Linux: sudo apt-get install pandoc wkhtmltopdf
```

&gt; 📚 **详细文档**: 完整的导出功能使用指南请参考 [导出功能指南](docs/EXPORT_GUIDE.md)

### 🚀 启动应用

#### 🐳 Docker启动（推荐）

如果您使用Docker部署，应用已经自动启动：

```bash
# 应用已在Docker中运行，直接访问：
# Web界面: http://localhost:8501
# 数据库管理: http://localhost:8081
# 缓存管理: http://localhost:8082

# 查看运行状态
docker-compose ps

# 查看日志
docker-compose logs -f web
```

#### 💻 本地启动

如果您使用本地部署：

```bash
# 1. 激活虚拟环境
# Windows
.\env\Scripts\activate
# Linux/macOS
source env/bin/activate

# 2. 安装项目到虚拟环境（重要！）
pip install -e .

# 3. 启动Web管理界面
# 方法1：使用项目启动脚本（推荐）
python start_web.py

# 方法2：使用原始启动脚本
python web/run_web.py

# 方法3：直接使用streamlit（需要先安装项目）
streamlit run web/app.py
```

然后在浏览器中访问 `http://loc

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[pathwaycom/pathway]]></title>
            <link>https://github.com/pathwaycom/pathway</link>
            <guid>https://github.com/pathwaycom/pathway</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:27 GMT</pubDate>
            <description><![CDATA[Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pathwaycom/pathway">pathwaycom/pathway</a></h1>
            <p>Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.</p>
            <p>Language: Python</p>
            <p>Stars: 44,991</p>
            <p>Forks: 1,376</p>
            <p>Stars today: 324 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pathway.com/&quot;&gt;
    &lt;img src=&quot;https://pathway.com/logo-light.svg&quot;/&gt;
  &lt;/a&gt;
  &lt;br /&gt;&lt;br /&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/10388&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/10388&quot; alt=&quot;pathwaycom%2Fpathway | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
  &lt;br /&gt;&lt;br /&gt;
&lt;/div&gt;
&lt;p align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml&quot;&gt;
        &lt;img src=&quot;https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml/badge.svg&quot; alt=&quot;ubuntu&quot;/&gt;
        &lt;br&gt;
        &lt;a href=&quot;https://github.com/pathwaycom/pathway/actions/workflows/release.yml&quot;&gt;
        &lt;img src=&quot;https://github.com/pathwaycom/pathway/actions/workflows/release.yml/badge.svg&quot; alt=&quot;Last release&quot;/&gt;&lt;/a&gt;
        &lt;a href=&quot;https://badge.fury.io/py/pathway&quot;&gt;&lt;img src=&quot;https://badge.fury.io/py/pathway.svg&quot; alt=&quot;PyPI version&quot; height=&quot;18&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://badge.fury.io/py/pathway&quot;&gt;&lt;img src=&quot;https://static.pepy.tech/badge/pathway&quot; alt=&quot;PyPI downloads&quot; height=&quot;18&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://github.com/pathwaycom/pathway/blob/main/LICENSE.txt&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/license-BSL-green&quot; alt=&quot;License: BSL&quot;/&gt;&lt;/a&gt;
      &lt;br&gt;
        &lt;a href=&quot;https://discord.gg/pathway&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1042405378304004156?logo=discord&quot;
            alt=&quot;chat on Discord&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=pathway_com&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/pathwaycom&quot;
            alt=&quot;follow on Twitter&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://linkedin.com/company/pathway&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/pathway-0077B5?style=social&amp;logo=linkedin&quot; alt=&quot;follow on LinkedIn&quot;&gt;&lt;/a&gt;
      &lt;a href=&quot;https://github.com/dylanhogg/awesome-python/blob/main/README.md&quot;&gt;
      &lt;img src=&quot;https://awesome.re/badge.svg&quot; alt=&quot;Awesome Python&quot;&gt;&lt;/a&gt;
      &lt;a href=&quot;https://gurubase.io/g/pathway&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Gurubase-Ask%20Pathway%20Guru-006BFF&quot; alt=&quot;Pathway Guru&quot;&gt;&lt;/a&gt;
    &lt;br&gt;
    &lt;a href=&quot;#getting-started&quot;&gt;Getting Started&lt;/a&gt; |
    &lt;a href=&quot;#deployment&quot;&gt;Deployment&lt;/a&gt; |
    &lt;a href=&quot;#resources&quot;&gt;Documentation and Support&lt;/a&gt; |
    &lt;a href=&quot;https://pathway.com/blog/&quot;&gt;Blog&lt;/a&gt; |
    &lt;a href=&quot;#license&quot;&gt;License&lt;/a&gt;

  
&lt;/p&gt;

# Pathway&lt;a id=&quot;pathway&quot;&gt; Live Data Framework&lt;/a&gt;

[Pathway](https://pathway.com) is a Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.

Pathway comes with an **easy-to-use Python API**, allowing you to seamlessly integrate your favorite Python ML libraries.
Pathway code is versatile and robust: **you can use it in both development and production environments, handling both batch and streaming data effectively**.
The same code can be used for local development, CI/CD tests, running batch jobs, handling stream replays, and processing data streams.

Pathway is powered by a **scalable Rust engine** based on Differential Dataflow and performs incremental computation.
Your Pathway code, despite being written in Python, is run by the Rust engine, enabling multithreading, multiprocessing, and distributed computations.
All the pipeline is kept in memory and can be easily deployed with **Docker and Kubernetes**.

You can install Pathway with pip:
```
pip install -U pathway
```

For any questions, you will find the community and team behind the project [on Discord](https://discord.com/invite/pathway).

## Use-cases and templates

Ready to see what Pathway can do?

[Try one of our easy-to-run examples](https://pathway.com/developers/templates)!

Available in both notebook and docker formats, these ready-to-launch examples can be launched in just a few clicks. Pick one and start your hands-on experience with Pathway today!

### Event processing and real-time analytics pipelines
With its unified engine for batch and streaming and its full Python compatibility, Pathway makes data processing as easy as possible. It&#039;s the ideal solution for a wide range of data processing pipelines, including:

- [Showcase: Real-time ETL.](https://pathway.com/developers/templates/kafka-etl)
- [Showcase: Event-driven pipelines with alerting.](https://pathway.com/developers/templates/realtime-log-monitoring)
- [Showcase: Realtime analytics.](https://pathway.com/developers/templates/linear_regression_with_kafka)
- [Docs: Switch from batch to streaming.](https://pathway.com/developers/user-guide/connecting-to-data/switch-from-batch-to-streaming)



### AI Pipelines

Pathway provides dedicated LLM tooling to build live LLM and RAG pipelines. Wrappers for most common LLM services and utilities are included, making working with LLMs and RAGs pipelines incredibly easy. Check out our [LLM xpack documentation](https://pathway.com/developers/user-guide/llm-xpack/overview).

Don&#039;t hesitate to try one of our runnable examples featuring LLM tooling.
You can find such examples [here](https://pathway.com/developers/user-guide/llm-xpack/llm-examples).

  - [Template: Unstructured data to SQL on-the-fly.](https://pathway.com/developers/templates/unstructured-to-structured)
  - [Template: Private RAG with Ollama and Mistral AI](https://pathway.com/developers/templates/private-rag-ollama-mistral)
  - [Template: Adaptive RAG](https://pathway.com/developers/templates/adaptive-rag)
  - [Template: Multimodal RAG with gpt-4o](https://pathway.com/developers/templates/multimodal-rag)

## Features

- **A wide range of connectors**: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector.
- **Stateless and stateful transformations**: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data.
- **Persistence**: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!
- **Consistency**: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the &quot;at least once&quot; consistency while the enterprise version provides the &quot;exactly once&quot; consistency.
- **Scalable Rust engine**: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can easily do multithreading, multiprocessing, and distributed computations.
- **LLM helpers**: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents.


## Getting started&lt;a id=&quot;getting-started&quot;&gt;&lt;/a&gt;

### Installation&lt;a id=&quot;installation&quot;&gt;&lt;/a&gt;

Pathway requires Python 3.10 or above.

You can install the current release of Pathway using `pip`:

```
$ pip install -U pathway
```

⚠️ Pathway is available on MacOS and Linux. Users of other systems should run Pathway on a Virtual Machine.


### Example: computing the sum of positive values in real time.&lt;a id=&quot;example&quot;&gt;&lt;/a&gt;

```python
import pathway as pw

# Define the schema of your data (Optional)
class InputSchema(pw.Schema):
  value: int

# Connect to your data using connectors
input_table = pw.io.csv.read(
  &quot;./input/&quot;,
  schema=InputSchema
)

#Define your operations on the data
filtered_table = input_table.filter(input_table.value&gt;=0)
result_table = filtered_table.reduce(
  sum_value = pw.reducers.sum(filtered_table.value)
)

# Load your results to external systems
pw.io.jsonlines.write(result_table, &quot;output.jsonl&quot;)

# Run the computation
pw.run()
```

Run Pathway [in Google Colab](https://colab.research.google.com/drive/1aBIJ2HCng-YEUOMrr0qtj0NeZMEyRz55?usp=sharing).

You can find more examples [here](https://github.com/pathwaycom/pathway/tree/main/examples).


## Deployment&lt;a id=&quot;deployment&quot;&gt;&lt;/a&gt;

### Locally&lt;a id=&quot;running-pathway-locally&quot;&gt;&lt;/a&gt;

To use Pathway, you only need to import it:

```python
import pathway as pw
```

Now, you can easily create your processing pipeline, and let Pathway handle the updates. Once your pipeline is created, you can launch the computation on streaming data with a one-line command:

```python
pw.run()
```

You can then run your Pathway project (say, `main.py`) just like a normal Python script: `$ python main.py`.
Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages. 

&lt;img src=&quot;https://d14l3brkh44201.cloudfront.net/pathway-dashboard.png&quot; width=&quot;1326&quot; alt=&quot;Pathway dashboard&quot;/&gt;

Alternatively, you can use the pathway&#039;ish version:

```
$ pathway spawn python main.py
```

Pathway natively supports multithreading.
To launch your application with 3 threads, you can do as follows:
```
$ pathway spawn --threads 3 python main.py
```

To jumpstart a Pathway project, you can use our [cookiecutter template](https://github.com/pathwaycom/cookiecutter-pathway).


### Docker&lt;a id=&quot;docker&quot;&gt;&lt;/a&gt;

You can easily run Pathway using docker.

#### Pathway image

You can use the [Pathway docker image](https://hub.docker.com/r/pathwaycom/pathway), using a Dockerfile:

```dockerfile
FROM pathwaycom/pathway:latest

WORKDIR /app

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD [ &quot;python&quot;, &quot;./your-script.py&quot; ]
```

You can then build and run the Docker image:

```console
docker build -t my-pathway-app .
docker run -it --rm --name my-pathway-app my-pathway-app
```

#### Run a single Python script

When dealing with single-file projects, creating a full-fledged `Dockerfile`
might seem unnecessary. In such scenarios, you can execute a
Python script directly using the Pathway Docker image. For example:

```console
docker run -it --rm --name my-pathway-app -v &quot;$PWD&quot;:/app pathwaycom/pathway:latest python my-pathway-app.py
```

#### Python docker image

You can also use a standard Python image and install Pathway using pip with a Dockerfile:

```dockerfile
FROM --platform=linux/x86_64 python:3.10

RUN pip install -U pathway
COPY ./pathway-script.py pathway-script.py

CMD [&quot;python&quot;, &quot;-u&quot;, &quot;pathway-script.py&quot;]
```

### Kubernetes and cloud&lt;a id=&quot;k8s&quot;&gt;&lt;/a&gt;

Docker containers are ideally suited for deployment on the cloud with Kubernetes.
If you want to scale your Pathway application, you may be interested in our Pathway for Enterprise.
Pathway for Enterprise is specially tailored towards end-to-end data processing and real time intelligent analytics.
It scales using distributed computing on the cloud and supports distributed Kubernetes deployment, with external persistence setup.

You can easily deploy Pathway using services like Render: see [how to deploy Pathway in a few clicks](https://pathway.com/developers/user-guide/deployment/render-deploy/).

If you are interested, don&#039;t hesitate to [contact us](mailto:contact@pathway.com) to learn more.

## Performance&lt;a id=&quot;performance&quot;&gt;&lt;/a&gt;

Pathway is made to outperform state-of-the-art technologies designed for streaming and batch data processing tasks, including: Flink, Spark, and Kafka Streaming. It also makes it possible to implement a lot of algorithms/UDF&#039;s in streaming mode which are not readily supported by other streaming frameworks (especially: temporal joins, iterative graph algorithms, machine learning routines).

If you are curious, here are [some benchmarks to play with](https://github.com/pathwaycom/pathway-benchmarks).

&lt;img src=&quot;https://github.com/pathwaycom/pathway-benchmarks/raw/main/images/bm-wordcount-lineplot.png&quot; width=&quot;1326&quot; alt=&quot;WordCount Graph&quot;/&gt;

## Documentation and Support&lt;a id=&quot;resources&quot;&gt;&lt;/a&gt;

The entire documentation of Pathway is available at [pathway.com/developers/](https://pathway.com/developers/user-guide/introduction/welcome), including the [API Docs](https://pathway.com/developers/api-docs/pathway).

If you have any question, don&#039;t hesitate to [open an issue on GitHub](https://github.com/pathwaycom/pathway/issues), join us on [Discord](https://discord.com/invite/pathway), or send us an email at [contact@pathway.com](mailto:contact@pathway.com).

## License&lt;a id=&quot;license&quot;&gt;&lt;/a&gt;

Pathway is distributed on a [BSL 1.1 License](https://github.com/pathwaycom/pathway/blob/main/LICENSE.txt) which allows for unlimited non-commercial use, as well as use of the Pathway package [for most commercial purposes](https://pathway.com/license/), free of charge. Code in this repository automatically converts to Open Source (Apache 2.0 License) after 4 years. Some [public repos](https://github.com/pathwaycom) which are complementary to this one (examples, libraries, connectors, etc.) are licensed as Open Source, under the MIT license.


## Contribution guidelines&lt;a id=&quot;contribution-guidelines&quot;&gt;&lt;/a&gt;

If you develop a library or connector which you would like to integrate with this repo, we suggest releasing it first as a separate repo on a MIT/Apache 2.0 license. 

For all concerns regarding core Pathway functionalities, Issues are encouraged. For further information, don&#039;t hesitate to engage with Pathway&#039;s [Discord community](https://discord.gg/pathway).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[xtekky/gpt4free]]></title>
            <link>https://github.com/xtekky/gpt4free</link>
            <guid>https://github.com/xtekky/gpt4free</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:26 GMT</pubDate>
            <description><![CDATA[The official gpt4free repository | various collection of powerful language models | o4, o3 and deepseek r1, gpt-4.1, gemini 2.5]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/xtekky/gpt4free">xtekky/gpt4free</a></h1>
            <p>The official gpt4free repository | various collection of powerful language models | o4, o3 and deepseek r1, gpt-4.1, gemini 2.5</p>
            <p>Language: Python</p>
            <p>Stars: 65,271</p>
            <p>Forks: 13,695</p>
            <p>Stars today: 33 stars today</p>
            <h2>README</h2><pre># GPT4Free (g4f)

[![PyPI](https://img.shields.io/pypi/v/g4f)](https://pypi.org/project/g4f) [![Docker Hub](https://img.shields.io/badge/docker-hlohaus789%2Fg4f-blue)](https://hub.docker.com/r/hlohaus789/g4f) [![License: GPL v3](https://img.shields.io/badge/License-GPLv3-red.svg)](https://www.gnu.org/licenses/gpl-3.0.txt)

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/7f60c240-00fa-4c37-bf7f-ae5cc20906a1&quot; alt=&quot;GPT4Free logo&quot; height=&quot;200&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;span style=&quot;background: linear-gradient(45deg, #12c2e9, #c471ed, #f64f59); -webkit-background-clip: text; -webkit-text-fill-color: transparent;&quot;&gt;
    &lt;strong&gt;Created by &lt;a href=&quot;https://github.com/xtekky&quot;&gt;@xtekky&lt;/a&gt;,&lt;br&gt; maintained by &lt;a href=&quot;https://github.com/hlohaus&quot;&gt;@hlohaus&lt;/a&gt;&lt;/strong&gt;
  &lt;/span&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;span&gt;Support the project on&lt;/span&gt;
      &lt;a href=&quot;https://github.com/sponsors/hlohaus&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;
        GitHub Sponsors
      &lt;/a&gt;
      ❤️
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Live demo &amp; docs: https://g4f.dev | Documentation: https://g4f.dev/docs
&lt;/p&gt;

---

GPT4Free (g4f) is a community-driven project that aggregates multiple accessible providers and interfaces to make working with modern LLMs and media-generation models easier and more flexible. GPT4Free aims to offer multi-provider support, local GUI, OpenAI-compatible REST APIs, and convenient Python and JavaScript clients — all under a community-first license.

This README is a consolidated, improved, and complete guide to installing, running, and contributing to GPT4Free.

Table of contents
- [What’s included](#whats-included)
- [Quick links](#quick-links)
- [Requirements &amp; compatibility](#requirements--compatibility)
- [Installation](#installation)
  - [Docker (recommended)](#docker-recommended)
  - [Slim Docker image](#slim-docker-image)
  - [Windows (.exe)](#windows-exe)
  - [Python (pip / from source / partial installs)](#python-pip--from-source--partial-installs)
- [Running the app](#running-the-app)
  - [GUI (web client)](#gui-web-client)
  - [FastAPI / Interference API](#fastapi--interference-api)
  - [CLI](#cli)
  - [Optional provider login (desktop in container)](#optional-provider-login-desktop-in-container)
- [Using the Python client](#using-the-python-client)
  - [Synchronous text example](#synchronous-text-example)
  - [Image generation example](#image-generation-example)
  - [Async client example](#async-client-example)
- [Using GPT4Free.js (browser JS client)](#using-gpt4freejs-browser-js-client)
- [Providers &amp; models (overview)](#providers--models-overview)
- [Local inference &amp; media](#local-inference--media)
- [Configuration &amp; customization](#configuration--customization)
- [Running on smartphone](#running-on-smartphone)
- [Interference API (OpenAI‑compatible)](#interference-api-openai-compatible)
- [Examples &amp; common patterns](#examples--common-patterns)
- [Contributing](#contributing)
  - [How to create a new provider](#how-to-create-a-new-provider)
  - [How AI can help you write code](#how-ai-can-help-you-write-code)
- [Security, privacy &amp; takedown policy](#security-privacy--takedown-policy)
- [Credits, contributors &amp; attribution](#credits-contributors--attribution)
- [Powered-by highlights](#powered-by-highlights)
- [Changelog &amp; releases](#changelog--releases)
- [Manifesto / Project principles](#manifesto--project-principles)
- [License](#license)
- [Contact &amp; sponsorship](#contact--sponsorship)
- [Appendix: Quick commands &amp; examples](#appendix-quick-commands--examples)

---

## What’s included
- Python client library and async client.
- Optional local web GUI.
- FastAPI-based OpenAI-compatible API (Interference API).
- Official browser JS client (g4f.dev distribution).
- Docker images (full and slim).
- Multi-provider adapters (LLMs, media providers, local inference backends).
- Tooling for image/audio/video generation and media persistence.

---

## Quick links
- Website &amp; docs: https://g4f.dev | https://g4f.dev/docs  
- PyPI: https://pypi.org/project/g4f  
- Docker image: https://hub.docker.com/r/hlohaus789/g4f  
- Releases: https://github.com/xtekky/gpt4free/releases  
- Issues: https://github.com/xtekky/gpt4free/issues  
- Community: Telegram (https://telegram.me/g4f_channel) · Discord News (https://discord.gg/5E39JUWUFa) · Discord Support (https://discord.gg/qXA4Wf4Fsm)

---

## Requirements &amp; compatibility
- Python 3.10+ recommended.
- Google Chrome/Chromium for providers using browser automation.
- Docker for containerized deployment.
- Works on x86_64 and arm64 (slim image supports both).
- Some provider adapters may require platform-specific tooling (Chrome/Chromium, etc.). Check provider docs for details.

---

## Installation

### Docker (recommended)
1. Install Docker: https://docs.docker.com/get-docker/
2. Create persistent directories:
   - Example (Linux/macOS):
     ```bash
     mkdir -p ${PWD}/har_and_cookies ${PWD}/generated_media
     sudo chown -R 1200:1201 ${PWD}/har_and_cookies ${PWD}/generated_media
     ```
3. Pull image:
   ```bash
   docker pull hlohaus789/g4f
   ```
4. Run container:
   ```bash
   docker run -p 8080:8080 -p 7900:7900 \
     --shm-size=&quot;2g&quot; \
     -v ${PWD}/har_and_cookies:/app/har_and_cookies \
     -v ${PWD}/generated_media:/app/generated_media \
     hlohaus789/g4f:latest
   ```
Notes:
- Port 8080 serves GUI/API; 7900 can expose a VNC-like desktop for provider logins (optional).
- Increase --shm-size for heavier browser automation tasks.

### Slim Docker image (x64 &amp; arm64)
```bash
mkdir -p ${PWD}/har_and_cookies ${PWD}/generated_media
chown -R 1000:1000 ${PWD}/har_and_cookies ${PWD}/generated_media

docker run \
  -p 1337:8080 -p 8080:8080 \
  -v ${PWD}/har_and_cookies:/app/har_and_cookies \
  -v ${PWD}/generated_media:/app/generated_media \
  hlohaus789/g4f:latest-slim
```
Notes:
- The slim image can update the g4f package on startup and installs additional dependencies as needed.
- In this example, the Interference API is mapped to 1337.

### Windows Guide (.exe)
1. Download the release artifact `g4f.exe.zip` from:
   https://github.com/xtekky/gpt4free/releases/latest
2. Unzip and run `g4f.exe`.
3. Open GUI at: http://localhost:8080/chat/
4. If Windows Firewall blocks access, allow the application.

### Python Installation (pip / from source / partial installs)

Prerequisites:
- Python 3.10+ (https://www.python.org/downloads/)
- Chrome/Chromium for some providers.

Install from PyPI (recommended):
```bash
pip install -U g4f[all]
```

Partial installs
- To install only specific functionality, use optional extras groups. See docs/requirements.md in the project docs.

Install from source:
```bash
git clone https://github.com/xtekky/gpt4free.git
cd gpt4free
pip install -r requirements.txt
pip install -e .
```

Notes:
- Some features require Chrome/Chromium or other tools; follow provider-specific docs.

---

## Running the app

### GUI (web client)
- Run via Python:
```python
from g4f.gui import run_gui
run_gui()
```
- Or via CLI:
```bash
python -m g4f.cli gui --port 8080 --debug
```
- Open: http://localhost:8080/chat/

### FastAPI / Interference API
- Start FastAPI server:
```bash
python -m g4f --port 8080 --debug
```
- If using slim docker mapping, Interference API may be available at `http://localhost:1337/v1`
- Swagger UI: `http://localhost:1337/docs`

### CLI
- Start GUI server:
```bash
python -m g4f.cli gui --port 8080 --debug
```

### Optional provider login (desktop within container)
- Accessible at:
  ```
  http://localhost:7900/?autoconnect=1&amp;resize=scale&amp;password=secret
  ```
- Useful for logging into web-based providers to obtain cookies/HAR files.

---

## Using the Python client

Install:
```bash
pip install -U g4f[all]
```

Synchronous text example:
```python
from g4f.client import Client

client = Client()
response = client.chat.completions.create(
    model=&quot;gpt-4o-mini&quot;,
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello, how are you?&quot;}],
    web_search=False
)
print(response.choices[0].message.content)
```
Expected:
```
Hello! How can I assist you today?
```

Image generation example:
```python
from g4f.client import Client

client = Client()
response = client.images.generate(
    model=&quot;flux&quot;,
    prompt=&quot;a white siamese cat&quot;,
    response_format=&quot;url&quot;
)
print(f&quot;Generated image URL: {response.data[0].url}&quot;)
```

Async client example:
```python
from g4f.client import AsyncClient
import asyncio

async def main():
    client = AsyncClient()
    response = await client.chat.completions.create(
        model=&quot;gpt-4o-mini&quot;,
        messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Explain quantum computing briefly&quot;}],
    )
    print(response.choices[0].message.content)

asyncio.run(main())
```

Notes:
- See the full API reference for streaming, tool-calling patterns, and advanced options: https://g4f.dev/docs/client

---

## Using GPT4Free.js (browser JS client)
Use the official JS client in the browser—no backend required.

Example:
```html
&lt;script type=&quot;module&quot;&gt;
  import Client from &#039;https://g4f.dev/dist/js/client.js&#039;;

  const client = new Client();
  const result = await client.chat.completions.create({
      model: &#039;gpt-4.1&#039;,  // Or &quot;gpt-4o&quot;, &quot;deepseek-v3&quot;, etc.
      messages: [{ role: &#039;user&#039;, content: &#039;Explain quantum computing&#039; }]
  });
  console.log(result.choices[0].message.content);
&lt;/script&gt;
```

Notes:
- The JS client is distributed via the g4f.dev CDN for easy usage. Review CORS considerations and usage limits.

---

## Providers &amp; models (overview)
- GPT4Free integrates many providers including (but not limited to) OpenAI-compatible endpoints, PerplexityLabs, Gemini, MetaAI, Pollinations (media), and local inference backends.
- Model availability and behavior depend on provider capabilities. See the providers doc for current, supported provider/model lists: https://g4f.dev/docs/providers-and-models

Provider requirements may include:
- API keys or tokens (for authenticated providers)
- Browser cookies / HAR files for providers scraped via browser automation
- Chrome/Chromium or headless browser tooling
- Local model binaries and runtime (for local inference)

---

## Local inference &amp; media
- GPT4Free supports local inference backends. See [docs/local.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/local.md) for supported runtimes and hardware guidance.
- Media generation (image, audio, video) is supported through providers (e.g., Pollinations). See [docs/media.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/media.md) for formats, options, and sample usage.

---

## Configuration &amp; customization
- Configure via environment variables, CLI flags, or config files. See [docs/config.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/config.md).
- To reduce install size, use partial requirement groups. See [docs/requirements.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/requirements.md).
- Provider selection: learn how to set defaults and override per-request at [docs/selecting_a_provider.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/selecting_a_provider.md).
- Persistence: HAR files, cookies, and generated media persist in mapped directories (e.g., har_and_cookies, generated_media).

---

## Running on smartphone
- The web GUI is responsive and can be accessed from a phone by visiting your host IP:8080 or via a tunnel. See [docs/guides/phone.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/guides/phone.md).

---

## Interference API (OpenAI‑compatible)
- The Interference API enables OpenAI-like workflows routed through GPT4Free provider selection.
- Docs: [docs/interference-api.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/interference-api.md)
- Default endpoint (example slim docker): `http://localhost:1337/v1`
- Swagger UI: `http://localhost:1337/docs`

---

## Examples &amp; common patterns
- Streaming completions, stopping criteria, system messages, and tool-calling patterns are documented in:
  - [docs/client.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/client.md)
  - [docs/async_client.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/async_client.md)
  - [docs/requests.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/requests.md)
- Integrations (LangChain, PydanticAI): [docs/pydantic_ai.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/pydantic_ai.md)
- Legacy examples: [docs/legacy.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/legacy.md)

---

## Contributing
Contributions are welcome — new providers, features, docs, and fixes are appreciated.

How to contribute:
1. Fork the repository.
2. Create a branch for your change.
3. Run tests and linters.
4. Open a Pull Request with a clear description and tests/examples if applicable.

Repository: https://github.com/xtekky/gpt4free

### How to create a new provider
- Read the guide: [docs/guides/create_provider.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/guides/create_provider.md)
- Typical steps:
  - Implement a provider adapter in `g4f/Provider/`
  - Add configuration and dependency notes
  - Include tests and usage examples
  - Respect third‑party code licenses and attribute appropriately

### How AI can help you write code
- See: [docs/guides/help_me.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/guides/help_me.md) for prompt templates and workflows to accelerate development.

---

## Security, privacy &amp; takedown policy
- Do not store or share sensitive credentials. Use per-provider recommended security practices.
- If your site appears in the project’s links and you want it removed, send proof of ownership to takedown@g4f.ai and it will be removed promptly.
- For production, secure the server with HTTPS, authentication, and firewall rules. Limit access to provider credentials and cookie/HAR storage.

---

## Credits, contributors &amp; attribution
- Core creators: [@xtekky](https://github.com/xtekky) (original), maintained by [@hlohaus](https://github.com/hlohaus).
- Full contributor graph: https://github.com/xtekky/gpt4free/graphs/contributors
- Notable code inputs and attributions:
  - `har_file.py` — input from [xqdoo00o/ChatGPT-to-API](https://github.com/xqdoo00o/ChatGPT-to-API)
  - `PerplexityLabs.py` — input from [nathanrchn/perplexityai](https://github.com/nathanrchn/perplexityai)
  - `Gemini.py` — input from [dsdanielpark/Gemini-API](https://github.com/dsdanielpark/Gemini-API) and [HanaokaYuzu/Gemini-API](https://github.com/HanaokaYuzu/Gemini-API)
  - `MetaAI.py` — inspired by [meta-ai-api by Strvm](https://github.com/Strvm/meta-ai-api)
  - `proofofwork.py` — input from [missuo/FreeGPT35](https://github.com/missuo/FreeGPT35)

Many more contributors are acknowledged in the repository.

---

## Powered-by highlights
- Pollinations AI — generative media: https://github.com/pollinations/pollinations
- MoneyPrinter V2 — example project using GPT4Free: https://github.com/FujiwaraChoki/MoneyPrinterV2
- For a full list of projects and sites using GPT4Free, see: [docs/powered-by.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/powered-by.md)

---

## Changelog &amp; releases
- Releases and full changelog: https://github.com/xtekky/gpt4free/releases
- Subscribe to Discord/Telegram for announcements.

---

## Manifesto / Project principles
GPT4Free is guided by community principles:
1. Open access to AI tooling and models.
2. Collaboration across providers and projects.
3. Opposition to monopolistic, closed systems that restrict creativity.
4. Community-centered development and broad access to AI technologies.
5. Promote innovation, creativity, and accessibility.

https://g4f.dev/manifest

---

## License
This program is licensed under the GNU General Public License v3.0 (GPLv3). See the full license: https://www.gnu.org/licenses/gpl-3.0.txt

Summary:
- You may redistribute and/or modify under the terms of GPLv3.
- The program is provided WITHOUT ANY WARRANTY.

Copyright notice
```
xtekky/gpt4free: Copyright (C) 2025 xtekky

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.
```

---

## Contact &amp; sponsorship
- Maintainers: https://github.com/hlohaus  
- Sponsorship: https://github.com/sponsors/hlohaus  
- Issues &amp; feature requests: https://github.com/xtekky/gpt4free/issues  
- Takedown requests: takedown@g4f.ai

---

## Appendix: Quick commands &amp; examples

Install (pip):
```bash
pip install -U g4f[all]
```

Run GUI (Python):
```bash
python -m g4f.cli gui --port 8080 --debug
# or
python -c &quot;from g4f.gui import run_gui; run_gui()&quot;
```

Docker (full):
```bash
docker pull hlohaus789/g4f
docker run -p 8080:8080 -p 7900:7900 \
  --shm-size=&quot;2g&quot; \
  -v ${PWD}/har_and_cookies:/app/har_and_cookies \
  -v ${PWD}/generated_media:/app/generated_media \
  hlohaus789/g4f:latest
```

Docker (slim):
```bash
docker run -p 1337:8080 -p 8080:8080 \
  -v ${PWD}/har_and_cookies:/app/har_and_cookies \
  -v ${PWD}/generated_media:/app/generated_media \
  hlohaus789/g4f:latest-slim
```

Python usage patterns:
- `client.chat.completions.create(...)`
- `client.images.generate(...)`
- Async variants via `AsyncClient`

Docs &amp; deeper reading
- Full docs: https://g4f.dev/docs  
- Client API docs: https://g4f.dev/docs/client  
- Async client docs: https://g4f.dev/docs/async_client  
- Provider guides: https://g4f.dev/docs/guides  
- Local inference: https://g4f.dev/docs/local

---

Thank you for using and contributing to GPT4Free — together we make powerful AI tooling accessible, flexible, and community-driven.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[airweave-ai/airweave]]></title>
            <link>https://github.com/airweave-ai/airweave</link>
            <guid>https://github.com/airweave-ai/airweave</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:25 GMT</pubDate>
            <description><![CDATA[Airweave lets agents search any app]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/airweave-ai/airweave">airweave-ai/airweave</a></h1>
            <p>Airweave lets agents search any app</p>
            <p>Language: Python</p>
            <p>Stars: 4,017</p>
            <p>Forks: 489</p>
            <p>Stars today: 173 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;frontend/public/logo-airweave-darkbg.svg&quot;/&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;frontend/public/logo-airweave-lightbg.svg&quot;/&gt;
  &lt;img width=&quot;1673&quot; alt=&quot;airweave-lettermark&quot; style=&quot;padding-bottom: 12px;&quot; src=&quot;frontend/public/logo-airweave-darkbg.svg&quot;/&gt;
&lt;/picture&gt;

&lt;div align=&quot;center&quot;&gt;

# Make Any App Searchable for AI Agents

[![Ruff](https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml/badge.svg)](https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml)
[![ESLint](https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml/badge.svg)](https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml)
[![System Tests](https://github.com/airweave-ai/airweave/actions/workflows/test-public-api.yml/badge.svg)](https://github.com/airweave-ai/airweave/actions/workflows/test-public-api.yml)
[![Codecov](https://codecov.io/gh/airweave-ai/airweave/branch/main/graph/badge.svg)](https://codecov.io/gh/airweave-ai/airweave)
[![Discord](https://img.shields.io/discord/1323415085011701870?label=Discord&amp;logo=discord&amp;logoColor=white&amp;style=flat-square)](https://discord.gg/gDuebsWGkn)
&lt;br&gt;
&lt;div style=&quot;padding-top: 16px;&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/13748&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13748&quot; alt=&quot;airweave-ai%2Fairweave | Trendshift&quot; style=&quot;width: 250px; height: 55px; margin-right: 24px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://www.ycombinator.com/launches/NX7-airweave-let-agents-search-any-app&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://www.ycombinator.com/launches/NX7-airweave-let-agents-search-any-app/upvote_embed.svg&quot; alt=&quot;Launch YC: Airweave - Let Agents Search Any App&quot; style=&quot;margin-left: 12px;&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;br&gt;

⭐ **Help us reach more developers and grow the Airweave community. Star this repo!**

&lt;/div&gt;

## Overview

**Airweave is a tool that lets agents search any app.** It connects to apps, productivity tools, databases, or document stores and transforms their contents into searchable knowledge bases, accessible through a standardized interface for agents.

The search interface is exposed via REST API or MCP. When using MCP, Airweave essentially builds a semantically searchable MCP server. The platform handles everything from auth and extraction to embedding and serving.

📺 Check out the quick demo below:

&lt;video width=&quot;100%&quot; src=&quot;https://github.com/user-attachments/assets/995e4a36-3f88-4d8e-b401-6ca43db0c7bf&quot; controls&gt;&lt;/video&gt;

[**🔗 Example notebooks**](https://github.com/airweave-ai/airweave/tree/main/examples)

## Table of Contents

- [Airweave](#airweave)
  - [Overview](#overview)
  - [Table of Contents](#table-of-contents)
  - [🚀 Quick Start](#-quick-start)
  - [🔌 Supported Integrations](#-supported-integrations)
  - [💻 Usage](#-usage)
    - [Frontend](#frontend)
    - [API](#api)
  - [📦 SDKs](#-sdks)
    - [Python](#python)
    - [TypeScript/JavaScript](#typescriptjavascript)
  - [🔑 Key Features](#-key-features)
  - [🔧 Technology Stack](#-tech-stack)
  - [👥 Contributing](#-contributing)
  - [📄 License](#-license)
  - [🔗 Connect](#-connect)

## 🚀 Quick Start

### Managed Service: [Airweave Cloud](https://app.airweave.ai/)

### Self-hosted:

Make sure docker and docker-compose are installed, then...

```bash
# 1. Clone the repository
git clone https://github.com/airweave-ai/airweave.git
cd airweave

# 2. Build and run
chmod +x start.sh
./start.sh
```

That&#039;s it! Access the dashboard at http://localhost:8080

## 🔌 Supported Integrations

&lt;!-- START_APP_GRID --&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;div style=&quot;display: inline-block; text-align: center; padding: 4px;&quot;&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/asana.svg&quot; alt=&quot;Asana&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/bitbucket.svg&quot; alt=&quot;Bitbucket&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/confluence.svg&quot; alt=&quot;Confluence&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/dropbox.svg&quot; alt=&quot;Dropbox&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/github.svg&quot; alt=&quot;Github&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/gmail.svg&quot; alt=&quot;Gmail&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/google_calendar.svg&quot; alt=&quot;Google Calendar&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/google_drive.svg&quot; alt=&quot;Google Drive&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/hubspot.svg&quot; alt=&quot;Hubspot&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/jira.svg&quot; alt=&quot;Jira&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/linear.svg&quot; alt=&quot;Linear&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/monday.svg&quot; alt=&quot;Monday&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/notion.svg&quot; alt=&quot;Notion&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/onedrive.svg&quot; alt=&quot;Onedrive&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/outlook_calendar.svg&quot; alt=&quot;Outlook Calendar&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/outlook_mail.svg&quot; alt=&quot;Outlook Mail&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/postgresql.svg&quot; alt=&quot;Postgresql&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/slack.svg&quot; alt=&quot;Slack&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/stripe.svg&quot; alt=&quot;Stripe&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/todoist.svg&quot; alt=&quot;Todoist&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
  &lt;/div&gt;
&lt;/p&gt;

&lt;!-- END_APP_GRID --&gt;

## 💻 Usage

### Frontend
- Access the UI at `http://localhost:8080`
- Connect sources, configure syncs, and query data

### API
- Swagger docs: `http://localhost:8001/docs`
- Create connections, trigger syncs, and search data

## 📦 SDKs

### Python

```bash
pip install airweave-sdk
```

```python
from airweave import AirweaveSDK

client = AirweaveSDK(
    api_key=&quot;YOUR_API_KEY&quot;,
    base_url=&quot;http://localhost:8001&quot;
)
client.collections.create(
    name=&quot;name&quot;,
)
```

### TypeScript/JavaScript
```bash
npm install @airweave/sdk
# or
yarn add @airweave/sdk
```

```typescript
import { AirweaveSDKClient, AirweaveSDKEnvironment } from &quot;@airweave/sdk&quot;;

const client = new AirweaveSDKClient({
    apiKey: &quot;YOUR_API_KEY&quot;,
    environment: AirweaveSDKEnvironment.Local
});
await client.collections.create({
    name: &quot;name&quot;,
});
```

## 🔑 Key Features

- **Data synchronization** from 25+ sources with minimal config
- **Entity extraction** and transformation pipeline
- **Multi-tenant** architecture with OAuth2
- **Incremental updates** using content hashing
- **Semantic search** for agent queries
- **Versioning** for data changes

## 🔧 Tech Stack

- **Frontend**: React/TypeScript with ShadCN
- **Backend**: FastAPI (Python)
- **Databases**: PostgreSQL (metadata), Qdrant (vectors)
- **Deployment**: Docker Compose (dev), Kubernetes (prod)

## 👥 Contributing

We welcome contributions! Please check [CONTRIBUTING.md](https://github.com/airweave-ai/airweave/blob/main/CONTRIBUTING.md) for details.

## 📄 License

Airweave is released under the [MIT](LICENSE) license.

## 🔗 Connect

- **[Discord](https://discord.com/invite/484HY9Ehxt)** - Get help and discuss features
- **[GitHub Issues](https://github.com/airweave-ai/airweave/issues)** - Report bugs or request features
- **[Twitter](https://x.com/airweave_ai)** - Follow for updates
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[EbookFoundation/free-programming-books]]></title>
            <link>https://github.com/EbookFoundation/free-programming-books</link>
            <guid>https://github.com/EbookFoundation/free-programming-books</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:24 GMT</pubDate>
            <description><![CDATA[📚 Freely available programming books]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/EbookFoundation/free-programming-books">EbookFoundation/free-programming-books</a></h1>
            <p>📚 Freely available programming books</p>
            <p>Language: Python</p>
            <p>Stars: 371,564</p>
            <p>Forks: 64,590</p>
            <p>Stars today: 125 stars today</p>
            <h2>README</h2><pre># List of Free Learning Resources In Many Languages

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)&amp;#160;
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)&amp;#160;
[![Hacktoberfest 2025 stats](https://img.shields.io/github/hacktoberfest/2025/EbookFoundation/free-programming-books?label=Hacktoberfest+2025)](https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged+created%3A2025-10-01..2025-10-31)

&lt;/div&gt;

Search the list at [https://ebookfoundation.github.io/free-programming-books-search/](https://ebookfoundation.github.io/free-programming-books-search/) [![https://ebookfoundation.github.io/free-programming-books-search/](https://img.shields.io/website?style=flat&amp;logo=www&amp;logoColor=whitesmoke&amp;label=Dynamic%20search%20site&amp;down_color=red&amp;down_message=down&amp;up_color=green&amp;up_message=up&amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books-search%2F)](https://ebookfoundation.github.io/free-programming-books-search/).

This page is available as an easy-to-read website. Access it by clicking on [![https://ebookfoundation.github.io/free-programming-books/](https://img.shields.io/website?style=flat&amp;logo=www&amp;logoColor=whitesmoke&amp;label=Static%20site&amp;down_color=red&amp;down_message=down&amp;up_color=green&amp;up_message=up&amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books%2F)](https://ebookfoundation.github.io/free-programming-books/).

&lt;div align=&quot;center&quot;&gt;
  &lt;form action=&quot;https://ebookfoundation.github.io/free-programming-books-search&quot;&gt;
    &lt;input type=&quot;text&quot; id=&quot;fpbSearch&quot; name=&quot;search&quot; required placeholder=&quot;Search Book or Author&quot;/&gt;
    &lt;label for=&quot;submit&quot;&gt; &lt;/label&gt;
    &lt;input type=&quot;submit&quot; id=&quot;submit&quot; name=&quot;submit&quot; value=&quot;Search&quot; /&gt;
  &lt;/form&gt;
&lt;/div&gt;

## Intro

This list was originally a clone of [StackOverflow - List of Freely Available Programming Books](https://web.archive.org/web/20140606191453/http://stackoverflow.com/questions/194812/list-of-freely-available-programming-books/392926) with contributions from Karan Bhangui and George Stocker.

The list was moved to GitHub by Victor Felder for collaborative updating and maintenance. It has grown to become one of [GitHub&#039;s most popular repositories](https://octoverse.github.com/).

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

[![GitHub repo forks](https://img.shields.io/github/forks/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Forks)](https://github.com/EbookFoundation/free-programming-books/network)&amp;#160;
[![GitHub repo stars](https://img.shields.io/github/stars/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Stars)](https://github.com/EbookFoundation/free-programming-books/stargazers)&amp;#160;
[![GitHub repo contributors](https://img.shields.io/github/contributors-anon/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Contributors)](https://github.com/EbookFoundation/free-programming-books/graphs/contributors)    
[![GitHub org sponsors](https://img.shields.io/github/sponsors/EbookFoundation?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Sponsors)](https://github.com/sponsors/EbookFoundation)&amp;#160;
[![GitHub repo watchers](https://img.shields.io/github/watchers/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Watchers)](https://github.com/EbookFoundation/free-programming-books/watchers)&amp;#160;
[![GitHub repo size](https://img.shields.io/github/repo-size/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Repo%20Size)](https://github.com/EbookFoundation/free-programming-books/archive/refs/heads/main.zip)

&lt;/div&gt;

The [Free Ebook Foundation](https://ebookfoundation.org) now administers the repo, a not-for-profit organization devoted to promoting the creation, distribution, archiving, and sustainability of free ebooks. [Donations](https://ebookfoundation.org/contributions.html) to the Free Ebook Foundation are tax-deductible in the US.


## How To Contribute

Please read [CONTRIBUTING](docs/CONTRIBUTING.md). If you&#039;re new to GitHub, [welcome](docs/HOWTO.md)! Remember to abide by our adapted from ![Contributor Covenant 1.3](https://img.shields.io/badge/Contributor%20Covenant-1.3-4baaaa.svg) [Code of Conduct](docs/CODE_OF_CONDUCT.md) too ([translations](#translations) also available).

Click on these badges to see how you might be able to help:

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

[![GitHub repo Issues](https://img.shields.io/github/issues/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=red&amp;label=Issues)](https://github.com/EbookFoundation/free-programming-books/issues)&amp;#160;
[![GitHub repo Good Issues for newbies](https://img.shields.io/github/issues/EbookFoundation/free-programming-books/good%20first%20issue?style=flat&amp;logo=github&amp;logoColor=green&amp;label=Good%20First%20issues)](https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)&amp;#160;
[![GitHub Help Wanted issues](https://img.shields.io/github/issues/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;logo=github&amp;logoColor=b545d1&amp;label=%22Help%20Wanted%22%20issues)](https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)    
[![GitHub repo PRs](https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=orange&amp;label=PRs)](https://github.com/EbookFoundation/free-programming-books/pulls)&amp;#160;
[![GitHub repo Merged PRs](https://img.shields.io/github/issues-search/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=green&amp;label=Merged%20PRs&amp;query=is%3Amerged)](https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged)&amp;#160;
[![GitHub Help Wanted PRs](https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;logo=github&amp;logoColor=b545d1&amp;label=%22Help%20Wanted%22%20PRs)](https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)

&lt;/div&gt;

## How To Share

&lt;div align=&quot;left&quot; markdown=&quot;1&quot;&gt;
&lt;a href=&quot;https://www.facebook.com/share.php?u=https%3A%2F%2Fgithub.com%2FEbookFoundation%2Ffree-programming-books&amp;p[images][0]=&amp;p[title]=Free%20Programming%20Books&amp;p[summary]=&quot;&gt;Share on Facebook&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;http://www.linkedin.com/shareArticle?mini=true&amp;url=https://github.com/EbookFoundation/free-programming-books&amp;title=Free%20Programming%20Books&amp;summary=&amp;source=&quot;&gt;Share on LinkedIn&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;https://toot.kytta.dev/?text=https://github.com/EbookFoundation/free-programming-books&quot;&gt;Share on Mastodon/Fediverse&lt;/a&gt;&lt;br&gt;    
&lt;a href=&quot;https://t.me/share/url?url=https://github.com/EbookFoundation/free-programming-books&quot;&gt;Share on Telegram&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;https://twitter.com/intent/tweet?text=https://github.com/EbookFoundation/free-programming-books%0AFree%20Programming%20Books&quot;&gt;Share on 𝕏 (Twitter)&lt;/a&gt;&lt;br&gt;
&lt;/div&gt;

## Resources

This project lists books and other resources grouped by genres:

### Books

[English, By Programming Language](books/free-programming-books-langs.md)

[English, By Subject](books/free-programming-books-subjects.md)

#### Other Languages

+ [Arabic / al arabiya / العربية](books/free-programming-books-ar.md)
+ [Armenian / Հայերեն](books/free-programming-books-hy.md)
+ [Azerbaijani / Азәрбајҹан дили / آذربايجانجا ديلي](books/free-programming-books-az.md)
+ [Bengali / বাংলা](books/free-programming-books-bn.md)
+ [Bulgarian / български](books/free-programming-books-bg.md)
+ [Burmese / မြန်မာဘာသာ](books/free-programming-books-my.md)
+ [Chinese / 中文](books/free-programming-books-zh.md)
+ [Czech / čeština / český jazyk](books/free-programming-books-cs.md)
+ [Catalan / catalan/ català](books/free-programming-books-ca.md)
+ [Danish / dansk](books/free-programming-books-da.md)
+ [Dutch / Nederlands](books/free-programming-books-nl.md)
+ [Estonian / eesti keel](books/free-programming-books-et.md)
+ [Finnish / suomi / suomen kieli](books/free-programming-books-fi.md)
+ [French / français](books/free-programming-books-fr.md)
+ [German / Deutsch](books/free-programming-books-de.md)
+ [Greek / ελληνικά](books/free-programming-books-el.md)
+ [Hebrew / עברית](books/free-programming-books-he.md)
+ [Hindi / हिन्दी](books/free-programming-books-hi.md)
+ [Hungarian / magyar / magyar nyelv](books/free-programming-books-hu.md)
+ [Indonesian / Bahasa Indonesia](books/free-programming-books-id.md)
+ [Italian / italiano](books/free-programming-books-it.md)
+ [Japanese / 日本語](books/free-programming-books-ja.md)
+ [Korean / 한국어](books/free-programming-books-ko.md)
+ [Latvian / Latviešu](books/free-programming-books-lv.md)
+ [Malayalam / മലയാളം](books/free-programming-books-ml.md)
+ [Norwegian / Norsk](books/free-programming-books-no.md)
+ [Persian / Farsi (Iran) / فارسى](books/free-programming-books-fa_IR.md)
+ [Polish / polski / język polski / polszczyzna](books/free-programming-books-pl.md)
+ [Portuguese (Brazil)](books/free-programming-books-pt_BR.md)
+ [Portuguese (Portugal)](books/free-programming-books-pt_PT.md)
+ [Romanian (Romania) / limba română / român](books/free-programming-books-ro.md)
+ [Russian / Русский язык](books/free-programming-books-ru.md)
+ [Serbian / српски језик / srpski jezik](books/free-programming-books-sr.md)
+ [Slovak / slovenčina](books/free-programming-books-sk.md)
+ [Spanish / español / castellano](books/free-programming-books-es.md)
+ [Swedish / Svenska](books/free-programming-books-sv.md)
+ [Tamil / தமிழ்](books/free-programming-books-ta.md)
+ [Telugu / తెలుగు](books/free-programming-books-te.md)
+ [Thai / ไทย](books/free-programming-books-th.md)
+ [Turkish / Türkçe](books/free-programming-books-tr.md)
+ [Ukrainian / Українська](books/free-programming-books-uk.md)
+ [Vietnamese / Tiếng Việt](books/free-programming-books-vi.md)

### Cheat Sheets

+ [All Languages](more/free-programming-cheatsheets.md)

### Free Online Courses

+ [Arabic / al arabiya / العربية](courses/free-courses-ar.md)
+ [Bengali / বাংলা](courses/free-courses-bn.md)
+ [Bulgarian / български](courses/free-courses-bg.md)
+ [Burmese / မြန်မာဘာသာ](courses/free-courses-my.md)
+ [Chinese / 中文](courses/free-courses-zh.md)
+ [English](courses/free-courses-en.md)
+ [Finnish / suomi / suomen kieli](courses/free-courses-fi.md)
+ [French / français](courses/free-courses-fr.md)
+ [German / Deutsch](courses/free-courses-de.md)
+ [Greek / ελληνικά](courses/free-courses-el.md)
+ [Hebrew / עברית](courses/free-courses-he.md)
+ [Hindi / हिंदी](courses/free-courses-hi.md)
+ [Indonesian / Bahasa Indonesia](courses/free-courses-id.md)
+ [Italian / italiano](courses/free-courses-it.md)
+ [Japanese / 日本語](courses/free-courses-ja.md)
+ [Kannada/ಕನ್ನಡ](courses/free-courses-kn.md)
+ [Kazakh / қазақша](courses/free-courses-kk.md)
+ [Khmer / ភាសាខ្មែរ](courses/free-courses-km.md)
+ [Korean / 한국어](courses/free-courses-ko.md)
+ [Malayalam / മലയാളം](courses/free-courses-ml.md)
+ [Marathi / मराठी](courses/free-courses-mr.md)
+ [Nepali / नेपाली](courses/free-courses-ne.md)
+ [Norwegian / Norsk](courses/free-courses-no.md)
+ [Persian / Farsi (Iran) / فارسى](courses/free-courses-fa_IR.md)
+ [Polish / polski / język polski / polszczyzna](courses/free-courses-pl.md)
+ [Portuguese (Brazil)](courses/free-courses-pt_BR.md)
+ [Portuguese (Portugal)](courses/free-courses-pt_PT.md)
+ [Russian / Русский язык](courses/free-courses-ru.md)
+ [Sinhala / සිංහල](courses/free-courses-si.md)
+ [Spanish / español / castellano](courses/free-courses-es.md)
+ [Swedish / svenska](courses/free-courses-sv.md)
+ [Tamil / தமிழ்](courses/free-courses-ta.md)
+ [Telugu / తెలుగు](courses/free-courses-te.md)
+ [Thai / ภาษาไทย](courses/free-courses-th.md)
+ [Turkish / Türkçe](courses/free-courses-tr.md)
+ [Ukrainian / Українська](courses/free-courses-uk.md)
+ [Urdu / اردو](courses/free-courses-ur.md)
+ [Vietnamese / Tiếng Việt](courses/free-courses-vi.md)


### Interactive Programming Resources

+ [Chinese / 中文](more/free-programming-interactive-tutorials-zh.md)
+ [English](more/free-programming-interactive-tutorials-en.md)
+ [German / Deutsch](more/free-programming-interactive-tutorials-de.md)
+ [Japanese / 日本語](more/free-programming-interactive-tutorials-ja.md)
+ [Russian / Русский язык](more/free-programming-interactive-tutorials-ru.md)


### Problem Sets and Competitive Programming

+ [Problem Sets](more/problem-sets-competitive-programming.md)


### Podcast - Screencast

Free Podcasts and Screencasts:

+ [Arabic / al Arabiya / العربية](casts/free-podcasts-screencasts-ar.md)
+ [Burmese / မြန်မာဘာသာ](casts/free-podcasts-screencasts-my.md)
+ [Chinese / 中文](casts/free-podcasts-screencasts-zh.md)
+ [Czech / čeština / český jazyk](casts/free-podcasts-screencasts-cs.md)
+ [Dutch / Nederlands](casts/free-podcasts-screencasts-nl.md)
+ [English](casts/free-podcasts-screencasts-en.md)
+ [Finnish / Suomi](casts/free-podcasts-screencasts-fi.md)
+ [French / français](casts/free-podcasts-screencasts-fr.md)
+ [German / Deutsch](casts/free-podcasts-screencasts-de.md)
+ [Hebrew / עברית](casts/free-podcasts-screencasts-he.md)
+ [Indonesian / Bahasa Indonesia](casts/free-podcasts-screencasts-id.md)
+ [Persian / Farsi (Iran) / فارسى](casts/free-podcasts-screencasts-fa_IR.md)
+ [Polish / polski / język polski / polszczyzna](casts/free-podcasts-screencasts-pl.md)
+ [Portuguese (Brazil)](casts/free-podcasts-screencasts-pt_BR.md)
+ [Portuguese (Portugal)](casts/free-podcasts-screencasts-pt_PT.md)
+ [Russian / Русский язык](casts/free-podcasts-screencasts-ru.md)
+ [Sinhala / සිංහල](casts/free-podcasts-screencasts-si.md)
+ [Spanish / español / castellano](casts/free-podcasts-screencasts-es.md)
+ [Swedish / Svenska](casts/free-podcasts-screencasts-sv.md)
+ [Turkish / Türkçe](casts/free-podcasts-screencasts-tr.md)
+ [Ukrainian / Українська](casts/free-podcasts-screencasts-uk.md)


### Programming Playgrounds

Write, compile, and run your code within a browser. Try it out!

+ [Chinese / 中文](more/free-programming-playgrounds-zh.md)
+ [English](more/free-programming-playgrounds.md)
+ [German / Deutsch](more/free-programming-playgrounds-de.md)

## Translations

Volunteers have translated many of our Contributing, How-to, and Code of Conduct documents into languages covered by our lists.

+ English
  + [Code of Conduct](docs/CODE_OF_CONDUCT.md)
  + [Contributing](docs/CONTRIBUTING.md)
  + [How-to](docs/HOWTO.md)
+ ... *[More languages](docs/README.md#translations)* ...

You might notice that there are [some missing translations here](docs/README.md#translations) - perhaps you would like to help out by [contributing a translation](docs/CONTRIBUTING.md#help-out-by-contributing-a-translation)?


## License

Each file included in this repository is licensed under the [CC BY License](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Alvin9999/new-pac]]></title>
            <link>https://github.com/Alvin9999/new-pac</link>
            <guid>https://github.com/Alvin9999/new-pac</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:23 GMT</pubDate>
            <description><![CDATA[翻墙-科学上网、自由上网、免费科学上网、免费翻墙、fanqiang、油管youtube/视频下载、软件、VPN、一键翻墙浏览器，vps一键搭建翻墙服务器脚本/教程，免费shadowsocks/ss/ssr/v2ray/goflyway账号/节点，翻墙梯子，电脑、手机、iOS、安卓、windows、Mac、Linux、路由器翻墙、科学上网、youtube视频下载、youtube油管镜像/免翻墙网站、美区apple id共享账号、翻墙-科学上网-梯子]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Alvin9999/new-pac">Alvin9999/new-pac</a></h1>
            <p>翻墙-科学上网、自由上网、免费科学上网、免费翻墙、fanqiang、油管youtube/视频下载、软件、VPN、一键翻墙浏览器，vps一键搭建翻墙服务器脚本/教程，免费shadowsocks/ss/ssr/v2ray/goflyway账号/节点，翻墙梯子，电脑、手机、iOS、安卓、windows、Mac、Linux、路由器翻墙、科学上网、youtube视频下载、youtube油管镜像/免翻墙网站、美区apple id共享账号、翻墙-科学上网-梯子</p>
            <p>Language: Python</p>
            <p>Stars: 69,032</p>
            <p>Forks: 10,397</p>
            <p>Stars today: 43 stars today</p>
            <h2>README</h2><pre>科学上网-翻墙、免费翻墙、免费科学上网、软件、VPN、一键翻墙浏览器，vps一键搭建翻墙服务器脚本/教程，免费shadowsocks/ss/ssr/v2ray/goflyway账号/节点，免费自由上网、fanqiang、翻墙梯子，电脑、手机、iOS、安卓、windows、Mac、Linux、路由器翻墙、youtube视频下载、youtube油管镜像/免翻墙网站、美区apple id共享账号

**https://github.com/Alvin9999/new-pac/wiki**

北京时间2025年10月06日07点51分更新。
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[freqtrade/freqtrade]]></title>
            <link>https://github.com/freqtrade/freqtrade</link>
            <guid>https://github.com/freqtrade/freqtrade</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:22 GMT</pubDate>
            <description><![CDATA[Free, open source crypto trading bot]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/freqtrade/freqtrade">freqtrade/freqtrade</a></h1>
            <p>Free, open source crypto trading bot</p>
            <p>Language: Python</p>
            <p>Stars: 43,323</p>
            <p>Forks: 8,800</p>
            <p>Stars today: 24 stars today</p>
            <h2>README</h2><pre># ![freqtrade](https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade_poweredby.svg)

[![Freqtrade CI](https://github.com/freqtrade/freqtrade/actions/workflows/ci.yml/badge.svg?branch=develop)](https://github.com/freqtrade/freqtrade/actions/)
[![DOI](https://joss.theoj.org/papers/10.21105/joss.04864/status.svg)](https://doi.org/10.21105/joss.04864)
[![Coverage Status](https://coveralls.io/repos/github/freqtrade/freqtrade/badge.svg?branch=develop&amp;service=github)](https://coveralls.io/github/freqtrade/freqtrade?branch=develop)
[![Documentation](https://readthedocs.org/projects/freqtrade/badge/)](https://www.freqtrade.io)

Freqtrade is a free and open source crypto trading bot written in Python. It is designed to support all major exchanges and be controlled via Telegram or webUI. It contains backtesting, plotting and money management tools as well as strategy optimization by machine learning.

![freqtrade](https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade-screenshot.png)

## Disclaimer

This software is for educational purposes only. Do not risk money which
you are afraid to lose. USE THE SOFTWARE AT YOUR OWN RISK. THE AUTHORS
AND ALL AFFILIATES ASSUME NO RESPONSIBILITY FOR YOUR TRADING RESULTS.

Always start by running a trading bot in Dry-run and do not engage money
before you understand how it works and what profit/loss you should
expect.

We strongly recommend you to have coding and Python knowledge. Do not
hesitate to read the source code and understand the mechanism of this bot.

## Supported Exchange marketplaces

Please read the [exchange specific notes](docs/exchanges.md) to learn about eventual, special configurations needed for each exchange.

- [X] [Binance](https://www.binance.com/)
- [X] [Bitmart](https://bitmart.com/)
- [X] [BingX](https://bingx.com/invite/0EM9RX)
- [X] [Bybit](https://bybit.com/)
- [X] [Gate.io](https://www.gate.io/ref/6266643)
- [X] [HTX](https://www.htx.com/)
- [X] [Hyperliquid](https://hyperliquid.xyz/) (A decentralized exchange, or DEX)
- [X] [Kraken](https://kraken.com/)
- [X] [OKX](https://okx.com/)
- [X] [MyOKX](https://okx.com/) (OKX EEA)
- [ ] [potentially many others](https://github.com/ccxt/ccxt/). _(We cannot guarantee they will work)_

### Supported Futures Exchanges (experimental)

- [X] [Binance](https://www.binance.com/)
- [X] [Gate.io](https://www.gate.io/ref/6266643)
- [X] [Hyperliquid](https://hyperliquid.xyz/) (A decentralized exchange, or DEX)
- [X] [OKX](https://okx.com/)
- [X] [Bybit](https://bybit.com/)

Please make sure to read the [exchange specific notes](docs/exchanges.md), as well as the [trading with leverage](docs/leverage.md) documentation before diving in.

### Community tested

Exchanges confirmed working by the community:

- [X] [Bitvavo](https://bitvavo.com/)
- [X] [Kucoin](https://www.kucoin.com/)

## Documentation

We invite you to read the bot documentation to ensure you understand how the bot is working.

Please find the complete documentation on the [freqtrade website](https://www.freqtrade.io).

## Features

- [x] **Based on Python 3.11+**: For botting on any operating system - Windows, macOS and Linux.
- [x] **Persistence**: Persistence is achieved through sqlite.
- [x] **Dry-run**: Run the bot without paying money.
- [x] **Backtesting**: Run a simulation of your buy/sell strategy.
- [x] **Strategy Optimization by machine learning**: Use machine learning to optimize your buy/sell strategy parameters with real exchange data.
- [X] **Adaptive prediction modeling**: Build a smart strategy with FreqAI that self-trains to the market via adaptive machine learning methods. [Learn more](https://www.freqtrade.io/en/stable/freqai/)
- [x] **Whitelist crypto-currencies**: Select which crypto-currency you want to trade or use dynamic whitelists.
- [x] **Blacklist crypto-currencies**: Select which crypto-currency you want to avoid.
- [x] **Builtin WebUI**: Builtin web UI to manage your bot.
- [x] **Manageable via Telegram**: Manage the bot with Telegram.
- [x] **Display profit/loss in fiat**: Display your profit/loss in fiat currency.
- [x] **Performance status report**: Provide a performance status of your current trades.

## Quick start

Please refer to the [Docker Quickstart documentation](https://www.freqtrade.io/en/stable/docker_quickstart/) on how to get started quickly.

For further (native) installation methods, please refer to the [Installation documentation page](https://www.freqtrade.io/en/stable/installation/).

## Basic Usage

### Bot commands

```
usage: freqtrade [-h] [-V]
                 {trade,create-userdir,new-config,show-config,new-strategy,download-data,convert-data,convert-trade-data,trades-to-ohlcv,list-data,backtesting,backtesting-show,backtesting-analysis,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-markets,list-pairs,list-strategies,list-hyperoptloss,list-freqaimodels,list-timeframes,show-trades,test-pairlist,convert-db,install-ui,plot-dataframe,plot-profit,webserver,strategy-updater,lookahead-analysis,recursive-analysis}
                 ...

Free, open source crypto trading bot

positional arguments:
  {trade,create-userdir,new-config,show-config,new-strategy,download-data,convert-data,convert-trade-data,trades-to-ohlcv,list-data,backtesting,backtesting-show,backtesting-analysis,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-markets,list-pairs,list-strategies,list-hyperoptloss,list-freqaimodels,list-timeframes,show-trades,test-pairlist,convert-db,install-ui,plot-dataframe,plot-profit,webserver,strategy-updater,lookahead-analysis,recursive-analysis}
    trade               Trade module.
    create-userdir      Create user-data directory.
    new-config          Create new config
    show-config         Show resolved config
    new-strategy        Create new strategy
    download-data       Download backtesting data.
    convert-data        Convert candle (OHLCV) data from one format to
                        another.
    convert-trade-data  Convert trade data from one format to another.
    trades-to-ohlcv     Convert trade data to OHLCV data.
    list-data           List downloaded data.
    backtesting         Backtesting module.
    backtesting-show    Show past Backtest results
    backtesting-analysis
                        Backtest Analysis module.
    hyperopt            Hyperopt module.
    hyperopt-list       List Hyperopt results
    hyperopt-show       Show details of Hyperopt results
    list-exchanges      Print available exchanges.
    list-markets        Print markets on exchange.
    list-pairs          Print pairs on exchange.
    list-strategies     Print available strategies.
    list-hyperoptloss   Print available hyperopt loss functions.
    list-freqaimodels   Print available freqAI models.
    list-timeframes     Print available timeframes for the exchange.
    show-trades         Show trades.
    test-pairlist       Test your pairlist configuration.
    convert-db          Migrate database to different system
    install-ui          Install FreqUI
    plot-dataframe      Plot candles with indicators.
    plot-profit         Generate plot showing profits.
    webserver           Webserver module.
    strategy-updater    updates outdated strategy files to the current version
    lookahead-analysis  Check for potential look ahead bias.
    recursive-analysis  Check for potential recursive formula issue.

options:
  -h, --help            show this help message and exit
  -V, --version         show program&#039;s version number and exit
```

### Telegram RPC commands

Telegram is not mandatory. However, this is a great way to control your bot. More details and the full command list on the [documentation](https://www.freqtrade.io/en/latest/telegram-usage/)

- `/start`: Starts the trader.
- `/stop`: Stops the trader.
- `/stopentry`: Stop entering new trades.
- `/status &lt;trade_id&gt;|[table]`: Lists all or specific open trades.
- `/profit [&lt;n&gt;]`: Lists cumulative profit from all finished trades, over the last n days.
- `/profit_long [&lt;n&gt;]`: Lists cumulative profit from all finished long trades, over the last n days.
- `/profit_short [&lt;n&gt;]`: Lists cumulative profit from all finished short trades, over the last n days.
- `/forceexit &lt;trade_id&gt;|all`: Instantly exits the given trade (Ignoring `minimum_roi`).
- `/fx &lt;trade_id&gt;|all`: Alias to `/forceexit`
- `/performance`: Show performance of each finished trade grouped by pair
- `/balance`: Show account balance per currency.
- `/daily &lt;n&gt;`: Shows profit or loss per day, over the last n days.
- `/help`: Show help message.
- `/version`: Show version.


## Development branches

The project is currently setup in two main branches:

- `develop` - This branch has often new features, but might also contain breaking changes. We try hard to keep this branch as stable as possible.
- `stable` - This branch contains the latest stable release. This branch is generally well tested.
- `feat/*` - These are feature branches, which are being worked on heavily. Please don&#039;t use these unless you want to test a specific feature.

## Support

### Help / Discord

For any questions not covered by the documentation or for further information about the bot, or to simply engage with like-minded individuals, we encourage you to join the Freqtrade [discord server](https://discord.gg/p7nuUNVfP7).

### [Bugs / Issues](https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue)

If you discover a bug in the bot, please
[search the issue tracker](https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue)
first. If it hasn&#039;t been reported, please
[create a new issue](https://github.com/freqtrade/freqtrade/issues/new/choose) and
ensure you follow the template guide so that the team can assist you as
quickly as possible.

For every [issue](https://github.com/freqtrade/freqtrade/issues/new/choose) created, kindly follow up and mark satisfaction or reminder to close issue when equilibrium ground is reached.

--Maintain github&#039;s [community policy](https://docs.github.com/en/site-policy/github-terms/github-community-code-of-conduct)--

### [Feature Requests](https://github.com/freqtrade/freqtrade/labels/enhancement)

Have you a great idea to improve the bot you want to share? Please,
first search if this feature was not [already discussed](https://github.com/freqtrade/freqtrade/labels/enhancement).
If it hasn&#039;t been requested, please
[create a new request](https://github.com/freqtrade/freqtrade/issues/new/choose)
and ensure you follow the template guide so that it does not get lost
in the bug reports.

### [Pull Requests](https://github.com/freqtrade/freqtrade/pulls)

Feel like the bot is missing a feature? We welcome your pull requests!

Please read the
[Contributing document](https://github.com/freqtrade/freqtrade/blob/develop/CONTRIBUTING.md)
to understand the requirements before sending your pull-requests.

Coding is not a necessity to contribute - maybe start with improving the documentation?
Issues labeled [good first issue](https://github.com/freqtrade/freqtrade/labels/good%20first%20issue) can be good first contributions, and will help get you familiar with the codebase.

**Note** before starting any major new feature work, *please open an issue describing what you are planning to do* or talk to us on [discord](https://discord.gg/p7nuUNVfP7) (please use the #dev channel for this). This will ensure that interested parties can give valuable feedback on the feature, and let others know that you are working on it.

**Important:** Always create your PR against the `develop` branch, not `stable`.

## Requirements

### Up-to-date clock

The clock must be accurate, synchronized to a NTP server very frequently to avoid problems with communication to the exchanges.

### Minimum hardware required

To run this bot we recommend you a cloud instance with a minimum of:

- Minimal (advised) system requirements: 2GB RAM, 1GB disk space, 2vCPU

### Software requirements

- [Python &gt;= 3.11](http://docs.python-guide.org/en/latest/starting/installation/)
- [pip](https://pip.pypa.io/en/stable/installing/)
- [git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)
- [TA-Lib](https://ta-lib.github.io/ta-lib-python/)
- [virtualenv](https://virtualenv.pypa.io/en/stable/installation.html) (Recommended)
- [Docker](https://www.docker.com/products/docker) (Recommended)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[AUTOMATIC1111/stable-diffusion-webui]]></title>
            <link>https://github.com/AUTOMATIC1111/stable-diffusion-webui</link>
            <guid>https://github.com/AUTOMATIC1111/stable-diffusion-webui</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:21 GMT</pubDate>
            <description><![CDATA[Stable Diffusion web UI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">AUTOMATIC1111/stable-diffusion-webui</a></h1>
            <p>Stable Diffusion web UI</p>
            <p>Language: Python</p>
            <p>Stars: 157,070</p>
            <p>Forks: 29,154</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre># Stable Diffusion web UI
A web interface for Stable Diffusion, implemented using Gradio library.

![](screenshot.png)

## Features
[Detailed feature showcase with images](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features):
- Original txt2img and img2img modes
- One click install and run script (but you still must install python and git)
- Outpainting
- Inpainting
- Color Sketch
- Prompt Matrix
- Stable Diffusion Upscale
- Attention, specify parts of text that the model should pay more attention to
    - a man in a `((tuxedo))` - will pay more attention to tuxedo
    - a man in a `(tuxedo:1.21)` - alternative syntax
    - select text and press `Ctrl+Up` or `Ctrl+Down` (or `Command+Up` or `Command+Down` if you&#039;re on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)
- Loopback, run img2img processing multiple times
- X/Y/Z plot, a way to draw a 3 dimensional plot of images with different parameters
- Textual Inversion
    - have as many embeddings as you want and use any names you like for them
    - use multiple embeddings with different numbers of vectors per token
    - works with half precision floating point numbers
    - train embeddings on 8GB (also reports of 6GB working)
- Extras tab with:
    - GFPGAN, neural network that fixes faces
    - CodeFormer, face restoration tool as an alternative to GFPGAN
    - RealESRGAN, neural network upscaler
    - ESRGAN, neural network upscaler with a lot of third party models
    - SwinIR and Swin2SR ([see here](https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/2092)), neural network upscalers
    - LDSR, Latent diffusion super resolution upscaling
- Resizing aspect ratio options
- Sampling method selection
    - Adjust sampler eta values (noise multiplier)
    - More advanced noise setting options
- Interrupt processing at any time
- 4GB video card support (also reports of 2GB working)
- Correct seeds for batches
- Live prompt token length validation
- Generation parameters
     - parameters you used to generate images are saved with that image
     - in PNG chunks for PNG, in EXIF for JPEG
     - can drag the image to PNG info tab to restore generation parameters and automatically copy them into UI
     - can be disabled in settings
     - drag and drop an image/text-parameters to promptbox
- Read Generation Parameters Button, loads parameters in promptbox to UI
- Settings page
- Running arbitrary python code from UI (must run with `--allow-code` to enable)
- Mouseover hints for most UI elements
- Possible to change defaults/mix/max/step values for UI elements via text config
- Tiling support, a checkbox to create images that can be tiled like textures
- Progress bar and live image generation preview
    - Can use a separate neural network to produce previews with almost none VRAM or compute requirement
- Negative prompt, an extra text field that allows you to list what you don&#039;t want to see in generated image
- Styles, a way to save part of prompt and easily apply them via dropdown later
- Variations, a way to generate same image but with tiny differences
- Seed resizing, a way to generate same image but at slightly different resolution
- CLIP interrogator, a button that tries to guess prompt from an image
- Prompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midway
- Batch Processing, process a group of files using img2img
- Img2img Alternative, reverse Euler method of cross attention control
- Highres Fix, a convenience option to produce high resolution pictures in one click without usual distortions
- Reloading checkpoints on the fly
- Checkpoint Merger, a tab that allows you to merge up to 3 checkpoints into one
- [Custom scripts](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts) with many extensions from community
- [Composable-Diffusion](https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/), a way to use multiple prompts at once
     - separate prompts using uppercase `AND`
     - also supports weights for prompts: `a cat :1.2 AND a dog AND a penguin :2.2`
- No token limit for prompts (original stable diffusion lets you use up to 75 tokens)
- DeepDanbooru integration, creates danbooru style tags for anime prompts
- [xformers](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers), major speed increase for select cards: (add `--xformers` to commandline args)
- via extension: [History tab](https://github.com/yfszzx/stable-diffusion-webui-images-browser): view, direct and delete images conveniently within the UI
- Generate forever option
- Training tab
     - hypernetworks and embeddings options
     - Preprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)
- Clip skip
- Hypernetworks
- Loras (same as Hypernetworks but more pretty)
- A separate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your prompt
- Can select to load a different VAE from settings screen
- Estimated completion time in progress bar
- API
- Support for dedicated [inpainting model](https://github.com/runwayml/stable-diffusion#inpainting-with-stable-diffusion) by RunwayML
- via extension: [Aesthetic Gradients](https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients), a way to generate images with a specific aesthetic by using clip images embeds (implementation of [https://github.com/vicgalle/stable-diffusion-aesthetic-gradients](https://github.com/vicgalle/stable-diffusion-aesthetic-gradients))
- [Stable Diffusion 2.0](https://github.com/Stability-AI/stablediffusion) support - see [wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#stable-diffusion-20) for instructions
- [Alt-Diffusion](https://arxiv.org/abs/2211.06679) support - see [wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#alt-diffusion) for instructions
- Now without any bad letters!
- Load checkpoints in safetensors format
- Eased resolution restriction: generated image&#039;s dimensions must be a multiple of 8 rather than 64
- Now with a license!
- Reorder elements in the UI from settings screen
- [Segmind Stable Diffusion](https://huggingface.co/segmind/SSD-1B) support

## Installation and Running
Make sure the required [dependencies](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Dependencies) are met and follow the instructions available for:
- [NVidia](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs) (recommended)
- [AMD](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs) GPUs.
- [Intel CPUs, Intel GPUs (both integrated and discrete)](https://github.com/openvinotoolkit/stable-diffusion-webui/wiki/Installation-on-Intel-Silicon) (external wiki page)
- [Ascend NPUs](https://github.com/wangshuai09/stable-diffusion-webui/wiki/Install-and-run-on-Ascend-NPUs) (external wiki page)

Alternatively, use online services (like Google Colab):

- [List of Online Services](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Online-Services)

### Installation on Windows 10/11 with NVidia-GPUs using release package
1. Download `sd.webui.zip` from [v1.0.0-pre](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.0.0-pre) and extract its contents.
2. Run `update.bat`.
3. Run `run.bat`.
&gt; For more details see [Install-and-Run-on-NVidia-GPUs](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs)

### Automatic Installation on Windows
1. Install [Python 3.10.6](https://www.python.org/downloads/release/python-3106/) (Newer version of Python does not support torch), checking &quot;Add Python to PATH&quot;.
2. Install [git](https://git-scm.com/download/win).
3. Download the stable-diffusion-webui repository, for example by running `git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git`.
4. Run `webui-user.bat` from Windows Explorer as normal, non-administrator, user.

### Automatic Installation on Linux
1. Install the dependencies:
```bash
# Debian-based:
sudo apt install wget git python3 python3-venv libgl1 libglib2.0-0
# Red Hat-based:
sudo dnf install wget git python3 gperftools-libs libglvnd-glx
# openSUSE-based:
sudo zypper install wget git python3 libtcmalloc4 libglvnd
# Arch-based:
sudo pacman -S wget git python3
```
If your system is very new, you need to install python3.11 or python3.10:
```bash
# Ubuntu 24.04
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.11

# Manjaro/Arch
sudo pacman -S yay
yay -S python311 # do not confuse with python3.11 package

# Only for 3.11
# Then set up env variable in launch script
export python_cmd=&quot;python3.11&quot;
# or in webui-user.sh
python_cmd=&quot;python3.11&quot;
```
2. Navigate to the directory you would like the webui to be installed and execute the following command:
```bash
wget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh
```
Or just clone the repo wherever you want:
```bash
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
```

3. Run `webui.sh`.
4. Check `webui-user.sh` for options.
### Installation on Apple Silicon

Find the instructions [here](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon).

## Contributing
Here&#039;s how to add code to this repo: [Contributing](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)

## Documentation

The documentation was moved from this README over to the project&#039;s [wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki).

For the purposes of getting Google and other search engines to crawl the wiki, here&#039;s a link to the (not for humans) [crawlable wiki](https://github-wiki-see.page/m/AUTOMATIC1111/stable-diffusion-webui/wiki).

## Credits
Licenses for borrowed code can be found in `Settings -&gt; Licenses` screen, and also in `html/licenses.html` file.

- Stable Diffusion - https://github.com/Stability-AI/stablediffusion, https://github.com/CompVis/taming-transformers, https://github.com/mcmonkey4eva/sd3-ref
- k-diffusion - https://github.com/crowsonkb/k-diffusion.git
- Spandrel - https://github.com/chaiNNer-org/spandrel implementing
  - GFPGAN - https://github.com/TencentARC/GFPGAN.git
  - CodeFormer - https://github.com/sczhou/CodeFormer
  - ESRGAN - https://github.com/xinntao/ESRGAN
  - SwinIR - https://github.com/JingyunLiang/SwinIR
  - Swin2SR - https://github.com/mv-lab/swin2sr
- LDSR - https://github.com/Hafiidz/latent-diffusion
- MiDaS - https://github.com/isl-org/MiDaS
- Ideas for optimizations - https://github.com/basujindal/stable-diffusion
- Cross Attention layer optimization - Doggettx - https://github.com/Doggettx/stable-diffusion, original idea for prompt editing.
- Cross Attention layer optimization - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (originally http://github.com/lstein/stable-diffusion)
- Sub-quadratic Cross Attention layer optimization - Alex Birch (https://github.com/Birch-san/diffusers/pull/1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)
- Textual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (we&#039;re not using his code, but we are using his ideas).
- Idea for SD upscale - https://github.com/jquesnelle/txt2imghd
- Noise generation for outpainting mk2 - https://github.com/parlance-zz/g-diffuser-bot
- CLIP interrogator idea and borrowing some code - https://github.com/pharmapsychotic/clip-interrogator
- Idea for Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch
- xformers - https://github.com/facebookresearch/xformers
- DeepDanbooru - interrogator for anime diffusers https://github.com/KichangKim/DeepDanbooru
- Sampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (https://github.com/Birch-san/diffusers-play/tree/92feee6)
- Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - https://github.com/timothybrooks/instruct-pix2pix
- Security advice - RyotaK
- UniPC sampler - Wenliang Zhao - https://github.com/wl-zhao/UniPC
- TAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesd
- LyCORIS - KohakuBlueleaf
- Restart sampling - lambertae - https://github.com/Newbeeer/diffusion_restart_sampling
- Hypertile - tfernd - https://github.com/tfernd/HyperTile
- Initial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.
- (You)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[pwndbg/pwndbg]]></title>
            <link>https://github.com/pwndbg/pwndbg</link>
            <guid>https://github.com/pwndbg/pwndbg</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:20 GMT</pubDate>
            <description><![CDATA[Exploit Development and Reverse Engineering with GDB & LLDB Made Easy]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pwndbg/pwndbg">pwndbg/pwndbg</a></h1>
            <p>Exploit Development and Reverse Engineering with GDB & LLDB Made Easy</p>
            <p>Language: Python</p>
            <p>Stars: 9,367</p>
            <p>Forks: 1,088</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>![repository-open-graph](https://github.com/pwndbg/pwndbg/assets/150354584/77b2e438-898f-416f-a989-4bef30759627)
# pwndbg

[![license](https://img.shields.io/github/license/mashape/apistatus.svg?maxAge=2592000)](https://choosealicense.com/licenses/mit/)
[![Tests](https://github.com/pwndbg/pwndbg/actions/workflows/tests.yml/badge.svg?branch=dev&amp;event=push)](https://github.com/pwndbg/pwndbg/actions/workflows/tests.yml)
[![codecov.io](https://codecov.io/github/pwndbg/pwndbg/branch/dev/badge.svg?token=i1cBPFVCav)](https://app.codecov.io/github/pwndbg/pwndbg/tree/dev)
[![Discord](https://img.shields.io/discord/843809097920413717?label=Discord&amp;style=plastic)](https://discord.gg/x47DssnGwm)

`pwndbg` (/paʊnˈdiˌbʌɡ/) is a GDB and LLDB plug-in that makes debugging suck less,
with a focus on features needed by low-level software developers, hardware hackers,
reverse-engineers and exploit developers.

It has a boatload of features, see our [Features page](https://pwndbg.re/pwndbg/latest/features/)
and [CHEATSHEET][CHEATSHEET] (feel free to print it!). If you have any questions you may read the
[documentation](https://pwndbg.re/pwndbg/latest/) or asks us in our [Discord server](https://discord.gg/x47DssnGwm).

[CHEATSHEET]: https://pwndbg.re/pwndbg/dev/CHEATSHEET.pdf

## Why?

Vanilla GDB and LLDB are terrible to use for reverse engineering and exploit development.
Typing `x/30gx $rsp` or navigating cumbersome LLDB commands is not fun and often provides
minimal information. The year is 2025, and core debuggers still lack many user-friendly
features such as a robust hexdump command. WinDbg users are completely lost when they
occasionally need to bump into GDB or LLDB.

Pwndbg is a Python module which can be loaded into GDB or run as a REPL interface for LLDB.
It provides a suite of utilities and enhancements that fill the gaps left by these debuggers,
smoothing out rough edges and making them more user-friendly.

## Installation

See [installation instructions](https://pwndbg.re/pwndbg/latest/setup).

## What about ...?

Many past ([gdbinit][gdbinit], [PEDA][PEDA]) and present projects ([GEF][GEF],
[bata24/GEF][bata24/GEF]) offer great features, but are hard to extend and are packaged
as large single files ([103KB][gdbinit2], [195KB][peda.py], [423KB][gef.py],
[4.12MB][bata24/gef.py]). Pwndbg aims to replace them with a faster, cleaner, and
more robust implementation.

[gdbinit]: https://github.com/gdbinit/Gdbinit
[gdbinit2]: https://github.com/gdbinit/Gdbinit/blob/master/gdbinit
[PEDA]: https://github.com/longld/peda
[peda.py]: https://github.com/longld/peda/blob/master/peda.py
[GEF]: https://github.com/hugsy/gef
[gef.py]: https://github.com/hugsy/gef/blob/main/gef.py
[bata24/GEF]: https://github.com/bata24/gef
[bata24/gef.py]: https://github.com/bata24/gef/blob/dev/gef.py

## When to Use GDB or LLDB?

Pwndbg supports both GDB and LLDB, and each debugger has its own strengths.
Here&#039;s a quick guide to help you decide which one to use:

| Use Case                                        | Supported Debugger   |
|-------------------------------------------------|----------------------|
| Debugging Linux binaries or ELF files           | **GDB**, **LLDB**    |
| Debugging Mach-O binaries on macOS              | **LLDB**             |
| Linux kernel debugging (qemu-system)            | **GDB**, **LLDB**    |
| Linux user-space emulation (qemu-user)          | **GDB**              |
| Embedded debugging (ARM Cortex M* or RISC-V/32) | **GDB**, **LLDB**    |

Pwndbg ensures a consistent experience across both, so switching between them is seamless.
&gt; The LLDB implementation in pwndbg is still in early-stage and may contain bugs or limitations.&lt;br/&gt;
&gt; Known issues are tracked in [GitHub Issues][lldb_tracker].
&gt;
&gt; If you encounter any problems, feel free to report them or discuss on our [Discord server](https://discord.gg/x47DssnGwm).

[lldb_tracker]: https://github.com/pwndbg/pwndbg/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22LLDB%20Port%22

### Compatibility Table
| Feature     | Supported Version               | Notes                                |
|-------------|---------------------------------|--------------------------------------|
| pwndbg-gdb  | - Python 3.10+ &lt;br/&gt;- GDB 12.1+ | Battle-tested on Ubuntu 22.04/24.04  |
| pwndbg-lldb | - Python 3.12+ &lt;br/&gt;- LLDB 19+  | Experimental/early-stage support     |
| qemu-user   | QEMU 8.1+                       | vFile API is needed for vmmap        |
| qemu-system | QEMU 6.2+                       | Supported version since ubuntu 22.04 |


## Contributing
Pull requests are welcome ❤️. Check out the [Contributing Guide](https://pwndbg.re/pwndbg/dev/contributing/).

## Acknowledgements
Pwndbg was originally created by [Zach Riggle](https://github.com/zachriggle), who is no longer with us. We want to thank Zach for all of his contributions to pwndbg and the wider security community.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[marketcalls/openalgo]]></title>
            <link>https://github.com/marketcalls/openalgo</link>
            <guid>https://github.com/marketcalls/openalgo</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:19 GMT</pubDate>
            <description><![CDATA[Open Source Algo Trading Platform for Everyone]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/marketcalls/openalgo">marketcalls/openalgo</a></h1>
            <p>Open Source Algo Trading Platform for Everyone</p>
            <p>Language: Python</p>
            <p>Stars: 842</p>
            <p>Forks: 383</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># OpenAlgo - Take Control of Your Algo Platform

&lt;div align=&quot;center&quot;&gt;

[![PyPI Downloads](https://static.pepy.tech/badge/openalgo)](https://pepy.tech/projects/openalgo)
[![PyPI Downloads](https://static.pepy.tech/badge/openalgo/month)](https://pepy.tech/projects/openalgo)
[![X (formerly Twitter) Follow](https://img.shields.io/twitter/follow/openalgoHQ)](https://twitter.com/openalgoHQ)
[![YouTube Channel Subscribers](https://img.shields.io/youtube/channel/subscribers/UCw7eVneIEyiTApy4RtxrJsQ)](https://youtube.com/@openalgoHQ)
[![Discord](https://img.shields.io/discord/1219847221055455263)](https://discord.com/invite/UPh7QPsNhP)

&lt;/div&gt;

![OpenAlgo - Your Personal Algo Trading Platform](static/images/image.png)

OpenAlgo is an open-source, Flask-based Python application designed to bridge the gap between traders and major trading platforms such as Amibroker, Tradingview, Python, Chartink, MetaTrader, Excel, and Google Spreadsheets. With a focus on simplifying algotrading, OpenAlgo facilitates easy integration, automation, and execution of trading strategies, providing a user-friendly interface to enhance trading performance.

## Installation Guide

For detailed installation instructions, please refer to [INSTALL.md](https://docs.openalgo.in/getting-started)

## What is OpenAlgo?
[![What is OpenAlgo](https://img.youtube.com/vi/kAS3jTb3OkI/0.jpg)](https://www.youtube.com/watch?v=kAS3jTb3OkI &quot;Watch the OpenAlgo Tutorial Video&quot;)

## Supported Brokers

- **5paisa**
- **5paisa (XTS)**
- **AliceBlue**
- **AngelOne**
- **Compositedge**
- **Definedge**
- **Dhan**
- **Dhan (Sandbox)**
- **Firstock**
- **Flattrade**
- **Fyers**
- **IBulls**
- **Indmoney**
- **Kotak** 
- **Paytm**
- **Pocketful**
- **Shoonya**
- **Tradejini**
- **Upstox**
- **Wisdom Capital**
- **Zebu**
- **Zerodha**

## Features

### WebSocket Architecture with ZMQ Integration
- **Unified WebSocket Proxy Server**: Central WebSocket server (port 8765) that handles client authentication and subscription management
- **ZeroMQ (ZMQ) Message Bus**: High-performance message queue for real-time market data distribution
  - Publisher-Subscriber pattern for efficient data broadcasting
  - Dynamic port binding with automatic port management
  - Broker adapters publish to ZMQ, proxy server subscribes and routes to clients
- **Broker-Specific Adapters**: Each broker has a dedicated adapter implementing the base WebSocket interface
  - Handles broker-specific WebSocket protocols and data formats
  - Transforms broker data to unified OpenAlgo format
  - Supports multiple subscription modes: LTP (Last Traded Price), Quote, and Market Depth
- **Real-Time Market Data**: Live streaming of market data with support for:
  - LTP updates
  - Full quotes with OHLC data
  - Market depth (5/20/30 levels based on broker support)
  - Auto-reconnection and connection management

### Unified API Layer (`/api/v1/`)
OpenAlgo provides a RESTful API with standardized endpoints across all supported brokers:

#### Order Management APIs
- **`/api/v1/placeorder`**: Place regular orders with standard parameters
- **`/api/v1/placesmartorder`**: Smart order routing with advanced logic
- **`/api/v1/modifyorder`**: Modify existing orders
- **`/api/v1/cancelorder`**: Cancel specific orders
- **`/api/v1/cancelallorder`**: Cancel all pending orders
- **`/api/v1/closeposition`**: Close open positions
- **`/api/v1/basketorder`**: Execute multiple orders in a single request
- **`/api/v1/splitorder`**: Split large orders into smaller chunks

#### Account &amp; Portfolio APIs
- **`/api/v1/funds`**: Get account funds and margins
- **`/api/v1/orderbook`**: Retrieve all orders for the day
- **`/api/v1/tradebook`**: Get executed trades
- **`/api/v1/positionbook`**: View current open positions
- **`/api/v1/holdings`**: Get demat holdings
- **`/api/v1/openposition`**: Check specific position details
- **`/api/v1/orderstatus`**: Get real-time order status

#### Market Data APIs
- **`/api/v1/quotes`**: Get real-time quotes for symbols
- **`/api/v1/history`**: Fetch historical OHLC data
- **`/api/v1/depth`**: Get market depth/order book
- **`/api/v1/ticker`**: Stream real-time price updates

#### Utility APIs
- **`/api/v1/search`**: Search for symbols across exchanges
- **`/api/v1/symbol`**: Get symbol details and mappings
- **`/api/v1/expiry`**: Get option expiry dates
- **`/api/v1/intervals`**: Get supported time intervals for historical data
- **`/api/v1/analyzer`**: Test and analyze API requests without execution
- **`/api/v1/ping`**: Test API connectivity and authentication

### Common Broker Integration Pattern
Each broker integration follows a standardized structure:
- **Authentication API** (`auth_api.py`): Handle login and session management
- **Order API** (`order_api.py`): Place, modify, cancel orders and manage positions
- **Data API** (`data.py`): Fetch quotes, historical data, and market information
- **Funds API** (`funds.py`): Get account balance and margin details
- **Symbol Mapping** (`transform_data.py`): Convert between OpenAlgo and broker formats
- **WebSocket Streaming** (`broker_adapter.py`): Real-time data streaming

- **ChartInk Platform Integration**: 
  - Direct integration with ChartInk for strategy execution
  - Automated scanning and trading based on ChartInk signals
  - Real-time strategy monitoring and management
  - Custom strategy configuration and deployment
  - Seamless execution of ChartInk strategies through your broker

- **Advanced Monitoring Tools**:
  - **Latency Monitor**: Track and analyze order execution performance
    - Real-time latency tracking across different brokers
    - Detailed breakdown of execution times
    - Performance comparison between brokers
    - Order execution success rates and patterns
  - **Traffic Monitor**: Monitor system performance and API usage
    - Real-time API request tracking
    - Endpoint-specific analytics
    - Error rate monitoring
    - System performance metrics
  - **PnL Tracker**: Real-time profit and loss monitoring with advanced charting
    - Intraday PnL curve visualization from 9 AM IST
    - Current MTM, Max MTM with time, Min MTM with time
    - Maximum drawdown tracking
    - Interactive charts powered by TradingView Lightweight Charts
    - Manual refresh control for performance optimization
    - IST timezone support for accurate time display
  For detailed information about monitoring tools, see [traffic.md](docs/traffic.md)

- **Modern UI with DaisyUI**: 
  - Sleek and responsive interface built with DaisyUI components
  - Three distinct themes:
    - Light theme for normal mode
    - Dark theme for reduced eye strain
    - Garden theme for analyzer mode
  - Instant theme switching with state preservation
  - Theme-aware syntax highlighting for code and JSON
  - Mobile-friendly layout with drawer navigation

- **Real-Time Trading Updates**:
  - Instant order book updates via WebSocket
  - Live trade book monitoring with automatic refresh
  - Real-time position tracking
  - Dynamic log updates for trade activities
  - Contextual notifications with sound alerts

- **API Analyzer**:
  - Real-time request validation and testing
  - Strategy testing without live execution
  - Detailed request/response analysis
  - Comprehensive error detection
  - Dedicated garden theme for better focus
  - See [Analyzer.md](docs/Analyzer.md) for detailed documentation

- **Comprehensive Integration**: Seamlessly connect with Amibroker, Tradingview, Excel, and Google Spreadsheets for smooth data and strategy transition.

- **User-Friendly Interface**: A straightforward Flask-based application interface accessible to traders of all levels of expertise.

- **Real-Time Execution**: Implement your trading strategies in real time, ensuring immediate action to capitalize on market opportunities.

- **Customizable Strategies**: Easily adapt and tailor your trading strategies to meet your specific needs, with extensive options for customization and automation.

- **Secure and Reliable**: With a focus on security and reliability, OpenAlgo provides a dependable platform for your algotrading activities, safeguarding your data and trades.

### Rate Limiting Controls
OpenAlgo implements comprehensive rate limiting to protect against abuse and ensure fair usage:

- **Configurable Rate Limits**: All rate limits are environment variable controlled
  - `LOGIN_RATE_LIMIT_MIN`: Login attempts per minute (default: 5 per minute)
  - `LOGIN_RATE_LIMIT_HOUR`: Login attempts per hour (default: 25 per hour)
  - `API_RATE_LIMIT`: General API endpoints (default: 10 per second)
  - `ORDER_RATE_LIMIT`: Order placement/modification/cancellation (default: 10 per second)
  - `SMART_ORDER_RATE_LIMIT`: Smart order operations
  - `WEBHOOK_RATE_LIMIT`: Webhook endpoint limits
  - `STRATEGY_RATE_LIMIT`: Strategy operation limits

- **Moving Window Strategy**: Uses Flask-Limiter with moving-window strategy for accurate rate limiting
- **IP-based Limiting**: Rate limits are applied per IP address
- **Graceful Handling**: Clear error messages when rate limits are exceeded

### Security Features

#### Browser-Level Security
- **Content Security Policy (CSP)**: Configurable CSP headers to prevent XSS attacks
  - Customizable directives via environment variables
  - Default restrictive policies for scripts, styles, and resources
  - WebSocket support for real-time features
- **CORS Protection**: Controlled Cross-Origin Resource Sharing
  - Configurable allowed origins, methods, and headers
  - Supports credentials for authenticated requests
- **CSRF Protection**: Built-in CSRF token validation for state-changing operations
- **Secure Headers**: X-Frame-Options, X-Content-Type-Options, and other security headers
- **Session Security**: Secure session management with proper cookie settings

#### Database-Level Security
- **Password Hashing**: Uses Argon2 (winner of Password Hashing Competition) for secure password storage
- **Token Encryption**: Auth tokens encrypted using Fernet symmetric encryption
  - PBKDF2 key derivation for encryption keys
  - Automatic encryption/decryption of sensitive tokens
- **API Key Security**: 
  - Hashed storage using Argon2 with pepper
  - Encrypted storage for retrieval
  - Time-based caching with TTL
- **SQL Injection Protection**: Uses SQLAlchemy ORM with parameterized queries
- **Connection Pooling**: Optimized database connections with proper pool management

### API Analyzer
The API Analyzer is a comprehensive testing and validation tool that provides:

#### For Traders
- **Risk-Free Testing**: Test all trading operations without actual execution
- **Real-Time Validation**: Instant feedback on order parameters and strategy logic
- **Strategy Monitoring**: Track multiple strategies simultaneously
- **Visual Feedback**: Garden theme UI with instant notifications and sound alerts
- **Cost Savings**: Avoid trading errors and optimize parameters without financial risk

#### For Developers
- **Complete API Testing**: Test all endpoints with detailed request/response analysis
- **Validation Engine**: Automatic parameter validation, symbol checks, and range verification
- **WebSocket Monitoring**: Real-time event tracking and debugging
- **Performance Metrics**: Track API usage, latency, and error rates
- **Debug Tools**: Complete request inspection and error analysis

The analyzer supports all major operations: Place Order, Smart Orders, Modifications, Cancellations, and Position Management. See [Analyzer.md](docs/Analyzer.md) for detailed documentation.

### OpenAlgo FOSS Universe
OpenAlgo is part of a larger ecosystem of open-source trading tools. The Mini FOSS Universe includes:

- **OpenAlgo Core**: Python Flask + Tailwind + DaisyUI (this repository)
- **Historify**: Full Stack Stock Market Data Management Platform
- **Python Library**: Native Python integration for algo trading
- **Node.js Library**: JavaScript/TypeScript support for trading applications
- **Excel Add-in**: Direct Excel integration for strategy development
- **Model Context Protocol**: AI Agents integration for intelligent trading
- **Chrome Plugin**: Browser-based trading tools
- **Fast Scalper**: High-performance trading built with Rust + Tauri
- **Web Portal**: Modern UI built with NextJS + ShadcnUI
- **Documentation**: Comprehensive guides on Gitbook

Built for traders, by traders - making algo trading more accessible, powerful, and open for everyone. Visit [docs.openalgo.in/mini-foss-universe](https://docs.openalgo.in/mini-foss-universe) for more details.

### Local MCP (Model Context Protocol) Integration
OpenAlgo includes native MCP server capabilities, enabling AI assistants to execute trades and manage portfolios directly:

#### Key Features
- **AI-Powered Trading**: Connect AI assistants like Claude Desktop, Cursor, or Windsurf to execute trades
- **Full Trading Capabilities**: 
  - Order Management: Place, modify, cancel orders (market/limit/stop-loss)
  - Smart Orders: Automatic position sizing and basket orders
  - Position Management: Close positions, track P&amp;L
  - Market Data: Real-time quotes, market depth, historical data
- **Multi-Platform Support**: Works with any MCP-compatible AI client
- **Local &amp; Secure**: Runs locally with your OpenAlgo instance

#### Available MCP Tools
- **Order Operations**: `place_order`, `place_smart_order`, `place_basket_order`, `modify_order`, `cancel_order`
- **Position Tracking**: `get_open_position`, `get_position_book`, `close_all_positions`
- **Market Data**: `get_quote`, `get_market_depth`, `get_historical_data`
- **Account Info**: `get_funds`, `get_holdings`, `get_order_book`, `get_trade_book`
- **Instrument Search**: `search_instruments`, `get_symbol_info`, `get_expiry_dates`

#### Quick Setup
1. Start your OpenAlgo server
2. Generate an API key from Settings → API Keys
3. Configure your AI assistant with the MCP server path and API key
4. Start trading with natural language commands like &quot;Buy 100 shares of RELIANCE&quot;

For detailed MCP setup instructions, see [mcp/README.md](mcp/README.md)

## Documentation

For detailed documentation on OpenAlgo, including setup guides, API references, and usage examples, refer to [https://docs.openalgo.in](https://docs.openalgo.in)

### Minimum Hardware Requirements

To run OpenAlgo we recommend:
- 2GB RAM or 0.5GB RAM with 2GB of Swap Memory
- 1GB disk space
- 1vCPU

## Contributing

We welcome contributions to OpenAlgo! If you&#039;re interested in improving the application or adding new features, please feel free to fork the repository, make your changes, and submit a pull request.

## License

OpenAlgo is released under the AGPL V3.0 License. See the `LICENSE` file for more details.

## Repo Activity

![Alt](https://repobeats.axiom.co/api/embed/0b6b18194a3089cb47ab8ae588caabb14aa9972b.svg &quot;Repobeats analytics image&quot;)

## Disclaimer

This software is for educational purposes only. Do not risk money which
you are afraid to lose. USE THE SOFTWARE AT YOUR OWN RISK. THE AUTHORS
AND ALL AFFILIATES ASSUME NO RESPONSIBILITY FOR YOUR TRADING RESULTS.

## Credits and Acknowledgements

### Third-Party Libraries

- **[DaisyUI](https://github.com/saadeghi/daisyui)** - The most popular component library for Tailwind CSS
  - License: MIT
  - Version: 4.12.21
  - Used for modern, responsive UI components throughout the application
  - Provides theming system (Light, Dark, Garden themes)
  - Powers the entire user interface design

- **[TradingView Lightweight Charts](https://github.com/tradingview/lightweight-charts)** - Advanced financial charting library
  - License: Apache 2.0
  - Version: 5.0.8
  - Used for interactive intraday PnL and drawdown visualization in PnL Tracker

## Support

For any questions not covered by the documentation or for further information about OpenAlgo, join our [Discord server](https://discord.com/invite/UPh7QPsNhP).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[microsoft/agent-framework]]></title>
            <link>https://github.com/microsoft/agent-framework</link>
            <guid>https://github.com/microsoft/agent-framework</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:18 GMT</pubDate>
            <description><![CDATA[A framework for building, orchestrating and deploying AI agents and multi-agent workflows with support for Python and .NET.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/agent-framework">microsoft/agent-framework</a></h1>
            <p>A framework for building, orchestrating and deploying AI agents and multi-agent workflows with support for Python and .NET.</p>
            <p>Language: Python</p>
            <p>Stars: 2,486</p>
            <p>Forks: 267</p>
            <p>Stars today: 352 stars today</p>
            <h2>README</h2><pre>![Microsoft Agent Framework](docs/assets/readme-banner.png)

# Welcome to Microsoft Agent Framework!

[![Microsoft Azure AI Foundry Discord](https://dcbadge.limes.pink/api/server/b5zjErwbQM?style=flat)](https://discord.gg/b5zjErwbQM)
[![MS Learn Documentation](https://img.shields.io/badge/MS%20Learn-Documentation-blue)](https://learn.microsoft.com/en-us/agent-framework/)
[![PyPI](https://img.shields.io/pypi/v/agent-framework)](https://pypi.org/project/agent-framework/)
[![NuGet](https://img.shields.io/nuget/v/Microsoft.Agents.AI)](https://www.nuget.org/profiles/MicrosoftAgentFramework/)

Welcome to Microsoft&#039;s comprehensive multi-language framework for building, orchestrating, and deploying AI agents with support for both .NET and Python implementations. This framework provides everything from simple chat agents to complex multi-agent workflows with graph-based orchestration.

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.youtube.com/watch?v=AAgdMhftj8w&quot; title=&quot;Watch the full Agent Framework introduction (30 min)&quot;&gt;
    &lt;img src=&quot;https://img.youtube.com/vi/AAgdMhftj8w/hqdefault.jpg&quot;
         alt=&quot;Watch the full Agent Framework introduction (30 min)&quot; width=&quot;480&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.youtube.com/watch?v=AAgdMhftj8w&quot;&gt;
    Watch the full Agent Framework introduction (30 min)
  &lt;/a&gt;
&lt;/p&gt;

## 📋 Getting Started

### 📦 Installation

Python

```bash
pip install agent-framework --pre
# This will install all sub-packages, see `python/packages` for individual packages.
# It may take a minute on first install on Windows.
```

.NET

```bash
dotnet add package Microsoft.Agents.AI
```

### 📚 Documentation

- **[Overview](https://learn.microsoft.com/agent-framework/overview/agent-framework-overview)** - High level overview of the framework
- **[Quick Start](https://learn.microsoft.com/agent-framework/tutorials/quick-start)** - Get started with a simple agent
- **[Tutorials](https://learn.microsoft.com/agent-framework/tutorials/overview)** - Step by step tutorials
- **[User Guide](https://learn.microsoft.com/en-us/agent-framework/user-guide/overview)** - In-depth user guide for building agents and workflows
- **[Migration from Semantic Kernel](https://learn.microsoft.com/en-us/agent-framework/migration-guide/from-semantic-kernel)** - Guide to migrate from Semantic Kernel
- **[Migration from AutoGen](https://learn.microsoft.com/en-us/agent-framework/migration-guide/from-autogen)** - Guide to migrate from AutoGen

### ✨ **Highlights**

- **Graph-based Workflows**: Connect agents and deterministic functions using data flows with streaming, checkpointing, human-in-the-loop, and time-travel capabilities
  - [Python workflows](./python/samples/getting_started/workflows/) | [.NET workflows](./dotnet/samples/GettingStarted/Workflows/)
- **AF Labs**: Experimental packages for cutting-edge features including benchmarking, reinforcement learning, and research initiatives
  - [Labs directory](./python/packages/lab/)
- **DevUI**: Interactive developer UI for agent development, testing, and debugging workflows
  - [DevUI package](./python/packages/devui/)

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.youtube.com/watch?v=mOAaGY4WPvc&quot;&gt;
    &lt;img src=&quot;https://img.youtube.com/vi/mOAaGY4WPvc/hqdefault.jpg&quot; alt=&quot;See the DevUI in action&quot; width=&quot;480&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.youtube.com/watch?v=mOAaGY4WPvc&quot;&gt;
    See the DevUI in action (1 min)
  &lt;/a&gt;
&lt;/p&gt;

- **Python and C#/.NET Support**: Full framework support for both Python and C#/.NET implementations with consistent APIs
  - [Python packages](./python/packages/) | [.NET source](./dotnet/src/)
- **Observability**: Built-in OpenTelemetry integration for distributed tracing, monitoring, and debugging
  - [Python observability](./python/samples/getting_started/observability/) | [.NET telemetry](./dotnet/samples/GettingStarted/AgentOpenTelemetry/)
- **Multiple Agent Provider Support**: Support for various LLM providers with more being added continuously
  - [Python examples](./python/samples/getting_started/agents/) | [.NET examples](./dotnet/samples/GettingStarted/AgentProviders/)
- **Middleware**: Flexible middleware system for request/response processing, exception handling, and custom pipelines
  - [Python middleware](./python/samples/getting_started/middleware/) | [.NET middleware](./dotnet/samples/GettingStarted/Agents/Agent_Step14_Middleware/)

### 💬 **We want your feedback!**

- For bugs, please file a [GitHub issue](https://github.com/microsoft/agent-framework/issues).

## Quickstart

### Basic Agent - Python

Create a simple Azure Responses Agent that writes a haiku about the Microsoft Agent Framework

```python
# pip install agent-framework --pre
# Use `az login` to authenticate with Azure CLI
import os
import asyncio
from agent_framework.azure import AzureOpenAIResponsesClient
from azure.identity import AzureCliCredential


async def main():
    # Initialize a chat agent with Azure OpenAI Responses
    # the endpoint, deployment name, and api version can be set via environment variables
    # or they can be passed in directly to the AzureOpenAIResponsesClient constructor
    agent = AzureOpenAIResponsesClient(
        # endpoint=os.environ[&quot;AZURE_OPENAI_ENDPOINT&quot;],
        # deployment_name=os.environ[&quot;AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME&quot;],
        # api_version=os.environ[&quot;AZURE_OPENAI_API_VERSION&quot;],
        # api_key=os.environ[&quot;AZURE_OPENAI_API_KEY&quot;],  # Optional if using AzureCliCredential
        credential=AzureCliCredential(), # Optional, if using api_key
    ).create_agent(
        name=&quot;HaikuBot&quot;,
        instructions=&quot;You are an upbeat assistant that writes beautifully.&quot;,
    )

    print(await agent.run(&quot;Write a haiku about Microsoft Agent Framework.&quot;))

if __name__ == &quot;__main__&quot;:
    asyncio.run(main())
```

### Basic Agent - .NET

```c#
// dotnet add package Microsoft.Agents.AI.OpenAI --prerelease
// dotnet add package Azure.AI.OpenAI
// dotnet add package Azure.Identity
// Use `az login` to authenticate with Azure CLI
using System;
using Azure.AI.OpenAI;
using Azure.Identity;
using Microsoft.Agents.AI;
using OpenAI;

var endpoint = Environment.GetEnvironmentVariable(&quot;AZURE_OPENAI_ENDPOINT&quot;)!;
var deploymentName = Environment.GetEnvironmentVariable(&quot;AZURE_OPENAI_DEPLOYMENT_NAME&quot;)!;

var agent = new AzureOpenAIClient(new Uri(endpoint), new AzureCliCredential())
    .GetOpenAIResponseClient(deploymentName)
    .CreateAIAgent(name: &quot;HaikuBot&quot;, instructions: &quot;You are an upbeat assistant that writes beautifully.&quot;);

Console.WriteLine(await agent.RunAsync(&quot;Write a haiku about Microsoft Agent Framework.&quot;));
```

## More Examples &amp; Samples

### Python

- [Getting Started with Agents](./python/samples/getting_started/agents): basic agent creation and tool usage
- [Chat Client Examples](./python/samples/getting_started/chat_client): direct chat client usage patterns
- [Getting Started with Workflows](./python/samples/getting_started/workflows): basic workflow creation and integration with agents

### .NET

- [Getting Started with Agents](./dotnet/samples/GettingStarted/Agents): basic agent creation and tool usage
- [Agent Provider Samples](./dotnet/samples/GettingStarted/AgentProviders): samples showing different agent providers
- [Workflow Samples](./dotnet/samples/GettingStarted/Workflows): advanced multi-agent patterns and workflow orchestration

## Contributor Resources

- [Contributing Guide](./CONTRIBUTING.md)
- [Python Development Guide](./python/DEV_SETUP.md)
- [Design Documents](./docs/design)
- [Architectural Decision Records](./docs/decisions)

## Important Notes

If you use the Microsoft Agent Framework to build applications that operate with third-party servers or agents, you do so at your own risk. We recommend reviewing all data being shared with third-party servers or agents and being cognizant of third-party practices for retention and location of data. It is your responsibility to manage whether your data will flow outside of your organization&#039;s Azure compliance and geographic boundaries and any related implications.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[iam-veeramalla/Jenkins-Zero-To-Hero]]></title>
            <link>https://github.com/iam-veeramalla/Jenkins-Zero-To-Hero</link>
            <guid>https://github.com/iam-veeramalla/Jenkins-Zero-To-Hero</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:17 GMT</pubDate>
            <description><![CDATA[Install Jenkins, configure Docker as slave, set up cicd, deploy applications to k8s using Argo CD in GitOps way.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/iam-veeramalla/Jenkins-Zero-To-Hero">iam-veeramalla/Jenkins-Zero-To-Hero</a></h1>
            <p>Install Jenkins, configure Docker as slave, set up cicd, deploy applications to k8s using Argo CD in GitOps way.</p>
            <p>Language: Python</p>
            <p>Stars: 8,797</p>
            <p>Forks: 17,094</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># Jenkins-Zero-To-Hero

Are you looking forward to learn Jenkins right from Zero(installation) to Hero(Build end to end pipelines)? then you are at the right place. 

## Installation on EC2 Instance

YouTube Video -&gt;
https://www.youtube.com/watch?v=zZfhAXfBvVA&amp;list=RDCMUCnnQ3ybuyFdzvgv2Ky5jnAA&amp;index=1


![Screenshot 2023-02-01 at 5 46 14 PM](https://user-images.githubusercontent.com/43399466/216040281-6c8b89c3-8c22-4620-ad1c-8edd78eb31ae.png)

Install Jenkins, configure Docker as agent, set up cicd, deploy applications to k8s and much more.

## AWS EC2 Instance

- Go to AWS Console
- Instances(running)
- Launch instances

&lt;img width=&quot;994&quot; alt=&quot;Screenshot 2023-02-01 at 12 37 45 PM&quot; src=&quot;https://user-images.githubusercontent.com/43399466/215974891-196abfe9-ace0-407b-abd2-adcffe218e3f.png&quot;&gt;

### Install Jenkins.

Pre-Requisites:
 - Java (JDK)

### Run the below commands to install Java and Jenkins

Install Java

```
sudo apt update
sudo apt install openjdk-17-jre
```

Verify Java is Installed

```
java -version
```

Now, you can proceed with installing Jenkins

```
curl -fsSL https://pkg.jenkins.io/debian/jenkins.io-2023.key | sudo tee \
  /usr/share/keyrings/jenkins-keyring.asc &gt; /dev/null
echo deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] \
  https://pkg.jenkins.io/debian binary/ | sudo tee \
  /etc/apt/sources.list.d/jenkins.list &gt; /dev/null
sudo apt-get update
sudo apt-get install jenkins
```

**Note: ** By default, Jenkins will not be accessible to the external world due to the inbound traffic restriction by AWS. Open port 8080 in the inbound traffic rules as show below.

- EC2 &gt; Instances &gt; Click on &lt;Instance-ID&gt;
- In the bottom tabs -&gt; Click on Security
- Security groups
- Add inbound traffic rules as shown in the image (you can just allow TCP 8080 as well, in my case, I allowed `All traffic`).

&lt;img width=&quot;1187&quot; alt=&quot;Screenshot 2023-02-01 at 12 42 01 PM&quot; src=&quot;https://user-images.githubusercontent.com/43399466/215975712-2fc569cb-9d76-49b4-9345-d8b62187aa22.png&quot;&gt;


### Login to Jenkins using the below URL:

http://&lt;ec2-instance-public-ip-address&gt;:8080    [You can get the ec2-instance-public-ip-address from your AWS EC2 console page]

Note: If you are not interested in allowing `All Traffic` to your EC2 instance
      1. Delete the inbound traffic rule for your instance
      2. Edit the inbound traffic rule to only allow custom TCP port `8080`
  
After you login to Jenkins, 
      - Run the command to copy the Jenkins Admin Password - `sudo cat /var/lib/jenkins/secrets/initialAdminPassword`
      - Enter the Administrator password
      
&lt;img width=&quot;1291&quot; alt=&quot;Screenshot 2023-02-01 at 10 56 25 AM&quot; src=&quot;https://user-images.githubusercontent.com/43399466/215959008-3ebca431-1f14-4d81-9f12-6bb232bfbee3.png&quot;&gt;

### Click on Install suggested plugins

&lt;img width=&quot;1291&quot; alt=&quot;Screenshot 2023-02-01 at 10 58 40 AM&quot; src=&quot;https://user-images.githubusercontent.com/43399466/215959294-047eadef-7e64-4795-bd3b-b1efb0375988.png&quot;&gt;

Wait for the Jenkins to Install suggested plugins

&lt;img width=&quot;1291&quot; alt=&quot;Screenshot 2023-02-01 at 10 59 31 AM&quot; src=&quot;https://user-images.githubusercontent.com/43399466/215959398-344b5721-28ec-47a5-8908-b698e435608d.png&quot;&gt;

Create First Admin User or Skip the step [If you want to use this Jenkins instance for future use-cases as well, better to create admin user]

&lt;img width=&quot;990&quot; alt=&quot;Screenshot 2023-02-01 at 11 02 09 AM&quot; src=&quot;https://user-images.githubusercontent.com/43399466/215959757-403246c8-e739-4103-9265-6bdab418013e.png&quot;&gt;

Jenkins Installation is Successful. You can now starting using the Jenkins 

&lt;img width=&quot;990&quot; alt=&quot;Screenshot 2023-02-01 at 11 14 13 AM&quot; src=&quot;https://user-images.githubusercontent.com/43399466/215961440-3f13f82b-61a2-4117-88bc-0da265a67fa7.png&quot;&gt;

## Install the Docker Pipeline plugin in Jenkins:

   - Log in to Jenkins.
   - Go to Manage Jenkins &gt; Manage Plugins.
   - In the Available tab, search for &quot;Docker Pipeline&quot;.
   - Select the plugin and click the Install button.
   - Restart Jenkins after the plugin is installed.
   
&lt;img width=&quot;1392&quot; alt=&quot;Screenshot 2023-02-01 at 12 17 02 PM&quot; src=&quot;https://user-images.githubusercontent.com/43399466/215973898-7c366525-15db-4876-bd71-49522ecb267d.png&quot;&gt;

Wait for the Jenkins to be restarted.


## Docker Slave Configuration

Run the below command to Install Docker

```
sudo apt update
sudo apt install docker.io
```
 
### Grant Jenkins user and Ubuntu user permission to docker deamon.

```
sudo su - 
usermod -aG docker jenkins
usermod -aG docker ubuntu
systemctl restart docker
```

Once you are done with the above steps, it is better to restart Jenkins.

```
http://&lt;ec2-instance-public-ip&gt;:8080/restart
```

The docker agent configuration is now successful.




</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[jiji262/douyin-downloader]]></title>
            <link>https://github.com/jiji262/douyin-downloader</link>
            <guid>https://github.com/jiji262/douyin-downloader</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:16 GMT</pubDate>
            <description><![CDATA[抖音批量下载工具，去水印，支持视频、图集、合集、音乐(原声)。免费！免费！免费！]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jiji262/douyin-downloader">jiji262/douyin-downloader</a></h1>
            <p>抖音批量下载工具，去水印，支持视频、图集、合集、音乐(原声)。免费！免费！免费！</p>
            <p>Language: Python</p>
            <p>Stars: 5,064</p>
            <p>Forks: 747</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre># 抖音下载器 - 无水印批量下载工具

![douyin-downloader](https://socialify.git.ci/jiji262/douyin-downloader/image?custom_description=%E6%8A%96%E9%9F%B3%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD%E5%B7%A5%E5%85%B7%EF%BC%8C%E5%8E%BB%E6%B0%B4%E5%8D%B0%EF%BC%8C%E6%94%AF%E6%8C%81%E8%A7%86%E9%A2%91%E3%80%81%E5%9B%BE%E9%9B%86%E3%80%81%E5%90%88%E9%9B%86%E3%80%81%E9%9F%B3%E4%B9%90%28%E5%8E%9F%E5%A3%B0%29%E3%80%82%0A%E5%85%8D%E8%B4%B9%EF%BC%81%E5%85%8D%E8%B4%B9%EF%BC%81%E5%85%8D%E8%B4%B9%EF%BC%81&amp;description=1&amp;font=Jost&amp;forks=1&amp;logo=https%3A%2F%2Fraw.githubusercontent.com%2Fjiji262%2Fdouyin-downloader%2Frefs%2Fheads%2Fmain%2Fimg%2Flogo.png&amp;name=1&amp;owner=1&amp;pattern=Circuit+Board&amp;pulls=1&amp;stargazers=1&amp;theme=Light)

一个功能强大的抖音内容批量下载工具，支持视频、图集、音乐、直播等多种内容类型的下载。提供两个版本：V1.0（稳定版）和 V2.0（增强版）。

## 📋 目录

- [快速开始](#-快速开始)
- [版本说明](#-版本说明)
- [V1.0 使用指南](#-v10-使用指南)
- [V2.0 使用指南](#-v20-使用指南)
- [Cookie 配置工具](#-cookie-配置工具)
- [支持的链接类型](#-支持的链接类型)
- [常见问题](#-常见问题)
- [更新日志](#-更新日志)

## ⚡ 快速开始

![qun](./img/fuye.jpg)

### 环境要求

- **Python 3.9+**
- **操作系统**：Windows、macOS、Linux

### 安装步骤

1. **克隆项目**
```bash
git clone https://github.com/jiji262/douyin-downloader.git
cd douyin-downloader
```

2. **安装依赖**
```bash
pip install -r requirements.txt
```

3. **配置 Cookie**（首次使用需要）
```bash
# 方式1：自动获取（推荐）
python cookie_extractor.py

# 方式2：手动获取
python get_cookies_manual.py
```

## 📦 版本说明

### V1.0 (DouYinCommand.py) - 稳定版
- ✅ **经过验证**：稳定可靠，经过大量测试
- ✅ **简单易用**：配置文件驱动，使用简单
- ✅ **功能完整**：支持所有内容类型下载
- ✅ **单个视频下载**：完全正常工作
- ⚠️ **需要手动配置**：需要手动获取和配置 Cookie

### V2.0 (downloader.py) - 增强版
- 🚀 **自动 Cookie 管理**：支持自动获取和刷新 Cookie
- 🚀 **统一入口**：整合所有功能到单一脚本
- 🚀 **异步架构**：性能更优，支持并发下载
- 🚀 **智能重试**：自动重试和错误恢复
- 🚀 **增量下载**：支持增量更新，避免重复下载
- ⚠️ **单个视频下载**：目前 API 返回空响应（已知问题）
- ✅ **用户主页下载**：完全正常工作

## 🎯 V1.0 使用指南

### 配置文件设置

1. **编辑配置文件**
```bash
cp config.example.yml config.yml
# 编辑 config.yml 文件
```

2. **配置示例**
```yaml
# 下载链接
link:
  - https://v.douyin.com/xxxxx/                    # 单个视频
  - https://www.douyin.com/user/xxxxx              # 用户主页
  - https://www.douyin.com/collection/xxxxx        # 合集

# 保存路径
path: ./Downloaded/

# Cookie配置（必填）
cookies:
  msToken: YOUR_MS_TOKEN_HERE
  ttwid: YOUR_TTWID_HERE
  odin_tt: YOUR_ODIN_TT_HERE
  passport_csrf_token: YOUR_PASSPORT_CSRF_TOKEN_HERE
  sid_guard: YOUR_SID_GUARD_HERE

# 下载选项
music: True    # 下载音乐
cover: True    # 下载封面
avatar: True   # 下载头像
json: True     # 保存JSON数据

# 下载模式
mode:
  - post       # 下载发布的作品
  # - like     # 下载喜欢的作品
  # - mix      # 下载合集

# 下载数量（0表示全部）
number:
  post: 0      # 发布作品数量
  like: 0      # 喜欢作品数量
  allmix: 0    # 合集数量
  mix: 0       # 单个合集内作品数量

# 其他设置
thread: 5      # 下载线程数
database: True # 使用数据库记录
```

### 运行程序

```bash
# 使用配置文件运行
python DouYinCommand.py

# 或者使用命令行参数
python DouYinCommand.py --cmd False
```

### 使用示例

```bash
# 下载单个视频
# 在 config.yml 中设置 link 为单个视频链接
python DouYinCommand.py

# 下载用户主页
# 在 config.yml 中设置 link 为用户主页链接
python DouYinCommand.py

# 下载合集
# 在 config.yml 中设置 link 为合集链接
python DouYinCommand.py
```

## 🚀 V2.0 使用指南

### 命令行使用

```bash
# 下载单个视频（需要先配置 Cookie）
python downloader.py -u &quot;https://v.douyin.com/xxxxx/&quot;

# 下载用户主页（推荐）
python downloader.py -u &quot;https://www.douyin.com/user/xxxxx&quot;

# 自动获取 Cookie 并下载
python downloader.py --auto-cookie -u &quot;https://www.douyin.com/user/xxxxx&quot;

# 指定保存路径
python downloader.py -u &quot;链接&quot; --path &quot;./my_videos/&quot;

# 使用配置文件
python downloader.py --config
```

### 配置文件使用

1. **创建配置文件**
```bash
cp config.example.yml config_simple.yml
```

2. **配置示例**
```yaml
# 下载链接
link:
  - https://www.douyin.com/user/xxxxx

# 保存路径
path: ./Downloaded/

# 自动 Cookie 管理
auto_cookie: true

# 下载选项
music: true
cover: true
avatar: true
json: true

# 下载模式
mode:
  - post

# 下载数量
number:
  post: 10

# 增量下载
increase:
  post: false

# 数据库
database: true
```

3. **运行程序**
```bash
python downloader.py --config
```

### 命令行参数

```bash
python downloader.py [选项] [链接...]

选项：
  -u, --url URL          下载链接
  -p, --path PATH        保存路径
  -c, --config           使用配置文件
  --auto-cookie          自动获取 Cookie
  --cookies COOKIES      手动指定 Cookie
  -h, --help            显示帮助信息
```

## 🍪 Cookie 配置工具

### 1. cookie_extractor.py - 自动获取工具

**功能**：使用 Playwright 自动打开浏览器，自动获取 Cookie

**使用方式**：
```bash
# 安装 Playwright
pip install playwright
playwright install chromium

# 运行自动获取
python cookie_extractor.py
```

**特点**：
- ✅ 自动打开浏览器
- ✅ 支持扫码登录
- ✅ 自动检测登录状态
- ✅ 自动保存到配置文件
- ✅ 支持多种登录方式

**使用步骤**：
1. 运行 `python cookie_extractor.py`
2. 选择提取方式（推荐选择1）
3. 在打开的浏览器中完成登录
4. 程序自动提取并保存 Cookie

### 2. get_cookies_manual.py - 手动获取工具

**功能**：通过浏览器开发者工具手动获取 Cookie

**使用方式**：
```bash
python get_cookies_manual.py
```

**特点**：
- ✅ 无需安装 Playwright
- ✅ 详细的操作教程
- ✅ 支持 Cookie 验证
- ✅ 自动保存到配置文件
- ✅ 支持备份和恢复

**使用步骤**：
1. 运行 `python get_cookies_manual.py`
2. 选择&quot;获取新的Cookie&quot;
3. 按照教程在浏览器中获取 Cookie
4. 粘贴 Cookie 内容
5. 程序自动解析并保存

### Cookie 获取教程

#### 方法一：浏览器开发者工具

1. 打开浏览器，访问 [抖音网页版](https://www.douyin.com)
2. 登录你的抖音账号
3. 按 `F12` 打开开发者工具
4. 切换到 `Network` 标签页
5. 刷新页面，找到任意请求
6. 在请求头中找到 `Cookie` 字段
7. 复制以下关键 cookie 值：
   - `msToken`
   - `ttwid`
   - `odin_tt`
   - `passport_csrf_token`
   - `sid_guard`

#### 方法二：使用自动工具

```bash
# 推荐使用自动工具
python cookie_extractor.py
```

## 📋 支持的链接类型

### 🎬 视频内容
- **单个视频分享链接**：`https://v.douyin.com/xxxxx/`
- **单个视频直链**：`https://www.douyin.com/video/xxxxx`
- **图集作品**：`https://www.douyin.com/note/xxxxx`

### 👤 用户内容
- **用户主页**：`https://www.douyin.com/user/xxxxx`
  - 支持下载用户发布的所有作品
  - 支持下载用户喜欢的作品（需要权限）

### 📚 合集内容
- **用户合集**：`https://www.douyin.com/collection/xxxxx`
- **音乐合集**：`https://www.douyin.com/music/xxxxx`

### 🔴 直播内容
- **直播间**：`https://live.douyin.com/xxxxx`

## 🔧 常见问题

### Q: 为什么单个视频下载失败？
**A**: 
- V1.0：请检查 Cookie 是否有效，确保包含必要的字段
- V2.0：目前已知问题，API 返回空响应，建议使用用户主页下载

### Q: Cookie 过期怎么办？
**A**: 
- 使用 `python cookie_extractor.py` 重新获取
- 或使用 `python get_cookies_manual.py` 手动获取

### Q: 下载速度慢怎么办？
**A**: 
- 调整 `thread` 参数增加并发数
- 检查网络连接
- 避免同时下载过多内容

### Q: 如何批量下载？
**A**: 
- V1.0：在 `config.yml` 中添加多个链接
- V2.0：使用命令行传入多个链接或使用配置文件

### Q: 支持哪些格式？
**A**: 
- 视频：MP4 格式（无水印）
- 图片：JPG 格式
- 音频：MP3 格式
- 数据：JSON 格式

## 📝 更新日志

### V2.0 (2025-08)
- ✅ **统一入口**：整合所有功能到 `downloader.py`
- ✅ **自动 Cookie 管理**：支持自动获取和刷新
- ✅ **异步架构**：性能优化，支持并发下载
- ✅ **智能重试**：自动重试和错误恢复
- ✅ **增量下载**：支持增量更新
- ✅ **用户主页下载**：完全正常工作
- ⚠️ **单个视频下载**：API 返回空响应（已知问题）

### V1.0 (2024-12)
- ✅ **稳定可靠**：经过大量测试验证
- ✅ **功能完整**：支持所有内容类型
- ✅ **单个视频下载**：完全正常工作
- ✅ **配置文件驱动**：简单易用
- ✅ **数据库支持**：记录下载历史

## ⚖️ 法律声明

- 本项目仅供**学习交流**使用
- 请遵守相关法律法规和平台服务条款
- 不得用于商业用途或侵犯他人权益
- 下载内容请尊重原作者版权

## 🤝 贡献指南

欢迎提交 Issue 和 Pull Request！

### 报告问题
- 使用 [Issues](https://github.com/jiji262/douyin-downloader/issues) 报告 bug
- 请提供详细的错误信息和复现步骤

### 功能建议
- 在 Issues 中提出新功能建议
- 详细描述功能需求和使用场景

## 📄 许可证

本项目采用 [MIT License](LICENSE) 开源许可证。

---

&lt;div align=&quot;center&quot;&gt;

**如果这个项目对你有帮助，请给个 ⭐ Star 支持一下！**

[🐛 报告问题](https://github.com/jiji262/douyin-downloader/issues) • [💡 功能建议](https://github.com/jiji262/douyin-downloader/issues) • [📖 查看文档](https://github.com/jiji262/douyin-downloader/wiki)

Made with ❤️ by [jiji262](https://github.com/jiji262)

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[pydantic/pydantic-ai]]></title>
            <link>https://github.com/pydantic/pydantic-ai</link>
            <guid>https://github.com/pydantic/pydantic-ai</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:15 GMT</pubDate>
            <description><![CDATA[GenAI Agent Framework, the Pydantic way]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pydantic/pydantic-ai">pydantic/pydantic-ai</a></h1>
            <p>GenAI Agent Framework, the Pydantic way</p>
            <p>Language: Python</p>
            <p>Stars: 12,781</p>
            <p>Forks: 1,282</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://ai.pydantic.dev/&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://ai.pydantic.dev/img/pydantic-ai-dark.svg&quot;&gt;
      &lt;img src=&quot;https://ai.pydantic.dev/img/pydantic-ai-light.svg&quot; alt=&quot;Pydantic AI&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;h3&gt;GenAI Agent Framework, the Pydantic way&lt;/h3&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/pydantic/pydantic-ai/actions/workflows/ci.yml?query=branch%3Amain&quot;&gt;&lt;img src=&quot;https://github.com/pydantic/pydantic-ai/actions/workflows/ci.yml/badge.svg?event=push&quot; alt=&quot;CI&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://coverage-badge.samuelcolvin.workers.dev/redirect/pydantic/pydantic-ai&quot;&gt;&lt;img src=&quot;https://coverage-badge.samuelcolvin.workers.dev/pydantic/pydantic-ai.svg&quot; alt=&quot;Coverage&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://pypi.python.org/pypi/pydantic-ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/pydantic-ai.svg&quot; alt=&quot;PyPI&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/pydantic/pydantic-ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/pyversions/pydantic-ai.svg&quot; alt=&quot;versions&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/pydantic/pydantic-ai/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/pydantic/pydantic-ai.svg?v&quot; alt=&quot;license&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://logfire.pydantic.dev/docs/join-slack/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Slack-Join%20Slack-4A154B?logo=slack&quot; alt=&quot;Join Slack&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;

---

**Documentation**: [ai.pydantic.dev](https://ai.pydantic.dev/)

---

### &lt;em&gt;Pydantic AI is a Python agent framework designed to help you quickly, confidently, and painlessly build production grade applications and workflows with Generative AI.&lt;/em&gt;


FastAPI revolutionized web development by offering an innovative and ergonomic design, built on the foundation of [Pydantic Validation](https://docs.pydantic.dev) and modern Python features like type hints.

Yet despite virtually every Python agent framework and LLM library using Pydantic Validation, when we began to use LLMs in [Pydantic Logfire](https://pydantic.dev/logfire), we couldn&#039;t find anything that gave us the same feeling.

We built Pydantic AI with one simple aim: to bring that FastAPI feeling to GenAI app and agent development.

## Why use Pydantic AI

1. **Built by the Pydantic Team**:
[Pydantic Validation](https://docs.pydantic.dev/latest/) is the validation layer of the OpenAI SDK, the Google ADK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers, CrewAI, Instructor and many more. _Why use the derivative when you can go straight to the source?_ :smiley:

2. **Model-agnostic**:
Supports virtually every [model](https://ai.pydantic.dev/models/overview) and provider: OpenAI, Anthropic, Gemini, DeepSeek, Grok, Cohere, Mistral, and Perplexity; Azure AI Foundry, Amazon Bedrock, Google Vertex AI, Ollama, LiteLLM, Groq, OpenRouter, Together AI, Fireworks AI, Cerebras, Hugging Face, GitHub, Heroku, Vercel. If your favorite model or provider is not listed, you can easily implement a [custom model](https://ai.pydantic.dev/models/overview#custom-models).

3. **Seamless Observability**:
Tightly [integrates](https://ai.pydantic.dev/logfire) with [Pydantic Logfire](https://pydantic.dev/logfire), our general-purpose OpenTelemetry observability platform, for real-time debugging, evals-based performance monitoring, and behavior, tracing, and cost tracking. If you already have an observability platform that supports OTel, you can [use that too](https://ai.pydantic.dev/logfire#alternative-observability-backends).

4. **Fully Type-safe**:
Designed to give your IDE or AI coding agent as much context as possible for auto-completion and [type checking](https://ai.pydantic.dev/agents#static-type-checking), moving entire classes of errors from runtime to write-time for a bit of that Rust &quot;if it compiles, it works&quot; feel.

5. **Powerful Evals**:
Enables you to systematically test and [evaluate](https://ai.pydantic.dev/evals) the performance and accuracy of the agentic systems you build, and monitor the performance over time in Pydantic Logfire.

6. **MCP, A2A, and AG-UI**:
Integrates the [Model Context Protocol](https://ai.pydantic.dev/mcp/client), [Agent2Agent](https://ai.pydantic.dev/a2a), and [AG-UI](https://ai.pydantic.dev/ag-ui) standards to give your agent access to external tools and data, let it interoperate with other agents, and build interactive applications with streaming event-based communication.

7. **Human-in-the-Loop Tool Approval**:
Easily lets you flag that certain tool calls [require approval](https://ai.pydantic.dev/deferred-tools#human-in-the-loop-tool-approval) before they can proceed, possibly depending on tool call arguments, conversation history, or user preferences.

8. **Durable Execution**:
Enables you to build [durable agents](https://ai.pydantic.dev/durable_execution/overview/) that can preserve their progress across transient API failures and application errors or restarts, and handle long-running, asynchronous, and human-in-the-loop workflows with production-grade reliability.

9. **Streamed Outputs**:
Provides the ability to [stream](https://ai.pydantic.dev/output#streamed-results) structured output continuously, with immediate validation, ensuring real time access to generated data.

10. **Graph Support**:
Provides a powerful way to define [graphs](https://ai.pydantic.dev/graph) using type hints, for use in complex applications where standard control flow can degrade to spaghetti code.

Realistically though, no list is going to be as convincing as [giving it a try](#next-steps) and seeing how it makes you feel!

## Hello World Example

Here&#039;s a minimal example of Pydantic AI:

```python
from pydantic_ai import Agent

# Define a very simple agent including the model to use, you can also set the model when running the agent.
agent = Agent(
    &#039;anthropic:claude-sonnet-4-0&#039;,
    # Register static instructions using a keyword argument to the agent.
    # For more complex dynamically-generated instructions, see the example below.
    instructions=&#039;Be concise, reply with one sentence.&#039;,
)

# Run the agent synchronously, conducting a conversation with the LLM.
result = agent.run_sync(&#039;Where does &quot;hello world&quot; come from?&#039;)
print(result.output)
&quot;&quot;&quot;
The first known use of &quot;hello, world&quot; was in a 1974 textbook about the C programming language.
&quot;&quot;&quot;
```

_(This example is complete, it can be run &quot;as is&quot;, assuming you&#039;ve [installed the `pydantic_ai` package](https://ai.pydantic.dev/install))_

The exchange will be very short: Pydantic AI will send the instructions and the user prompt to the LLM, and the model will return a text response.

Not very interesting yet, but we can easily add [tools](https://ai.pydantic.dev/tools), [dynamic instructions](https://ai.pydantic.dev/agents#instructions), and [structured outputs](https://ai.pydantic.dev/output) to build more powerful agents.

## Tools &amp; Dependency Injection Example

Here is a concise example using Pydantic AI to build a support agent for a bank:

**(Better documented example [in the docs](https://ai.pydantic.dev/#tools-dependency-injection-example))**

```python
from dataclasses import dataclass

from pydantic import BaseModel, Field
from pydantic_ai import Agent, RunContext

from bank_database import DatabaseConn


# SupportDependencies is used to pass data, connections, and logic into the model that will be needed when running
# instructions and tool functions. Dependency injection provides a type-safe way to customise the behavior of your agents.
@dataclass
class SupportDependencies:
    customer_id: int
    db: DatabaseConn


# This Pydantic model defines the structure of the output returned by the agent.
class SupportOutput(BaseModel):
    support_advice: str = Field(description=&#039;Advice returned to the customer&#039;)
    block_card: bool = Field(description=&quot;Whether to block the customer&#039;s card&quot;)
    risk: int = Field(description=&#039;Risk level of query&#039;, ge=0, le=10)


# This agent will act as first-tier support in a bank.
# Agents are generic in the type of dependencies they accept and the type of output they return.
# In this case, the support agent has type `Agent[SupportDependencies, SupportOutput]`.
support_agent = Agent(
    &#039;openai:gpt-5&#039;,
    deps_type=SupportDependencies,
    # The response from the agent will, be guaranteed to be a SupportOutput,
    # if validation fails the agent is prompted to try again.
    output_type=SupportOutput,
    instructions=(
        &#039;You are a support agent in our bank, give the &#039;
        &#039;customer support and judge the risk level of their query.&#039;
    ),
)


# Dynamic instructions can make use of dependency injection.
# Dependencies are carried via the `RunContext` argument, which is parameterized with the `deps_type` from above.
# If the type annotation here is wrong, static type checkers will catch it.
@support_agent.instructions
async def add_customer_name(ctx: RunContext[SupportDependencies]) -&gt; str:
    customer_name = await ctx.deps.db.customer_name(id=ctx.deps.customer_id)
    return f&quot;The customer&#039;s name is {customer_name!r}&quot;


# The `tool` decorator let you register functions which the LLM may call while responding to a user.
# Again, dependencies are carried via `RunContext`, any other arguments become the tool schema passed to the LLM.
# Pydantic is used to validate these arguments, and errors are passed back to the LLM so it can retry.
@support_agent.tool
async def customer_balance(
        ctx: RunContext[SupportDependencies], include_pending: bool
) -&gt; float:
    &quot;&quot;&quot;Returns the customer&#039;s current account balance.&quot;&quot;&quot;
    # The docstring of a tool is also passed to the LLM as the description of the tool.
    # Parameter descriptions are extracted from the docstring and added to the parameter schema sent to the LLM.
    balance = await ctx.deps.db.customer_balance(
        id=ctx.deps.customer_id,
        include_pending=include_pending,
    )
    return balance


...  # In a real use case, you&#039;d add more tools and a longer system prompt


async def main():
    deps = SupportDependencies(customer_id=123, db=DatabaseConn())
    # Run the agent asynchronously, conducting a conversation with the LLM until a final response is reached.
    # Even in this fairly simple case, the agent will exchange multiple messages with the LLM as tools are called to retrieve an output.
    result = await support_agent.run(&#039;What is my balance?&#039;, deps=deps)
    # The `result.output` will be validated with Pydantic to guarantee it is a `SupportOutput`. Since the agent is generic,
    # it&#039;ll also be typed as a `SupportOutput` to aid with static type checking.
    print(result.output)
    &quot;&quot;&quot;
    support_advice=&#039;Hello John, your current account balance, including pending transactions, is $123.45.&#039; block_card=False risk=1
    &quot;&quot;&quot;

    result = await support_agent.run(&#039;I just lost my card!&#039;, deps=deps)
    print(result.output)
    &quot;&quot;&quot;
    support_advice=&quot;I&#039;m sorry to hear that, John. We are temporarily blocking your card to prevent unauthorized transactions.&quot; block_card=True risk=8
    &quot;&quot;&quot;
```

## Next Steps

To try Pydantic AI for yourself, [install it](https://ai.pydantic.dev/install) and follow the instructions [in the examples](https://ai.pydantic.dev/examples/setup).

Read the [docs](https://ai.pydantic.dev/agents/) to learn more about building applications with Pydantic AI.

Read the [API Reference](https://ai.pydantic.dev/api/agent/) to understand Pydantic AI&#039;s interface.

Join [Slack](https://logfire.pydantic.dev/docs/join-slack/) or file an issue on [GitHub](https://github.com/pydantic/pydantic-ai/issues) if you have any questions.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Asabeneh/30-Days-Of-Python]]></title>
            <link>https://github.com/Asabeneh/30-Days-Of-Python</link>
            <guid>https://github.com/Asabeneh/30-Days-Of-Python</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:14 GMT</pubDate>
            <description><![CDATA[30 days of Python programming challenge is a step-by-step guide to learn the Python programming language in 30 days. This challenge may take more than100 days, follow your own pace. These videos may help too: https://www.youtube.com/channel/UC7PNRuno1rzYPb1xLa4yktw]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Asabeneh/30-Days-Of-Python">Asabeneh/30-Days-Of-Python</a></h1>
            <p>30 days of Python programming challenge is a step-by-step guide to learn the Python programming language in 30 days. This challenge may take more than100 days, follow your own pace. These videos may help too: https://www.youtube.com/channel/UC7PNRuno1rzYPb1xLa4yktw</p>
            <p>Language: Python</p>
            <p>Stars: 50,821</p>
            <p>Forks: 9,677</p>
            <p>Stars today: 56 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[simular-ai/Agent-S]]></title>
            <link>https://github.com/simular-ai/Agent-S</link>
            <guid>https://github.com/simular-ai/Agent-S</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:13 GMT</pubDate>
            <description><![CDATA[Agent S: an open agentic framework that uses computers like a human]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/simular-ai/Agent-S">simular-ai/Agent-S</a></h1>
            <p>Agent S: an open agentic framework that uses computers like a human</p>
            <p>Language: Python</p>
            <p>Stars: 6,628</p>
            <p>Forks: 720</p>
            <p>Stars today: 161 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/agent_s.png&quot; alt=&quot;Logo&quot; style=&quot;vertical-align:middle&quot; width=&quot;60&quot;&gt; Agent S:
  &lt;small&gt;Use Computer Like a Human&lt;/small&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;&amp;nbsp;
  🌐 &lt;a href=&quot;https://www.simular.ai/articles/agent-s3&quot;&gt;[S3 blog]&lt;/a&gt;&amp;nbsp;
  📄 &lt;a href=&quot;https://arxiv.org/abs/2510.02250&quot;&gt;[S3 Paper]&lt;/a&gt;&amp;nbsp;
  🎥 &lt;a href=&quot;https://www.youtube.com/watch?v=VHr0a3UBsh4&quot;&gt;[S3 Video]&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&amp;nbsp;
  🌐 &lt;a href=&quot;https://www.simular.ai/articles/agent-s2-technical-review&quot;&gt;[S2 blog]&lt;/a&gt;&amp;nbsp;
  📄 &lt;a href=&quot;https://arxiv.org/abs/2504.00906&quot;&gt;[S2 Paper (COLM 2025)]&lt;/a&gt;&amp;nbsp;
  🎥 &lt;a href=&quot;https://www.youtube.com/watch?v=wUGVQl7c0eg&quot;&gt;[S2 Video]&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&amp;nbsp;
  🌐 &lt;a href=&quot;https://www.simular.ai/agent-s&quot;&gt;[S1 blog]&lt;/a&gt;&amp;nbsp;
  📄 &lt;a href=&quot;https://arxiv.org/abs/2410.08164&quot;&gt;[S1 Paper (ICLR 2025)]&lt;/a&gt;&amp;nbsp;
  🎥 &lt;a href=&quot;https://www.youtube.com/watch?v=OBDE3Knte0g&quot;&gt;[S1 Video]&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&amp;nbsp;
&lt;a href=&quot;https://trendshift.io/repositories/13151&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13151&quot; alt=&quot;simular-ai%2FAgent-S | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/OS-Windows-blue?logo=windows&amp;logoColor=white&quot; alt=&quot;Windows&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/OS-macOS-black?logo=apple&amp;logoColor=white&quot; alt=&quot;macOS&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/OS-Linux-yellow?logo=linux&amp;logoColor=black&quot; alt=&quot;Linux&quot;&gt;
  &lt;a href=&quot;https://discord.gg/E2XfsK9fPV&quot;&gt;
    &lt;img src=&quot;https://dcbadge.limes.pink/api/server/https://discord.gg/E2XfsK9fPV?style=flat&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt;
  &amp;nbsp;&amp;nbsp;
  &lt;a href=&quot;https://pepy.tech/projects/gui-agents&quot;&gt;
    &lt;img src=&quot;https://static.pepy.tech/badge/gui-agents&quot; alt=&quot;PyPI Downloads&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
  &lt;a href=&quot;https://www.readme-i18n.com/simular-ai/Agent-S?lang=de&quot;&gt;Deutsch&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/simular-ai/Agent-S?lang=es&quot;&gt;Español&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/simular-ai/Agent-S?lang=fr&quot;&gt;français&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/simular-ai/Agent-S?lang=ja&quot;&gt;日本語&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/simular-ai/Agent-S?lang=ko&quot;&gt;한국어&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/simular-ai/Agent-S?lang=pt&quot;&gt;Português&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/simular-ai/Agent-S?lang=ru&quot;&gt;Русский&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/simular-ai/Agent-S?lang=zh&quot;&gt;中文&lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &amp;nbsp;&amp;nbsp;
&lt;p&gt;Skip the setup? Try Agent S in &lt;a href=&quot;https://cloud.simular.ai/&quot;&gt;Simular Cloud&lt;/a&gt;
&lt;/div&gt;

## 🥳 Updates
- [x] **2025/10/02**: Released Agent S3 and its [technical paper](https://arxiv.org/abs/2510.02250), setting a new SOTA of **69.9%** on OSWorld (approaching 72% human performance), with strong generalizability on WindowsAgentArena and AndroidWorld! It is also simpler, faster, and more flexible.
- [x] **2025/08/01**: Agent S2.5 is released (gui-agents v0.2.5): simpler, better, and faster! New SOTA on [OSWorld-Verified](https://os-world.github.io)!
- [x] **2025/07/07**: The [Agent S2 paper](https://arxiv.org/abs/2504.00906) is accepted to COLM 2025! See you in Montreal!
- [x] **2025/04/27**: The Agent S paper won the Best Paper Award 🏆 at ICLR 2025 Agentic AI for Science Workshop!
- [x] **2025/04/01**: Released the [Agent S2 paper](https://arxiv.org/abs/2504.00906) with new SOTA results on OSWorld, WindowsAgentArena, and AndroidWorld!
- [x] **2025/03/12**: Released Agent S2 along with v0.2.0 of [gui-agents](https://github.com/simular-ai/Agent-S), the new state-of-the-art for computer use agents (CUA), outperforming OpenAI&#039;s CUA/Operator and Anthropic&#039;s Claude 3.7 Sonnet Computer-Use!
- [x] **2025/01/22**: The [Agent S paper](https://arxiv.org/abs/2410.08164) is accepted to ICLR 2025!
- [x] **2025/01/21**: Released v0.1.2 of [gui-agents](https://github.com/simular-ai/Agent-S) library, with support for Linux and Windows!
- [x] **2024/12/05**: Released v0.1.0 of [gui-agents](https://github.com/simular-ai/Agent-S) library, allowing you to use Agent-S for Mac, OSWorld, and WindowsAgentArena with ease!
- [x] **2024/10/10**: Released the [Agent S paper](https://arxiv.org/abs/2410.08164) and codebase!

## Table of Contents

1. [💡 Introduction](#-introduction)
2. [🎯 Current Results](#-current-results)
3. [🛠️ Installation &amp; Setup](#%EF%B8%8F-installation--setup) 
4. [🚀 Usage](#-usage)
5. [🤝 Acknowledgements](#-acknowledgements)
6. [💬 Citation](#-citation)

## 💡 Introduction

Welcome to **Agent S**, an open-source framework designed to enable autonomous interaction with computers through Agent-Computer Interface. Our mission is to build intelligent GUI agents that can learn from past experiences and perform complex tasks autonomously on your computer. 

Whether you&#039;re interested in AI, automation, or contributing to cutting-edge agent-based systems, we&#039;re excited to have you here!

## 🎯 Current Results

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/s3_results.png&quot; alt=&quot;Agent S3 Results&quot; width=&quot;700&quot;/&gt;
&lt;/p&gt;

On OSWorld, Agent S3 alone reaches 62.6% in the 100-step setting, already exceeding the previous state of the art of 61.4% (Claude Sonnet 4.5). With the addition of Behavior Best-of-N, performance climbs even higher to 69.9%, bringing computer-use agents to within just a few points of human-level accuracy (72%).

Agent S3 also demonstrates strong zero-shot generalization. On WindowsAgentArena, accuracy rises from 50.2% using only Agent S3 to 56.6% by selecting from 3 rollouts. Similarly on AndroidWorld, performance improves from 68.1% to 71.6%

## 🛠️ Installation &amp; Setup

### Prerequisites
- **Single Monitor**: Our agent is designed for single monitor screens
- **Security**: The agent runs Python code to control your computer - use with care
- **Supported Platforms**: Linux, Mac, and Windows


### Installation
To install Agent S3 without cloning the repository, run
```bash
pip install gui-agents
```
If you would like to test Agent S3 while making changes, clone the repository and install using
```
pip install -e .
```

Don&#039;t forget to also `brew install tesseract`! Pytesseract requires this extra installation to work.

### API Configuration

#### Option 1: Environment Variables
Add to your `.bashrc` (Linux) or `.zshrc` (MacOS):
```bash
export OPENAI_API_KEY=&lt;YOUR_API_KEY&gt;
export ANTHROPIC_API_KEY=&lt;YOUR_ANTHROPIC_API_KEY&gt;
export HF_TOKEN=&lt;YOUR_HF_TOKEN&gt;
```

#### Option 2: Python Script
```python
import os
os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;&lt;YOUR_API_KEY&gt;&quot;
```

### Supported Models
We support Azure OpenAI, Anthropic, Gemini, Open Router, and vLLM inference. See [models.md](models.md) for details.

### Grounding Models (Required)
For optimal performance, we recommend [UI-TARS-1.5-7B](https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B) hosted on Hugging Face Inference Endpoints or another provider. See [Hugging Face Inference Endpoints](https://huggingface.co/learn/cookbook/en/enterprise_dedicated_endpoints) for setup instructions.

## 🚀 Usage


&gt; ⚡️ **Recommended Setup:**  
&gt; For the best configuration, we recommend using **OpenAI gpt-5-2025-08-07** as the main model, paired with **UI-TARS-1.5-7B** for grounding.  


### CLI

Note, this is running Agent S3, our improved agent, without bBoN. 

Run Agent S3 with the required parameters:

```bash
agent_s \
    --provider openai \
    --model gpt-5-2025-08-07 \
    --ground_provider huggingface \
    --ground_url http://localhost:8080 \
    --ground_model ui-tars-1.5-7b \
    --grounding_width 1920 \
    --grounding_height 1080
```

#### Local Coding Environment (Optional)
For tasks that require code execution (e.g., data processing, file manipulation, system automation), you can enable the local coding environment:

```bash
agent_s \
    --provider openai \
    --model gpt-5-2025-08-07 \
    --ground_provider huggingface \
    --ground_url http://localhost:8080 \
    --ground_model ui-tars-1.5-7b \
    --grounding_width 1920 \
    --grounding_height 1080 \
    --enable_local_env
```

⚠️ **WARNING**: The local coding environment executes arbitrary Python and Bash code locally on your machine. Only use this feature in trusted environments and with trusted inputs.

#### Required Parameters
- **`--provider`**: Main generation model provider (e.g., openai, anthropic, etc.) - Default: &quot;openai&quot;
- **`--model`**: Main generation model name (e.g., gpt-5-2025-08-07) - Default: &quot;gpt-5-2025-08-07&quot;
- **`--ground_provider`**: The provider for the grounding model - **Required**
- **`--ground_url`**: The URL of the grounding model - **Required**
- **`--ground_model`**: The model name for the grounding model - **Required**
- **`--grounding_width`**: Width of the output coordinate resolution from the grounding model - **Required**
- **`--grounding_height`**: Height of the output coordinate resolution from the grounding model - **Required**

#### Optional Parameters
- **`--model_temperature`**: The temperature to fix all model calls to (necessary to set to 1.0 for models like o3 but can be left blank for other models)

#### Grounding Model Dimensions
The grounding width and height should match the output coordinate resolution of your grounding model:
- **UI-TARS-1.5-7B**: Use `--grounding_width 1920 --grounding_height 1080`
- **UI-TARS-72B**: Use `--grounding_width 1000 --grounding_height 1000`

#### Optional Parameters
- **`--model_url`**: Custom API URL for main generation model - Default: &quot;&quot;
- **`--model_api_key`**: API key for main generation model - Default: &quot;&quot;
- **`--ground_api_key`**: API key for grounding model endpoint - Default: &quot;&quot;
- **`--max_trajectory_length`**: Maximum number of image turns to keep in trajectory - Default: 8
- **`--enable_reflection`**: Enable reflection agent to assist the worker agent - Default: True
- **`--enable_local_env`**: Enable local coding environment for code execution (WARNING: Executes arbitrary code locally) - Default: False

#### Local Coding Environment Details
The local coding environment enables Agent S3 to execute Python and Bash code directly on your machine. This is particularly useful for:

- **Data Processing**: Manipulating spreadsheets, CSV files, or databases
- **File Operations**: Bulk file processing, content extraction, or file organization
- **System Automation**: Configuration changes, system setup, or automation scripts
- **Code Development**: Writing, editing, or executing code files
- **Text Processing**: Document manipulation, content editing, or formatting

When enabled, the agent can use the `call_code_agent` action to execute code blocks for tasks that can be completed through programming rather than GUI interaction.

**Requirements:**
- **Python**: The same Python interpreter used to run Agent S3 (automatically detected)
- **Bash**: Available at `/bin/bash` (standard on macOS and Linux)
- **System Permissions**: The agent runs with the same permissions as the user executing it

**Security Considerations:**
- The local environment executes arbitrary code with the same permissions as the user running the agent
- Only enable this feature in trusted environments
- Be cautious when the agent generates code for system-level operations
- Consider running in a sandboxed environment for untrusted tasks
- Bash scripts are executed with a 30-second timeout to prevent hanging processes

### `gui_agents` SDK

First, we import the necessary modules. `AgentS3` is the main agent class for Agent S3. `OSWorldACI` is our grounding agent that translates agent actions into executable python code.
```python
import pyautogui
import io
from gui_agents.s3.agents.agent_s import AgentS3
from gui_agents.s3.agents.grounding import OSWorldACI
from gui_agents.s3.utils.local_env import LocalEnv  # Optional: for local coding environment

# Load in your API keys.
from dotenv import load_dotenv
load_dotenv()

current_platform = &quot;linux&quot;  # &quot;darwin&quot;, &quot;windows&quot;
```

Next, we define our engine parameters. `engine_params` is used for the main agent, and `engine_params_for_grounding` is for grounding. For `engine_params_for_grounding`, we support custom endpoints like HuggingFace TGI, vLLM, and Open Router.

```python
engine_params = {
  &quot;engine_type&quot;: provider,
  &quot;model&quot;: model,
  &quot;base_url&quot;: model_url,           # Optional
  &quot;api_key&quot;: model_api_key,        # Optional
  &quot;temperature&quot;: model_temperature # Optional
}

# Load the grounding engine from a custom endpoint
ground_provider = &quot;&lt;your_ground_provider&gt;&quot;
ground_url = &quot;&lt;your_ground_url&gt;&quot;
ground_model = &quot;&lt;your_ground_model&gt;&quot;
ground_api_key = &quot;&lt;your_ground_api_key&gt;&quot;

# Set grounding dimensions based on your model&#039;s output coordinate resolution
# UI-TARS-1.5-7B: grounding_width=1920, grounding_height=1080
# UI-TARS-72B: grounding_width=1000, grounding_height=1000
grounding_width = 1920  # Width of output coordinate resolution
grounding_height = 1080  # Height of output coordinate resolution

engine_params_for_grounding = {
  &quot;engine_type&quot;: ground_provider,
  &quot;model&quot;: ground_model,
  &quot;base_url&quot;: ground_url,
  &quot;api_key&quot;: ground_api_key,  # Optional
  &quot;grounding_width&quot;: grounding_width,
  &quot;grounding_height&quot;: grounding_height,
}
```

Then, we define our grounding agent and Agent S3.

```python
# Optional: Enable local coding environment
enable_local_env = False  # Set to True to enable local code execution
local_env = LocalEnv() if enable_local_env else None

grounding_agent = OSWorldACI(
    env=local_env,  # Pass local_env for code execution capability
    platform=current_platform,
    engine_params_for_generation=engine_params,
    engine_params_for_grounding=engine_params_for_grounding,
    width=1920,  # Optional: screen width
    height=1080  # Optional: screen height
)

agent = AgentS3(
    engine_params,
    grounding_agent,
    platform=current_platform,
    max_trajectory_length=8,  # Optional: maximum image turns to keep
    enable_reflection=True     # Optional: enable reflection agent
)
```

Finally, let&#039;s query the agent!

```python
# Get screenshot.
screenshot = pyautogui.screenshot()
buffered = io.BytesIO() 
screenshot.save(buffered, format=&quot;PNG&quot;)
screenshot_bytes = buffered.getvalue()

obs = {
  &quot;screenshot&quot;: screenshot_bytes,
}

instruction = &quot;Close VS Code&quot;
info, action = agent.predict(instruction=instruction, observation=obs)

exec(action[0])
```

Refer to `gui_agents/s3/cli_app.py` for more details on how the inference loop works.

### OSWorld

To deploy Agent S3 in OSWorld, follow the [OSWorld Deployment instructions](osworld_setup/s3/OSWorld.md).

## 💬 Citations

If you find this codebase useful, please cite:

```
@misc{Agent-S3,
      title={The Unreasonable Effectiveness of Scaling Agents for Computer Use}, 
      author={Gonzalo Gonzalez-Pumariega and Vincent Tu and Chih-Lun Lee and Jiachen Yang and Ang Li and Xin Eric Wang},
      year={2025},
      eprint={2510.02250},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2510.02250}, 
}

@misc{Agent-S2,
      title={Agent S2: A Compositional Generalist-Specialist Framework for Computer Use Agents}, 
      author={Saaket Agashe and Kyle Wong and Vincent Tu and Jiachen Yang and Ang Li and Xin Eric Wang},
      year={2025},
      eprint={2504.00906},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2504.00906}, 
}

@inproceedings{Agent-S,
    title={{Agent S: An Open Agentic Framework that Uses Computers Like a Human}},
    author={Saaket Agashe and Jiuzhou Han and Shuyu Gan and Jiachen Yang and Ang Li and Xin Eric Wang},
    booktitle={International Conference on Learning Representations (ICLR)},
    year={2025},
    url={https://arxiv.org/abs/2410.08164}
}
```

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=simular-ai/Agent-S&amp;type=Date)](https://star-history.com/#simular-ai/Agent-S&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[derv82/wifite2]]></title>
            <link>https://github.com/derv82/wifite2</link>
            <guid>https://github.com/derv82/wifite2</guid>
            <pubDate>Mon, 06 Oct 2025 00:04:12 GMT</pubDate>
            <description><![CDATA[Rewrite of the popular wireless network auditor, "wifite"]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/derv82/wifite2">derv82/wifite2</a></h1>
            <p>Rewrite of the popular wireless network auditor, "wifite"</p>
            <p>Language: Python</p>
            <p>Stars: 7,263</p>
            <p>Forks: 1,516</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>Wifite
======

This repo is a complete re-write of [`wifite`](https://github.com/derv82/wifite), a Python script for auditing wireless networks.

Wifite runs existing wireless-auditing tools for you. Stop memorizing command arguments &amp; switches!

Wifite is designed to use all known methods for retrieving the password of a wireless access point (router).  These methods include:
1. WPS: The [Offline Pixie-Dust attack](https://en.wikipedia.org/wiki/Wi-Fi_Protected_Setup#Offline_brute-force_attack)
1. WPS: The [Online Brute-Force PIN attack](https://en.wikipedia.org/wiki/Wi-Fi_Protected_Setup#Online_brute-force_attack)
2. WPA: The [WPA Handshake Capture](https://hashcat.net/forum/thread-7717.html) + offline crack.
3. WPA: The [PMKID Hash Capture](https://hashcat.net/forum/thread-7717.html) + offline crack.
4. WEP: Various known attacks against WEP, including *fragmentation*, *chop-chop*, *aireplay*, etc.

Run wifite, select your targets, and Wifite will automatically start trying to capture or crack the password.

Supported Operating Systems
---------------------------
Wifite is designed specifically for the latest version of [**Kali** Linux](https://www.kali.org/). [ParrotSec](https://www.parrotsec.org/) is also supported.

Other pen-testing distributions (such as BackBox or Ubuntu) have outdated versions of the tools used by Wifite. Do not expect support unless you are using the latest versions of the *Required Tools*, and also [patched wireless drivers that support injection]().

Required Tools
--------------
First and foremost, you will need a wireless card capable of &quot;Monitor Mode&quot; and packet injection (see [this tutorial for checking if your wireless card is compatible](http://www.aircrack-ng.org/doku.php?id=compatible_cards) and also [this guide](https://en.wikipedia.org/wiki/Wi-Fi_Protected_Setup#Offline_brute-force_attack)). There are many cheap wireless cards that plug into USB available from online stores.

Second, only the latest versions of these programs are supported and must be installed for Wifite to work properly:

**Required:**

* `python`: Wifite is compatible with both `python2` and `python3`.
* [`iwconfig`](https://wiki.debian.org/iwconfig): For identifying wireless devices already in Monitor Mode.
* [`ifconfig`](https://en.wikipedia.org/wiki/Ifconfig): For starting/stopping wireless devices.
* [`Aircrack-ng`](http://aircrack-ng.org/) suite, includes:
   * [`airmon-ng`](https://tools.kali.org/wireless-attacks/airmon-ng): For enumerating and enabling Monitor Mode on wireless devices.
   * [`aircrack-ng`](https://tools.kali.org/wireless-attacks/aircrack-ng): For cracking WEP .cap files and WPA handshake captures.
   * [`aireplay-ng`](https://tools.kali.org/wireless-attacks/aireplay-ng): For deauthing access points, replaying capture files, various WEP attacks.
   * [`airodump-ng`](https://tools.kali.org/wireless-attacks/airodump-ng): For target scanning &amp; capture file generation.
   * [`packetforge-ng`](https://tools.kali.org/wireless-attacks/packetforge-ng): For forging capture files.

**Optional, but Recommended:**

* [`tshark`](https://www.wireshark.org/docs/man-pages/tshark.html): For detecting WPS networks and inspecting handshake capture files.
* [`reaver`](https://github.com/t6x/reaver-wps-fork-t6x): For WPS Pixie-Dust &amp; brute-force attacks.
   * Note: Reaver&#039;s `wash` tool can be used to detect WPS networks if `tshark` is not found.
* [`bully`](https://github.com/aanarchyy/bully): For WPS Pixie-Dust &amp; brute-force attacks.
   * Alternative to Reaver. Specify `--bully` to use Bully instead of Reaver.
   * Bully is also used to fetch PSK if `reaver` cannot after cracking WPS PIN.
* [`coWPAtty`](https://tools.kali.org/wireless-attacks/cowpatty): For detecting handshake captures.
* [`pyrit`](https://github.com/JPaulMora/Pyrit): For detecting handshake captures.
* [`hashcat`](https://hashcat.net/): For cracking PMKID hashes.
   * [`hcxdumptool`](https://github.com/ZerBea/hcxdumptool): For capturing PMKID hashes.
   * [`hcxpcaptool`](https://github.com/ZerBea/hcxtools): For converting PMKID packet captures into `hashcat`&#039;s format.


Run Wifite
----------
```
git clone https://github.com/derv82/wifite2.git
cd wifite2
sudo ./Wifite.py
```

Install Wifite
--------------
To install onto your computer (so you can just run `wifite` from any terminal), run:

```bash
sudo python setup.py install
```

This will install `wifite` to `/usr/sbin/wifite` which should be in your terminal path.

**Note:** Uninstalling is [not as easy](https://stackoverflow.com/questions/1550226/python-setup-py-uninstall#1550235). The only way to uninstall is to record the files installed by the above command and *remove* those files:

```bash
sudo python setup.py install --record files.txt \
  &amp;&amp; cat files.txt | xargs sudo rm \
  &amp;&amp; rm -f files.txt
```

Brief Feature List
------------------
* [PMKID hash capture](https://hashcat.net/forum/thread-7717.html) (enabled by-default, force with: `--pmkid`)
* WPS Offline Brute-Force Attack aka &quot;Pixie-Dust&quot;. (enabled by-default, force with: `--wps-only --pixie`)
* WPS Online Brute-Force Attack aka &quot;PIN attack&quot;. (enabled by-default, force with: `--wps-only --no-pixie`)
* WPA/2 Offline Brute-Force Attack via 4-Way Handshake capture (enabled by-default, force with: `--no-wps`)
* Validates handshakes against `pyrit`, `tshark`, `cowpatty`, and `aircrack-ng` (when available)
* Various WEP attacks (replay, chopchop, fragment, hirte, p0841, caffe-latte)
* Automatically decloaks hidden access points while scanning or attacking.
   * Note: Only works when channel is fixed. Use `-c &lt;channel&gt;`
   * Disable this using `--no-deauths`
* 5Ghz support for some wireless cards (via `-5` switch).
   * Note: Some tools don&#039;t play well on 5GHz channels (e.g. `aireplay-ng`)
* Stores cracked passwords and handshakes to the current directory (`--cracked`)
   * Includes information about the cracked access point (Name, BSSID, Date, etc).
* Easy to try to crack handshakes or PMKID hashes against a wordlist (`--crack`)

What&#039;s new?
-----------
Comparing this repo to the &quot;old wifite&quot; @ https://github.com/derv82/wifite

* **Less bugs**
   * Cleaner process management. Does not leave processes running in the background (the old `wifite` was bad about this).
   * No longer &quot;one monolithic script&quot;. Has working unit tests. Pull requests are less-painful!
* **Speed**
   * Target access points are refreshed every second instead of every 5 seconds.
* **Accuracy**
   * Displays realtime Power level of currently-attacked target.
   * Displays more information during an attack (e.g. % during WEP chopchop attacks, Pixie-Dust step index, etc)
* **Educational**
   * The `--verbose` option (expandable to `-vv` or `-vvv`) shows which commands are executed &amp; the output of those commands.
   * This can help debug why Wifite is not working for you. Or so you can learn how these tools are used.
* More-actively developed.
* Python 3 support.
* Sweet new ASCII banner.

What&#039;s gone?
------------
* Some command-line arguments (`--wept`, `--wpst`, and other confusing switches).
   * You can still access some of these obscure options, try `wifite -h -v`

What&#039;s not new?
---------------
* (Mostly) Backwards compatible with the original `wifite`&#039;s arguments.
* Same text-based interface everyone knows and loves.

Screenshots
-----------
Cracking WPS PIN using `reaver`&#039;s Pixie-Dust attack, then fetching WPA key using `bully`:
![Pixie-Dust with Reaver to get PIN and Bully to get PSK](https://i.imgur.com/Q5KSDbg.gif)

-------------

Cracking WPA key using PMKID attack:
![PMKID attack](https://i.imgur.com/CR8oOp0.gif)

-------------

Decloaking &amp; cracking a hidden access point (via the WPA Handshake attack):
![Decloaking and Cracking a hidden access point](https://i.imgur.com/F6VPhbm.gif)

-------------

Cracking a weak WEP password (using the WEP Replay attack):
![Cracking a weak WEP password](https://i.imgur.com/jP72rVo.gif)

-------------

Cracking a pre-captured handshake using John The Ripper (via the `--crack` option):
![--crack option](https://i.imgur.com/iHcfCjp.gif)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>