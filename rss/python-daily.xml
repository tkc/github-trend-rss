<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Thu, 24 Jul 2025 00:04:36 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[OpenBB-finance/OpenBB]]></title>
            <link>https://github.com/OpenBB-finance/OpenBB</link>
            <guid>https://github.com/OpenBB-finance/OpenBB</guid>
            <pubDate>Thu, 24 Jul 2025 00:04:36 GMT</pubDate>
            <description><![CDATA[Investment Research for Everyone, Everywhere.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/OpenBB-finance/OpenBB">OpenBB-finance/OpenBB</a></h1>
            <p>Investment Research for Everyone, Everywhere.</p>
            <p>Language: Python</p>
            <p>Stars: 44,830</p>
            <p>Forks: 4,048</p>
            <p>Stars today: 619 stars today</p>
            <h2>README</h2><pre>&lt;br /&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/platform-light.svg?raw=true#gh-light-mode-only&quot; alt=&quot;OpenBB Platform logo&quot; width=&quot;600&quot;&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only&quot; alt=&quot;OpenBB Platform logo&quot; width=&quot;600&quot;&gt;
&lt;br /&gt;
&lt;br /&gt;

[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;label=Follow%20%40openbb_finance)](https://x.com/openbb_finance)
[![Discord Shield](https://img.shields.io/discord/831165782750789672)](https://discord.com/invite/xPHTuHCmuV)
[![Open in Dev Containers](https://img.shields.io/static/v1?label=Dev%20Containers&amp;message=Open&amp;color=blue&amp;logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB)
&lt;a href=&quot;https://codespaces.new/OpenBB-finance/OpenBB&quot;&gt;
  &lt;img src=&quot;https://github.com/codespaces/badge.svg&quot; height=&quot;20&quot; /&gt;
&lt;/a&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb&quot;&gt;
  &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open In Colab&quot;/&gt;
&lt;/a&gt;
[![PyPI](https://img.shields.io/pypi/v/openbb?color=blue&amp;label=PyPI%20Package)](https://pypi.org/project/openbb/)

The first financial Platform that is open source.

The OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.

Get started with: `pip install openbb`

```python
from openbb import obb
output = obb.equity.price.historical(&quot;AAPL&quot;)
df = output.to_dataframe()
```

You can sign up to the [OpenBB Hub](https://my.openbb.co/login) to get the most out of the OpenBB ecosystem.

Data integrations available can be found here: &lt;https://docs.openbb.co/platform/reference&gt;

---

## OpenBB Workspace

While the OpenBB Platform is all about an integration to dozens of different data vendors, the interface is either Python or a CLI.

If you want an enterprise UI to visualize this datasets and use AI agents on top, you can find OpenBB Workspace at &lt;https://pro.openbb.co&gt;.

&lt;a href=&quot;https://pro.openbb.co&quot;&gt;
  &lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png&quot; alt=&quot;Logo&quot; width=&quot;1000&quot;&gt;
  &lt;/div&gt;
&lt;/a&gt;

Data integration:

- You can learn more about adding data to the OpenBB workspace from the [docs](https://docs.openbb.co/workspace) or [this open source repository](https://github.com/OpenBB-finance/backends-for-openbb).

AI Agents integration:

- You can learn more about adding AI agents to the OpenBB workspace from [this open source repository](https://github.com/OpenBB-finance/agents-for-openbb).

### Integrating OpenBB Platform to the OpenBB Workspace

Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.

#### Run OpenBB Platform backend

- Install the packages.

```sh
pip install &quot;openbb[all]&quot;
```

- Start the API server over localhost.

```sh
openbb-api
```

This will launch a FastAPI server, via Uvicorn, at `127.0.0.1:6900`.

You can check that it works by going to &lt;http://127.0.0.1:6900&gt;.

#### Integrate OpenBB Platform backend to OpenBB Workspace

Sign-in to the [OpenBB Workspace](https://pro.openbb.co/), and follow the following steps:

![CleanShot 2025-05-17 at 09 51 56@2x](https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069)

1. Go to the &quot;Apps&quot; tab
2. Click on &quot;Connect backend&quot;
3. Fill in the form with:
   Name: OpenBB Platform
   URL: &lt;http://127.0.0.1:6900&gt;
4. Click on &quot;Test&quot;. You should get a &quot;Test successful&quot; with the number of apps found.
5. Click on &quot;Add&quot;.

That&#039;s it.

---

&lt;!-- TABLE OF CONTENTS --&gt;
&lt;details closed=&quot;closed&quot;&gt;
  &lt;summary&gt;&lt;h2 style=&quot;display: inline-block&quot;&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt;
  &lt;ol&gt;
    &lt;li&gt;&lt;a href=&quot;#1-installation&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#2-contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#3-license&quot;&gt;License&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#4-disclaimer&quot;&gt;Disclaimer&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#5-contacts&quot;&gt;Contacts&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#6-star-history&quot;&gt;Star History&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#7-contributors&quot;&gt;Contributors&lt;/a&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/details&gt;

## 1. Installation

The OpenBB Platform can be installed as a [PyPI package](https://pypi.org/project/openbb/) by running `pip install openbb`

or by cloning the repository directly with `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process, in the [OpenBB Documentation](https://docs.openbb.co/platform/installation).

### OpenBB Platform CLI installation

The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.

It can be installed by running `pip install openbb-cli`

or by cloning the repository directly with  `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process in the [OpenBB Documentation](https://docs.openbb.co/cli/installation).

## 2. Contributing

There are three main ways of contributing to this project. (Hopefully you have starred the project by now ‚≠êÔ∏è)

### Become a Contributor

- More information on our [Contributing Documentation](https://docs.openbb.co/platform/developer_guide/misc/contributing).

### Create a GitHub ticket

Before creating a ticket make sure the one you are creating doesn&#039;t exist already [here](https://github.com/OpenBB-finance/OpenBB/issues)

- [Report bug](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.md&amp;title=%5BBug%5D)
- [Suggest improvement](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=enhancement&amp;template=enhancement.md&amp;title=%5BIMPROVE%5D)
- [Request a feature](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=new+feature&amp;template=feature_request.md&amp;title=%5BFR%5D)

### Provide feedback

We are most active on [our Discord](https://openbb.co/discord), but feel free to reach out to us in any of [our social media](https://openbb.co/links) for feedback.

## 3. License

Distributed under the AGPLv3 License. See
[LICENSE](https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE) for more information.

## 4. Disclaimer

Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment
amount, and may not be suitable for all investors.

Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.

The data contained in the OpenBB Platform is not necessarily accurate.

OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.

All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.

Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.

## 5. Contacts

If you have any questions about the platform or anything OpenBB, feel free to email us at `support@openbb.co`

If you want to say hi, or are interested in partnering with us, feel free to reach us at `hello@openbb.co`

Any of our social media platforms: [openbb.co/links](https://openbb.co/links)

## 6. Star History

This is a proxy of our growth and that we are just getting started.

But for more metrics important to us check [openbb.co/open](https://openbb.co/open).

[![Star History Chart](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)

## 7. Contributors

OpenBB wouldn&#039;t be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.

&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/graphs/contributors&quot;&gt;
   &lt;img src=&quot;https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB&quot; width=&quot;800&quot;/&gt;
&lt;/a&gt;

&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt;
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;

[contributors-shield]: https://img.shields.io/github/contributors/OpenBB-finance/OpenBB.svg?style=for-the-badge
[contributors-url]: https://github.com/OpenBB-finance/OpenBB/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/OpenBB-finance/OpenBB.svg?style=for-the-badge
[forks-url]: https://github.com/OpenBB-finance/OpenBB/network/members
[stars-shield]: https://img.shields.io/github/stars/OpenBB-finance/OpenBB.svg?style=for-the-badge
[stars-url]: https://github.com/OpenBB-finance/OpenBB/stargazers
[issues-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB.svg?style=for-the-badge&amp;color=blue
[issues-url]: https://github.com/OpenBB-finance/OpenBB/issues
[bugs-open-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=yellow
[bugs-open-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aopen
[bugs-closed-shield]: https://img.shields.io/github/issues-closed/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=success
[bugs-closed-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aclosed
[license-shield]: https://img.shields.io/github/license/OpenBB-finance/OpenBB.svg?style=for-the-badge
[license-url]: https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&amp;logo=linkedin&amp;colorB=555
[linkedin-url]: https://linkedin.com/in/DidierRLopes
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[donnemartin/system-design-primer]]></title>
            <link>https://github.com/donnemartin/system-design-primer</link>
            <guid>https://github.com/donnemartin/system-design-primer</guid>
            <pubDate>Thu, 24 Jul 2025 00:04:35 GMT</pubDate>
            <description><![CDATA[Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/donnemartin/system-design-primer">donnemartin/system-design-primer</a></h1>
            <p>Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.</p>
            <p>Language: Python</p>
            <p>Stars: 312,591</p>
            <p>Forks: 51,376</p>
            <p>Stars today: 204 stars today</p>
            <h2>README</h2><pre>*[English](README.md) ‚àô [Êó•Êú¨Ë™û](README-ja.md) ‚àô [ÁÆÄ‰Ωì‰∏≠Êñá](README-zh-Hans.md) ‚àô [ÁπÅÈ´î‰∏≠Êñá](README-zh-TW.md) | [ÿßŸÑÿπŸéÿ±Ÿéÿ®ŸêŸäŸéŸëÿ©‚Äé](https://github.com/donnemartin/system-design-primer/issues/170) ‚àô [‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ](https://github.com/donnemartin/system-design-primer/issues/220) ‚àô [Portugu√™s do Brasil](https://github.com/donnemartin/system-design-primer/issues/40) ‚àô [Deutsch](https://github.com/donnemartin/system-design-primer/issues/186) ‚àô [ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨](https://github.com/donnemartin/system-design-primer/issues/130) ‚àô [◊¢◊ë◊®◊ô◊™](https://github.com/donnemartin/system-design-primer/issues/272) ‚àô [Italiano](https://github.com/donnemartin/system-design-primer/issues/104) ‚àô [ÌïúÍµ≠Ïñ¥](https://github.com/donnemartin/system-design-primer/issues/102) ‚àô [ŸÅÿßÿ±ÿ≥€å](https://github.com/donnemartin/system-design-primer/issues/110) ‚àô [Polski](https://github.com/donnemartin/system-design-primer/issues/68) ‚àô [—Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫](https://github.com/donnemartin/system-design-primer/issues/87) ‚àô [Espa√±ol](https://github.com/donnemartin/system-design-primer/issues/136) ‚àô [‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢](https://github.com/donnemartin/system-design-primer/issues/187) ‚àô [T√ºrk√ße](https://github.com/donnemartin/system-design-primer/issues/39) ‚àô [ti·∫øng Vi·ªát](https://github.com/donnemartin/system-design-primer/issues/127) ‚àô [Fran√ßais](https://github.com/donnemartin/system-design-primer/issues/250) | [Add Translation](https://github.com/donnemartin/system-design-primer/issues/28)*

**Help [translate](TRANSLATIONS.md) this guide!**

# The System Design Primer

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/jj3A5N8.png&quot;&gt;
  &lt;br/&gt;
&lt;/p&gt;

## Motivation

&gt; Learn how to design large-scale systems.
&gt;
&gt; Prep for the system design interview.

### Learn how to design large-scale systems

Learning how to design scalable systems will help you become a better engineer.

System design is a broad topic.  There is a **vast amount of resources scattered throughout the web** on system design principles.

This repo is an **organized collection** of resources to help you learn how to build systems at scale.

### Learn from the open source community

This is a continually updated, open source project.

[Contributions](#contributing) are welcome!

### Prep for the system design interview

In addition to coding interviews, system design is a **required component** of the **technical interview process** at many tech companies.

**Practice common system design interview questions** and **compare** your results with **sample solutions**: discussions, code, and diagrams.

Additional topics for interview prep:

* [Study guide](#study-guide)
* [How to approach a system design interview question](#how-to-approach-a-system-design-interview-question)
* [System design interview questions, **with solutions**](#system-design-interview-questions-with-solutions)
* [Object-oriented design interview questions, **with solutions**](#object-oriented-design-interview-questions-with-solutions)
* [Additional system design interview questions](#additional-system-design-interview-questions)

## Anki flashcards

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/zdCAkB3.png&quot;&gt;
  &lt;br/&gt;
&lt;/p&gt;

The provided [Anki flashcard decks](https://apps.ankiweb.net/) use spaced repetition to help you retain key system design concepts.

* [System design deck](https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design.apkg)
* [System design exercises deck](https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design%20Exercises.apkg)
* [Object oriented design exercises deck](https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/OO%20Design.apkg)

Great for use while on-the-go.

### Coding Resource: Interactive Coding Challenges

Looking for resources to help you prep for the [**Coding Interview**](https://github.com/donnemartin/interactive-coding-challenges)?

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/b4YtAEN.png&quot;&gt;
  &lt;br/&gt;
&lt;/p&gt;

Check out the sister repo [**Interactive Coding Challenges**](https://github.com/donnemartin/interactive-coding-challenges), which contains an additional Anki deck:

* [Coding deck](https://github.com/donnemartin/interactive-coding-challenges/tree/master/anki_cards/Coding.apkg)

## Contributing

&gt; Learn from the community.

Feel free to submit pull requests to help:

* Fix errors
* Improve sections
* Add new sections
* [Translate](https://github.com/donnemartin/system-design-primer/issues/28)

Content that needs some polishing is placed [under development](#under-development).

Review the [Contributing Guidelines](CONTRIBUTING.md).

## Index of system design topics

&gt; Summaries of various system design topics, including pros and cons.  **Everything is a trade-off**.
&gt;
&gt; Each section contains links to more in-depth resources.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/jrUBAF7.png&quot;&gt;
  &lt;br/&gt;
&lt;/p&gt;

* [System design topics: start here](#system-design-topics-start-here)
    * [Step 1: Review the scalability video lecture](#step-1-review-the-scalability-video-lecture)
    * [Step 2: Review the scalability article](#step-2-review-the-scalability-article)
    * [Next steps](#next-steps)
* [Performance vs scalability](#performance-vs-scalability)
* [Latency vs throughput](#latency-vs-throughput)
* [Availability vs consistency](#availability-vs-consistency)
    * [CAP theorem](#cap-theorem)
        * [CP - consistency and partition tolerance](#cp---consistency-and-partition-tolerance)
        * [AP - availability and partition tolerance](#ap---availability-and-partition-tolerance)
* [Consistency patterns](#consistency-patterns)
    * [Weak consistency](#weak-consistency)
    * [Eventual consistency](#eventual-consistency)
    * [Strong consistency](#strong-consistency)
* [Availability patterns](#availability-patterns)
    * [Fail-over](#fail-over)
    * [Replication](#replication)
    * [Availability in numbers](#availability-in-numbers)
* [Domain name system](#domain-name-system)
* [Content delivery network](#content-delivery-network)
    * [Push CDNs](#push-cdns)
    * [Pull CDNs](#pull-cdns)
* [Load balancer](#load-balancer)
    * [Active-passive](#active-passive)
    * [Active-active](#active-active)
    * [Layer 4 load balancing](#layer-4-load-balancing)
    * [Layer 7 load balancing](#layer-7-load-balancing)
    * [Horizontal scaling](#horizontal-scaling)
* [Reverse proxy (web server)](#reverse-proxy-web-server)
    * [Load balancer vs reverse proxy](#load-balancer-vs-reverse-proxy)
* [Application layer](#application-layer)
    * [Microservices](#microservices)
    * [Service discovery](#service-discovery)
* [Database](#database)
    * [Relational database management system (RDBMS)](#relational-database-management-system-rdbms)
        * [Master-slave replication](#master-slave-replication)
        * [Master-master replication](#master-master-replication)
        * [Federation](#federation)
        * [Sharding](#sharding)
        * [Denormalization](#denormalization)
        * [SQL tuning](#sql-tuning)
    * [NoSQL](#nosql)
        * [Key-value store](#key-value-store)
        * [Document store](#document-store)
        * [Wide column store](#wide-column-store)
        * [Graph Database](#graph-database)
    * [SQL or NoSQL](#sql-or-nosql)
* [Cache](#cache)
    * [Client caching](#client-caching)
    * [CDN caching](#cdn-caching)
    * [Web server caching](#web-server-caching)
    * [Database caching](#database-caching)
    * [Application caching](#application-caching)
    * [Caching at the database query level](#caching-at-the-database-query-level)
    * [Caching at the object level](#caching-at-the-object-level)
    * [When to update the cache](#when-to-update-the-cache)
        * [Cache-aside](#cache-aside)
        * [Write-through](#write-through)
        * [Write-behind (write-back)](#write-behind-write-back)
        * [Refresh-ahead](#refresh-ahead)
* [Asynchronism](#asynchronism)
    * [Message queues](#message-queues)
    * [Task queues](#task-queues)
    * [Back pressure](#back-pressure)
* [Communication](#communication)
    * [Transmission control protocol (TCP)](#transmission-control-protocol-tcp)
    * [User datagram protocol (UDP)](#user-datagram-protocol-udp)
    * [Remote procedure call (RPC)](#remote-procedure-call-rpc)
    * [Representational state transfer (REST)](#representational-state-transfer-rest)
* [Security](#security)
* [Appendix](#appendix)
    * [Powers of two table](#powers-of-two-table)
    * [Latency numbers every programmer should know](#latency-numbers-every-programmer-should-know)
    * [Additional system design interview questions](#additional-system-design-interview-questions)
    * [Real world architectures](#real-world-architectures)
    * [Company architectures](#company-architectures)
    * [Company engineering blogs](#company-engineering-blogs)
* [Under development](#under-development)
* [Credits](#credits)
* [Contact info](#contact-info)
* [License](#license)

## Study guide

&gt; Suggested topics to review based on your interview timeline (short, medium, long).

![Imgur](images/OfVllex.png)

**Q: For interviews, do I need to know everything here?**

**A: No, you don&#039;t need to know everything here to prepare for the interview**.

What you are asked in an interview depends on variables such as:

* How much experience you have
* What your technical background is
* What positions you are interviewing for
* Which companies you are interviewing with
* Luck

More experienced candidates are generally expected to know more about system design.  Architects or team leads might be expected to know more than individual contributors.  Top tech companies are likely to have one or more design interview rounds.

Start broad and go deeper in a few areas.  It helps to know a little about various key system design topics.  Adjust the following guide based on your timeline, experience, what positions you are interviewing for, and which companies you are interviewing with.

* **Short timeline** - Aim for **breadth** with system design topics.  Practice by solving **some** interview questions.
* **Medium timeline** - Aim for **breadth** and **some depth** with system design topics.  Practice by solving **many** interview questions.
* **Long timeline** - Aim for **breadth** and **more depth** with system design topics.  Practice by solving **most** interview questions.

| | Short | Medium | Long |
|---|---|---|---|
| Read through the [System design topics](#index-of-system-design-topics) to get a broad understanding of how systems work | :+1: | :+1: | :+1: |
| Read through a few articles in the [Company engineering blogs](#company-engineering-blogs) for the companies you are interviewing with | :+1: | :+1: | :+1: |
| Read through a few [Real world architectures](#real-world-architectures) | :+1: | :+1: | :+1: |
| Review [How to approach a system design interview question](#how-to-approach-a-system-design-interview-question) | :+1: | :+1: | :+1: |
| Work through [System design interview questions with solutions](#system-design-interview-questions-with-solutions) | Some | Many | Most |
| Work through [Object-oriented design interview questions with solutions](#object-oriented-design-interview-questions-with-solutions) | Some | Many | Most |
| Review [Additional system design interview questions](#additional-system-design-interview-questions) | Some | Many | Most |

## How to approach a system design interview question

&gt; How to tackle a system design interview question.

The system design interview is an **open-ended conversation**.  You are expected to lead it.

You can use the following steps to guide the discussion.  To help solidify this process, work through the [System design interview questions with solutions](#system-design-interview-questions-with-solutions) section using the following steps.

### Step 1: Outline use cases, constraints, and assumptions

Gather requirements and scope the problem.  Ask questions to clarify use cases and constraints.  Discuss assumptions.

* Who is going to use it?
* How are they going to use it?
* How many users are there?
* What does the system do?
* What are the inputs and outputs of the system?
* How much data do we expect to handle?
* How many requests per second do we expect?
* What is the expected read to write ratio?

### Step 2: Create a high level design

Outline a high level design with all important components.

* Sketch the main components and connections
* Justify your ideas

### Step 3: Design core components

Dive into details for each core component.  For example, if you were asked to [design a url shortening service](solutions/system_design/pastebin/README.md), discuss:

* Generating and storing a hash of the full url
    * [MD5](solutions/system_design/pastebin/README.md) and [Base62](solutions/system_design/pastebin/README.md)
    * Hash collisions
    * SQL or NoSQL
    * Database schema
* Translating a hashed url to the full url
    * Database lookup
* API and object-oriented design

### Step 4: Scale the design

Identify and address bottlenecks, given the constraints.  For example, do you need the following to address scalability issues?

* Load balancer
* Horizontal scaling
* Caching
* Database sharding

Discuss potential solutions and trade-offs.  Everything is a trade-off.  Address bottlenecks using [principles of scalable system design](#index-of-system-design-topics).

### Back-of-the-envelope calculations

You might be asked to do some estimates by hand.  Refer to the [Appendix](#appendix) for the following resources:

* [Use back of the envelope calculations](http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html)
* [Powers of two table](#powers-of-two-table)
* [Latency numbers every programmer should know](#latency-numbers-every-programmer-should-know)

### Source(s) and further reading

Check out the following links to get a better idea of what to expect:

* [How to ace a systems design interview](https://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/)
* [The system design interview](http://www.hiredintech.com/system-design)
* [Intro to Architecture and Systems Design Interviews](https://www.youtube.com/watch?v=ZgdS0EUmn70)
* [System design template](https://leetcode.com/discuss/career/229177/My-System-Design-Template)

## System design interview questions with solutions

&gt; Common system design interview questions with sample discussions, code, and diagrams.
&gt;
&gt; Solutions linked to content in the `solutions/` folder.

| Question | |
|---|---|
| Design Pastebin.com (or Bit.ly) | [Solution](solutions/system_design/pastebin/README.md) |
| Design the Twitter timeline and search (or Facebook feed and search) | [Solution](solutions/system_design/twitter/README.md) |
| Design a web crawler | [Solution](solutions/system_design/web_crawler/README.md) |
| Design Mint.com | [Solution](solutions/system_design/mint/README.md) |
| Design the data structures for a social network | [Solution](solutions/system_design/social_graph/README.md) |
| Design a key-value store for a search engine | [Solution](solutions/system_design/query_cache/README.md) |
| Design Amazon&#039;s sales ranking by category feature | [Solution](solutions/system_design/sales_rank/README.md) |
| Design a system that scales to millions of users on AWS | [Solution](solutions/system_design/scaling_aws/README.md) |
| Add a system design question | [Contribute](#contributing) |

### Design Pastebin.com (or Bit.ly)

[View exercise and solution](solutions/system_design/pastebin/README.md)

![Imgur](images/4edXG0T.png)

### Design the Twitter timeline and search (or Facebook feed and search)

[View exercise and solution](solutions/system_design/twitter/README.md)

![Imgur](images/jrUBAF7.png)

### Design a web crawler

[View exercise and solution](solutions/system_design/web_crawler/README.md)

![Imgur](images/bWxPtQA.png)

### Design Mint.com

[View exercise and solution](solutions/system_design/mint/README.md)

![Imgur](images/V5q57vU.png)

### Design the data structures for a social network

[View exercise and solution](solutions/system_design/social_graph/README.md)

![Imgur](images/cdCv5g7.png)

### Design a key-value store for a search engine

[View exercise and solution](solutions/system_design/query_cache/README.md)

![Imgur](images/4j99mhe.png)

### Design Amazon&#039;s sales ranking by category feature

[View exercise and solution](solutions/system_design/sales_rank/README.md)

![Imgur](images/MzExP06.png)

### Design a system that scales to millions of users on AWS

[View exercise and solution](solutions/system_design/scaling_aws/README.md)

![Imgur](images/jj3A5N8.png)

## Object-oriented design interview questions with solutions

&gt; Common object-oriented design interview questions with sample discussions, code, and diagrams.
&gt;
&gt; Solutions linked to content in the `solutions/` folder.

&gt;**Note: This section is under development**

| Question | |
|---|---|
| Design a hash map | [Solution](solutions/object_oriented_design/hash_table/hash_map.ipynb)  |
| Design a least recently used cache | [Solution](solutions/object_oriented_design/lru_cache/lru_cache.ipynb)  |
| Design a call center | [Solution](solutions/object_oriented_design/call_center/call_center.ipynb)  |
| Design a deck of cards | [Solution](solutions/object_oriented_design/deck_of_cards/deck_of_cards.ipynb)  |
| Design a parking lot | [Solution](solutions/object_oriented_design/parking_lot/parking_lot.ipynb)  |
| Design a chat server | [Solution](solutions/object_oriented_design/online_chat/online_chat.ipynb)  |
| Design a circular array | [Contribute](#contributing)  |
| Add an object-oriented design question | [Contribute](#contributing) |

## System design topics: start here

New to system design?

First, you&#039;ll need a basic understanding of common principles, learning about what they are, how they are used, and their pros and cons.

### Step 1: Review the scalability video lecture

[Scalability Lecture at Harvard](https://www.youtube.com/watch?v=-W9F__D3oY4)

* Topics covered:
    * Vertical scaling
    * Horizontal scaling
    * Caching
    * Load balancing
    * Database replication
    * Database partitioning

### Step 2: Review the scalability article

[Scalability](https://web.archive.org/web/20221030091841/http://www.lecloud.net/tagged/scalability/chrono)

* Topics covered:
    * [Clones](https://web.archive.org/web/20220530193911/https://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones)
    * [Databases](https://web.archive.org/web/20220602114024/https://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database)
    * [Caches](https://web.archive.org/web/20230126233752/https://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache)
    * [Asynchronism](https://web.archive.org/web/20220926171507/https://www.lecloud.net/post/9699762917/scalability-for-dummies-part-4-asynchronism)

### Next steps

Next, we&#039;ll look at high-level trade-offs:

* **Performance** vs **scalability**
* **Latency** vs **throughput**
* **Availability** vs **consistency**

Keep in mind that **everything is a trade-off**.

Then we&#039;ll dive into more specific topics such as DNS, CDNs, and load balancers.

## Performance vs scalability

A service is **scalable** if it results in increased **performance** in a manner proportional to resources added. Generally, increasing performance means serving more units of work, but it can also be to handle larger units of work, such as when datasets grow.&lt;sup&gt;&lt;a href=http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html&gt;1&lt;/a&gt;&lt;/sup&gt;

Another way to look at performance vs scalability:

* If you have a **performance** problem, your system is slow for a single user.
* If you have a **scalability** problem, your system is fast for a single user but slow under heavy load.

### Source(s) and further reading

* [A word on scalability](http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html)
* [Scalability, availability, s

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[roboflow/supervision]]></title>
            <link>https://github.com/roboflow/supervision</link>
            <guid>https://github.com/roboflow/supervision</guid>
            <pubDate>Thu, 24 Jul 2025 00:04:34 GMT</pubDate>
            <description><![CDATA[We write your reusable computer vision tools. üíú]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/roboflow/supervision">roboflow/supervision</a></h1>
            <p>We write your reusable computer vision tools. üíú</p>
            <p>Language: Python</p>
            <p>Stars: 29,773</p>
            <p>Forks: 2,334</p>
            <p>Stars today: 447 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;p&gt;
    &lt;a align=&quot;center&quot; href=&quot;&quot; target=&quot;https://supervision.roboflow.com&quot;&gt;
      &lt;img
        width=&quot;100%&quot;
        src=&quot;https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529&quot;
      &gt;
    &lt;/a&gt;
  &lt;/p&gt;

&lt;br&gt;

[notebooks](https://github.com/roboflow/notebooks) | [inference](https://github.com/roboflow/inference) | [autodistill](https://github.com/autodistill/autodistill) | [maestro](https://github.com/roboflow/multimodal-maestro)

&lt;br&gt;

[![version](https://badge.fury.io/py/supervision.svg)](https://badge.fury.io/py/supervision)
[![downloads](https://img.shields.io/pypi/dm/supervision)](https://pypistats.org/packages/supervision)
[![snyk](https://snyk.io/advisor/python/supervision/badge.svg)](https://snyk.io/advisor/python/supervision)
[![license](https://img.shields.io/pypi/l/supervision)](https://github.com/roboflow/supervision/blob/main/LICENSE.md)
[![python-version](https://img.shields.io/pypi/pyversions/supervision)](https://badge.fury.io/py/supervision)
[![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb)
[![gradio](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/Roboflow/Annotators)
[![discord](https://img.shields.io/discord/1159501506232451173?logo=discord&amp;label=discord&amp;labelColor=fff&amp;color=5865f2&amp;link=https%3A%2F%2Fdiscord.gg%2FGbfgXGJ8Bk)](https://discord.gg/GbfgXGJ8Bk)
[![built-with-material-for-mkdocs](https://img.shields.io/badge/Material_for_MkDocs-526CFE?logo=MaterialForMkDocs&amp;logoColor=white)](https://squidfunk.github.io/mkdocs-material/)

  &lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/124&quot;  target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/124&quot; alt=&quot;roboflow%2Fsupervision | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
  &lt;/div&gt;

&lt;/div&gt;

## üëã hello

**We write your reusable computer vision tools.** Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! ü§ù

## üíª install

Pip install the supervision package in a
[**Python&gt;=3.9**](https://www.python.org/) environment.

```bash
pip install supervision
```

Read more about conda, mamba, and installing from source in our [guide](https://roboflow.github.io/supervision/).

## üî• quickstart

### models

Supervision was designed to be model agnostic. Just plug in any classification, detection, or segmentation model. For your convenience, we have created [connectors](https://supervision.roboflow.com/latest/detection/core/#detections) for the most popular libraries like Ultralytics, Transformers, or MMDetection.

```python
import cv2
import supervision as sv
from ultralytics import YOLO

image = cv2.imread(...)
model = YOLO(&quot;yolov8s.pt&quot;)
result = model(image)[0]
detections = sv.Detections.from_ultralytics(result)

len(detections)
# 5
```

&lt;details&gt;
&lt;summary&gt;üëâ more model connectors&lt;/summary&gt;

- inference

  Running with [Inference](https://github.com/roboflow/inference) requires a [Roboflow API KEY](https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key).

  ```python
  import cv2
  import supervision as sv
  from inference import get_model

  image = cv2.imread(...)
  model = get_model(model_id=&quot;yolov8s-640&quot;, api_key=&lt;ROBOFLOW API KEY&gt;)
  result = model.infer(image)[0]
  detections = sv.Detections.from_inference(result)

  len(detections)
  # 5
  ```

&lt;/details&gt;

### annotators

Supervision offers a wide range of highly customizable [annotators](https://supervision.roboflow.com/latest/detection/annotators/), allowing you to compose the perfect visualization for your use case.

```python
import cv2
import supervision as sv

image = cv2.imread(...)
detections = sv.Detections(...)

box_annotator = sv.BoxAnnotator()
annotated_frame = box_annotator.annotate(
  scene=image.copy(),
  detections=detections)
```

https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce

### datasets

Supervision provides a set of [utils](https://supervision.roboflow.com/latest/datasets/core/) that allow you to load, split, merge, and save datasets in one of the supported formats.

```python
import supervision as sv
from roboflow import Roboflow

project = Roboflow().workspace(&lt;WORKSPACE_ID&gt;).project(&lt;PROJECT_ID&gt;)
dataset = project.version(&lt;PROJECT_VERSION&gt;).download(&quot;coco&quot;)

ds = sv.DetectionDataset.from_coco(
    images_directory_path=f&quot;{dataset.location}/train&quot;,
    annotations_path=f&quot;{dataset.location}/train/_annotations.coco.json&quot;,
)

path, image, annotation = ds[0]
    # loads image on demand

for path, image, annotation in ds:
    # loads image on demand
```

&lt;details close&gt;
&lt;summary&gt;üëâ more dataset utils&lt;/summary&gt;

- load

  ```python
  dataset = sv.DetectionDataset.from_yolo(
      images_directory_path=...,
      annotations_directory_path=...,
      data_yaml_path=...
  )

  dataset = sv.DetectionDataset.from_pascal_voc(
      images_directory_path=...,
      annotations_directory_path=...
  )

  dataset = sv.DetectionDataset.from_coco(
      images_directory_path=...,
      annotations_path=...
  )
  ```

- split

  ```python
  train_dataset, test_dataset = dataset.split(split_ratio=0.7)
  test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)

  len(train_dataset), len(test_dataset), len(valid_dataset)
  # (700, 150, 150)
  ```

- merge

  ```python
  ds_1 = sv.DetectionDataset(...)
  len(ds_1)
  # 100
  ds_1.classes
  # [&#039;dog&#039;, &#039;person&#039;]

  ds_2 = sv.DetectionDataset(...)
  len(ds_2)
  # 200
  ds_2.classes
  # [&#039;cat&#039;]

  ds_merged = sv.DetectionDataset.merge([ds_1, ds_2])
  len(ds_merged)
  # 300
  ds_merged.classes
  # [&#039;cat&#039;, &#039;dog&#039;, &#039;person&#039;]
  ```

- save

  ```python
  dataset.as_yolo(
      images_directory_path=...,
      annotations_directory_path=...,
      data_yaml_path=...
  )

  dataset.as_pascal_voc(
      images_directory_path=...,
      annotations_directory_path=...
  )

  dataset.as_coco(
      images_directory_path=...,
      annotations_path=...
  )
  ```

- convert

  ```python
  sv.DetectionDataset.from_yolo(
      images_directory_path=...,
      annotations_directory_path=...,
      data_yaml_path=...
  ).as_pascal_voc(
      images_directory_path=...,
      annotations_directory_path=...
  )
  ```

&lt;/details&gt;

## üé¨ tutorials

Want to learn how to use Supervision? Explore our [how-to guides](https://supervision.roboflow.com/develop/how_to/detect_and_annotate/), [end-to-end examples](https://github.com/roboflow/supervision/tree/develop/examples), [cheatsheet](https://roboflow.github.io/cheatsheet-supervision/), and [cookbooks](https://supervision.roboflow.com/develop/cookbooks/)!

&lt;br/&gt;

&lt;p align=&quot;left&quot;&gt;
&lt;a href=&quot;https://youtu.be/hAWpsIuem10&quot; title=&quot;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&quot;&gt;&lt;img src=&quot;https://github.com/SkalskiP/SkalskiP/assets/26109316/a742823d-c158-407d-b30f-063a5d11b4e1&quot; alt=&quot;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&quot; width=&quot;300px&quot; align=&quot;left&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://youtu.be/hAWpsIuem10&quot; title=&quot;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&quot;&gt;&lt;strong&gt;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&lt;/strong&gt;&lt;/a&gt;
&lt;div&gt;&lt;strong&gt;Created: 5 Apr 2024&lt;/strong&gt;&lt;/div&gt;
&lt;br/&gt;Learn how to use computer vision to analyze wait times and optimize processes. This tutorial covers object detection, tracking, and calculating time spent in designated zones. Use these techniques to improve customer experience in retail, traffic management, or other scenarios.&lt;/p&gt;

&lt;br/&gt;

&lt;p align=&quot;left&quot;&gt;
&lt;a href=&quot;https://youtu.be/uWP6UjDeZvY&quot; title=&quot;Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source&quot;&gt;&lt;img src=&quot;https://github.com/SkalskiP/SkalskiP/assets/26109316/61a444c8-b135-48ce-b979-2a5ab47c5a91&quot; alt=&quot;Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source&quot; width=&quot;300px&quot; align=&quot;left&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://youtu.be/uWP6UjDeZvY&quot; title=&quot;Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source&quot;&gt;&lt;strong&gt;Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source&lt;/strong&gt;&lt;/a&gt;
&lt;div&gt;&lt;strong&gt;Created: 11 Jan 2024&lt;/strong&gt;&lt;/div&gt;
&lt;br/&gt;Learn how to track and estimate the speed of vehicles using YOLO, ByteTrack, and Roboflow Inference. This comprehensive tutorial covers object detection, multi-object tracking, filtering detections, perspective transformation, speed estimation, visualization improvements, and more.&lt;/p&gt;

## üíú built with supervision

Did you build something cool using supervision? [Let us know!](https://github.com/roboflow/supervision/discussions/categories/built-with-supervision)

https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4

https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900

https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f

## üìö documentation

Visit our [documentation](https://roboflow.github.io/supervision) page to learn how supervision can help you build computer vision applications faster and more reliably.

## üèÜ contribution

We love your input! Please see our [contributing guide](https://github.com/roboflow/supervision/blob/main/CONTRIBUTING.md) to get started. Thank you üôè to all our contributors!

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/roboflow/supervision/graphs/contributors&quot;&gt;
      &lt;img src=&quot;https://contrib.rocks/image?repo=roboflow/supervision&quot; /&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;br&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;div align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://youtube.com/roboflow&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/youtube.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949634652&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://roboflow.com&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/roboflow-app.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949746649&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://www.linkedin.com/company/roboflow-ai/&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/linkedin.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949633691&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://docs.roboflow.com&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/knowledge.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949634511&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://discuss.roboflow.com&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/forum.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949633584&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://blog.roboflow.com&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/blog.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949633605&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[frappe/hrms]]></title>
            <link>https://github.com/frappe/hrms</link>
            <guid>https://github.com/frappe/hrms</guid>
            <pubDate>Thu, 24 Jul 2025 00:04:33 GMT</pubDate>
            <description><![CDATA[Open Source HR and Payroll Software]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/frappe/hrms">frappe/hrms</a></h1>
            <p>Open Source HR and Payroll Software</p>
            <p>Language: Python</p>
            <p>Stars: 3,169</p>
            <p>Forks: 1,271</p>
            <p>Stars today: 88 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
	&lt;a href=&quot;https://frappe.io/hr&quot;&gt;
		&lt;img src=&quot;.github/frappe-hr-logo.png&quot; height=&quot;80px&quot; width=&quot;80px&quot; alt=&quot;Frappe HR Logo&quot;&gt;
	&lt;/a&gt;
	&lt;h2&gt;Frappe HR&lt;/h2&gt;
	&lt;p align=&quot;center&quot;&gt;
		&lt;p&gt;Open Source, modern, and easy-to-use HR and Payroll Software&lt;/p&gt;
	&lt;/p&gt;

[![CI](https://github.com/frappe/hrms/actions/workflows/ci.yml/badge.svg?branch=develop)](https://github.com/frappe/hrms/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/frappe/hrms/branch/develop/graph/badge.svg?token=0TwvyUg3I5)](https://codecov.io/gh/frappe/hrms)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
	&lt;img src=&quot;.github/hrms-hero.png&quot;/&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
	&lt;a href=&quot;https://frappe.io/hr&quot;&gt;Website&lt;/a&gt;
	-
	&lt;a href=&quot;https://docs.frappe.io/hr/introduction&quot;&gt;Documentation&lt;/a&gt;
&lt;/div&gt;

## Frappe HR

Frappe HR has everything you need to drive excellence within the company. It&#039;s a complete HRMS solution with over 13 different modules right from Employee Management, Onboarding, Leaves, to Payroll, Taxation, and more!

## Motivation
When Frappe team started growing in terms of size, we needed an open-source HR and Payroll software. We didn&#039;t find any &quot;true&quot; open-source HR software out there and so decided to build one ourselves.
Initially, it was a set of modules within ERPNext but version 14 onwards, as the modules became more mature, Frappe HR was created as a separate product.

## Key Features

- **Employee Lifecycle**: From onboarding employees, managing promotions and transfers, all the way to documenting feedback with exit interviews, make life easier for employees throughout their life cycle.
- **Leave and Attendance**: Configure leave policies, pull regional holidays with a click, check-in and check-out with geolocation capturing, track leave balances and attendance with reports.
- **Expense Claims and Advances**: Manage employee advances, claim expenses, configure multi-level approval workflows, all this with seamless integration with ERPNext accounting.
- **Performance Management**: Track goals, align goals with key result areas (KRAs), enable employees to evaluate themselves, make managing appraisal cycles easy.
- **Payroll &amp; Taxation**: Create salary structures, configure income tax slabs, run standard payroll, accomodate additional salaries and off cycle payments, view income breakup on salary slips and so much more.
- **Frappe HR Mobile App**: Apply for and approve leaves on the go, check-in and check-out, access employee profile right from the mobile app.

&lt;details open&gt;

&lt;summary&gt;View Screenshots&lt;/summary&gt;
	&lt;img src=&quot;.github/hrms-appraisal.png&quot;/&gt;
	&lt;img src=&quot;.github/hrms-requisition.png&quot;/&gt;
	&lt;img src=&quot;.github/hrms-attendance.png&quot;/&gt;
	&lt;img src=&quot;.github/hrms-salary.png&quot;/&gt;
	&lt;img src=&quot;.github/hrms-pwa.png&quot;/&gt;
&lt;/details&gt;

### Under the Hood

- [**Frappe Framework**](https://github.com/frappe/frappe): A full-stack web application framework written in Python and Javascript. The framework provides a robust foundation for building web applications, including a database abstraction layer, user authentication, and a REST API.

- [**Frappe UI**](https://github.com/frappe/frappe-ui): A Vue-based UI library, to provide a modern user interface. The Frappe UI library provides a variety of components that can be used to build single-page applications on top of the Frappe Framework.

## Production Setup

### Managed Hosting

You can try [Frappe Cloud](https://frappecloud.com), a simple, user-friendly and sophisticated [open-source](https://github.com/frappe/press) platform to host Frappe applications with peace of mind.

It takes care of installation, setup, upgrades, monitoring, maintenance and support of your Frappe deployments. It is a fully featured developer platform with an ability to manage and control multiple Frappe deployments.

&lt;div&gt;
	&lt;a href=&quot;https://frappecloud.com/hrms/signup&quot; target=&quot;_blank&quot;&gt;
		&lt;picture&gt;
			&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://frappe.io/files/try-on-fc-white.png&quot;&gt;
			&lt;img src=&quot;https://frappe.io/files/try-on-fc-black.png&quot; alt=&quot;Try on Frappe Cloud&quot; height=&quot;28&quot; /&gt;
		&lt;/picture&gt;
	&lt;/a&gt;
&lt;/div&gt;


## Development setup
### Docker
You need Docker, docker-compose and git setup on your machine. Refer [Docker documentation](https://docs.docker.com/). After that, run the following commands:
```
git clone https://github.com/frappe/hrms
cd hrms/docker
docker-compose up
```

Wait for some time until the setup script creates a site. After that you can access `http://localhost:8000` in your browser and the login screen for HR should show up.

Use the following credentials to log in:

- Username: `Administrator`
- Password: `admin`

### Local

1. Set up bench by following the [Installation Steps](https://frappeframework.com/docs/user/en/installation) and start the server and keep it running
	```sh
	$ bench start
	```
2. In a separate terminal window, run the following commands
	```sh
	$ bench new-site hrms.local
	$ bench get-app erpnext
	$ bench get-app hrms
	$ bench --site hrms.local install-app hrms
	$ bench --site hrms.local add-to-hosts
	```
3. You can access the site at `http://hrms.local:8080`

## Learning and Community

1. [Frappe School](https://frappe.school) - Learn Frappe Framework and ERPNext from the various courses by the maintainers or from the community.
2. [Documentation](https://docs.frappe.io/hr) - Extensive documentation for Frappe HR.
3. [User Forum](https://discuss.erpnext.com/) - Engage with the community of ERPNext users and service providers.
4. [Telegram Group](https://t.me/frappehr) - Get instant help from the community of users.


## Contributing

1. [Issue Guidelines](https://github.com/frappe/erpnext/wiki/Issue-Guidelines)
1. [Report Security Vulnerabilities](https://erpnext.com/security)
1. [Pull Request Requirements](https://github.com/frappe/erpnext/wiki/Contribution-Guidelines)


## Logo and Trademark Policy

Please read our [Logo and Trademark Policy](TRADEMARK_POLICY.md).

&lt;br /&gt;
&lt;br /&gt;
&lt;div align=&quot;center&quot; style=&quot;padding-top: 0.75rem;&quot;&gt;
	&lt;a href=&quot;https://frappe.io&quot; target=&quot;_blank&quot;&gt;
		&lt;picture&gt;
			&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://frappe.io/files/Frappe-white.png&quot;&gt;
			&lt;img src=&quot;https://frappe.io/files/Frappe-black.png&quot; alt=&quot;Frappe Technologies&quot; height=&quot;28&quot;/&gt;
		&lt;/picture&gt;
	&lt;/a&gt;
&lt;/div&gt;

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[yeongpin/cursor-free-vip]]></title>
            <link>https://github.com/yeongpin/cursor-free-vip</link>
            <guid>https://github.com/yeongpin/cursor-free-vip</guid>
            <pubDate>Thu, 24 Jul 2025 00:04:32 GMT</pubDate>
            <description><![CDATA[[Support 0.49.x]ÔºàReset Cursor AI MachineID & Bypass Higher Token LimitÔºâ Cursor Ai ÔºåËá™Âä®ÈáçÁΩÆÊú∫Âô®ID Ôºå ÂÖçË¥πÂçáÁ∫ß‰ΩøÁî®ProÂäüËÉΩ: You've reached your trial request limit. / Too many free trial accounts used on this machine. Please upgrade to pro. We have this limit in place to prevent abuse. Please let us know if you believe this is a mistake.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/yeongpin/cursor-free-vip">yeongpin/cursor-free-vip</a></h1>
            <p>[Support 0.49.x]ÔºàReset Cursor AI MachineID & Bypass Higher Token LimitÔºâ Cursor Ai ÔºåËá™Âä®ÈáçÁΩÆÊú∫Âô®ID Ôºå ÂÖçË¥πÂçáÁ∫ß‰ΩøÁî®ProÂäüËÉΩ: You've reached your trial request limit. / Too many free trial accounts used on this machine. Please upgrade to pro. We have this limit in place to prevent abuse. Please let us know if you believe this is a mistake.</p>
            <p>Language: Python</p>
            <p>Stars: 32,782</p>
            <p>Forks: 4,060</p>
            <p>Stars today: 112 stars today</p>
            <h2>README</h2><pre># ‚û§ Cursor Free VIP

&lt;div align=&quot;center&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/logo.png&quot; alt=&quot;Cursor Pro Logo&quot; width=&quot;200&quot; style=&quot;border-radius: 6px;&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;

[![Release](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/release/yeongpin/cursor-free-vip)](https://github.com/yeongpin/cursor-free-vip/releases/latest)
[![License: CC BY-NC-ND 4.0](https://img.shields.io/badge/License-CC_BY--NC--ND_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-nd/4.0/)
[![Stars](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/stars/yeongpin/cursor-free-vip)](https://github.com/yeongpin/cursor-free-vip/stargazers)
[![Downloads](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/yeongpin/cursor-free-vip/total)](https://github.com/yeongpin/cursor-free-vip/releases/latest)
&lt;a href=&quot;https://buymeacoffee.com/yeongpin&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Buy Me a Coffee&quot; src=&quot;https://img.shields.io/badge/Buy%20Me%20a%20Coffee-Support%20Me-FFDA33&quot;&gt;&lt;/a&gt;
 [&lt;img src=&quot;https://devin.ai/assets/deepwiki-badge.png&quot; alt=&quot;Ask DeepWiki.com&quot; height=&quot;20&quot;/&gt;](https://deepwiki.com/yeongpin/cursor-free-vip)

&lt;/p&gt;


&lt;a href=&quot;https://trendshift.io/repositories/13425&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13425&quot; alt=&quot;yeongpin%2Fcursor-free-vip | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;br&gt;
&lt;a href=&quot;https://www.buymeacoffee.com/yeongpin&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://img.buymeacoffee.com/button-api/?text=buy me a coffee&amp;emoji=‚òï&amp;slug=yeongpin&amp;button_colour=ffda33&amp;font_colour=000000&amp;font_family=Bree&amp;outline_colour=000000&amp;coffee_colour=FFDD00&amp;latest=2&quot; width=&quot;160&quot; height=&#039;55&#039; alt=&quot;Buy Me a Coffee&quot;/&gt;
&lt;/a&gt;


&lt;h4&gt;Support Latest 0.49.x Version | ÊîØÊåÅÊúÄÊñ∞ 0.49.x ÁâàÊú¨&lt;/h4&gt;

This tool is for educational purposes, currently the repo does not violate any laws. Please support the original project.
This tool will not generate any fake email accounts and OAuth access.

Supports Windows, macOS and Linux.

For optimal performance, run with privileges and always stay up to date.

ÈÄôÊòØ‰∏ÄÊ¨æÁî®ÊñºÂ≠∏ÁøíÂíåÁ†îÁ©∂ÁöÑÂ∑•ÂÖ∑ÔºåÁõÆÂâç repo Ê≤íÊúâÈÅïÂèç‰ªª‰ΩïÊ≥ïÂæã„ÄÇË´ãÊîØÊåÅÂéü‰ΩúËÄÖ„ÄÇ
ÈÄôÊ¨æÂ∑•ÂÖ∑‰∏çÊúÉÁîüÊàê‰ªª‰ΩïÂÅáÁöÑÈõªÂ≠êÈÉµ‰ª∂Â∏≥Êà∂Âíå OAuth Ë®™Âïè„ÄÇ

ÊîØÊåÅ Windows„ÄÅmacOS Âíå Linux„ÄÇ

Â∞çÊñºÊúÄ‰Ω≥ÊÄßËÉΩÔºåË´ã‰ª•ÁÆ°ÁêÜÂì°Ë∫´‰ªΩÈÅãË°å‰∏¶ÂßãÁµÇ‰øùÊåÅÊúÄÊñ∞„ÄÇ


&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/product_2025-04-16_10-40-21.png&quot; alt=&quot;new&quot; width=&quot;800&quot; style=&quot;border-radius: 6px;&quot;/&gt;&lt;br&gt;
&lt;/p&gt;

&lt;/div&gt;

## üîÑ Change Log | Êõ¥Êñ∞Êó•Âøó

[Watch Change Log | Êü•ÁúãÊõ¥Êñ∞Êó•Âøó](CHANGELOG.md)

## ‚ú® Features | ÂäüËÉΩÁâπÈªû

* Support Windows macOS and Linux systems&lt;br&gt;ÊîØÊåÅ Windows„ÄÅmacOS Âíå Linux Á≥ªÁµ±&lt;br&gt;

* Reset Cursor&#039;s configuration&lt;br&gt;ÈáçÁΩÆ Cursor ÁöÑÈÖçÁΩÆ&lt;br&gt;

* Multi-language support (English, ÁÆÄ‰Ωì‰∏≠Êñá, ÁπÅÈ´î‰∏≠Êñá, Vietnamese)&lt;br&gt;Â§öË™ûË®ÄÊîØÊåÅÔºàËã±Êñá„ÄÅÁÆÄ‰Ωì‰∏≠Êñá„ÄÅÁπÅÈ´î‰∏≠Êñá„ÄÅË∂äÂçóË™ûÔºâ&lt;br&gt;

## üíª System Support | Á≥ªÁµ±ÊîØÊåÅ

| Operating System | Architecture      | Supported |
|------------------|-------------------|-----------|
| Windows          | x64, x86          | ‚úÖ         |
| macOS            | Intel, Apple Silicon | ‚úÖ      |
| Linux            | x64, x86, ARM64   | ‚úÖ         |

## üëÄ How to use | Â¶Ç‰Ωï‰ΩøÁî®

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;‚≠ê Auto Run Script | ËÖ≥Êú¨Ëá™ÂãïÂåñÈÅãË°å&lt;/b&gt;&lt;/summary&gt;

### **Linux/macOS**

```bash
curl -fsSL https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.sh -o install.sh &amp;&amp; chmod +x install.sh &amp;&amp; ./install.sh
```

### **Archlinux**

Install via [AUR](https://aur.archlinux.org/packages/cursor-free-vip-git)

```bash
yay -S cursor-free-vip-git
```

### **Windows**

```powershell
irm https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.ps1 | iex
```

&lt;/details&gt;

If you want to stop the script, please press Ctrl+C&lt;br&gt;Ë¶ÅÂÅúÊ≠¢ËÖ≥Êú¨ÔºåË´ãÊåâ Ctrl+C

## ‚ùó Note | Ê≥®ÊÑè‰∫ãÈ†Ö

üìù Config | Êñá‰ª∂ÈÖçÁΩÆ
`Win / Macos / Linux Path | Ë∑ØÂæë [Documents/.cursor-free-vip/config.ini]`
&lt;details&gt;
&lt;summary&gt;&lt;b&gt;‚≠ê Config | Êñá‰ª∂ÈÖçÁΩÆ&lt;/b&gt;&lt;/summary&gt;

```
[Chrome]
# Default Google Chrome Path | ÈªòË™çGoogle Chrome ÈÅäË¶ΩÂô®Ë∑ØÂæë
chromepath = C:\Program Files\Google/Chrome/Application/chrome.exe

[Turnstile]
# Handle Turnstile Wait Time | Á≠âÂæÖ‰∫∫Ê©üÈ©óË≠âÊôÇÈñì
handle_turnstile_time = 2
# Handle Turnstile Wait Random Time (must merge 1-3 or 1,3) | Á≠âÂæÖ‰∫∫Ê©üÈ©óË≠âÈö®Ê©üÊôÇÈñìÔºàÂøÖÈ†àÊòØ 1-3 ÊàñËÄÖ 1,3 ÈÄôÊ®£ÁöÑÁµÑÂêàÔºâ
handle_turnstile_random_time = 1-3

[OSPaths]
# Storage Path | Â≠òÂÑ≤Ë∑ØÂæë
storage_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/storage.json
# SQLite Path | SQLiteË∑ØÂæë
sqlite_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/state.vscdb
# Machine ID Path | Ê©üÂô®IDË∑ØÂæë
machine_id_path = /Users/username/Library/Application Support/Cursor/machineId
# For Linux users: ~/.config/cursor/machineid

[Timing]
# Min Random Time | ÊúÄÂ∞èÈö®Ê©üÊôÇÈñì
min_random_time = 0.1
# Max Random Time | ÊúÄÂ§ßÈö®Ê©üÊôÇÈñì
max_random_time = 0.8
# Page Load Wait | È†ÅÈù¢Âä†ËºâÁ≠âÂæÖÊôÇÈñì
page_load_wait = 0.1-0.8
# Input Wait | Ëº∏ÂÖ•Á≠âÂæÖÊôÇÈñì
input_wait = 0.3-0.8
# Submit Wait | Êèê‰∫§Á≠âÂæÖÊôÇÈñì
submit_wait = 0.5-1.5
# Verification Code Input | È©óË≠âÁ¢ºËº∏ÂÖ•Á≠âÂæÖÊôÇÈñì
verification_code_input = 0.1-0.3
# Verification Success Wait | È©óË≠âÊàêÂäüÁ≠âÂæÖÊôÇÈñì
verification_success_wait = 2-3
# Verification Retry Wait | È©óË≠âÈáçË©¶Á≠âÂæÖÊôÇÈñì
verification_retry_wait = 2-3
# Email Check Initial Wait | ÈÉµ‰ª∂Ê™¢Êü•ÂàùÂßãÁ≠âÂæÖÊôÇÈñì
email_check_initial_wait = 4-6
# Email Refresh Wait | ÈÉµ‰ª∂Âà∑Êñ∞Á≠âÂæÖÊôÇÈñì
email_refresh_wait = 2-4
# Settings Page Load Wait | Ë®≠ÁΩÆÈ†ÅÈù¢Âä†ËºâÁ≠âÂæÖÊôÇÈñì
settings_page_load_wait = 1-2
# Failed Retry Time | Â§±ÊïóÈáçË©¶ÊôÇÈñì
failed_retry_time = 0.5-1
# Retry Interval | ÈáçË©¶ÈñìÈöî
retry_interval = 8-12
# Max Timeout | ÊúÄÂ§ßË∂ÖÊôÇÊôÇÈñì
max_timeout = 160

[Utils]
# Check Update | Ê™¢Êü•Êõ¥Êñ∞
check_update = True
# Show Account Info | È°ØÁ§∫Ë≥¨Ëôü‰ø°ÊÅØ
show_account_info = True

[TempMailPlus]
# Enable TempMailPlus | ÂïìÁî® TempMailPlusÔºà‰ªª‰ΩïËΩâÁôºÂà∞TempMailPlusÁöÑÈÉµ‰ª∂ÈÉΩÊîØÊåÅÁç≤ÂèñÈ©óË≠âÁ¢ºÔºå‰æãÂ¶ÇcloudflareÈÉµ‰ª∂Catch-allÔºâ
enabled = false
# TempMailPlus Email | TempMailPlus ÈõªÂ≠êÈÉµ‰ª∂
email = xxxxx@mailto.plus
# TempMailPlus pin | TempMailPlus pinÁ¢º
epin = 

[WindowsPaths]
storage_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\storage.json
sqlite_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\state.vscdb
machine_id_path = C:\Users\yeongpin\AppData\Roaming\Cursor\machineId
cursor_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app
updater_path = C:\Users\yeongpin\AppData\Local\cursor-updater
update_yml_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app-update.yml
product_json_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app\product.json

[Browser]
default_browser = opera
chrome_path = C:\Program Files\Google\Chrome\Application\chrome.exe
edge_path = C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe
firefox_path = C:\Program Files\Mozilla Firefox\firefox.exe
brave_path = C:\Program Files\BraveSoftware/Brave-Browser/Application/brave.exe
chrome_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe
edge_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\msedgedriver.exe
firefox_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\geckodriver.exe
brave_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe
opera_path = C:\Users\yeongpin\AppData\Local\Programs\Opera\opera.exe
opera_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe

[OAuth]
show_selection_alert = False
timeout = 120
max_attempts = 3
```

&lt;/details&gt;

* Use administrator privileges to run the script &lt;br&gt;Ë´ã‰ΩøÁî®ÁÆ°ÁêÜÂì°Ë∫´‰ªΩÈÅãË°åËÖ≥Êú¨

* Confirm that Cursor is closed before running the script &lt;br&gt;Ë´ãÁ¢∫‰øùÂú®ÈÅãË°åËÖ≥Êú¨ÂâçÂ∑≤Á∂ìÈóúÈñâ Cursor&lt;br&gt;

* This tool is only for learning and research purposes &lt;br&gt;Ê≠§Â∑•ÂÖ∑ÂÉÖ‰æõÂ≠∏ÁøíÂíåÁ†îÁ©∂‰ΩøÁî®&lt;br&gt;

* Please comply with the relevant software usage terms when using this tool &lt;br&gt;‰ΩøÁî®Êú¨Â∑•ÂÖ∑ÊôÇË´ãÈÅµÂÆàÁõ∏ÈóúËªü‰ª∂‰ΩøÁî®Ê¢ùÊ¨æ

## üö® Common Issues | Â∏∏Ë¶ãÂïèÈ°å

|                   Â¶ÇÊûúÈÅáÂà∞Ê¨äÈôêÂïèÈ°åÔºåË´ãÁ¢∫‰øùÔºö                    |                   Ê≠§ËÖ≥Êú¨‰ª•ÁÆ°ÁêÜÂì°Ë∫´‰ªΩÈÅãË°å                    |
|:--------------------------------------------------:|:------------------------------------------------:|
| If you encounter permission issues, please ensure: | This script is run with administrator privileges |
| Error &#039;User is not authorized&#039; | This means your account was banned for using temporary (disposal) mail. Ensure using a non-temporary mail service |
## ü§© Contribution | Ë≤¢Áçª

Ê≠°ËøéÊèê‰∫§ Issue Âíå Pull RequestÔºÅ


&lt;a href=&quot;https://github.com/yeongpin/cursor-free-vip/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=yeongpin/cursor-free-vip&amp;preview=true&amp;max=&amp;columns=&quot; /&gt;
&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;

## üì© Disclaimer | ÂÖçË≤¨ËÅ≤Êòé

Êú¨Â∑•ÂÖ∑ÂÉÖ‰æõÂ≠∏ÁøíÂíåÁ†îÁ©∂‰ΩøÁî®Ôºå‰ΩøÁî®Êú¨Â∑•ÂÖ∑ÊâÄÁî¢ÁîüÁöÑ‰ªª‰ΩïÂæåÊûúÁî±‰ΩøÁî®ËÄÖËá™Ë°åÊâøÊìî„ÄÇ &lt;br&gt;

This tool is only for learning and research purposes, and any consequences arising from the use of this tool are borne
by the user.

## üí∞ Buy Me a Coffee | Ë´ãÊàëÂñùÊùØÂíñÂï°

&lt;div align=&quot;center&quot;&gt;
  &lt;table&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;img src=&quot;./images/provi-code.jpg&quot; alt=&quot;buy_me_a_coffee&quot; width=&quot;280&quot;/&gt;&lt;br&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;img src=&quot;./images/paypal.png&quot; alt=&quot;buy_me_a_coffee&quot; width=&quot;280&quot;/&gt;&lt;br&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

## ‚≠ê Star History | ÊòüÊòüÊï∏

&lt;div align=&quot;center&quot;&gt;

[![Star History Chart](https://api.star-history.com/svg?repos=yeongpin/cursor-free-vip&amp;type=Date)](https://star-history.com/#yeongpin/cursor-free-vip&amp;Date)

&lt;/div&gt;

## üìù License | ÊéàÊ¨ä

Êú¨È†ÖÁõÆÊé°Áî® [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/) ÊéàÊ¨ä„ÄÇ
Please refer to the [LICENSE](LICENSE.md) file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[hesreallyhim/awesome-claude-code]]></title>
            <link>https://github.com/hesreallyhim/awesome-claude-code</link>
            <guid>https://github.com/hesreallyhim/awesome-claude-code</guid>
            <pubDate>Thu, 24 Jul 2025 00:04:31 GMT</pubDate>
            <description><![CDATA[A curated list of awesome commands, files, and workflows for Claude Code]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hesreallyhim/awesome-claude-code">hesreallyhim/awesome-claude-code</a></h1>
            <p>A curated list of awesome commands, files, and workflows for Claude Code</p>
            <p>Language: Python</p>
            <p>Stars: 6,138</p>
            <p>Forks: 310</p>
            <p>Stars today: 386 stars today</p>
            <h2>README</h2><pre>&lt;!--lint disable remark-lint:awesome-badge--&gt;

#

&lt;!-- [![Awesome](https://awesome.re/badge-flat2.svg)](https://awesome.re) --&gt;

&lt;pre style=&quot;display: inline-block; text-align: left;&quot;&gt;
 ‚ñà‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚îê    ‚ñà‚ñà‚îê‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚ñà‚îê   ‚ñà‚ñà‚ñà‚îê‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê
‚ñà‚ñà‚îå‚îÄ‚îÄ‚ñà‚ñà‚îê‚ñà‚ñà‚îÇ    ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚ñà‚ñà‚îê‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚ñà‚ñà‚îÇ‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ ‚ñà‚îê ‚ñà‚ñà‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚îê  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê‚ñà‚ñà‚îÇ   ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îå‚ñà‚ñà‚ñà‚ñà‚îå‚ñà‚ñà‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚îê
‚ñà‚ñà‚îå‚îÄ‚îÄ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ‚ñà‚ñà‚ñà‚îê‚ñà‚ñà‚îÇ‚ñà‚ñà‚îå‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ   ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ‚îî‚ñà‚ñà‚îå‚îò‚ñà‚ñà‚îÇ‚ñà‚ñà‚îå‚îÄ‚îÄ‚îò
‚ñà‚ñà‚îÇ  ‚ñà‚ñà‚îÇ‚îî‚ñà‚ñà‚ñà‚îå‚ñà‚ñà‚ñà‚îå‚îò‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ‚îî‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îå‚îò‚ñà‚ñà‚îÇ ‚îî‚îÄ‚îò ‚ñà‚ñà‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê
‚îî‚îÄ‚îò  ‚îî‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îò     ‚îî‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê‚ñà‚ñà‚îê      ‚ñà‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚îê   ‚ñà‚ñà‚îê‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê
‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚ñà‚ñà‚îÇ     ‚ñà‚ñà‚îå‚îÄ‚îÄ‚ñà‚ñà‚îê‚ñà‚ñà‚îÇ   ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îå‚îÄ‚îÄ‚ñà‚ñà‚îê‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚ñà‚ñà‚îê‚ñà‚ñà‚îå‚îÄ‚îÄ‚ñà‚ñà‚îê‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚ñà‚ñà‚îÇ     ‚ñà‚ñà‚îÇ     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ   ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ  ‚ñà‚ñà‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚îê      ‚ñà‚ñà‚îÇ     ‚ñà‚ñà‚îÇ   ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ  ‚ñà‚ñà‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚îê
‚ñà‚ñà‚îÇ     ‚ñà‚ñà‚îÇ     ‚ñà‚ñà‚îå‚îÄ‚îÄ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ   ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ  ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îå‚îÄ‚îÄ‚îò      ‚ñà‚ñà‚îÇ     ‚ñà‚ñà‚îÇ   ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ  ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îå‚îÄ‚îÄ‚îò
‚îî‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê‚ñà‚ñà‚îÇ  ‚ñà‚ñà‚îÇ‚îî‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îå‚îò‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îå‚îò‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê    ‚îî‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê‚îî‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îå‚îò‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îå‚îò‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îò  ‚îî‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&lt;/pre&gt;

&lt;!--lint enable remark-lint:awesome-badge--&gt;

[![Awesome](https://awesome.re/badge-flat2.svg)](https://awesome.re)

&lt;!--lint enable remark-lint:awesome-badge--&gt;

&lt;!--lint disable double-link--&gt;

This is a curated list of slash-commands, `CLAUDE.md` files, CLI tools, and other resources and guides for enhancing your [Claude Code](https://docs.anthropic.com/en/docs/claude-code) workflow, productivity, and vibes.

&lt;!--lint enable double-link--&gt;

Claude Code is a cutting-edge CLI-based coding assistant and agent that you can access in your terminal or IDE. It is a rapidly evolving tool that offers a number of powerful capabilities, and allows for a lot of configuration, in a lot of different ways. Users are actively working out best practices and workflows. It is the hope that this repo will help the community share knowledge and understand how to get the most out of Claude Code.

### Announcements

- 2025-07-18 - I ended up over-engineering the submission workflow, but I think it&#039;s done, I just have to smoke test it and update the docs. For anyone with existing PR&#039;s, don&#039;t worry about updating them (for formatting purposes, that is), I can take care of it myself. For anoyne with new PR&#039;s, you _should_ be able to run `make submit` from the root directory of your fork for an interactive experience (as I said, needs smoke testing) - alternatively, add your entry to the bottom of [`THE_RESOURCES_TABLE`](../THE_RESOURCES_TABLE.csv) and run `make generate` to automatically update the `README.md` based on the information you filled in. If it&#039;s not working, just open a PR with the relevant information and I&#039;ll deal with it, I created this mess anyway üòÉ.

&lt;br&gt;

## Contents

‚ñ™&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Workflows &amp; Knowledge Guides](#workflows--knowledge-guides-)  
‚ñ™&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Tooling](#tooling-)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[IDE Integrations](#ide-integrations)  
‚ñ™&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Hooks](#hooks-)  
‚ñ™&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Slash-Commands](#slash-commands-)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Version Control &amp; Git](#version-control--git)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Code Analysis &amp; Testing](#code-analysis--testing)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Context Loading &amp; Priming](#context-loading--priming)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Documentation &amp; Changelogs](#documentation--changelogs)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[CI / Deployment](#ci--deployment)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Project &amp; Task Management](#project--task-management)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Miscellaneous](#miscellaneous)  
‚ñ™&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[CLAUDE.md Files](#claudemd-files-)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Language-Specific](#language-specific)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Domain-Specific](#domain-specific)  
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Project Scaffolding &amp; MCP](#project-scaffolding--mcp)  
‚ñ™&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[Official Documentation](#official-documentation-)  

&lt;br&gt;

## Workflows &amp; Knowledge Guides üß†

&gt; A **workflow** is a tightly coupled set of Claude Code-native resources that facilitate specific projects

[`Blogging Platform Instructions`](https://github.com/cloudartisan/cloudartisan.github.io/tree/main/.claude/commands) &amp;nbsp; by &amp;nbsp; [cloudartisan](https://github.com/cloudartisan)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;CC-BY-SA-4.0  
Provides a well-structured set of commands for publishing and maintaining a blogging platform, including commands for creating posts, managing categories, and handling media files.

[`ClaudeLog`](https://claudelog.com) &amp;nbsp; by &amp;nbsp; [InventorBlack](https://www.reddit.com/user/inventor_black/)    
A comprehensive knowledge repository that features detailed breakdowns of advanced Claude Code mechanics including [CLAUDE.md best practices](https://claudelog.com/mechanics/claude-md-supremacy), practical technique guides like [plan mode](https://claudelog.com/mechanics/plan-mode), and a [configuration guide](https://claudelog.com/configuration).

[`Context Priming`](https://github.com/disler/just-prompt/tree/main/.claude/commands) &amp;nbsp; by &amp;nbsp; [disler](https://github.com/disler)    
Provides a systematic approach to priming Claude Code with comprehensive project context through specialized commands for different project scenarios and development contexts.

[`n8n_agent`](https://github.com/kingler/n8n_agent/tree/main/.claude/commands) &amp;nbsp; by &amp;nbsp; [kingler](https://github.com/kingler)    
Amazing comprehensive set of comments for code analysis, QA, design, documentation, project structure, project management, optimization, and many more.

[`Project Bootstrapping and Task Management`](https://github.com/steadycursor/steadystart/tree/main/.claude/commands) &amp;nbsp; by &amp;nbsp; [steadycursor](https://github.com/steadycursor)    
Provides a structured set of commands for bootstrapping and managing a new project, including meta-commands for creating and editing custom slash-commands.

[`Project Management, Implementation, Planning, and Release`](https://github.com/scopecraft/command/tree/main/.claude/commands) &amp;nbsp; by &amp;nbsp; [scopecraft](https://github.com/scopecraft)    
Really comprehensive set of commands for all aspects of SDLC.

[`Project Workflow System`](https://github.com/harperreed/dotfiles/tree/master/.claude/commands) &amp;nbsp; by &amp;nbsp; [harperreed](https://github.com/harperreed)    
A set of commands that provide a comprehensive workflow system for managing projects, including task management, code review, and deployment processes.

[`Shipping Real Code w/ Claude`](https://diwank.space/field-notes-from-shipping-real-code-with-claude) &amp;nbsp; by &amp;nbsp; [Diwank](https://github.com/creatorrr)    
A detailed blog post explaining the author&#039;s process for shipping a product with Claude Code, including CLAUDE.md files and other interesting resources.

[`Simone`](https://github.com/Helmi/claude-simone) &amp;nbsp; by &amp;nbsp; [Helmi](https://github.com/Helmi)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT  
A broader project management workflow for Claude Code that encompasses not just a set of commands, but a system of documents, guidelines, and processes to facilitate project planning and execution.

[`Slash-commands megalist`](https://github.com/wcygan/dotfiles/tree/d8ab6b9f5a7a81007b7f5fa3025d4f83ce12cc02/claude/commands) &amp;nbsp; by &amp;nbsp; [wcygan](https://github.com/wcygan)    
A pretty stunning list (88 at the time of this post!) of slash-commands ranging from agent orchestration, code review, project management, security, documentation, self-assessment, almost anything you can dream of.

&lt;br&gt;

## Tooling üß∞

&gt; **Tooling** denotes applications that are built on top of Claude Code and consist of more components than slash-commands and `CLAUDE.md` files

[`CC Usage`](https://github.com/ryoppippi/ccusage) &amp;nbsp; by &amp;nbsp; [ryoppippi](https://github.com/ryoppippi)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT  
Handy CLI tool for managing and analyzing Claude Code usage, based on analyzing local Claude Code logs. Presents a nice dashboard regarding cost information, token consumption, etc.

[`ccexp`](https://github.com/nyatinte/ccexp) &amp;nbsp; by &amp;nbsp; [nyatinte](https://github.com/nyatinte)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT  
Interactive CLI tool for discovering and managing Claude Code configuration files and slash commands with a beautiful terminal UI.

[`Claude Code Flow`](https://github.com/ruvnet/claude-code-flow) &amp;nbsp; by &amp;nbsp; [ruvnet](https://github.com/ruvnet)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT  
This mode serves as a code-first orchestration layer, enabling Claude to write, edit, test, and optimize code autonomously across recursive agent cycles.

[`Claude Composer`](https://github.com/possibilities/claude-composer) &amp;nbsp; by &amp;nbsp; [Mike Bannister](https://github.com/possibilities)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Unlicense  
A tool that adds small enhancements to Claude Code.

[`Claude Hub`](https://github.com/claude-did-this/claude-hub) &amp;nbsp; by &amp;nbsp; [Claude Did This](https://github.com/claude-did-this)    
A webhook service that connects Claude Code to GitHub repositories, enabling AI-powered code assistance directly through pull requests and issues. This integration allows Claude to analyze repositories, answer technical questions, and help developers understand and improve their codebase through simple @mentions.

[`Claude Squad`](https://github.com/smtg-ai/claude-squad) &amp;nbsp; by &amp;nbsp; [smtg-ai](https://github.com/smtg-ai)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;AGPL-3.0  
Claude Squad is a terminal app that manages multiple Claude Code, Codex (and other local agents including Aider) in separate workspaces, allowing you to work on multiple tasks simultaneously.

[`Claude Swarm`](https://github.com/parruda/claude-swarm) &amp;nbsp; by &amp;nbsp; [parruda](https://github.com/parruda)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT  
Launch Claude Code session that is connected to a swarm of Claude Code Agents.

[`Claude Task Master`](https://github.com/eyaltoledano/claude-task-master) &amp;nbsp; by &amp;nbsp; [eyaltoledano](https://github.com/eyaltoledano)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;NOASSERTION  
A task management system for AI-driven development with Claude, designed to work seamlessly with Cursor AI.

[`Claude Task Runner`](https://github.com/grahama1970/claude-task-runner) &amp;nbsp; by &amp;nbsp; [grahama1970](https://github.com/grahama1970)    
A specialized tool to manage context isolation and focused task execution with Claude Code, solving the critical challenge of context length limitations and task focus when working with Claude on complex, multi-step projects.

[`Container Use`](https://github.com/dagger/container-use) &amp;nbsp; by &amp;nbsp; [dagger](https://github.com/dagger)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0  
Development environments for coding agents. Enable multiple agents to work safely and independently with your preferred stack.


### IDE Integrations

[`claude-code.el`](https://github.com/stevemolitor/claude-code.el) &amp;nbsp; by &amp;nbsp; [stevemolitor](https://github.com/stevemolitor)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0  
An Emacs interface for Claude Code CLI.

[`claude-code.nvim`](https://github.com/greggh/claude-code.nvim) &amp;nbsp; by &amp;nbsp; [greggh](https://github.com/greggh)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT  
A seamless integration between Claude Code AI assistant and Neovim.

[`crystal`](https://github.com/stravu/crystal) &amp;nbsp; by &amp;nbsp; [stravu](https://github.com/stravu)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT  
A full-fledged desktop application for orchestrating, monitoring, and interacting with Claude Code agents.

&lt;br&gt;

## Hooks ü™ù

&gt; **Hooks** are a brand new API for Claude Code that allows users to activate commands and run scripts at different points in Claude&#039;s agentic lifecycle.

**[Experimental]** - The resources listed in this section have not been fully vetted and may not work as expected, given the bleeding-edge nature of Claude Code hooks. Nevertheless, I wished to include them at least as a source of inspiration and to explore this unknown terrain. YMMV!

[`claude-code-hooks-sdk`](https://github.com/beyondcode/claude-hooks-sdk) &amp;nbsp; by &amp;nbsp; [beyondcode](https://github.com/beyondcode)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT  
A Laravel-inspired PHP SDK for building Claude Code hook responses with a clean, fluent API. This SDK makes it easy to create structured JSON responses for Claude Code hooks using an expressive, chainable interface.

[`claude-hooks`](https://github.com/johnlindquist/claude-hooks) &amp;nbsp; by &amp;nbsp; [John Lindquist](https://github.com/johnlindquist)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT  
A TypeScript-based system for configuring and customizing Claude Code hooks with a powerful and flexible interface.

[`Linting, testing, and notifications (in go)`](https://github.com/Veraticus/nix-config/tree/main/home-manager/claude-code/hooks) &amp;nbsp; by &amp;nbsp; [Josh Symonds](https://github.com/Veraticus)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT  
Nice set of hooks for enforcing code quality (linting, testing, notifications), with a nice configuration setup as well.

[`TDD Guard`](https://github.com/nizos/tdd-guard) &amp;nbsp; by &amp;nbsp; [Nizar Selander](https://github.com/nizos)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT  
A hooks-driven system that monitors file operations in real-time and blocks changes that violate TDD principles.

&lt;br&gt;

## Slash-Commands üî™

### Version Control &amp; Git

[`/bug-fix`](https://github.com/danielscholl/mvn-mcp-server/blob/main/.claude/commands/bug-fix.md) &amp;nbsp; by &amp;nbsp; [danielscholl](https://github.com/danielscholl)    
Streamlines bug fixing by creating a GitHub issue first, then a feature branch for implementing and thoroughly testing the solution before merging.

[`/commit`](https://github.com/evmts/tevm-monorepo/blob/main/.claude/commands/commit.md) &amp;nbsp; by &amp;nbsp; [evmts](https://github.com/evmts)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT  
Creates git commits using conventional commit format with appropriate emojis, following project standards and creating descriptive messages that explain the purpose of changes.

[`/commit-fast`](https://github.com/steadycursor/steadystart/blob/main/.claude/commands/2-commit-fast.md) &amp;nbsp; by &amp;nbsp; [steadycursor](https://github.com/steadycursor)    
Automates git commit process by selecting the first suggested message, generating structured commits with consistent formatting while skipping manual confirmation and removing Claude co-Contributorship footer

[`/create-pr`](https://github.com/toyamarinyon/giselle/blob/main/.claude/commands/create-pr.md) &amp;nbsp; by &amp;nbsp; [toyamarinyon](https://github.com/toyamarinyon)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0  
Streamlines pull request creation by handling the entire workflow: creating a new branch, committing changes, formatting modified files with Biome, and submitting the PR.

[`/create-pull-request`](https://github.com/liam-hq/liam/blob/main/.claude/commands/create-pull-request.md) &amp;nbsp; by &amp;nbsp; [liam-hq](https://github.com/liam-hq)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0  
Provides comprehensive PR creation guidance with GitHub CLI, enforcing title conventions, following template structure, and offering concrete command examples with best practices.

[`/create-worktrees`](https://github.com/evmts/tevm-monorepo/blob/main/.claude/commands/create-worktrees.md) &amp;nbsp; by &amp;nbsp; [evmts](https://github.com/evmts)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT  
Creates git worktrees for all open PRs or specific branches, handling branches with slashes, cleaning up stale worktrees, and supporting custom branch creation for development.

[`/fix-github-issue`](https://github.com/jeremymailen/kotlinter-gradle/blob/master/.claude/commands/fix-github-issue.md) &amp;nbsp; by &amp;nbsp; [jeremymailen](https://github.com/jeremymailen)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0  
Analyzes and fixes GitHub issues using a structured approach with GitHub CLI for issue details, implementing necessary code changes, running tests, and creating proper commit messages.

[`/fix-issue`](https://github.com/metabase/metabase/blob/master/.claude/commands/fix-issue.md) &amp;nbsp; by &amp;nbsp; [metabase](https://github.com/metabase)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;NOASSERTION  
Addresses GitHub issues by taking issue number as parameter, analyzing context, implementing solution, and testing/validating the fix for proper integration.

[`/fix-pr`](https://github.com/metabase/metabase/blob/master/.claude/commands/fix-pr.md) &amp;nbsp; by &amp;nbsp; [metabase](https://github.com/metabase)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;NOASSERTION  
Fetches and fixes unresolved PR comments by automatically retrieving feedback, addressing reviewer concerns, making targeted code improvements, and streamlining the review process.

[`/husky`](https://github.com/evmts/tevm-monorepo/blob/main/.claude/commands/husky.md) &amp;nbsp; by &amp;nbsp; [evmts](https://github.com/evmts)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT  
Sets up and manages Husky Git hooks by configuring pre-commit hooks, establishing commit message standards, integrating with linting tools, and ensuring code quality on commits.

[`/pr-review`](https://github.com/arkavo-org/opentdf-rs/blob/main/.claude/commands/pr-review.md) &amp;nbsp; by &amp;nbsp; [arkavo-org](https://github.com/arkavo-org)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT  
Reviews pull request changes to provide feedback, check for issues, and suggest improvements before merging into the main codebase.

[`/update-branch-name`](https://github.com/giselles-ai/giselle/blob/main/.claude/commands/update-branch-name.md) &amp;nbsp; by &amp;nbsp; [giselles-ai](https://github.com/giselles-ai)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0  
Updates branch names with proper prefixes and formats, enforcing naming conventions, supporting semantic prefixes, and managing remote branch updates.


### Code Analysis &amp; Testing

[`/check`](https://github.com/rygwdn/slack-tools/blob/main/.claude/commands/check.md) &amp;nbsp; by &amp;nbsp; [rygwdn](https://github.com/rygwdn)    
Performs comprehensive code quality and security checks, featuring static analysis integration, security vulnerability scanning, code style enforcement, and detailed reporting.

[`/clean`](https://github.com/Graphlet-AI/eridu/blob/main/.claude/commands/clean.md) &amp;nbsp; by &amp;nbsp; [Graphlet-AI](https://github.com/Graphlet-AI)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0  
Addresses code formatting and quality issues by fixing black formatting problems, organizing imports with isort, resolving flake8 linting issues, and correcting mypy type errors.

[`/code_analysis`](https://github.com/kingler/n8n_agent/blob/main/.claude/commands/code_analysis.md) &amp;nbsp; by &amp;nbsp; [kingler](https://github.com/kingler)    
Provides a menu of advanced code analysis commands for deep inspection, including knowledge graph generation, optimization suggestions, and quality evaluation.

[`/optimize`](https://github.com/to4iki/ai-project-rules/blob/main/.claude/commands/optimize.md) &amp;nbsp; by &amp;nbsp; [to4iki](https://github.com/to4iki)  &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT  
Analyzes code performance to identify bottlenecks, proposing concrete optimizations with implementation guidance for improved application performance.

[`/repro-issue`](https://github.com/rzykov/metabase/blob/master/.claude/commands/repro-issue.md) &amp;nbsp; by &amp;nbsp; [

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[myshell-ai/OpenVoice]]></title>
            <link>https://github.com/myshell-ai/OpenVoice</link>
            <guid>https://github.com/myshell-ai/OpenVoice</guid>
            <pubDate>Thu, 24 Jul 2025 00:04:30 GMT</pubDate>
            <description><![CDATA[Instant voice cloning by MIT and MyShell. Audio foundation model.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/myshell-ai/OpenVoice">myshell-ai/OpenVoice</a></h1>
            <p>Instant voice cloning by MIT and MyShell. Audio foundation model.</p>
            <p>Language: Python</p>
            <p>Stars: 33,412</p>
            <p>Forks: 3,557</p>
            <p>Stars today: 81 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;div&gt;&amp;nbsp;&lt;/div&gt;
  &lt;img src=&quot;resources/openvoicelogo.jpg&quot; width=&quot;400&quot;/&gt; 

[Paper](https://arxiv.org/abs/2312.01479) |
[Website](https://research.myshell.ai/open-voice) &lt;br&gt; &lt;br&gt;
&lt;a href=&quot;https://trendshift.io/repositories/6161&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/6161&quot; alt=&quot;myshell-ai%2FOpenVoice | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

## Introduction

### OpenVoice V1

As we detailed in our [paper](https://arxiv.org/abs/2312.01479) and [website](https://research.myshell.ai/open-voice), the advantages of OpenVoice are three-fold:

**1. Accurate Tone Color Cloning.**
OpenVoice can accurately clone the reference tone color and generate speech in multiple languages and accents.

**2. Flexible Voice Style Control.**
OpenVoice enables granular control over voice styles, such as emotion and accent, as well as other style parameters including rhythm, pauses, and intonation. 

**3. Zero-shot Cross-lingual Voice Cloning.**
Neither of the language of the generated speech nor the language of the reference speech needs to be presented in the massive-speaker multi-lingual training dataset.

### OpenVoice V2

In April 2024, we released OpenVoice V2, which includes all features in V1 and has:

**1. Better Audio Quality.**
OpenVoice V2 adopts a different training strategy that delivers better audio quality.

**2. Native Multi-lingual Support.**
English, Spanish, French, Chinese, Japanese and Korean are natively supported in OpenVoice V2.

**3. Free Commercial Use.**
Starting from April 2024, both V2 and V1 are released under MIT License. Free for commercial use.

[Video](https://github.com/myshell-ai/OpenVoice/assets/40556743/3cba936f-82bf-476c-9e52-09f0f417bb2f)

OpenVoice has been powering the instant voice cloning capability of [myshell.ai](https://app.myshell.ai/explore) since May 2023. Until Nov 2023, the voice cloning model has been used tens of millions of times by users worldwide, and witnessed the explosive user growth on the platform.

## Main Contributors

- [Zengyi Qin](https://www.qinzy.tech) at MIT
- [Wenliang Zhao](https://wl-zhao.github.io) at Tsinghua University
- [Xumin Yu](https://yuxumin.github.io) at Tsinghua University
- [Ethan Sun](https://twitter.com/ethan_myshell) at MyShell

## How to Use
Please see [usage](docs/USAGE.md) for detailed instructions.

## Common Issues

Please see [QA](docs/QA.md) for common questions and answers. We will regularly update the question and answer list.

## Citation
```
@article{qin2023openvoice,
  title={OpenVoice: Versatile Instant Voice Cloning},
  author={Qin, Zengyi and Zhao, Wenliang and Yu, Xumin and Sun, Xin},
  journal={arXiv preprint arXiv:2312.01479},
  year={2023}
}
```

## License
OpenVoice V1 and V2 are MIT Licensed. Free for both commercial and research use.

## Acknowledgements
This implementation is based on several excellent projects, [TTS](https://github.com/coqui-ai/TTS), [VITS](https://github.com/jaywalnut310/vits), and [VITS2](https://github.com/daniilrobnikov/vits2). Thanks for their awesome work!
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[unclecode/crawl4ai]]></title>
            <link>https://github.com/unclecode/crawl4ai</link>
            <guid>https://github.com/unclecode/crawl4ai</guid>
            <pubDate>Thu, 24 Jul 2025 00:04:29 GMT</pubDate>
            <description><![CDATA[üöÄü§ñ Crawl4AI: Open-source LLM Friendly Web Crawler & Scraper. Don't be shy, join here: https://discord.gg/jP8KfhDhyN]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/unclecode/crawl4ai">unclecode/crawl4ai</a></h1>
            <p>üöÄü§ñ Crawl4AI: Open-source LLM Friendly Web Crawler & Scraper. Don't be shy, join here: https://discord.gg/jP8KfhDhyN</p>
            <p>Language: Python</p>
            <p>Stars: 49,432</p>
            <p>Forks: 4,785</p>
            <p>Stars today: 338 stars today</p>
            <h2>README</h2><pre># üöÄü§ñ Crawl4AI: Open-source LLM Friendly Web Crawler &amp; Scraper.

&lt;div align=&quot;center&quot;&gt;

&lt;a href=&quot;https://trendshift.io/repositories/11716&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/11716&quot; alt=&quot;unclecode%2Fcrawl4ai | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

[![GitHub Stars](https://img.shields.io/github/stars/unclecode/crawl4ai?style=social)](https://github.com/unclecode/crawl4ai/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/unclecode/crawl4ai?style=social)](https://github.com/unclecode/crawl4ai/network/members)

[![PyPI version](https://badge.fury.io/py/crawl4ai.svg)](https://badge.fury.io/py/crawl4ai)
[![Python Version](https://img.shields.io/pypi/pyversions/crawl4ai)](https://pypi.org/project/crawl4ai/)
[![Downloads](https://static.pepy.tech/badge/crawl4ai/month)](https://pepy.tech/project/crawl4ai)

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://x.com/crawl4ai&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Follow%20on%20X-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white&quot; alt=&quot;Follow on X&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://www.linkedin.com/company/crawl4ai&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Follow%20on%20LinkedIn-0077B5?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white&quot; alt=&quot;Follow on LinkedIn&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/jP8KfhDhyN&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Join%20our%20Discord-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;Join our Discord&quot; /&gt;
    &lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

Crawl4AI is the #1 trending GitHub repository, actively maintained by a vibrant community. It delivers blazing-fast, AI-ready web crawling tailored for LLMs, AI agents, and data pipelines. Open source, flexible, and built for real-time performance, Crawl4AI empowers developers with unmatched speed, precision, and deployment ease.  

[‚ú® Check out latest update v0.7.0](#-recent-updates)

üéâ **Version 0.7.0 is now available!** The Adaptive Intelligence Update introduces groundbreaking features: Adaptive Crawling that learns website patterns, Virtual Scroll support for infinite pages, intelligent Link Preview with 3-layer scoring, Async URL Seeder for massive discovery, and significant performance improvements. [Read the release notes ‚Üí](https://docs.crawl4ai.com/blog/release-v0.7.0)

&lt;details&gt;
&lt;summary&gt;ü§ì &lt;strong&gt;My Personal Story&lt;/strong&gt;&lt;/summary&gt;

My journey with computers started in childhood when my dad, a computer scientist, introduced me to an Amstrad computer. Those early days sparked a fascination with technology, leading me to pursue computer science and specialize in NLP during my postgraduate studies. It was during this time that I first delved into web crawling, building tools to help researchers organize papers and extract information from publications a challenging yet rewarding experience that honed my skills in data extraction.

Fast forward to 2023, I was working on a tool for a project and needed a crawler to convert a webpage into markdown. While exploring solutions, I found one that claimed to be open-source but required creating an account and generating an API token. Worse, it turned out to be a SaaS model charging $16, and its quality didn‚Äôt meet my standards. Frustrated, I realized this was a deeper problem. That frustration turned into turbo anger mode, and I decided to build my own solution. In just a few days, I created Crawl4AI. To my surprise, it went viral, earning thousands of GitHub stars and resonating with a global community.

I made Crawl4AI open-source for two reasons. First, it‚Äôs my way of giving back to the open-source community that has supported me throughout my career. Second, I believe data should be accessible to everyone, not locked behind paywalls or monopolized by a few. Open access to data lays the foundation for the democratization of AI, a vision where individuals can train their own models and take ownership of their information. This library is the first step in a larger journey to create the best open-source data extraction and generation tool the world has ever seen, built collaboratively by a passionate community.

Thank you to everyone who has supported this project, used it, and shared feedback. Your encouragement motivates me to dream even bigger. Join us, file issues, submit PRs, or spread the word. Together, we can build a tool that truly empowers people to access their own data and reshape the future of AI.
&lt;/details&gt;

## üßê Why Crawl4AI?

1. **Built for LLMs**: Creates smart, concise Markdown optimized for RAG and fine-tuning applications.  
2. **Lightning Fast**: Delivers results 6x faster with real-time, cost-efficient performance.  
3. **Flexible Browser Control**: Offers session management, proxies, and custom hooks for seamless data access.  
4. **Heuristic Intelligence**: Uses advanced algorithms for efficient extraction, reducing reliance on costly models.  
5. **Open Source &amp; Deployable**: Fully open-source with no API keys‚Äîready for Docker and cloud integration.  
6. **Thriving Community**: Actively maintained by a vibrant community and the #1 trending GitHub repository.

## üöÄ Quick Start 

1. Install Crawl4AI:
```bash
# Install the package
pip install -U crawl4ai

# For pre release versions
pip install crawl4ai --pre

# Run post-installation setup
crawl4ai-setup

# Verify your installation
crawl4ai-doctor
```

If you encounter any browser-related issues, you can install them manually:
```bash
python -m playwright install --with-deps chromium
```

2. Run a simple web crawl with Python:
```python
import asyncio
from crawl4ai import *

async def main():
    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(
            url=&quot;https://www.nbcnews.com/business&quot;,
        )
        print(result.markdown)

if __name__ == &quot;__main__&quot;:
    asyncio.run(main())
```

3. Or use the new command-line interface:
```bash
# Basic crawl with markdown output
crwl https://www.nbcnews.com/business -o markdown

# Deep crawl with BFS strategy, max 10 pages
crwl https://docs.crawl4ai.com --deep-crawl bfs --max-pages 10

# Use LLM extraction with a specific question
crwl https://www.example.com/products -q &quot;Extract all product prices&quot;
```

## ‚ú® Features 

&lt;details&gt;
&lt;summary&gt;üìù &lt;strong&gt;Markdown Generation&lt;/strong&gt;&lt;/summary&gt;

- üßπ **Clean Markdown**: Generates clean, structured Markdown with accurate formatting.
- üéØ **Fit Markdown**: Heuristic-based filtering to remove noise and irrelevant parts for AI-friendly processing.
- üîó **Citations and References**: Converts page links into a numbered reference list with clean citations.
- üõ†Ô∏è **Custom Strategies**: Users can create their own Markdown generation strategies tailored to specific needs.
- üìö **BM25 Algorithm**: Employs BM25-based filtering for extracting core information and removing irrelevant content. 
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üìä &lt;strong&gt;Structured Data Extraction&lt;/strong&gt;&lt;/summary&gt;

- ü§ñ **LLM-Driven Extraction**: Supports all LLMs (open-source and proprietary) for structured data extraction.
- üß± **Chunking Strategies**: Implements chunking (topic-based, regex, sentence-level) for targeted content processing.
- üåå **Cosine Similarity**: Find relevant content chunks based on user queries for semantic extraction.
- üîé **CSS-Based Extraction**: Fast schema-based data extraction using XPath and CSS selectors.
- üîß **Schema Definition**: Define custom schemas for extracting structured JSON from repetitive patterns.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üåê &lt;strong&gt;Browser Integration&lt;/strong&gt;&lt;/summary&gt;

- üñ•Ô∏è **Managed Browser**: Use user-owned browsers with full control, avoiding bot detection.
- üîÑ **Remote Browser Control**: Connect to Chrome Developer Tools Protocol for remote, large-scale data extraction.
- üë§ **Browser Profiler**: Create and manage persistent profiles with saved authentication states, cookies, and settings.
- üîí **Session Management**: Preserve browser states and reuse them for multi-step crawling.
- üß© **Proxy Support**: Seamlessly connect to proxies with authentication for secure access.
- ‚öôÔ∏è **Full Browser Control**: Modify headers, cookies, user agents, and more for tailored crawling setups.
- üåç **Multi-Browser Support**: Compatible with Chromium, Firefox, and WebKit.
- üìê **Dynamic Viewport Adjustment**: Automatically adjusts the browser viewport to match page content, ensuring complete rendering and capturing of all elements.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üîé &lt;strong&gt;Crawling &amp; Scraping&lt;/strong&gt;&lt;/summary&gt;

- üñºÔ∏è **Media Support**: Extract images, audio, videos, and responsive image formats like `srcset` and `picture`.
- üöÄ **Dynamic Crawling**: Execute JS and wait for async or sync for dynamic content extraction.
- üì∏ **Screenshots**: Capture page screenshots during crawling for debugging or analysis.
- üìÇ **Raw Data Crawling**: Directly process raw HTML (`raw:`) or local files (`file://`).
- üîó **Comprehensive Link Extraction**: Extracts internal, external links, and embedded iframe content.
- üõ†Ô∏è **Customizable Hooks**: Define hooks at every step to customize crawling behavior.
- üíæ **Caching**: Cache data for improved speed and to avoid redundant fetches.
- üìÑ **Metadata Extraction**: Retrieve structured metadata from web pages.
- üì° **IFrame Content Extraction**: Seamless extraction from embedded iframe content.
- üïµÔ∏è **Lazy Load Handling**: Waits for images to fully load, ensuring no content is missed due to lazy loading.
- üîÑ **Full-Page Scanning**: Simulates scrolling to load and capture all dynamic content, perfect for infinite scroll pages.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üöÄ &lt;strong&gt;Deployment&lt;/strong&gt;&lt;/summary&gt;

- üê≥ **Dockerized Setup**: Optimized Docker image with FastAPI server for easy deployment.
- üîë **Secure Authentication**: Built-in JWT token authentication for API security.
- üîÑ **API Gateway**: One-click deployment with secure token authentication for API-based workflows.
- üåê **Scalable Architecture**: Designed for mass-scale production and optimized server performance.
- ‚òÅÔ∏è **Cloud Deployment**: Ready-to-deploy configurations for major cloud platforms.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üéØ &lt;strong&gt;Additional Features&lt;/strong&gt;&lt;/summary&gt;

- üï∂Ô∏è **Stealth Mode**: Avoid bot detection by mimicking real users.
- üè∑Ô∏è **Tag-Based Content Extraction**: Refine crawling based on custom tags, headers, or metadata.
- üîó **Link Analysis**: Extract and analyze all links for detailed data exploration.
- üõ°Ô∏è **Error Handling**: Robust error management for seamless execution.
- üîê **CORS &amp; Static Serving**: Supports filesystem-based caching and cross-origin requests.
- üìñ **Clear Documentation**: Simplified and updated guides for onboarding and advanced usage.
- üôå **Community Recognition**: Acknowledges contributors and pull requests for transparency.

&lt;/details&gt;

## Try it Now!

‚ú® Play around with this [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1SgRPrByQLzjRfwoRNq1wSGE9nYY_EE8C?usp=sharing)

‚ú® Visit our [Documentation Website](https://docs.crawl4ai.com/)

## Installation üõ†Ô∏è

Crawl4AI offers flexible installation options to suit various use cases. You can install it as a Python package or use Docker.

&lt;details&gt;
&lt;summary&gt;üêç &lt;strong&gt;Using pip&lt;/strong&gt;&lt;/summary&gt;

Choose the installation option that best fits your needs:

### Basic Installation

For basic web crawling and scraping tasks:

```bash
pip install crawl4ai
crawl4ai-setup # Setup the browser
```

By default, this will install the asynchronous version of Crawl4AI, using Playwright for web crawling.

üëâ **Note**: When you install Crawl4AI, the `crawl4ai-setup` should automatically install and set up Playwright. However, if you encounter any Playwright-related errors, you can manually install it using one of these methods:

1. Through the command line:

   ```bash
   playwright install
   ```

2. If the above doesn&#039;t work, try this more specific command:

   ```bash
   python -m playwright install chromium
   ```

This second method has proven to be more reliable in some cases.

---

### Installation with Synchronous Version

The sync version is deprecated and will be removed in future versions. If you need the synchronous version using Selenium:

```bash
pip install crawl4ai[sync]
```

---

### Development Installation

For contributors who plan to modify the source code:

```bash
git clone https://github.com/unclecode/crawl4ai.git
cd crawl4ai
pip install -e .                    # Basic installation in editable mode
```

Install optional features:

```bash
pip install -e &quot;.[torch]&quot;           # With PyTorch features
pip install -e &quot;.[transformer]&quot;     # With Transformer features
pip install -e &quot;.[cosine]&quot;          # With cosine similarity features
pip install -e &quot;.[sync]&quot;            # With synchronous crawling (Selenium)
pip install -e &quot;.[all]&quot;             # Install all optional features
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üê≥ &lt;strong&gt;Docker Deployment&lt;/strong&gt;&lt;/summary&gt;

&gt; üöÄ **Now Available!** Our completely redesigned Docker implementation is here! This new solution makes deployment more efficient and seamless than ever.

### New Docker Features

The new Docker implementation includes:
- **Browser pooling** with page pre-warming for faster response times
- **Interactive playground** to test and generate request code
- **MCP integration** for direct connection to AI tools like Claude Code
- **Comprehensive API endpoints** including HTML extraction, screenshots, PDF generation, and JavaScript execution
- **Multi-architecture support** with automatic detection (AMD64/ARM64)
- **Optimized resources** with improved memory management

### Getting Started

```bash
# Pull and run the latest release candidate
docker pull unclecode/crawl4ai:0.7.0
docker run -d -p 11235:11235 --name crawl4ai --shm-size=1g unclecode/crawl4ai:0.7.0

# Visit the playground at http://localhost:11235/playground
```

For complete documentation, see our [Docker Deployment Guide](https://docs.crawl4ai.com/core/docker-deployment/).

&lt;/details&gt;

---

### Quick Test

Run a quick test (works for both Docker options):

```python
import requests

# Submit a crawl job
response = requests.post(
    &quot;http://localhost:11235/crawl&quot;,
    json={&quot;urls&quot;: [&quot;https://example.com&quot;], &quot;priority&quot;: 10}
)
if response.status_code == 200:
    print(&quot;Crawl job submitted successfully.&quot;)
    
if &quot;results&quot; in response.json():
    results = response.json()[&quot;results&quot;]
    print(&quot;Crawl job completed. Results:&quot;)
    for result in results:
        print(result)
else:
    task_id = response.json()[&quot;task_id&quot;]
    print(f&quot;Crawl job submitted. Task ID:: {task_id}&quot;)
    result = requests.get(f&quot;http://localhost:11235/task/{task_id}&quot;)
```

For more examples, see our [Docker Examples](https://github.com/unclecode/crawl4ai/blob/main/docs/examples/docker_example.py). For advanced configuration, environment variables, and usage examples, see our [Docker Deployment Guide](https://docs.crawl4ai.com/basic/docker-deployment/).

&lt;/details&gt;


## üî¨ Advanced Usage Examples üî¨

You can check the project structure in the directory [https://github.com/unclecode/crawl4ai/docs/examples](docs/examples). Over there, you can find a variety of examples; here, some popular examples are shared.

&lt;details&gt;
&lt;summary&gt;üìù &lt;strong&gt;Heuristic Markdown Generation with Clean and Fit Markdown&lt;/strong&gt;&lt;/summary&gt;

```python
import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode
from crawl4ai.content_filter_strategy import PruningContentFilter, BM25ContentFilter
from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator

async def main():
    browser_config = BrowserConfig(
        headless=True,  
        verbose=True,
    )
    run_config = CrawlerRunConfig(
        cache_mode=CacheMode.ENABLED,
        markdown_generator=DefaultMarkdownGenerator(
            content_filter=PruningContentFilter(threshold=0.48, threshold_type=&quot;fixed&quot;, min_word_threshold=0)
        ),
        # markdown_generator=DefaultMarkdownGenerator(
        #     content_filter=BM25ContentFilter(user_query=&quot;WHEN_WE_FOCUS_BASED_ON_A_USER_QUERY&quot;, bm25_threshold=1.0)
        # ),
    )
    
    async with AsyncWebCrawler(config=browser_config) as crawler:
        result = await crawler.arun(
            url=&quot;https://docs.micronaut.io/4.7.6/guide/&quot;,
            config=run_config
        )
        print(len(result.markdown.raw_markdown))
        print(len(result.markdown.fit_markdown))

if __name__ == &quot;__main__&quot;:
    asyncio.run(main())
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üñ•Ô∏è &lt;strong&gt;Executing JavaScript &amp; Extract Structured Data without LLMs&lt;/strong&gt;&lt;/summary&gt;

```python
import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode
from crawl4ai import JsonCssExtractionStrategy
import json

async def main():
    schema = {
    &quot;name&quot;: &quot;KidoCode Courses&quot;,
    &quot;baseSelector&quot;: &quot;section.charge-methodology .w-tab-content &gt; div&quot;,
    &quot;fields&quot;: [
        {
            &quot;name&quot;: &quot;section_title&quot;,
            &quot;selector&quot;: &quot;h3.heading-50&quot;,
            &quot;type&quot;: &quot;text&quot;,
        },
        {
            &quot;name&quot;: &quot;section_description&quot;,
            &quot;selector&quot;: &quot;.charge-content&quot;,
            &quot;type&quot;: &quot;text&quot;,
        },
        {
            &quot;name&quot;: &quot;course_name&quot;,
            &quot;selector&quot;: &quot;.text-block-93&quot;,
            &quot;type&quot;: &quot;text&quot;,
        },
        {
            &quot;name&quot;: &quot;course_description&quot;,
            &quot;selector&quot;: &quot;.course-content-text&quot;,
            &quot;type&quot;: &quot;text&quot;,
        },
        {
            &quot;name&quot;: &quot;course_icon&quot;,
            &quot;selector&quot;: &quot;.image-92&quot;,
            &quot;type&quot;: &quot;attribute&quot;,
            &quot;attribute&quot;: &quot;src&quot;
        }
    }
}

    extraction_strategy = JsonCssExtractionStrategy(schema, verbose=True)

    browser_config = BrowserConfig(
        headless=False,
        verbose=True
    )
    run_config = CrawlerRunConfig(
        extraction_strategy=extraction_strategy,
        js_code=[&quot;&quot;&quot;(async () =&gt; {const tabs = document.querySelectorAll(&quot;section.charge-methodology .tabs-menu-3 &gt; div&quot;);for(let tab of tabs) {tab.scrollIntoView();tab.click();await new Promise(r =&gt; setTimeout(r, 500));}})();&quot;&quot;&quot;],
        cache_mode=CacheMode.BYPASS
    )
        
    async with AsyncWebCrawler(config=browser_config) as crawler:
        
        result = await crawler.arun(
            url=&quot;https://www.kidocode.com/degrees/technology&quot;,
            config=run_config
        )

        companies = json.loads(result.extracted_content)
        print(f&quot;Successfully extracted {len(companies)} companies&quot;)
        print(json.dumps(companies[0], indent=2))


if __name__ == &quot;__main__&quot;:
    asyncio.run(main())
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üìö &lt;strong&gt;Extracting Structured Data with LLMs&lt;/strong&gt;&lt;/summary&gt;

```python
import os
import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode, LLMConfig
from crawl4ai import LLMExtractionStrategy
from pydantic import BaseModel, Field

class OpenAIModelFee(BaseModel):
    model_name: str = Field(..., description=&quot;Name of the OpenAI model.&quot;)
    input_fee: str = Field(..., description=&quot;Fee for input token for the OpenAI model.&quot;)
    output_fee: str = Field(..., description=&quot;Fee for output token for the OpenAI model.&quot;)

async def main():
    browser_config = BrowserConfig(verbose=True)
    run_config = CrawlerRunConfig(
        word_count_threshold=1,
        extraction_strategy=LLMExtractionStrategy(
            # Here you can use any provider that Litellm library supports, for instance: ollama/qwen2
            # provider=&quot;ollama/qwen2&quot;, api_token=&quot;no-token&quot;, 
            llm_config = LLMConfig(provider=&quot;openai/gpt-4o&quot;, api_token=os.getenv(&#039;OPENAI_API_KEY&#039;)), 
            schema=OpenAIModelFee.schema(),
            extraction_type=&quot;schema&quot;,
            instruction=&quot;&quot;&quot;From the crawled content, extract all mentioned model names along with their fees for input and output tokens. 
            Do not miss any models in the entire content. One

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[onnx/onnx]]></title>
            <link>https://github.com/onnx/onnx</link>
            <guid>https://github.com/onnx/onnx</guid>
            <pubDate>Thu, 24 Jul 2025 00:04:28 GMT</pubDate>
            <description><![CDATA[Open standard for machine learning interoperability]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/onnx/onnx">onnx/onnx</a></h1>
            <p>Open standard for machine learning interoperability</p>
            <p>Language: Python</p>
            <p>Stars: 19,310</p>
            <p>Forks: 3,770</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre>&lt;!--
Copyright (c) ONNX Project Contributors

SPDX-License-Identifier: Apache-2.0
--&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;40%&quot; src=&quot;https://github.com/onnx/onnx/raw/main/docs/onnx-horizontal-color.png&quot; /&gt;&lt;/p&gt;

[![PyPI - Version](https://img.shields.io/pypi/v/onnx.svg)](https://pypi.org/project/onnx)
[![CI](https://github.com/onnx/onnx/actions/workflows/main.yml/badge.svg)](https://github.com/onnx/onnx/actions/workflows/main.yml)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/3313/badge)](https://bestpractices.coreinfrastructure.org/projects/3313)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/onnx/onnx/badge)](https://api.securityscorecards.dev/projects/github.com/onnx/onnx)
[![REUSE compliant](https://api.reuse.software/badge/github.com/onnx/onnx)](https://api.reuse.software/info/github.com/onnx/onnx)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)
[![Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

[Open Neural Network Exchange (ONNX)](https://onnx.ai) is an open ecosystem that empowers AI developers
to choose the right tools as their project evolves. ONNX provides an open source format for AI models, both deep learning and traditional ML. It defines an extensible computation graph model, as well as definitions of built-in operators and standard
data types. Currently we focus on the capabilities needed for inferencing (scoring).

ONNX is [widely supported](http://onnx.ai/supported-tools) and can be found in many frameworks, tools, and hardware. Enabling interoperability between different frameworks and streamlining the path from research to production helps increase the speed of innovation in the AI community. We invite the community to join us and further evolve ONNX.

# Use ONNX

* [Documentation of ONNX Python Package](https://onnx.ai/onnx/)
* [Tutorials for creating ONNX models](https://github.com/onnx/tutorials)
* [Pre-trained ONNX models](https://github.com/onnx/models)

# Learn about the ONNX spec

* [Overview](https://github.com/onnx/onnx/blob/main/docs/Overview.md)
* [ONNX intermediate representation spec](https://github.com/onnx/onnx/blob/main/docs/IR.md)
* [Versioning principles of the spec](https://github.com/onnx/onnx/blob/main/docs/Versioning.md)
* [Operators documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md)
* [Operators documentation](https://onnx.ai/onnx/operators/index.html) (latest release)
* [Python API Overview](https://github.com/onnx/onnx/blob/main/docs/PythonAPIOverview.md)

# Programming utilities for working with ONNX Graphs

* [Shape and Type Inference](https://github.com/onnx/onnx/blob/main/docs/ShapeInference.md)
* [Graph Optimization](https://github.com/onnx/optimizer)
* [Opset Version Conversion](https://github.com/onnx/onnx/blob/main/docs/docsgen/source/api/version_converter.md)

# Contribute

ONNX is a community project and the open governance model is described [here](https://github.com/onnx/onnx/blob/main/community/readme.md). We encourage you to join the effort and contribute feedback, ideas, and code. You can participate in the [Special Interest Groups](https://github.com/onnx/onnx/blob/main/community/sigs.md) and [Working Groups](https://github.com/onnx/onnx/blob/main/community/working-groups.md) to shape the future of ONNX.

Check out our [contribution guide](https://github.com/onnx/onnx/blob/main/CONTRIBUTING.md) to get started.

If you think some operator should be added to ONNX specification, please read
[this document](https://github.com/onnx/onnx/blob/main/docs/AddNewOp.md).

# Community meetings

The schedules of the regular meetings of the Steering Committee, the working groups and the SIGs can be found [here](https://onnx.ai/calendar)

Community Meetups are held at least once a year. Content from previous community meetups are at:

* 2020.04.09 &lt;https://lf-aidata.atlassian.net/wiki/spaces/DL/pages/14091402/LF+AI+Day+-ONNX+Community+Virtual+Meetup+-+Silicon+Valley+-+2020+April+9&gt;
* 2020.10.14 &lt;https://lf-aidata.atlassian.net/wiki/spaces/DL/pages/14092138/LF+AI+Day+-+ONNX+Community+Workshop+-+2020+October+14&gt;
* 2021.03.24 &lt;https://lf-aidata.atlassian.net/wiki/spaces/DL/pages/14092424/Instructions+for+Event+Hosts+-+LF+AI+Data+Day+-+ONNX+Virtual+Community+Meetup+-+March+2021&gt;
* 2021.10.21 &lt;https://lf-aidata.atlassian.net/wiki/spaces/DL/pages/14093194/LF+AI+Data+Day+ONNX+Community+Virtual+Meetup+-+October+2021&gt;
* 2022.06.24 &lt;https://lf-aidata.atlassian.net/wiki/spaces/DL/pages/14093969/ONNX+Community+Day+-+2022+June+24&gt;
* 2023.06.28 &lt;https://lf-aidata.atlassian.net/wiki/spaces/DL/pages/14094507/ONNX+Community+Day+2023+-+June+28&gt;



# Discuss

We encourage you to open [Issues](https://github.com/onnx/onnx/issues), or use [Slack](https://lfaifoundation.slack.com/) (If you have not joined yet, please use this [link](https://join.slack.com/t/lfaifoundation/shared_invite/zt-o65errpw-gMTbwNr7FnNbVXNVFkmyNA) to join the group) for more real-time discussion.

# Follow Us

Stay up to date with the latest ONNX news. [[Facebook](https://www.facebook.com/onnxai/)] [[Twitter](https://twitter.com/onnxai)]

# Roadmap

A roadmap process takes place every year. More details can be found [here](https://github.com/onnx/steering-committee/tree/main/roadmap)

# Installation

ONNX released packages are published in PyPi.

```sh
pip install onnx # or pip install onnx[reference] for optional reference implementation dependencies
```

[ONNX weekly packages](https://pypi.org/project/onnx-weekly/) are published in PyPI to enable experimentation and early testing.

Detailed install instructions, including Common Build Options and Common Errors can be found [here](https://github.com/onnx/onnx/blob/main/INSTALL.md)

# Testing

ONNX uses [pytest](https://docs.pytest.org) as test driver. In order to run tests, you will first need to install `pytest`:

```sh
pip install pytest
```

After installing pytest, use the following command to run tests.

```sh
pytest
```

# Development

Check out the [contributor guide](https://github.com/onnx/onnx/blob/main/CONTRIBUTING.md) for instructions.

# License

[Apache License v2.0](LICENSE)

# Code of Conduct

[ONNX Open Source Code of Conduct](https://onnx.ai/codeofconduct.html)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[QwenLM/Qwen-Agent]]></title>
            <link>https://github.com/QwenLM/Qwen-Agent</link>
            <guid>https://github.com/QwenLM/Qwen-Agent</guid>
            <pubDate>Thu, 24 Jul 2025 00:04:27 GMT</pubDate>
            <description><![CDATA[Agent framework and applications built upon Qwen>=3.0, featuring Function Calling, MCP, Code Interpreter, RAG, Chrome extension, etc.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/QwenLM/Qwen-Agent">QwenLM/Qwen-Agent</a></h1>
            <p>Agent framework and applications built upon Qwen>=3.0, featuring Function Calling, MCP, Code Interpreter, RAG, Chrome extension, etc.</p>
            <p>Language: Python</p>
            <p>Stars: 10,262</p>
            <p>Forks: 907</p>
            <p>Stars today: 66 stars today</p>
            <h2>README</h2><pre>&lt;!---
Copyright 2023 The Qwen team, Alibaba Group. All rights reserved.

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

[‰∏≠Êñá](https://github.com/QwenLM/Qwen-Agent/blob/main/README_CN.md) ÔΩú English

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/logo_qwen_agent.png&quot; width=&quot;400&quot;/&gt;
&lt;p&gt;
&lt;br&gt;

&lt;p align=&quot;center&quot;&gt;
          üíú &lt;a href=&quot;https://chat.qwen.ai/&quot;&gt;&lt;b&gt;Qwen Chat&lt;/b&gt;&lt;/a&gt;&amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbspü§ó &lt;a href=&quot;https://huggingface.co/Qwen&quot;&gt;Hugging Face&lt;/a&gt;&amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbspü§ñ &lt;a href=&quot;https://modelscope.cn/organization/qwen&quot;&gt;ModelScope&lt;/a&gt;&amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbsp üìë &lt;a href=&quot;https://qwenlm.github.io/&quot;&gt;Blog&lt;/a&gt; &amp;nbsp&amp;nbsp ÔΩú &amp;nbsp&amp;nbspüìñ &lt;a href=&quot;https://qwen.readthedocs.io/&quot;&gt;Documentation&lt;/a&gt;

&lt;br&gt;
üí¨ &lt;a href=&quot;https://github.com/QwenLM/Qwen/blob/main/assets/wechat.png&quot;&gt;WeChat (ÂæÆ‰ø°)&lt;/a&gt;&amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbspü´® &lt;a href=&quot;https://discord.gg/CV4E9rpNSD&quot;&gt;Discord&lt;/a&gt;&amp;nbsp&amp;nbsp
&lt;/p&gt;


Qwen-Agent is a framework for developing LLM applications based on the instruction following, tool usage, planning, and
memory capabilities of Qwen.
It also comes with example applications such as Browser Assistant, Code Interpreter, and Custom Assistant.
Now Qwen-Agent plays as the backend of [Qwen Chat](https://chat.qwen.ai/).

# News
* üî•üî•üî• Jul 23, 2025: Add [Qwen3-Coder Tool-call Demo](./examples/assistant_qwen3_coder.py); Added native API tool call interface support, such as using vLLM&#039;s built-in tool call parsing.
* üî•üî•üî• May 1, 2025: Add [Qwen3 Tool-call Demo](./examples/assistant_qwen3.py), and add [MCP Cookbooks](./examples/).
* Mar 18, 2025: Support for the `reasoning_content` field; adjust the default [Function Call template](./qwen_agent/llm/fncall_prompts/nous_fncall_prompt.py), which is applicable to the Qwen2.5 series general models and QwQ-32B. If you need to use the old version of the template, please refer to the [example](./examples/function_calling.py) for passing parameters.
* Mar 7, 2025: Added [QwQ-32B Tool-call Demo](./examples/assistant_qwq.py). It supports parallel, multi-step, and multi-turn tool calls.
* Dec 3, 2024: Upgrade GUI to Gradio 5 based. Note: GUI requires Python 3.10 or higher.
* Sep 18, 2024: Added [Qwen2.5-Math Demo](./examples/tir_math.py) to showcase the Tool-Integrated Reasoning capabilities of Qwen2.5-Math. Note: The python executor is not sandboxed and is intended for local testing only, not for production use.

# Getting Started

## Installation

- Install the stable version from PyPI:
```bash
pip install -U &quot;qwen-agent[gui,rag,code_interpreter,mcp]&quot;
# Or use `pip install -U qwen-agent` for the minimal requirements.
# The optional requirements, specified in double brackets, are:
#   [gui] for Gradio-based GUI support;
#   [rag] for RAG support;
#   [code_interpreter] for Code Interpreter support;
#   [mcp] for MCP support.
```

- Alternatively, you can install the latest development version from the source:
```bash
git clone https://github.com/QwenLM/Qwen-Agent.git
cd Qwen-Agent
pip install -e ./&quot;[gui,rag,code_interpreter,mcp]&quot;
# Or `pip install -e ./` for minimal requirements.
```

## Preparation: Model Service

You can either use the model service provided by Alibaba
Cloud&#039;s [DashScope](https://help.aliyun.com/zh/dashscope/developer-reference/quick-start), or deploy and use your own
model service using the open-source Qwen models.

- If you choose to use the model service offered by DashScope, please ensure that you set the environment
variable `DASHSCOPE_API_KEY` to your unique DashScope API key.

- Alternatively, if you prefer to deploy and use your own model service, please follow the instructions provided in the README of Qwen2 for deploying an OpenAI-compatible API service.
Specifically, consult the [vLLM](https://github.com/QwenLM/Qwen2?tab=readme-ov-file#vllm) section for high-throughput GPU deployment or the [Ollama](https://github.com/QwenLM/Qwen2?tab=readme-ov-file#ollama) section for local CPU (+GPU) deployment.
For the QwQ and Qwen3 model, it is recommended to **do not** add the `--enable-auto-tool-choice` and `--tool-call-parser hermes` parameters, as Qwen-Agent will parse the tool outputs from vLLM on its own.
For Qwen3-Coder, it is recommended to enable both of the above parameters, use vLLM&#039;s built-in tool parsing, and combine with the `use_raw_api` parameter [usage](#how-to-pass-llm-parameters-to-the-agent).

## Developing Your Own Agent

Qwen-Agent offers atomic components, such as LLMs (which inherit from `class BaseChatModel` and come with [function calling](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/function_calling.py)) and Tools (which inherit
from `class BaseTool`), along with high-level components like Agents (derived from `class Agent`).

The following example illustrates the process of creating an agent capable of reading PDF files and utilizing tools, as
well as incorporating a custom tool:

```py
import pprint
import urllib.parse
import json5
from qwen_agent.agents import Assistant
from qwen_agent.tools.base import BaseTool, register_tool
from qwen_agent.utils.output_beautify import typewriter_print


# Step 1 (Optional): Add a custom tool named `my_image_gen`.
@register_tool(&#039;my_image_gen&#039;)
class MyImageGen(BaseTool):
    # The `description` tells the agent the functionality of this tool.
    description = &#039;AI painting (image generation) service, input text description, and return the image URL drawn based on text information.&#039;
    # The `parameters` tell the agent what input parameters the tool has.
    parameters = [{
        &#039;name&#039;: &#039;prompt&#039;,
        &#039;type&#039;: &#039;string&#039;,
        &#039;description&#039;: &#039;Detailed description of the desired image content, in English&#039;,
        &#039;required&#039;: True
    }]

    def call(self, params: str, **kwargs) -&gt; str:
        # `params` are the arguments generated by the LLM agent.
        prompt = json5.loads(params)[&#039;prompt&#039;]
        prompt = urllib.parse.quote(prompt)
        return json5.dumps(
            {&#039;image_url&#039;: f&#039;https://image.pollinations.ai/prompt/{prompt}&#039;},
            ensure_ascii=False)


# Step 2: Configure the LLM you are using.
llm_cfg = {
    # Use the model service provided by DashScope:
    &#039;model&#039;: &#039;qwen-max-latest&#039;,
    &#039;model_type&#039;: &#039;qwen_dashscope&#039;,
    # &#039;api_key&#039;: &#039;YOUR_DASHSCOPE_API_KEY&#039;,
    # It will use the `DASHSCOPE_API_KEY&#039; environment variable if &#039;api_key&#039; is not set here.

    # Use a model service compatible with the OpenAI API, such as vLLM or Ollama:
    # &#039;model&#039;: &#039;Qwen2.5-7B-Instruct&#039;,
    # &#039;model_server&#039;: &#039;http://localhost:8000/v1&#039;,  # base_url, also known as api_base
    # &#039;api_key&#039;: &#039;EMPTY&#039;,

    # (Optional) LLM hyperparameters for generation:
    &#039;generate_cfg&#039;: {
        &#039;top_p&#039;: 0.8
    }
}

# Step 3: Create an agent. Here we use the `Assistant` agent as an example, which is capable of using tools and reading files.
system_instruction = &#039;&#039;&#039;After receiving the user&#039;s request, you should:
- first draw an image and obtain the image url,
- then run code `request.get(image_url)` to download the image,
- and finally select an image operation from the given document to process the image.
Please show the image using `plt.show()`.&#039;&#039;&#039;
tools = [&#039;my_image_gen&#039;, &#039;code_interpreter&#039;]  # `code_interpreter` is a built-in tool for executing code.
files = [&#039;./examples/resource/doc.pdf&#039;]  # Give the bot a PDF file to read.
bot = Assistant(llm=llm_cfg,
                system_message=system_instruction,
                function_list=tools,
                files=files)

# Step 4: Run the agent as a chatbot.
messages = []  # This stores the chat history.
while True:
    # For example, enter the query &quot;draw a dog and rotate it 90 degrees&quot;.
    query = input(&#039;\nuser query: &#039;)
    # Append the user query to the chat history.
    messages.append({&#039;role&#039;: &#039;user&#039;, &#039;content&#039;: query})
    response = []
    response_plain_text = &#039;&#039;
    print(&#039;bot response:&#039;)
    for response in bot.run(messages=messages):
        # Streaming output.
        response_plain_text = typewriter_print(response, response_plain_text)
    # Append the bot responses to the chat history.
    messages.extend(response)
```

In addition to using built-in agent implementations such as `class Assistant`, you can also develop your own agent implemetation by inheriting from `class Agent`.

The framework also provides a convenient GUI interface, supporting the rapid deployment of Gradio Demos for Agents.
For example, in the case above, you can quickly launch a Gradio Demo using the following code:

```py
from qwen_agent.gui import WebUI
WebUI(bot).run()  # bot is the agent defined in the above code, we do not repeat the definition here for saving space.
```
Now you can chat with the Agent in the web UI. Please refer to the [examples](https://github.com/QwenLM/Qwen-Agent/blob/main/examples) directory for more usage examples.

# FAQ

## How to Use MCP?

You can select the required tools on the open-source [MCP server website](https://github.com/modelcontextprotocol/servers) and configure the relevant environment.

Example of MCP invocation format:
```
{
    &quot;mcpServers&quot;: {
        &quot;memory&quot;: {
            &quot;command&quot;: &quot;npx&quot;,
            &quot;args&quot;: [&quot;-y&quot;, &quot;@modelcontextprotocol/server-memory&quot;]
        },
        &quot;filesystem&quot;: {
            &quot;command&quot;: &quot;npx&quot;,
            &quot;args&quot;: [&quot;-y&quot;, &quot;@modelcontextprotocol/server-filesystem&quot;, &quot;/path/to/allowed/files&quot;]
        },
        &quot;sqlite&quot; : {
            &quot;command&quot;: &quot;uvx&quot;,
            &quot;args&quot;: [
                &quot;mcp-server-sqlite&quot;,
                &quot;--db-path&quot;,
                &quot;test.db&quot;
            ]
        }
    }
}
```
For more details, you can refer to the [MCP usage example](./examples/assistant_mcp_sqlite_bot.py)

The dependencies required to run this example are as follows:
```
# Node.js (Download and install the latest version from the Node.js official website)
# uv 0.4.18 or higher (Check with uv --version)
# Git (Check with git --version)
# SQLite (Check with sqlite3 --version)

# For macOS users, you can install these components using Homebrew:
brew install uv git sqlite3

# For Windows users, you can install these components using winget:
winget install --id=astral-sh.uv -e
winget install git.git sqlite.sqlite
```
## Do you have function calling (aka tool calling)?

Yes. The LLM classes provide [function calling](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/function_calling.py). Additionally, some Agent classes also are built upon the function calling capability, e.g., FnCallAgent and ReActChat.

The current default tool calling template natively supports **Parallel Function Calls**.

## How to pass LLM parameters to the Agent?
```py
llm_cfg = {
    # The model name being used:
    &#039;model&#039;: &#039;qwen3-32b&#039;,
    # The model service being used:
    &#039;model_type&#039;: &#039;qwen_dashscope&#039;,
    # If &#039;api_key&#039; is not set here, it will default to reading the `DASHSCOPE_API_KEY` environment variable:
    &#039;api_key&#039;: &#039;YOUR_DASHSCOPE_API_KEY&#039;,

    # Using an OpenAI API compatible model service, such as vLLM or Ollama:
    # &#039;model&#039;: &#039;qwen3-32b&#039;,
    # &#039;model_server&#039;: &#039;http://localhost:8000/v1&#039;,  # base_url, also known as api_base
    # &#039;api_key&#039;: &#039;EMPTY&#039;,

    # (Optional) LLM hyperparameters:
    &#039;generate_cfg&#039;: {
        # This parameter will affect the tool-call parsing logic. Default is False:
          # Set to True: when content is `&lt;think&gt;this is the thought&lt;/think&gt;this is the answer`
          # Set to False: when response consists of reasoning_content and content
        # &#039;thought_in_content&#039;: True,

        # tool-call template: default is nous (recommended for qwen3):
        # &#039;fncall_prompt_type&#039;: &#039;nous&#039;

        # Maximum input length, messages will be truncated if they exceed this length, please adjust according to model API:
        # &#039;max_input_tokens&#039;: 58000

        # Parameters that will be passed directly to the model API, such as top_p, enable_thinking, etc., according to the API specifications:
        # &#039;top_p&#039;: 0.8

        # Using the API&#039;s native tool call interface
        # &#039;use_raw_api&#039;: True,
    }
}
```

## How to do question-answering over super-long documents involving 1M tokens?

We have released [a fast RAG solution](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/assistant_rag.py), as well as [an expensive but competitive agent](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/parallel_doc_qa.py), for doing question-answering over super-long documents. They have managed to outperform native long-context models on two challenging benchmarks while being more efficient, and perform perfectly in the single-needle &quot;needle-in-the-haystack&quot; pressure test involving 1M-token contexts. See the [blog](https://qwenlm.github.io/blog/qwen-agent-2405/) for technical details.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/qwen-agent-2405-blog-long-context-results.png&quot; width=&quot;400&quot;/&gt;
&lt;p&gt;

# Application: BrowserQwen

BrowserQwen is a browser assistant built upon Qwen-Agent. Please refer to its [documentation](https://github.com/QwenLM/Qwen-Agent/blob/main/browser_qwen.md) for details.

# Disclaimer

The code interpreter is not sandboxed, and it executes code in your own environment. Please do not ask Qwen to perform dangerous tasks, and do not directly use the code interpreter for production purposes.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[p1ngul1n0/blackbird]]></title>
            <link>https://github.com/p1ngul1n0/blackbird</link>
            <guid>https://github.com/p1ngul1n0/blackbird</guid>
            <pubDate>Thu, 24 Jul 2025 00:04:26 GMT</pubDate>
            <description><![CDATA[An OSINT tool to search for accounts by username and email in social networks.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/p1ngul1n0/blackbird">p1ngul1n0/blackbird</a></h1>
            <p>An OSINT tool to search for accounts by username and email in social networks.</p>
            <p>Language: Python</p>
            <p>Stars: 4,243</p>
            <p>Forks: 494</p>
            <p>Stars today: 335 stars today</p>
            <h2>README</h2><pre># Blackbird

&lt;figure&gt;&lt;img src=&quot;./docs/.gitbook/assets/ai-demo.png&quot; alt=&quot;&quot;&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&gt; Blackbird is a powerful OSINT tool that combines fast username and email searches across more than 600 platforms with free AI-powered profiling. By leveraging community-driven projects like WhatsMyName, it ensures low false positive rates and high-quality results. Features include smart filters, polished PDF/CSV exports, and fully automated analysis ‚Äî all from a single CLI.
&lt;br&gt;

[![SherlockEyeCover](./docs/.gitbook/assets/sherlockeye_cover.jpg)](https://cutt.ly/frtVNzQQ)

### Setup

**Clone the repository**

```bash
git clone https://github.com/p1ngul1n0/blackbird
cd blackbird
```

**Install requirements**

```bash
pip install -r requirements.txt
```

### Usage

**Search by username**

```bash
python blackbird.py --username johndoe
```

**Search by email**

```bash
python blackbird.py --email johndoe@example.com 
```

**Export results to PDF**

```bash
python blackbird.py --email  --pdf
```

##  ‚ú® AI (Free)
Blackbird integrates an AI engine that analyzes the sites where a username or email is found and returns a behavioral and technical profile of the user ‚Äî helping you understand more, with less effort.

- No sensitive data is shared ‚Äî only site names are sent

- Usage is completely free, with a fair daily limit

- AI results are also included in PDF exports (```--pdf```)
#### Generate an API key:
```bash
python blackbird.py --setup-ai
```
#### Use it
```bash
python blackbird.py --username johndoe --ai
```

## More
For more details about the project, visit the &lt;a href=&quot;https://p1ngul1n0.gitbook.io/blackbird/&quot;&gt;Docs&lt;/a&gt;

### Project Developer

[Lucas Antoniaci](https://www.linkedin.com/in/lucas-antoniaci/)

### WhatsMyName

Blackbird is fully integrated with [WhatsMyName](https://github.com/WebBreacher/WhatsMyName) project, witch has 600+ sites to perform accurate reverse username search.

### Sponsors

[![DigitalOcean Referral Badge](https://web-platforms.sfo2.cdn.digitaloceanspaces.com/WWW/Badge%203.svg)](https://www.digitalocean.com/?refcode=eae02be1dd10&amp;utm_campaign=Referral_Invite&amp;utm_medium=Referral_Program&amp;utm_source=badge)

### Disclaimer

```
This or previous program is for Educational purpose ONLY. Do not use it without permission. 
The usual disclaimer applies, especially the fact that me (P1ngul1n0) is not liable for any 
damages caused by direct or indirect use of the information or functionality provided by these 
programs. The author or any Internet provider bears NO responsibility for content or misuse 
of these programs or any derivatives thereof. By using these programs you accept the fact 
that any damage (dataloss, system crash, system compromise, etc.) caused by the use of these 
programs is not P1ngul1n0&#039;s responsibility.
```
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[openai/openai-agents-python]]></title>
            <link>https://github.com/openai/openai-agents-python</link>
            <guid>https://github.com/openai/openai-agents-python</guid>
            <pubDate>Thu, 24 Jul 2025 00:04:25 GMT</pubDate>
            <description><![CDATA[A lightweight, powerful framework for multi-agent workflows]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/openai-agents-python">openai/openai-agents-python</a></h1>
            <p>A lightweight, powerful framework for multi-agent workflows</p>
            <p>Language: Python</p>
            <p>Stars: 12,870</p>
            <p>Forks: 2,018</p>
            <p>Stars today: 40 stars today</p>
            <h2>README</h2><pre># OpenAI Agents SDK

The OpenAI Agents SDK is a lightweight yet powerful framework for building multi-agent workflows. It is provider-agnostic, supporting the OpenAI Responses and Chat Completions APIs, as well as 100+ other LLMs.

&lt;img src=&quot;https://cdn.openai.com/API/docs/images/orchestration.png&quot; alt=&quot;Image of the Agents Tracing UI&quot; style=&quot;max-height: 803px;&quot;&gt;

&gt; [!NOTE]
&gt; Looking for the JavaScript/TypeScript version? Check out [Agents SDK JS/TS](https://github.com/openai/openai-agents-js).

### Core concepts:

1. [**Agents**](https://openai.github.io/openai-agents-python/agents): LLMs configured with instructions, tools, guardrails, and handoffs
2. [**Handoffs**](https://openai.github.io/openai-agents-python/handoffs/): A specialized tool call used by the Agents SDK for transferring control between agents
3. [**Guardrails**](https://openai.github.io/openai-agents-python/guardrails/): Configurable safety checks for input and output validation
4. [**Sessions**](#sessions): Automatic conversation history management across agent runs
5. [**Tracing**](https://openai.github.io/openai-agents-python/tracing/): Built-in tracking of agent runs, allowing you to view, debug and optimize your workflows

Explore the [examples](examples) directory to see the SDK in action, and read our [documentation](https://openai.github.io/openai-agents-python/) for more details.

## Get started

1. Set up your Python environment

-   Option A: Using venv (traditional method)

```bash
python -m venv env
source env/bin/activate  # On Windows: env\Scripts\activate
```

-   Option B: Using uv (recommended)

```bash
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

2. Install Agents SDK

```bash
pip install openai-agents
```

For voice support, install with the optional `voice` group: `pip install &#039;openai-agents[voice]&#039;`.

## Hello world example

```python
from agents import Agent, Runner

agent = Agent(name=&quot;Assistant&quot;, instructions=&quot;You are a helpful assistant&quot;)

result = Runner.run_sync(agent, &quot;Write a haiku about recursion in programming.&quot;)
print(result.final_output)

# Code within the code,
# Functions calling themselves,
# Infinite loop&#039;s dance.
```

(_If running this, ensure you set the `OPENAI_API_KEY` environment variable_)

(_For Jupyter notebook users, see [hello_world_jupyter.ipynb](examples/basic/hello_world_jupyter.ipynb)_)

## Handoffs example

```python
from agents import Agent, Runner
import asyncio

spanish_agent = Agent(
    name=&quot;Spanish agent&quot;,
    instructions=&quot;You only speak Spanish.&quot;,
)

english_agent = Agent(
    name=&quot;English agent&quot;,
    instructions=&quot;You only speak English&quot;,
)

triage_agent = Agent(
    name=&quot;Triage agent&quot;,
    instructions=&quot;Handoff to the appropriate agent based on the language of the request.&quot;,
    handoffs=[spanish_agent, english_agent],
)


async def main():
    result = await Runner.run(triage_agent, input=&quot;Hola, ¬øc√≥mo est√°s?&quot;)
    print(result.final_output)
    # ¬°Hola! Estoy bien, gracias por preguntar. ¬øY t√∫, c√≥mo est√°s?


if __name__ == &quot;__main__&quot;:
    asyncio.run(main())
```

## Functions example

```python
import asyncio

from agents import Agent, Runner, function_tool


@function_tool
def get_weather(city: str) -&gt; str:
    return f&quot;The weather in {city} is sunny.&quot;


agent = Agent(
    name=&quot;Hello world&quot;,
    instructions=&quot;You are a helpful agent.&quot;,
    tools=[get_weather],
)


async def main():
    result = await Runner.run(agent, input=&quot;What&#039;s the weather in Tokyo?&quot;)
    print(result.final_output)
    # The weather in Tokyo is sunny.


if __name__ == &quot;__main__&quot;:
    asyncio.run(main())
```

## The agent loop

When you call `Runner.run()`, we run a loop until we get a final output.

1. We call the LLM, using the model and settings on the agent, and the message history.
2. The LLM returns a response, which may include tool calls.
3. If the response has a final output (see below for more on this), we return it and end the loop.
4. If the response has a handoff, we set the agent to the new agent and go back to step 1.
5. We process the tool calls (if any) and append the tool responses messages. Then we go to step 1.

There is a `max_turns` parameter that you can use to limit the number of times the loop executes.

### Final output

Final output is the last thing the agent produces in the loop.

1.  If you set an `output_type` on the agent, the final output is when the LLM returns something of that type. We use [structured outputs](https://platform.openai.com/docs/guides/structured-outputs) for this.
2.  If there&#039;s no `output_type` (i.e. plain text responses), then the first LLM response without any tool calls or handoffs is considered as the final output.

As a result, the mental model for the agent loop is:

1. If the current agent has an `output_type`, the loop runs until the agent produces structured output matching that type.
2. If the current agent does not have an `output_type`, the loop runs until the current agent produces a message without any tool calls/handoffs.

## Common agent patterns

The Agents SDK is designed to be highly flexible, allowing you to model a wide range of LLM workflows including deterministic flows, iterative loops, and more. See examples in [`examples/agent_patterns`](examples/agent_patterns).

## Tracing

The Agents SDK automatically traces your agent runs, making it easy to track and debug the behavior of your agents. Tracing is extensible by design, supporting custom spans and a wide variety of external destinations, including [Logfire](https://logfire.pydantic.dev/docs/integrations/llms/openai/#openai-agents), [AgentOps](https://docs.agentops.ai/v1/integrations/agentssdk), [Braintrust](https://braintrust.dev/docs/guides/traces/integrations#openai-agents-sdk), [Scorecard](https://docs.scorecard.io/docs/documentation/features/tracing#openai-agents-sdk-integration), and [Keywords AI](https://docs.keywordsai.co/integration/development-frameworks/openai-agent). For more details about how to customize or disable tracing, see [Tracing](http://openai.github.io/openai-agents-python/tracing), which also includes a larger list of [external tracing processors](http://openai.github.io/openai-agents-python/tracing/#external-tracing-processors-list).

## Sessions

The Agents SDK provides built-in session memory to automatically maintain conversation history across multiple agent runs, eliminating the need to manually handle `.to_input_list()` between turns.

### Quick start

```python
from agents import Agent, Runner, SQLiteSession

# Create agent
agent = Agent(
    name=&quot;Assistant&quot;,
    instructions=&quot;Reply very concisely.&quot;,
)

# Create a session instance
session = SQLiteSession(&quot;conversation_123&quot;)

# First turn
result = await Runner.run(
    agent,
    &quot;What city is the Golden Gate Bridge in?&quot;,
    session=session
)
print(result.final_output)  # &quot;San Francisco&quot;

# Second turn - agent automatically remembers previous context
result = await Runner.run(
    agent,
    &quot;What state is it in?&quot;,
    session=session
)
print(result.final_output)  # &quot;California&quot;

# Also works with synchronous runner
result = Runner.run_sync(
    agent,
    &quot;What&#039;s the population?&quot;,
    session=session
)
print(result.final_output)  # &quot;Approximately 39 million&quot;
```

### Session options

-   **No memory** (default): No session memory when session parameter is omitted
-   **`session: Session = DatabaseSession(...)`**: Use a Session instance to manage conversation history

```python
from agents import Agent, Runner, SQLiteSession

# Custom SQLite database file
session = SQLiteSession(&quot;user_123&quot;, &quot;conversations.db&quot;)
agent = Agent(name=&quot;Assistant&quot;)

# Different session IDs maintain separate conversation histories
result1 = await Runner.run(
    agent,
    &quot;Hello&quot;,
    session=session
)
result2 = await Runner.run(
    agent,
    &quot;Hello&quot;,
    session=SQLiteSession(&quot;user_456&quot;, &quot;conversations.db&quot;)
)
```

### Custom session implementations

You can implement your own session memory by creating a class that follows the `Session` protocol:

```python
from agents.memory import Session
from typing import List

class MyCustomSession:
    &quot;&quot;&quot;Custom session implementation following the Session protocol.&quot;&quot;&quot;

    def __init__(self, session_id: str):
        self.session_id = session_id
        # Your initialization here

    async def get_items(self, limit: int | None = None) -&gt; List[dict]:
        # Retrieve conversation history for the session
        pass

    async def add_items(self, items: List[dict]) -&gt; None:
        # Store new items for the session
        pass

    async def pop_item(self) -&gt; dict | None:
        # Remove and return the most recent item from the session
        pass

    async def clear_session(self) -&gt; None:
        # Clear all items for the session
        pass

# Use your custom session
agent = Agent(name=&quot;Assistant&quot;)
result = await Runner.run(
    agent,
    &quot;Hello&quot;,
    session=MyCustomSession(&quot;my_session&quot;)
)
```

## Development (only needed if you need to edit the SDK/examples)

0. Ensure you have [`uv`](https://docs.astral.sh/uv/) installed.

```bash
uv --version
```

1. Install dependencies

```bash
make sync
```

2. (After making changes) lint/test

```
make check # run tests linter and typechecker
```

Or to run them individually:

```
make tests  # run tests
make mypy   # run typechecker
make lint   # run linter
make format-check # run style checker
```

## Acknowledgements

We&#039;d like to acknowledge the excellent work of the open-source community, especially:

-   [Pydantic](https://docs.pydantic.dev/latest/) (data validation) and [PydanticAI](https://ai.pydantic.dev/) (advanced agent framework)
-   [MkDocs](https://github.com/squidfunk/mkdocs-material)
-   [Griffe](https://github.com/mkdocstrings/griffe)
-   [uv](https://github.com/astral-sh/uv) and [ruff](https://github.com/astral-sh/ruff)

We&#039;re committed to continuing to build the Agents SDK as an open source framework so others in the community can expand on our approach.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[getzep/graphiti]]></title>
            <link>https://github.com/getzep/graphiti</link>
            <guid>https://github.com/getzep/graphiti</guid>
            <pubDate>Thu, 24 Jul 2025 00:04:24 GMT</pubDate>
            <description><![CDATA[Build Real-Time Knowledge Graphs for AI Agents]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/getzep/graphiti">getzep/graphiti</a></h1>
            <p>Build Real-Time Knowledge Graphs for AI Agents</p>
            <p>Language: Python</p>
            <p>Stars: 14,872</p>
            <p>Forks: 1,250</p>
            <p>Stars today: 187 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.getzep.com/&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/119c5682-9654-4257-8922-56b7cb8ffd73&quot; width=&quot;150&quot; alt=&quot;Zep Logo&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;
Graphiti
&lt;/h1&gt;
&lt;h2 align=&quot;center&quot;&gt; Build Real-Time Knowledge Graphs for AI Agents&lt;/h2&gt;
&lt;div align=&quot;center&quot;&gt;

[![Lint](https://github.com/getzep/Graphiti/actions/workflows/lint.yml/badge.svg?style=flat)](https://github.com/getzep/Graphiti/actions/workflows/lint.yml)
[![Unit Tests](https://github.com/getzep/Graphiti/actions/workflows/unit_tests.yml/badge.svg)](https://github.com/getzep/Graphiti/actions/workflows/unit_tests.yml)
[![MyPy Check](https://github.com/getzep/Graphiti/actions/workflows/typecheck.yml/badge.svg)](https://github.com/getzep/Graphiti/actions/workflows/typecheck.yml)

![GitHub Repo stars](https://img.shields.io/github/stars/getzep/graphiti)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?&amp;logo=discord&amp;logoColor=white)](https://discord.com/invite/W8Kw6bsgXQ)
[![arXiv](https://img.shields.io/badge/arXiv-2501.13956-b31b1b.svg?style=flat)](https://arxiv.org/abs/2501.13956)
[![Release](https://img.shields.io/github/v/release/getzep/graphiti?style=flat&amp;label=Release&amp;color=limegreen)](https://github.com/getzep/graphiti/releases)

&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;

&lt;a href=&quot;https://trendshift.io/repositories/12986&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/12986&quot; alt=&quot;getzep%2Fgraphiti | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

:star: _Help us reach more developers and grow the Graphiti community. Star this repo!_

&lt;br /&gt;

&gt; [!TIP]
&gt; Check out the new [MCP server for Graphiti](mcp_server/README.md)! Give Claude, Cursor, and other MCP clients powerful Knowledge Graph-based memory.

Graphiti is a framework for building and querying temporally-aware knowledge graphs, specifically tailored for AI agents operating in dynamic environments. Unlike traditional retrieval-augmented generation (RAG) methods, Graphiti continuously integrates user interactions, structured and unstructured enterprise data, and external information into a coherent, queryable graph. The framework supports incremental data updates, efficient retrieval, and precise historical queries without requiring complete graph recomputation, making it suitable for developing interactive, context-aware AI applications.

Use Graphiti to:

- Integrate and maintain dynamic user interactions and business data.
- Facilitate state-based reasoning and task automation for agents.
- Query complex, evolving data with semantic, keyword, and graph-based search methods.

&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;images/graphiti-graph-intro.gif&quot; alt=&quot;Graphiti temporal walkthrough&quot; width=&quot;700px&quot;&gt;   
&lt;/p&gt;

&lt;br /&gt;

A knowledge graph is a network of interconnected facts, such as _&quot;Kendra loves Adidas shoes.&quot;_ Each fact is a &quot;triplet&quot; represented by two entities, or
nodes (&quot;Kendra&quot;, &quot;Adidas shoes&quot;), and their relationship, or edge (&quot;loves&quot;). Knowledge Graphs have been explored
extensively for information retrieval. What makes Graphiti unique is its ability to autonomously build a knowledge graph
while handling changing relationships and maintaining historical context.

## Graphiti and Zep Memory

Graphiti powers the core of [Zep&#039;s memory layer](https://www.getzep.com) for AI Agents.

Using Graphiti, we&#039;ve demonstrated Zep is
the [State of the Art in Agent Memory](https://blog.getzep.com/state-of-the-art-agent-memory/).

Read our paper: [Zep: A Temporal Knowledge Graph Architecture for Agent Memory](https://arxiv.org/abs/2501.13956).

We&#039;re excited to open-source Graphiti, believing its potential reaches far beyond AI memory applications.

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://arxiv.org/abs/2501.13956&quot;&gt;&lt;img src=&quot;images/arxiv-screenshot.png&quot; alt=&quot;Zep: A Temporal Knowledge Graph Architecture for Agent Memory&quot; width=&quot;700px&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

## Why Graphiti?

Traditional RAG approaches often rely on batch processing and static data summarization, making them inefficient for frequently changing data. Graphiti addresses these challenges by providing:

- **Real-Time Incremental Updates:** Immediate integration of new data episodes without batch recomputation.
- **Bi-Temporal Data Model:** Explicit tracking of event occurrence and ingestion times, allowing accurate point-in-time queries.
- **Efficient Hybrid Retrieval:** Combines semantic embeddings, keyword (BM25), and graph traversal to achieve low-latency queries without reliance on LLM summarization.
- **Custom Entity Definitions:** Flexible ontology creation and support for developer-defined entities through straightforward Pydantic models.
- **Scalability:** Efficiently manages large datasets with parallel processing, suitable for enterprise environments.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;/images/graphiti-intro-slides-stock-2.gif&quot; alt=&quot;Graphiti structured + unstructured demo&quot; width=&quot;700px&quot;&gt;   
&lt;/p&gt;

## Graphiti vs. GraphRAG

| Aspect                     | GraphRAG                              | Graphiti                                         |
| -------------------------- | ------------------------------------- | ------------------------------------------------ |
| **Primary Use**            | Static document summarization         | Dynamic data management                          |
| **Data Handling**          | Batch-oriented processing             | Continuous, incremental updates                  |
| **Knowledge Structure**    | Entity clusters &amp; community summaries | Episodic data, semantic entities, communities    |
| **Retrieval Method**       | Sequential LLM summarization          | Hybrid semantic, keyword, and graph-based search |
| **Adaptability**           | Low                                   | High                                             |
| **Temporal Handling**      | Basic timestamp tracking              | Explicit bi-temporal tracking                    |
| **Contradiction Handling** | LLM-driven summarization judgments    | Temporal edge invalidation                       |
| **Query Latency**          | Seconds to tens of seconds            | Typically sub-second latency                     |
| **Custom Entity Types**    | No                                    | Yes, customizable                                |
| **Scalability**            | Moderate                              | High, optimized for large datasets               |

Graphiti is specifically designed to address the challenges of dynamic and frequently updated datasets, making it particularly suitable for applications requiring real-time interaction and precise historical queries.

## Installation

Requirements:

- Python 3.10 or higher
- Neo4j 5.26 / FalkorDB 1.1.2 or higher (serves as the embeddings storage backend)
- OpenAI API key (Graphiti defaults to OpenAI for LLM inference and embedding)

&gt; [!IMPORTANT]
&gt; Graphiti works best with LLM services that support Structured Output (such as OpenAI and Gemini).
&gt; Using other services may result in incorrect output schemas and ingestion failures. This is particularly
&gt; problematic when using smaller models.

Optional:

- Google Gemini, Anthropic, or Groq API key (for alternative LLM providers)

&gt; [!TIP]
&gt; The simplest way to install Neo4j is via [Neo4j Desktop](https://neo4j.com/download/). It provides a user-friendly
&gt; interface to manage Neo4j instances and databases.
&gt; Alternatively, you can use FalkorDB on-premises via Docker and instantly start with the quickstart example:

```bash
docker run -p 6379:6379 -p 3000:3000 -it --rm falkordb/falkordb:latest

```

```bash
pip install graphiti-core
```

or

```bash
uv add graphiti-core
```

### Installing with FalkorDB Support

If you plan to use FalkorDB as your graph database backend, install with the FalkorDB extra:

```bash
pip install graphiti-core[falkordb]

# or with uv
uv add graphiti-core[falkordb]
```

### You can also install optional LLM providers as extras:

```bash
# Install with Anthropic support
pip install graphiti-core[anthropic]

# Install with Groq support
pip install graphiti-core[groq]

# Install with Google Gemini support
pip install graphiti-core[google-genai]

# Install with multiple providers
pip install graphiti-core[anthropic,groq,google-genai]

# Install with FalkorDB and LLM providers
pip install graphiti-core[falkordb,anthropic,google-genai]
```

## Quick Start

&gt; [!IMPORTANT]
&gt; Graphiti defaults to using OpenAI for LLM inference and embedding. Ensure that an `OPENAI_API_KEY` is set in your environment.
&gt; Support for Anthropic and Groq LLM inferences is available, too. Other LLM providers may be supported via OpenAI
&gt; compatible APIs.

For a complete working example, see the [Quickstart Example](./examples/quickstart/README.md) in the examples directory. The quickstart demonstrates:

1. Connecting to a Neo4j or FalkorDB database
2. Initializing Graphiti indices and constraints
3. Adding episodes to the graph (both text and structured JSON)
4. Searching for relationships (edges) using hybrid search
5. Reranking search results using graph distance
6. Searching for nodes using predefined search recipes

The example is fully documented with clear explanations of each functionality and includes a comprehensive README with setup instructions and next steps.

## MCP Server

The `mcp_server` directory contains a Model Context Protocol (MCP) server implementation for Graphiti. This server allows AI assistants to interact with Graphiti&#039;s knowledge graph capabilities through the MCP protocol.

Key features of the MCP server include:

- Episode management (add, retrieve, delete)
- Entity management and relationship handling
- Semantic and hybrid search capabilities
- Group management for organizing related data
- Graph maintenance operations

The MCP server can be deployed using Docker with Neo4j, making it easy to integrate Graphiti into your AI assistant workflows.

For detailed setup instructions and usage examples, see the [MCP server README](./mcp_server/README.md).

## REST Service

The `server` directory contains an API service for interacting with the Graphiti API. It is built using FastAPI.

Please see the [server README](./server/README.md) for more information.

## Optional Environment Variables

In addition to the Neo4j and OpenAi-compatible credentials, Graphiti also has a few optional environment variables.
If you are using one of our supported models, such as Anthropic or Voyage models, the necessary environment variables
must be set.

### Database Configuration

Database names are configured directly in the driver constructors:

- **Neo4j**: Database name defaults to `neo4j` (hardcoded in Neo4jDriver)
- **FalkorDB**: Database name defaults to `default_db` (hardcoded in FalkorDriver)

As of v0.17.0, if you need to customize your database configuration, you can instantiate a database driver and pass it to the Graphiti constructor using the `graph_driver` parameter.

#### Neo4j with Custom Database Name

```python
from graphiti_core import Graphiti
from graphiti_core.driver.neo4j_driver import Neo4jDriver

# Create a Neo4j driver with custom database name
driver = Neo4jDriver(
    uri=&quot;bolt://localhost:7687&quot;,
    user=&quot;neo4j&quot;,
    password=&quot;password&quot;,
    database=&quot;my_custom_database&quot;  # Custom database name
)

# Pass the driver to Graphiti
graphiti = Graphiti(graph_driver=driver)
```

#### FalkorDB with Custom Database Name

```python
from graphiti_core import Graphiti
from graphiti_core.driver.falkordb_driver import FalkorDriver

# Create a FalkorDB driver with custom database name
driver = FalkorDriver(
    host=&quot;localhost&quot;,
    port=6379,
    username=&quot;falkor_user&quot;,  # Optional
    password=&quot;falkor_password&quot;,  # Optional
    database=&quot;my_custom_graph&quot;  # Custom database name
)

# Pass the driver to Graphiti
graphiti = Graphiti(graph_driver=driver)
```


### Performance Configuration

`USE_PARALLEL_RUNTIME` is an optional boolean variable that can be set to true if you wish
to enable Neo4j&#039;s parallel runtime feature for several of our search queries.
Note that this feature is not supported for Neo4j Community edition or for smaller AuraDB instances,
as such this feature is off by default.

## Using Graphiti with Azure OpenAI

Graphiti supports Azure OpenAI for both LLM inference and embeddings. Azure deployments often require different endpoints for LLM and embedding services, and separate deployments for default and small models.

```python
from openai import AsyncAzureOpenAI
from graphiti_core import Graphiti
from graphiti_core.llm_client import LLMConfig, OpenAIClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient

# Azure OpenAI configuration - use separate endpoints for different services
api_key = &quot;&lt;your-api-key&gt;&quot;
api_version = &quot;&lt;your-api-version&gt;&quot;
llm_endpoint = &quot;&lt;your-llm-endpoint&gt;&quot;  # e.g., &quot;https://your-llm-resource.openai.azure.com/&quot;
embedding_endpoint = &quot;&lt;your-embedding-endpoint&gt;&quot;  # e.g., &quot;https://your-embedding-resource.openai.azure.com/&quot;

# Create separate Azure OpenAI clients for different services
llm_client_azure = AsyncAzureOpenAI(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=llm_endpoint
)

embedding_client_azure = AsyncAzureOpenAI(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=embedding_endpoint
)

# Create LLM Config with your Azure deployment names
azure_llm_config = LLMConfig(
    small_model=&quot;gpt-4.1-nano&quot;,
    model=&quot;gpt-4.1-mini&quot;,
)

# Initialize Graphiti with Azure OpenAI clients
graphiti = Graphiti(
    &quot;bolt://localhost:7687&quot;,
    &quot;neo4j&quot;,
    &quot;password&quot;,
    llm_client=OpenAIClient(
        llm_config=azure_llm_config,
        client=llm_client_azure
    ),
    embedder=OpenAIEmbedder(
        config=OpenAIEmbedderConfig(
            embedding_model=&quot;text-embedding-3-small-deployment&quot;  # Your Azure embedding deployment name
        ),
        client=embedding_client_azure
    ),
    cross_encoder=OpenAIRerankerClient(
        llm_config=LLMConfig(
            model=azure_llm_config.small_model  # Use small model for reranking
        ),
        client=llm_client_azure
    )
)

# Now you can use Graphiti with Azure OpenAI
```

Make sure to replace the placeholder values with your actual Azure OpenAI credentials and deployment names that match your Azure OpenAI service configuration.

## Using Graphiti with Google Gemini

Graphiti supports Google&#039;s Gemini models for LLM inference, embeddings, and cross-encoding/reranking. To use Gemini, you&#039;ll need to configure the LLM client, embedder, and the cross-encoder with your Google API key.

Install Graphiti:

```bash
uv add &quot;graphiti-core[google-genai]&quot;

# or

pip install &quot;graphiti-core[google-genai]&quot;
```

```python
from graphiti_core import Graphiti
from graphiti_core.llm_client.gemini_client import GeminiClient, LLMConfig
from graphiti_core.embedder.gemini import GeminiEmbedder, GeminiEmbedderConfig
from graphiti_core.cross_encoder.gemini_reranker_client import GeminiRerankerClient

# Google API key configuration
api_key = &quot;&lt;your-google-api-key&gt;&quot;

# Initialize Graphiti with Gemini clients
graphiti = Graphiti(
    &quot;bolt://localhost:7687&quot;,
    &quot;neo4j&quot;,
    &quot;password&quot;,
    llm_client=GeminiClient(
        config=LLMConfig(
            api_key=api_key,
            model=&quot;gemini-2.0-flash&quot;
        )
    ),
    embedder=GeminiEmbedder(
        config=GeminiEmbedderConfig(
            api_key=api_key,
            embedding_model=&quot;embedding-001&quot;
        )
    ),
    cross_encoder=GeminiRerankerClient(
        config=LLMConfig(
            api_key=api_key,
            model=&quot;gemini-2.5-flash-lite-preview-06-17&quot;
        )
    )
)

# Now you can use Graphiti with Google Gemini for all components
```

The Gemini reranker uses the `gemini-2.5-flash-lite-preview-06-17` model by default, which is optimized for cost-effective and low-latency classification tasks. It uses the same boolean classification approach as the OpenAI reranker, leveraging Gemini&#039;s log probabilities feature to rank passage relevance.

## Using Graphiti with Ollama (Local LLM)

Graphiti supports Ollama for running local LLMs and embedding models via Ollama&#039;s OpenAI-compatible API. This is ideal for privacy-focused applications or when you want to avoid API costs.

Install the models:
ollama pull deepseek-r1:7b # LLM
ollama pull nomic-embed-text # embeddings

```python
from graphiti_core import Graphiti
from graphiti_core.llm_client.config import LLMConfig
from graphiti_core.llm_client.openai_client import OpenAIClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient

# Configure Ollama LLM client
llm_config = LLMConfig(
    api_key=&quot;abc&quot;,  # Ollama doesn&#039;t require a real API key
    model=&quot;deepseek-r1:7b&quot;,
    small_model=&quot;deepseek-r1:7b&quot;,
    base_url=&quot;http://localhost:11434/v1&quot;, # Ollama provides this port
)

llm_client = OpenAIClient(config=llm_config)

# Initialize Graphiti with Ollama clients
graphiti = Graphiti(
    &quot;bolt://localhost:7687&quot;,
    &quot;neo4j&quot;,
    &quot;password&quot;,
    llm_client=llm_client,
    embedder=OpenAIEmbedder(
        config=OpenAIEmbedderConfig(
            api_key=&quot;abc&quot;,
            embedding_model=&quot;nomic-embed-text&quot;,
            embedding_dim=768,
            base_url=&quot;http://localhost:11434/v1&quot;,
        )
    ),
    cross_encoder=OpenAIRerankerClient(client=llm_client, config=llm_config),
)

# Now you can use Graphiti with local Ollama models
```

Ensure Ollama is running (`ollama serve`) and that you have pulled the models you want to use.

## Documentation

- [Guides and API documentation](https://help.getzep.com/graphiti).
- [Quick Start](https://help.getzep.com/graphiti/graphiti/quick-start)
- [Building an agent with LangChain&#039;s LangGraph and Graphiti](https://help.getzep.com/graphiti/graphiti/lang-graph-agent)

## Telemetry

Graphiti collects anonymous usage statistics to help us understand how the framework is being used and improve it for everyone. We believe transparency is important, so here&#039;s exactly what we collect and why.

### What We Collect

When you initialize a Graphiti instance, we collect:

- **Anonymous identifier**: A randomly generated UUID stored locally in `~/.cache/graphiti/telemetry_anon_id`
- **System information**: Operating system, Python version, and system architecture
- **Graphiti version**: The version you&#039;re using
- **Configuration choices**:
  - LLM provider type (OpenAI, Azure, Anthropic, etc.)
  - Database backend (Neo4j, FalkorDB)
  - Embedder provider (OpenAI, Azure, Voyage, etc.)

### What We Don&#039;t Collect

We are committed to protecting your privacy. We **never** collect:

- Personal information or identifiers
- API keys or credentials
- Your actual data, queries, or graph content
- IP addresses or hostnames
- File paths or system-specific information
- Any content from your episodes, nodes, or edges

### Why We Collect This Data

This information helps us:

- Understand which configurations are most popular to prioritize support and testing
- Identify which LLM and database providers to focus development efforts on
- Track adoption patterns to guide our roadmap
- Ensure compatibility across different Python versions and operating systems

By sharing this anonymous information, you help us make Graphiti better for everyone in the community.

### View the Telemetry Code

The Telemetry code [may be found here](graphiti_core/telemetry/telemetry.py).

### How to Disable Telemetry

Telemetry is **opt-out** and can be disabled at any time. To disable telemetry collection:

**Option 1: Environment Variable**

```bash
export GRAPHITI_TELEMETRY_ENABLED=false
```

**Option 2: Set in your shell profile**

```bash
# For bash users (~/.bashrc or ~/.bash_profile)
echo &#039;export GRAPHITI_TELEMETRY_ENABLED=false&#039; &gt;&gt; ~/.bashrc

# For zsh users (~/.zshrc)
echo &#039;export

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>