<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Tue, 19 Aug 2025 00:04:21 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[coleam00/Archon]]></title>
            <link>https://github.com/coleam00/Archon</link>
            <guid>https://github.com/coleam00/Archon</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:21 GMT</pubDate>
            <description><![CDATA[Beta release of Archon OS - the knowledge and task management backbone for AI coding assistants.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/coleam00/Archon">coleam00/Archon</a></h1>
            <p>Beta release of Archon OS - the knowledge and task management backbone for AI coding assistants.</p>
            <p>Language: Python</p>
            <p>Stars: 8,944</p>
            <p>Forks: 1,594</p>
            <p>Stars today: 1,353 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./archon-ui-main/public/archon-main-graphic.png&quot; alt=&quot;Archon Main Graphic&quot; width=&quot;853&quot; height=&quot;422&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;em&gt;Power up your AI coding assistants with your own custom knowledge base and task management as an MCP server&lt;/em&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;#quick-start&quot;&gt;Quick Start&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#whats-included&quot;&gt;What&#039;s Included&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#architecture&quot;&gt;Architecture&lt;/a&gt;
&lt;/p&gt;

---

## üéØ What is Archon?

&gt; Archon is currently in beta! Expect things to not work 100%, and please feel free to share any feedback and contribute with fixes/new features! Thank you to everyone for all the excitement we have for Archon already, as well as the bug reports, PRs, and discussions. It&#039;s a lot for our small team to get through but we&#039;re committed to addressing everything and making Archon into the best tool it possibly can be!

Archon is the **command center** for AI coding assistants. For you, it&#039;s a sleek interface to manage knowledge, context, and tasks for your projects. For the AI coding assistant(s), it&#039;s a **Model Context Protocol (MCP) server** to collaborate on and leverage the same knowledge, context, and tasks. Connect Claude Code, Kiro, Cursor, Windsurf, etc. to give your AI agents access to:

- **Your documentation** (crawled websites, uploaded PDFs/docs)
- **Smart search capabilities** with advanced RAG strategies
- **Task management** integrated with your knowledge base
- **Real-time updates** as you add new content and collaborate with your coding assistant on tasks
- **Much more** coming soon to build Archon into an integrated environment for all context engineering

This new vision for Archon replaces the old one (the agenteer). Archon used to be the AI agent that builds other agents, and now you can use Archon to do that and more.

&gt; It doesn&#039;t matter what you&#039;re building or if it&#039;s a new/existing codebase - Archon&#039;s knowledge and task management capabilities will improve the output of **any** AI driven coding.

## üîó Important Links

- **[GitHub Discussions](https://github.com/coleam00/Archon/discussions)** - Join the conversation and share ideas about Archon
- **[Contributing Guide](CONTRIBUTING.md)** - How to get involved and contribute to Archon
- **[Introduction Video](https://youtu.be/8pRc_s2VQIo)** - Getting Started Guide and Vision for Archon
- **[Dynamous AI Mastery](https://dynamous.ai)** - The birthplace of Archon - come join a vibrant community of other early AI adopters all helping each other transform their careers and businesses!

## Quick Start

### Prerequisites

- [Docker Desktop](https://www.docker.com/products/docker-desktop/)
- [Supabase](https://supabase.com/) account (free tier or local Supabase both work)
- [OpenAI API key](https://platform.openai.com/api-keys) (Gemini and Ollama are supported too!)

### Setup Instructions

1. **Clone Repository**:

   ```bash
   git clone https://github.com/coleam00/archon.git
   cd archon
   ```

2. **Environment Configuration**:

   ```bash
   cp .env.example .env
   # Edit .env and add your Supabase credentials:
   # SUPABASE_URL=https://your-project.supabase.co
   # SUPABASE_SERVICE_KEY=your-service-key-here
   ```

   NOTE: Supabase introduced a new type of service key but use the legacy one (the longer one).

   OPTIONAL: If you want to enable the reranking RAG strategy, uncomment lines 20-22 in `python\requirements.server.txt`. This will significantly increase the size of the Archon Server container which is why it&#039;s off by default.

3. **Database Setup**: In your [Supabase project](https://supabase.com/dashboard) SQL Editor, copy, paste, and execute the contents of `migration/complete_setup.sql`

4. **Start Services**:

   ```bash
   docker-compose up --build -d
   ```

   This starts the core microservices:
   - **Server**: Core API and business logic (Port: 8181)
   - **MCP Server**: Protocol interface for AI clients (Port: 8051)
   - **Agents (coming soon!)**: AI operations and streaming (Port: 8052)
   - **UI**: Web interface (Port: 3737)

   Ports are configurable in your .env as well!

5. **Configure API Keys**:
   - Open http://localhost:3737
   - Go to **Settings** ‚Üí Select your LLM/embedding provider and set the API key (OpenAI is default)
   - Test by uploading a document or crawling a website

## üîÑ Database Reset (Start Fresh if Needed)

If you need to completely reset your database and start fresh:

&lt;details&gt;
&lt;summary&gt;‚ö†Ô∏è &lt;strong&gt;Reset Database - This will delete ALL data for Archon!&lt;/strong&gt;&lt;/summary&gt;

1. **Run Reset Script**: In your Supabase SQL Editor, run the contents of `migration/RESET_DB.sql`

   ‚ö†Ô∏è WARNING: This will delete all Archon specific tables and data! Nothing else will be touched in your DB though.

2. **Rebuild Database**: After reset, run `migration/complete_setup.sql` to create all the tables again.

3. **Restart Services**:

   ```bash
   docker-compose up -d
   ```

4. **Reconfigure**:
   - Select your LLM/embedding provider and set the API key again
   - Re-upload any documents or re-crawl websites

The reset script safely removes all tables, functions, triggers, and policies with proper dependency handling.

&lt;/details&gt;

## ‚ö° Quick Test

Once everything is running:

1. **Test Web Crawling**: Go to http://localhost:3737 ‚Üí Knowledge Base ‚Üí &quot;Crawl Website&quot; ‚Üí Enter a doc URL (such as https://ai.pydantic.dev/llms-full.txt)
2. **Test Document Upload**: Knowledge Base ‚Üí Upload a PDF
3. **Test Projects**: Projects ‚Üí Create a new project and add tasks
4. **Integrate with your AI coding assistant**: MCP Dashboard ‚Üí Copy connection config for your AI coding assistant

## üìö Documentation

### Core Services

| Service            | Container Name | Default URL           | Purpose                           |
| ------------------ | -------------- | --------------------- | --------------------------------- |
| **Web Interface**  | archon-ui      | http://localhost:3737 | Main dashboard and controls       |
| **API Service**    | archon-server  | http://localhost:8181 | Web crawling, document processing |
| **MCP Server**     | archon-mcp     | http://localhost:8051 | Model Context Protocol interface  |
| **Agents Service** | archon-agents  | http://localhost:8052 | AI/ML operations, reranking       |

## What&#039;s Included

### üß† Knowledge Management

- **Smart Web Crawling**: Automatically detects and crawls entire documentation sites, sitemaps, and individual pages
- **Document Processing**: Upload and process PDFs, Word docs, markdown files, and text documents with intelligent chunking
- **Code Example Extraction**: Automatically identifies and indexes code examples from documentation for enhanced search
- **Vector Search**: Advanced semantic search with contextual embeddings for precise knowledge retrieval
- **Source Management**: Organize knowledge by source, type, and tags for easy filtering

### ü§ñ AI Integration

- **Model Context Protocol (MCP)**: Connect any MCP-compatible client (Claude Code, Cursor, even non-AI coding assistants like Claude Desktop)
- **10 MCP Tools**: Comprehensive yet simple set of tools for RAG queries, task management, and project operations
- **Multi-LLM Support**: Works with OpenAI, Ollama, and Google Gemini models
- **RAG Strategies**: Hybrid search, contextual embeddings, and result reranking for optimal AI responses
- **Real-time Streaming**: Live responses from AI agents with progress tracking

### üìã Project &amp; Task Management

- **Hierarchical Projects**: Organize work with projects, features, and tasks in a structured workflow
- **AI-Assisted Creation**: Generate project requirements and tasks using integrated AI agents
- **Document Management**: Version-controlled documents with collaborative editing capabilities
- **Progress Tracking**: Real-time updates and status management across all project activities

### üîÑ Real-time Collaboration

- **WebSocket Updates**: Live progress tracking for crawling, processing, and AI operations
- **Multi-user Support**: Collaborative knowledge building and project management
- **Background Processing**: Asynchronous operations that don&#039;t block the user interface
- **Health Monitoring**: Built-in service health checks and automatic reconnection

## Architecture

### Microservices Structure

Archon uses true microservices architecture with clear separation of concerns:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend UI   ‚îÇ    ‚îÇ  Server (API)   ‚îÇ    ‚îÇ   MCP Server    ‚îÇ    ‚îÇ Agents Service  ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ  React + Vite   ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ    FastAPI +    ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ    Lightweight  ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   PydanticAI    ‚îÇ
‚îÇ  Port 3737      ‚îÇ    ‚îÇ    SocketIO     ‚îÇ    ‚îÇ    HTTP Wrapper ‚îÇ    ‚îÇ   Port 8052     ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ    Port 8181    ‚îÇ    ‚îÇ    Port 8051    ‚îÇ    ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                        ‚îÇ                        ‚îÇ                        ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ                        ‚îÇ
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
                         ‚îÇ    Database     ‚îÇ               ‚îÇ
                         ‚îÇ                 ‚îÇ               ‚îÇ
                         ‚îÇ    Supabase     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ    PostgreSQL   ‚îÇ
                         ‚îÇ    PGVector     ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Service Responsibilities

| Service        | Location             | Purpose                      | Key Features                                                       |
| -------------- | -------------------- | ---------------------------- | ------------------------------------------------------------------ |
| **Frontend**   | `archon-ui-main/`    | Web interface and dashboard  | React, TypeScript, TailwindCSS, Socket.IO client                   |
| **Server**     | `python/src/server/` | Core business logic and APIs | FastAPI, service layer, Socket.IO broadcasts, all ML/AI operations |
| **MCP Server** | `python/src/mcp/`    | MCP protocol interface       | Lightweight HTTP wrapper, 10 MCP tools, session management         |
| **Agents**     | `python/src/agents/` | PydanticAI agent hosting     | Document and RAG agents, streaming responses                       |

### Communication Patterns

- **HTTP-based**: All inter-service communication uses HTTP APIs
- **Socket.IO**: Real-time updates from Server to Frontend
- **MCP Protocol**: AI clients connect to MCP Server via SSE or stdio
- **No Direct Imports**: Services are truly independent with no shared code dependencies

### Key Architectural Benefits

- **Lightweight Containers**: Each service contains only required dependencies
- **Independent Scaling**: Services can be scaled independently based on load
- **Development Flexibility**: Teams can work on different services without conflicts
- **Technology Diversity**: Each service uses the best tools for its specific purpose

## üîß Configuring Custom Ports &amp; Hostname

By default, Archon services run on the following ports:

- **Archon-UI**: 3737
- **Archon-Server**: 8181
- **Archon-MCP**: 8051
- **Archon-Agents**: 8052
- **Archon-Docs**: 3838 (optional)

### Changing Ports

To use custom ports, add these variables to your `.env` file:

```bash
# Service Ports Configuration
ARCHON_UI_PORT=3737
ARCHON_SERVER_PORT=8181
ARCHON_MCP_PORT=8051
ARCHON_AGENTS_PORT=8052
ARCHON_DOCS_PORT=3838
```

Example: Running on different ports:

```bash
ARCHON_SERVER_PORT=8282
ARCHON_MCP_PORT=8151
```

### Configuring Hostname

By default, Archon uses `localhost` as the hostname. You can configure a custom hostname or IP address by setting the `HOST` variable in your `.env` file:

```bash
# Hostname Configuration
HOST=localhost  # Default

# Examples of custom hostnames:
HOST=192.168.1.100     # Use specific IP address
HOST=archon.local      # Use custom domain
HOST=myserver.com      # Use public domain
```

This is useful when:

- Running Archon on a different machine and accessing it remotely
- Using a custom domain name for your installation
- Deploying in a network environment where `localhost` isn&#039;t accessible

After changing hostname or ports:

1. Restart Docker containers: `docker-compose down &amp;&amp; docker-compose up -d`
2. Access the UI at: `http://${HOST}:${ARCHON_UI_PORT}`
3. Update your AI client configuration with the new hostname and MCP port

## üîß Development

For development with hot reload:

```bash
# Backend services (with auto-reload)
docker-compose up archon-server archon-mcp archon-agents --build

# Frontend (with hot reload)
cd archon-ui-main &amp;&amp; npm run dev

# Documentation (with hot reload)
cd docs &amp;&amp; npm start
```

**Note**: The backend services are configured with `--reload` flag in their uvicorn commands and have source code mounted as volumes for automatic hot reloading when you make changes.

## üìÑ License

Archon Community License (ACL) v1.2 - see [LICENSE](LICENSE) file for details.

**TL;DR**: Archon is free, open, and hackable. Run it, fork it, share it - just don&#039;t sell it as-a-service without permission.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[emcie-co/parlant]]></title>
            <link>https://github.com/emcie-co/parlant</link>
            <guid>https://github.com/emcie-co/parlant</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:20 GMT</pubDate>
            <description><![CDATA[LLM agents built for control. Designed for real-world use. Deployed in minutes.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/emcie-co/parlant">emcie-co/parlant</a></h1>
            <p>LLM agents built for control. Designed for real-world use. Deployed in minutes.</p>
            <p>Language: Python</p>
            <p>Stars: 5,637</p>
            <p>Forks: 508</p>
            <p>Stars today: 1,129 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/emcie-co/parlant/blob/develop/docs/LogoTransparentLight.png?raw=true&quot;&gt;
  &lt;img alt=&quot;Parlant - AI Agent Framework&quot; src=&quot;https://github.com/emcie-co/parlant/blob/develop/docs/LogoTransparentDark.png?raw=true&quot; width=400 /&gt;
&lt;/picture&gt;

&lt;h3&gt;Finally, LLM agents that actually follow instructions&lt;/h3&gt;

&lt;p&gt;
  &lt;a href=&quot;https://www.parlant.io/&quot; target=&quot;_blank&quot;&gt;üåê Website&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://www.parlant.io/docs/quickstart/installation&quot; target=&quot;_blank&quot;&gt;‚ö° Quick Start&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://discord.gg/duxWqxKk6J&quot; target=&quot;_blank&quot;&gt;üí¨ Discord&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://www.parlant.io/docs/quickstart/examples&quot; target=&quot;_blank&quot;&gt;üìñ Examples&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;
  &lt;a href=&quot;https://pypi.org/project/parlant/&quot;&gt;&lt;img alt=&quot;PyPI&quot; src=&quot;https://img.shields.io/pypi/v/parlant?color=blue&quot;&gt;&lt;/a&gt;
  &lt;img alt=&quot;Python 3.10+&quot; src=&quot;https://img.shields.io/badge/python-3.10+-blue&quot;&gt;
  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;&lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/badge/license-Apache%202.0-green&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/duxWqxKk6J&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1312378700993663007?color=7289da&amp;logo=discord&amp;logoColor=white&quot;&gt;&lt;/a&gt;
  &lt;img alt=&quot;GitHub Repo stars&quot; src=&quot;https://img.shields.io/github/stars/emcie-co/parlant?style=social&quot;&gt;
&lt;/p&gt;

&lt;a href=&quot;https://trendshift.io/repositories/12768&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://trendshift.io/api/badge/repositories/12768&quot; alt=&quot;Trending on TrendShift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
&lt;/a&gt;

&lt;/div&gt;

## üéØ The Problem Every AI Developer Faces

You build an AI agent. It works great in testing. Then real users start talking to it and...

- ‚ùå It ignores your carefully crafted system prompts
- ‚ùå It hallucinates responses in critical moments
- ‚ùå It can&#039;t handle edge cases consistently
- ‚ùå Each conversation feels like a roll of the dice

**Sound familiar?** You&#039;re not alone. This is the #1 pain point for developers building production AI agents.

## ‚ö° The Solution: Teach Principles, Not Scripts

Parlant flips the script on AI agent development. Instead of hoping your LLM will follow instructions, **Parlant guarantees it**.

```python
# Traditional approach: Cross your fingers ü§û
system_prompt = &quot;You are a helpful assistant. Please follow these 47 rules...&quot;

# Parlant approach: Guaranteed compliance ‚úÖ
await agent.create_guideline(
    condition=&quot;Customer asks about refunds&quot;,
    action=&quot;Check order status first to see if eligible&quot;,
    tools=[check_order_status],
)
```

&lt;div align=&quot;center&quot;&gt;

## üöÄ Get Your Agent Running in 60 Seconds

&lt;/div&gt;

```bash
pip install parlant
```

```python
import parlant.sdk as p

@p.tool
async def get_weather(context: p.ToolContext, city: str) -&gt; p.ToolResult:
    # Your weather API logic here
    return p.ToolResult(f&quot;Sunny, 72¬∞F in {city}&quot;)

async def main():
    async with p.Server() as server:
        agent = await server.create_agent(
            name=&quot;WeatherBot&quot;,
            description=&quot;Helpful weather assistant&quot;
        )

        # Define behavior with natural language
        await agent.create_guideline(
            condition=&quot;User asks about weather&quot;,
            action=&quot;Get current weather and provide a friendly response with suggestions&quot;,
            tools=[get_weather]
        )

        # üéâ Test playground ready at http://localhost:8800
        # Integrate the official React widget into your app,
        # or follow the tutorial to build your own frontend!

if __name__ == &quot;__main__&quot;:
    import asyncio
    asyncio.run(main())
```

**That&#039;s it!** Your agent is running with guaranteed rule-following behavior.

## üé¨ See It In Action

&lt;img alt=&quot;Parlant Demo&quot; src=&quot;https://github.com/emcie-co/parlant/blob/develop/docs/demo.gif?raw=true&quot; width=&quot;100%&quot; /&gt;

## üî• Why Developers Are Switching to Parlant

&lt;table width=&quot;100%&quot;&gt;
&lt;tr&gt;
  &lt;td width=&quot;50%&quot;&gt;

### üèóÔ∏è **Traditional AI Frameworks**

  &lt;/td&gt;
  &lt;td width=&quot;50%&quot;&gt;

### ‚ö° **Parlant**

  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;50%&quot;&gt;

- Write complex system prompts
- Hope the LLM follows them
- Debug unpredictable behaviors
- Scale by prompt engineering
- Cross fingers for reliability

&lt;/td&gt;
&lt;td width=&quot;50%&quot;&gt;

- Define rules in natural language
- **Guaranteed** rule compliance
- Predictable, consistent behavior
- Scale by adding guidelines
- Production-ready from day one

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

## üéØ Perfect For Your Use Case

&lt;div align=&quot;center&quot;&gt;

|  **Financial Services**  |     **Healthcare**      |       **E-commerce**        |       **Legal Tech**       |
| :----------------------: | :---------------------: | :-------------------------: | :------------------------: |
| Compliance-first design  |   HIPAA-ready agents    |  Customer service at scale  |   Precise legal guidance   |
| Built-in risk management | Patient data protection | Order processing automation | Document review assistance |

&lt;/div&gt;

## üõ†Ô∏è Enterprise-Grade Features

- **üß≠ Conversational Journeys** - Lead the customer step-by-step to a goal
- **üéØ Dynamic Guideline Matching** - Context-aware rule application
- **üîß Reliable Tool Integration** - APIs, databases, external services
- **üìä Conversation Analytics** - Deep insights into agent behavior
- **üîÑ Iterative Refinement** - Continuously improve agent responses
- **üõ°Ô∏è Built-in Guardrails** - Prevent hallucination and off-topic responses
- **üì± React Widget** - [Drop-in chat UI for any web app](https://github.com/emcie-co/parlant-chat-react)
- **üîç Full Explainability** - Understand every decision your agent makes

## üìà Join 1000+ Developers Building Better AI

&lt;div align=&quot;center&quot;&gt;

**Companies using Parlant in production:**

_Financial institutions ‚Ä¢ Healthcare providers ‚Ä¢ Legal firms ‚Ä¢ E-commerce platforms_

[![Star History Chart](https://api.star-history.com/svg?repos=emcie-co/parlant&amp;type=Date)](https://star-history.com/#emcie-co/parlant&amp;Date)

&lt;/div&gt;

## üèÉ‚Äç‚ôÇÔ∏è Quick Start Paths

&lt;table border=&quot;0&quot;&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;üéØ I want to test it myself&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://www.parlant.io/docs/quickstart/installation&quot;&gt;‚Üí 5-minute quickstart&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;üõ†Ô∏è I want to see an example&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://www.parlant.io/docs/quickstart/examples&quot;&gt;‚Üí Healthcare agent example&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;üöÄ I want to get involved&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://discord.gg/duxWqxKk6J&quot;&gt;‚Üí Join our Discord community&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

## üåü What Developers Are Saying

&gt; _&quot;By far the most elegant conversational AI framework that I&#039;ve come across! Developing with Parlant is pure joy.&quot;_ **‚Äî Vishal Ahuja, Senior Lead, Customer-Facing Conversational AI @ JPMorgan Chase**

## ü§ù Community &amp; Support

- üí¨ **[Discord Community](https://discord.gg/duxWqxKk6J)** - Get help from the team and community
- üìñ **[Documentation](https://parlant.io/docs/quickstart/installation)** - Comprehensive guides and examples
- üêõ **[GitHub Issues](https://github.com/emcie-co/parlant/issues)** - Bug reports and feature requests
- üìß **[Direct Support](https://parlant.io/contact)** - Direct line to our engineering team

## üìÑ License

Apache 2.0 - Use it anywhere, including commercial projects.

---

&lt;div align=&quot;center&quot;&gt;

**Ready to build AI agents that actually work?**

‚≠ê **Star this repo** ‚Ä¢ üöÄ **[Try Parlant now](https://parlant.io/)** ‚Ä¢ üí¨ **[Join Discord](https://discord.gg/duxWqxKk6J)**

_Built with ‚ù§Ô∏è by the team at [Emcie](https://emcie.co)_

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Shubhamsaboo/awesome-llm-apps]]></title>
            <link>https://github.com/Shubhamsaboo/awesome-llm-apps</link>
            <guid>https://github.com/Shubhamsaboo/awesome-llm-apps</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:19 GMT</pubDate>
            <description><![CDATA[Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Shubhamsaboo/awesome-llm-apps">Shubhamsaboo/awesome-llm-apps</a></h1>
            <p>Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.</p>
            <p>Language: Python</p>
            <p>Stars: 59,554</p>
            <p>Forks: 7,141</p>
            <p>Stars today: 804 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;http://www.theunwindai.com&quot;&gt;
    &lt;img src=&quot;docs/banner/unwind_black.png&quot; width=&quot;900px&quot; alt=&quot;Unwind AI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.linkedin.com/in/shubhamsaboo/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-Follow%20Shubham%20Saboo-blue?logo=linkedin&amp;style=flat-square&quot; alt=&quot;LinkedIn&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/Saboo_Shubham_&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/twitter/follow/Shubham_Saboo&quot; alt=&quot;Twitter&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=de&quot;&gt;Deutsch&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=es&quot;&gt;Espa√±ol&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=fr&quot;&gt;fran√ßais&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ja&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ko&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=pt&quot;&gt;Portugu√™s&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ru&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=zh&quot;&gt;‰∏≠Êñá&lt;/a&gt;
&lt;/p&gt;

&lt;hr/&gt;

# üåü Awesome LLM Apps

A curated collection of **Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.** This repository features LLM apps that use models from OpenAI, Anthropic, Google, and open-source models like DeepSeek, Qwen or Llama that you can run locally on your computer.

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/9876&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/9876&quot; alt=&quot;Shubhamsaboo%2Fawesome-llm-apps | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## ü§î Why Awesome LLM Apps?

- üí° Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.
- üî• Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with AI Agents, Agent Teams, MCP &amp; RAG.
- üéì Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.

## üìÇ Featured AI Projects

### AI Agents

### üå± Starter AI Agents

*   [üéôÔ∏è AI Blog to Podcast Agent](starter_ai_agents/ai_blog_to_podcast_agent/)
*   [‚ù§Ô∏è‚Äçü©π AI Breakup Recovery Agent](starter_ai_agents/ai_breakup_recovery_agent/)
*   [üìä AI Data Analysis Agent](starter_ai_agents/ai_data_analysis_agent/)
*   [ü©ª AI Medical Imaging Agent](starter_ai_agents/ai_medical_imaging_agent/)
*   [üòÇ AI Meme Generator Agent (Browser)](starter_ai_agents/ai_meme_generator_agent_browseruse/)
*   [üéµ AI Music Generator Agent](starter_ai_agents/ai_music_generator_agent/)
*   [üõ´ AI Travel Agent (Local &amp; Cloud)](starter_ai_agents/ai_travel_agent/)
*   [‚ú® Gemini Multimodal Agent](starter_ai_agents/gemini_multimodal_agent_demo/)
*   [üåê Local News Agent (OpenAI Swarm)](starter_ai_agents/local_news_agent_openai_swarm/)
*   [üîÑ Mixture of Agents](starter_ai_agents/mixture_of_agents/)
*   [üìä xAI Finance Agent](starter_ai_agents/xai_finance_agent/)
*   [üîç OpenAI Research Agent](starter_ai_agents/opeani_research_agent/)
*   [üï∏Ô∏è Web Scrapping AI Agent (Local &amp; Cloud)](starter_ai_agents/web_scrapping_ai_agent/)

### üöÄ Advanced AI Agents

*   [üîç AI Deep Research Agent](advanced_ai_agents/single_agent_apps/ai_deep_research_agent/)
*   [ü§ù AI Consultant Agent](advanced_ai_agents/single_agent_apps/ai_consultant_agent)
*   [üèóÔ∏è AI System Architect Agent](advanced_ai_agents/single_agent_apps/ai_system_architect_r1/)
*   [üéØ AI Lead Generation Agent](advanced_ai_agents/single_agent_apps/ai_lead_generation_agent/)
*   [üí∞ AI Financial Coach Agent](advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/)
*   [üé¨ AI Movie Production Agent](advanced_ai_agents/single_agent_apps/ai_movie_production_agent/)
*   [üìà AI Investment Agent](advanced_ai_agents/single_agent_apps/ai_investment_agent/)
*   [üèãÔ∏è‚Äç‚ôÇÔ∏è AI Health &amp; Fitness Agent](advanced_ai_agents/single_agent_apps/ai_health_fitness_agent/)
*   [üöÄ AI Product Launch Intelligence Agent](advanced_ai_agents/multi_agent_apps/product_launch_intelligence_agent)
*   [üóûÔ∏è AI Journalist Agent](advanced_ai_agents/single_agent_apps/ai_journalist_agent/)
*   [üß† AI Mental Wellbeing Agent](advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/)
*   [üìë AI Meeting Agent](advanced_ai_agents/single_agent_apps/ai_meeting_agent/)
*   [üß¨ AI Self-Evolving Agent](advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/)
*   [üéß AI Social Media News and Podcast Agent](advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/)

### üéÆ Autonomous Game Playing Agents

*   [üéÆ AI 3D Pygame Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/)
*   [‚ôú AI Chess Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/)
*   [üé≤ AI Tic-Tac-Toe Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/)

### ü§ù Multi-agent Teams

*   [üß≤ AI Competitor Intelligence Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/)
*   [üí≤ AI Finance Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/)
*   [üé® AI Game Design Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/)
*   [üë®‚Äç‚öñÔ∏è AI Legal Agent Team (Cloud &amp; Local)](advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/)
*   [üíº AI Recruitment Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/)
*   [üè† AI Real Estate Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_real_estate_agent_team)
*   [üë®‚Äçüíº AI Services Agency (CrewAI)](advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/)
*   [üë®‚Äçüè´ AI Teaching Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/)
*   [üíª Multimodal Coding Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/)
*   [‚ú® Multimodal Design Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/)
*   [üåè AI Travel Planner Agent Team](/advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/)

### üó£Ô∏è Voice AI Agents

*   [üó£Ô∏è AI Audio Tour Agent](voice_ai_agents/ai_audio_tour_agent/)
*   [üìû Customer Support Voice Agent](voice_ai_agents/customer_support_voice_agent/)
*   [üîä Voice RAG Agent (OpenAI SDK)](voice_ai_agents/voice_rag_openaisdk/)


### üåê MCP AI Agents

*   [‚ôæÔ∏è Browser MCP Agent](mcp_ai_agents/browser_mcp_agent/)
*   [üêô GitHub MCP Agent](mcp_ai_agents/github_mcp_agent/)
*   [üìë Notion MCP Agent](mcp_ai_agents/notion_mcp_agent) 
*   [üåç AI Travel Planner MCP Agent](mcp_ai_agents/ai_travel_planner_mcp_agent_team)

### üìÄ RAG (Retrieval Augmented Generation)
*   [üîó Agentic RAG](rag_tutorials/agentic_rag/)
*   [üßê Agentic RAG with Reasoning](rag_tutorials/agentic_rag_with_reasoning/)
*   [üì∞ AI Blog Search (RAG)](rag_tutorials/ai_blog_search/)
*   [üîç Autonomous RAG](rag_tutorials/autonomous_rag/)
*   [üîÑ Corrective RAG (CRAG)](rag_tutorials/corrective_rag/)
*   [üêã Deepseek Local RAG Agent](rag_tutorials/deepseek_local_rag_agent/)
*   [ü§î Gemini Agentic RAG](rag_tutorials/gemini_agentic_rag/)
*   [üëÄ Hybrid Search RAG (Cloud)](rag_tutorials/hybrid_search_rag/)
*   [üîÑ Llama 3.1 Local RAG](rag_tutorials/llama3.1_local_rag/)
*   [üñ•Ô∏è Local Hybrid Search RAG](rag_tutorials/local_hybrid_search_rag/)
*   [ü¶ô Local RAG Agent](rag_tutorials/local_rag_agent/)
*   [üß© RAG-as-a-Service](rag_tutorials/rag-as-a-service/)
*   [‚ú® RAG Agent with Cohere](rag_tutorials/rag_agent_cohere/)
*   [‚õìÔ∏è Basic RAG Chain](rag_tutorials/rag_chain/)
*   [üì† RAG with Database Routing](rag_tutorials/rag_database_routing/)
*   [üñºÔ∏è Vision RAG](rag_tutorials/vision_rag/)

### üíæ LLM Apps with Memory Tutorials

*   [üíæ AI ArXiv Agent with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/ai_arxiv_agent_memory/)
*   [üõ©Ô∏è AI Travel Agent with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/ai_travel_agent_memory/)
*   [üí¨ Llama3 Stateful Chat](advanced_llm_apps/llm_apps_with_memory_tutorials/llama3_stateful_chat/)
*   [üìù LLM App with Personalized Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/llm_app_personalized_memory/)
*   [üóÑÔ∏è Local ChatGPT Clone with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/local_chatgpt_with_memory/)
*   [üß† Multi-LLM Application with Shared Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/multi_llm_memory/)


### üí¨ Chat with X Tutorials

*   [üí¨ Chat with GitHub (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_github/)
*   [üì® Chat with Gmail](advanced_llm_apps/chat_with_X_tutorials/chat_with_gmail/)
*   [üìÑ Chat with PDF (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_pdf/)
*   [üìö Chat with Research Papers (ArXiv) (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_research_papers/)
*   [üìù Chat with Substack](advanced_llm_apps/chat_with_X_tutorials/chat_with_substack/)
*   [üìΩÔ∏è Chat with YouTube Videos](advanced_llm_apps/chat_with_X_tutorials/chat_with_youtube_videos/)

### üîß LLM Fine-tuning Tutorials

*   [üîß Llama 3.2 Fine-tuning](advanced_llm_apps/llm_finetuning_tutorials/llama3.2_finetuning/)

### üßë‚Äçüè´ AI Agent Framework Crash Course

- [Google ADK Crash Course](ai_agent_framework_crash_course/google_adk_crash_course/)
  - Starter agent; model‚Äëagnostic (OpenAI, Claude)
  - Structured outputs (Pydantic)
  - Tools: built‚Äëin, function, third‚Äëparty, MCP tools
  - Memory; callbacks; Plugins
  - Simple multi‚Äëagent; Multi‚Äëagent patterns

## üöÄ Getting Started

1. **Clone the repository** 

    ```bash 
    git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git 
    ```

2. **Navigate to the desired project directory**

    ```bash 
    cd awesome-llm-apps/starter_ai_agents/ai_travel_agent
    ```

3. **Install the required dependencies**

    ```bash
    pip install -r requirements.txt
    ```

4. **Follow the project-specific instructions** in each project&#039;s `README.md` file to set up and run the app.

## ü§ù Contributing to Open Source

Contributions are welcome! If you have any ideas, improvements, or new apps to add, please create a new [GitHub Issue](https://github.com/Shubhamsaboo/awesome-llm-apps/issues) or submit a pull request. Make sure to follow the existing project structure and include a detailed `README.md` for each new app.

### Thank You, Community, for the Support! üôè

[![Star History Chart](https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&amp;type=Date)](https://star-history.com/#Shubhamsaboo/awesome-llm-apps&amp;Date)

üåü **Don‚Äôt miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.**
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[OpenBB-finance/OpenBB]]></title>
            <link>https://github.com/OpenBB-finance/OpenBB</link>
            <guid>https://github.com/OpenBB-finance/OpenBB</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:18 GMT</pubDate>
            <description><![CDATA[Financial data aggregator for humans and AI agents.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/OpenBB-finance/OpenBB">OpenBB-finance/OpenBB</a></h1>
            <p>Financial data aggregator for humans and AI agents.</p>
            <p>Language: Python</p>
            <p>Stars: 50,215</p>
            <p>Forks: 4,685</p>
            <p>Stars today: 508 stars today</p>
            <h2>README</h2><pre>&lt;br /&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/platform-light.svg?raw=true#gh-light-mode-only&quot; alt=&quot;OpenBB Platform logo&quot; width=&quot;600&quot;&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only&quot; alt=&quot;OpenBB Platform logo&quot; width=&quot;600&quot;&gt;
&lt;br /&gt;
&lt;br /&gt;

[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;label=Follow%20%40openbb_finance)](https://x.com/openbb_finance)
[![Discord Shield](https://img.shields.io/discord/831165782750789672)](https://discord.com/invite/xPHTuHCmuV)
[![Open in Dev Containers](https://img.shields.io/static/v1?label=Dev%20Containers&amp;message=Open&amp;color=blue&amp;logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB)
&lt;a href=&quot;https://codespaces.new/OpenBB-finance/OpenBB&quot;&gt;
  &lt;img src=&quot;https://github.com/codespaces/badge.svg&quot; height=&quot;20&quot; /&gt;
&lt;/a&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb&quot;&gt;
  &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open In Colab&quot;/&gt;
&lt;/a&gt;
[![PyPI](https://img.shields.io/pypi/v/openbb?color=blue&amp;label=PyPI%20Package)](https://pypi.org/project/openbb/)

The first financial Platform that is open source.

The OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.

Get started with: `pip install openbb`

```python
from openbb import obb
output = obb.equity.price.historical(&quot;AAPL&quot;)
df = output.to_dataframe()
```

You can sign up to the [OpenBB Hub](https://my.openbb.co/login) to get the most out of the OpenBB ecosystem.

Data integrations available can be found here: &lt;https://docs.openbb.co/platform/reference&gt;

---

## OpenBB Workspace

While the OpenBB Platform is all about an integration to dozens of different data vendors, the interface is either Python or a CLI.

If you want an enterprise UI to visualize this datasets and use AI agents on top, you can find OpenBB Workspace at &lt;https://pro.openbb.co&gt;.

&lt;a href=&quot;https://pro.openbb.co&quot;&gt;
  &lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png&quot; alt=&quot;Logo&quot; width=&quot;1000&quot;&gt;
  &lt;/div&gt;
&lt;/a&gt;

Data integration:

- You can learn more about adding data to the OpenBB workspace from the [docs](https://docs.openbb.co/workspace) or [this open source repository](https://github.com/OpenBB-finance/backends-for-openbb).

AI Agents integration:

- You can learn more about adding AI agents to the OpenBB workspace from [this open source repository](https://github.com/OpenBB-finance/agents-for-openbb).

### Integrating OpenBB Platform to the OpenBB Workspace

Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.

#### Run OpenBB Platform backend

- Install the packages.

```sh
pip install &quot;openbb[all]&quot;
```

- Start the API server over localhost.

```sh
openbb-api
```

This will launch a FastAPI server, via Uvicorn, at `127.0.0.1:6900`.

You can check that it works by going to &lt;http://127.0.0.1:6900&gt;.

#### Integrate OpenBB Platform backend to OpenBB Workspace

Sign-in to the [OpenBB Workspace](https://pro.openbb.co/), and follow the following steps:

![CleanShot 2025-05-17 at 09 51 56@2x](https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069)

1. Go to the &quot;Apps&quot; tab
2. Click on &quot;Connect backend&quot;
3. Fill in the form with:
   Name: OpenBB Platform
   URL: &lt;http://127.0.0.1:6900&gt;
4. Click on &quot;Test&quot;. You should get a &quot;Test successful&quot; with the number of apps found.
5. Click on &quot;Add&quot;.

That&#039;s it.

---

&lt;!-- TABLE OF CONTENTS --&gt;
&lt;details closed=&quot;closed&quot;&gt;
  &lt;summary&gt;&lt;h2 style=&quot;display: inline-block&quot;&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt;
  &lt;ol&gt;
    &lt;li&gt;&lt;a href=&quot;#1-installation&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#2-contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#3-license&quot;&gt;License&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#4-disclaimer&quot;&gt;Disclaimer&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#5-contacts&quot;&gt;Contacts&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#6-star-history&quot;&gt;Star History&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#7-contributors&quot;&gt;Contributors&lt;/a&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/details&gt;

## 1. Installation

The OpenBB Platform can be installed as a [PyPI package](https://pypi.org/project/openbb/) by running `pip install openbb`

or by cloning the repository directly with `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process, in the [OpenBB Documentation](https://docs.openbb.co/platform/installation).

### OpenBB Platform CLI installation

The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.

It can be installed by running `pip install openbb-cli`

or by cloning the repository directly with  `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process in the [OpenBB Documentation](https://docs.openbb.co/cli/installation).

## 2. Contributing

There are three main ways of contributing to this project. (Hopefully you have starred the project by now ‚≠êÔ∏è)

### Become a Contributor

- More information on our [Contributing Documentation](https://docs.openbb.co/platform/developer_guide/misc/contributing).

### Create a GitHub ticket

Before creating a ticket make sure the one you are creating doesn&#039;t exist already [here](https://github.com/OpenBB-finance/OpenBB/issues)

- [Report bug](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.md&amp;title=%5BBug%5D)
- [Suggest improvement](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=enhancement&amp;template=enhancement.md&amp;title=%5BIMPROVE%5D)
- [Request a feature](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=new+feature&amp;template=feature_request.md&amp;title=%5BFR%5D)

### Provide feedback

We are most active on [our Discord](https://openbb.co/discord), but feel free to reach out to us in any of [our social media](https://openbb.co/links) for feedback.

## 3. License

Distributed under the AGPLv3 License. See
[LICENSE](https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE) for more information.

## 4. Disclaimer

Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment
amount, and may not be suitable for all investors.

Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.

The data contained in the OpenBB Platform is not necessarily accurate.

OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.

All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.

Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.

## 5. Contacts

If you have any questions about the platform or anything OpenBB, feel free to email us at `support@openbb.co`

If you want to say hi, or are interested in partnering with us, feel free to reach us at `hello@openbb.co`

Any of our social media platforms: [openbb.co/links](https://openbb.co/links)

## 6. Star History

This is a proxy of our growth and that we are just getting started.

But for more metrics important to us check [openbb.co/open](https://openbb.co/open).

[![Star History Chart](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)

## 7. Contributors

OpenBB wouldn&#039;t be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.

&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/graphs/contributors&quot;&gt;
   &lt;img src=&quot;https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB&quot; width=&quot;800&quot;/&gt;
&lt;/a&gt;

&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt;
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;

[contributors-shield]: https://img.shields.io/github/contributors/OpenBB-finance/OpenBB.svg?style=for-the-badge
[contributors-url]: https://github.com/OpenBB-finance/OpenBB/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/OpenBB-finance/OpenBB.svg?style=for-the-badge
[forks-url]: https://github.com/OpenBB-finance/OpenBB/network/members
[stars-shield]: https://img.shields.io/github/stars/OpenBB-finance/OpenBB.svg?style=for-the-badge
[stars-url]: https://github.com/OpenBB-finance/OpenBB/stargazers
[issues-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB.svg?style=for-the-badge&amp;color=blue
[issues-url]: https://github.com/OpenBB-finance/OpenBB/issues
[bugs-open-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=yellow
[bugs-open-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aopen
[bugs-closed-shield]: https://img.shields.io/github/issues-closed/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=success
[bugs-closed-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aclosed
[license-shield]: https://img.shields.io/github/license/OpenBB-finance/OpenBB.svg?style=for-the-badge
[license-url]: https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&amp;logo=linkedin&amp;colorB=555
[linkedin-url]: https://linkedin.com/in/DidierRLopes
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[aliasrobotics/cai]]></title>
            <link>https://github.com/aliasrobotics/cai</link>
            <guid>https://github.com/aliasrobotics/cai</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:17 GMT</pubDate>
            <description><![CDATA[Cybersecurity AI (CAI), the framework for AI Security]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aliasrobotics/cai">aliasrobotics/cai</a></h1>
            <p>Cybersecurity AI (CAI), the framework for AI Security</p>
            <p>Language: Python</p>
            <p>Stars: 2,872</p>
            <p>Forks: 409</p>
            <p>Stars today: 329 stars today</p>
            <h2>README</h2><pre># Cybersecurity AI (`CAI`)

&lt;div align=&quot;center&quot;&gt;
  &lt;p&gt;
    &lt;a align=&quot;center&quot; href=&quot;&quot; target=&quot;https://github.com/aliasrobotics/CAI&quot;&gt;
      &lt;img
        width=&quot;100%&quot;
        src=&quot;https://github.com/aliasrobotics/cai/raw/main/media/cai.png&quot;
      &gt;
    &lt;/a&gt;
  &lt;/p&gt;


[![version](https://badge.fury.io/py/cai-framework.svg)](https://badge.fury.io/py/cai-framework)
[![downloads](https://img.shields.io/pypi/dm/cai-framework)](https://pypistats.org/packages/cai-framework)
[![Linux](https://img.shields.io/badge/Linux-Supported-brightgreen?logo=linux&amp;logoColor=white)](https://github.com/aliasrobotics/cai)
[![OS X](https://img.shields.io/badge/OS%20X-Supported-brightgreen?logo=apple&amp;logoColor=white)](https://github.com/aliasrobotics/cai)
[![Windows](https://img.shields.io/badge/Windows-Supported-brightgreen?logo=windows&amp;logoColor=white)](https://github.com/aliasrobotics/cai)
[![Android](https://img.shields.io/badge/Android-Supported-brightgreen?logo=android&amp;logoColor=white)](https://github.com/aliasrobotics/cai)
[![Discord](https://img.shields.io/badge/Discord-7289DA?logo=discord&amp;logoColor=white)](https://discord.gg/fnUFcTaQAC)
[![arXiv](https://img.shields.io/badge/arXiv-2504.06017-b31b1b.svg)](https://arxiv.org/pdf/2504.06017)
[![arXiv](https://img.shields.io/badge/arXiv-2506.23592-b31b1b.svg)](https://arxiv.org/abs/2506.23592)



&lt;/div&gt;

Cybersecurity AI (CAI) is a lightweight, open-source framework that empowers security professionals to build and deploy AI-powered offensive and defensive automation. CAI is the *de facto* framework for AI Security, already used by thousands of individual users and hundreds of organizations. Whether you&#039;re a security researcher, ethical hacker, IT professional, or organization looking to enhance your security posture, CAI provides the building blocks to create specialized AI agents that can assist with mitigation, vulnerability discovery, exploitation, and security assessment.

**Key Features:**
- ü§ñ **300+ AI Models**: Support for OpenAI, Anthropic, DeepSeek, Ollama, and more
- üîß **Built-in Security Tools**: Ready-to-use tools for reconnaissance, exploitation, and privilege escalation  
- üèÜ **Battle-tested**: Proven in HackTheBox CTFs, bug bounties, and real-world security [case studies](https://aliasrobotics.com/case-studies-robot-cybersecurity.php)
- üéØ **Agent-based Architecture**: Modular design with specialized agents for different security tasks

&gt; [!NOTE]
&gt; Read the technical report: [CAI: An Open, Bug Bounty-Ready Cybersecurity AI](https://arxiv.org/pdf/2504.06017)


| [`OT` - CAI and alias0 on: Ecoforest Heat Pumps](https://aliasrobotics.com/case-study-ecoforest.php) | [`Robotics` - CAI and alias0 on: Mobile Industrial Robots (MiR)](https://aliasrobotics.com/case-study-cai-mir.php) |
|------------------------------------------------|---------------------------------|
| CAI discovers critical vulnerability in Ecoforest heat pumps allowing unauthorized remote access and potential catastrophic failures. AI-powered security testing reveals exposed credentials and DES encryption weaknesses affecting all of their deployed units across Europe.  | CAI-powered security testing of MiR (Mobile Industrial Robot) platform through automated ROS message injection attacks. This study demonstrates how AI-driven vulnerability discovery can expose unauthorized access to robot control systems and alarm triggers.  |
| [![](https://aliasrobotics.com/img/case-study-portada-ecoforest.png)](https://aliasrobotics.com/case-study-ecoforest.php) | [![](https://aliasrobotics.com/img/case-study-portada-mir-cai.png)](https://aliasrobotics.com/case-study-cai-mir.php) |

| [`IT` (Web) - CAI and alias0 on: Mercado Libre&#039;s e-commerce](https://aliasrobotics.com/case-study-mercado-libre.php) | [`OT` - CAI and alias0 on: MQTT broker](https://aliasrobotics.com/case-study-cai-mqtt-broker.php) |
|------------------------------------------------|---------------------------------|
|  CAI-powered API vulnerability discovery at Mercado Libre through automated enumeration attacks. This study demonstrates how AI-driven security testing can expose user data exposure risks in e-commerce platforms at scale.  |  CAI-powered testing exposed critical flaws in an MQTT broker within a Dockerized OT network. Without authentication, CAI subscribed to temperature and humidity topics and injected false values, corrupting data shown in Grafana dashboards. |
| [![](https://aliasrobotics.com/img/case-study-portada-mercado-libre.png)](https://aliasrobotics.com/case-study-mercado-libre.php) | [![](https://aliasrobotics.com/img/case-study-portada-mqtt-broker-cai.png)](https://aliasrobotics.com/case-study-cai-mqtt-broker.php) |



&gt; [!WARNING]
&gt; :warning: CAI is in active development, so don&#039;t expect it to work flawlessly. Instead, contribute by raising an issue or [sending a PR](https://github.com/aliasrobotics/cai/pulls).
&gt;
&gt; Access to this library and the use of information, materials (or portions thereof), is **&lt;u&gt;not intended&lt;/u&gt;, and is &lt;u&gt;prohibited&lt;/u&gt;, where such access or use violates applicable laws or regulations**. By no means the authors encourage or promote the unauthorized tampering with running systems. This can cause serious human harm and material damages.
&gt;
&gt; *By no means the authors of CAI encourage or promote the unauthorized tampering with compute systems. Please don&#039;t use the source code in here for cybercrime. &lt;u&gt;Pentest for good instead&lt;/u&gt;*. By downloading, using, or modifying this source code, you agree to the terms of the [`LICENSE`](LICENSE) and the limitations outlined in the [`DISCLAIMER`](DISCLAIMER) file.

## :bookmark: Table of Contents

- [Cybersecurity AI (`CAI`)](#cybersecurity-ai-cai)
  - [:bookmark: Table of Contents](#bookmark-table-of-contents)
  - [üéØ Milestones](#-milestones)
  - [PoCs](#pocs)
  - [Motivation](#motivation)
    - [:bust\_in\_silhouette: Why CAI?](#bust_in_silhouette-why-cai)
    - [Ethical principles behind CAI](#ethical-principles-behind-cai)
    - [Closed-source alternatives](#closed-source-alternatives)
  - [Learn - `CAI` Fluency](#learn---cai-fluency)
  - [:nut\_and\_bolt: Install](#nut_and_bolt-install)
    - [OS X](#os-x)
    - [Ubuntu 24.04](#ubuntu-2404)
    - [Ubuntu 20.04](#ubuntu-2004)
    - [Windows WSL](#windows-wsl)
    - [Android](#android)
    - [:nut\_and\_bolt: Setup `.env` file](#nut_and_bolt-setup-env-file)
    - [üîπ Custom OpenAI Base URL Support](#-custom-openai-base-url-support)
  - [:triangular\_ruler: Architecture:](#triangular_ruler-architecture)
    - [üîπ Agent](#-agent)
    - [üîπ Tools](#-tools)
    - [üîπ Handoffs](#-handoffs)
    - [üîπ Patterns](#-patterns)
    - [üîπ Turns and Interactions](#-turns-and-interactions)
    - [üîπ Tracing](#-tracing)
    - [üîπ Human-In-The-Loop (HITL)](#-human-in-the-loop-hitl)
  - [:rocket: Quickstart](#rocket-quickstart)
    - [Environment Variables](#environment-variables)
    - [OpenRouter Integration](#openrouter-integration)
    - [MCP](#mcp)
  - [Development](#development)
    - [Contributions](#contributions)
    - [Optional Requirements: caiextensions](#optional-requirements-caiextensions)
    - [:information\_source: Usage Data Collection](#information_source-usage-data-collection)
    - [Reproduce CI-Setup locally](#reproduce-ci-setup-locally)
  - [FAQ](#faq)
  - [Citation](#citation)
  - [Acknowledgements](#acknowledgements)



## üéØ Milestones
[![](https://img.shields.io/badge/HTB_ranking-top_90_Spain_(5_days)-red.svg)](https://app.hackthebox.com/users/2268644)
[![](https://img.shields.io/badge/HTB_ranking-top_50_Spain_(6_days)-red.svg)](https://app.hackthebox.com/users/2268644)
[![](https://img.shields.io/badge/HTB_ranking-top_30_Spain_(7_days)-red.svg)](https://app.hackthebox.com/users/2268644)
[![](https://img.shields.io/badge/HTB_ranking-top_500_World_(7_days)-red.svg)](https://app.hackthebox.com/users/2268644)
[![](https://img.shields.io/badge/HTB_&quot;Human_vs_AI&quot;_CTF-top_1_(AIs)_world-red.svg)](https://ctf.hackthebox.com/event/2000/scoreboard)
[![](https://img.shields.io/badge/HTB_&quot;Human_vs_AI&quot;_CTF-top_1_Spain-red.svg)](https://ctf.hackthebox.com/event/2000/scoreboard)
[![](https://img.shields.io/badge/HTB_&quot;Human_vs_AI&quot;_CTF-top_20_World-red.svg)](https://ctf.hackthebox.com/event/2000/scoreboard)
[![](https://img.shields.io/badge/HTB_&quot;Human_vs_AI&quot;_CTF-750_$-yellow.svg)](https://ctf.hackthebox.com/event/2000/scoreboard)
[![](https://img.shields.io/badge/Mistral_AI_Robotics_Hackathon-2500_$-yellow.svg)](https://lu.ma/roboticshack?tk=RuryKF)

## PoCs
| CAI with `alias0` on ROS message injection attacks in MiR-100 robot | CAI with `alias0` on API vulnerability discovery at Mercado Libre |
|-----------------------------------------------|---------------------------------|
| [![asciicast](https://asciinema.org/a/dNv705hZel2Rzrw0cju9HBGPh.svg)](https://asciinema.org/a/dNv705hZel2Rzrw0cju9HBGPh) | [![asciicast](https://asciinema.org/a/9Hc9z1uFcdNjqP3bY5y7wO1Ww.svg)](https://asciinema.org/a/9Hc9z1uFcdNjqP3bY5y7wO1Ww) |


| CAI on JWT@PortSwigger CTF ‚Äî Cybersecurity AI | CAI on HackableII Boot2Root CTF ‚Äî Cybersecurity AI |
|-----------------------------------------------|---------------------------------|
| [![asciicast](https://asciinema.org/a/713487.svg)](https://asciinema.org/a/713487) | [![asciicast](https://asciinema.org/a/713485.svg)](https://asciinema.org/a/713485) |

More case studies and PoCs are available at [https://aliasrobotics.com/case-studies-robot-cybersecurity.php](https://aliasrobotics.com/case-studies-robot-cybersecurity.php).

## Motivation
### :bust_in_silhouette: Why CAI?
The cybersecurity landscape is undergoing a dramatic transformation as AI becomes increasingly integrated into security operations. **We predict that by 2028, AI-powered security testing tools will outnumber human pentesters**. This shift represents a fundamental change in how we approach cybersecurity challenges. *AI is not just another tool - it&#039;s becoming essential for addressing complex security vulnerabilities and staying ahead of sophisticated threats. As organizations face more advanced cyber attacks, AI-enhanced security testing will be crucial for maintaining robust defenses.*

This work builds upon prior efforts[^4] and similarly, we believe that democratizing access to advanced cybersecurity AI tools is vital for the entire security community. That&#039;s why we&#039;re releasing Cybersecurity AI (`CAI`) as an open source framework. Our goal is to empower security researchers, ethical hackers, and organizations to build and deploy powerful AI-driven security tools. By making these capabilities openly available, we aim to level the playing field and ensure that cutting-edge security AI technology isn&#039;t limited to well-funded private companies or state actors.

Bug Bounty programs have become a cornerstone of modern cybersecurity, providing a crucial mechanism for organizations to identify and fix vulnerabilities in their systems before they can be exploited. These programs have proven highly effective at securing both public and private infrastructure, with researchers discovering critical vulnerabilities that might have otherwise gone unnoticed. CAI is specifically designed to enhance these efforts by providing a lightweight, ergonomic framework for building specialized AI agents that can assist in various aspects of Bug Bounty hunting - from initial reconnaissance to vulnerability validation and reporting. Our framework aims to augment human expertise with AI capabilities, helping researchers work more efficiently and thoroughly in their quest to make digital systems more secure.

### Ethical principles behind CAI

You might be wondering if releasing CAI *in-the-wild* given its capabilities and security implications is ethical. Our decision to open-source this framework is guided by two core ethical principles:

1. **Democratizing Cybersecurity AI**: We believe that advanced cybersecurity AI tools should be accessible to the entire security community, not just well-funded private companies or state actors. By releasing CAI as an open source framework, we aim to empower security researchers, ethical hackers, and organizations to build and deploy powerful AI-driven security tools, leveling the playing field in cybersecurity.

2. **Transparency in AI Security Capabilities**: Based on our research results, understanding of the technology, and dissection of top technical reports, we argue that current LLM vendors are undermining their cybersecurity capabilities. This is extremely dangerous and misleading. By developing CAI openly, we provide a transparent benchmark of what AI systems can actually do in cybersecurity contexts, enabling more informed decisions about security postures.

CAI is built on the following core principles:
- **Cybersecurity oriented AI framework**: CAI is specifically designed for cybersecurity use cases, aiming at semi- and fully-automating offensive and defensive security tasks.
- **Open source, free for research**: CAI is open source and free for research purposes. We aim at democratizing access to AI and Cybersecurity. For professional or commercial use, including on-premise deployments, dedicated technical support and custom extensions [reach out](mailto:research@aliasrobotics.com) to obtain a license.
- **Lightweight**: CAI is designed to be fast, and easy to use.
- **Modular and agent-centric design**: CAI operates on the basis of agents and agentic patterns, which allows flexibility and scalability. You can easily add the most suitable agents and pattern for your cybersecuritytarget case.
- **Tool-integration**: CAI integrates already built-in tools, and allows the user to integrate their own tools with their own logic easily.
- **Logging and tracing integrated**: using [`phoenix`](https://github.com/Arize-ai/phoenix), the open source tracing and logging tool for LLMs. This provides the user with a detailed traceability of the agents and their execution.
- **Multi-Model Support**: more than 300 supported and empowered by [LiteLLM](https://github.com/BerriAI/litellm). The most popular providers:
  - **Anthropic**: `Claude 3.7`, `Claude 3.5`, `Claude 3`, `Claude 3 Opus`
  - **OpenAI**: `O1`, `O1 Mini`, `O3 Mini`, `GPT-4o`, `GPT-4.5 Preview`
  - **DeepSeek**: `DeepSeek V3`, `DeepSeek R1`
  - **Ollama**: `Qwen2.5 72B`, `Qwen2.5 14B`, etc


### Closed-source alternatives
Cybersecurity AI is a critical field, yet many groups are misguidedly pursuing it through closed-source methods for pure economic return, leveraging similar techniques and building upon existing closed-source (*often third-party owned*) models. This approach not only squanders valuable engineering resources but also represents an economic waste and results in redundant efforts, as they often end up reinventing the wheel. Here are some of the closed-source initiatives we keep track of and attempting to leverage genAI and agentic frameworks in cybersecurity AI:

- [Autonomous Cyber](https://www.acyber.co/)
- [CrackenAGI](https://cracken.ai/)
- [ETHIACK](https://ethiack.com/)
- [Horizon3](https://horizon3.ai/)
- [Kindo](https://www.kindo.ai/)
- [Lakera](https://lakera.ai)
- [Mindfort](www.mindfort.ai)
- [Mindgard](https://mindgard.ai/)
- [NDAY Security](https://ndaysecurity.com/)
- [Runsybil](https://www.runsybil.com)
- [Selfhack](https://www.selfhack.fi)
- [SQUR](https://squr.ai/)
- [Staris](https://staris.tech/)
- [Sxipher](https://www.sxipher.com/) (seems discontinued)
- [Terra Security](https://www.terra.security)
- [Xint](https://xint.io/)
- [XBOW](https://www.xbow.com)
- [ZeroPath](https://www.zeropath.com)
- [Zynap](https://www.zynap.com)
- [7ai](https://7ai.com)


## Learn - `CAI` Fluency

&lt;div align=&quot;center&quot;&gt;
  &lt;p&gt;
    &lt;a align=&quot;center&quot; href=&quot;&quot; target=&quot;https://github.com/aliasrobotics/CAI&quot;&gt;
      &lt;img
        width=&quot;100%&quot;
        src=&quot;https://github.com/aliasrobotics/cai/raw/main/media/caiedu.PNG&quot;
      &gt;
    &lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;


|       |   Description  | English | Spanish |
|-------|----------------|---------|---------|
| **Episode 0**: What is CAI? | Cybersecurity AI (`CAI`) explained  |  [![Watch the video](https://img.youtube.com/vi/nBdTxbKM4oo/0.jpg)](https://www.youtube.com/watch?v=nBdTxbKM4oo) | [![Watch the video](https://img.youtube.com/vi/FaUL9HXrQ5k/0.jpg)](https://www.youtube.com/watch?v=FaUL9HXrQ5k) |
| **Episode 1**: The `CAI` Framework | Vision &amp; Ethics - Explore the core motivation behind CAI and delve into the crucial ethical principles guiding its development. Understand the motivation behind CAI and how you can actively contribute to the future of cybersecurity and the CAI framework. | [![Watch the video](https://img.youtube.com/vi/QEiGdsMf29M/0.jpg)](https://www.youtube.com/watch?v=QEiGdsMf29M&amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;index=3) |  |
| **Episode 2**: From Zero to Cyber Hero | Breaking into Cybersecurity with AI - A comprehensive guide for complete beginners to become cybersecurity practitioners using CAI and AI tools. Learn how to leverage artificial intelligence to accelerate your cybersecurity learning journey, from understanding basic security concepts to performing real-world security assessments, all without requiring prior cybersecurity experience. | [![Watch the video](https://img.youtube.com/vi/hSTLHOOcQoY/0.jpg)](https://www.youtube.com/watch?v=hSTLHOOcQoY&amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;index=14) |  |
| **Episode 3**: Vibe-Hacking Tutorial | &quot;My first Hack&quot; - A Vibe-Hacking guide for newbies. We demonstrate a simple web security hack using a default agent and show how to leverage tools and interpret CIA output with the help of the CAI Python API. You&#039;ll also learn to compare different LLM models to find the best fit for your hacking endeavors. | [![Watch the video](https://img.youtube.com/vi/9vZ_Iyex7uI/0.jpg)](https://www.youtube.com/watch?v=9vZ_Iyex7uI&amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;index=1) | [![Watch the video](https://img.youtube.com/vi/iAOMaI1ftiA/0.jpg)](https://www.youtube.com/watch?v=iAOMaI1ftiA&amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;index=2) |
| **Episode 4**: Intro ReAct | The Evolution of LLMs - Learn how LLMs evolved from basic language models to advanced multiagency AI systems. From basic LLMs to Chain-of-Thought and Reasoning LLMs towards ReAct and Multi-Agent Architectures. Get to know the basic terms | [![Watch the video](https://img.youtube.com/vi/tLdFO1flj_o/0.jpg)](https://www.youtube.com/watch?v=tLdFO1flj_o&amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;index=13) | |
| **Episode 5**: CAI on CTF challenges | Dive into Capture The Flag (CTF) competitions using CAI. Learn how to leverage AI agents to solve various cybersecurity challenges including web exploitation, cryptography, reverse engineering, and forensics. Discover how to configure CAI for competitive hacking scenarios and maximize your CTF performance with intelligent automation. | [![Watch the video](https://img.youtube.com/vi/MrXTQ0e2to4/0.jpg)](https://www.youtube.com/watch?v=MrXTQ0e2to4&amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;index=13) | [![Watch the video](https://img.youtube.com/vi/r9US_JZa9_c/0.jpg)](https://www.youtube.com/watch?v=r9US_JZa9_c&amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;index=12) |
|  |  |  |  |
| **Annex 1**: `CAI` 0.5.x release  | Introduce version 0.5 of `CAI` including new multi-agent functionality, new commands such as `/history`, `/compact`, `/graph` or `/memory` and a case study showing how `CAI` found a critical security flaw in OT heap pumps spread around the world. |  [![Watch the video](https://img.youtube.com/vi/OPFH0ANUMMw/0.jpg)](https://www.youtube.com/watch?v=OPFH0ANUMMw) | [![Watch the video](https://img.youtube.com/vi/Q8AI4E4gH8k/0.jpg)](https://www.youtube.com/watch?v=Q8AI4E4gH8k) |
| **Annex 2**: `CAI` 0.4.x release and `alias0`  | Introducing version 0.4 of `CAI` with *streaming* and improved MCP support. We also introduce `alias0`, the Privacy-First Cybersecurity AI, a Model-of-Models Intelligence that implements a Privacy-by-Design architecture and obtains state-

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[jianchang512/pyvideotrans]]></title>
            <link>https://github.com/jianchang512/pyvideotrans</link>
            <guid>https://github.com/jianchang512/pyvideotrans</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:16 GMT</pubDate>
            <description><![CDATA[Translate the video from one language to another and add dubbing. Â∞ÜËßÜÈ¢ë‰ªé‰∏ÄÁßçËØ≠Ë®ÄÁøªËØë‰∏∫Âè¶‰∏ÄÁßçËØ≠Ë®ÄÔºåÂêåÊó∂ÊîØÊåÅËØ≠Èü≥ËØÜÂà´ËΩ¨ÂΩï„ÄÅËØ≠Èü≥ÂêàÊàê„ÄÅÂ≠óÂπïÁøªËØë„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jianchang512/pyvideotrans">jianchang512/pyvideotrans</a></h1>
            <p>Translate the video from one language to another and add dubbing. Â∞ÜËßÜÈ¢ë‰ªé‰∏ÄÁßçËØ≠Ë®ÄÁøªËØë‰∏∫Âè¶‰∏ÄÁßçËØ≠Ë®ÄÔºåÂêåÊó∂ÊîØÊåÅËØ≠Èü≥ËØÜÂà´ËΩ¨ÂΩï„ÄÅËØ≠Èü≥ÂêàÊàê„ÄÅÂ≠óÂπïÁøªËØë„ÄÇ</p>
            <p>Language: Python</p>
            <p>Stars: 13,751</p>
            <p>Forks: 1,568</p>
            <p>Stars today: 56 stars today</p>
            <h2>README</h2><pre>ÁÆÄ‰Ωì‰∏≠Êñá | [English](docs/EN/README_EN.md)  | [ÊçêÂä©](docs/about.md) | ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑Ôºö`pyvideotrans`

# ËßÜÈ¢ëÁøªËØëÈÖçÈü≥Â∑•ÂÖ∑

ËøôÊòØ‰∏Ä‰∏™ËßÜÈ¢ëÁøªËØëÈÖçÈü≥Â∑•ÂÖ∑ÔºåÂèØÂ∞Ü‰∏ÄÁßçËØ≠Ë®ÄÁöÑËßÜÈ¢ëÁøªËØë‰∏∫ÊåáÂÆöËØ≠Ë®ÄÁöÑËßÜÈ¢ëÔºåËá™Âä®ÁîüÊàêÂíåÊ∑ªÂä†ËØ•ËØ≠Ë®ÄÁöÑÂ≠óÂπïÂíåÈÖçÈü≥„ÄÇÂπ∂ÊîØÊåÅAPIË∞ÉÁî®(v3.0‰ª•‰∏ãÁâàÊú¨Ôºå‰ª•‰∏ä‰πÖÊú™Êõ¥Êñ∞)


ËØ≠Èü≥ËØÜÂà´ÊîØÊåÅ `faster-whisper/openai-whisper/OpenAI API/Deepgram.com/Gemini/Parakeet/GoogleSpeech/ÈòøÈáåFunasr/Â≠óËäÇÁÅ´Â±±Á≠â`ÔºåÂπ∂ÊîØÊåÅËá™ÂÆö‰πâËØ≠Èü≥ËØÜÂà´api.

ÊñáÂ≠óÁøªËØëÊîØÊåÅ `ÂæÆËΩØÁøªËØë|GoogleÁøªËØë|ÁôæÂ∫¶ÁøªËØë|ËÖæËÆØÁøªËØë|ChatGPT|AzureAI|Gemini|DeepSeek|claude|DeepL|DeepLX|Â≠óËäÇÁÅ´Â±±|Á¶ªÁ∫øÁøªËØëOTT|Ëá™ÂÆö‰πâAPIÁ≠â`

ÊñáÂ≠óÂêàÊàêËØ≠Èü≥ÊîØÊåÅ `Edge tts` `Google tts` `Azure AI TTS` `Openai TTS` `Elevenlabs TTS` `Ëá™ÂÆö‰πâTTSÊúçÂä°Âô®api` `GPT-SoVITS` `F5-TTS` `Index-tts` `ChatterBox` `Gemini-tts` [clone-voice](https://github.com/jianchang512/clone-voice)  [ChatTTS-ui](https://github.com/jianchang512/ChatTTS-ui)  [Fish TTS](https://github.com/fishaudio/fish-speech)  [CosyVoice](https://github.com/FunAudioLLM/CosyVoice) 

ÂÖÅËÆ∏‰øùÁïôËÉåÊôØ‰º¥Â•èÈü≥‰πêÁ≠â(Âü∫‰∫éuvr5)

ÊîØÊåÅÁöÑËØ≠Ë®ÄÔºö‰∏≠ÊñáÁÆÄÁπÅ„ÄÅËã±ËØ≠„ÄÅÈü©ËØ≠„ÄÅÊó•ËØ≠„ÄÅ‰øÑËØ≠„ÄÅÊ≥ïËØ≠„ÄÅÂæ∑ËØ≠„ÄÅÊÑèÂ§ßÂà©ËØ≠„ÄÅË•øÁè≠ÁâôËØ≠„ÄÅËë°ËêÑÁâôËØ≠„ÄÅË∂äÂçóËØ≠„ÄÅÊ≥∞ÂõΩËØ≠„ÄÅÈòøÊãâ‰ºØËØ≠„ÄÅÂúüËÄ≥ÂÖ∂ËØ≠„ÄÅÂåàÁâôÂà©ËØ≠„ÄÅÂç∞Â∫¶ËØ≠„ÄÅ‰πåÂÖãÂÖ∞ËØ≠„ÄÅÂìàËê®ÂÖãËØ≠„ÄÅÂç∞Â∞ºËØ≠„ÄÅÈ©¨Êù•ËØ≠„ÄÅÊç∑ÂÖãËØ≠„ÄÅÊ≥¢ÂÖ∞ËØ≠„ÄÅËç∑ÂÖ∞ËØ≠„ÄÅÁëûÂÖ∏ËØ≠„ÄÅËä¨ÂÖ∞ËØ≠„ÄÅËè≤ÂæãÂÆæËØ≠„ÄÅÂ≠üÂä†ÊãâËØ≠„ÄÅ‰πåÂ∞îÈÉΩËØ≠„ÄÅÂ∏å‰ºØÊù•ËØ≠„ÄÅÁ≤§ËØ≠Á≠âÔºåÂÖ∂‰ªñËØ≠Ë®ÄÂèØÈÄâËá™Âä®Ê£ÄÊµã


&gt; **[ËµûÂä©ÂïÜ]**
&gt; 
&gt; [![](https://github.com/user-attachments/assets/5348c86e-2d5f-44c7-bc1b-3cc5f077e710)](https://gpt302.saaslink.net/teRK8Y)
&gt;  [302.AI](https://gpt302.saaslink.net/teRK8Y)ÊòØ‰∏Ä‰∏™ÊåâÈúÄ‰ªòË¥πÁöÑ‰∏ÄÁ´ôÂºèAIÂ∫îÁî®Âπ≥Âè∞ÔºåÂºÄÊîæÂπ≥Âè∞ÔºåÂºÄÊ∫êÁîüÊÄÅ, [302.AIÂºÄÊ∫êÂú∞ÂùÄ](https://gpt302.saaslink.net/teRK8Y)
&gt; 
&gt; ÈõÜÂêà‰∫ÜÊúÄÊñ∞ÊúÄÂÖ®ÁöÑAIÊ®°ÂûãÂíåÂìÅÁâå/ÊåâÈúÄ‰ªòË¥πÈõ∂ÊúàË¥π/ÁÆ°ÁêÜÂíå‰ΩøÁî®ÂàÜÁ¶ª/ÊâÄÊúâAIËÉΩÂäõÂùáÊèê‰æõAPI/ÊØèÂë®Êé®Âá∫2-3‰∏™Êñ∞Â∫îÁî®


## ‰∏ªË¶ÅÁî®ÈÄîÂíåÂäüËÉΩ

„ÄêËá™Âä®ÁøªËØëËßÜÈ¢ëÂπ∂ÈÖçÈü≥„ÄëÂ∞ÜËßÜÈ¢ë‰∏≠ÁöÑÂ£∞Èü≥ÁøªËØë‰∏∫Âè¶‰∏ÄÁßçËØ≠Ë®ÄÁöÑÈÖçÈü≥ÔºåÂπ∂ÂµåÂÖ•ËØ•ËØ≠Ë®ÄÂ≠óÂπï

„ÄêËØ≠Èü≥ËØÜÂà´/Â∞ÜÈü≥È¢ëËßÜÈ¢ëËΩ¨‰∏∫Â≠óÂπï„ÄëÂèØÊâπÈáèÂ∞ÜÈü≥È¢ë„ÄÅËßÜÈ¢ëÊñá‰ª∂‰∏≠ÁöÑ‰∫∫Á±ªËØ¥ËØùÂ£∞ÔºåËØÜÂà´‰∏∫ÊñáÂ≠óÂπ∂ÂØºÂá∫‰∏∫srtÂ≠óÂπïÊñá‰ª∂

„ÄêËØ≠Èü≥ÂêàÊàê/Â≠óÂπïÈÖçÈü≥„ÄëÊ†πÊçÆÊú¨Âú∞Â∑≤ÊúâÁöÑsrtÂ≠óÂπïÊñá‰ª∂ÂàõÂª∫ÈÖçÈü≥ÔºåÊîØÊåÅÂçï‰∏™ÊàñÊâπÈáèÂ≠óÂπï

„ÄêÂ≠óÂπïÂ§öËßíËâ≤ÈÖçÈü≥„ÄëÂØºÂÖ•Êú¨Âú∞Â∑≤ÊúâÁöÑsrtÂ≠óÂπïÔºå‰∏∫ÊØèÊù°Â≠óÂπïÊåáÂÆö‰∏Ä‰∏™ÈÖçÈü≥ËßíËâ≤ÔºåÂàõÂª∫Â§öËßíËâ≤ÈÖçÈü≥Êñá‰ª∂

„ÄêÁøªËØëÂ≠óÂπïÊñá‰ª∂„ÄëÂ∞Ü‰∏Ä‰∏™ÊàñÂ§ö‰∏™srtÂ≠óÂπïÊñá‰ª∂ÁøªËØë‰∏∫ÂÖ∂‰ªñËØ≠Ë®ÄÁöÑÂ≠óÂπïÊñá‰ª∂

„ÄêÂêàÂπ∂ËßÜÈ¢ëÂíåÈü≥È¢ë„ÄëÊâπÈáèÂ∞ÜËßÜÈ¢ëÊñá‰ª∂ÂíåÈü≥È¢ëÊñá‰ª∂‰∏Ä‰∏ÄÂØπÂ∫îÂêàÂπ∂

„ÄêÂêàÂπ∂ËßÜÈ¢ëÂíåsrtÂ≠óÂπï„ÄëÊâπÈáèÂ∞ÜËßÜÈ¢ëÊñá‰ª∂srtÂ≠óÂπïÊñá‰ª∂‰∏Ä‰∏ÄÂØπÂ∫îÂêàÂπ∂

„Äê‰∏∫ËßÜÈ¢ëÊ∑ªÂä†ÂõæÁâáÊ∞¥Âç∞„ÄëÊâπÈáèÂ∞ÜËßÜÈ¢ëÊñá‰ª∂‰∏≠ÂµåÂÖ•ÂõæÁâáÊ∞¥Âç∞

„Äê‰ªéËßÜÈ¢ë‰∏≠ÊèêÂèñÈü≥È¢ë„Äë‰ªéËßÜÈ¢ë‰∏≠ÂàÜÁ¶ª‰∏∫Èü≥È¢ëÊñá‰ª∂ÂíåÊó†Â£∞ËßÜÈ¢ë

„ÄêÈü≥È¢ëËßÜÈ¢ëÊ†ºÂºèËΩ¨Êç¢„ÄëÊâπÈáèÂ∞ÜÈü≥È¢ëËßÜÈ¢ëËøõË°åÊ†ºÂºèËΩ¨Êç¢

„ÄêÂ≠óÂπïÁºñËæëÂπ∂ÂØºÂá∫Â§öÊ†ºÂºè„ÄëÊîØÊåÅÂØºÂÖ•srt„ÄÅvtt„ÄÅassÊ†ºÂºèÂ≠óÂπïÔºåÁºñËæëÂêéÂèØËÆæÁΩÆÂ≠ó‰ΩìÊ†∑Âºè„ÄÅËâ≤ÂΩ©Á≠âÂØºÂá∫ÂØπÂ∫îÊ†ºÂºèÂ≠óÂπï

„ÄêÂ≠óÂπïÊ†ºÂºèËΩ¨Êç¢„ÄëÊâπÈáèÂ∞ÜÂ≠óÂπïÊñá‰ª∂ËøõË°å srt/ass/vtt Ê†ºÂºè‰∫íËΩ¨

„Äê‰∫∫Â£∞ËÉåÊôØ‰πêÂàÜÁ¶ª„Äë

„ÄêAPIË∞ÉÁî®&lt;v3.0„ÄëÊîØÊåÅ ËØ≠Èü≥ÂêàÊàê„ÄÅËØ≠Ë®ÄËØÜÂà´„ÄÅÂ≠óÂπïÁøªËØë„ÄÅËßÜÈ¢ëÁøªËØëÊé•Âè£Ë∞ÉÁî®

----

![pyvideotrans-home](https://github.com/user-attachments/assets/b2f95a7f-b4e5-4a6d-b2a5-eb6cd22531e0)

[![Open In Colab](https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&amp;logo=googlecolab&amp;color=525252)](https://colab.research.google.com/drive/1kPTeAMz3LnWRnGmabcz4AWW42hiehmfm?usp=sharing)

## È¢ÑÊâìÂåÖÁâàÊú¨(‰ªÖwin10/win11ÂèØÁî®ÔºåMacOS/LinuxÁ≥ªÁªü‰ΩøÁî®Ê∫êÁ†ÅÈÉ®ÁΩ≤)

&gt; ‰ΩøÁî®pyinstallerÊâìÂåÖÔºåÊú™ÂÅöÂÖçÊùÄÂíåÁ≠æÂêçÔºåÊùÄËΩØÂèØËÉΩÊä•ÊØíÔºåËØ∑Âä†ÂÖ•‰ø°‰ªªÂêçÂçïÊàñ‰ΩøÁî®Ê∫êÁ†ÅÈÉ®ÁΩ≤

0. [ÁÇπÂáªÂéª‰∏ãËΩΩÈ¢ÑÊâìÂåÖÁâà,Ëß£ÂéãÂà∞Êó†Á©∫Ê†ºÁöÑËã±ÊñáÁõÆÂΩïÂêéÔºåÂèåÂáª sp.exe (https://github.com/jianchang512/pyvideotrans/releases)

1. Ëß£ÂéãÂà∞Ëã±ÊñáË∑ØÂæÑ‰∏ãÔºåÂπ∂‰∏îË∑ØÂæÑ‰∏≠‰∏çÂê´ÊúâÁ©∫Ê†º„ÄÇËß£ÂéãÂêéÂèåÂáª sp.exe  (Ëã•ÈÅáÂà∞ÊùÉÈôêÈóÆÈ¢òÂèØÂè≥ÈîÆ‰ΩøÁî®ÁÆ°ÁêÜÂëòÊùÉÈôêÊâìÂºÄ)

4. Ê≥®ÊÑèÔºöÂøÖÈ°ªËß£ÂéãÂêé‰ΩøÁî®Ôºå‰∏çÂèØÁõ¥Êé•ÂéãÁº©ÂåÖÂÜÖÂèåÂáª‰ΩøÁî®Ôºå‰πü‰∏çÂèØËß£ÂéãÂêéÁßªÂä®sp.exeÊñá‰ª∂Âà∞ÂÖ∂‰ªñ‰ΩçÁΩÆ



## MacOSÊ∫êÁ†ÅÈÉ®ÁΩ≤

0. ÊâìÂºÄÁªàÁ´ØÁ™óÂè£ÔºåÂàÜÂà´ÊâßË°åÂ¶Ç‰∏ãÂëΩ‰ª§
	
	&gt; ÊâßË°åÂâçÁ°Æ‰øùÂ∑≤ÂÆâË£Ö HomebrewÔºåÂ¶ÇÊûú‰Ω†Ê≤°ÊúâÂÆâË£Ö Homebrew,ÈÇ£‰πàÈúÄË¶ÅÂÖàÂÆâË£Ö
	&gt;
	&gt; ÊâßË°åÂëΩ‰ª§ÂÆâË£Ö HomebrewÔºö  `/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;`
	&gt;
	&gt; ÂÆâË£ÖÂÆåÊàêÂêéÔºåÊâßË°åÔºö `eval $(brew --config)`
	&gt;

    ```
    brew install libsndfile

    brew install ffmpeg

    brew install git

    brew install python@3.10

    ```

    ÁªßÁª≠ÊâßË°å

    ```
    export PATH=&quot;/usr/local/opt/python@3.10/bin:$PATH&quot;

    source ~/.bash_profile 
	
	source ~/.zshrc

    ```



1. ÂàõÂª∫‰∏çÂê´Á©∫Ê†ºÂíå‰∏≠ÊñáÁöÑÊñá‰ª∂Â§πÔºåÂú®ÁªàÁ´Ø‰∏≠ËøõÂÖ•ËØ•Êñá‰ª∂Â§π„ÄÇ
2. ÁªàÁ´Ø‰∏≠ÊâßË°åÂëΩ‰ª§ `git clone https://github.com/jianchang512/pyvideotrans `
3. ÊâßË°åÂëΩ‰ª§ `cd pyvideotrans`
4. ÁªßÁª≠ÊâßË°å `python -m venv venv`
5. ÁªßÁª≠ÊâßË°åÂëΩ‰ª§ `source ./venv/bin/activate`ÔºåÊâßË°åÂÆåÊØïÊü•ÁúãÁ°ÆËÆ§ÁªàÁ´ØÂëΩ‰ª§ÊèêÁ§∫Á¨¶Â∑≤ÂèòÊàêÂ∑≤`(venv)`ÂºÄÂ§¥,‰ª•‰∏ãÂëΩ‰ª§ÂøÖÈ°ªÁ°ÆÂÆöÁªàÁ´ØÊèêÁ§∫Á¨¶ÊòØ‰ª•`(venv)`ÂºÄÂ§¥
6. ÊâßË°å `pip install -r requirements.txt `ÔºåÂ¶ÇÊûúÊèêÁ§∫Â§±Ë¥•ÔºåÊâßË°åÂ¶Ç‰∏ã2Êù°ÂëΩ‰ª§ÂàáÊç¢pipÈïúÂÉèÂà∞ÈòøÈáåÈïúÂÉè

    ```
    pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/
    pip config set install.trusted-host mirrors.aliyun.com
    ```

    ÁÑ∂ÂêéÈáçÊñ∞ÊâßË°å
    Â¶ÇÊûúÂ∑≤ÂàáÊç¢Âà∞ÈòøÈáåÈïúÂÉèÊ∫êÔºå‰ªçÊèêÁ§∫Â§±Ë¥•ÔºåËØ∑Â∞ùËØïÊâßË°å `pip install -r requirements.txt`

7. `python sp.py` ÊâìÂºÄËΩØ‰ª∂ÁïåÈù¢



## Linux Ê∫êÁ†ÅÈÉ®ÁΩ≤

0. CentOS/RHELÁ≥ª‰æùÊ¨°ÊâßË°åÂ¶Ç‰∏ãÂëΩ‰ª§ÂÆâË£Ö python3.10

```

sudo yum update

sudo yum groupinstall &quot;Development Tools&quot;

sudo yum install openssl-devel bzip2-devel libffi-devel

cd /tmp

wget https://www.python.org/ftp/python/3.10.4/Python-3.10.4.tgz

tar xzf Python-3.10.4.tgz

cd Python-3.10.4

./configure ‚Äî enable-optimizations

sudo make &amp;&amp; sudo make install

sudo alternatives ‚Äî install /usr/bin/python3 python3 /usr/local/bin/python3.10 1

sudo yum install -y ffmpeg

```

1. Ubuntu/DebianÁ≥ªÊâßË°åÂ¶Ç‰∏ãÂëΩ‰ª§ÂÆâË£Öpython3.10

```

apt update &amp;&amp; apt upgrade -y

apt install software-properties-common -y

add-apt-repository ppa:deadsnakes/ppa

apt update

sudo apt-get install libxcb-cursor0

apt install python3.10

curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10

sudo update-alternatives --install /usr/bin/python python /usr/local/bin/python3.10  1

sudo update-alternatives --config python

apt-get install ffmpeg

```


**ÊâìÂºÄ‰ªªÊÑè‰∏Ä‰∏™ÁªàÁ´ØÔºåÊâßË°å `python3 -V`ÔºåÂ¶ÇÊûúÊòæÁ§∫ ‚Äú3.10.4‚ÄùÔºåËØ¥ÊòéÂÆâË£ÖÊàêÂäüÔºåÂê¶ÂàôÂ§±Ë¥•**


1. ÂàõÂª∫‰∏™‰∏çÂê´Á©∫Ê†ºÂíå‰∏≠ÊñáÁöÑÊñá‰ª∂Â§πÔºå ‰ªéÁªàÁ´ØÊâìÂºÄËØ•Êñá‰ª∂Â§π„ÄÇ
3. ÁªàÁ´Ø‰∏≠ÊâßË°åÂëΩ‰ª§ `git clone https://github.com/jianchang512/pyvideotrans`
4. ÁªßÁª≠ÊâßË°åÂëΩ‰ª§ `cd pyvideotrans`
5. ÁªßÁª≠ÊâßË°å `python -m venv venv`
6. ÁªßÁª≠ÊâßË°åÂëΩ‰ª§ `source .\venv\scripts\activate`ÔºåÊâßË°åÂÆåÊØïÊü•ÁúãÁ°ÆËÆ§ÁªàÁ´ØÂëΩ‰ª§ÊèêÁ§∫Á¨¶Â∑≤ÂèòÊàêÂ∑≤`(venv)`ÂºÄÂ§¥,‰ª•‰∏ãÂëΩ‰ª§ÂøÖÈ°ªÁ°ÆÂÆöÁªàÁ´ØÊèêÁ§∫Á¨¶ÊòØ‰ª•`(venv)`ÂºÄÂ§¥
7. ÊâßË°å `pip install -r requirements.txt`ÔºåÂ¶ÇÊûúÊèêÁ§∫Â§±Ë¥•ÔºåÊâßË°åÂ¶Ç‰∏ã2Êù°ÂëΩ‰ª§ÂàáÊç¢pipÈïúÂÉèÂà∞ÈòøÈáåÈïúÂÉè

    ```

    pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/
    pip config set install.trusted-host mirrors.aliyun.com

    ```

    ÁÑ∂ÂêéÈáçÊñ∞ÊâßË°å,Â¶ÇÊûúÂ∑≤ÂàáÊç¢Âà∞ÈòøÈáåÈïúÂÉèÊ∫êÔºå‰ªçÊèêÁ§∫Â§±Ë¥•ÔºåËØ∑Â∞ùËØïÊâßË°å `pip install -r requirements.txt `
8. Â¶ÇÊûúË¶Å‰ΩøÁî®CUDAÂä†ÈÄüÔºåÂàÜÂà´ÊâßË°å

    `pip uninstall -y torch torchaudio`

    `pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu126`

    `pip install nvidia-cublas-cu12 nvidia-cudnn-cu12`

9. linux Â¶ÇÊûúË¶ÅÂêØÁî®cudaÂä†ÈÄüÔºåÂøÖÈ°ªÊúâËã±‰ºüËææÊòæÂç°ÔºåÂπ∂‰∏îÈÖçÁΩÆÂ•Ω‰∫ÜCUDA12+ÁéØÂ¢É,ËØ∑Ëá™Ë°åÊêúÁ¥¢ &quot;Linux CUDA ÂÆâË£Ö&quot;


10. `python sp.py` ÊâìÂºÄËΩØ‰ª∂ÁïåÈù¢


## Window10/11 Ê∫êÁ†ÅÈÉ®ÁΩ≤

0. ÊâìÂºÄ https://www.python.org/downloads/ ‰∏ãËΩΩ windows3.10Ôºå‰∏ãËΩΩÂêéÂèåÂáªÔºå‰∏ÄË∑ØnextÔºåÊ≥®ÊÑèË¶ÅÈÄâ‰∏≠‚ÄúAdd to PATH‚Äù

   **ÊâìÂºÄ‰∏Ä‰∏™cmdÔºåÊâßË°å `python -V`ÔºåÂ¶ÇÊûúËæìÂá∫‰∏çÊòØ `3.10.4`,ËØ¥ÊòéÂÆâË£ÖÂá∫ÈîôÔºåÊàñÊ≤°ÊúâÂä†ÂÖ• `Add to PATH`,ËØ∑ÈáçÊñ∞ÂÆâË£Ö**

1. ÊâìÂºÄ https://github.com/git-for-windows/git/releases/download/v2.45.0.windows.1/Git-2.45.0-64-bit.exe Ôºå‰∏ãËΩΩgitÔºå‰∏ãËΩΩÂêéÂèåÂáª‰∏ÄË∑Ø‰∏ã‰∏ÄÊ≠•„ÄÇ
2. Êâæ‰∏™‰∏çÂê´Á©∫Ê†ºÂíå‰∏≠ÊñáÁöÑÊñá‰ª∂Â§πÔºåÂú∞ÂùÄÊ†è‰∏≠ËæìÂÖ• `cmd`ÂõûËΩ¶ÔºåÊâìÂºÄÁªàÁ´ØÔºå‰ª•‰∏ãÂëΩ‰ª§ÂùáÂú®ËØ•ÁªàÁ´Ø‰∏≠ÊâßË°å
3. ÊâßË°åÂëΩ‰ª§ `git clone https://github.com/jianchang512/pyvideotrans`
4. ÁªßÁª≠ÊâßË°åÂëΩ‰ª§ `cd pyvideotrans`
5. ÁªßÁª≠ÊâßË°å `python -m venv venv`
6. ÁªßÁª≠ÊâßË°åÂëΩ‰ª§ `venv\Scripts\activate`,ÊâßË°åÂêéËØ∑Êü•ÁúãÁ°ÆËÆ§ÂëΩ‰ª§Ë°åÂºÄÂ§¥Â∑≤ÂèòÊàê‰∫Ü`(venv)`,Âê¶ÂàôËØ¥ÊòéÂá∫Èîô
7. ÊâßË°å `pip install -r requirements.txt `ÔºåÂ¶ÇÊûúÊèêÁ§∫Â§±Ë¥•ÔºåÊâßË°åÂ¶Ç‰∏ã2Êù°ÂëΩ‰ª§ÂàáÊç¢pipÈïúÂÉèÂà∞ÈòøÈáåÈïúÂÉè

    ```

    pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/
    pip config set install.trusted-host mirrors.aliyun.com

    ```

    ÁÑ∂ÂêéÈáçÊñ∞ÊâßË°å,Â¶ÇÊûúÂ∑≤ÂàáÊç¢Âà∞ÈòøÈáåÈïúÂÉèÊ∫êÔºå‰ªçÊèêÁ§∫Â§±Ë¥•ÔºåËØ∑Â∞ùËØïÊâßË°å `pip install -r requirements.txt`
8.  Â¶ÇÊûúË¶Å‰ΩøÁî®CUDAÂä†ÈÄüÔºåÂàÜÂà´ÊâßË°å

    `pip uninstall -y torch torchaudio`

    `pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu126`


9. windows  Â¶ÇÊûúË¶ÅÂêØÁî®cudaÂä†ÈÄüÔºåÂøÖÈ°ªÊúâËã±‰ºüËææÊòæÂç°ÔºåÂπ∂‰∏îÈÖçÁΩÆÂ•Ω‰∫ÜCUDA12+ÁéØÂ¢ÉÔºåÂÖ∑‰ΩìÂÆâË£ÖËßÅ [CUDAÂä†ÈÄüÊîØÊåÅ](https://pyvideotrans.com/gpu)

10. Ëß£Âéã ffmpeg.zip Âà∞ÂΩìÂâçÊ∫êÁ†ÅÁõÆÂΩï‰∏ãÔºåÊèêÁ§∫Ë¶ÜÁõñÂàôË¶ÜÁõñÔºåËß£ÂéãÂêéÁ°Æ‰øùÊ∫êÁ†Å‰∏ãÁöÑffmepgÊñá‰ª∂Â§πÂÜÖËÉΩÁúãÂà∞ ffmpeg.exe ffprobe.exe ytwin32.exe,

11. `python sp.py` ÊâìÂºÄËΩØ‰ª∂ÁïåÈù¢


## [‰ΩøÁî® UV ÈÉ®ÁΩ≤ÔºöÂèÇËÄÉÊñáÊ°£](https://pyvideotrans.com/blog/uv)


##  Ê∫êÁ†ÅÈÉ®ÁΩ≤ÈóÆÈ¢òËØ¥Êòé

1. ÈªòËÆ§‰ΩøÁî® ctranslate2ÁöÑ4.xÁâàÊú¨Ôºå‰ªÖÊîØÊåÅCUDA12.xÁâàÊú¨ÔºåÂ¶ÇÊûú‰Ω†ÁöÑcuda‰Ωé‰∫é12ÔºåÂπ∂‰∏îÊó†Ê≥ïÂçáÁ∫ßcudaÂà∞12.xÔºåËØ∑ÊâßË°åÂëΩ‰ª§Âç∏ËΩΩctranslate2ÁÑ∂ÂêéÈáçÊñ∞ÂÆâË£Ö

```

pip uninstall -y ctranslate2

pip install ctranslate2==3.24.0

```

2. ÂèØËÉΩ‰ºöÈÅáÂà∞ `xx module not found ` ‰πãÁ±ªÈîôËØØÔºåËØ∑ÊâìÂºÄ requirements.txtÔºåÊêúÁ¥¢ËØ• xx Ê®°ÂùóÔºåÁÑ∂ÂêéÂ∞ÜxxÂêéÁöÑ ==ÂèäÁ≠â‰ºöÂêéÁöÑÁâàÊú¨Âè∑ÂéªÊéâ




# ‰ΩøÁî®ÊïôÁ®ãÂíåÊñáÊ°£

ËØ∑Êü•Áúã https://pyvideotrans.com


# ËØ≠Èü≥ËØÜÂà´Ê®°Âûã:

   ‰∏ãËΩΩÂú∞ÂùÄÔºö https://pyvideotrans.com/model.html



# ËßÜÈ¢ëÊïôÁ®ã(Á¨¨‰∏âÊñπ)

[Mac‰∏ãÊ∫êÁ†ÅÈÉ®ÁΩ≤/bÁ´ô](https://www.bilibili.com/video/BV1tK421y7rd/)

[Áî®Gemini Api ÁªôËßÜÈ¢ëÁøªËØëËÆæÁΩÆÊñπÊ≥ï/bÁ´ô](https://b23.tv/fED1dS3)

[Â¶Ç‰Ωï‰∏ãËΩΩÂíåÂÆâË£Ö](https://www.bilibili.com/video/BV1Gr421s7cN/)


# ËΩØ‰ª∂È¢ÑËßàÊà™Âõæ

![pyvideotrans-home](https://github.com/user-attachments/assets/b2f95a7f-b4e5-4a6d-b2a5-eb6cd22531e0)

![image](https://github.com/user-attachments/assets/b5d1b5fb-c579-477c-bca4-6c5e9aa14d7d)



# Áõ∏ÂÖ≥ËÅîÈ°πÁõÆ

[ChatTTS-ui:‰ΩøÁî®ChatTTSÂêàÊàêÂ£∞Èü≥ÁöÑUIÁïåÈù¢](https://github.com/jianchang512/ChatTTS-ui)

[OTT:Êú¨Âú∞Á¶ªÁ∫øÊñáÂ≠óÁøªËØëÂ∑•ÂÖ∑](https://github.com/jianchang512/ott)

[Â£∞Èü≥ÂÖãÈöÜÂ∑•ÂÖ∑:Áî®‰ªªÊÑèÈü≥Ëâ≤ÂêàÊàêËØ≠Èü≥](https://github.com/jianchang512/clone-voice)

[ËØ≠Èü≥ËØÜÂà´Â∑•ÂÖ∑:Êú¨Âú∞Á¶ªÁ∫øÁöÑËØ≠Èü≥ËØÜÂà´ËΩ¨ÊñáÂ≠óÂ∑•ÂÖ∑](https://github.com/jianchang512/stt)

[‰∫∫Â£∞ËÉåÊôØ‰πêÂàÜÁ¶ª:‰∫∫Â£∞ÂíåËÉåÊôØÈü≥‰πêÂàÜÁ¶ªÂ∑•ÂÖ∑](https://github.com/jianchang512/vocal-separate)

[GPT-SoVITSÁöÑapi.pyÊîπËâØÁâà](https://github.com/jianchang512/gptsovits-api)

[ÈÄÇÈÖç CosyVoice ÁöÑ api.py](https://github.com/jianchang512/cosyvoice-api)


## Ëá¥Ë∞¢

&gt; Êú¨Á®ãÂ∫è‰∏ªË¶Å‰æùËµñÁöÑÈÉ®ÂàÜÂºÄÊ∫êÈ°πÁõÆ

1. [ffmpeg](https://github.com/FFmpeg/FFmpeg)
2. [PySide6](https://pypi.org/project/PySide6/)
3. [edge-tts](https://github.com/rany2/edge-tts)
4. [faster-whisper](https://github.com/SYSTRAN/faster-whisper)
5. [openai-whisper](https://github.com/openai/whisper)
6. [pydub](https://github.com/jiaaro/pydub)

## ÂÖ≥Ê≥®‰ΩúËÄÖÂæÆ‰ø°ÂÖ¨‰ºóÂè∑

&lt;img width=&quot;200&quot; src=&quot;https://github.com/jianchang512/pyvideotrans/assets/3378335/f9337111-9084-41fe-8840-1fb8fedca92d&quot;&gt;


Â¶ÇÊûúËßâÂæóËØ•È°πÁõÆÂØπ‰Ω†Êúâ‰ª∑ÂÄºÔºåÂπ∂Â∏åÊúõËØ•È°πÁõÆËÉΩ‰∏ÄÁõ¥Á®≥ÂÆöÊåÅÁª≠Áª¥Êä§ÔºåÊ¨¢ËøéÊçêÂä©

&lt;img width=&quot;200&quot; src=&quot;https://github.com/user-attachments/assets/5e8688ef-47c3-4a3c-a016-e60f73ccc4dc&quot;&gt;


&lt;img width=&quot;200&quot; src=&quot;https://github.com/jianchang512/pyvideotrans/assets/3378335/fe1aa29d-c26d-46d3-b7f3-e9c030ef32c7&quot;&gt;

&lt;img width=&quot;200&quot; src=&quot;https://pyvideotrans.com/images/biancn.jpg&quot;&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[HunxByts/GhostTrack]]></title>
            <link>https://github.com/HunxByts/GhostTrack</link>
            <guid>https://github.com/HunxByts/GhostTrack</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:15 GMT</pubDate>
            <description><![CDATA[Useful tool to track location or mobile number]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/HunxByts/GhostTrack">HunxByts/GhostTrack</a></h1>
            <p>Useful tool to track location or mobile number</p>
            <p>Language: Python</p>
            <p>Stars: 1,837</p>
            <p>Forks: 311</p>
            <p>Stars today: 134 stars today</p>
            <h2>README</h2><pre># GhostTrack
Useful tool to track location or mobile number, so this tool can be called osint or also information gathering

&lt;img src=&quot;https://github.com/HunxByts/GhostTrack/blob/main/asset/bn.png&quot;/&gt;

New update :
```Version 2.2```

### Instalation on Linux (deb)
```
sudo apt-get install git
sudo apt-get install python3
```

### Instalation on Termux
```
pkg install git
pkg install python3
```

### Usage Tool
```
git clone https://github.com/HunxByts/GhostTrack.git
cd GhostTrack
pip3 install -r requirements.txt
python3 GhostTR.py
```

Display on the menu ```IP Tracker```

&lt;img src=&quot;https://github.com/HunxByts/GhostTrack/blob/main/asset/ip.png &quot; /&gt;

on the IP Track menu, you can combo with the seeker tool to get the target IP
&lt;details&gt;
&lt;summary&gt;:zap: Install Seeker :&lt;/summary&gt;
- &lt;strong&gt;&lt;a href=&quot;https://github.com/thewhiteh4t/seeker&quot;&gt;Get Seeker&lt;/a&gt;&lt;/strong&gt;
&lt;/details&gt;

Display on the menu ```Phone Tracker```

&lt;img src=&quot;https://github.com/HunxByts/GhostTrack/blob/main/asset/phone.png&quot; /&gt;

on this menu you can search for information from the target phone number

Display on the menu ```Username Tracker```

&lt;img src=&quot;https://github.com/HunxByts/GhostTrack/blob/main/asset/User.png&quot;/&gt;
on this menu you can search for information from the target username on social media

&lt;details&gt;
&lt;summary&gt;:zap: Author :&lt;/summary&gt;
- &lt;strong&gt;&lt;a href=&quot;https://github.com/HunxByts&quot;&gt;HunxByts&lt;/a&gt;&lt;/strong&gt;
&lt;/details&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[LMCache/LMCache]]></title>
            <link>https://github.com/LMCache/LMCache</link>
            <guid>https://github.com/LMCache/LMCache</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:14 GMT</pubDate>
            <description><![CDATA[Supercharge Your LLM with the Fastest KV Cache Layer]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/LMCache/LMCache">LMCache/LMCache</a></h1>
            <p>Supercharge Your LLM with the Fastest KV Cache Layer</p>
            <p>Language: Python</p>
            <p>Stars: 4,678</p>
            <p>Forks: 519</p>
            <p>Stars today: 236 stars today</p>
            <h2>README</h2><pre># LMCache core library

## Installation

**Prerequisite:** Python &gt;= 3.10

```bash
pip install -e .
```

## Demos
Feel free to try our docker-based demos yourself! All the demos are available [in this repo](https://github.com/LMCache/demo).

## Quickstart: 

**Prerequisites**: To run the quickstart demo, your server should have 1 GPU and the [docker environment](https://docs.docker.com/engine/install/) installed.

**Step 1:** Pull docker images
```bash
docker pull apostacyh/vllm:lmcache-0.1.0
```

**Step 2:** Start vLLM + LMCache 
```bash
model=mistralai/Mistral-7B-Instruct-v0.2    # Replace with your model name
sudo docker run --runtime nvidia --gpus &#039;&quot;device=0&quot;&#039; \
    -v &lt;Huggingface cache dir on your local machine&gt;:/root/.cache/huggingface \
    -p 8000:8000 \
    --env &quot;HF_TOKEN=&lt;Your huggingface access token&gt;&quot; \
    --ipc=host \
    --network=host \
    apostacyh/vllm:lmcache-0.1.0 \
    --model $model --gpu-memory-utilization 0.6 --port 8000 \
    --lmcache-config-file /lmcache/LMCache/examples/example-local.yaml
```
Please fill `Huggingface cache dir on your local machine` and `Your huggingface access token` in the above command. 

You can also change the `model` variable to use different models.

The vLLM engine is ready after you see the logs like this:
```
INFO:     Started server process [865615]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

**Step 3:** Run demo application

You can now run the demo application in the LMCache repo. Please execute the following commands on the server
```bash
git clone https://github.com/LMCache/LMCache
cd LMCache/examples/

# Install openai client library
pip install openai

# Start the demo chat application
python openai_chat_completion_client.py 8000
```

This demo is a QA application based on a long context (`examples/f.txt`). The TTFT should be drastically reduced since the second round of QA.



## Use case 1: share prefix KV between different vLLM instance through LMCache
The following instructions help deploy LMCache backend + multile vLLM instance by docker containers. The architecture of the demo application looks like this:

&lt;img width=&quot;817&quot; alt=&quot;image&quot; src=&quot;https://github.com/LMCache/LMCache/assets/25103655/ab64f84d-26e1-46ce-a503-e7e917b618bc&quot;&gt;


**Prerequisites**: To run the quickstart demo, your server must have 2 GPUs and the [docker environment](https://docs.docker.com/engine/install/) installed.


**Step 1:** Pull docker images
```bash
docker pull apostacyh/lmcache-server:0.1.0
docker pull apostacyh/vllm:lmcache-0.1.0
```

**Step 2:** Start LMCache backend server 
```bash
docker run --name lmcache-server --network host -d apostacyh/lmcache-server:0.1.0 0.0.0.0 65432
```

**Step 3:** start 2 vLLM instances
```bash
# The first vLLM instance listens at port 8000
model=mistralai/Mistral-7B-Instruct-v0.2    # Replace with your model name
sudo docker run --runtime nvidia --gpus &#039;&quot;device=0&quot;&#039; \
    -v &lt;Huggingface cache dir on your local machine&gt;:/root/.cache/huggingface \
    -p 8000:8000 \
    --env &quot;HF_TOKEN=&lt;Your huggingface token&gt;&quot; \
    --ipc=host \
    --network=host \
    apostacyh/vllm:lmcache-0.1.0 \
    --model $model --gpu-memory-utilization 0.7 --port 8000 \
    --lmcache-config-file /lmcache/LMCache/examples/example.yaml
```

Now, open another terminal and start another vLLM instance
```bash
# The second vLLM instance listens at port 8001
model=mistralai/Mistral-7B-Instruct-v0.2    # Replace with your model name
sudo docker run --runtime nvidia --gpus &#039;&quot;device=1&quot;&#039; \
    -v &lt;Huggingface cache dir on your local machine&gt;:/root/.cache/huggingface \
    -p 8001:8001 \
    --env &quot;HF_TOKEN=&lt;Your huggingface token&gt;&quot; \
    --ipc=host \
    --network=host \
    apostacyh/vllm:lmcache-0.1.0 \
    --model $model --gpu-memory-utilization 0.7 --port 8001 \
    --lmcache-config-file /lmcache/LMCache/examples/example.yaml
```

Remember to replace the `Huggingface cache dir on your local machine` and `Your huggingface token` in the commandline.

The vLLM engines are ready after you see the logs like this:
```
INFO:     Started server process [865615]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

**Step 4:** Run demo application
You can run the demo application in the LMCache repo. Please execute the following commands on the server
```bash
git clone https://github.com/LMCache/LMCache
cd LMCache/examples/

# Install openai client library
pip install openai
```

In one terminal:
```
# Connect to the first vLLM engine
python openai_chat_completion_client.py 8000
```

In another terminal
```
# Connect to the second vLLM engine
python openai_chat_completion_client.py 8001
```

You should be able to see the second vLLM engine has much lower response delay.
This is because the KV cache of the long context can be shared across both vLLM engines by using LMCache.

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[commaai/opendbc]]></title>
            <link>https://github.com/commaai/opendbc</link>
            <guid>https://github.com/commaai/opendbc</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:13 GMT</pubDate>
            <description><![CDATA[a Python API for your car]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/commaai/opendbc">commaai/opendbc</a></h1>
            <p>a Python API for your car</p>
            <p>Language: Python</p>
            <p>Stars: 2,499</p>
            <p>Forks: 1,527</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; style=&quot;text-align: center;&quot;&gt;

&lt;h1&gt;opendbc&lt;/h1&gt;
&lt;p&gt;
  &lt;b&gt;opendbc is a Python API for your car.&lt;/b&gt;
  &lt;br&gt;
  Control the gas, brake, steering, and more. Read the speed, steering angle, and more.
&lt;/p&gt;

&lt;h3&gt;
  &lt;a href=&quot;https://docs.comma.ai&quot;&gt;Docs&lt;/a&gt;
  &lt;span&gt; ¬∑ &lt;/span&gt;
  &lt;a href=&quot;https://github.com/commaai/openpilot/blob/master/docs/CONTRIBUTING.md&quot;&gt;Contribute&lt;/a&gt;
  &lt;span&gt; ¬∑ &lt;/span&gt;
  &lt;a href=&quot;https://discord.comma.ai&quot;&gt;Discord&lt;/a&gt;
&lt;/h3&gt;

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![X Follow](https://img.shields.io/twitter/follow/comma_ai)](https://x.com/comma_ai)
[![Discord](https://img.shields.io/discord/469524606043160576)](https://discord.comma.ai)

&lt;/div&gt;

---

Most cars since 2016 have electronically-actuatable steering, gas, and brakes thanks to [LKAS](https://en.wikipedia.org/wiki/Lane_departure_warning_system#Lane_keeping_and_next_technologies) and [ACC](https://en.wikipedia.org/wiki/Adaptive_cruise_control).
The goal of this project is to support controlling the steering, gas, and brakes on every single one of those cars.

While the primary focus is on supporting ADAS interfaces for [openpilot](https://github.com/commaai/openpilot), we&#039;re also interested in reading and writing as many things as we can (EV charge status, lock/unlocking doors, etc) such that we can build the best vehicle management app ever.

---

This README and the [supported cars list](docs/CARS.md) are all the docs for the opendbc project.
Everything you need to know to use, contribute, and extend opendbc are in these docs.

## Quick start

```bash
git clone https://github.com/commaai/opendbc.git
cd opendbc

# you probably just want to use this. it&#039;s an all-in-one for dependency
# installation, compiling, linting, and tests. it&#039;s also what runs in CI
./test.sh

# here are the individual commands it runs
pip3 install -e .[testing,docs]  # install dependencies
scons -j8                        # build with 8 cores
pytest .                         # run the tests
lefthook run lint                # run the linter
```

[`examples/`](examples/) contains small example programs that can read state from the car and control the steering, gas, and brakes.
[`examples/joystick.py`](examples/joystick.py) allows you to control a car with a joystick.

### Project Structure
* [`opendbc/dbc/`](opendbc/dbc/) is a repository of [DBC](https://en.wikipedia.org/wiki/CAN_bus#DBC) files
* [`opendbc/can/`](opendbc/can/) is a library for parsing and building CAN messages from DBC files
* [`opendbc/car/`](opendbc/car/) is a high-level library for interfacing with cars using Python
* [`opendbc/safety/`](opendbc/safety/) is the functional safety for all the cars supported by `opendbc/car/`

## How to Port a Car

This guide covers everything from adding support to a new car all the way to improving existing cars (e.g. adding longitudinal control or radar parsing). If similar cars to yours are already compatible, most of this work is likely already done for you.

At its most basic, a car port will control the steering on a car. A &quot;complete&quot; car port will have all of: lateral control, longitudinal control, good tuning for both lateral and longitudinal, radar parsing (if equipped), fuzzy fingerprinting, and more. The new car support docs will clearly communicate each car&#039;s support level.

### Connect to the Car

The first step is to get connected to the car with a comma 3X and a car harness.
The car harness gets you connected to two different CAN buses and splits one of those buses to send our own actuation messages.

If you&#039;re lucky, a harness compatible with your car will already be designed and sold on comma.ai/shop.
If you&#039;re not so lucky, start with a &quot;developer harness&quot; from comma.ai/shop and crimp on whatever connector you need.

### Structure of a port

Depending on the brand, most of this basic structure will already be in place.

The entirety of a car port lives in `opendbc/car/&lt;brand&gt;/`:
* `carstate.py`: parses out the relevant information from the CAN stream using the car&#039;s DBC file
* `carcontroller.py`: outputs CAN messages to control the car
* `&lt;brand&gt;can.py`: thin Python helpers around the DBC file to build CAN messages
* `fingerprints.py`: database of ECU firmware versions for identifying car models
* `interface.py`: high level class for interfacing with the car
* `radar_interface.py`: parses out the radar
* `values.py`: enumerates the brand&#039;s supported cars

### Reverse Engineer CAN messages

Start off by recording a route with lots of interesting events: enable LKAS and ACC, turn the steering wheel both extremes, etc. Then, load up that route in [cabana](https://github.com/commaai/openpilot/tree/master/tools/cabana).

### Tuning

#### Longitudinal

Use the [longitudinal maneuvers](https://github.com/commaai/openpilot/tree/master/tools/longitudinal_maneuvers) report to evaluate your car&#039;s longitudinal control and tune it.

## Contributing

All opendbc development is coordinated on GitHub and [Discord](https://discord.comma.ai). Check out the `#dev-opendbc-cars` channel and `Vehicle Specific` section.

### Roadmap

Short term
- [ ] `pip install opendbc`
- [ ] 100% type coverage
- [ ] 100% line coverage
- [ ] Make car ports easier: refactors, tools, tests, and docs
- [ ] Expose the state of all supported cars better: https://github.com/commaai/opendbc/issues/1144

Longer term
- [ ] Extend support to every car with LKAS + ACC interfaces
- [ ] Automatic lateral and longitudinal control/tuning evaluation
- [ ] Auto-tuning for [lateral](https://blog.comma.ai/090release/#torqued-an-auto-tuner-for-lateral-control) and longitudinal control
- [ ] [Automatic Emergency Braking](https://en.wikipedia.org/wiki/Automated_emergency_braking_system)

Contributions towards anything here are welcome.

## Safety Model

When a [panda](https://comma.ai/shop/panda) powers up with [opendbc safety firmware](opendbc/safety), by default it&#039;s in `SAFETY_SILENT` mode. While in `SAFETY_SILENT` mode, the CAN buses are forced to be silent. In order to send messages, you have to select a safety mode. Some of safety modes (for example `SAFETY_ALLOUTPUT`) are disabled in release firmwares. In order to use them, compile and flash your own build.

Safety modes optionally support `controls_allowed`, which allows or blocks a subset of messages based on a customizable state in the board.

## Code Rigor

The opendbc safety firmware is written for its use in conjunction with [openpilot](https://github.com/commaai/openpilot) and [panda](https://github.com/commaai/panda). The safety firmware, through its safety model, provides and enforces the
[openpilot safety](https://github.com/commaai/openpilot/blob/master/docs/SAFETY.md). Due to its critical function, it&#039;s important that the application code rigor within the `safety` folder is held to high standards.

These are the [CI regression tests](https://github.com/commaai/opendbc/actions) we have in place:
* A generic static code analysis is performed by [cppcheck](https://github.com/danmar/cppcheck/).
* In addition, [cppcheck](https://github.com/danmar/cppcheck/) has a specific addon to check for [MISRA C:2012](https://misra.org.uk/) violations. See [current coverage](opendbc/safety/tests/misra/coverage_table).
* Compiler options are relatively strict: the flags `-Wall -Wextra -Wstrict-prototypes -Werror` are enforced.
* The [safety logic](opendbc/safety) is tested and verified by [unit tests](opendbc/safety/tests) for each supported car variant.

The above tests are themselves tested by:
* a [mutation test](opendbc/safety/tests/misra/test_mutation.py) on the MISRA coverage
* 100% line coverage enforced on the safety unit tests

In addition, we run the [ruff linter](https://github.com/astral-sh/ruff) and [mypy](https://mypy-lang.org/) on the car interface library.

### Bounties

Every car port is eligible for a bounty:
* $2000 - [Any car brand / platform port](https://github.com/orgs/commaai/projects/26/views/1?pane=issue&amp;itemId=47913774)
* $250 - [Any car model port](https://github.com/orgs/commaai/projects/26/views/1?pane=issue&amp;itemId=47913790)
* $300 - [Reverse Engineering a new Actuation Message](https://github.com/orgs/commaai/projects/26/views/1?pane=issue&amp;itemId=73445563)

In addition to the standard bounties, we also offer higher value bounties for more popular cars. See those at [comma.ai/bounties](comma.ai/bounties).

## FAQ

***How do I use this?*** A [comma 3X](https://comma.ai/shop/comma-3x) is custom-designed to be the best way to run and develop opendbc and openpilot.

***Which cars are supported?*** See the [supported cars list](docs/CARS.md).

***Can I add support for my car?*** Yes, most car support comes from the community. Read the guide [here](https://github.com/commaai/opendbc/blob/docs/README.md#how-to-port-a-car).

***Which cars can be supported?*** Any car with LKAS and ACC. More info [here](https://github.com/commaai/openpilot/blob/master/docs/CARS.md#dont-see-your-car-here).

***How does this work?*** In short, we designed hardware to replace your car&#039;s built-in lane keep and adaptive cruise features. See [this talk](https://www.youtube.com/watch?v=FL8CxUSfipM) for an in-depth explanation.

***Is there a timeline or roadmap for adding car support?*** No, most car support comes from the community, with comma doing final safety and quality validation. The more complete the community car port is and the more popular the car is, the more likely we are to pick it up as the next one to validate.

### Terms

* **port**: refers to the integration and support of a specific car
* **lateral control**: aka steering control
* **longitudinal control**: aka gas/brakes control
* **fingerprinting**: automatic process for identifying the car
* **[LKAS](https://en.wikipedia.org/wiki/Lane_departure_warning_system)**: lane keeping assist
* **[ACC](https://en.wikipedia.org/wiki/Adaptive_cruise_control)**: adaptive cruise control
* **[harness](https://comma.ai/shop/car-harness)**: car-specific hardware to attach to the car and intercept the ADAS messages
* **[panda](https://github.com/commaai/panda)**: hardware used to get on a car&#039;s CAN bus
* **[ECU](https://en.wikipedia.org/wiki/Electronic_control_unit)**: computers or control modules inside the car
* **[CAN bus](https://en.wikipedia.org/wiki/CAN_bus)**: a bus that connects the ECUs in a car
* **[cabana](https://github.com/commaai/openpilot/tree/master/tools/cabana#readme)**: our tool for reverse engineering CAN messages
* **[DBC file](https://en.wikipedia.org/wiki/CAN_bus#DBC)**: contains definitions for messages on a CAN bus
* **[openpilot](https://github.com/commaai/openpilot)**: an ADAS system for cars supported by opendbc
* **[comma](https://github.com/commaai)**: the company behind opendbc
* **[comma 3X](https://comma.ai/shop/comma-3x)**: the hardware used to run openpilot

### More resources

* [*How Do We Control The Car?*](https://www.youtube.com/watch?v=nNU6ipme878&amp;pp=ygUoY29tbWEgY29uIDIwMjEgaG93IGRvIHdlIGNvbnRyb2wgdGhlIGNhcg%3D%3D) by [@robbederks](https://github.com/robbederks) from COMMA_CON 2021
* [*How to Port a Car*](https://www.youtube.com/watch?v=XxPS5TpTUnI&amp;t=142s&amp;pp=ygUPamFzb24gY29tbWEgY29u) by [@jyoung8607](https://github.com/jyoung8607) from COMMA_CON 2023
* [commaCarSegments](https://huggingface.co/datasets/commaai/commaCarSegments): a massive dataset of CAN data from 300 different car models
* [cabana](https://github.com/commaai/openpilot/tree/master/tools/cabana#readme): our tool for reverse engineering CAN messages
* [can_print_changes.py](https://github.com/commaai/openpilot/blob/master/selfdrive/debug/can_print_changes.py): diff the whole CAN bus across two drives, such as one without any LKAS and one with LKAS
* [longitudinal maneuvers](https://github.com/commaai/openpilot/tree/master/tools/longitudinal_maneuvers): a tool for evaluating and tuning longitudinal control
* [opendbc data](https://commaai.github.io/opendbc-data/): a repository of longitudinal maneuver evaluations

## Come work with us -- [comma.ai/jobs](https://comma.ai/jobs)

comma is hiring engineers to work on opendbc and [openpilot](https://github.com/commaai/openpilot). We love hiring contributors.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[virattt/ai-hedge-fund]]></title>
            <link>https://github.com/virattt/ai-hedge-fund</link>
            <guid>https://github.com/virattt/ai-hedge-fund</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:12 GMT</pubDate>
            <description><![CDATA[An AI Hedge Fund Team]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/virattt/ai-hedge-fund">virattt/ai-hedge-fund</a></h1>
            <p>An AI Hedge Fund Team</p>
            <p>Language: Python</p>
            <p>Stars: 39,380</p>
            <p>Forks: 6,936</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre># AI Hedge Fund

This is a proof of concept for an AI-powered hedge fund.  The goal of this project is to explore the use of AI to make trading decisions.  This project is for **educational** purposes only and is not intended for real trading or investment.

This system employs several agents working together:

1. Aswath Damodaran Agent - The Dean of Valuation, focuses on story, numbers, and disciplined valuation
2. Ben Graham Agent - The godfather of value investing, only buys hidden gems with a margin of safety
3. Bill Ackman Agent - An activist investor, takes bold positions and pushes for change
4. Cathie Wood Agent - The queen of growth investing, believes in the power of innovation and disruption
5. Charlie Munger Agent - Warren Buffett&#039;s partner, only buys wonderful businesses at fair prices
6. Michael Burry Agent - The Big Short contrarian who hunts for deep value
7. Peter Lynch Agent - Practical investor who seeks &quot;ten-baggers&quot; in everyday businesses
8. Phil Fisher Agent - Meticulous growth investor who uses deep &quot;scuttlebutt&quot; research 
9. Rakesh Jhunjhunwala Agent - The Big Bull of India
10. Stanley Druckenmiller Agent - Macro legend who hunts for asymmetric opportunities with growth potential
11. Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price
12. Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals
13. Sentiment Agent - Analyzes market sentiment and generates trading signals
14. Fundamentals Agent - Analyzes fundamental data and generates trading signals
15. Technicals Agent - Analyzes technical indicators and generates trading signals
16. Risk Manager - Calculates risk metrics and sets position limits
17. Portfolio Manager - Makes final trading decisions and generates orders

&lt;img width=&quot;1042&quot; alt=&quot;Screenshot 2025-03-22 at 6 19 07 PM&quot; src=&quot;https://github.com/user-attachments/assets/cbae3dcf-b571-490d-b0ad-3f0f035ac0d4&quot; /&gt;

Note: the system does not actually make any trades.

[![Twitter Follow](https://img.shields.io/twitter/follow/virattt?style=social)](https://twitter.com/virattt)

## Disclaimer

This project is for **educational and research purposes only**.

- Not intended for real trading or investment
- No investment advice or guarantees provided
- Creator assumes no liability for financial losses
- Consult a financial advisor for investment decisions
- Past performance does not indicate future results

By using this software, you agree to use it solely for learning purposes.

## Table of Contents
- [How to Install](#how-to-install)
- [How to Run](#how-to-run)
  - [‚å®Ô∏è Command Line Interface](#Ô∏è-command-line-interface)
  - [üñ•Ô∏è Web Application (NEW!)](#Ô∏è-web-application)
- [Contributing](#contributing)
- [Feature Requests](#feature-requests)
- [License](#license)

## How to Install

Before you can run the AI Hedge Fund, you&#039;ll need to install it and set up your API keys. These steps are common to both the full-stack web application and command line interface.

### 1. Clone the Repository

```bash
git clone https://github.com/virattt/ai-hedge-fund.git
cd ai-hedge-fund
```

### 2. Set Up Your API Keys

Create a `.env` file for your API keys:
```bash
# Create .env file for your API keys (in the root directory)
cp .env.example .env
```

Open and edit the `.env` file to add your API keys:
```bash
# For running LLMs hosted by openai (gpt-4o, gpt-4o-mini, etc.)
OPENAI_API_KEY=your-openai-api-key

# For running GigaChat (use gigachat credentials)
GIGACHAT_API_KEY=your-gigachat-api-key

# For running LLMs hosted by groq (deepseek, llama3, etc.)
GROQ_API_KEY=your-groq-api-key

# For getting financial data to power the hedge fund
FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key
```

**Important**: You must set at least one LLM API key (`OPENAI_API_KEY`, `GROQ_API_KEY`, `ANTHROPIC_API_KEY`, or `DEEPSEEK_API_KEY`) for the hedge fund to work. 

**Financial Data**: Data for AAPL, GOOGL, MSFT, NVDA, and TSLA is free and does not require an API key. For any other ticker, you will need to set the `FINANCIAL_DATASETS_API_KEY` in the .env file.

## How to Run

### ‚å®Ô∏è Command Line Interface

For users who prefer working with command line tools, you can run the AI Hedge Fund directly via terminal. This approach offers more granular control and is useful for automation, scripting, and integration purposes.

&lt;img width=&quot;992&quot; alt=&quot;Screenshot 2025-01-06 at 5 50 17 PM&quot; src=&quot;https://github.com/user-attachments/assets/e8ca04bf-9989-4a7d-a8b4-34e04666663b&quot; /&gt;

Choose one of the following installation methods:

#### Using Poetry

1. Install Poetry (if not already installed):
```bash
curl -sSL https://install.python-poetry.org | python3 -
```

2. Install dependencies:
```bash
poetry install
```

#### Using Docker

1. Make sure you have Docker installed on your system. If not, you can download it from [Docker&#039;s official website](https://www.docker.com/get-started).

2. Navigate to the docker directory:
```bash
cd docker
```

3. Build the Docker image:
```bash
# On Linux/Mac:
./run.sh build

# On Windows:
run.bat build
```

#### Running the AI Hedge Fund (with Poetry)
```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA
```

#### Running the AI Hedge Fund (with Docker)
```bash
# Navigate to the docker directory first
cd docker

# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA main

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA main
```

You can also specify a `--ollama` flag to run the AI hedge fund using local LLMs.

```bash
# With Poetry:
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --ollama

# With Docker (from docker/ directory):
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA --ollama main

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA --ollama main
```

You can also specify a `--show-reasoning` flag to print the reasoning of each agent to the console.

```bash
# With Poetry:
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --show-reasoning

# With Docker (from docker/ directory):
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA --show-reasoning main

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA --show-reasoning main
```

You can optionally specify the start and end dates to make decisions for a specific time period.

```bash
# With Poetry:
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 

# With Docker (from docker/ directory):
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 main

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 main
```

#### Running the Backtester (with Poetry)
```bash
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA
```

#### Running the Backtester (with Docker)
```bash
# Navigate to the docker directory first
cd docker

# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA backtest

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA backtest
```

**Example Output:**
&lt;img width=&quot;941&quot; alt=&quot;Screenshot 2025-01-06 at 5 47 52 PM&quot; src=&quot;https://github.com/user-attachments/assets/00e794ea-8628-44e6-9a84-8f8a31ad3b47&quot; /&gt;


You can optionally specify the start and end dates to backtest over a specific time period.

```bash
# With Poetry:
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01

# With Docker (from docker/ directory):
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 backtest

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 backtest
```

You can also specify a `--ollama` flag to run the backtester using local LLMs.
```bash
# With Poetry:
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA --ollama

# With Docker (from docker/ directory):
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA --ollama backtest

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA --ollama backtest
```

### üñ•Ô∏è Web Application

The new way to run the AI Hedge Fund is through our web application that provides a user-friendly interface. **This is recommended for most users, especially those who prefer visual interfaces over command line tools.**

&lt;img width=&quot;1721&quot; alt=&quot;Screenshot 2025-06-28 at 6 41 03‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/b95ab696-c9f4-416c-9ad1-51feb1f5374b&quot; /&gt;

#### For Mac/Linux:
```bash
cd app &amp;&amp; ./run.sh
```

If you get a &quot;permission denied&quot; error, run this first:
```bash
cd app &amp;&amp; chmod +x run.sh &amp;&amp; ./run.sh
```

#### For Windows:
```bash
# Go to /app directory
cd app

# Run the app
\.run.bat
```

**That&#039;s it!** These scripts will:
1. Check for required dependencies (Node.js, Python, Poetry)
2. Install all dependencies automatically  
3. Start both frontend and backend services
4. **Automatically open your web browser** to the application


#### Detailed Setup Instructions

For detailed setup instructions, troubleshooting, and advanced configuration options, see:
- [Full-Stack App Documentation](./app/README.md)
- [Frontend Documentation](./app/frontend/README.md)  
- [Backend Documentation](./app/backend/README.md)


## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

**Important**: Please keep your pull requests small and focused.  This will make it easier to review and merge.

## Feature Requests

If you have a feature request, please open an [issue](https://github.com/virattt/ai-hedge-fund/issues) and make sure it is tagged with `enhancement`.

## License

This project is licensed under the MIT License - see the LICENSE file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[DrewThomasson/ebook2audiobook]]></title>
            <link>https://github.com/DrewThomasson/ebook2audiobook</link>
            <guid>https://github.com/DrewThomasson/ebook2audiobook</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:11 GMT</pubDate>
            <description><![CDATA[Generate audiobooks from e-books, voice cloning & 1107+ languages!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DrewThomasson/ebook2audiobook">DrewThomasson/ebook2audiobook</a></h1>
            <p>Generate audiobooks from e-books, voice cloning & 1107+ languages!</p>
            <p>Language: Python</p>
            <p>Stars: 11,073</p>
            <p>Forks: 828</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre># üìö ebook2audiobook
CPU/GPU Converter from eBooks to audiobooks with chapters and metadata&lt;br/&gt;
using XTTSv2, Bark, Vits, Fairseq, YourTTS, Tacotron and more. Supports voice cloning and +1110 languages!
&gt; [!IMPORTANT]
**This tool is intended for use with non-DRM, legally acquired eBooks only.** &lt;br&gt;
The authors are not responsible for any misuse of this software or any resulting legal consequences. &lt;br&gt;
Use this tool responsibly and in accordance with all applicable laws.

[![Discord](https://dcbadge.limes.pink/api/server/https://discord.gg/63Tv3F65k6)](https://discord.gg/63Tv3F65k6)

### Thanks to support ebook2audiobook developers!
[![Ko-Fi](https://img.shields.io/badge/Ko--fi-F16061?style=for-the-badge&amp;logo=ko-fi&amp;logoColor=white)](https://ko-fi.com/athomasson2) 

### Run locally

[![Quick Start](https://img.shields.io/badge/Quick%20Start-blue?style=for-the-badge)](#launching-gradio-web-interface)

[![Docker Build](https://github.com/DrewThomasson/ebook2audiobook/actions/workflows/Docker-Build.yml/badge.svg)](https://github.com/DrewThomasson/ebook2audiobook/actions/workflows/Docker-Build.yml)  [![Download](https://img.shields.io/badge/Download-Now-blue.svg)](https://github.com/DrewThomasson/ebook2audiobook/releases/latest)   


&lt;a href=&quot;https://github.com/DrewThomasson/ebook2audiobook&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/Platform-mac%20|%20linux%20|%20windows-lightgrey&quot; alt=&quot;Platform&quot;&gt;
&lt;/a&gt;&lt;a href=&quot;https://hub.docker.com/r/athomasson2/ebook2audiobook&quot;&gt;
&lt;img alt=&quot;Docker Pull Count&quot; src=&quot;https://img.shields.io/docker/pulls/athomasson2/ebook2audiobook.svg&quot;/&gt;
&lt;/a&gt;

### Run Remotely
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-Spaces-yellow?style=flat&amp;logo=huggingface)](https://huggingface.co/spaces/drewThomasson/ebook2audiobook)
[![Free Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DrewThomasson/ebook2audiobook/blob/main/Notebooks/colab_ebook2audiobook.ipynb) [![Kaggle](https://img.shields.io/badge/Kaggle-035a7d?style=flat&amp;logo=kaggle&amp;logoColor=white)](https://github.com/Rihcus/ebook2audiobookXTTS/blob/main/Notebooks/kaggle-ebook2audiobook.ipynb)

#### GUI Interface
![demo_web_gui](assets/demo_web_gui.gif)

&lt;details&gt;
  &lt;summary&gt;Click to see images of Web GUI&lt;/summary&gt;
  &lt;img width=&quot;1728&quot; alt=&quot;GUI Screen 1&quot; src=&quot;assets/gui_1.png&quot;&gt;
  &lt;img width=&quot;1728&quot; alt=&quot;GUI Screen 2&quot; src=&quot;assets/gui_2.png&quot;&gt;
  &lt;img width=&quot;1728&quot; alt=&quot;GUI Screen 3&quot; src=&quot;assets/gui_3.png&quot;&gt;
&lt;/details&gt;

## Demos

**New Default Voice Demo**  

https://github.com/user-attachments/assets/750035dc-e355-46f1-9286-05c1d9e88cea  

&lt;details&gt;
  &lt;summary&gt;More Demos&lt;/summary&gt;

**ASMR Voice** 

https://github.com/user-attachments/assets/68eee9a1-6f71-4903-aacd-47397e47e422

**Rainy Day Voice**  

https://github.com/user-attachments/assets/d25034d9-c77f-43a9-8f14-0d167172b080  

**Scarlett Voice**

https://github.com/user-attachments/assets/b12009ee-ec0d-45ce-a1ef-b3a52b9f8693

**David Attenborough Voice** 

https://github.com/user-attachments/assets/81c4baad-117e-4db5-ac86-efc2b7fea921

**Example**

![Example](https://github.com/DrewThomasson/VoxNovel/blob/dc5197dff97252fa44c391dc0596902d71278a88/readme_files/example_in_app.jpeg)
&lt;/details&gt;

## README.md

## Table of Contents
- [ebook2audiobook](#-ebook2audiobook)
- [Features](#features)
- [GUI Interface](#gui-interface)
- [Demos](#demos)
- [Supported Languages](#supported-languages)
- [Minimum Requirements](#hardware-requirements)
- [Usage](#launching-gradio-web-interface)
  - [Run Locally](#launching-gradio-web-interface)
    - [Launching Gradio Web Interface](#launching-gradio-web-interface)
    - [Basic Headless Usage](#basic--usage)
    - [Headless Custom XTTS Model Usage](#example-of-custom-model-zip-upload)
    - [Help command output](#help-command-output)
  - [Run Remotely](#run-remotely)  
- [Fine Tuned TTS models](#fine-tuned-tts-models)
  - [Collection of Fine-Tuned TTS Models](#fine-tuned-tts-collection)
  - [Train XTTSv2](#fine-tune-your-own-xttsv2-model)
- [Docker](#docker-gpu-options) 
  - [GPU options](#docker-gpu-options)
  - [Docker Run](#running-the-pre-built-docker-container)
  - [Docker Build](#building-the-docker-container)
  - [Docker Compose](#docker-compose)
  - [Docker headless guide](#docker-headless-guide)
  - [Docker container file locations](#docker-container-file-locations)
  - [Common Docker issues](#common-docker-issues)
- [Supported eBook Formats](#supported-ebook-formats)
- [Output Formats](#output-formats)
- [Updating to Latest Version](#updating-to-latest-version)
- [Revert to older Version](#reverting-to-older-versions)
- [Common Issues](#common-issues)
- [Special Thanks](#special-thanks)
- [Table of Contents](#table-of-contents)


## Features
- üìö Splits eBook into chapters for organized audio.
- üéôÔ∏è High-quality text-to-speech with [Coqui XTTSv2](https://huggingface.co/coqui/XTTS-v2) and [Fairseq](https://github.com/facebookresearch/fairseq/tree/main/examples/mms) (and more).
- üó£Ô∏è Optional voice cloning with your own voice file.
- üåç Supports +1110 languages (English by default). [List of Supported languages](https://dl.fbaipublicfiles.com/mms/tts/all-tts-languages.html)
- üñ•Ô∏è Designed to run on 4GB RAM.


## Supported Languages
| **Arabic (ar)**    | **Chinese (zh)**    | **English (en)**   | **Spanish (es)**   |
|:------------------:|:------------------:|:------------------:|:------------------:|
| **French (fr)**    | **German (de)**     | **Italian (it)**   | **Portuguese (pt)** |
| **Polish (pl)**    | **Turkish (tr)**    | **Russian (ru)**   | **Dutch (nl)**     |
| **Czech (cs)**     | **Japanese (ja)**   | **Hindi (hi)**     | **Bengali (bn)**   |
| **Hungarian (hu)** | **Korean (ko)**     | **Vietnamese (vi)**| **Swedish (sv)**   |
| **Persian (fa)**   | **Yoruba (yo)**     | **Swahili (sw)**   | **Indonesian (id)**|
| **Slovak (sk)**    | **Croatian (hr)**   | **Tamil (ta)**     | **Danish (da)**    |
- [**+1100 languages and dialects here**](https://dl.fbaipublicfiles.com/mms/tts/all-tts-languages.html)


##  Hardware Requirements
- 4gb RAM minimum, 8GB recommended
- Virtualization enabled if running on windows (Docker only)
- CPU (intel, AMD, ARM), GPU (Nvidia, AMD*, Intel*) (Recommended), MPS (Apple Silicon CPU)
*available very soon

&gt; [!IMPORTANT]
**Before to post an install or bug issue search carefully to the opened and closed issues TAB&lt;br&gt;
to be sure your issue does not exist already.**


&gt;[!NOTE]
**Lacking of any standards structure like what is a chapter, paragraph, preface etc.&lt;br&gt;
you should first remove manually any text you don&#039;t want to be converted in audio.**

### Installation Instructions
1. **Clone repo**
```bash
git clone https://github.com/DrewThomasson/ebook2audiobook.git
cd ebook2audiobook
```

### Launching Gradio Web Interface  
1. **Run ebook2audiobook**:  
   - **Linux/MacOS**  
     ```bash
     ./ebook2audiobook.sh  # Run launch script
     ```

   - **Mac Launcher**  
     Double click `Mac Ebook2Audiobook Launcher.command`

  
   - **Windows**  
     ```bash
     ebook2audiobook.cmd  # Run launch script or double click on it
     ```
     
   - **Windows Launcher**  
     Double click `ebook2audiobook.cmd`


   - **Manual Python Install**
     ```bash
     # (for experts only!)
     REQUIRED_PROGRAMS=(&quot;calibre&quot; &quot;ffmpeg&quot; &quot;nodejs&quot; &quot;mecab&quot; &quot;espeak-ng&quot; &quot;rust&quot; &quot;sox&quot;)
     REQUIRED_PYTHON_VERSION=&quot;3.12&quot;
     pip install -r requirements.txt  # Install Python Requirements
     python app.py  # Run Ebook2Audiobook
     ```
   
1. **Open the Web App**: Click the URL provided in the terminal to access the web app and convert eBooks. `http://localhost:7860/`
2. **For Public Link**:
   `python app.py --share` (all OS)
   `./ebook2audiobook.sh --share` (Linux/MacOS)
   `ebook2audiobook.cmd --share` (Windows)

&gt; [!IMPORTANT]
**If the script is stopped and run again, you need to refresh your gradio GUI interface&lt;br&gt;
to let the web page reconnect to the new connection socket.**

### Basic  Usage
   - **Linux/MacOS**:
     ```bash
     ./ebook2audiobook.sh --headless --ebook &lt;path_to_ebook_file&gt; \
         --voice [path_to_voice_file] --language [language_code]
     ```
   - **Windows**
     ```bash
     ebook2audiobook.cmd --headless --ebook &lt;path_to_ebook_file&gt;
         --voice [path_to_voice_file] --language [language_code]
     ```
     
  - **[--ebook]**: Path to your eBook file
  - **[--voice]**: Voice cloning file path (optional)
  - **[--language]**: Language code in ISO-639-3 (i.e.: ita for italian, eng for english, deu for german...).&lt;br&gt;
    Default language is eng and --language is optional for default language set in ./lib/lang.py.&lt;br&gt;
    The ISO-639-1 2 letters codes are also supported.


###  Example of Custom Model Zip Upload
  (must be a .zip file containing the mandatory model files. Example for XTTSv2: config.json, model.pth, vocab.json and ref.wav)
   - **Linux/MacOS**
     ```bash
     ./ebook2audiobook.sh --headless --ebook &lt;ebook_file_path&gt; \
         --voice &lt;target_voice_file_path&gt; --language &lt;language&gt; --custom_model &lt;custom_model_path&gt;
     ```
   - **Windows**
     ```bash
     ebook2audiobook.cmd --headless --ebook &lt;ebook_file_path&gt; \
         --voice &lt;target_voice_file_path&gt; --language &lt;language&gt; --custom_model &lt;custom_model_path&gt;
     ```
- **&lt;custom_model_path&gt;**: Path to `model_name.zip` file,
      which must contain (according to the tts engine) all the mandatory files&lt;br&gt;
      (see ./lib/models.py).


### For Detailed Guide with list of all Parameters to use
   - **Linux/MacOS**
     ```bash
     ./ebook2audiobook.sh --help
     ```
   - **Windows**
     ```bash
     ebook2audiobook.cmd --help
     ```
   - **Or for all OS**
    ```python
     app.py --help
    ```

&lt;a id=&quot;help-command-output&quot;&gt;&lt;/a&gt;
```bash
usage: app.py [-h] [--session SESSION] [--share] [--headless] [--ebook EBOOK]
              [--ebooks_dir EBOOKS_DIR] [--language LANGUAGE] [--voice VOICE]
              [--device {cpu,gpu,mps}]
              [--tts_engine {XTTSv2,BARK,VITS,FAIRSEQ,TACOTRON2,YOURTTS,xtts,bark,vits,fairseq,tacotron,yourtts}]
              [--custom_model CUSTOM_MODEL] [--fine_tuned FINE_TUNED]
              [--output_format OUTPUT_FORMAT] [--temperature TEMPERATURE]
              [--length_penalty LENGTH_PENALTY] [--num_beams NUM_BEAMS]
              [--repetition_penalty REPETITION_PENALTY] [--top_k TOP_K]
              [--top_p TOP_P] [--speed SPEED] [--enable_text_splitting]
              [--text_temp TEXT_TEMP] [--waveform_temp WAVEFORM_TEMP]
              [--output_dir OUTPUT_DIR] [--version]

Convert eBooks to Audiobooks using a Text-to-Speech model. You can either launch the Gradio interface or run the script in headless mode for direct conversion.

options:
  -h, --help            show this help message and exit
  --session SESSION     Session to resume the conversion in case of interruption, crash, 
                            or reuse of custom models and custom cloning voices.

**** The following options are for all modes:
  Optional

**** The following option are for gradio/gui mode only:
  Optional

  --share               Enable a public shareable Gradio link.

**** The following options are for --headless mode only:
  --headless            Run the script in headless mode
  --ebook EBOOK         Path to the ebook file for conversion. Cannot be used when --ebooks_dir is present.
  --ebooks_dir EBOOKS_DIR
                        Relative or absolute path of the directory containing the files to convert. 
                            Cannot be used when --ebook is present.
  --language LANGUAGE   Language of the e-book. Default language is set 
                            in ./lib/lang.py sed as default if not present. All compatible language codes are in ./lib/lang.py

optional parameters:
  --voice VOICE         (Optional) Path to the voice cloning file for TTS engine. 
                            Uses the default voice if not present.
  --device {cpu,gpu,mps}
                        (Optional) Pprocessor unit type for the conversion. 
                            Default is set in ./lib/conf.py if not present. Fall back to CPU if GPU not available.
  --tts_engine {XTTSv2,BARK,VITS,FAIRSEQ,TACOTRON2,YOURTTS,xtts,bark,vits,fairseq,tacotron,yourtts}
                        (Optional) Preferred TTS engine (available are: [&#039;XTTSv2&#039;, &#039;BARK&#039;, &#039;VITS&#039;, &#039;FAIRSEQ&#039;, &#039;TACOTRON2&#039;, &#039;YOURTTS&#039;, &#039;xtts&#039;, &#039;bark&#039;, &#039;vits&#039;, &#039;fairseq&#039;, &#039;tacotron&#039;, &#039;yourtts&#039;].
                            Default depends on the selected language. The tts engine should be compatible with the chosen language
  --custom_model CUSTOM_MODEL
                        (Optional) Path to the custom model zip file cntaining mandatory model files. 
                            Please refer to ./lib/models.py
  --fine_tuned FINE_TUNED
                        (Optional) Fine tuned model path. Default is builtin model.
  --output_format OUTPUT_FORMAT
                        (Optional) Output audio format. Default is set in ./lib/conf.py
  --temperature TEMPERATURE
                        (xtts only, optional) Temperature for the model. 
                            Default to config.json model. Higher temperatures lead to more creative outputs.
  --length_penalty LENGTH_PENALTY
                        (xtts only, optional) A length penalty applied to the autoregressive decoder. 
                            Default to config.json model. Not applied to custom models.
  --num_beams NUM_BEAMS
                        (xtts only, optional) Controls how many alternative sequences the model explores. Must be equal or greater than length penalty. 
                            Default to config.json model.
  --repetition_penalty REPETITION_PENALTY
                        (xtts only, optional) A penalty that prevents the autoregressive decoder from repeating itself. 
                            Default to config.json model.
  --top_k TOP_K         (xtts only, optional) Top-k sampling. 
                            Lower values mean more likely outputs and increased audio generation speed. 
                            Default to config.json model.
  --top_p TOP_P         (xtts only, optional) Top-p sampling. 
                            Lower values mean more likely outputs and increased audio generation speed. Default to config.json model.
  --speed SPEED         (xtts only, optional) Speed factor for the speech generation. 
                            Default to config.json model.
  --enable_text_splitting
                        (xtts only, optional) Enable TTS text splitting. This option is known to not be very efficient. 
                            Default to config.json model.
  --text_temp TEXT_TEMP
                        (bark only, optional) Text Temperature for the model. 
                            Default to 0.85. Higher temperatures lead to more creative outputs.
  --waveform_temp WAVEFORM_TEMP
                        (bark only, optional) Waveform Temperature for the model. 
                            Default to 0.5. Higher temperatures lead to more creative outputs.
  --output_dir OUTPUT_DIR
                        (Optional) Path to the output directory. Default is set in ./lib/conf.py
  --version             Show the version of the script and exit

Example usage:    
Windows:
    Gradio/GUI:
    ebook2audiobook.cmd
    Headless mode:
    ebook2audiobook.cmd --headless --ebook &#039;/path/to/file&#039;
Linux/Mac:
    Gradio/GUI:
    ./ebook2audiobook.sh
    Headless mode:
    ./ebook2audiobook.sh --headless --ebook &#039;/path/to/file&#039;
    
Tip: to add of silence (1.4 seconds) into your text just use &quot;###&quot; or &quot;[pause]&quot;.

```

NOTE: in gradio/gui mode, to cancel a running conversion, just click on the [X] from the ebook upload component.

TIP: if it needs some more pauses, just add &#039;###&#039; or &#039;[pause]&#039; between the words you wish more pause. one [pause] equals to 1.4 seconds

#### Docker GPU Options

Available pre-build tags: `latest` (CUDA 11.8)
#### Edit: IF GPU isn&#039;t detected then you&#039;ll have to build the image -&gt; [Building the Docker Container](#building-the-docker-container)



#### Running the pre-built Docker Container

 -Run with CPU only
```powershell
docker run --pull always --rm -p 7860:7860 athomasson2/ebook2audiobook
```
 -Run with GPU Speedup (NVIDIA compatible only)
```powershell
docker run --pull always --rm --gpus all -p 7860:7860 athomasson2/ebook2audiobook
```

This command will start the Gradio interface on port 7860.(localhost:7860)
- For more options add the parameter `--help`


#### Building the Docker Container
- You can build the docker image with the command:
```powershell
docker build -t athomasson2/ebook2audiobook .
```
#### Avalible Docker Build Arguments

`--build-arg TORCH_VERSION=cuda118` Available tags: [cuda121, cuda118, cuda128, rocm, xpu, cpu] 

All CUDA version numbers should work, Ex: CUDA 11.6-&gt; cuda116

`--build-arg SKIP_XTTS_TEST=true` (Saves space by not baking XTTSv2 model into docker image)


## Docker container file locations
All ebook2audiobooks will have the base dir of `/app/`
For example:
`tmp` = `/app/tmp`
`audiobooks` = `/app/audiobooks`


## Docker headless guide

- Before you do run this you need to create a dir named &quot;input-folder&quot; in your current dir
  which will be linked, This is where you can put your input files for the docker image to see
```bash
mkdir input-folder &amp;&amp; mkdir Audiobooks
```
- In the command below swap out **YOUR_INPUT_FILE.TXT** with the name of your input file 
```bash
docker run --pull always --rm \
    -v $(pwd)/input-folder:/app/input_folder \
    -v $(pwd)/audiobooks:/app/audiobooks \
    athomasson2/ebook2audiobook \
    --headless --ebook /input_folder/YOUR_EBOOK_FILE
```
- The output Audiobooks will be found in the Audiobook folder which will also be located
  in your local dir you ran this docker command in


## To get the help command for the other parameters this program has you can run this 

```bash
docker run --pull always --rm athomasson2/ebook2audiobook --help

```
That will output this 
[Help command output](#help-command-output)


### Docker Compose
This project uses Docker Compose to run locally. You can enable or disable GPU support 
by setting either `*gpu-enabled` or `*gpu-disabled` in `docker-compose.yml`


#### Steps to Run
1. **Clone the Repository** (if you haven&#039;t already):
   ```bash
   git clone https://github.com/DrewThomasson/ebook2audiobook.git
   cd ebook2audiobook
   ```
2. **Set GPU Support (disabled by default)**
  To enable GPU support, modify `docker-compose.yml` and change `*gpu-disabled` to `*gpu-enabled`
3. **Start the service:**
    ```bash
    # Docker
    docker-compose up -d # To update add --build

    # Podman
    podman compose -f podman-compose.yml up -d # To update add --build
    ```
4. **Access the service:**
  The service will be available at http://localhost:7860.


## Common Docker Issues

- My NVIDIA GPU isnt being detected?? -&gt; [GPU ISSUES Wiki Page](https://github.com/DrewThomasson/ebook2audiobook/wiki/GPU-ISSUES)

- `python: can&#039;t open file &#039;/home/user/app/app.py&#039;: [Errno 2] No such file or directory` (Just remove all post arguments as I replaced the `CMD` with `ENTRYPOINT` in the [Dockerfile](Dockerfile))
  - Example: `docker run --pull always athomasson2/ebook2audiobook app.py --script_mode full_docker` - &gt; corrected - &gt; `docker run --pull always athomasson2/ebook2audiobook`
  - Arguments can be easily added like this now `docker run --pull always athomasson2/ebook2audiobook --share`

- Docker gets stuck downloading Fine-Tuned models.
  (This does not happen for every computer but some appear to run into this issue)
  Disabling the progress bar appears to fix the issue,
  as discussed [here in #191](https://github.com/DrewThomasson/ebook2audiobook/issues/191)
  Example of adding this fix in the `docker run` command
```Dockerfile
docker run --pull always --rm --gpus all -e HF_HUB_DISABLE_PROGRESS_BARS=1 -e HF_HUB_ENABLE_HF_TRANSFER=0 \
    -p 7860:7860 athomasson2/eboo

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[srbhr/Resume-Matcher]]></title>
            <link>https://github.com/srbhr/Resume-Matcher</link>
            <guid>https://github.com/srbhr/Resume-Matcher</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:10 GMT</pubDate>
            <description><![CDATA[Improve your resumes with Resume Matcher. Get insights, keyword suggestions and tune your resumes to job descriptions.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/srbhr/Resume-Matcher">srbhr/Resume-Matcher</a></h1>
            <p>Improve your resumes with Resume Matcher. Get insights, keyword suggestions and tune your resumes to job descriptions.</p>
            <p>Language: Python</p>
            <p>Stars: 22,503</p>
            <p>Forks: 4,336</p>
            <p>Stars today: 154 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

[![Resume Matcher](assets/page_2.png)](https://www.resumematcher.fyi)

# Resume Matcher


[ùôπùöòùöíùöó ùô≥ùöíùöúùöåùöòùöõùöç](https://dsc.gg/resume-matcher) ‚ú¶ [ùöÜùöéùöãùöúùöíùöùùöé](https://resumematcher.fyi) ‚ú¶ [ùô∑ùöòùö† ùöùùöò ùô∏ùöóùöúùöùùöäùöïùöï ](#how-to-install) ‚ú¶ [ùô≤ùöòùöóùöùùöõùöíùöãùöûùöùùöòùöõùöú](#contributors) ‚ú¶ [ùô≥ùöòùöóùöäùöùùöé](#support-the-development-by-donating) ‚ú¶ [ùöÉùö†ùöíùöùùöùùöéùöõ/ùöá](https://twitter.com/_srbhr_) ‚ú¶ [ùôªùöíùöóùöîùöéùöçùô∏ùöó](https://www.linkedin.com/company/resume-matcher/)

**Stop getting auto-rejected by ATS bots.** Resume Matcher is the AI-powered platform that reverse-engineers hiring algorithms to show you exactly how to tailor your resume. Get the keywords, formatting, and insights that actually get you past the first screen and into human hands.

Hoping to make this, **VS Code for making resumes**.

&lt;/div&gt;

&lt;br&gt;

&lt;div align=&quot;center&quot;&gt;

![Stars](https://img.shields.io/github/stars/srbhr/Resume-Matcher?labelColor=black&amp;style=for-the-badge&amp;color=c20a71)
![Apache 2.0](https://img.shields.io/github/license/srbhr/Resume-Matcher?labelColor=black&amp;style=for-the-badge&amp;color=c20a71) ![Forks](https://img.shields.io/github/forks/srbhr/Resume-Matcher?labelColor=black&amp;style=for-the-badge&amp;color=c20a71) ![version](https://img.shields.io/badge/Version-0.1%20Veridis%20Quo-FFF?labelColor=black&amp;logo=LinkedIn&amp;style=for-the-badge&amp;color=c20a71)


[![Discord](https://img.shields.io/discord/1122069176962531400?labelColor=black&amp;logo=discord&amp;logoColor=c20a71&amp;style=for-the-badge&amp;color=c20a71)](https://dsc.gg/resume-matcher) [![Website](https://img.shields.io/badge/website-Resume%20Matcher-FFF?labelColor=black&amp;style=for-the-badge&amp;color=c20a71)](https://resumematcher.fyi) [![LinkedIn](https://img.shields.io/badge/LinkedIn-Resume%20Matcher-FFF?labelColor=black&amp;logo=LinkedIn&amp;style=for-the-badge&amp;color=c20a71)](https://www.linkedin.com/company/resume-matcher/)

&lt;a href=&quot;https://trendshift.io/repositories/565&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/565&quot; alt=&quot;srbhr%2FResume-Matcher | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

![Vercel OSS Program](https://vercel.com/oss/program-badge.svg)

&lt;/div&gt;

&gt; \[!IMPORTANT]
&gt;
&gt; This project is in active development. New features are being added continuously, and we welcome contributions from the community. There are some breaking changes on the `main` branch. If you have any suggestions or feature requests, please feel free to open an issue on GitHub or discuss it on our [Discord](https://dsc.gg/resume-matcher) server.


## Getting started with Resume Matcher

Resume Matcher is designed to help you optimize your resume with the aim to highlight your skills and experience in a way that resonates with potential employers.

We&#039;re working on actively improving the platform, towards building a **VS Code for making resumes**, and adding new features. The best way to stay updated is to join the discord discussion and be part of the active development community.

&gt; Join our [Discord](https://dsc.gg/resume-matcher) community üëá
[![Discord](assets/resume_matcher_discord.png)](https://dsc.gg/resume-matcher)

&gt; Follow us on [LinkedIn](https://www.linkedin.com/company/resume-matcher/) ‚ú®
[![LinkedIn](assets/resume_matcher_linkedin.png)](https://www.linkedin.com/company/resume-matcher/)

&gt; ‚≠ê Star Resume Matcher to support the development and get updates on GitHub.
![Star Resume Matcher](assets/star_resume_matcher.png)

## Key Features

![resume_matcher_features](assets/resume_matcher_features.png)

- **Works locally**: No need to upload your resume to a server. Everything runs on your machine with open source AI models by Ollama.
- **ATS Compatibility**: Get a detailed analysis of your resume&#039;s compatibility with ATS systems.
- **Instant Match Score**: Upload resume &amp; job description for a quick match score and key improvement areas.
- **Keyword Optimizer**: Align your resume with job keywords and identify critical content gaps.
- **Guided Improvements**: Get clear suggestions to make your resume stand out.

### Roadmap 

If you have any suggestions or feature requests, please feel free to open an issue on GitHub. And discuss it on our [Discord](https://dsc.gg/resume-matcher) server.

- Visual keyword highlighting.
- AI Canvas, which can help to craft impactful, metric-driven resume content.
- Multi-job description optimization.

## How to Install

![Installation](assets/how_to_install_resumematcher.png)

Follow the instructions in the [SETUP.md](SETUP.md) file to set up the project locally. The setup script will install all the necessary dependencies and configure your environment.

The project is built using:

- FastAPI for the backend.
- Next.js for the frontend.
- Ollama for local AI model serving.
- Tailwind CSS for styling.
- SQLite for the database.

| Technology   | Info/Version                               |
|--------------|---------------------------------------|
| Python      | 3.12+                   |
| Next.js      | 15+                   |
| Ollama       |        0.6.7        |


## Join Us and Contribute

![how to contribute](assets/how_to_contribute.png)

We welcome contributions from everyone! Whether you&#039;re a developer, designer, or just someone who wants to help out. All the contributors are listed in the [about page](https://resumematcher.fyi/about) on our website and on the GitHub Readme here.

Checkout the roadmap if you would like to work on the features that are planned for the future. If you have any suggestions or feature requests, please feel free to open an issue on GitHub. And discuss it on our [Discord](https://dsc.gg/resume-matcher) server.

## Contributors
![Contributors](assets/contributors.png)

&lt;a href=&quot;https://github.com/srbhr/Resume-Matcher/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=srbhr/Resume-Matcher&quot; /&gt;
&lt;/a&gt;

## Support the Development by Donating
![donate](assets/supporting_resume_matcher.png)

If you would like to support the development of Resume Matcher, you can do so by donating. Your contributions will help us keep the project alive and continue adding new features.

| Platform  | Link                                   |
|-----------|----------------------------------------|
| GitHub    | [![GitHub Sponsors](https://img.shields.io/github/sponsors/srbhr?style=for-the-badge&amp;color=c20a71&amp;labelColor=black&amp;logo=github)](https://github.com/sponsors/srbhr) |
| Buy Me a Coffee | [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&amp;logo=buy-me-a-coffee&amp;color=c20a72&amp;logoColor=white)](https://www.buymeacoffee.com/srbhr) |

&lt;details&gt;
  &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=srbhr/resume-matcher&amp;theme=dark&amp;type=Date&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;https://api.star-history.com/svg?repos=srbhr/resume-matcher&amp;theme=dark&amp;type=Date&quot;&gt;
  &lt;/picture&gt;
&lt;/details&gt;

## Resume Matcher is a part of [Vercel Open Source Program](https://vercel.com/oss)


![Vercel OSS Program](https://vercel.com/oss/program-badge.svg)

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[9001/copyparty]]></title>
            <link>https://github.com/9001/copyparty</link>
            <guid>https://github.com/9001/copyparty</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:09 GMT</pubDate>
            <description><![CDATA[Portable file server with accelerated resumable uploads, dedup, WebDAV, FTP, TFTP, zeroconf, media indexer, thumbnails++ all in one file, no deps]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/9001/copyparty">9001/copyparty</a></h1>
            <p>Portable file server with accelerated resumable uploads, dedup, WebDAV, FTP, TFTP, zeroconf, media indexer, thumbnails++ all in one file, no deps</p>
            <p>Language: Python</p>
            <p>Stars: 24,894</p>
            <p>Forks: 897</p>
            <p>Stars today: 316 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://github.com/9001/copyparty/raw/hovudstraum/docs/logo.svg&quot; width=&quot;250&quot; align=&quot;right&quot;/&gt;

### üíæüéâ copyparty

turn almost any device into a file server with resumable uploads/downloads using [*any*](#browser-support) web browser

* server only needs Python (2 or 3), all dependencies optional
* üîå protocols: [http](#the-browser) // [webdav](#webdav-server) // [ftp](#ftp-server) // [tftp](#tftp-server) // [smb/cifs](#smb-server)
* üì± [android app](#android-app) // [iPhone shortcuts](#ios-shortcuts)

üëâ **[Get started](#quickstart)!** or visit the **[read-only demo server](https://a.ocv.me/pub/demo/)** üëÄ running on a nuc in my basement

üì∑ **screenshots:** [browser](#the-browser) // [upload](#uploading) // [unpost](#unpost) // [thumbnails](#thumbnails) // [search](#searching) // [fsearch](#file-search) // [zip-DL](#zip-downloads) // [md-viewer](#markdown-viewer)

üé¨ **videos:** [upload](https://a.ocv.me/pub/demo/pics-vids/up2k.webm) // [cli-upload](https://a.ocv.me/pub/demo/pics-vids/u2cli.webm) // [race-the-beam](https://a.ocv.me/pub/g/nerd-stuff/cpp/2024-0418-race-the-beam.webm) // üëâ **[feature-showcase](https://a.ocv.me/pub/demo/showcase-hq.webm)** ([youtube](https://www.youtube.com/watch?v=15_-hgsX2V0))

made in Norway üá≥üá¥


## readme toc

* top
    * [quickstart](#quickstart) - just run **[copyparty-sfx.py](https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py)** -- that&#039;s it! üéâ
        * [at home](#at-home) - make it accessible over the internet
        * [on servers](#on-servers) - you may also want these, especially on servers
    * [features](#features) - also see [comparison to similar software](./docs/versus.md)
    * [testimonials](#testimonials) - small collection of user feedback
* [motivations](#motivations) - project goals / philosophy
    * [notes](#notes) - general notes
* [bugs](#bugs) - roughly sorted by chance of encounter
    * [not my bugs](#not-my-bugs) - same order here too
* [breaking changes](#breaking-changes) - upgrade notes
* [FAQ](#FAQ) - &quot;frequently&quot; asked questions
* [accounts and volumes](#accounts-and-volumes) - per-folder, per-user permissions
    * [shadowing](#shadowing) - hiding specific subfolders
    * [dotfiles](#dotfiles) - unix-style hidden files/folders
* [the browser](#the-browser) - accessing a copyparty server using a web-browser
    * [tabs](#tabs) - the main tabs in the ui
    * [hotkeys](#hotkeys) - the browser has the following hotkeys
    * [navpane](#navpane) - switching between breadcrumbs or navpane
    * [thumbnails](#thumbnails) - press `g` or `Áî∞` to toggle grid-view instead of the file listing
    * [zip downloads](#zip-downloads) - download folders (or file selections) as `zip` or `tar` files
    * [uploading](#uploading) - drag files/folders into the web-browser to upload
        * [file-search](#file-search) - dropping files into the browser also lets you see if they exist on the server
        * [unpost](#unpost) - undo/delete accidental uploads
        * [self-destruct](#self-destruct) - uploads can be given a lifetime
        * [race the beam](#race-the-beam) - download files while they&#039;re still uploading ([demo video](http://a.ocv.me/pub/g/nerd-stuff/cpp/2024-0418-race-the-beam.webm))
        * [incoming files](#incoming-files) - the control-panel shows the ETA for all incoming files
    * [file manager](#file-manager) - cut/paste, rename, and delete files/folders (if you have permission)
    * [shares](#shares) - share a file or folder by creating a temporary link
    * [batch rename](#batch-rename) - select some files and press `F2` to bring up the rename UI
    * [rss feeds](#rss-feeds) - monitor a folder with your RSS reader
    * [recent uploads](#recent-uploads) - list all recent uploads
    * [media player](#media-player) - plays almost every audio format there is
        * [playlists](#playlists) - create and play [m3u8](https://en.wikipedia.org/wiki/M3U) playlists
        * [creating a playlist](#creating-a-playlist) - with a standalone mediaplayer or copyparty
        * [audio equalizer](#audio-equalizer) - and [dynamic range compressor](https://en.wikipedia.org/wiki/Dynamic_range_compression)
        * [fix unreliable playback on android](#fix-unreliable-playback-on-android) - due to phone / app settings
    * [textfile viewer](#textfile-viewer) - with realtime streaming of logfiles and such ([demo](https://a.ocv.me/pub/demo/logtail/))
    * [markdown viewer](#markdown-viewer) - and there are *two* editors
        * [markdown vars](#markdown-vars) - dynamic docs with serverside variable expansion
    * [other tricks](#other-tricks)
    * [searching](#searching) - search by size, date, path/name, mp3-tags, ...
* [server config](#server-config) - using arguments or config files, or a mix of both
    * [zeroconf](#zeroconf) - announce enabled services on the LAN ([pic](https://user-images.githubusercontent.com/241032/215344737-0eae8d98-9496-4256-9aa8-cd2f6971810d.png))
        * [mdns](#mdns) - LAN domain-name and feature announcer
        * [ssdp](#ssdp) - windows-explorer announcer
    * [qr-code](#qr-code) - print a qr-code [(screenshot)](https://user-images.githubusercontent.com/241032/194728533-6f00849b-c6ac-43c6-9359-83e454d11e00.png) for quick access
    * [ftp server](#ftp-server) - an FTP server can be started using `--ftp 3921`
    * [webdav server](#webdav-server) - with read-write support
        * [connecting to webdav from windows](#connecting-to-webdav-from-windows) - using the GUI
    * [tftp server](#tftp-server) - a TFTP server (read/write) can be started using `--tftp 3969`
    * [smb server](#smb-server) - unsafe, slow, not recommended for wan
    * [browser ux](#browser-ux) - tweaking the ui
    * [opengraph](#opengraph) - discord and social-media embeds
    * [file deduplication](#file-deduplication) - enable symlink-based upload deduplication
    * [file indexing](#file-indexing) - enable music search, upload-undo, and better dedup
        * [exclude-patterns](#exclude-patterns) - to save some time
        * [filesystem guards](#filesystem-guards) - avoid traversing into other filesystems
        * [periodic rescan](#periodic-rescan) - filesystem monitoring
    * [upload rules](#upload-rules) - set upload rules using volflags
    * [compress uploads](#compress-uploads) - files can be autocompressed on upload
    * [chmod and chown](#chmod-and-chown) - per-volume filesystem-permissions and ownership
    * [other flags](#other-flags)
    * [database location](#database-location) - in-volume (`.hist/up2k.db`, default) or somewhere else
    * [metadata from audio files](#metadata-from-audio-files) - set `-e2t` to index tags on upload
    * [file parser plugins](#file-parser-plugins) - provide custom parsers to index additional tags
    * [event hooks](#event-hooks) - trigger a program on uploads, renames etc ([examples](./bin/hooks/))
        * [zeromq](#zeromq) - event-hooks can send zeromq messages
        * [upload events](#upload-events) - the older, more powerful approach ([examples](./bin/mtag/))
    * [handlers](#handlers) - redefine behavior with plugins ([examples](./bin/handlers/))
    * [ip auth](#ip-auth) - autologin based on IP range (CIDR)
        * [restrict to ip](#restrict-to-ip) - limit a user to certain IP ranges (CIDR)
    * [identity providers](#identity-providers) - replace copyparty passwords with oauth and such
        * [generic header auth](#generic-header-auth) - other ways to auth by header
    * [user-changeable passwords](#user-changeable-passwords) - if permitted, users can change their own passwords
    * [using the cloud as storage](#using-the-cloud-as-storage) - connecting to an aws s3 bucket and similar
    * [hiding from google](#hiding-from-google) - tell search engines you don&#039;t wanna be indexed
    * [themes](#themes)
    * [complete examples](#complete-examples)
    * [listen on port 80 and 443](#listen-on-port-80-and-443) - become a *real* webserver
    * [reverse-proxy](#reverse-proxy) - running copyparty next to other websites
        * [real-ip](#real-ip) - teaching copyparty how to see client IPs
        * [reverse-proxy performance](#reverse-proxy-performance)
    * [permanent cloudflare tunnel](#permanent-cloudflare-tunnel) - if you have a domain and want to get your copyparty online real quick
    * [prometheus](#prometheus) - metrics/stats can be enabled
    * [other extremely specific features](#other-extremely-specific-features) - you&#039;ll never find a use for these
        * [custom mimetypes](#custom-mimetypes) - change the association of a file extension
        * [GDPR compliance](#GDPR-compliance) - imagine using copyparty professionally...
        * [feature chickenbits](#feature-chickenbits) - buggy feature? rip it out
        * [feature beefybits](#feature-beefybits) - force-enable features with known issues on your OS/env
* [packages](#packages) - the party might be closer than you think
    * [arch package](#arch-package) - `pacman -S copyparty` (in [arch linux extra](https://archlinux.org/packages/extra/any/copyparty/))
    * [fedora package](#fedora-package) - does not exist yet
    * [nix package](#nix-package) - `nix profile install github:9001/copyparty`
    * [nixos module](#nixos-module)
* [browser support](#browser-support) - TLDR: yes
* [client examples](#client-examples) - interact with copyparty using non-browser clients
    * [folder sync](#folder-sync) - sync folders to/from copyparty
    * [mount as drive](#mount-as-drive) - a remote copyparty server as a local filesystem
* [android app](#android-app) - upload to copyparty with one tap
* [iOS shortcuts](#iOS-shortcuts) - there is no iPhone app, but
* [performance](#performance) - defaults are usually fine - expect `8 GiB/s` download, `1 GiB/s` upload
    * [client-side](#client-side) - when uploading files
* [security](#security) - there is a [discord server](https://discord.gg/25J8CdTT6G)
    * [gotchas](#gotchas) - behavior that might be unexpected
    * [cors](#cors) - cross-site request config
    * [filekeys](#filekeys) - prevent filename bruteforcing
        * [dirkeys](#dirkeys) - share specific folders in a volume
    * [password hashing](#password-hashing) - you can hash passwords
    * [https](#https) - both HTTP and HTTPS are accepted
* [recovering from crashes](#recovering-from-crashes)
    * [client crashes](#client-crashes)
        * [firefox wsod](#firefox-wsod) - firefox 87 can crash during uploads
* [HTTP API](#HTTP-API) - see [devnotes](./docs/devnotes.md#http-api)
* [dependencies](#dependencies) - mandatory deps
    * [optional dependencies](#optional-dependencies) - install these to enable bonus features
        * [dependency chickenbits](#dependency-chickenbits) - prevent loading an optional dependency
    * [optional gpl stuff](#optional-gpl-stuff)
* [sfx](#sfx) - the self-contained &quot;binary&quot; (recommended!)
    * [copyparty.exe](#copypartyexe) - download [copyparty.exe](https://github.com/9001/copyparty/releases/latest/download/copyparty.exe) (win8+) or [copyparty32.exe](https://github.com/9001/copyparty/releases/latest/download/copyparty32.exe) (win7+)
    * [zipapp](#zipapp) - another emergency alternative, [copyparty.pyz](https://github.com/9001/copyparty/releases/latest/download/copyparty.pyz)
* [install on android](#install-on-android)
* [reporting bugs](#reporting-bugs) - ideas for context to include, and where to submit them
* [devnotes](#devnotes) - for build instructions etc, see [./docs/devnotes.md](./docs/devnotes.md)


## quickstart

just run **[copyparty-sfx.py](https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py)** -- that&#039;s it! üéâ

&gt; ‚ÑπÔ∏è the sfx is a [self-extractor](https://github.com/9001/copyparty/issues/270) which unpacks an embedded `tar.gz` into `$TEMP` -- if this looks too scary, you can use the [zipapp](#zipapp) which has slightly worse performance

* or install through [pypi](https://pypi.org/project/copyparty/): `python3 -m pip install --user -U copyparty`
* or if you cannot install python, you can use [copyparty.exe](#copypartyexe) instead
* or install [on arch](#arch-package) ‚ï± [on NixOS](#nixos-module) ‚ï± [through nix](#nix-package)
* or if you are on android, [install copyparty in termux](#install-on-android)
* or maybe you have a [synology nas / dsm](./docs/synology-dsm.md)
* or if you have [uv](https://docs.astral.sh/uv/) installed, run `uv tool run copyparty`
* or if your computer is messed up and nothing else works, [try the pyz](#zipapp)
* or if your OS is dead, give the [bootable flashdrive / cd-rom](https://a.ocv.me/pub/stuff/edcd001/enterprise-edition/) a spin
* or if you don&#039;t trust copyparty yet and want to isolate it a little, then...
  * ...maybe [prisonparty](./bin/prisonparty.sh) to create a tiny [chroot](https://wiki.archlinux.org/title/Chroot) (very portable),
  * ...or [bubbleparty](./bin/bubbleparty.sh) to wrap it in [bubblewrap](https://github.com/containers/bubblewrap) (much better)
* or if you prefer to [use docker](./scripts/docker/) üêã you can do that too
  * docker has all deps built-in, so skip this step:

enable thumbnails (images/audio/video), media indexing, and audio transcoding by installing some recommended deps:

* **Alpine:** `apk add py3-pillow ffmpeg`
* **Debian:** `apt install --no-install-recommends python3-pil ffmpeg`
* **Fedora:** rpmfusion + `dnf install python3-pillow ffmpeg --allowerasing`
* **FreeBSD:** `pkg install py39-sqlite3 py39-pillow ffmpeg`
* **MacOS:** `port install py-Pillow ffmpeg`
* **MacOS** (alternative): `brew install pillow ffmpeg`
* **Windows:** `python -m pip install --user -U Pillow`
  * install [python](https://www.python.org/downloads/windows/) and [ffmpeg](#optional-dependencies) manually; do not use `winget` or `Microsoft Store` (it breaks $PATH)
  * copyparty.exe comes with `Pillow` and only needs [ffmpeg](#optional-dependencies) for mediatags/videothumbs
* see [optional dependencies](#optional-dependencies) to enable even more features

running copyparty without arguments (for example doubleclicking it on Windows) will give everyone read/write access to the current folder; you may want [accounts and volumes](#accounts-and-volumes)

or see [some usage examples](#complete-examples) for inspiration, or the [complete windows example](./docs/examples/windows.md)

some recommended options:
* `-e2dsa` enables general [file indexing](#file-indexing)
* `-e2ts` enables audio metadata indexing (needs either FFprobe or Mutagen)
* `-v /mnt/music:/music:r:rw,foo -a foo:bar` shares `/mnt/music` as `/music`, `r`eadable by anyone, and read-write for user `foo`, password `bar`
  * replace `:r:rw,foo` with `:r,foo` to only make the folder readable by `foo` and nobody else
  * see [accounts and volumes](#accounts-and-volumes) (or `--help-accounts`) for the syntax and other permissions


### at home

make it accessible over the internet  by starting a [cloudflare quicktunnel](https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/do-more-with-tunnels/trycloudflare/) like so:

first download [cloudflared](https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/downloads/) and then start the tunnel with `cloudflared tunnel --url http://127.0.0.1:3923`

as the tunnel starts, it will show a URL which you can share to let anyone browse your stash or upload files to you

but if you have a domain, then you probably want to skip the random autogenerated URL and instead make a [permanent cloudflare tunnel](#permanent-cloudflare-tunnel)

since people will be connecting through cloudflare, run copyparty with `--xff-hdr cf-connecting-ip` to detect client IPs correctly


### on servers

you may also want these, especially on servers:

* [contrib/systemd/copyparty.service](contrib/systemd/copyparty.service) to run copyparty as a systemd service (see guide inside)
* [contrib/systemd/prisonparty.service](contrib/systemd/prisonparty.service) to run it in a chroot (for extra security)
* [contrib/openrc/copyparty](contrib/openrc/copyparty) to run copyparty on Alpine / Gentoo
* [contrib/rc/copyparty](contrib/rc/copyparty) to run copyparty on FreeBSD
* [nixos module](#nixos-module) to run copyparty on NixOS hosts
* [contrib/nginx/copyparty.conf](contrib/nginx/copyparty.conf) to [reverse-proxy](#reverse-proxy) behind nginx (for better https)

and remember to open the ports you want; here&#039;s a complete example including every feature copyparty has to offer:
```
firewall-cmd --permanent --add-port={80,443,3921,3923,3945,3990}/tcp  # --zone=libvirt
firewall-cmd --permanent --add-port=12000-12099/tcp  # --zone=libvirt
firewall-cmd --permanent --add-port={69,1900,3969,5353}/udp  # --zone=libvirt
firewall-cmd --reload
```
(69:tftp, 1900:ssdp, 3921:ftp, 3923:http/https, 3945:smb, 3969:tftp, 3990:ftps, 5353:mdns, 12000:passive-ftp)


## features

also see [comparison to similar software](./docs/versus.md)

* backend stuff
  * ‚òë IPv6 + unix-sockets
  * ‚òë [multiprocessing](#performance) (actual multithreading)
  * ‚òë volumes (mountpoints)
  * ‚òë [accounts](#accounts-and-volumes)
  * ‚òë [ftp server](#ftp-server)
  * ‚òë [tftp server](#tftp-server)
  * ‚òë [webdav server](#webdav-server)
  * ‚òë [smb/cifs server](#smb-server)
  * ‚òë [qr-code](#qr-code) for quick access
  * ‚òë [upnp / zeroconf / mdns / ssdp](#zeroconf)
  * ‚òë [event hooks](#event-hooks) / script runner
  * ‚òë [reverse-proxy support](https://github.com/9001/copyparty#reverse-proxy)
  * ‚òë cross-platform (Windows, Linux, Macos, Android, FreeBSD, arm32/arm64, ppc64le, s390x, risc-v/riscv64)
* upload
  * ‚òë basic: plain multipart, ie6 support
  * ‚òë [up2k](#uploading): js, resumable, multithreaded
    * **no filesize limit!** even on Cloudflare
  * ‚òë stash: simple PUT filedropper
  * ‚òë filename randomizer
  * ‚òë write-only folders
  * ‚òë [unpost](#unpost): undo/delete accidental uploads
  * ‚òë [self-destruct](#self-destruct) (specified server-side or client-side)
  * ‚òë [race the beam](#race-the-beam) (almost like peer-to-peer)
  * ‚òë symlink/discard duplicates (content-matching)
* download
  * ‚òë single files in browser
  * ‚òë [folders as zip / tar files](#zip-downloads)
  * ‚òë [FUSE client](https://github.com/9001/copyparty/tree/hovudstraum/bin#partyfusepy) (read-only)
* browser
  * ‚òë [navpane](#navpane) (directory tree sidebar)
  * ‚òë file manager (cut/paste, delete, [batch-rename](#batch-rename))
  * ‚òë audio player (with [OS media controls](https://user-images.githubusercontent.com/241032/215347492-b4250797-6c90-4e09-9a4c-721edf2fb15c.png) and opus/mp3 transcoding)
    * ‚òë play video files as audio (converted on server)
    * ‚òë create and play [m3u8 playlists](#playlists)
  * ‚òë image gallery with webm player
  * ‚òë [textfile browser](#textfile-viewer) with syntax hilighting
    * ‚òë realtime streaming of growing files (logfiles and such)
  * ‚òë [thumbnails](#thumbnails)
    * ‚òë ...of images using Pillow, pyvips, or FFmpeg
    * ‚òë ...of RAW images using rawpy
    * ‚òë ...of videos using FFmpeg
    * ‚òë ...of audio (spectrograms) using FFmpeg
    * ‚òë cache eviction (max-age; maybe max-size eventually)
  * ‚òë multilingual UI (english, norwegian, chinese, [add your own](./docs/rice/#translations)))
  * ‚òë SPA (browse while uploading)
* server indexing
  * ‚òë [locate files by contents](#file-search)
  * ‚òë search by name/path/date/size
  * ‚òë [search by ID3-tags etc.](#searching)
* client support
  * ‚òë [folder sync](#folder-sync) (one-way only; full sync will never be supported)
  * ‚òë [curl-friendly](https://user-images.githubusercontent.com/241032/215322619-ea5fd606-3654-40ad-94ee-2bc058647bb2.png)
  * ‚òë [opengraph](#opengraph) (discord embeds)
* markdown
  * ‚òë [viewer](#markdown-viewer)
  * ‚òë editor (sure why not)
  * ‚òë [variables](#markdown-vars)

PS: something missing? post any crazy ideas you&#039;ve got as a [feature request](https://github.com/9001/copyparty/issues/new?assignees=9001&amp;labels=enhancement&amp;template=feature_request.md) or [discussion](https://github.com/9001/copyparty/discussions/new?category=idea

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[3b1b/manim]]></title>
            <link>https://github.com/3b1b/manim</link>
            <guid>https://github.com/3b1b/manim</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:08 GMT</pubDate>
            <description><![CDATA[Animation engine for explanatory math videos]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/3b1b/manim">3b1b/manim</a></h1>
            <p>Animation engine for explanatory math videos</p>
            <p>Language: Python</p>
            <p>Stars: 79,611</p>
            <p>Forks: 6,831</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/3b1b/manim&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/3b1b/manim/master/logo/cropped.png&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

[![pypi version](https://img.shields.io/pypi/v/manimgl?logo=pypi)](https://pypi.org/project/manimgl/)
[![MIT License](https://img.shields.io/badge/license-MIT-blue.svg?style=flat)](http://choosealicense.com/licenses/mit/)
[![Manim Subreddit](https://img.shields.io/reddit/subreddit-subscribers/manim.svg?color=ff4301&amp;label=reddit&amp;logo=reddit)](https://www.reddit.com/r/manim/)
[![Manim Discord](https://img.shields.io/discord/581738731934056449.svg?label=discord&amp;logo=discord)](https://discord.com/invite/bYCyhM9Kz2)
[![docs](https://github.com/3b1b/manim/workflows/docs/badge.svg)](https://3b1b.github.io/manim/)

Manim is an engine for precise programmatic animations, designed for creating explanatory math videos.

Note, there are two versions of manim.  This repository began as a personal project by the author of [3Blue1Brown](https://www.3blue1brown.com/) for the purpose of animating those videos, with video-specific code available [here](https://github.com/3b1b/videos).  In 2020 a group of developers forked it into what is now the [community edition](https://github.com/ManimCommunity/manim/), with a goal of being more stable, better tested, quicker to respond to community contributions, and all around friendlier to get started with. See [this page](https://docs.manim.community/en/stable/faq/installation.html#different-versions) for more details.

## Installation
&gt; [!Warning]
&gt; **WARNING:** These instructions are for ManimGL _only_. Trying to use these instructions to install [Manim Community/manim](https://github.com/ManimCommunity/manim) or instructions there to install this version will cause problems. You should first decide which version you wish to install, then only follow the instructions for your desired version.

&gt; [!Note]
&gt; **Note**: To install manim directly through pip, please pay attention to the name of the installed package. This repository is ManimGL of 3b1b. The package name is `manimgl` instead of `manim` or `manimlib`. Please use `pip install manimgl` to install the version in this repository.

Manim runs on Python 3.7 or higher.

System requirements are [FFmpeg](https://ffmpeg.org/), [OpenGL](https://www.opengl.org/) and [LaTeX](https://www.latex-project.org) (optional, if you want to use LaTeX).
For Linux, [Pango](https://pango.org) along with its development headers are required. See instruction [here](https://github.com/ManimCommunity/ManimPango#building).


### Directly

```sh
# Install manimgl
pip install manimgl

# Try it out
manimgl
```

For more options, take a look at the [Using manim](#using-manim) sections further below.

If you want to hack on manimlib itself, clone this repository and in that directory execute:

```sh
# Install manimgl
pip install -e .

# Try it out
manimgl example_scenes.py OpeningManimExample
# or
manim-render example_scenes.py OpeningManimExample
```

### Directly (Windows)

1. [Install FFmpeg](https://www.wikihow.com/Install-FFmpeg-on-Windows).
2. Install a LaTeX distribution. [MiKTeX](https://miktex.org/download) is recommended.
3. Install the remaining Python packages.
    ```sh
    git clone https://github.com/3b1b/manim.git
    cd manim
    pip install -e .
    manimgl example_scenes.py OpeningManimExample
    ```

### Mac OSX

1. Install FFmpeg, LaTeX in terminal using homebrew.
    ```sh
    brew install ffmpeg mactex
    ```

2. If you are using an ARM-based processor, install Cairo. 
    ```sh
    arch -arm64 brew install pkg-config cairo
    ```
   
3. Install latest version of manim using these command.
    ```sh
    git clone https://github.com/3b1b/manim.git
    cd manim
    pip install -e .
    manimgl example_scenes.py OpeningManimExample (make sure to add manimgl to path first.)
    ```

## Anaconda Install

1. Install LaTeX as above.
2. Create a conda environment using `conda create -n manim python=3.8`.
3. Activate the environment using `conda activate manim`.
4. Install manimgl using `pip install -e .`.


## Using manim
Try running the following:
```sh
manimgl example_scenes.py OpeningManimExample
```
This should pop up a window playing a simple scene.

Look through the [example scenes](https://3b1b.github.io/manim/getting_started/example_scenes.html) to see examples of the library&#039;s syntax, animation types and object types. In the [3b1b/videos](https://github.com/3b1b/videos) repo, you can see all the code for 3blue1brown videos, though code from older videos may not be compatible with the most recent version of manim. The readme of that repo also outlines some details for how to set up a more interactive workflow, as shown in [this manim demo video](https://www.youtube.com/watch?v=rbu7Zu5X1zI) for example.

When running in the CLI, some useful flags include:
* `-w` to write the scene to a file
* `-o` to write the scene to a file and open the result
* `-s` to skip to the end and just show the final frame.
    * `-so` will save the final frame to an image and show it
* `-n &lt;number&gt;` to skip ahead to the `n`&#039;th animation of a scene.
* `-f` to make the playback window fullscreen

Take a look at custom_config.yml for further configuration.  To add your customization, you can either edit this file, or add another file by the same name &quot;custom_config.yml&quot; to whatever directory you are running manim from.  For example [this is the one](https://github.com/3b1b/videos/blob/master/custom_config.yml) for 3blue1brown videos.  There you can specify where videos should be output to, where manim should look for image files and sounds you want to read in, and other defaults regarding style and video quality.

### Documentation
Documentation is in progress at [3b1b.github.io/manim](https://3b1b.github.io/manim/). And there is also a Chinese version maintained by [**@manim-kindergarten**](https://manim.org.cn): [docs.manim.org.cn](https://docs.manim.org.cn/) (in Chinese).

[manim-kindergarten](https://github.com/manim-kindergarten/) wrote and collected some useful extra classes and some codes of videos in [manim_sandbox repo](https://github.com/manim-kindergarten/manim_sandbox).


## Contributing
Is always welcome.  As mentioned above, the [community edition](https://github.com/ManimCommunity/manim) has the most active ecosystem for contributions, with testing and continuous integration, but pull requests are welcome here too.  Please explain the motivation for a given change and examples of its effect.


## License
This project falls under the MIT license.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[bkerler/mtkclient]]></title>
            <link>https://github.com/bkerler/mtkclient</link>
            <guid>https://github.com/bkerler/mtkclient</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:07 GMT</pubDate>
            <description><![CDATA[MTK reverse engineering and flash tool]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bkerler/mtkclient">bkerler/mtkclient</a></h1>
            <p>MTK reverse engineering and flash tool</p>
            <p>Language: Python</p>
            <p>Stars: 3,573</p>
            <p>Forks: 686</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;right&quot;&gt;
  Language:
  üá∫üá∏
  &lt;a title=&quot;Chinese&quot; href=&quot;./README.zh-CN.md&quot;&gt;üá®üá≥&lt;/a&gt;
&lt;/div&gt;

# MTKClient
![Logo](mtkclient/gui/images/logo_256.png)

Just some mtk tool for exploitation, reading/writing flash and doing crazy stuff.
For windows, you need to install the stock mtk port and the usbdk driver (see instructions below).
For linux, a patched kernel is only needed when using old kamakiri (see Setup folder) (except for read/write flash).

Once the mtk script is running, boot into brom mode by powering off device, press and hold either
vol up + power or vol down + power and connect the phone. Once detected by the tool,
release the buttons.

## MT6781, MT6789, MT6855, MT6886, MT6895, MT6983, MT8985
- These chipsets use a new protocol called V6 and the bootrom is patched, thus you need a valid da via --loader option.
- On some devices, preloader is deactivated, but you still use it by running &quot;adb reboot edl&quot;.
- This only works with UNFUSED devices currently.
- For all devices with DAA, SLA and Remote-Auth activated no public solution currently exists (for various reasons).

## Credits
- kamakiri [xyzz]
- linecode exploit [chimera]
- Chaosmaster
- Geert-Jan Kreileman (GUI, design &amp; fixes)
- All contributors

## Installation

### Use Re LiveDVD (everything ready to go, based on Ubuntu):
User: user, Password:user (based on Ubuntu 22.04 LTS)

[Live DVD V6](https://www.androidfilehost.com/?fid=1109791587270922802)


## Install

### Linux - (Ubuntu recommended, no patched kernel needed except for kamakiri)

#### Install python &gt;=3.8, git and other deps

#### For Debian/Ubuntu
```
sudo apt install python3 git libusb-1.0-0 python3-pip libfuse2
```
#### For ArchLinux
```
(sudo) pacman -S  python python-pip python-pipenv git libusb fuse2
```
or
```
yay -S python python-pip git libusb fuse2
```

#### For Fedora
```
sudo dnf install python3 git libusb1 fuse
```

#### Grab files
```
git clone https://github.com/bkerler/mtkclient
cd mtkclient
pip3 install -r requirements.txt
pip3 install .
```

### Using venv
```
python3 -m venv ~/.venv
git clone https://github.com/bkerler/mtkclient
cd mtkclient
. ~/.venv/bin/activate
pip install -r requirements.txt
pip install .
```

#### Install rules
```
sudo usermod -a -G plugdev $USER
sudo usermod -a -G dialout $USER
sudo cp mtkclient/Setup/Linux/*.rules /etc/udev/rules.d
sudo udevadm control -R
sudo udevadm trigger
```
Make sure to reboot after adding the user to dialout/plugdev. If the device
has a vendor interface 0xFF (like LG), make sure to add &quot;blacklist qcaux&quot; to
the &quot;/etc/modprobe.d/blacklist.conf&quot;.

---------------------------------------------------------------------------------------------------------------

### macOS

#### Install brew, macFUSE, OpenSSL

```
/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;
brew install macfuse openssl
```

You may need to **reboot**

#### Grab files
```
git clone https://github.com/bkerler/mtkclient
cd mtkclient
```

#### Create python 3.9 venv and install dependencies
```
python3.9 -m venv mtk_venv
source mtk_venv/bin/activate
pip3 install --pre --no-binary capstone capstone
pip3 install PySide6 libusb
pip3 install -r requirements.txt
```

---------------------------------------------------------------------------------------------------------------

### Windows

#### Install python + git
- Install python &gt;= 3.9 and git
- If you install python from microsoft store, &quot;python setup.py install&quot; will fail, but that step isn&#039;t required.
- WIN+R ```cmd```

#### Install Winfsp (for fuse)
Download and install [here](https://winfsp.dev/rel/)

#### Install OpenSSL 1.1.1 (for python scrypt dependency)
Download and install [here](https://sourceforge.net/projects/openssl-for-windows/files/)

#### Grab files and install
```
git clone https://github.com/bkerler/mtkclient
cd mtkclient
pip3 install -r requirements.txt
```

#### Get latest UsbDk 64-Bit
- Install normal MTK Serial Port driver (or use default Windows COM Port one, make sure no exclamation is seen)
- Get usbdk installer (.msi) from [here](https://github.com/daynix/UsbDk/releases/) and install it
- Test on device connect using &quot;UsbDkController -n&quot; if you see a device with 0x0E8D 0x0003
- Works fine under Windows 10 and 11 :D

#### Building wheel issues (creds to @Oyoh-Edmond)
##### Download and Install the Build Tools:
    Go to the Visual Studio Build Tools [download](https://visualstudio.microsoft.com/visual-cpp-build-tools) page.
    Download the installer and run it.

###### Select the Necessary Workloads:
    In the installer, select the &quot;Desktop development with C++&quot; workload.
    Ensure that the &quot;MSVC v142 - VS 2019 C++ x64/x86 build tools&quot; (or later) component is selected.
    You can also check &quot;Windows 10 SDK&quot; if it‚Äôs not already selected.

###### Complete the Installation:
    Click on the &quot;Install&quot; button to begin the installation.
    Follow the prompts to complete the installation.
    Restart your computer if required.

---------------------------------------------------------------------------------------------------------------
### Use kamakiri (optional, only needed for mt6260 or older)

- For linux (kamakiri attack), you need to recompile your linux kernel using this kernel patch :
```
sudo apt-get install build-essential libncurses-dev bison flex libssl-dev libelf-dev libdw-dev
git clone https://git.kernel.org/pub/scm/devel/pahole/pahole.git
cd pahole &amp;&amp; mkdir build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; make &amp;&amp; sudo make install
sudo mv /usr/local/libdwarves* /usr/local/lib/ &amp;&amp; sudo ldconfig
```

```
wget https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-`uname -r`.tar.xz
tar xvf linux-`uname -r`.tar.xz
cd linux-`uname -r`
patch -p1 &lt; ../Setup/kernelpatches/disable-usb-checks-5.10.patch
cp -v /boot/config-$(uname -r) .config
make menuconfig
make
sudo make modules_install
sudo make install
```

- These aren&#039;t needed for current ubuntu (as make install will do, just for reference):

```
sudo update-initramfs -c -k `uname -r`
sudo update-grub
```

See Setup/kernels for ready-to-use kernel setups


- Reboot

```
sudo reboot
```


---------------------------------------------------------------------------------------------------------------

## Usage

### Using MTKTools via the graphical user interface:
For the &#039;basics&#039; you can use the GUI interface. This supports dumping partitions or the full flash for now. Run the following command:
```
python mtk_gui.py
```

### Using stock mtk functionality without exploits :
```
python mtk.py --stock
```

### Run multiple commands
```bash
python mtk.py script examples/run.example
```
or
```
python mtk.py multi &quot;cmd1;cmd2&quot;
```
See the file &quot;[run.example](https://github.com/bkerler/mtkclient/blob/main/examples/run.example)&quot; on how to structure the script file

### Using in on venv
Basically, you created a venv folder, so you need to use it to python find the right packages, and don&#039;t have any conflicts
```
. ~/.venv/bin/activate
```
You should see something like this...
```
(.venv) [user@hostname]$ 
```
This means you are on venv folder!

* Example comands below...

```
./mtk.py r boot,vbmeta boot.img,vbmeta.img
./mtk.py payload
./mtk.py reset
```
or simply
```
mtk r boot,vbmeta boot.img,vbmeta.img
mtk payload
mtk reset
```

### Root the phone (Tested with android 9 - 12)

1. Dump boot and vbmeta
```
python mtk.py r boot,vbmeta boot.img,vbmeta.img
```

2. Reboot the phone
```
python mtk.py reset
```

3. Download patched magisk for mtk:
Download latest Magisk [here](https://github.com/topjohnwu/Magisk/releases/latest)

4. Install on target phone
- you need to enable usb-debugging via Settings/About phone/Version, Tap 7x on build number
- Go to Settings/Additional settings/Developer options, enable &quot;OEM unlock&quot; and &quot;USB Debugging&quot;
- Install magisk apk
```
adb install app-release.apk
```
- accept auth rsa request on mobile screen of course to allow adb connection

5. Upload boot to /sdcard/Download
```
adb push boot.img /sdcard/Download
```

6. Start magisk, tap on Install, select boot.img from /sdcard/Download, then:
```
adb pull /sdcard/Download/[displayed magisk patched boot filename here]
mv [displayed magisk patched boot filename here] boot.patched
```

7. Do the steps needed in section &quot;Unlock bootloader below&quot;

8. Flash magisk-patched boot and disable verity + verification on vbmeta
```
python mtk.py da vbmeta 3
python mtk.py w boot boot.patched
```

9. Reboot the phone
```
python mtk.py reset
```

10. Disconnect usb cable and enjoy your rooted phone :)


### Boot to meta mode via payload

Example:

```
python mtk.py payload --metamode FASTBOOT
```

### Dump preloader
```
mtk.py r preloader preloader.bin --parttype boot1
```

### Dump serialnumber / special partition
```
mtk.py r preloader preloader.bin --parttype boot2
```

### Read efuses

Example:

```
python mtk.py da efuse
```

### Unlock bootloader

1. Erase metadata and userdata (and md_udc if existing):
```
python mtk.py e metadata,userdata,md_udc
```

2. Unlock bootloader:
```
python mtk.py da seccfg unlock
```
for relocking use:
```
python mtk.py da seccfg lock
```

3. Reboot the phone:
```
python mtk.py reset
```

and disconnect usb cable to let the phone reboot.

If you are getting a dm-verity error on Android 11, just press the power button,
then the device should boot and show a yellow warning about unlocked bootloader and
then the device should boot within 5 seconds.


### Read flash

Dump boot partition to filename boot.bin via preloader

```
python mtk.py r boot boot.bin
```

Dump boot partition to filename boot.bin via bootrom

```
python mtk.py r boot boot.bin [--preloader=Loader/Preloader/your_device_preloader.bin]
```


Dump preloader partition to filename preloader.bin via bootrom

```
python mtk.py r preloader preloader.bin --parttype=boot1 [--preloader=Loader/Preloader/your_device_preloader.bin]
```

Read full flash to filename flash.bin (use --preloader for brom)

```
python mtk.py rf flash.bin
```

Read full flash to filename flash.bin (use --preloader for brom) for IoT devices (MT6261/MT2301):

```
python mtk.py rf flash.bin --iot
```

Read flash offset 0x128000 with length 0x200000 to filename flash.bin (use --preloader for brom)

```
python mtk.py ro 0x128000 0x200000 flash.bin
```

Dump all partitions to directory &quot;out&quot;. (use --preloader for brom)

```
python mtk.py rl out
```

Show gpt (use --preloader for brom)

```
python mtk.py printgpt
```


Mount the flash as a filesystem

```
python mtk.py fs /mnt/mtk
```

### Write flash
(use --preloader for brom)

Write filename boot.bin to boot partition

```
python mtk.py w boot boot.bin
```

Write filename flash.bin as full flash (currently only works in da mode)

```
python mtk.py wf flash.bin
```

Write all files in directory &quot;out&quot; to the flash partitions

```
python mtk.py wl out
```

write file flash.bin to flash offset 0x128000 with length 0x200000 (use --preloader for brom)

```
python mtk.py wo 0x128000 0x200000 flash.bin
```

### Erase flash

Erase boot partition
```
python mtk.py e boot
```

Erase boot sectors
```
python mtk.py es boot [sector count]
```

### DA commands:

Peek memory
```
python mtk.py da peek [addr in hex] [length in hex] [optional: -filename filename.bin for reading to file]
```

Poke memory
```
python mtk.py da poke [addr in hex] [data as hexstring or -filename for reading from file]
```

Read rpmb (Only xflash for now)
```
python mtk.py da rpmb r [will read to rpmb.bin]
```

Write rpmb [Currently broken, xflash only]
```
python mtk.py da rpmb w filename
```

Generate and display rpmb1-3 key
```
python mtk.py da generatekeys
```

Unlock / Lock bootloader
```
python mtk.py da seccfg [lock or unlock]
```

---------------------------------------------------------------------------------------------------------------

### Bypass SLA, DAA and SBC (using generic_patcher_payload)
``
python mtk.py payload
``
If you want to use SP Flash tool afterwards, make sure you select &quot;UART&quot; in the settings, not &quot;USB&quot;.

### Dump preloader
- Device has to be in bootrom mode and preloader has to be intact on the device
```
python mtk.py dumppreloader [--ptype=[&quot;amonet&quot;,&quot;kamakiri&quot;,&quot;kamakiri2&quot;,&quot;hashimoto&quot;]] [--filename=preloader.bin]
```

### Dump brom
- Device has to be in bootrom mode, or da mode has to be crashed to enter damode
- if no option is given, either kamakiri or da will be used (da for insecure targets)
- if &quot;kamakiri&quot; is used as an option, kamakiri is enforced
- Valid options are : &quot;kamakiri&quot; (via usb_ctrl_handler attack), &quot;amonet&quot; (via gcpu)
  and &quot;hashimoto&quot; (via cqdma)

```
python mtk.py dumpbrom --ptype=[&quot;amonet&quot;,&quot;kamakiri&quot;,&quot;hashimoto&quot;] [--filename=brom.bin]
```

For to dump unknown bootroms, use brute option :
```
python mtk.py brute
```
If it&#039;s successful, please add an issue over here and append the bootrom in order to add full support.

---------------------------------------------------------------------------------------------------------------

### Crash da in order to enter brom

```
python mtk.py crash [--vid=vid] [--pid=pid] [--interface=interface]
```

### Read memory using patched preloader
- Boot in Brom or crash to Brom
```
python mtk.py peek [addr] [length] --preloader=patched_preloader.bin
```

### Run custom payload

```
python mtk.py payload --payload=payload.bin [--var1=var1] [--wdt=wdt] [--uartaddr=addr] [--da_addr=addr] [--brom_addr=addr]
```

---------------------------------------------------------------------------------------------------------------
## Stage2 usage
### Run python mtk.py stage (brom) or mtk plstage (preloader)

#### Run stage2 in bootrom
``
python mtk.py stage
``

#### Run stage2 in preloader
``
python mtk.py plstage
``

#### Run stage2 plstage in bootrom
- Boot in Brom or crash to Brom
```
python mtk.py plstage --preloader=preloader.bin
```

### Use stage2 tool


### Leave stage2 and reboot
``
python stage2.py reboot
``

### Read rpmb in stage2 mode
``
python stage2.py rpmb
``

### Read preloader in stage2 mode
``
python stage2.py preloader
``

### Read memory as hex data in stage2 mode
``
python stage2.py memread [start addr] [length]
``

### Read memory to file in stage2 mode
``
python stage2.py memread [start addr] [length] --filename filename.bin
``

### Write hex data to memory in stage2 mode
``
python stage2.py memwrite [start addr] --data [data as hexstring]
``

### Write memory from file in stage2 mode
``
python stage2.py memwrite [start addr] --filename filename.bin
``

### Extract keys
``
python stage2.py keys --mode [sej, dxcc]
``
For dxcc, you need to use plstage instead of stage

---------------------------------------------------------------------

### I have issues ....... please send logs and full console details !

- Run the mtk tool with --debugmode. Log will be written to log.txt (hopefully)

## Rules / Infos

### Chip details / configs
- Go to config/brom_config.py
- Unknown usb vid/pids for autodetection go to config/usb_ids.py
# [LEARNING_RESOURCES](https://github.com/bkerler/mtkclient/blob/main/learning_resources.md)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>