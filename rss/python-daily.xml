<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Wed, 16 Apr 2025 00:04:57 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[virattt/ai-hedge-fund]]></title>
            <link>https://github.com/virattt/ai-hedge-fund</link>
            <guid>https://github.com/virattt/ai-hedge-fund</guid>
            <pubDate>Wed, 16 Apr 2025 00:04:57 GMT</pubDate>
            <description><![CDATA[An AI Hedge Fund Team]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/virattt/ai-hedge-fund">virattt/ai-hedge-fund</a></h1>
            <p>An AI Hedge Fund Team</p>
            <p>Language: Python</p>
            <p>Stars: 22,711</p>
            <p>Forks: 4,027</p>
            <p>Stars today: 636 stars today</p>
            <h2>README</h2><pre># AI Hedge Fund

This is a proof of concept for an AI-powered hedge fund.  The goal of this project is to explore the use of AI to make trading decisions.  This project is for **educational** purposes only and is not intended for real trading or investment.

This system employs several agents working together:

1. Ben Graham Agent - The godfather of value investing, only buys hidden gems with a margin of safety
2. Bill Ackman Agent - An activist investors, takes bold positions and pushes for change
3. Cathie Wood Agent - The queen of growth investing, believes in the power of innovation and disruption
4. Charlie Munger Agent - Warren Buffett&#039;s partner, only buys wonderful businesses at fair prices
5. Michael Burry Agent - The Big Short contrarian who hunts for deep value
6. Peter Lynch Agent - Practical investor who seeks &quot;ten-baggers&quot; in everyday businesses
7. Phil Fisher Agent - Meticulous growth investor who uses deep &quot;scuttlebutt&quot; research 
8. Stanley Druckenmiller Agent - Macro legend who hunts for asymmetric opportunities with growth potential
9. Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price
10. Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals
11. Sentiment Agent - Analyzes market sentiment and generates trading signals
12. Fundamentals Agent - Analyzes fundamental data and generates trading signals
13. Technicals Agent - Analyzes technical indicators and generates trading signals
14. Risk Manager - Calculates risk metrics and sets position limits
15. Portfolio Manager - Makes final trading decisions and generates orders
    
&lt;img width=&quot;1042&quot; alt=&quot;Screenshot 2025-03-22 at 6 19 07â€¯PM&quot; src=&quot;https://github.com/user-attachments/assets/cbae3dcf-b571-490d-b0ad-3f0f035ac0d4&quot; /&gt;


**Note**: the system simulates trading decisions, it does not actually trade.

[![Twitter Follow](https://img.shields.io/twitter/follow/virattt?style=social)](https://twitter.com/virattt)

## Disclaimer

This project is for **educational and research purposes only**.

- Not intended for real trading or investment
- No warranties or guarantees provided
- Past performance does not indicate future results
- Creator assumes no liability for financial losses
- Consult a financial advisor for investment decisions

By using this software, you agree to use it solely for learning purposes.

## Table of Contents
- [Setup](#setup)
- [Usage](#usage)
  - [Running the Hedge Fund](#running-the-hedge-fund)
  - [Running the Backtester](#running-the-backtester)
- [Project Structure](#project-structure)
- [Contributing](#contributing)
- [Feature Requests](#feature-requests)
- [License](#license)

## Setup

Clone the repository:
```bash
git clone https://github.com/virattt/ai-hedge-fund.git
cd ai-hedge-fund
```

1. Install Poetry (if not already installed):
```bash
curl -sSL https://install.python-poetry.org | python3 -
```

2. Install dependencies:
```bash
poetry install
```

3. Set up your environment variables:
```bash
# Create .env file for your API keys
cp .env.example .env
```

4. Set your API keys:
```bash
# For running LLMs hosted by openai (gpt-4o, gpt-4o-mini, etc.)
# Get your OpenAI API key from https://platform.openai.com/
OPENAI_API_KEY=your-openai-api-key

# For running LLMs hosted by groq (deepseek, llama3, etc.)
# Get your Groq API key from https://groq.com/
GROQ_API_KEY=your-groq-api-key

# For getting financial data to power the hedge fund
# Get your Financial Datasets API key from https://financialdatasets.ai/
FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key
```

**Important**: You must set `OPENAI_API_KEY`, `GROQ_API_KEY`, `ANTHROPIC_API_KEY`, or `DEEPSEEK_API_KEY` for the hedge fund to work.  If you want to use LLMs from all providers, you will need to set all API keys.

Financial data for AAPL, GOOGL, MSFT, NVDA, and TSLA is free and does not require an API key.

For any other ticker, you will need to set the `FINANCIAL_DATASETS_API_KEY` in the .env file.

## Usage

### Running the Hedge Fund
```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA
```

**Example Output:**
&lt;img width=&quot;992&quot; alt=&quot;Screenshot 2025-01-06 at 5 50 17â€¯PM&quot; src=&quot;https://github.com/user-attachments/assets/e8ca04bf-9989-4a7d-a8b4-34e04666663b&quot; /&gt;

You can also specify a `--ollama` flag to run the AI hedge fund using local LLMs.

```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --ollama
```

You can also specify a `--show-reasoning` flag to print the reasoning of each agent to the console.

```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --show-reasoning
```
You can optionally specify the start and end dates to make decisions for a specific time period.

```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 
```

### Running the Backtester

```bash
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA
```

**Example Output:**
&lt;img width=&quot;941&quot; alt=&quot;Screenshot 2025-01-06 at 5 47 52â€¯PM&quot; src=&quot;https://github.com/user-attachments/assets/00e794ea-8628-44e6-9a84-8f8a31ad3b47&quot; /&gt;


You can optionally specify the start and end dates to backtest over a specific time period.

```bash
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01
```

You can also specify a `--ollama` flag to run the backtester using local LLMs.
```bash
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA --ollama
```


## Project Structure 
```
ai-hedge-fund/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                   # Agent definitions and workflow
â”‚   â”‚   â”œâ”€â”€ bill_ackman.py        # Bill Ackman agent
â”‚   â”‚   â”œâ”€â”€ fundamentals.py       # Fundamental analysis agent
â”‚   â”‚   â”œâ”€â”€ portfolio_manager.py  # Portfolio management agent
â”‚   â”‚   â”œâ”€â”€ risk_manager.py       # Risk management agent
â”‚   â”‚   â”œâ”€â”€ sentiment.py          # Sentiment analysis agent
â”‚   â”‚   â”œâ”€â”€ technicals.py         # Technical analysis agent
â”‚   â”‚   â”œâ”€â”€ valuation.py          # Valuation analysis agent
â”‚   â”‚   â”œâ”€â”€ warren_buffett.py     # Warren Buffett agent
â”‚   â”œâ”€â”€ tools/                    # Agent tools
â”‚   â”‚   â”œâ”€â”€ api.py                # API tools
â”‚   â”œâ”€â”€ backtester.py             # Backtesting tools
â”‚   â”œâ”€â”€ main.py # Main entry point
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ ...
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

**Important**: Please keep your pull requests small and focused.  This will make it easier to review and merge.

## Feature Requests

If you have a feature request, please open an [issue](https://github.com/virattt/ai-hedge-fund/issues) and make sure it is tagged with `enhancement`.

## License

This project is licensed under the MIT License - see the LICENSE file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[vanna-ai/vanna]]></title>
            <link>https://github.com/vanna-ai/vanna</link>
            <guid>https://github.com/vanna-ai/vanna</guid>
            <pubDate>Wed, 16 Apr 2025 00:04:56 GMT</pubDate>
            <description><![CDATA[ğŸ¤– Chat with your SQL database ğŸ“Š. Accurate Text-to-SQL Generation via LLMs using RAG ğŸ”„.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vanna-ai/vanna">vanna-ai/vanna</a></h1>
            <p>ğŸ¤– Chat with your SQL database ğŸ“Š. Accurate Text-to-SQL Generation via LLMs using RAG ğŸ”„.</p>
            <p>Language: Python</p>
            <p>Stars: 15,556</p>
            <p>Forks: 1,402</p>
            <p>Stars today: 154 stars today</p>
            <h2>README</h2><pre>

| GitHub | PyPI | Documentation | Gurubase |
| ------ | ---- | ------------- | -------- |
| [![GitHub](https://img.shields.io/badge/GitHub-vanna-blue?logo=github)](https://github.com/vanna-ai/vanna) | [![PyPI](https://img.shields.io/pypi/v/vanna?logo=pypi)](https://pypi.org/project/vanna/) | [![Documentation](https://img.shields.io/badge/Documentation-vanna-blue?logo=read-the-docs)](https://vanna.ai/docs/) | [![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Vanna%20Guru-006BFF)](https://gurubase.io/g/vanna) |

# Vanna
Vanna is an MIT-licensed open-source Python RAG (Retrieval-Augmented Generation) framework for SQL generation and related functionality.

https://github.com/vanna-ai/vanna/assets/7146154/1901f47a-515d-4982-af50-f12761a3b2ce

![vanna-quadrants](https://github.com/vanna-ai/vanna/assets/7146154/1c7c88ba-c144-4ecf-a028-cf5ba7344ca2)

## How Vanna works

![Screen Recording 2024-01-24 at 11 21 37â€¯AM](https://github.com/vanna-ai/vanna/assets/7146154/1d2718ad-12a8-4a76-afa2-c61754462f93)


Vanna works in two easy steps - train a RAG &quot;model&quot; on your data, and then ask questions which will return SQL queries that can be set up to automatically run on your database.

1. **Train a RAG &quot;model&quot; on your data**.
2. **Ask questions**.

![](img/vanna-readme-diagram.png)

If you don&#039;t know what RAG is, don&#039;t worry -- you don&#039;t need to know how this works under the hood to use it. You just need to know that you &quot;train&quot; a model, which stores some metadata and then use it to &quot;ask&quot; questions.

See the [base class](https://github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py) for more details on how this works under the hood.

## User Interfaces
These are some of the user interfaces that we&#039;ve built using Vanna. You can use these as-is or as a starting point for your own custom interface.

- [Jupyter Notebook](https://vanna.ai/docs/postgres-openai-vanna-vannadb/)
- [vanna-ai/vanna-streamlit](https://github.com/vanna-ai/vanna-streamlit)
- [vanna-ai/vanna-flask](https://github.com/vanna-ai/vanna-flask)
- [vanna-ai/vanna-slack](https://github.com/vanna-ai/vanna-slack)

## Supported LLMs

- [OpenAI](https://github.com/vanna-ai/vanna/tree/main/src/vanna/openai)
- [Anthropic](https://github.com/vanna-ai/vanna/tree/main/src/vanna/anthropic)
- [Gemini](https://github.com/vanna-ai/vanna/blob/main/src/vanna/google/gemini_chat.py)
- [HuggingFace](https://github.com/vanna-ai/vanna/blob/main/src/vanna/hf/hf.py)
- [AWS Bedrock](https://github.com/vanna-ai/vanna/tree/main/src/vanna/bedrock)
- [Ollama](https://github.com/vanna-ai/vanna/tree/main/src/vanna/ollama)
- [Qianwen](https://github.com/vanna-ai/vanna/tree/main/src/vanna/qianwen)
- [Qianfan](https://github.com/vanna-ai/vanna/tree/main/src/vanna/qianfan)
- [Zhipu](https://github.com/vanna-ai/vanna/tree/main/src/vanna/ZhipuAI)

## Supported VectorStores

- [AzureSearch](https://github.com/vanna-ai/vanna/tree/main/src/vanna/azuresearch)
- [Opensearch](https://github.com/vanna-ai/vanna/tree/main/src/vanna/opensearch)
- [PgVector](https://github.com/vanna-ai/vanna/tree/main/src/vanna/pgvector)
- [PineCone](https://github.com/vanna-ai/vanna/tree/main/src/vanna/pinecone)
- [ChromaDB](https://github.com/vanna-ai/vanna/tree/main/src/vanna/chromadb)
- [FAISS](https://github.com/vanna-ai/vanna/tree/main/src/vanna/faiss)
- [Marqo](https://github.com/vanna-ai/vanna/tree/main/src/vanna/marqo)
- [Milvus](https://github.com/vanna-ai/vanna/tree/main/src/vanna/milvus)
- [Qdrant](https://github.com/vanna-ai/vanna/tree/main/src/vanna/qdrant)
- [Weaviate](https://github.com/vanna-ai/vanna/tree/main/src/vanna/weaviate)
- [Oracle](https://github.com/vanna-ai/vanna/tree/main/src/vanna/oracle)

## Supported Databases

- [PostgreSQL](https://www.postgresql.org/)
- [MySQL](https://www.mysql.com/)
- [PrestoDB](https://prestodb.io/)
- [Apache Hive](https://hive.apache.org/)
- [ClickHouse](https://clickhouse.com/)
- [Snowflake](https://www.snowflake.com/en/)
- [Oracle](https://www.oracle.com/)
- [Microsoft SQL Server](https://www.microsoft.com/en-us/sql-server/sql-server-downloads)
- [BigQuery](https://cloud.google.com/bigquery)
- [SQLite](https://www.sqlite.org/)
- [DuckDB](https://duckdb.org/)


## Getting started
See the [documentation](https://vanna.ai/docs/) for specifics on your desired database, LLM, etc.

If you want to get a feel for how it works after training, you can try this [Colab notebook](https://vanna.ai/docs/app/).


### Install
```bash
pip install vanna
```

There are a number of optional packages that can be installed so see the [documentation](https://vanna.ai/docs/) for more details.

### Import
See the [documentation](https://vanna.ai/docs/) if you&#039;re customizing the LLM or vector database.

```python
# The import statement will vary depending on your LLM and vector database. This is an example for OpenAI + ChromaDB

from vanna.openai.openai_chat import OpenAI_Chat
from vanna.chromadb.chromadb_vector import ChromaDB_VectorStore

class MyVanna(ChromaDB_VectorStore, OpenAI_Chat):
    def __init__(self, config=None):
        ChromaDB_VectorStore.__init__(self, config=config)
        OpenAI_Chat.__init__(self, config=config)

vn = MyVanna(config={&#039;api_key&#039;: &#039;sk-...&#039;, &#039;model&#039;: &#039;gpt-4-...&#039;})

# See the documentation for other options

```


## Training
You may or may not need to run these `vn.train` commands depending on your use case. See the [documentation](https://vanna.ai/docs/) for more details.

These statements are shown to give you a feel for how it works.

### Train with DDL Statements
DDL statements contain information about the table names, columns, data types, and relationships in your database.

```python
vn.train(ddl=&quot;&quot;&quot;
    CREATE TABLE IF NOT EXISTS my-table (
        id INT PRIMARY KEY,
        name VARCHAR(100),
        age INT
    )
&quot;&quot;&quot;)
```

### Train with Documentation
Sometimes you may want to add documentation about your business terminology or definitions.

```python
vn.train(documentation=&quot;Our business defines XYZ as ...&quot;)
```

### Train with SQL
You can also add SQL queries to your training data. This is useful if you have some queries already laying around. You can just copy and paste those from your editor to begin generating new SQL.

```python
vn.train(sql=&quot;SELECT name, age FROM my-table WHERE name = &#039;John Doe&#039;&quot;)
```


## Asking questions
```python
vn.ask(&quot;What are the top 10 customers by sales?&quot;)
```

You&#039;ll get SQL
```sql
SELECT c.c_name as customer_name,
        sum(l.l_extendedprice * (1 - l.l_discount)) as total_sales
FROM   snowflake_sample_data.tpch_sf1.lineitem l join snowflake_sample_data.tpch_sf1.orders o
        ON l.l_orderkey = o.o_orderkey join snowflake_sample_data.tpch_sf1.customer c
        ON o.o_custkey = c.c_custkey
GROUP BY customer_name
ORDER BY total_sales desc limit 10;
```

If you&#039;ve connected to a database, you&#039;ll get the table:
&lt;div&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;CUSTOMER_NAME&lt;/th&gt;
      &lt;th&gt;TOTAL_SALES&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Customer#000143500&lt;/td&gt;
      &lt;td&gt;6757566.0218&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Customer#000095257&lt;/td&gt;
      &lt;td&gt;6294115.3340&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Customer#000087115&lt;/td&gt;
      &lt;td&gt;6184649.5176&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Customer#000131113&lt;/td&gt;
      &lt;td&gt;6080943.8305&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;Customer#000134380&lt;/td&gt;
      &lt;td&gt;6075141.9635&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;Customer#000103834&lt;/td&gt;
      &lt;td&gt;6059770.3232&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;Customer#000069682&lt;/td&gt;
      &lt;td&gt;6057779.0348&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;Customer#000102022&lt;/td&gt;
      &lt;td&gt;6039653.6335&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;td&gt;Customer#000098587&lt;/td&gt;
      &lt;td&gt;6027021.5855&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;9&lt;/th&gt;
      &lt;td&gt;Customer#000064660&lt;/td&gt;
      &lt;td&gt;5905659.6159&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

You&#039;ll also get an automated Plotly chart:
![](img/top-10-customers.png)

## RAG vs. Fine-Tuning
RAG
- Portable across LLMs
- Easy to remove training data if any of it becomes obsolete
- Much cheaper to run than fine-tuning
- More future-proof -- if a better LLM comes out, you can just swap it out

Fine-Tuning
- Good if you need to minimize tokens in the prompt
- Slow to get started
- Expensive to train and run (generally)

## Why Vanna?

1. **High accuracy on complex datasets.**
    - Vannaâ€™s capabilities are tied to the training data you give it
    - More training data means better accuracy for large and complex datasets
2. **Secure and private.**
    - Your database contents are never sent to the LLM or the vector database
    - SQL execution happens in your local environment
3. **Self learning.**
    - If using via Jupyter, you can choose to &quot;auto-train&quot; it on the queries that were successfully executed
    - If using via other interfaces, you can have the interface prompt the user to provide feedback on the results
    - Correct question to SQL pairs are stored for future reference and make the future results more accurate
4. **Supports any SQL database.**
    - The package allows you to connect to any SQL database that you can otherwise connect to with Python
5. **Choose your front end.**
    - Most people start in a Jupyter Notebook.
    - Expose to your end users via Slackbot, web app, Streamlit app, or a custom front end.

## Extending Vanna
Vanna is designed to connect to any database, LLM, and vector database. There&#039;s a [VannaBase](https://github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py) abstract base class that defines some basic functionality. The package provides implementations for use with OpenAI and ChromaDB. You can easily extend Vanna to use your own LLM or vector database. See the [documentation](https://vanna.ai/docs/) for more details.

## Vanna in 100 Seconds

https://github.com/vanna-ai/vanna/assets/7146154/eb90ee1e-aa05-4740-891a-4fc10e611cab

## More resources
 - [Full Documentation](https://vanna.ai/docs/)
 - [Website](https://vanna.ai)
 - [Discord group for support](https://discord.gg/qUZYKHremx)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[yeongpin/cursor-free-vip]]></title>
            <link>https://github.com/yeongpin/cursor-free-vip</link>
            <guid>https://github.com/yeongpin/cursor-free-vip</guid>
            <pubDate>Wed, 16 Apr 2025 00:04:55 GMT</pubDate>
            <description><![CDATA[[Support 0.48.x]ï¼ˆReset Cursor AI MachineID & Auto Sign Up / In & Bypass Higher Token Limitï¼‰è‡ªåŠ¨æ³¨å†Œ Cursor Ai ï¼Œè‡ªåŠ¨é‡ç½®æœºå™¨ID ï¼Œ å…è´¹å‡çº§ä½¿ç”¨ProåŠŸèƒ½: You've reached your trial request limit. / Too many free trial accounts used on this machine. Please upgrade to pro. We have this limit in place to prevent abuse. Please let us know if you believe this is a mistake.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/yeongpin/cursor-free-vip">yeongpin/cursor-free-vip</a></h1>
            <p>[Support 0.48.x]ï¼ˆReset Cursor AI MachineID & Auto Sign Up / In & Bypass Higher Token Limitï¼‰è‡ªåŠ¨æ³¨å†Œ Cursor Ai ï¼Œè‡ªåŠ¨é‡ç½®æœºå™¨ID ï¼Œ å…è´¹å‡çº§ä½¿ç”¨ProåŠŸèƒ½: You've reached your trial request limit. / Too many free trial accounts used on this machine. Please upgrade to pro. We have this limit in place to prevent abuse. Please let us know if you believe this is a mistake.</p>
            <p>Language: Python</p>
            <p>Stars: 17,087</p>
            <p>Forks: 2,016</p>
            <p>Stars today: 2,208 stars today</p>
            <h2>README</h2><pre># â¤ Cursor Free VIP

&lt;div align=&quot;center&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/logo.png&quot; alt=&quot;Cursor Pro Logo&quot; width=&quot;200&quot; style=&quot;border-radius: 6px;&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;

[![Release](https://img.shields.io/endpoint?url=https://www.pinnumber.rr.nu/badges/release/yeongpin/cursor-free-vip)](https://github.com/yeongpin/cursor-free-vip/releases/latest)
[![License: CC BY-NC-ND 4.0](https://img.shields.io/badge/License-CC_BY--NC--ND_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-nd/4.0/)
[![Stars](https://img.shields.io/endpoint?url=https://www.pinnumber.rr.nu/badges/stars/yeongpin/cursor-free-vip)](https://github.com/yeongpin/cursor-free-vip/stargazers)
[![Downloads](https://img.shields.io/endpoint?url=https://www.pinnumber.rr.nu/badges/downloads/yeongpin/cursor-free-vip/total)](https://github.com/yeongpin/cursor-free-vip/releases/latest)
&lt;a href=&quot;https://buymeacoffee.com/yeongpin&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Buy Me a Coffee&quot; src=&quot;https://img.shields.io/badge/Buy%20Me%20a%20Coffee-Support%20Me-FFDA33&quot;&gt;&lt;/a&gt;

&lt;/p&gt;

&lt;a href=&quot;https://trendshift.io/repositories/13425&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13425&quot; alt=&quot;yeongpin%2Fcursor-free-vip | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;br&gt;
&lt;a href=&quot;https://www.buymeacoffee.com/yeongpin&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://img.buymeacoffee.com/button-api/?text=buy me a coffee&amp;emoji=â˜•&amp;slug=yeongpin&amp;button_colour=ffda33&amp;font_colour=000000&amp;font_family=Bree&amp;outline_colour=000000&amp;coffee_colour=FFDD00&amp;latest=2&quot; width=&quot;160&quot; height=&#039;55&#039; alt=&quot;Buy Me a Coffee&quot;/&gt;
&lt;/a&gt;


&lt;h4&gt;Support Latest 0.48.x Version | æ”¯æŒæœ€æ–° 0.48.x ç‰ˆæœ¬&lt;/h4&gt;

This tool registers accounts with custom emails, support Google and GitHub account registrations, temporary GitHub account registration, kills all Cursor&#039;s running processes, resets and wipes Cursor data and hardware info.

Supports Windows, macOS and Linux.

For optimal performance, run with privileges and always stay up to date.

Always clean your browser&#039;s cache and cookies. If possible, use a VPN to create new accounts.


é€™æ˜¯ä¸€å€‹è‡ªå‹•åŒ–å·¥å…·ï¼Œè‡ªå‹•è¨»å†Šï¼Œæ”¯æŒ Windows macOS å’Œ Linux ç³»çµ±ï¼Œå®Œæˆ Auth é©—è­‰ï¼Œé‡ç½® Cursor çš„é…ç½®ã€‚

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pro_2025-04-05_18-47-56.png&quot; alt=&quot;new&quot; width=&quot;800&quot; style=&quot;border-radius: 6px;&quot;/&gt;&lt;br&gt;
&lt;/p&gt;

##### If you don&#039;t have browser, you can download it from  

##### å¦‚æœæ²’æœ‰ç€è¦½å™¨ï¼Œå¯ä»¥å¾è¿™é‡Œä¸‹è¼‰  

[Google Chrome](https://www.google.com/intl/en_pk/chrome/) | [Opera](https://www.opera.com/download) | [Edge](https://www.microsoft.com/en-us/edge) | [Firefox](https://www.mozilla.org/en-US/firefox/new/) | [Brave](https://www.brave.com/download/)

&lt;/div&gt;

## ğŸ”„ Change Log | æ›´æ–°æ—¥å¿—

[Watch Change Log | æŸ¥çœ‹æ›´æ–°æ—¥å¿—](CHANGELOG.md)

## âœ¨ Features | åŠŸèƒ½ç‰¹é»

* ğŸŒŸ Google OAuth Authentication with Lifetime Access&lt;br&gt;ä½¿ç”¨ Google OAuth èªè­‰ï¼ˆçµ‚èº«è¨ªå•ï¼‰&lt;br&gt;

* â­ GitHub OAuth Authentication with Lifetime Access&lt;br&gt;ä½¿ç”¨ GitHub OAuth èªè­‰ï¼ˆçµ‚èº«è¨ªå•ï¼‰&lt;br&gt;

* Automatically register Cursor membership&lt;br&gt;è‡ªå‹•è¨»å†Š Cursor æœƒå“¡&lt;br&gt;

* Support Windows macOS and Linux systems&lt;br&gt;æ”¯æŒ Windowsã€macOS å’Œ Linux ç³»çµ±&lt;br&gt;

* Complete Auth verification&lt;br&gt;å®Œæˆ Auth é©—è­‰&lt;br&gt;

* Reset Cursor&#039;s configuration&lt;br&gt;é‡ç½® Cursor çš„é…ç½®&lt;br&gt;

* Delete Cursor Google Account&lt;br&gt;åˆ é™¤ Cursor Google è´¦å·&lt;br&gt;

* Multi-language support (English, ç®€ä½“ä¸­æ–‡, ç¹é«”ä¸­æ–‡, Vietnamese)&lt;br&gt;å¤šèªè¨€æ”¯æŒï¼ˆè‹±æ–‡ã€ç®€ä½“ä¸­æ–‡ã€ç¹é«”ä¸­æ–‡ã€è¶Šå—èªï¼‰&lt;br&gt;

## ğŸ’» System Support | ç³»çµ±æ”¯æŒ

| Operating System | Architecture      | Supported |
|------------------|-------------------|-----------|
| Windows          | x64, x86          | âœ…         |
| macOS            | Intel, Apple Silicon | âœ…      |
| Linux            | x64, x86, ARM64   | âœ…         |

## ğŸ‘€ How to use | å¦‚ä½•ä½¿ç”¨

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;â­ Auto Run Script | è…³æœ¬è‡ªå‹•åŒ–é‹è¡Œ&lt;/b&gt;&lt;/summary&gt;

### **Linux/macOS**

```bash
curl -fsSL https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.sh -o install.sh &amp;&amp; chmod +x install.sh &amp;&amp; ./install.sh
```

### **Archlinux**

Install via [AUR](https://aur.archlinux.org/packages/cursor-free-vip-git)

```bash
yay -S cursor-free-vip-git
```

### **Windows**

```powershell
irm https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.ps1 | iex
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;â­ Manual Reset Machine | æ‰‹å‹•é‹è¡Œé‡ç½®æ©Ÿå™¨&lt;/b&gt;&lt;/summary&gt;

### **Linux/macOS**

```bash
curl -fsSL https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/reset.sh | sudo bash
```

### **Windows**

```powershell
irm https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/reset.ps1 | iex
```

&lt;/details&gt;

If you want to stop the script, please press Ctrl+C&lt;br&gt;è¦åœæ­¢è…³æœ¬ï¼Œè«‹æŒ‰ Ctrl+C

## â— Note | æ³¨æ„äº‹é …

ğŸ“ Config | æ–‡ä»¶é…ç½®
`Win / Macos / Linux Path | è·¯å¾‘ [Documents/.cursor-free-vip/config.ini]`
&lt;details&gt;
&lt;summary&gt;&lt;b&gt;â­ Config | æ–‡ä»¶é…ç½®&lt;/b&gt;&lt;/summary&gt;

```
[Chrome]
# Default Google Chrome Path | é»˜èªGoogle Chrome éŠè¦½å™¨è·¯å¾‘
chromepath = C:\Program Files\Google/Chrome/Application/chrome.exe

[Turnstile]
# Handle Turnstile Wait Time | ç­‰å¾…äººæ©Ÿé©—è­‰æ™‚é–“
handle_turnstile_time = 2
# Handle Turnstile Wait Random Time (must merge 1-3 or 1,3) | ç­‰å¾…äººæ©Ÿé©—è­‰éš¨æ©Ÿæ™‚é–“ï¼ˆå¿…é ˆæ˜¯ 1-3 æˆ–è€… 1,3 é€™æ¨£çš„çµ„åˆï¼‰
handle_turnstile_random_time = 1-3

[OSPaths]
# Storage Path | å­˜å„²è·¯å¾‘
storage_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/storage.json
# SQLite Path | SQLiteè·¯å¾‘
sqlite_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/state.vscdb
# Machine ID Path | æ©Ÿå™¨IDè·¯å¾‘
machine_id_path = /Users/username/Library/Application Support/Cursor/machineId
# For Linux users: ~/.config/cursor/machineid

[Timing]
# Min Random Time | æœ€å°éš¨æ©Ÿæ™‚é–“
min_random_time = 0.1
# Max Random Time | æœ€å¤§éš¨æ©Ÿæ™‚é–“
max_random_time = 0.8
# Page Load Wait | é é¢åŠ è¼‰ç­‰å¾…æ™‚é–“
page_load_wait = 0.1-0.8
# Input Wait | è¼¸å…¥ç­‰å¾…æ™‚é–“
input_wait = 0.3-0.8
# Submit Wait | æäº¤ç­‰å¾…æ™‚é–“
submit_wait = 0.5-1.5
# Verification Code Input | é©—è­‰ç¢¼è¼¸å…¥ç­‰å¾…æ™‚é–“
verification_code_input = 0.1-0.3
# Verification Success Wait | é©—è­‰æˆåŠŸç­‰å¾…æ™‚é–“
verification_success_wait = 2-3
# Verification Retry Wait | é©—è­‰é‡è©¦ç­‰å¾…æ™‚é–“
verification_retry_wait = 2-3
# Email Check Initial Wait | éƒµä»¶æª¢æŸ¥åˆå§‹ç­‰å¾…æ™‚é–“
email_check_initial_wait = 4-6
# Email Refresh Wait | éƒµä»¶åˆ·æ–°ç­‰å¾…æ™‚é–“
email_refresh_wait = 2-4
# Settings Page Load Wait | è¨­ç½®é é¢åŠ è¼‰ç­‰å¾…æ™‚é–“
settings_page_load_wait = 1-2
# Failed Retry Time | å¤±æ•—é‡è©¦æ™‚é–“
failed_retry_time = 0.5-1
# Retry Interval | é‡è©¦é–“éš”
retry_interval = 8-12
# Max Timeout | æœ€å¤§è¶…æ™‚æ™‚é–“
max_timeout = 160

[Utils]
# Check Update | æª¢æŸ¥æ›´æ–°
check_update = True
# Show Account Info | é¡¯ç¤ºè³¬è™Ÿä¿¡æ¯
show_account_info = True

[WindowsPaths]
storage_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\storage.json
sqlite_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\state.vscdb
machine_id_path = C:\Users\yeongpin\AppData\Roaming\Cursor\machineId
cursor_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app
updater_path = C:\Users\yeongpin\AppData\Local\cursor-updater
update_yml_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app-update.yml
product_json_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app\product.json

[Browser]
default_browser = opera
chrome_path = C:\Program Files\Google\Chrome\Application\chrome.exe
edge_path = C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe
firefox_path = C:\Program Files\Mozilla Firefox\firefox.exe
brave_path = C:\Program Files\BraveSoftware/Brave-Browser/Application/brave.exe
chrome_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe
edge_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\msedgedriver.exe
firefox_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\geckodriver.exe
brave_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe
opera_path = C:\Users\yeongpin\AppData\Local\Programs\Opera\opera.exe
opera_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe

[OAuth]
show_selection_alert = False
timeout = 120
max_attempts = 3
```

&lt;/details&gt;

* Use administrator privileges to run the script &lt;br&gt;è«‹ä½¿ç”¨ç®¡ç†å“¡èº«ä»½é‹è¡Œè…³æœ¬

* Confirm that Cursor is closed before running the script &lt;br&gt;è«‹ç¢ºä¿åœ¨é‹è¡Œè…³æœ¬å‰å·²ç¶“é—œé–‰ Cursor&lt;br&gt;

* This tool is only for learning and research purposes &lt;br&gt;æ­¤å·¥å…·åƒ…ä¾›å­¸ç¿’å’Œç ”ç©¶ä½¿ç”¨&lt;br&gt;

* Please comply with the relevant software usage terms when using this tool &lt;br&gt;ä½¿ç”¨æœ¬å·¥å…·æ™‚è«‹éµå®ˆç›¸é—œè»Ÿä»¶ä½¿ç”¨æ¢æ¬¾

## ğŸš¨ Common Issues | å¸¸è¦‹å•é¡Œ

|                   å¦‚æœé‡åˆ°æ¬Šé™å•é¡Œï¼Œè«‹ç¢ºä¿ï¼š                    |                   æ­¤è…³æœ¬ä»¥ç®¡ç†å“¡èº«ä»½é‹è¡Œ                    |
|:--------------------------------------------------:|:------------------------------------------------:|
| If you encounter permission issues, please ensure: | This script is run with administrator privileges |
| Error &#039;User is not authorized&#039; | This means your account was banned for using temporary (disposal) mail. Ensure using a non-temporary mail service |
## ğŸ¤© Contribution | è²¢ç»

æ­¡è¿æäº¤ Issue å’Œ Pull Requestï¼


&lt;a href=&quot;https://github.com/yeongpin/cursor-free-vip/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=yeongpin/cursor-free-vip&amp;preview=true&amp;max=&amp;columns=&quot; /&gt;
&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;

## ğŸ“© Disclaimer | å…è²¬è²æ˜

æœ¬å·¥å…·åƒ…ä¾›å­¸ç¿’å’Œç ”ç©¶ä½¿ç”¨ï¼Œä½¿ç”¨æœ¬å·¥å…·æ‰€ç”¢ç”Ÿçš„ä»»ä½•å¾Œæœç”±ä½¿ç”¨è€…è‡ªè¡Œæ‰¿æ“”ã€‚ &lt;br&gt;

This tool is only for learning and research purposes, and any consequences arising from the use of this tool are borne
by the user.

## ğŸ’° Buy Me a Coffee | è«‹æˆ‘å–æ¯å’–å•¡

&lt;div align=&quot;center&quot;&gt;
  &lt;table&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;img src=&quot;./images/provi-code.jpg&quot; alt=&quot;buy_me_a_coffee&quot; width=&quot;280&quot;/&gt;&lt;br&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;img src=&quot;./images/paypal.png&quot; alt=&quot;buy_me_a_coffee&quot; width=&quot;280&quot;/&gt;&lt;br&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

## â­ Star History | æ˜Ÿæ˜Ÿæ•¸

&lt;div align=&quot;center&quot;&gt;

[![Star History Chart](https://api.star-history.com/svg?repos=yeongpin/cursor-free-vip&amp;type=Date)](https://star-history.com/#yeongpin/cursor-free-vip&amp;Date)

&lt;/div&gt;

## ğŸ“ License | æˆæ¬Š

æœ¬é …ç›®æ¡ç”¨ [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/) æˆæ¬Šã€‚
Please refer to the [LICENSE](LICENSE.md) file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[nautechsystems/nautilus_trader]]></title>
            <link>https://github.com/nautechsystems/nautilus_trader</link>
            <guid>https://github.com/nautechsystems/nautilus_trader</guid>
            <pubDate>Wed, 16 Apr 2025 00:04:54 GMT</pubDate>
            <description><![CDATA[A high-performance algorithmic trading platform and event-driven backtester]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nautechsystems/nautilus_trader">nautechsystems/nautilus_trader</a></h1>
            <p>A high-performance algorithmic trading platform and event-driven backtester</p>
            <p>Language: Python</p>
            <p>Stars: 5,359</p>
            <p>Forks: 782</p>
            <p>Stars today: 86 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader-logo.png&quot; width=&quot;500&quot;&gt;

[![codecov](https://codecov.io/gh/nautechsystems/nautilus_trader/branch/master/graph/badge.svg?token=DXO9QQI40H)](https://codecov.io/gh/nautechsystems/nautilus_trader)
[![codspeed](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/nautechsystems/nautilus_trader)
![pythons](https://img.shields.io/pypi/pyversions/nautilus_trader)
![pypi-version](https://img.shields.io/pypi/v/nautilus_trader)
![pypi-format](https://img.shields.io/pypi/format/nautilus_trader?color=blue)
[![Downloads](https://pepy.tech/badge/nautilus-trader)](https://pepy.tech/project/nautilus-trader)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/NautilusTrader)

| Branch    | Version                                                                                                                                                                                                                     | Status                                                                                                                                                                                            |
| :-------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `master`  | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fmaster%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html)  | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)  |
| `nightly` | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fnightly%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html) | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |
| `develop` | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fdevelop%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html) | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=develop)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |

| Platform           | Rust    | Python     |
| :----------------- | :------ | :--------- |
| `Linux (x86_64)`   | 1.86.0+ | 3.11-3.13  |
| `Linux (ARM64)`    | 1.86.0+ | 3.11-3.13  |
| `macOS (ARM64)`    | 1.86.0+ | 3.11-3.13  |
| `Windows (x86_64)` | 1.86.0+ | 3.11-3.13  |

- **Docs**: https://nautilustrader.io/docs/
- **Website**: https://nautilustrader.io
- **Support**: [support@nautilustrader.io](mailto:support@nautilustrader.io)

## Introduction

NautilusTrader is an open-source, high-performance, production-grade algorithmic trading platform,
providing quantitative traders with the ability to backtest portfolios of automated trading strategies
on historical data with an event-driven engine, and also deploy those same strategies live, with no code changes.

The platform is *AI-first*, designed to develop and deploy algorithmic trading strategies within a highly performant
and robust Python-native environment. This helps to address the parity challenge of keeping the Python research/backtest
environment consistent with the production live trading environment.

NautilusTrader&#039;s design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting Python-native, mission-critical, trading system backtesting
and live deployment workloads.

The platform is also universal, and asset-class-agnostic â€”  with any REST API or WebSocket feed able to be integrated via modular
adapters. It supports high-frequency trading across a wide range of asset classes and instrument types
including FX, Equities, Futures, Options, Crypto and Betting, enabling seamless operations across multiple venues simultaneously.

![nautilus-trader](https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader.png &quot;nautilus-trader&quot;)

## Features

- **Fast**: Core is written in Rust with asynchronous networking using [tokio](https://crates.io/crates/tokio).
- **Reliable**: Type safety and thread safety through Rust. [Redis](https://redis.io)-backed performant state persistence (optional).
- **Portable**: OS independent, runs on Linux, macOS, and Windows. Deploy using Docker.
- **Flexible**: Modular adapters mean any REST API or WebSocket feed can be integrated.
- **Advanced**: Time in force `IOC`, `FOK`, `GTC`, `GTD`, `DAY`, `AT_THE_OPEN`, `AT_THE_CLOSE`, advanced order types and conditional triggers. Execution instructions `post-only`, `reduce-only`, and icebergs. Contingency orders including `OCO`, `OUO`, `OTO`.
- **Customizable**: Add user-defined custom components, or assemble entire systems from scratch leveraging the [cache](https://nautilustrader.io/docs/latest/concepts/cache) and [message bus](https://nautilustrader.io/docs/latest/concepts/message_bus).
- **Backtesting**: Run with multiple venues, instruments and strategies simultaneously using historical quote tick, trade tick, bar, order book and custom data with nanosecond resolution.
- **Live**: Use identical strategy implementations between backtesting and live deployments.
- **Multi-venue**: Multiple venue capabilities facilitate market-making and statistical arbitrage strategies.
- **AI Training**: Backtest engine fast enough to be used to train AI trading agents (RL/ES).

![Alt text](https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-art.png &quot;nautilus&quot;)

&gt; _nautilus - from ancient Greek &#039;sailor&#039; and naus &#039;ship&#039;._
&gt;
&gt; _The nautilus shell consists of modular chambers with a growth factor which approximates a logarithmic spiral.
&gt; The idea is that this can be translated to the aesthetics of design and architecture._

## Why NautilusTrader?

- **Highly performant event-driven Python**: Native binary core components.
- **Parity between backtesting and live trading**: Identical strategy code.
- **Reduced operational risk**: Enhanced risk management functionality, logical accuracy, and type safety.
- **Highly extendable**: Message bus, custom components and actors, custom data, custom adapters.

Traditionally, trading strategy research and backtesting might be conducted in Python
using vectorized methods, with the strategy then needing to be reimplemented in a more event-driven way
using C++, C#, Java or other statically typed language(s). The reasoning here is that vectorized backtesting code cannot
express the granular time and event dependent complexity of real-time trading, where compiled languages have
proven to be more suitable due to their inherently higher performance, and type safety.

One of the key advantages of NautilusTrader here, is that this reimplementation step is now circumvented - as the critical core components of the platform
have all been written entirely in [Rust](https://www.rust-lang.org/) or [Cython](https://cython.org/).
This means we&#039;re using the right tools for the job, where systems programming languages compile performant binaries,
with CPython C extension modules then able to offer a Python-native environment, suitable for professional quantitative traders and trading firms.

## Why Python?

Python was originally created decades ago as a simple scripting language with a clean straightforward syntax.
It has since evolved into a fully fledged general purpose object-oriented programming language.
Based on the TIOBE index, Python is currently the most popular programming language in the world.
Not only that, Python has become the _de facto lingua franca_ of data science, machine learning, and artificial intelligence.

The language out of the box is not without its drawbacks however, especially in the context of
implementing large performance-critical systems. Cython has addressed a lot of these issues, offering all the advantages
of a statically typed language, embedded into Python&#039;s rich ecosystem of software libraries and
developer/user communities.

## What is Rust?

[Rust](https://www.rust-lang.org/) is a multi-paradigm programming language designed for performance and safety, especially safe
concurrency. Rust is &quot;blazingly fast&quot; and memory-efficient (comparable to C and C++) with no garbage collector.
It can power mission-critical systems, run on embedded devices, and easily integrates with other languages.

Rustâ€™s rich type system and ownership model guarantees memory-safety and thread-safety deterministically â€”
eliminating many classes of bugs at compile-time.

The project increasingly utilizes Rust for core performance-critical components. Python language binding is handled through
Cython and [PyO3](https://pyo3.rs), with static libraries linked at compile-time before the wheel binaries are packaged, so a user
does not need to have Rust installed to run NautilusTrader.

This project makes the [Soundness Pledge](https://raphlinus.github.io/rust/2020/01/18/soundness-pledge.html):

&gt; â€œThe intent of this project is to be free of soundness bugs.
&gt; The developers will do their best to avoid them, and welcome help in analyzing and fixing them.â€

&gt; [!NOTE]
&gt;
&gt; **MSRV:** NautilusTrader relies heavily on improvements in the Rust language and compiler.
&gt; As a result, the Minimum Supported Rust Version (MSRV) is generally equal to the latest stable release of Rust.

## Integrations

NautilusTrader is modularly designed to work with _adapters_, enabling connectivity to trading venues
and data providers by translating their raw APIs into a unified interface and normalized domain model.

The following integrations are currently supported:

| Name                                                                         | ID                    | Type                    | Status                                                  | Docs                                                                            |
| :--------------------------------------------------------------------------- | :-------------------- | :---------------------- | :------------------------------------------------------ | :------------------------------------------------------------------------------ |
| [Betfair](https://betfair.com)                                               | `BETFAIR`             | Sports Betting Exchange | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/betfair.html)       |
| [Binance](https://binance.com)                                               | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/binance.html)       |
| [Binance US](https://binance.us)                                             | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/binance.html)       |
| [Binance Futures](https://www.binance.com/en/futures)                        | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/binance.html)       |
| [Bybit](https://www.bybit.com)                                               | `BYBIT`               | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/bybit.html)         |
| [Coinbase International](https://www.coinbase.com/en/international-exchange) | `COINBASE_INTX`       | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/beta-yellow)     | [Guide](https://nautilustrader.io/docs/nightly/integrations/coinbase_intx.html) |
| [Databento](https://databento.com)                                           | `DATABENTO`           | Data Provider           | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/databento.html)     |
| [dYdX](https://dydx.exchange/)                                               | `DYDX`                | Crypto Exchange (DEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/dydx.html)          |
| [Interactive Brokers](https://www.interactivebrokers.com)                    | `INTERACTIVE_BROKERS` | Brokerage (multi-venue) | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/ib.html)            |
| [OKX](https://okx.com)                                                       | `OKX`                 | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/building-orange) | [Guide](https://nautilustrader.io/docs/nightly/integrations/okx.html)           |
| [Polymarket](https://polymarket.com)                                         | `POLYMARKET`          | Prediction Market (DEX) | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/polymarket.html)    |
| [Tardis](https://tardis.dev)                                                 | `TARDIS`              | Crypto Data Provider    | ![status](https://img.shields.io/badge/stable-green)    | [Guide](https://nautilustrader.io/docs/nightly/integrations/tardis.html)        |

- **ID**: The default client ID for the integrations adapter clients.
- **Type**: The type of integration (often the venue type).

### Status
- `building`: Under construction and likely not in a usable state.
- `beta`: Completed to a minimally working state and in a beta testing phase.
- `stable`: Stabilized feature set and API, the integration has been tested by both developers and users to a reasonable level (some bugs may still remain).

See the [Integrations](https://nautilustrader.io/docs/latest/integrations/index.html) documentation for further details.

## Versioning and releases

**NautilusTrader is still under active development**. Some features may be incomplete, and while
the API is becoming more stable, breaking changes can occur between releases.
We strive to document these changes in the release notes on a **best-effort basis**.

We aim to follow a **bi-weekly release schedule**, though experimental or larger features may cause delays.

### Branches

We aim to maintain a stable, passing build across all branches.

- `master`: Reflects the source code for the latest released version.
- `nightly`: Includes experimental and in-progress features, merged from the `develop` branch daily at **14:00 UTC** and also when required.
- `develop`: The most active branch, frequently updated with new commits, including experimental and in-progress features.

&gt; [!NOTE]
&gt;
&gt; Our [roadmap](/ROADMAP.md) aims to achieve a **stable API for version 2.x** (likely after the Rust port).
&gt; Once this milestone is reached, we plan to implement a formal deprecation process for any API changes.
&gt; This approach allows us to maintain a rapid development pace for now.

## Precision mode

NautilusTrader supports two precision modes for its core value types (`Price`, `Quantity`, `Money`),
which differ in their internal bit-width and maximum decimal precision.

- **High-precision**: 128-bit integers with up to 16 decimals of precision, and a larger value range.
- **Standard-precision**: 64-bit integers with up to 9 decimals of precision, and a smaller value range.

&gt; [!NOTE]
&gt;
&gt; By default, the official Python wheels **ship** in high-precision (128-bit) mode on Linux and macOS.
&gt; On Windows, only standard-precision (64-bit) is available due to the lack of native 128-bit integer support.
&gt; For the Rust crates, the default is standard-precision unless you explicitly enable the `high-precision` feature flag.

See the [Installation Guide](https://nautilustrader.io/docs/latest/getting_started/installation) for further details.

## Installation

### From PyPI

We recommend using the latest supported version of Python and setting up [nautilus_trader](https://pypi.org/project/nautilus_trader/) in a virtual environment to isolate dependencies.

To install the latest binary wheel (or sdist package) from PyPI using Python&#039;s pip package manager:

    pip install -U nautilus_trader

### From the Nautech Systems package index

The Nautech Systems package index (`packages.nautechsystems.io`) is [PEP-503](https://peps.python.org/pep-0503/) compliant and hosts both stable and development binary wheels for `nautilus_trader`.
This enables users to install either the latest stable release or pre-release versions for testing.

#### Stable wheels

Stable wheels correspond to official releases of `nautilus_trader` on PyPI, and use standard versioning.

To install the latest stable release:

    pip install -U nautilus_trader --index-url=https://packages.nautechsystems.io/simple

#### Development wheels

Development wheels are published from both the `nightly` and `develop` branches,
allowing users to test features and fixes ahead of stable releases.

**Note**: Wheels from the `develop` branch are only built for the Linux x86_64 platform to save time
and compute resources, while `nightly` wheels support additional platforms as shown below.

| Platform           | Nightly | Develop |
| :----------------- | :------ | :------ |
| `Linux (x86_64)`   | âœ“       | âœ“       |
| `Linux (ARM64)`    | âœ“       | -       |
| `macOS (ARM64)`    | âœ“       | -       |
| `Windows (x86_64)` | âœ“       | -       |

This process also helps preserve compute resources and ensures easy access to the exact binaries tested in CI pipelines,
while adhering to [PEP-440](https://peps.python.org/pep-0440/) versioning standards:

- `develop` wheels use the version format `dev{date}+{build_number}` (e.g., `1.208.0.dev20241212+7001`).
- `nightly` wheels use the version format `a{date}` (alpha) (e.g., `1.208.0a20241212`).

&gt; [!WARNING]
&gt;
&gt; We don&#039;t recommend using development wheels in production environments, such as live trading controlling real capital.

#### Installation commands

By default, pip installs the latest stable release. Adding the `--pre` flag ensures that pre-release versions, including development wheels, are considered.

To install the latest available pre-release (including development wheels):

    pip install -U nautilus_trader --pre --index-url=https://packages.nautechsystems.io/simple

To install a specific development wheel (e.g., `1.208.0a20241212` for December 12, 2024):

    pip install nautilus_trader==1.208.0a20241212 --index-url=https://packages.nautechsystems.io/simple

#### Available versions

You can view all available versions of `nautilus_trader` on the [package index](https://packages.nautechsystems.io/simple/nautilus-trader/index.html).

To programmatically fetch and list available versions:

    curl -s https://packages.nautechsystems.io/simple/nautilus-trader/index.html | grep -oP &#039;(?&lt;=&lt;a href=&quot;)[^&quot;]+(?=&quot;)&#039; | awk -F&#039;#&#039; &#039;{print $1}&#039; | sort

#### Branch updates

- `develop` branch wheels (`.dev`): Are built and published continuously with every merged commit.
- `nightly` b

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[bregman-arie/devops-exercises]]></title>
            <link>https://github.com/bregman-arie/devops-exercises</link>
            <guid>https://github.com/bregman-arie/devops-exercises</guid>
            <pubDate>Wed, 16 Apr 2025 00:04:53 GMT</pubDate>
            <description><![CDATA[Linux, Jenkins, AWS, SRE, Prometheus, Docker, Python, Ansible, Git, Kubernetes, Terraform, OpenStack, SQL, NoSQL, Azure, GCP, DNS, Elastic, Network, Virtualization. DevOps Interview Questions]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bregman-arie/devops-exercises">bregman-arie/devops-exercises</a></h1>
            <p>Linux, Jenkins, AWS, SRE, Prometheus, Docker, Python, Ansible, Git, Kubernetes, Terraform, OpenStack, SQL, NoSQL, Azure, GCP, DNS, Elastic, Network, Virtualization. DevOps Interview Questions</p>
            <p>Language: Python</p>
            <p>Stars: 73,845</p>
            <p>Forks: 16,423</p>
            <p>Stars today: 86 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;images/devops_exercises.png&quot;/&gt;&lt;/p&gt;

:information_source: &amp;nbsp;This repo contains questions and exercises on various technical topics, sometimes related to DevOps and SRE

:bar_chart: &amp;nbsp;There are currently **2624** exercises and questions

:warning: &amp;nbsp;You can use these for preparing for an interview but most of the questions and exercises don&#039;t represent an actual interview. Please read [FAQ page](faq.md) for more details

:stop_sign: &amp;nbsp;If you are interested in pursuing a career as DevOps engineer, learning some of the concepts mentioned here would be useful, but you should know it&#039;s not about learning all the topics and technologies mentioned in this repository

:pencil: &amp;nbsp;You can add more exercises by submitting pull requests :) Read about contribution guidelines [here](CONTRIBUTING.md)

****

&lt;!-- ALL-TOPICS-LIST:START --&gt;
&lt;!-- prettier-ignore-start --&gt;
&lt;!-- markdownlint-disable --&gt;
&lt;center&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/devops/README.md&quot;&gt;&lt;img src=&quot;images/devops.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;DevOps&quot; /&gt;&lt;br /&gt;&lt;b&gt;DevOps&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/git/README.md&quot;&gt;&lt;img src=&quot;images/git.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Git&quot;/&gt;&lt;br /&gt;&lt;b&gt;Git&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#network&quot;&gt;&lt;img src=&quot;images/network.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Network&quot;/&gt;&lt;br /&gt;&lt;b&gt;Network&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#hardware&quot;&gt;&lt;img src=&quot;images/hardware.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Hardware&quot;/&gt;&lt;br /&gt;&lt;b&gt;Hardware&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/kubernetes/README.md&quot;&gt;&lt;img src=&quot;images/kubernetes.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;kubernetes&quot;/&gt;&lt;br /&gt;&lt;b&gt;Kubernetes&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/software_development/README.md&quot;&gt;&lt;img src=&quot;images/programming.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;programming&quot;/&gt;&lt;br /&gt;&lt;b&gt;Software Development&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/bregman-arie/python-exercises&quot;&gt;&lt;img src=&quot;images/python.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Python&quot;/&gt;&lt;br /&gt;&lt;b&gt;Python&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/bregman-arie/go-exercises&quot;&gt;&lt;img src=&quot;images/Go.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;go&quot;/&gt;&lt;br /&gt;&lt;b&gt;Go&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/perl/README.md&quot;&gt;&lt;img src=&quot;images/perl.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;perl&quot;/&gt;&lt;br /&gt;&lt;b&gt;Perl&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#regex&quot;&gt;&lt;img src=&quot;images/regex.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;RegEx&quot;/&gt;&lt;br /&gt;&lt;b&gt;Regex&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/cloud/README.md&quot;&gt;&lt;img src=&quot;images/cloud.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Cloud&quot;/&gt;&lt;br /&gt;&lt;b&gt;Cloud&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/aws/README.md&quot;&gt;&lt;img src=&quot;images/aws.png&quot; width=&quot;100px;&quot; height=&quot;75px;&quot; alt=&quot;aws&quot;/&gt;&lt;br /&gt;&lt;b&gt;AWS&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/azure/README.md&quot;&gt;&lt;img src=&quot;images/azure.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;azure&quot;/&gt;&lt;br /&gt;&lt;b&gt;Azure&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/gcp/README.md&quot;&gt;&lt;img src=&quot;images/googlecloud.png&quot; width=&quot;70px;&quot; height=&quot;70px;&quot; alt=&quot;Google Cloud Platform&quot;/&gt;&lt;br /&gt;&lt;b&gt;Google Cloud Platform&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#openstack/README.md&quot;&gt;&lt;img src=&quot;images/openstack.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;openstack&quot;/&gt;&lt;br /&gt;&lt;b&gt;OpenStack&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#operating-system&quot;&gt;&lt;img src=&quot;images/os.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Operating System&quot;/&gt;&lt;br /&gt;&lt;b&gt;Operating System&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/linux/README.md&quot;&gt;&lt;img src=&quot;images/logos/linux.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Linux&quot;/&gt;&lt;br /&gt;&lt;b&gt;Linux&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#virtualization&quot;&gt;&lt;img src=&quot;images/virtualization.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Virtualization&quot;/&gt;&lt;br /&gt;&lt;b&gt;Virtualization&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/dns/README.md&quot;&gt;&lt;img src=&quot;images/dns.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;DNS&quot;/&gt;&lt;br /&gt;&lt;b&gt;DNS&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/shell/README.md&quot;&gt;&lt;img src=&quot;images/bash.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Bash&quot;/&gt;&lt;br /&gt;&lt;b&gt;Shell Scripting&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/databases/README.md&quot;&gt;&lt;img src=&quot;images/databases.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Databases&quot;/&gt;&lt;br /&gt;&lt;b&gt;Databases&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#sql&quot;&gt;&lt;img src=&quot;images/sql.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;sql&quot;/&gt;&lt;br /&gt;&lt;b&gt;SQL&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#mongo&quot;&gt;&lt;img src=&quot;images/mongo.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Mongo&quot;/&gt;&lt;br /&gt;&lt;b&gt;Mongo&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#testing&quot;&gt;&lt;img src=&quot;images/testing.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Testing&quot;/&gt;&lt;br /&gt;&lt;b&gt;Testing&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#big-data&quot;&gt;&lt;img src=&quot;images/big-data.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Big Data&quot;/&gt;&lt;br /&gt;&lt;b&gt;Big Data&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;

  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/cicd/README.md&quot;&gt;&lt;img src=&quot;images/cicd.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;cicd&quot;/&gt;&lt;br /&gt;&lt;b&gt;CI/CD&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#certificates&quot;&gt;&lt;img src=&quot;images/certificates.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Certificates&quot;/&gt;&lt;br /&gt;&lt;b&gt;Certificates&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/containers/README.md&quot;&gt;&lt;img src=&quot;images/containers.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Containers&quot;/&gt;&lt;br /&gt;&lt;b&gt;Containers&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/openshift/README.md&quot;&gt;&lt;img src=&quot;images/openshift.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;OpenShift&quot;/&gt;&lt;br /&gt;&lt;b&gt;OpenShift&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#storage&quot;&gt;&lt;img src=&quot;images/storage.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Storage&quot;/&gt;&lt;br /&gt;&lt;b&gt;Storage&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/terraform/README.md&quot;&gt;&lt;img src=&quot;images/terraform.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Terraform&quot;/&gt;&lt;br /&gt;&lt;b&gt;Terraform&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#puppet&quot;&gt;&lt;img src=&quot;images/puppet.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;puppet&quot;/&gt;&lt;br /&gt;&lt;b&gt;Puppet&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#distributed&quot;&gt;&lt;img src=&quot;images/distributed.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Distributed&quot;/&gt;&lt;br /&gt;&lt;b&gt;Distributed&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#questions-you-ask&quot;&gt;&lt;img src=&quot;images/you.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;you&quot;/&gt;&lt;br /&gt;&lt;b&gt;Questions you can ask&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/ansible/README.md&quot;&gt;&lt;img src=&quot;images/ansible.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;ansible&quot;/&gt;&lt;br /&gt;&lt;b&gt;Ansible&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/observability/README.md&quot;&gt;&lt;img src=&quot;images/observability.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;observability&quot;/&gt;&lt;br /&gt;&lt;b&gt;Observability&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#prometheus&quot;&gt;&lt;img src=&quot;images/prometheus.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Prometheus&quot;/&gt;&lt;br /&gt;&lt;b&gt;Prometheus&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/circleci/README.md&quot;&gt;&lt;img src=&quot;images/logos/circleci.png&quot; width=&quot;70px;&quot; height=&quot;70px;&quot; alt=&quot;Circle CI&quot;/&gt;&lt;br /&gt;&lt;b&gt;Circle CI&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/datadog/README.md&quot;&gt;&lt;img src=&quot;images/logos/datadog.png&quot; width=&quot;80px;&quot; height=&quot;80px;&quot; alt=&quot;DataDog&quot;/&gt;&lt;br /&gt;&lt;b&gt;&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/grafana/README.md&quot;&gt;&lt;img src=&quot;images/logos/grafana.png&quot; width=&quot;80px;&quot; height=&quot;80px;&quot; alt=&quot;Grafana&quot;/&gt;&lt;br /&gt;&lt;b&gt;Grafana&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/argo/README.md&quot;&gt;&lt;img src=&quot;images/logos/argo.png&quot; width=&quot;80px;&quot; height=&quot;80px;&quot; alt=&quot;Argo&quot;/&gt;&lt;br /&gt;&lt;b&gt;Argo&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/soft_skills/README.md&quot;&gt;&lt;img src=&quot;images/HR.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;HR&quot;/&gt;&lt;br /&gt;&lt;b&gt;Soft Skills&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/security/README.md&quot;&gt;&lt;img src=&quot;images/security.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;security&quot;/&gt;&lt;br /&gt;&lt;b&gt;Security&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#system-design&quot;&gt;&lt;img src=&quot;images/design.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Design&quot;/&gt;&lt;br /&gt;&lt;b&gt;System Design&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
   &lt;/tr&gt;

   &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/chaos_engineering/README.md&quot;&gt;&lt;img src=&quot;images/logos/chaos_engineering.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Chaos Engineering&quot;/&gt;&lt;br /&gt;&lt;b&gt;Chaos Engineering&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#Misc&quot;&gt;&lt;img src=&quot;images/general.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Misc&quot;/&gt;&lt;br /&gt;&lt;b&gt;Misc&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#elastic&quot;&gt;&lt;img src=&quot;images/elastic.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Elastic&quot;/&gt;&lt;br /&gt;&lt;b&gt;Elastic&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/kafka/README.md&quot;&gt;&lt;img src=&quot;images/logos/kafka.png&quot; width=&quot;85px;&quot; height=&quot;80px;&quot; alt=&quot;Kafka&quot;/&gt;&lt;br /&gt;&lt;b&gt;Kafka&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/node/node_questions_basic.md&quot;&gt;&lt;img src=&quot;images/nodejs.png&quot; width=&quot;85px;&quot; height=&quot;80px;&quot; alt=&quot;NodeJs&quot;/&gt;&lt;br /&gt;&lt;b&gt;NodeJs&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
   &lt;/tr&gt;
   
&lt;/table&gt;
&lt;/center&gt;
&lt;!-- markdownlint-enable --&gt;
&lt;!-- prettier-ignore-end --&gt;
&lt;!-- ALL-TOPICS-LIST:END --&gt;

## DevOps Applications

&lt;table&gt;
&lt;tr&gt;
  &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://play.google.com/store/apps/details?id=com.codingshell.kubeprep&quot;&gt;&lt;img src=&quot;images/apps/kubeprep.png&quot; width=&quot;200px;&quot; height=&quot;300px;&quot; alt=&quot;KubePrep&quot;/&gt;&lt;br /&gt;&lt;b&gt;KubePrep&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://play.google.com/store/apps/details?id=com.codingshell.linuxmaster&quot;&gt;&lt;img src=&quot;images/apps/linux_master.png&quot; width=&quot;200px;&quot; height=&quot;300px;&quot; alt=&quot;Linux Master&quot;/&gt;&lt;br /&gt;&lt;b&gt;Linux Master&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://play.google.com/store/apps/details?id=com.codingshell.system_design_hero&quot;&gt;&lt;img src=&quot;images/apps/system_design_hero.png&quot; width=&quot;200px;&quot; height=&quot;300px;&quot; alt=&quot;Sytem Design Hero&quot;/&gt;&lt;br /&gt;&lt;b&gt;System Design Hero&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;


## Network

&lt;details&gt;
&lt;summary&gt;In general, what do you need in order to communicate?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

  - A common language (for the two ends to understand)
  - A way to address who you want to communicate with
  - A Connection (so the content of the communication can reach the recipients)

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is TCP/IP?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

A set of protocols that define how two or more devices can communicate with each other.

To learn more about TCP/IP, read [here](http://www.penguintutor.com/linux/basic-network-reference)

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is Ethernet?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

Ethernet simply refers to the most common type of Local Area Network (LAN) used today. A LANâ€”in contrast to a WAN (Wide Area Network), which spans a larger geographical areaâ€”is a connected network of computers in a small area, like your office, college campus, or even home.

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is a MAC address? What is it used for?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

A MAC address is a unique identification number or code used to identify individual devices on the network.

Packets that are sent on the ethernet are always coming from a MAC address and sent to a MAC address. If a network adapter is receiving a packet, it is comparing the packetâ€™s destination MAC address to the adapterâ€™s own MAC address.

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;When is this MAC address used?: ff:ff:ff:ff:ff:ff&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

When a device sends a packet to the broadcast MAC address (FF:FF:FF:FF:FF:FFâ€‹), it is delivered to all stations on the local network. Ethernet broadcasts are used to resolve IP addresses to MAC addresses (by ARP) at the data link layer.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is an IP address?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

An Internet Protocol address (IP address) is a numerical label assigned to each device connected to a computer network that uses the Internet Protocol for communication.An IP address serves two main functions: host or network interface identification and location addressing.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Explain the subnet mask and give an example&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

A Subnet mask is a 32-bit number that masks an IP address and divides the IP addresses into network addresses and host addresses. Subnet Mask is made by setting network bits to all &quot;1&quot;s and setting host bits to all &quot;0&quot;s. Within a given network, out of the total usable host addresses, two are always reserved for specific purposes and cannot be allocated to any host. These are the first address, which is reserved as a network address (a.k.a network ID), and the last address used for network broadcast.

[Example](https://github.com/philemonnwanne/projects/tree/main/exercises/exe-09)

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is a private IP address? In which scenarios/system designs, one should use it?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;
Private IP addresses are assigned to the hosts in the same network to communicate with one another. As the name &quot;private&quot; suggests, the devices having the private IP addresses assigned can&#039;t be reached by the devices from any external network. For example, if I am living in a hostel and I want my hostel mates to join the game server I have hosted, I will ask them to join via my server&#039;s private IP address, since the network is local to the hostel.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is a public IP address? In which scenarios/system designs, one should use it?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;
A public IP address is a public-facing IP address. In the event that you were hosting a game server that you want your friends to join, you will give your friends your public IP address to allow their computers to identify and locate your network and server in order for the connection to take place. One time that you would not need to use a public-facing IP address is in the event that you were playing with friends who were connected to the same network as you, in that case, you would use a private IP address. In order for someone to be able to connect to your server that is located internally, you will have to set up a port forward to tell your router to allow traffic from the public domain into your network and vice versa.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Explain the OSI model. What layers there are? What each layer is responsible for?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

- Application: user end (HTTP is here)
- Presentation: establishes context between application-layer entities (Encryption is here)
- Session: establishes, manages, and terminates the connections
- Transport: transfers variable-length data sequences from a source to a destination host (TCP &amp; UDP are here)
- Network: transfers datagrams from one network to another (IP is here)
- Data link: provides a link between two directly connected nodes (MAC is here)
- Physical: the electrical and physical spec of the data connection (Bits are here)

You can read more about the OSI model in [penguintutor.com](http://www.penguintutor.com/linux/basic-network-reference)
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;For each of the following determines to which OSI layer it belongs:

  * Error correction
  * Packets routing
  * Cables and electrical signals
  * MAC address
  * IP address
  * Terminate connections
  * 3 way handshake&lt;/summary&gt;&lt;br&gt;&lt;b&gt;
  * Error correction - Data link
  * Packets routing - Network
  * Cables and electrical signals - Physical
  * MAC address - Data link
  * IP address - Network
  * Terminate connections - Session
  * 3-way handshake - Transport
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What delivery schemes are you familiar with?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

Unicast: One-to-one communication where there is one sender and one receiver.

Broadcast: Sending a message to everyone in the network. The address ff:ff:ff:ff:ff:ff is used for broadcasting.
           Two common protocols which use broadcast are ARP and DHCP.

Multicast: Sending a message to a group of subscribers. It can be one-to-many or many-to-many.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is CSMA/CD? Is it used in modern ethernet networks?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

CSMA/CD stands for Carrier Sense Multiple Access / Collision Detection.
Its primary focus is to manage access to a shared medium/bus where only one host can transmit at a given point in time.

CSMA/CD algorithm:

1. Before sending a frame, it checks whether another host is already transmitting a frame.
2. If no one is transmitting, it starts transmitting the frame.
3. If two hosts transmit at the same time, we have a collision.
4. Both hosts stop sending the frame and they send everyone a &#039;jam signal&#039; notifying everyone that a collision occurred
5. They are waiting for a random time before sending it again
6. Once each host waited for a random time, they try to send the frame again and so the cycle starts again
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Describe the following network devices and the difference between them:

  * router
  * switch
  * hub&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

A router, switch, and hub are all network devices used to connect devices in a local area network (LAN). However, each device operates differently and has its specific use cases. Here is a brief description of each device and the differences between them:

1. Router: a network device that connects multiple network segments together. It operates at theÂ network layer (Layer 3)Â of the OSI model and uses routing protocols to direct data between networks. Routers use IP addresses to identify devices and route data packets to the correct destination.
2. Switch: a network device that connects multiple devices on a LAN. It operates at theÂ data link layer (Layer 2)Â of the OSI model and uses MAC addresses to identify devices and direct data packets to the correct destination. Switches allow devices on the same network to communicate with each other more efficiently and can prevent data collisions that can occur when multiple devices send data simultaneously.
3. Hub: a network device that connects multiple devices through a single cable and is used to connect multiple devices without segmenting a network. However, unlike a switch, it operates at theÂ physical layer (Layer 1)Â of the OSI model and simply broadcasts data packets to all devices connected to it, regardless of whether the device is the intended recipient or not. This means that data collisions can occur, and the network&#039;s efficiency can suffer as a result. Hubs are generally not used in modern network setups, as switches are more efficient and provide better network performance.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is a &quot;Collision Domain&quot;?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;
A collision domain is a network segment in which devices can potentially interfere with each other by attempting to transmit data at the same time. When two devices transmit data at the same time, it can cause a collision, resulting in lost or corrupted data. In a collision domain, all devices share the same bandwidth, and any device can potentially interfere with the transmission of data by other devices.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is a &quot;Broadcast Domain&quot;?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;
A broadcast domain is a network segment in which all devices can communicate with each other by sending broadcast messages. A broadcast message is a message that is sent to all devices in a network rather than a specific device. In a broadcast domain, all devices can receive and process broadcast messages, regardless of whether the message was intended for them or not.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;three computers connected to a switch. How many collision domains are there? How many broadcast domains?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

Three collision domains and one broadcast domain
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;How does a router work?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

A router is a physical or virtual appliance that passes information between two or more packet-switched computer networks. A router inspects a given data packet&#039;s destination Internet Protocol address (IP address), calculates the best way for it to reach its destination, and then forwards it accordingly.

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is NAT?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

 Netw

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[freqtrade/freqtrade]]></title>
            <link>https://github.com/freqtrade/freqtrade</link>
            <guid>https://github.com/freqtrade/freqtrade</guid>
            <pubDate>Wed, 16 Apr 2025 00:04:52 GMT</pubDate>
            <description><![CDATA[Free, open source crypto trading bot]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/freqtrade/freqtrade">freqtrade/freqtrade</a></h1>
            <p>Free, open source crypto trading bot</p>
            <p>Language: Python</p>
            <p>Stars: 38,398</p>
            <p>Forks: 7,550</p>
            <p>Stars today: 233 stars today</p>
            <h2>README</h2><pre># ![freqtrade](https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade_poweredby.svg)

[![Freqtrade CI](https://github.com/freqtrade/freqtrade/actions/workflows/ci.yml/badge.svg?branch=develop)](https://github.com/freqtrade/freqtrade/actions/)
[![DOI](https://joss.theoj.org/papers/10.21105/joss.04864/status.svg)](https://doi.org/10.21105/joss.04864)
[![Coverage Status](https://coveralls.io/repos/github/freqtrade/freqtrade/badge.svg?branch=develop&amp;service=github)](https://coveralls.io/github/freqtrade/freqtrade?branch=develop)
[![Documentation](https://readthedocs.org/projects/freqtrade/badge/)](https://www.freqtrade.io)
[![Maintainability](https://api.codeclimate.com/v1/badges/5737e6d668200b7518ff/maintainability)](https://codeclimate.com/github/freqtrade/freqtrade/maintainability)

Freqtrade is a free and open source crypto trading bot written in Python. It is designed to support all major exchanges and be controlled via Telegram or webUI. It contains backtesting, plotting and money management tools as well as strategy optimization by machine learning.

![freqtrade](https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade-screenshot.png)

## Disclaimer

This software is for educational purposes only. Do not risk money which
you are afraid to lose. USE THE SOFTWARE AT YOUR OWN RISK. THE AUTHORS
AND ALL AFFILIATES ASSUME NO RESPONSIBILITY FOR YOUR TRADING RESULTS.

Always start by running a trading bot in Dry-run and do not engage money
before you understand how it works and what profit/loss you should
expect.

We strongly recommend you to have coding and Python knowledge. Do not
hesitate to read the source code and understand the mechanism of this bot.

## Supported Exchange marketplaces

Please read the [exchange specific notes](docs/exchanges.md) to learn about eventual, special configurations needed for each exchange.

- [X] [Binance](https://www.binance.com/)
- [X] [Bitmart](https://bitmart.com/)
- [X] [BingX](https://bingx.com/invite/0EM9RX)
- [X] [Bybit](https://bybit.com/)
- [X] [Gate.io](https://www.gate.io/ref/6266643)
- [X] [HTX](https://www.htx.com/)
- [X] [Hyperliquid](https://hyperliquid.xyz/) (A decentralized exchange, or DEX)
- [X] [Kraken](https://kraken.com/)
- [X] [OKX](https://okx.com/)
- [X] [MyOKX](https://okx.com/) (OKX EEA)
- [ ] [potentially many others](https://github.com/ccxt/ccxt/). _(We cannot guarantee they will work)_

### Supported Futures Exchanges (experimental)

- [X] [Binance](https://www.binance.com/)
- [X] [Gate.io](https://www.gate.io/ref/6266643)
- [X] [Hyperliquid](https://hyperliquid.xyz/) (A decentralized exchange, or DEX)
- [X] [OKX](https://okx.com/)
- [X] [Bybit](https://bybit.com/)

Please make sure to read the [exchange specific notes](docs/exchanges.md), as well as the [trading with leverage](docs/leverage.md) documentation before diving in.

### Community tested

Exchanges confirmed working by the community:

- [X] [Bitvavo](https://bitvavo.com/)
- [X] [Kucoin](https://www.kucoin.com/)

## Documentation

We invite you to read the bot documentation to ensure you understand how the bot is working.

Please find the complete documentation on the [freqtrade website](https://www.freqtrade.io).

## Features

- [x] **Based on Python 3.10+**: For botting on any operating system - Windows, macOS and Linux.
- [x] **Persistence**: Persistence is achieved through sqlite.
- [x] **Dry-run**: Run the bot without paying money.
- [x] **Backtesting**: Run a simulation of your buy/sell strategy.
- [x] **Strategy Optimization by machine learning**: Use machine learning to optimize your buy/sell strategy parameters with real exchange data.
- [X] **Adaptive prediction modeling**: Build a smart strategy with FreqAI that self-trains to the market via adaptive machine learning methods. [Learn more](https://www.freqtrade.io/en/stable/freqai/)
- [x] **Edge position sizing** Calculate your win rate, risk reward ratio, the best stoploss and adjust your position size before taking a position for each specific market. [Learn more](https://www.freqtrade.io/en/stable/edge/).
- [x] **Whitelist crypto-currencies**: Select which crypto-currency you want to trade or use dynamic whitelists.
- [x] **Blacklist crypto-currencies**: Select which crypto-currency you want to avoid.
- [x] **Builtin WebUI**: Builtin web UI to manage your bot.
- [x] **Manageable via Telegram**: Manage the bot with Telegram.
- [x] **Display profit/loss in fiat**: Display your profit/loss in fiat currency.
- [x] **Performance status report**: Provide a performance status of your current trades.

## Quick start

Please refer to the [Docker Quickstart documentation](https://www.freqtrade.io/en/stable/docker_quickstart/) on how to get started quickly.

For further (native) installation methods, please refer to the [Installation documentation page](https://www.freqtrade.io/en/stable/installation/).

## Basic Usage

### Bot commands

```
usage: freqtrade [-h] [-V]
                 {trade,create-userdir,new-config,show-config,new-strategy,download-data,convert-data,convert-trade-data,trades-to-ohlcv,list-data,backtesting,backtesting-show,backtesting-analysis,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-markets,list-pairs,list-strategies,list-hyperoptloss,list-freqaimodels,list-timeframes,show-trades,test-pairlist,convert-db,install-ui,plot-dataframe,plot-profit,webserver,strategy-updater,lookahead-analysis,recursive-analysis}
                 ...

Free, open source crypto trading bot

positional arguments:
  {trade,create-userdir,new-config,show-config,new-strategy,download-data,convert-data,convert-trade-data,trades-to-ohlcv,list-data,backtesting,backtesting-show,backtesting-analysis,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-markets,list-pairs,list-strategies,list-hyperoptloss,list-freqaimodels,list-timeframes,show-trades,test-pairlist,convert-db,install-ui,plot-dataframe,plot-profit,webserver,strategy-updater,lookahead-analysis,recursive-analysis}
    trade               Trade module.
    create-userdir      Create user-data directory.
    new-config          Create new config
    show-config         Show resolved config
    new-strategy        Create new strategy
    download-data       Download backtesting data.
    convert-data        Convert candle (OHLCV) data from one format to
                        another.
    convert-trade-data  Convert trade data from one format to another.
    trades-to-ohlcv     Convert trade data to OHLCV data.
    list-data           List downloaded data.
    backtesting         Backtesting module.
    backtesting-show    Show past Backtest results
    backtesting-analysis
                        Backtest Analysis module.
    edge                Edge module.
    hyperopt            Hyperopt module.
    hyperopt-list       List Hyperopt results
    hyperopt-show       Show details of Hyperopt results
    list-exchanges      Print available exchanges.
    list-markets        Print markets on exchange.
    list-pairs          Print pairs on exchange.
    list-strategies     Print available strategies.
    list-hyperoptloss   Print available hyperopt loss functions.
    list-freqaimodels   Print available freqAI models.
    list-timeframes     Print available timeframes for the exchange.
    show-trades         Show trades.
    test-pairlist       Test your pairlist configuration.
    convert-db          Migrate database to different system
    install-ui          Install FreqUI
    plot-dataframe      Plot candles with indicators.
    plot-profit         Generate plot showing profits.
    webserver           Webserver module.
    strategy-updater    updates outdated strategy files to the current version
    lookahead-analysis  Check for potential look ahead bias.
    recursive-analysis  Check for potential recursive formula issue.

options:
  -h, --help            show this help message and exit
  -V, --version         show program&#039;s version number and exit
```

### Telegram RPC commands

Telegram is not mandatory. However, this is a great way to control your bot. More details and the full command list on the [documentation](https://www.freqtrade.io/en/latest/telegram-usage/)

- `/start`: Starts the trader.
- `/stop`: Stops the trader.
- `/stopentry`: Stop entering new trades.
- `/status &lt;trade_id&gt;|[table]`: Lists all or specific open trades.
- `/profit [&lt;n&gt;]`: Lists cumulative profit from all finished trades, over the last n days.
- `/forceexit &lt;trade_id&gt;|all`: Instantly exits the given trade (Ignoring `minimum_roi`).
- `/fx &lt;trade_id&gt;|all`: Alias to `/forceexit`
- `/performance`: Show performance of each finished trade grouped by pair
- `/balance`: Show account balance per currency.
- `/daily &lt;n&gt;`: Shows profit or loss per day, over the last n days.
- `/help`: Show help message.
- `/version`: Show version.

## Development branches

The project is currently setup in two main branches:

- `develop` - This branch has often new features, but might also contain breaking changes. We try hard to keep this branch as stable as possible.
- `stable` - This branch contains the latest stable release. This branch is generally well tested.
- `feat/*` - These are feature branches, which are being worked on heavily. Please don&#039;t use these unless you want to test a specific feature.

## Support

### Help / Discord

For any questions not covered by the documentation or for further information about the bot, or to simply engage with like-minded individuals, we encourage you to join the Freqtrade [discord server](https://discord.gg/p7nuUNVfP7).

### [Bugs / Issues](https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue)

If you discover a bug in the bot, please
[search the issue tracker](https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue)
first. If it hasn&#039;t been reported, please
[create a new issue](https://github.com/freqtrade/freqtrade/issues/new/choose) and
ensure you follow the template guide so that the team can assist you as
quickly as possible.

For every [issue](https://github.com/freqtrade/freqtrade/issues/new/choose) created, kindly follow up and mark satisfaction or reminder to close issue when equilibrium ground is reached.

--Maintain github&#039;s [community policy](https://docs.github.com/en/site-policy/github-terms/github-community-code-of-conduct)--

### [Feature Requests](https://github.com/freqtrade/freqtrade/labels/enhancement)

Have you a great idea to improve the bot you want to share? Please,
first search if this feature was not [already discussed](https://github.com/freqtrade/freqtrade/labels/enhancement).
If it hasn&#039;t been requested, please
[create a new request](https://github.com/freqtrade/freqtrade/issues/new/choose)
and ensure you follow the template guide so that it does not get lost
in the bug reports.

### [Pull Requests](https://github.com/freqtrade/freqtrade/pulls)

Feel like the bot is missing a feature? We welcome your pull requests!

Please read the
[Contributing document](https://github.com/freqtrade/freqtrade/blob/develop/CONTRIBUTING.md)
to understand the requirements before sending your pull-requests.

Coding is not a necessity to contribute - maybe start with improving the documentation?
Issues labeled [good first issue](https://github.com/freqtrade/freqtrade/labels/good%20first%20issue) can be good first contributions, and will help get you familiar with the codebase.

**Note** before starting any major new feature work, *please open an issue describing what you are planning to do* or talk to us on [discord](https://discord.gg/p7nuUNVfP7) (please use the #dev channel for this). This will ensure that interested parties can give valuable feedback on the feature, and let others know that you are working on it.

**Important:** Always create your PR against the `develop` branch, not `stable`.

## Requirements

### Up-to-date clock

The clock must be accurate, synchronized to a NTP server very frequently to avoid problems with communication to the exchanges.

### Minimum hardware required

To run this bot we recommend you a cloud instance with a minimum of:

- Minimal (advised) system requirements: 2GB RAM, 1GB disk space, 2vCPU

### Software requirements

- [Python &gt;= 3.10](http://docs.python-guide.org/en/latest/starting/installation/)
- [pip](https://pip.pypa.io/en/stable/installing/)
- [git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)
- [TA-Lib](https://ta-lib.github.io/ta-lib-python/)
- [virtualenv](https://virtualenv.pypa.io/en/stable/installation.html) (Recommended)
- [Docker](https://www.docker.com/products/docker) (Recommended)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[opendatalab/MinerU]]></title>
            <link>https://github.com/opendatalab/MinerU</link>
            <guid>https://github.com/opendatalab/MinerU</guid>
            <pubDate>Wed, 16 Apr 2025 00:04:51 GMT</pubDate>
            <description><![CDATA[A high-quality tool for convert PDF to Markdown and JSON.ä¸€ç«™å¼å¼€æºé«˜è´¨é‡æ•°æ®æå–å·¥å…·ï¼Œå°†PDFè½¬æ¢æˆMarkdownå’ŒJSONæ ¼å¼ã€‚]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/opendatalab/MinerU">opendatalab/MinerU</a></h1>
            <p>A high-quality tool for convert PDF to Markdown and JSON.ä¸€ç«™å¼å¼€æºé«˜è´¨é‡æ•°æ®æå–å·¥å…·ï¼Œå°†PDFè½¬æ¢æˆMarkdownå’ŒJSONæ ¼å¼ã€‚</p>
            <p>Language: Python</p>
            <p>Stars: 30,854</p>
            <p>Forks: 2,460</p>
            <p>Stars today: 297 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; xmlns=&quot;http://www.w3.org/1999/html&quot;&gt;
&lt;!-- logo --&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;docs/images/MinerU-logo.png&quot; width=&quot;300px&quot; style=&quot;vertical-align:middle;&quot;&gt;
&lt;/p&gt;

&lt;!-- icon --&gt;

[![stars](https://img.shields.io/github/stars/opendatalab/MinerU.svg)](https://github.com/opendatalab/MinerU)
[![forks](https://img.shields.io/github/forks/opendatalab/MinerU.svg)](https://github.com/opendatalab/MinerU)
[![open issues](https://img.shields.io/github/issues-raw/opendatalab/MinerU)](https://github.com/opendatalab/MinerU/issues)
[![issue resolution](https://img.shields.io/github/issues-closed-raw/opendatalab/MinerU)](https://github.com/opendatalab/MinerU/issues)
[![PyPI version](https://img.shields.io/pypi/v/magic-pdf)](https://pypi.org/project/magic-pdf/)
[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/magic-pdf)](https://pypi.org/project/magic-pdf/)
[![Downloads](https://static.pepy.tech/badge/magic-pdf)](https://pepy.tech/project/magic-pdf)
[![Downloads](https://static.pepy.tech/badge/magic-pdf/month)](https://pepy.tech/project/magic-pdf)

[![OpenDataLab](https://img.shields.io/badge/Demo_on_OpenDataLab-blue?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTM0IiBoZWlnaHQ9IjEzNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBkPSJtMTIyLDljMCw1LTQsOS05LDlzLTktNC05LTksNC05LDktOSw5LDQsOSw5eiIgZmlsbD0idXJsKCNhKSIvPjxwYXRoIGQ9Im0xMjIsOWMwLDUtNCw5LTksOXMtOS00LTktOSw0LTksOS05LDksNCw5LDl6IiBmaWxsPSIjMDEwMTAxIi8+PHBhdGggZD0ibTkxLDE4YzAsNS00LDktOSw5cy05LTQtOS05LDQtOSw5LTksOSw0LDksOXoiIGZpbGw9InVybCgjYikiLz48cGF0aCBkPSJtOTEsMThjMCw1LTQsOS05LDlzLTktNC05LTksNC05LDktOSw5LDQsOSw5eiIgZmlsbD0iIzAxMDEwMSIvPjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJtMzksNjJjMCwxNiw4LDMwLDIwLDM4LDctNiwxMi0xNiwxMi0yNlY0OWMwLTQsMy03LDYtOGw0Ni0xMmM1LTEsMTEsMywxMSw4djMxYzAsMzctMzAsNjYtNjYsNjYtMzcsMC02Ni0zMC02Ni02NlY0NmMwLTQsMy03LDYtOGwyMC02YzUtMSwxMSwzLDExLDh2MjF6bS0yOSw2YzAsMTYsNiwzMCwxNyw0MCwzLDEsNSwxLDgsMSw1LDAsMTAtMSwxNS0zQzM3LDk1LDI5LDc5LDI5LDYyVjQybC0xOSw1djIweiIgZmlsbD0idXJsKCNjKSIvPjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJtMzksNjJjMCwxNiw4LDMwLDIwLDM4LDctNiwxMi0xNiwxMi0yNlY0OWMwLTQsMy03LDYtOGw0Ni0xMmM1LTEsMTEsMywxMSw4djMxYzAsMzctMzAsNjYtNjYsNjYtMzcsMC02Ni0zMC02Ni02NlY0NmMwLTQsMy03LDYtOGwyMC02YzUtMSwxMSwzLDExLDh2MjF6bS0yOSw2YzAsMTYsNiwzMCwxNyw0MCwzLDEsNSwxLDgsMSw1LDAsMTAtMSwxNS0zQzM3LDk1LDI5LDc5LDI5LDYyVjQybC0xOSw1djIweiIgZmlsbD0iIzAxMDEwMSIvPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYSIgeDE9Ijg0IiB5MT0iNDEiIHgyPSI3NSIgeTI9IjEyMCIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiNmZmYiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiMyZTJlMmUiLz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYiIgeDE9Ijg0IiB5MT0iNDEiIHgyPSI3NSIgeTI9IjEyMCIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiNmZmYiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiMyZTJlMmUiLz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYyIgeDE9Ijg0IiB5MT0iNDEiIHgyPSI3NSIgeTI9IjEyMCIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiNmZmYiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiMyZTJlMmUiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48L3N2Zz4=&amp;labelColor=white)](https://mineru.net/OpenSourceTools/Extractor?source=github)
[![HuggingFace](https://img.shields.io/badge/Demo_on_HuggingFace-yellow.svg?logo=data:image/png;base64,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&amp;labelColor=white)](https://huggingface.co/spaces/opendatalab/MinerU)
[![ModelScope](https://img.shields.io/badge/Demo_on_ModelScope-purple?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIzIiBoZWlnaHQ9IjIwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCiA8Zz4KICA8dGl0bGU+TGF5ZXIgMTwvdGl0bGU+CiAgPHBhdGggaWQ9InN2Z18xNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTAsODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTUiIGZpbGw9IiM2MjRhZmYiIGQ9Im05OS4xNCwxMTUuNDlsMjUuNjUsMGwwLDI1LjY1bC0yNS42NSwwbDAsLTI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTYiIGZpbGw9IiM2MjRhZmYiIGQ9Im0xNzYuMDksMTQxLjE0bC0yNS42NDk5OSwwbDAsMjIuMTlsNDcuODQsMGwwLC00Ny44NGwtMjIuMTksMGwwLDI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTciIGZpbGw9IiMzNmNmZDEiIGQ9Im0xMjQuNzksODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTgiIGZpbGw9IiMzNmNmZDEiIGQ9Im0wLDY0LjE5bDI1LjY1LDBsMCwyNS42NWwtMjUuNjUsMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzE5IiBmaWxsPSIjNjI0YWZmIiBkPSJtMTk4LjI4LDg5Ljg0bDI1LjY0OTk5LDBsMCwyNS42NDk5OWwtMjUuNjQ5OTksMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIwIiBmaWxsPSIjMzZjZmQxIiBkPSJtMTk4LjI4LDY0LjE5bDI1LjY0OTk5LDBsMCwyNS42NWwtMjUuNjQ5OTksMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIxIiBmaWxsPSIjNjI0YWZmIiBkPSJtMTUwLjQ0LDQybDAsMjIuMTlsMjUuNjQ5OTksMGwwLDI1LjY1bDIyLjE5LDBsMCwtNDcuODRsLTQ3Ljg0LDB6Ii8+CiAgPHBhdGggaWQ9InN2Z18yMiIgZmlsbD0iIzM2Y2ZkMSIgZD0ibTczLjQ5LDg5Ljg0bDI1LjY1LDBsMCwyNS42NDk5OWwtMjUuNjUsMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIzIiBmaWxsPSIjNjI0YWZmIiBkPSJtNDcuODQsNjQuMTlsMjUuNjUsMGwwLC0yMi4xOWwtNDcuODQsMGwwLDQ3Ljg0bDIyLjE5LDBsMCwtMjUuNjV6Ii8+CiAgPHBhdGggaWQ9InN2Z18yNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTQ3Ljg0LDExNS40OWwtMjIuMTksMGwwLDQ3Ljg0bDQ3Ljg0LDBsMCwtMjIuMTlsLTI1LjY1LDBsMCwtMjUuNjV6Ii8+CiA8L2c+Cjwvc3ZnPg==&amp;labelColor=white)](https://www.modelscope.cn/studios/OpenDataLab/MinerU)
[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/gist/myhloli/3b3a00a4a0a61577b6c30f989092d20d/mineru_demo.ipynb)
[![Paper](https://img.shields.io/badge/Paper-arXiv-green)](https://arxiv.org/abs/2409.18839)


&lt;a href=&quot;https://trendshift.io/repositories/11174&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/11174&quot; alt=&quot;opendatalab%2FMinerU | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

&lt;!-- language --&gt;

[English](README.md) | [ç®€ä½“ä¸­æ–‡](README_zh-CN.md)

&lt;!-- hot link --&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/opendatalab/PDF-Extract-Kit&quot;&gt;PDF-Extract-Kit: High-Quality PDF Extraction Toolkit&lt;/a&gt;ğŸ”¥ğŸ”¥ğŸ”¥
&lt;br&gt;
&lt;br&gt;
&lt;a href=&quot;https://mineru.net/client?source=github&quot;&gt;
Easier to use: Just grab MinerU Desktop. No coding, no login, just a simple interface and smooth interactions. Enjoy it without any fuss!&lt;/a&gt;ğŸš€ğŸš€ğŸš€

&lt;/p&gt;

&lt;!-- join us --&gt;

&lt;p align=&quot;center&quot;&gt;
    ğŸ‘‹ join us on &lt;a href=&quot;https://discord.gg/Tdedn9GTXq&quot; target=&quot;_blank&quot;&gt;Discord&lt;/a&gt; and &lt;a href=&quot;http://mineru.space/s/V85Yl&quot; target=&quot;_blank&quot;&gt;WeChat&lt;/a&gt;
&lt;/p&gt;

&lt;/div&gt;

# Changelog
- 2025/04/12 1.3.2 released
  - Fixed the issue of incompatible dependency package versions when installing in Python 3.13 environment on Windows systems.
  - Optimized memory usage during batch inference.
  - Improved the parsing effect of tables rotated by 90 degrees.
  - Enhanced the parsing accuracy for large tables in financial report samples.
  - Fixed the occasional word concatenation issue in English text areas when OCR language is not specified.(The model needs to be updated)
- 2025/04/08 1.3.1 released, fixed some compatibility issues
  - Supported Python 3.13
  - Made the final adaptation for some outdated Linux systems (e.g., CentOS 7), and no further support will be guaranteed for subsequent versions. [Installation Instructions](https://github.com/opendatalab/MinerU/issues/1004)
- 2025/04/03 1.3.0 released, in this version we made many optimizations and improvements:
  - Installation and compatibility optimization
    - By removing the use of `layoutlmv3` in layout, resolved compatibility issues caused by `detectron2`.
    - Torch version compatibility extended to 2.2~2.6 (excluding 2.5).
    - CUDA compatibility supports 11.8/12.4/12.6/12.8 (CUDA version determined by torch), resolving compatibility issues for some users with 50-series and H-series GPUs.
    - Python compatible versions expanded to 3.10~3.12, solving the problem of automatic downgrade to 0.6.1 during installation in non-3.10 environments.
    - Offline deployment process optimized; no internet connection required after successful deployment to download any model files.
  - Performance optimization
    - By supporting batch processing of multiple PDF files ([script example](demo/batch_demo.py)), improved parsing speed for small files in batches (compared to version 1.0.1, formula parsing speed increased by over 1400%, overall parsing speed increased by over 500%).
    - Optimized loading and usage of the mfr model, reducing GPU memory usage and improving parsing speed (requires re-execution of the [model download process](docs/how_to_download_models_en.md) to obtain incremental updates of model files).
    - Optimized GPU memory usage, requiring only a minimum of 6GB to run this project.
    - Improved running speed on MPS devices.
  - Parsing effect optimization
    - Updated the mfr model to `unimernet(2503)`, solving the issue of lost line breaks in multi-line formulas.
  - Usability Optimization
    - By using `paddleocr2torch`, completely replaced the use of the `paddle` framework and `paddleocr` in the project, resolving conflicts between `paddle` and `torch`, as well as thread safety issues caused by the `paddle` framework.
    - Added a real-time progress bar during the parsing process to accurately track progress, making the wait less painful.
&lt;details&gt;
&lt;summary&gt;2025/03/03 1.2.1 released&lt;/summary&gt;
&lt;ul&gt;
  &lt;li&gt;Fixed the impact on punctuation marks during full-width to half-width conversion of letters and numbers&lt;/li&gt;
  &lt;li&gt;Fixed caption matching inaccuracies in certain scenarios&lt;/li&gt;
  &lt;li&gt;Fixed formula span loss issues in certain scenarios&lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;2025/02/24 1.2.0 released&lt;/summary&gt;
&lt;p&gt;This version includes several fixes and improvements to enhance parsing efficiency and accuracy:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Performance Optimization&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Increased classification speed for PDF documents in auto mode.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Parsing Optimization&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Improved parsing logic for documents containing watermarks, significantly enhancing the parsing results for such documents.&lt;/li&gt;
      &lt;li&gt;Enhanced the matching logic for multiple images/tables and captions within a single page, improving the accuracy of image-text matching in complex layouts.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bug Fixes&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Fixed an issue where image/table spans were incorrectly filled into text blocks under certain conditions.&lt;/li&gt;
      &lt;li&gt;Resolved an issue where title blocks were empty in some cases.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;2025/01/22 1.1.0 released&lt;/summary&gt;
&lt;p&gt;In this version we have focused on improving parsing accuracy and efficiency:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Model capability upgrade&lt;/strong&gt; (requires re-executing the &lt;a href=&quot;https://github.com/opendatalab/MinerU/blob/master/docs/how_to_download_models_en.md&quot;&gt;model download process&lt;/a&gt; to obtain incremental updates of model files)
    &lt;ul&gt;
      &lt;li&gt;The layout recognition model has been upgraded to the latest &lt;code&gt;doclayout_yolo(2501)&lt;/code&gt; model, improving layout recognition accuracy.&lt;/li&gt;
      &lt;li&gt;The formula parsing model has been upgraded to the latest &lt;code&gt;unimernet(2501)&lt;/code&gt; model, improving formula recognition accuracy.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Performance optimization&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;On devices that meet certain configuration requirements (16GB+ VRAM), by optimizing resource usage and restructuring the processing pipeline, overall parsing speed has been increased by more than 50%.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Parsing effect optimization&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Added a new heading classification feature (testing version, enabled by default) to the online demo (&lt;a href=&quot;https://mineru.net/OpenSourceTools/Extractor&quot;&gt;mineru.net&lt;/a&gt;/&lt;a href=&quot;https://huggingface.co/spaces/opendatalab/MinerU&quot;&gt;huggingface&lt;/a&gt;/&lt;a href=&quot;https://www.modelscope.cn/studios/OpenDataLab/MinerU&quot;&gt;modelscope&lt;/a&gt;), which supports hierarchical classification of headings, thereby enhancing document structuring.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;2025/01/10 1.0.1 released&lt;/summary&gt;
&lt;p&gt;This is our first official release, where we have introduced a completely new API interface and enhanced compatibility through extensive refactoring, as well as a brand new automatic language identification feature:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;New API Interface&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;For the data-side API, we have introduced the Dataset class, designed to provide a robust and flexible data processing framework. This framework currently supports a variety of document formats, including images (.jpg and .png), PDFs, Word documents (.doc and .docx), and PowerPoint presentations (.ppt and .pptx). It ensures effective support for data processing tasks ranging from simple to complex.&lt;/li&gt;
      &lt;li&gt;For the user-side API, we have meticulously designed the MinerU processing workflow as a series of composable Stages. Each Stage represents a specific processing step, allowing users to define new Stages according to their needs and creatively combine these stages to customize their data processing workflows.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Enhanced Compatibility&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;By optimizing the dependency environment and configuration items, we ensure stable and efficient operation on ARM architecture Linux systems.&lt;/li&gt;
      &lt;li&gt;We have deeply integrated with Huawei Ascend NPU acceleration, providing autonomous and controllable high-performance computing capabilities. This supports the localization and development of AI application platforms in China. &lt;a href=&quot;https://github.com/opendatalab/MinerU/blob/master/docs/README_Ascend_NPU_Acceleration_zh_CN.md&quot;&gt;Ascend NPU Acceleration&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Automatic Language Identification&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;By introducing a new language recognition model, setting the &lt;code&gt;lang&lt;/code&gt; configuration to &lt;code&gt;auto&lt;/code&gt; during document parsing will automatically select the appropriate OCR language model, improving the accuracy of scanned document parsing.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;2024/11/22 0.10.0 released&lt;/summary&gt;
&lt;p&gt;Introducing hybrid OCR text extraction capabilities:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Significantly improved parsing performance in complex text distribution scenarios such as dense formulas, irregular span regions, and text represented by images.&lt;/li&gt;
  &lt;li&gt;Combines the dual advantages of accurate content extraction and faster speed in text mode, and more precise span/line region recognition in OCR mode.&lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;2024/11/15 0.9.3 released&lt;/summary&gt;
&lt;p&gt;Integrated &lt;a href=&quot;https://github.com/RapidAI/RapidTable&quot;&gt;RapidTable&lt;/a&gt; for table recognition, improving single-table parsing speed by more than 10 times, with higher accuracy and lower GPU memory usage.&lt;/p&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;2024/11/06 0.9.2 released&lt;/summary&gt;
&lt;p&gt;Integrated the &lt;a href=&quot;https://huggingface.co/U4R/StructTable-InternVL2-1B&quot;&gt;StructTable-InternVL2-1B&lt;/a&gt; model for table recognition functionality.&lt;/p&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;2024/10/31 0.9.0 released&lt;/summary&gt;
&lt;p&gt;This is a major new version with extensive code refactoring, addressing numerous issues, improving performance, reducing hardware requirements, and enhancing usability:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Refactored the sorting module code to use &lt;a href=&quot;https://github.com/ppaanngggg/layoutreader&quot;&gt;layoutreader&lt;/a&gt; for reading order sorting, ensuring high accuracy in various layouts.&lt;/li&gt;
  &lt;li&gt;Refactored the paragraph concatenation module to achieve good results in cross-column, cross-page, cross-figure, and cross-table scenarios.&lt;/li&gt;
  &lt;li&gt;Refactored the list and table of contents recognition functions, significantly improving the accuracy of list blocks and table of contents blocks, as well as the parsing of corresponding text paragraphs.&lt;/li&gt;
  &lt;li&gt;Refactored the matching logic for figures, tables, and descriptive text, greatly enhancing the accuracy of matching captions and footnotes to figures and tables, and reducing the loss rate of descriptive text to near zero.&lt;/li&gt;
  &lt;li&gt;Added multi-language support for OCR, supporting detection and recognition of 84 languages. For the list of supported languages, see &lt;a href=&quot;https://paddlepaddle.github.io/PaddleOCR/latest/en/ppocr/blog/multi_languages.html#5-support-languages-and-abbreviations&quot;&gt;OCR Language Support List&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Added memory recycling logic and other memory optimization measures, significantly reducing memory usage. The memory requirement for enabling all acceleration features except table acceleration (layout/formula/OCR) has been reduced from 16GB to 8GB, and the memory requirement for enabling all acceleration features has been reduced from 24GB to 10GB.&lt;/li&gt;
  &lt;li&gt;Optimized configuration file feature switches, adding an independent formula detection switch to significantly improve speed and parsing results when formula detection is not needed.&lt;/li&gt;
  &lt;li&gt;Integrated &lt;a href=&quot;https://github.com/opendatalab/PDF-Extract-Kit&quot;&gt;PDF-Extract-Kit 1.0&lt;/a&gt;:
    &lt;ul&gt;
      &lt;li&gt;Added the self-developed &lt;code&gt;doclayout_yolo&lt;/code&gt; model, which speeds up processing by more than 10 times compared to the original solution while maintaining similar parsing effects, and can be freely switched with &lt;code&gt;layoutlmv3&lt;/code&gt; via the configuration file.&lt;/li&gt;
      &lt;li&gt;Upgraded formula parsing to &lt;code&gt;unimernet 0.2.1&lt;/code&gt;, improving formula parsing accuracy while significantly reducing memory usage.&lt;/li&gt;
      &lt;li&gt;Due to the repository change for &lt;code&gt;PDF-Extract-Kit 1.0&lt;/code&gt;, you need to re-download the model. Please refer to &lt;a href=&quot;https

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Agenta-AI/agenta]]></title>
            <link>https://github.com/Agenta-AI/agenta</link>
            <guid>https://github.com/Agenta-AI/agenta</guid>
            <pubDate>Wed, 16 Apr 2025 00:04:50 GMT</pubDate>
            <description><![CDATA[The open-source LLMOps platform: prompt playground, prompt management, LLM evaluation, and LLM observability all in one place.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Agenta-AI/agenta">Agenta-AI/agenta</a></h1>
            <p>The open-source LLMOps platform: prompt playground, prompt management, LLM evaluation, and LLM observability all in one place.</p>
            <p>Language: Python</p>
            <p>Stars: 2,561</p>
            <p>Forks: 300</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre>
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://agenta.ai?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme&quot;&gt;
      &lt;picture &gt;
        &lt;source width=&quot;275&quot; media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/Agenta-AI/agenta/assets/4510758/cdddf5ad-2352-4920-b1d9-ae7f8d9d7735&quot;  &gt;
        &lt;source width=&quot;275&quot; media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/Agenta-AI/agenta/assets/4510758/ab75cbac-b807-496f-aab3-57463a33f726&quot;  &gt;
        &lt;img alt=&quot;Shows the logo of agenta&quot; src=&quot;https://github.com/Agenta-AI/agenta/assets/4510758/68e055d4-d7b8-4943-992f-761558c64253&quot; &gt;
      &lt;/picture&gt;
  &lt;/a&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;strong&gt; &lt;h1&gt; The Open-source LLMOps Platform &lt;/h1&gt;&lt;/strong&gt;
  Build reliable LLM applications faster with integrated prompt management, evaluation, and observability.
&lt;/div&gt;
  &lt;br /&gt;
      &lt;div align=&quot;center&quot; &gt;
        &lt;a href=&quot;https://cloud.agenta.ai?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme&quot;&gt;
          &lt;picture &gt;
        &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://imagedelivery.net/UNvjPBCIZFONpkVPQTxVuA/9a4fde42-c96c-4ec2-b8d1-c8c0e3851a00/large&quot;  &gt;
        &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://imagedelivery.net/UNvjPBCIZFONpkVPQTxVuA/98140352-14c0-4db1-bafb-a1e8d271d500/large&quot;  &gt;
        &lt;img alt=&quot;Shows the logo of agenta&quot; src=&quot;https://imagedelivery.net/UNvjPBCIZFONpkVPQTxVuA/98140352-14c0-4db1-bafb-a1e8d271d500/large&quot; &gt;
          &lt;/picture&gt;
        &lt;/a&gt;
    &lt;/div&gt;
&lt;/div&gt;

---

&lt;h3 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.agenta.ai?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme&quot;&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; &amp;bull;
  &lt;a href=&quot;https://agenta.ai?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme&quot;&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; &amp;bull;
  &lt;a href=&quot;https://cloud.agenta.ai?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme&quot;&gt;&lt;b&gt;Agenta Cloud&lt;/b&gt;&lt;/a&gt;
&lt;/h3&gt;

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/license-MIT-blue.svg&quot; alt=&quot;MIT license.&quot; /&gt;
  &lt;a href=&quot;https://docs.agenta.ai?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Doc-online-green&quot; alt=&quot;Doc&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/Agenta-AI/agenta/blob/main/CONTRIBUTING.md&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/PRs-Welcome-brightgreen&quot; alt=&quot;PRs welcome&quot; /&gt;
  &lt;/a&gt;
  &lt;img src=&quot;https://img.shields.io/github/contributors/Agenta-AI/agenta&quot; alt=&quot;Contributors&quot;&gt;
  &lt;a href=&quot;https://pypi.org/project/agenta/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/pypi/dm/agenta&quot; alt=&quot;PyPI - Downloads&quot;&gt;
  &lt;/a&gt;
  &lt;img src=&quot;https://img.shields.io/github/last-commit/Agenta-AI/agenta&quot; alt=&quot;Last Commit&quot;&gt;
&lt;/br&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://join.slack.com/t/agenta-hq/shared_invite/zt-2yewk6o2b-DmhyA4h_lkKwecDtIsj1AQ&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/JOIN US ON SLACK-4A154B?style=for-the-badge&amp;logo=slack&amp;logoColor=white&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://www.linkedin.com/company/agenta-ai/&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white&quot; /&gt;
    &lt;/a&gt;
    &lt;a  href=&quot;https://twitter.com/agenta_ai&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/agenta_ai?style=social&quot; height=&quot;28&quot; /&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://cloud.agenta.ai?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme&quot;&gt;
      &lt;picture &gt;
        &lt;source width=&quot;200&quot; media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/a2069e7b-c3e0-4a5e-9e41-8ddc4660d1f2&quot;  &gt;
        &lt;source width=&quot;200&quot; media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/a2069e7b-c3e0-4a5e-9e41-8ddc4660d1f2&quot;  &gt;
        &lt;img alt=&quot;Try Agenta Live Demo&quot; src=&quot;https://github.com/user-attachments/assets/a2069e7b-c3e0-4a5e-9e41-8ddc4660d1f2&quot; &gt;
      &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

---

## What is Agenta?

Agenta is a platform for building production-grade LLM applications. It helps **engineering** and **product teams** create reliable LLM apps faster through integrated prompt management, evaluation, and observability.

## Core Features

### ğŸ§ª Prompt Engineering &amp; Management
Collaborate with Subject Matter Experts (SMEs) on prompt engineering and make sure nothing breaks in production.

- **Interactive Playground**: Compare prompts side by side against your test cases
- **Multi-Model Support**: Experiment with 50+ LLM models or [bring-your-own models](https://docs.agenta.ai/prompt-management/adding-custom-providers?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme)
- **Version Control**: Version prompts and configurations with branching and environments
- **Complex Configurations**: Enable SMEs to collaborate on [complex configuration schemas](https://docs.agenta.ai/custom-workflows/overview?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme) beyond simple prompts

[Explore prompt management â†’](https://docs.agenta.ai/prompt-management/overview?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme)

### ğŸ“Š Evaluation &amp; Testing
Evaluate your LLM applications systematically with both human and automated feedback.
- **Flexible Test Sets**: Create test cases from production data, playground experiments, or upload CSVs
- **Pre-built and Custom Evaluators**: Use LLM-as-judge, one of our 20+ pre-built evaluators, or you custom evaluators
- **UI and API Access**: Run evaluations via UI (for SMEs) or programmatically (for engineers)
- **Human Feedback Integration**: Collect and incorporate expert annotations

[Explore evaluation frameworks â†’](https://docs.agenta.ai/evaluation/overview?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme)

### ğŸ“¡ Observability &amp; Monitoring
Get visibility into your LLM applications in production.
- **Cost &amp; Performance Tracking**: Monitor spending, latency, and usage patterns
- **Tracing**: Debug complex workflows with detailed traces
- **Open Standards**: OpenTelemetry native tracing compatible with OpenLLMetry, and OpenInference
- **Integrations**: Comes with pre-built integrations for most models and frameworks

[Learn about observability â†’](https://docs.agenta.ai/observability/overview?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme)

## ğŸ“¸ Screenshots

&lt;img alt=&quot;Playground&quot; src=&quot;https://imagedelivery.net/UNvjPBCIZFONpkVPQTxVuA/e7d16967-d564-4148-3615-03bfe2a29d00/large&quot; /&gt;
&lt;img alt=&quot;Prompt Management&quot; src=&quot;https://imagedelivery.net/UNvjPBCIZFONpkVPQTxVuA/b4210a13-b41e-4dfd-d383-4286fb011e00/large&quot; /&gt;
&lt;img alt=&quot;Evaluation&quot; src=&quot;https://imagedelivery.net/UNvjPBCIZFONpkVPQTxVuA/4b1c62b9-ff6e-4bd1-4c8d-de59b8485e00/large&quot; /&gt;
&lt;img  alt=&quot;Observability&quot; src=&quot;https://imagedelivery.net/UNvjPBCIZFONpkVPQTxVuA/5c764759-e525-499e-544a-1077c45e9600/large&quot; /&gt;

## ğŸš€ Getting Started 

### Agenta Cloud (Recommended):
The easiest way to get started is through Agenta Cloud. Free tier available with no credit card required.

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://cloud.agenta.ai?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme&quot;&gt;
      &lt;picture &gt;
        &lt;source width=&quot;200&quot; media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/3aa96780-b7e5-4b6f-bfee-8feaa36ff3b2&quot;  &gt;
        &lt;source width=&quot;200&quot; media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/3aa96780-b7e5-4b6f-bfee-8feaa36ff3b2&quot;  &gt;
        &lt;img alt=&quot;Try Agenta Live Demo&quot; src=&quot;https://github.com/user-attachments/assets/3aa96780-b7e5-4b6f-bfee-8feaa36ff3b2&quot; &gt;
      &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

  
   
### Self-hosting Agenta

1. Clone Agenta:
```bash
git clone https://github.com/Agenta-AI/agenta &amp;&amp; cd agenta
```

2. Start Agenta services:
```bash
docker compose -f hosting/docker-compose/oss/docker-compose.gh.yml --env-file hosting/docker-compose/oss/.env.oss.gh --profile with-web up -d
```

3. Access Agenta at `http://localhost`.

For deploying on a remote host, or using different ports refers to our [self-hosting](https://docs.agenta.ai/self-host/host-locally?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme) and [remote deployment documentation](https://docs.agenta.ai/self-host/host-remotely?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme).

## ğŸ’¬ Community

Find help, explore resources, or get involved:

### ğŸ§° Support

- **ğŸ“š [Documentation](https://docs.agenta.ai?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme)** â€“ Full guides and API reference  
- **ğŸ“‹ [Changelog](https://docs.agenta.ai/changelog/main?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme)** â€“ Track recent updates  
- **ğŸ’¬ [Slack Community](https://join.slack.com/t/agenta-hq/shared_invite/zt-2yewk6o2b-DmhyA4h_lkKwecDtIsj1AQ)** â€“ Ask questions and get support  

### ğŸ¤ Contribute

We welcome contributions of all kinds â€” from filing issues and sharing ideas to improving the codebase.

- **ğŸ› [Report bugs](https://github.com/Agenta-AI/agenta/issues)** â€“ Help us by reporting problems you encounter  
- **ğŸ’¡ [Share ideas and feedback](https://github.com/Agenta-AI/agenta/discussions)** â€“ Suggest features or vote on ideas
- **ğŸ”§ [Contribute to the codebase](https://docs.agenta.ai/misc/contributing/getting-started?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme)** â€“ Read the guide and open a pull request

## â­ Star Agenta

**Consider giving us a star!** It helps us grow our community and gets Agenta in front of more developers.
&lt;/br&gt;
&lt;/br&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/agenta-ai/agenta&quot;&gt;

  &lt;img width=&quot;300&quot; alt=&quot;Star us&quot; src=&quot;https://github.com/user-attachments/assets/2c8e580a-c930-4312-bf1b-08f631b41c62&quot; /&gt;
    &lt;a href=&quot;https://cloud.agenta.ai?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme&quot;&gt;

&lt;/p&gt;

## Contributors âœ¨

&lt;!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section --&gt;
[![All Contributors](https://img.shields.io/badge/all_contributors-49-orange.svg?style=flat-square)](#contributors-)
&lt;!-- ALL-CONTRIBUTORS-BADGE:END --&gt;

Thanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):

&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt;
&lt;!-- prettier-ignore-start --&gt;
&lt;!-- markdownlint-disable --&gt;
&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/SamMethnani&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/57623556?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Sameh Methnani&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sameh Methnani&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=SamMethnani&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=SamMethnani&quot; title=&quot;Documentation&quot;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/suadsuljovic&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/8658374?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Suad Suljovic&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Suad Suljovic&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=suadsuljovic&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt; &lt;a href=&quot;#design-suadsuljovic&quot; title=&quot;Design&quot;&gt;ğŸ¨&lt;/a&gt; &lt;a href=&quot;#mentoring-suadsuljovic&quot; title=&quot;Mentoring&quot;&gt;ğŸ§‘â€ğŸ«&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/pulls?q=is%3Apr+reviewed-by%3Asuadsuljovic&quot; title=&quot;Reviewed Pull Requests&quot;&gt;ğŸ‘€&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/burtenshaw&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/19620375?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;burtenshaw&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;burtenshaw&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=burtenshaw&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://abram.tech&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/55067204?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Abram&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Abram&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=aybruhm&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=aybruhm&quot; title=&quot;Documentation&quot;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://israelabebe.com&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/7479824?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Israel Abebe&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Israel Abebe&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/issues?q=author%3Avernu&quot; title=&quot;Bug reports&quot;&gt;ğŸ›&lt;/a&gt; &lt;a href=&quot;#design-vernu&quot; title=&quot;Design&quot;&gt;ğŸ¨&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=vernu&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/SohaibAnwaar&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/29427728?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Master X&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Master X&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=SohaibAnwaar&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://main-portfolio-26wv6oglp-witehound.vercel.app/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/26417477?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;corinthian&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;corinthian&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=witehound&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt; &lt;a href=&quot;#design-witehound&quot; title=&quot;Design&quot;&gt;ğŸ¨&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/Pajko97&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/25198892?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Pavle Janjusevic&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Pavle Janjusevic&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#infra-Pajko97&quot; title=&quot;Infrastructure (Hosting, Build-Tools, etc)&quot;&gt;ğŸš‡&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://kaosiso-ezealigo.netlify.app&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/99529776?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Kaosi Ezealigo&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Kaosi Ezealigo&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/issues?q=author%3Abekossy&quot; title=&quot;Bug reports&quot;&gt;ğŸ›&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=bekossy&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/albnunes&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/46302915?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Alberto Nunes&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Alberto Nunes&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/issues?q=author%3Aalbnunes&quot; title=&quot;Bug reports&quot;&gt;ğŸ›&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.linkedin.com/in/mohammed-maaz-6290b0116/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/17180132?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Maaz Bin Khawar&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Maaz Bin Khawar&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=MohammedMaaz&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/pulls?q=is%3Apr+reviewed-by%3AMohammedMaaz&quot; title=&quot;Reviewed Pull Requests&quot;&gt;ğŸ‘€&lt;/a&gt; &lt;a href=&quot;#mentoring-MohammedMaaz&quot; title=&quot;Mentoring&quot;&gt;ğŸ§‘â€ğŸ«&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/devgenix&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/56418363?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Nehemiah Onyekachukwu Emmanuel&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Nehemiah Onyekachukwu Emmanuel&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=devgenix&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt; &lt;a href=&quot;#example-devgenix&quot; title=&quot;Examples&quot;&gt;ğŸ’¡&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=devgenix&quot; title=&quot;Documentation&quot;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/philipokiokio&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/55271518?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Philip Okiokio&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Philip Okiokio&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=philipokiokio&quot; title=&quot;Documentation&quot;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://sweetdevil144.github.io/My-Website/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/117591942?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Abhinav Pandey&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Abhinav Pandey&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=Sweetdevil144&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/RamchandraWarang9822&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/92023869?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Ramchandra Warang&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ramchandra Warang&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=RamchandraWarang9822&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/issues?q=author%3ARamchandraWarang9822&quot; title=&quot;Bug reports&quot;&gt;ğŸ›&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/lazyfuhrer&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/64888892?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Biswarghya Biswas&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Biswarghya Biswas&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=lazyfuhrer&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/okieLoki&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/96105929?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Uddeepta Raaj Kashyap&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Uddeepta Raaj Kashyap&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=okieLoki&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://www.linkedin.com/in/nayeem-abdullah-317098141&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/32274108?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Nayeem Abdullah&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Nayeem Abdullah&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=nayeem01&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/kangsuhyun-yanolja&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/124246127?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Kang Suhyun&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Kang Suhyun&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=kangsuhyun-yanolja&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/yeokyeong-yanolja&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/128676129?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Yoon&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Yoon&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=yeokyeong-yanolja&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://mrkirthi24.netlify.app/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/53830546?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Kirthi Bagrecha Jain&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Kirthi Bagrecha Jain&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=mrkirthi-24&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/navdeep1840&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/80774259?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Navdeep&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Navdeep&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=navdeep1840&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.linkedin.com/in/rhythm-sharma-708a421a8/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/64489317?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Rhythm Sharma&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Rhythm Sharma&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=Rhythm-08&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://osinachi.me&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/40396070?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Osinachi Chukwujama &quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Osinachi Chukwujama &lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=vicradon&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://liduos.com/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/47264881?v

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Pennyw0rth/NetExec]]></title>
            <link>https://github.com/Pennyw0rth/NetExec</link>
            <guid>https://github.com/Pennyw0rth/NetExec</guid>
            <pubDate>Wed, 16 Apr 2025 00:04:49 GMT</pubDate>
            <description><![CDATA[The Network Execution Tool]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Pennyw0rth/NetExec">Pennyw0rth/NetExec</a></h1>
            <p>The Network Execution Tool</p>
            <p>Language: Python</p>
            <p>Stars: 4,020</p>
            <p>Forks: 452</p>
            <p>Stars today: 176 stars today</p>
            <h2>README</h2><pre>![Supported Python versions](https://img.shields.io/badge/python-3.10+-blue.svg)
[![Twitter](https://img.shields.io/twitter/follow/al3xn3ff?label=al3x_n3ff&amp;style=social)](https://twitter.com/intent/follow?screen_name=al3x_n3ff)
[![Twitter](https://img.shields.io/twitter/follow/_zblurx?label=_zblurx&amp;style=social)](https://twitter.com/intent/follow?screen_name=_zblurx)
[![Twitter](https://img.shields.io/twitter/follow/MJHallenbeck?label=MJHallenbeck&amp;style=social)](https://twitter.com/intent/follow?screen_name=MJHallenbeck)
[![Twitter](https://img.shields.io/twitter/follow/mpgn_x64?label=mpgn_x64&amp;style=social)](https://twitter.com/intent/follow?screen_name=mpgn_x64)


ğŸš© This is the open source repository of NetExec maintained by a community of passionate people
# NetExec - The Network Execution Tool

This project was initially created in 2015 by @byt3bl33d3r, known as CrackMapExec. In 2019 @mpgn_x64 started maintaining the project for the next 4 years, adding a lot of great tools and features. In September 2023 he retired from maintaining the project.

Along with many other contributors, we (NeffIsBack, Marshall-Hallenbeck, and zblurx) developed new features, bug fixes, and helped maintain the original project CrackMapExec.
During this time, with both a private and public repository, community contributions were not easily merged into the project. The 6-8 month discrepancy between the code bases caused many development issues and heavily reduced community-driven development.
With the end of mpgn&#039;s maintainer role, we (the remaining most active contributors) decided to maintain the project together as a fully free and open source project under the new name **NetExec** ğŸš€
Going forward, our intent is to maintain a community-driven and maintained project with regular updates for everyone to use.

&lt;p align=&quot;center&quot;&gt;
  &lt;!-- placeholder for nxc logo--&gt;
&lt;/p&gt;

You are on the **latest up-to-date** repository of the project NetExec (nxc) ! ğŸ‰

- ğŸš§ If you want to report a problem, open an [Issue](https://github.com/Pennyw0rth/NetExec/issues) 
- ğŸ”€ If you want to contribute, open a [Pull Request](https://github.com/Pennyw0rth/NetExec/pulls)
- ğŸ’¬ If you want to discuss, open a [Discussion](https://github.com/Pennyw0rth/NetExec/discussions)

## Official Discord Channel

If you don&#039;t have a Github account, you can ask your questions on Discord!

[![NetExec](https://discordapp.com/api/guilds/1148685154601160794/widget.png?style=banner3)](https://discord.gg/pjwUTQzg8R)

# Documentation, Tutorials, Examples
See the project&#039;s [wiki](https://netexec.wiki/) (in development) for documentation and usage examples

# Installation
Please see the installation instructions on the [wiki](https://netexec.wiki/getting-started/installation) (in development)

## Linux
```
sudo apt install pipx git
pipx ensurepath
pipx install git+https://github.com/Pennyw0rth/NetExec
```

## Availability on Unix distributions

[![Packaging status](https://repology.org/badge/vertical-allrepos/netexec.svg)](https://repology.org/project/netexec/versions)

# Development
Development guidelines and recommendations in development

# Acknowledgments
All the hard work and development over the years from everyone in the CrackMapExec project

# Code Contributors
Awesome code contributors of NetExec:

[![](https://github.com/mpgn.png?size=50)](https://github.com/mpgn)
[![](https://github.com/Marshall-Hallenbeck.png?size=50)](https://github.com/Marshall-Hallenbeck)
[![](https://github.com/zblurx.png?size=50)](https://github.com/zblurx)
[![](https://github.com/NeffIsBack.png?size=50)](https://github.com/NeffIsBack)
[![](https://github.com/Hackndo.png?size=50)](https://github.com/Hackndo)
[![](https://github.com/XiaoliChan.png?size=50)](https://github.com/XiaoliChan)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[potpie-ai/potpie]]></title>
            <link>https://github.com/potpie-ai/potpie</link>
            <guid>https://github.com/potpie-ai/potpie</guid>
            <pubDate>Wed, 16 Apr 2025 00:04:48 GMT</pubDate>
            <description><![CDATA[Prompt-To-Agent : Create custom engineering agents for your codebase]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/potpie-ai/potpie">potpie-ai/potpie</a></h1>
            <p>Prompt-To-Agent : Create custom engineering agents for your codebase</p>
            <p>Language: Python</p>
            <p>Stars: 3,398</p>
            <p>Forks: 328</p>
            <p>Stars today: 152 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://potpie.ai?utm_source=github&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/1a0b9824-833b-4c0a-b56d-ede5623295ca&quot; width=&quot;318px&quot; alt=&quot;Momentum logo&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;br/&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/12918&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/12918&quot; alt=&quot;potpie-ai%2Fpotpie | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/br&gt;
  &lt;br /&gt;
  &lt;a href=&quot;https://app.potpie.ai&quot; rel=&quot;dofollow&quot;&gt;App&lt;/a&gt; | &lt;a href=&quot;https://docs.potpie.ai&quot; rel=&quot;dofollow&quot;&gt;Documentation&lt;/a&gt; | &lt;a href=&quot;https://docs.potpie.ai/open-source&quot;  rel=&quot;dofollow&quot;&gt;API Reference&lt;/a&gt; | &lt;a href=&quot;https://app.potpie.ai/newchat?repo=potpie-ai/potpie&amp;branch=main&quot; rel=&quot;dofollow&quot;&gt;Chat with ğŸ¥§ Repo&lt;/a&gt;
  &lt;br /&gt;

  &lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;

  &lt;a href=&quot;https://github.com/potpie-ai/potpie/blob/main/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/potpie-ai/potpie&quot; alt=&quot;Apache 2.0&quot;&gt;
  &lt;/a&gt;

  &lt;a href=&quot;https://github.com/potpie-ai/potpie&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/stars/potpie-ai/potpie&quot; alt=&quot;GitHub Repo stars&quot;&gt;
  &lt;/a&gt;

&lt;/br&gt;


&lt;a href=&quot;https://discord.gg/ryk5CMD5v6&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Join%20our-Discord-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;Join our Discord&quot;&gt;
&lt;/a&gt;
&lt;/br&gt;
&lt;a href=&quot;https://marketplace.visualstudio.com/items?itemName=PotpieAI.potpie-vscode-extension&quot;&gt;
    &lt;img src=&quot;https://custom-icon-badges.demolab.com/badge/Visual%20Studio%20Code-0078d7.svg?logo=vsc&amp;logoColor=white&quot; alt=&quot;VS Code Extension&quot;&gt;
&lt;/a&gt;
&lt;/br&gt;
&lt;a href=&quot;https://twitter.com/intent/tweet?text=I%20created%20custom%20engineering%20agents%20for%20my%20codebase%20in%20minutes%20with%20potpie.ai%20@potpiedotai%20!ğŸ¥§&quot;&gt;
    &lt;img alt=&quot;tweet&quot; src=&quot;https://img.shields.io/twitter/url/http/shields.io.svg?style=social&quot;&gt;
&lt;/a&gt;

&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;

Prompt-To-Agent: Create custom engineering agents for your code
&lt;/h1&gt;

Potpie is an open-source platform that creates AI agents specialized in your codebase, enabling automated code analysis, testing, and development tasks. By building a comprehensive knowledge graph of your code, Potpie&#039;s agents can understand complex relationships and assist with everything from debugging to feature development.

&lt;p align=&quot;center&quot;&gt;
&lt;img width=&quot;1506&quot; alt=&quot;Screenshot 2025-03-28 at 2 51 34â€¯PM&quot; src=&quot;https://github.com/user-attachments/assets/dc45286f-4aa6-46d1-950f-cc77ceccce3d&quot; /&gt;

&lt;/p&gt;

## ğŸ“š Table of Contents
- [ğŸ¥§ Why Potpie?](#why-potpie)
- [ğŸ¤– Our Prebuilt Agents](#prebuilt-agents)
- [ğŸ› ï¸ Tooling](#potpies-tooling-system)
- [ğŸš€ Getting Started](#getting-started)
- [ğŸ’¡ Use Cases](#use-cases)
- [ğŸ› ï¸ Custom Agents](#custom-agents-upgrade)
- [ğŸ—ï¸ Accessing Agents via API Key](#accessing-agents-via-api-key)
- [ğŸ¨ Make Potpie Your Own](#make-potpie-your-own)
- [ğŸ¤ Contributing](#contributing)
- [ğŸ“œ License](#license)
- [ğŸ’ª Contributors](#-thanks-to-all-contributors)


## ğŸ¥§ Why Potpie?
- ğŸ§  **Deep Code Understanding**: Built-in knowledge graph captures relationships between code components
- ğŸ¤– **Pre-built &amp; Custom Agents**: Ready-to-use agents for common tasks + build your own
- ğŸ”„ **Seamless Integration**: Works with your existing development workflow
- ğŸ“ˆ **Flexible**: Handles codebases of any size or language


## ğŸ”Œ VSCode Extension

Bring the power of Potpie&#039;s AI agents directly into your development environment with our VSCode extension:

- **Direct Integration**: Access all Potpie agents without leaving your editor
- **Quick Setup**: Install directly from the [VSCode Marketplace](https://marketplace.visualstudio.com/items?itemName=PotpieAI.potpie-vscode-extension)
- **Seamless Workflow**: Ask questions, get explanations, and implement suggestions right where you code


## ğŸ¤– Potpie&#039;s Prebuilt Agents

Potpie offers a suite of specialized codebase agents for automating and optimizing key aspects of software development:

- **Debugging Agent**: Automatically analyzes stacktraces and provides debugging steps specific to your codebase.
- **Codebase Q&amp;A Agent**: Answers questions about your codebase and explains functions, features, and architecture.
- **Code Changes Agent**: Analyzes code changes, identifies affected APIs, and suggests improvements before merging.
- **Integration Test Agent**: Generates integration test plans and code for flows to ensure components work together properly.
- **Unit Test Agent**: Automatically creates unit test plan and code for individual functions to enhance test coverage.
- **LLD Agent**: Creates a low level design for implementing a new feature by providing functional requirements to this agent.
- **Code Generation Agent**: Generates code for new features, refactors existing code, and suggests optimizations.

## ğŸ› ï¸ Potpie&#039;s Tooling System

Potpie provides a set of tools that agents can use to interact with the knowledge graph and the underlying infrastructure:

- **get_code_from_probable_node_name**: Retrieves code snippets based on a probable node name.
- **get_code_from_node_id**: Fetches code associated with a specific node ID.
- **get_code_from_multiple_node_ids**: Retrieves code snippets for multiple node IDs simultaneously.
- **ask_knowledge_graph_queries**: Executes vector similarity searches to obtain relevant information.
- **get_nodes_from_tags**: Retrieves nodes tagged with specific keywords.
- **get_code_graph_from_node_id/name**: Fetches code graph structures for a specific node.
- **change_detection**: Detects changes in the current branch compared to the default branch.
- **get_code_file_structure**: Retrieves the file structure of the codebase.

## ğŸš€ Getting Started

### Prerequisites
- Docker installed and running
- Git installed (for repository access)
- Python 3.10.x

### Potpie UI
  An easy to use interface to interact with your Agents
  ## Initialize the UI Submodule
  To initialize the submodule:

  ```bash
  git submodule update --init
  ```

  ### 1. Navigate to the `potpie-ui` Directory

  ```bash
  cd potpie-ui
  ```

  ### 2. Update the Main Branch and Checkout

  ```bash
  git checkout main
  git pull origin main
  ```

  ### 3. Set Up the Environment

  Create a `.env` file in the `potpie-ui` directory and copy the required configuration from `.env.template`.

  ```bash
  cp .env.template .env
  ```

  ### 4. Build the Frontend

  ```bash
  pnpm build
  ```

  ### 5. Start the Application

  ```bash
  pnpm start
  ```


### Setup Steps

**Install Python 3.10**
   - Download and install Python 3.10 from the official Python website:
     https://www.python.org/downloads/release/python-3100/

1. **Prepare Your Environment**
   - Create a `.env` file based on the `.env.template`
   - Add the following required configurations:
      ```bash
      isDevelopmentMode=enabled
      ENV=development
      POSTGRES_SERVER=postgresql://postgres:mysecretpassword@localhost:5432/momentum
      NEO4J_URI=bolt://127.0.0.1:7687
      NEO4J_USERNAME=neo4j
      NEO4J_PASSWORD=mysecretpassword
      REDISHOST=127.0.0.1
      REDISPORT=6379
      BROKER_URL=redis://127.0.0.1:6379/0
      CELERY_QUEUE_NAME=dev
      defaultUsername=defaultuser
      PROJECT_PATH=projects #repositories will be downloaded/cloned to this path on your system.
      {PROVIDER}_API_KEY=sk-proj-your-key #your provider key e.g. ANTHROPIC_API_KEY for Anthropic
      INFERENCE_MODEL=ollama_chat/qwen2.5-coder:7b #provider model name
      CHAT_MODEL=ollama_chat/qwen2.5-coder:7b #provider model name
      ```
      **`INFERENCE_MODEL`** and **`CHAT_MODEL`** correspond to the models that will be used for generating knowledge graph and for agent reasoning respectively. These model names should be in the format of `provider/model_name` format or as expected by Litellm. For more information, refer to the [Litellm documentation](https://docs.litellm.ai/docs/providers).
      &lt;br&gt;
   -  Create a Virtual Environment using Python 3.10:
      ```
      python3.10 -m venv venv
      source venv/bin/activate

    - Install dependencies in your venv:
      ```bash
      pip install -r requirements.txt

2. **Start Potpie**

   ```bash
   chmod +x start.sh
   ./start.sh

3. **Authentication Setup** (Skip this step in development mode)
   ```bash
   curl -X POST &#039;http://localhost:8001/api/v1/login&#039; \
     -H &#039;Content-Type: application/json&#039; \
     -d &#039;{
       &quot;email&quot;: &quot;your-email&quot;,
       &quot;password&quot;: &quot;your-password&quot;
     }&#039;
   # Save the bearer token from the response for subsequent requests

4. **Initialize Repository Parsing**
   ```bash
   # For development mode:
   curl -X POST &#039;http://localhost:8001/api/v1/parse&#039; \
     -H &#039;Content-Type: application/json&#039; \
     -d &#039;{
       &quot;repo_path&quot;: &quot;path/to/local/repo&quot;,
       &quot;branch_name&quot;: &quot;main&quot;
     }&#039;

   # For production mode:
   curl -X POST &#039;http://localhost:8001/api/v1/parse&#039; \
     -H &#039;Content-Type: application/json&#039; \
     -d &#039;{
       &quot;repo_name&quot;: &quot;owner/repo-name&quot;,
       &quot;branch_name&quot;: &quot;main&quot;
     }&#039;
   # Save the project_id from the response

5. **Monitor Parsing Status**
   ```bash
   curl -X GET &#039;http://localhost:8001/api/v1/parsing-status/your-project-id&#039;
   # Wait until parsing is complete

6. **View Available Agents**
   ```bash
   curl -X GET &#039;http://localhost:8001/api/v1/list-available-agents/?list_system_agents=true&#039;
   # Note down the agent_id you want to use
   ```

7. **Create a Conversation**
   ```bash
   curl -X POST &#039;http://localhost:8001/api/v1/conversations/&#039; \
     -H &#039;Content-Type: application/json&#039; \
     -d &#039;{
       &quot;user_id&quot;: &quot;your_user_id&quot;,
       &quot;title&quot;: &quot;My First Conversation&quot;,
       &quot;status&quot;: &quot;active&quot;,
       &quot;project_ids&quot;: [&quot;your-project-id&quot;],
       &quot;agent_ids&quot;: [&quot;chosen-agent-id&quot;]
     }&#039;
   # Save the conversation_id from the response

8. **Start Interacting with Your Agent**
   ```bash
   curl -X POST &#039;http://localhost:8001/api/v1/conversations/your-conversation-id/message/&#039; \
     -H &#039;Content-Type: application/json&#039; \
     -d &#039;{
       &quot;content&quot;: &quot;Your question or request here&quot;,
       &quot;node_ids&quot;:[]
     }&#039;
   ```

9. **View Conversation History** (Optional)
   ```bash
   curl -X GET &#039;http://localhost:8001/api/v1/conversations/your-conversation-id/messages/?start=0&amp;limit=10&#039;
   ```

## ğŸ’¡ Use Cases

- **Onboarding**: For developers new to a codebase, the codebase QnA agent helps them understand the codebase and get up to speed quickly. Ask it how to setup a new project, how to run the tests etc
&gt;We tried to onboard ourselves with Potpie to the [**AgentOps**](https://github.com/AgentOps-AI/AgentOps) codebase and it worked like a charm : Video [here](https://youtu.be/_mPixNDn2r8).

- **Codebase Understanding**: Answer questions about any library you&#039;re integrating, explain functions, features, and architecture.
&gt;We used the Q&amp;A agent to understand the underlying working of a feature of the [**CrewAI**](https://github.com/CrewAIInc/CrewAI) codebase that was not documented in official docs : Video [here](https://www.linkedin.com/posts/dhirenmathur_what-do-you-do-when-youre-stuck-and-even-activity-7256704603977613312-8X8G).

- **Low Level Design**: Get detailed implementation plans for new features or improvements before writing code.
&gt;We fed an open issue from the [**Portkey-AI/Gateway**](https://github.com/Portkey-AI/Gateway) project to this agent to generate a low level design for it: Video [here](https://www.linkedin.com/posts/dhirenmathur_potpie-ai-agents-vs-llms-i-am-extremely-activity-7255607456448286720-roOC).

- **Reviewing Code Changes**: Understand the functional impact of changes and compute the blast radius of modifications.

- **Debugging**: Get step-by-step debugging guidance based on stacktraces and codebase context.

- **Testing**: Generate contextually aware unit and integration test plans and test code that understand your codebase&#039;s structure and purpose.

## ğŸ› ï¸ Custom Agents [Upgrade âœ¨](https://potpie.ai/pricing)

With Custom Agents, you can design personalized tools that handle repeatable tasks with precision. Key components include:
- **System Instructions**: Define the agent&#039;s task, goal, and expected output
- **Agent Information**: Metadata about the agent&#039;s role and context
- **Tasks**: Individual steps for job completion
- **Tools**: Functions for querying the knowledge graph or retrieving code

## ğŸ—ï¸ Accessing Agents via API Key

You can access Potpie Agents through an API key, enabling integration into CI/CD workflows and other automated processes. For detailed instructions, please refer to the [Potpie API documentation](https://docs.potpie.ai/agents/api-access).

- **Generate an API Key**: Easily create an API key for secure access.
- **Parse Repositories**: Use the Parse API to analyze code repositories and obtain a project ID.
- **Monitor Parsing Status**: Check the status of your parsing requests.
- **Create Conversations**: Initiate conversations with specific agents using project and agent IDs adn get a conversation id.
- **Send Messages**: Communicate with agents by sending messages within a conversation.

## ğŸ¨ Make Potpie Your Own

Potpie is designed to be flexible and customizable. Here are key areas to personalize your own deployment:

### **Effortless Agent Creation**:
Design custom agents tailored to your specific tasks using a single prompt. Utilize the following API to create your custom agents:

  ```bash
  curl -X POST &quot;http://localhost:8001/api/v1/custom-agents/agents/auto&quot; \
       -H &quot;Content-Type: application/json&quot; \
       -d &#039;{
             &quot;prompt&quot;: &quot;Aan agent that takes stacktrace as input and gives root cause analysis and proposed solution as output&quot;
           }&#039;
  ```

  Read more about other custom agent APIs to edit and delete your custom agents in our [documentation](https://docs.potpie.ai/open-source/agents/create-agent-from-prompt).

### Tool Integration
Edit or add tools in the `app/modules/intelligence/tools` directory for your custom agents.
Initialise the tools in the  `app/modules/intelligence/tools/tool_service.py` file and include them in your agent.

## ğŸ¤ Contributing

We welcome contributions! To contribute:
1. Fork the repository
2. Create a new branch (`git checkout -b feature-branch`)
3. Make your changes
4. Commit (`git commit -m &#039;Add new feature&#039;`)
5. Push to the branch (`git push origin feature-branch`)
6. Open a Pull Request

See [Contributing Guide](./contributing.md) for more details.

## ğŸ“œ License

This project is licensed under the Apache 2.0 License - see the [LICENSE](LICENSE) file for details.

## ğŸ’ª Thanks To All Contributors

Thanks for spending your time helping build Potpie. Keep rocking ğŸ¥‚

&lt;img src=&quot;https://contributors-img.web.app/image?repo=potpie-ai/potpie&quot; alt=&quot;Contributors&quot;/&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[TarlogicSecurity/BlueSpy]]></title>
            <link>https://github.com/TarlogicSecurity/BlueSpy</link>
            <guid>https://github.com/TarlogicSecurity/BlueSpy</guid>
            <pubDate>Wed, 16 Apr 2025 00:04:47 GMT</pubDate>
            <description><![CDATA[PoC to record audio from a Bluetooth device]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/TarlogicSecurity/BlueSpy">TarlogicSecurity/BlueSpy</a></h1>
            <p>PoC to record audio from a Bluetooth device</p>
            <p>Language: Python</p>
            <p>Stars: 1,195</p>
            <p>Forks: 160</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre># BlueSpy - PoC to record audio from a Bluetooth device

![BlueSpy script](resources/BlueSpy.png)

This repository contains the implementation of a proof of concept to record and replay audio from a bluetooth device without the legitimate user&#039;s awareness.

The PoC was demonstrated during the talk **BSAM: Seguridad en Bluetooth** at **RootedCON 2024** in Madrid.

It&#039;s designed to raise awareness about the insecure use of Bluetooth devices, and the need of a consistent methodology for security evaluations. That&#039;s the purpose of **BSAM, the Bluetooth Security Assessment Methodology**, published by Tarlogic and available [here](https://www.tarlogic.com/bsam/).

This proof of concept exploits the failure to comply with the [**BSAM-PA-05 control**](https://www.tarlogic.com/bsam/controls/bluetooth-pairing-without-interaction/) within the BSAM methodology. Consequently, the device enables the pairing procedure without requiring user interaction and exposes its functionality to any agent within the signal range.

More information on our [blog](https://www.tarlogic.com/blog/bluespy-spying-on-bluetooth-conversations/).

## Requirements

The code is written in Python and has been tested with Python 3.11.8, but it mainly uses widely available tools in Linux systems.

The PoC uses the following tools:
+ `bluetoothctl`
+ `btmgmt`
+ `pactl`
+ `parecord`
+ `paplay`

In Arch Linux distributions, `bluetoothctl` and `btmgmt` can be installed with the package `bluez-utils`, while `pactl`, `parecord` and `paplay` are available in the `libpulse` package.

For the PoC to work, it is necessary to have a working installation of the BlueZ Bluetooth stack, available in the `bluez`package for Arch Linux distributions. A working installation of an audio server compatible with PulseAudio, such as PipeWire, is also required to record and play audio.

## Setup

Ensure that your device is capable of functioning as an audio source, meaning it has a microphone, and that it is discoverable and connectable via Bluetooth.

For instance, to be discoverable and connectable, the earbuds used during the talk must be outside of their charging case. By default, they only activate the microphone when placed in the user&#039;s ears, although this setting can be adjusted in the configuration app.

Additionally, ensure that the device is not already connected, or alternatively, that it supports multiple connections.

## Execution

Firstly, the address of the device must be discovered using a tool such as `bluetoothctl`:

```
$ bluetoothctl
[bluetooth]# scan on
```

Once the address of the device is discovered, the script can handle the rest:

```
$ python BlueSpy.py -a &lt;address&gt;
```

Note: The script might prompt for superuser permissions to modify the configuration of your **BlueZ** instance and pair it with the remote device.

## Troubleshooting

`BlueSpy.py` is the main script that executes every step of the process. However, if you encounter issues with any of the phases, so it might be helpful to execute them individually:
+ `pair.py` utilizes the command-line tool `btmgmt` to modify the configuration of your **BlueZ** and initiate a pairing process with the remote device. The exact commands used are in the `pair` function inside `core.py`.
+ `connect.py` utilizes the command-line tool `bluetoothctl` to initiate a quick scan (necessary for BlueZ) and establish a connection to the device. The exact commands used are in the `connect` function inside `core.py`.
+ `just_record.py` utilizes the command-line tools `pactl` and `parecord` to search for the device in the system&#039;s audio sources (it must function as a microphone) and initiate a recording session. The exact commands used are in the `record` function inside `core.py`.
+ The `playback` function inside `core.py` executes `paplay` to play back the captured audio.

If you encounter issues with any of the phases, examine the commands in `core.py` and try to execute them in a shell. This will provide more information on what may be failing.

## References

If you have any questions regarding how the Bluetooth standard operates or how to assess the security of a Bluetooth device, please refer to our BSAM methodology webpage:
+ [BSAM: Bluetooth Security Assessment Methodology](https://www.tarlogic.com/bsam/)

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[AI-Hypercomputer/RecML]]></title>
            <link>https://github.com/AI-Hypercomputer/RecML</link>
            <guid>https://github.com/AI-Hypercomputer/RecML</guid>
            <pubDate>Wed, 16 Apr 2025 00:04:46 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/AI-Hypercomputer/RecML">AI-Hypercomputer/RecML</a></h1>
            <p></p>
            <p>Language: Python</p>
            <p>Stars: 159</p>
            <p>Forks: 10</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre># RecML: High-Performance Recommender Library

## Vision

RecML is envisioned as a high-performance, large-scale deep learning recommender
system library optimized for Cloud TPUs. It aims to provide researchers and
practitioners state-of-the-art reference implementations, tools, and best
practice guidelines for building and deploying recommender systems.

The key goals of RecML are:

*   **Performance &amp; Scalability:** Leverage Cloud TPUs (including SparseCore
    acceleration) to deliver exceptional performance for training and serving
    massive models with large embeddings on datasets with millions or billions
    of items/users. RecML can additionally target Cloud GPUs.
*   **State-of-the-Art Models:** Provide production-ready, easy-to-understand
    reference implementations of popular and cutting-edge models, with a strong
    focus on LLM-based recommenders.
*   **Ease of Use:** Offer a user-friendly API, intuitive abstractions, and
    comprehensive documentation/examples for rapid prototyping and deployment.
*   **Flexibility:** Primarily built with Keras and JAX, but designed with
    potential future expansion to other frameworks like PyTorch/XLA.
*   **Open Source:** Foster community collaboration and provide components to
    help users get started with advanced recommender workloads on Google Cloud.

## Features

*   **High Performance:** Optimized for Cloud TPU (SparseCore) training and
    inference.
*   **Scalable Architecture:** Designed for massive datasets and models with
    large embedding tables. Includes support for efficient data loading
    (tf.data, potentially Grain) and sharding/SPMD.
*   **State-of-the-Art Model Implementations:** Reference implementations for
    various recommendation tasks (ranking, retrieval, sequential).
*   **Reusable Building Blocks:**
    *   Common recommendation layers (e.g., DCN, BERT4Rec).
    *   Specialized Embedding APIs (e.g. JAX Embedding API for SparseCore).
    *   Standardized metrics (e.g., AUC, Accuracy, NDCG@K, MRR, Recall@K).
    *   Common loss functions.
*   **Unified Trainer:** A high-level trainer abstraction capable of targeting
    different hardware (TPU/GPU) and frameworks. Includes customizable training
    and evaluation loops.
*   **End-to-End Support:** Covers aspects from data pipelines to training,
    evaluation, checkpointing, metrics logging (e.g., to BigQuery), and model
    export/serving considerations.

## Models Included

This library aims to house implementations for a variety of recommender models,
including:

*   **SASRec:** Self-Attention based Sequential Recommendation
*   **BERT4Rec:** Bidirectional Encoder Representations from Transformer for
    Sequential Recommendation.
*   **Mamba4Rec:** Efficient Sequential Recommendation with Selective State
    Space Models.
*   **HSTU:** Hierarchical Sequential Transduction Units for Generative
    Recommendations.
*   **DLRM v2:** Deep Learning Recommendation Model

## Roadmap / Future Work

*   Expand reference model implementations (Retrieval, Uplift, foundation user
    model).
*   Add support for optimized configurations and lower precision training
    (bfloat16, fp16).
*   Improve support for Cloud GPU training and inference
*   Enhance sharding and quantization support.
*   Improve integration with Keras (and Keras Recommenders) and potentially
    PyTorch/XLA.
*   Develop comprehensive model serving examples and integrations.
*   Refine data loading pipelines (e.g., Grain support).
*   Add more common layers, losses, and metrics.

## Responsible Use

As with any machine learning model, potential risks exist. The performance and
behavior depend heavily on the training data, which may contain biases reflected
in the recommendations. Developers should carefully evaluate the model&#039;s
fairness and potential limitations in their specific application context.

## License

RecML is released under the Apache 2.0. Please see the `LICENSE` file for full
details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[pathwaycom/pathway]]></title>
            <link>https://github.com/pathwaycom/pathway</link>
            <guid>https://github.com/pathwaycom/pathway</guid>
            <pubDate>Wed, 16 Apr 2025 00:04:45 GMT</pubDate>
            <description><![CDATA[Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pathwaycom/pathway">pathwaycom/pathway</a></h1>
            <p>Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.</p>
            <p>Language: Python</p>
            <p>Stars: 24,463</p>
            <p>Forks: 355</p>
            <p>Stars today: 505 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pathway.com/&quot;&gt;
    &lt;img src=&quot;https://pathway.com/logo-light.svg&quot;/&gt;
  &lt;/a&gt;
  &lt;br /&gt;&lt;br /&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/10388&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/10388&quot; alt=&quot;pathwaycom%2Fpathway | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
  &lt;br /&gt;&lt;br /&gt;
&lt;/div&gt;
&lt;p align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml&quot;&gt;
        &lt;img src=&quot;https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml/badge.svg&quot; alt=&quot;ubuntu&quot;/&gt;
        &lt;br&gt;
        &lt;a href=&quot;https://github.com/pathwaycom/pathway/actions/workflows/release.yml&quot;&gt;
        &lt;img src=&quot;https://github.com/pathwaycom/pathway/actions/workflows/release.yml/badge.svg&quot; alt=&quot;Last release&quot;/&gt;&lt;/a&gt;
        &lt;a href=&quot;https://badge.fury.io/py/pathway&quot;&gt;&lt;img src=&quot;https://badge.fury.io/py/pathway.svg&quot; alt=&quot;PyPI version&quot; height=&quot;18&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://badge.fury.io/py/pathway&quot;&gt;&lt;img src=&quot;https://static.pepy.tech/badge/pathway&quot; alt=&quot;PyPI downloads&quot; height=&quot;18&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://github.com/pathwaycom/pathway/blob/main/LICENSE.txt&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/license-BSL-green&quot; alt=&quot;License: BSL&quot;/&gt;&lt;/a&gt;
      &lt;br&gt;
        &lt;a href=&quot;https://discord.gg/pathway&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1042405378304004156?logo=discord&quot;
            alt=&quot;chat on Discord&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=pathway_com&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/pathwaycom&quot;
            alt=&quot;follow on Twitter&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://linkedin.com/company/pathway&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/pathway-0077B5?style=social&amp;logo=linkedin&quot; alt=&quot;follow on LinkedIn&quot;&gt;&lt;/a&gt;
      &lt;a href=&quot;https://github.com/dylanhogg/awesome-python/blob/main/README.md&quot;&gt;
      &lt;img src=&quot;https://awesome.re/badge.svg&quot; alt=&quot;Awesome Python&quot;&gt;&lt;/a&gt;
      &lt;a href=&quot;https://gurubase.io/g/pathway&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Gurubase-Ask%20Pathway%20Guru-006BFF&quot; alt=&quot;Pathway Guru&quot;&gt;&lt;/a&gt;
    &lt;br&gt;
    &lt;a href=&quot;#getting-started&quot;&gt;Getting Started&lt;/a&gt; |
    &lt;a href=&quot;#deployment&quot;&gt;Deployment&lt;/a&gt; |
    &lt;a href=&quot;#resources&quot;&gt;Documentation and Support&lt;/a&gt; |
    &lt;a href=&quot;https://pathway.com/blog/&quot;&gt;Blog&lt;/a&gt; |
    &lt;a href=&quot;#license&quot;&gt;License&lt;/a&gt;

  
&lt;/p&gt;

# Pathway&lt;a id=&quot;pathway&quot;&gt; Live Data Framework&lt;/a&gt;

[Pathway](https://pathway.com) is a Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.

Pathway comes with an **easy-to-use Python API**, allowing you to seamlessly integrate your favorite Python ML libraries.
Pathway code is versatile and robust: **you can use it in both development and production environments, handling both batch and streaming data effectively**.
The same code can be used for local development, CI/CD tests, running batch jobs, handling stream replays, and processing data streams.

Pathway is powered by a **scalable Rust engine** based on Differential Dataflow and performs incremental computation.
Your Pathway code, despite being written in Python, is run by the Rust engine, enabling multithreading, multiprocessing, and distributed computations.
All the pipeline is kept in memory and can be easily deployed with **Docker and Kubernetes**.

You can install Pathway with pip:
```
pip install -U pathway
```

For any questions, you will find the community and team behind the project [on Discord](https://discord.com/invite/pathway).

## Use-cases and templates

Ready to see what Pathway can do?

[Try one of our easy-to-run examples](https://pathway.com/developers/templates)!

Available in both notebook and docker formats, these ready-to-launch examples can be launched in just a few clicks. Pick one and start your hands-on experience with Pathway today!

### Event processing and real-time analytics pipelines
With its unified engine for batch and streaming and its full Python compatibility, Pathway makes data processing as easy as possible. It&#039;s the ideal solution for a wide range of data processing pipelines, including:

- [Showcase: Real-time ETL.](https://pathway.com/developers/templates/kafka-etl)
- [Showcase: Event-driven pipelines with alerting.](https://pathway.com/developers/templates/realtime-log-monitoring)
- [Showcase: Realtime analytics.](https://pathway.com/developers/templates/linear_regression_with_kafka/)
- [Docs: Switch from batch to streaming.](https://pathway.com/developers/user-guide/connecting-to-data/switch-from-batch-to-streaming)



### AI Pipelines

Pathway provides dedicated LLM tooling to build live LLM and RAG pipelines. Wrappers for most common LLM services and utilities are included, making working with LLMs and RAGs pipelines incredibly easy. Check out our [LLM xpack documentation](https://pathway.com/developers/user-guide/llm-xpack/overview).

Don&#039;t hesitate to try one of our runnable examples featuring LLM tooling.
You can find such examples [here](https://pathway.com/developers/user-guide/llm-xpack/llm-examples).

  - [Template: Unstructured data to SQL on-the-fly.](https://pathway.com/developers/templates/unstructured-to-structured/)
  - [Template: Private RAG with Ollama and Mistral AI](https://pathway.com/developers/templates/private-rag-ollama-mistral)
  - [Template: Adaptive RAG](https://pathway.com/developers/templates/adaptive-rag)
  - [Template: Multimodal RAG with gpt-4o](https://pathway.com/developers/templates/multimodal-rag)

## Features

- **A wide range of connectors**: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector.
- **Stateless and stateful transformations**: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data.
- **Persistence**: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!
- **Consistency**: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the &quot;at least once&quot; consistency while the enterprise version provides the &quot;exactly once&quot; consistency.
- **Scalable Rust engine**: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can easily do multithreading, multiprocessing, and distributed computations.
- **LLM helpers**: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents.


## Getting started&lt;a id=&quot;getting-started&quot;&gt;&lt;/a&gt;

### Installation&lt;a id=&quot;installation&quot;&gt;&lt;/a&gt;

Pathway requires Python 3.10 or above.

You can install the current release of Pathway using `pip`:

```
$ pip install -U pathway
```

âš ï¸ Pathway is available on MacOS and Linux. Users of other systems should run Pathway on a Virtual Machine.


### Example: computing the sum of positive values in real time.&lt;a id=&quot;example&quot;&gt;&lt;/a&gt;

```python
import pathway as pw

# Define the schema of your data (Optional)
class InputSchema(pw.Schema):
  value: int

# Connect to your data using connectors
input_table = pw.io.csv.read(
  &quot;./input/&quot;,
  schema=InputSchema
)

#Define your operations on the data
filtered_table = input_table.filter(input_table.value&gt;=0)
result_table = filtered_table.reduce(
  sum_value = pw.reducers.sum(filtered_table.value)
)

# Load your results to external systems
pw.io.jsonlines.write(result_table, &quot;output.jsonl&quot;)

# Run the computation
pw.run()
```

Run Pathway [in Google Colab](https://colab.research.google.com/drive/1aBIJ2HCng-YEUOMrr0qtj0NeZMEyRz55?usp=sharing).

You can find more examples [here](https://github.com/pathwaycom/pathway/tree/main/examples).


## Deployment&lt;a id=&quot;deployment&quot;&gt;&lt;/a&gt;

### Locally&lt;a id=&quot;running-pathway-locally&quot;&gt;&lt;/a&gt;

To use Pathway, you only need to import it:

```python
import pathway as pw
```

Now, you can easily create your processing pipeline, and let Pathway handle the updates. Once your pipeline is created, you can launch the computation on streaming data with a one-line command:

```python
pw.run()
```

You can then run your Pathway project (say, `main.py`) just like a normal Python script: `$ python main.py`.
Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages. 

&lt;img src=&quot;https://d14l3brkh44201.cloudfront.net/pathway-dashboard.png&quot; width=&quot;1326&quot; alt=&quot;Pathway dashboard&quot;/&gt;

Alternatively, you can use the pathway&#039;ish version:

```
$ pathway spawn python main.py
```

Pathway natively supports multithreading.
To launch your application with 3 threads, you can do as follows:
```
$ pathway spawn --threads 3 python main.py
```

To jumpstart a Pathway project, you can use our [cookiecutter template](https://github.com/pathwaycom/cookiecutter-pathway).


### Docker&lt;a id=&quot;docker&quot;&gt;&lt;/a&gt;

You can easily run Pathway using docker.

#### Pathway image

You can use the [Pathway docker image](https://hub.docker.com/r/pathwaycom/pathway), using a Dockerfile:

```dockerfile
FROM pathwaycom/pathway:latest

WORKDIR /app

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD [ &quot;python&quot;, &quot;./your-script.py&quot; ]
```

You can then build and run the Docker image:

```console
docker build -t my-pathway-app .
docker run -it --rm --name my-pathway-app my-pathway-app
```

#### Run a single Python script

When dealing with single-file projects, creating a full-fledged `Dockerfile`
might seem unnecessary. In such scenarios, you can execute a
Python script directly using the Pathway Docker image. For example:

```console
docker run -it --rm --name my-pathway-app -v &quot;$PWD&quot;:/app pathwaycom/pathway:latest python my-pathway-app.py
```

#### Python docker image

You can also use a standard Python image and install Pathway using pip with a Dockerfile:

```dockerfile
FROM --platform=linux/x86_64 python:3.10

RUN pip install -U pathway
COPY ./pathway-script.py pathway-script.py

CMD [&quot;python&quot;, &quot;-u&quot;, &quot;pathway-script.py&quot;]
```

### Kubernetes and cloud&lt;a id=&quot;k8s&quot;&gt;&lt;/a&gt;

Docker containers are ideally suited for deployment on the cloud with Kubernetes.
If you want to scale your Pathway application, you may be interested in our Pathway for Enterprise.
Pathway for Enterprise is specially tailored towards end-to-end data processing and real time intelligent analytics.
It scales using distributed computing on the cloud and supports distributed Kubernetes deployment, with external persistence setup.

You can easily deploy Pathway using services like Render: see [how to deploy Pathway in a few clicks](https://pathway.com/developers/user-guide/deployment/render-deploy/).

If you are interested, don&#039;t hesitate to [contact us](mailto:contact@pathway.com) to learn more.

## Performance&lt;a id=&quot;performance&quot;&gt;&lt;/a&gt;

Pathway is made to outperform state-of-the-art technologies designed for streaming and batch data processing tasks, including: Flink, Spark, and Kafka Streaming. It also makes it possible to implement a lot of algorithms/UDF&#039;s in streaming mode which are not readily supported by other streaming frameworks (especially: temporal joins, iterative graph algorithms, machine learning routines).

If you are curious, here are [some benchmarks to play with](https://github.com/pathwaycom/pathway-benchmarks).

&lt;img src=&quot;https://github.com/pathwaycom/pathway-benchmarks/raw/main/images/bm-wordcount-lineplot.png&quot; width=&quot;1326&quot; alt=&quot;WordCount Graph&quot;/&gt;

## Documentation and Support&lt;a id=&quot;resources&quot;&gt;&lt;/a&gt;

The entire documentation of Pathway is available at [pathway.com/developers/](https://pathway.com/developers/user-guide/introduction/welcome), including the [API Docs](https://pathway.com/developers/api-docs/pathway).

If you have any question, don&#039;t hesitate to [open an issue on GitHub](https://github.com/pathwaycom/pathway/issues), join us on [Discord](https://discord.com/invite/pathway), or send us an email at [contact@pathway.com](mailto:contact@pathway.com).

## License&lt;a id=&quot;license&quot;&gt;&lt;/a&gt;

Pathway is distributed on a [BSL 1.1 License](https://github.com/pathwaycom/pathway/blob/main/LICENSE.txt) which allows for unlimited non-commercial use, as well as use of the Pathway package [for most commercial purposes](https://pathway.com/license/), free of charge. Code in this repository automatically converts to Open Source (Apache 2.0 License) after 4 years. Some [public repos](https://github.com/pathwaycom) which are complementary to this one (examples, libraries, connectors, etc.) are licensed as Open Source, under the MIT license.


## Contribution guidelines&lt;a id=&quot;contribution-guidelines&quot;&gt;&lt;/a&gt;

If you develop a library or connector which you would like to integrate with this repo, we suggest releasing it first as a separate repo on a MIT/Apache 2.0 license. 

For all concerns regarding core Pathway functionalities, Issues are encouraged. For further information, don&#039;t hesitate to engage with Pathway&#039;s [Discord community](https://discord.gg/pathway).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[jixiaozhong/Sonic]]></title>
            <link>https://github.com/jixiaozhong/Sonic</link>
            <guid>https://github.com/jixiaozhong/Sonic</guid>
            <pubDate>Wed, 16 Apr 2025 00:04:44 GMT</pubDate>
            <description><![CDATA[Official implementation of "Sonic: Shifting Focus to Global Audio Perception in Portrait Animation"]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jixiaozhong/Sonic">jixiaozhong/Sonic</a></h1>
            <p>Official implementation of "Sonic: Shifting Focus to Global Audio Perception in Portrait Animation"</p>
            <p>Language: Python</p>
            <p>Stars: 2,440</p>
            <p>Forks: 203</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre># Sonic
Sonic: Shifting Focus to Global Audio Perception in Portrait Animation, CVPR 2025.


&lt;a href=&#039;https://jixiaozhong.github.io/Sonic/&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/Project-Page-Green&#039;&gt;&lt;/a&gt;
&lt;a href=&quot;http://demo.sonic.jixiaozhong.online/&quot; style=&quot;margin: 0 2px;&quot;&gt;
    &lt;img src=&#039;https://img.shields.io/badge/Demo-Gradio-gold?style=flat&amp;logo=Gradio&amp;logoColor=red&#039; alt=&#039;Demo&#039;&gt;
  &lt;/a&gt;
&lt;a href=&#039;https://arxiv.org/pdf/2411.16331&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/Paper-Arxiv-red&#039;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://huggingface.co/spaces/xiaozhongji/Sonic&quot; style=&quot;margin: 0 2px;&quot;&gt;
    &lt;img src=&#039;https://img.shields.io/badge/Space-ZeroGPU-orange?style=flat&amp;logo=Gradio&amp;logoColor=red&#039; alt=&#039;Demo&#039;&gt;
    &lt;/a&gt;
  &lt;a href=&quot;https://raw.githubusercontent.com/jixiaozhong/Sonic/refs/heads/main/LICENSE&quot; style=&quot;margin: 0 2px;&quot;&gt;
    &lt;img src=&#039;https://img.shields.io/badge/License-CC BY--NC--SA--4.0-lightgreen?style=flat&amp;logo=Lisence&#039; alt=&#039;License&#039;&gt;
  &lt;/a&gt;

&lt;p align=&quot;center&quot;&gt;
    ğŸ‘‹ Join our &lt;a href=&quot;examples/image/QQ.png&quot; target=&quot;_blank&quot;&gt;QQ Chat Group&lt;/a&gt; 
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;


## ğŸ”¥ğŸ”¥ğŸ”¥ NEWS

**`2025/03/14`**: Super stoked to share that our Sonic is accpted by the CVPR 2025! See you Nashville!!

**`2025/02/08`**: Many thanks to the open-source community contributors for making the ComfyUI version of Sonic a reality. Your efforts are truly appreciated! [**ComfyUI version of Sonic**](https://github.com/smthemex/ComfyUI_Sonic)

**`2025/02/06`**: Commercialization: Note that our license is **non-commercial**. If commercialization is required, please use Tencent Cloud Video Creation Large Model: [**Introduction**](https://cloud.tencent.com/product/vclm) / [**API documentation**](https://cloud.tencent.com/document/api/1616/109378)

**`2025/01/17`**: Our [**Online huggingface Demo**](https://huggingface.co/spaces/xiaozhongji/Sonic/) is released.

**`2025/01/17`**: Thank you to NewGenAI for promoting our Sonic and creating a Windows-based tutorial on [**YouTube**](https://www.youtube.com/watch?v=KiDDtcvQyS0).

**`2024/12/16`**: Our [**Online Demo**](http://demo.sonic.jixiaozhong.online/) is released.


## ğŸ¥ Demo
| Input                | Output                | Input                | Output                |
|----------------------|-----------------------|----------------------|-----------------------|
|&lt;img src=&quot;examples/image/anime1.png&quot; width=&quot;360&quot;&gt;|&lt;video src=&quot;https://github.com/user-attachments/assets/636c3ff5-210e-44b8-b901-acf828071133&quot; width=&quot;360&quot;&gt; &lt;/video&gt;|&lt;img src=&quot;examples/image/female_diaosu.png&quot; width=&quot;360&quot;&gt;|&lt;video src=&quot;https://github.com/user-attachments/assets/e8207300-2569-47d1-9ad4-4b4c9b0f0bd4&quot; width=&quot;360&quot;&gt; &lt;/video&gt;|
|&lt;img src=&quot;examples/image/hair.png&quot; width=&quot;360&quot;&gt;|&lt;video src=&quot;https://github.com/user-attachments/assets/dcb755c1-de01-4afe-8b4f-0e0b2c2439c1&quot; width=&quot;360&quot;&gt; &lt;/video&gt;|&lt;img src=&quot;examples/image/leonnado.jpg&quot; width=&quot;360&quot;&gt;|&lt;video src=&quot;https://github.com/user-attachments/assets/b50e61bb-62d4-469d-b402-b37cda3fbd27&quot; width=&quot;360&quot;&gt; &lt;/video&gt;|


For more visual demos, please visit our [**Page**](https://jixiaozhong.github.io/Sonic/).

## ğŸ§© Community Contributions
If you develop/use Sonic in your projects, welcome to let us know.

- ComfyUI version of Sonic: [**ComfyUI_Sonic**](https://github.com/smthemex/ComfyUI_Sonic)


## ğŸ“‘ Updates
**`2025/01/14`**: Our inference code and weights are released. Stay tuned, we will continue to polish the model.


## ğŸ“œ Requirements
* An NVIDIA GPU with CUDA support is required. 
  * The model is tested on a single 32G GPU.
* Tested operating system: Linux

## ğŸ”‘ Inference

### Installtion

- install pytorch
```shell
  pip3 install -r requirements.txt
```
- All models are stored in `checkpoints` by default, and the file structure is as follows
```shell
Sonic
  â”œâ”€â”€checkpoints
  â”‚  â”œâ”€â”€Sonic
  â”‚  â”‚  â”œâ”€â”€audio2bucket.pth
  â”‚  â”‚  â”œâ”€â”€audio2token.pth
  â”‚  â”‚  â”œâ”€â”€unet.pth
  â”‚  â”œâ”€â”€stable-video-diffusion-img2vid-xt
  â”‚  â”‚  â”œâ”€â”€...
  â”‚  â”œâ”€â”€whisper-tiny
  â”‚  â”‚  â”œâ”€â”€...
  â”‚  â”œâ”€â”€RIFE
  â”‚  â”‚  â”œâ”€â”€flownet.pkl
  â”‚  â”œâ”€â”€yoloface_v5m.pt
  â”œâ”€â”€...
```
Download by `huggingface-cli` follow
```shell
  python3 -m pip install &quot;huggingface_hub[cli]&quot;
  huggingface-cli download LeonJoe13/Sonic --local-dir  checkpoints
  huggingface-cli download stabilityai/stable-video-diffusion-img2vid-xt --local-dir  checkpoints/stable-video-diffusion-img2vid-xt
  huggingface-cli download openai/whisper-tiny --local-dir checkpoints/whisper-tiny
```

or manully download [pretrain model](https://drive.google.com/drive/folders/1oe8VTPUy0-MHHW2a_NJ1F8xL-0VN5G7W?usp=drive_link), [svd-xt](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt) and [whisper-tiny](https://huggingface.co/openai/whisper-tiny) to checkpoints/ 


### Run demo
```shell
  python3 demo.py \
  &#039;/path/to/input_image&#039; \
  &#039;/path/to/input_audio&#039; \
  &#039;/path/to/output_video&#039;
```



 
## ğŸ”— Citation

If you find our work helpful for your research, please consider citing our work.   

```bibtex
@article{ji2024sonic,
  title={Sonic: Shifting Focus to Global Audio Perception in Portrait Animation},
  author={Ji, Xiaozhong and Hu, Xiaobin and Xu, Zhihong and Zhu, Junwei and Lin, Chuming and He, Qingdong and Zhang, Jiangning and Luo, Donghao and Chen, Yi and Lin, Qin and others},
  journal={arXiv preprint arXiv:2411.16331},
  year={2024}
}

@article{ji2024realtalk,
  title={Realtalk: Real-time and realistic audio-driven face generation with 3d facial prior-guided identity alignment network},
  author={Ji, Xiaozhong and Lin, Chuming and Ding, Zhonggan and Tai, Ying and Zhu, Junwei and Hu, Xiaobin and Luo, Donghao and Ge, Yanhao and Wang, Chengjie},
  journal={arXiv preprint arXiv:2406.18284},
  year={2024}
}
```

## ğŸ“œ Related Works

Explore our related researches:
-  **[Super-fast talkï¼šreal-time and less GPU computation]** [Realtalk: Real-time and realistic audio-driven face generation with 3d facial prior-guided identity alignment network](https://arxiv.org/pdf/2406.18284)

## ğŸ“ˆ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=jixiaozhong/Sonic&amp;type=Date)](https://star-history.com/#jixiaozhong/Sonic&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[OpenBB-finance/OpenBB]]></title>
            <link>https://github.com/OpenBB-finance/OpenBB</link>
            <guid>https://github.com/OpenBB-finance/OpenBB</guid>
            <pubDate>Wed, 16 Apr 2025 00:04:43 GMT</pubDate>
            <description><![CDATA[Investment Research for Everyone, Everywhere.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/OpenBB-finance/OpenBB">OpenBB-finance/OpenBB</a></h1>
            <p>Investment Research for Everyone, Everywhere.</p>
            <p>Language: Python</p>
            <p>Stars: 40,646</p>
            <p>Forks: 3,624</p>
            <p>Stars today: 162 stars today</p>
            <h2>README</h2><pre>&lt;br /&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/platform-light.svg?raw=true#gh-light-mode-only&quot; alt=&quot;OpenBB Platform logo&quot; width=&quot;600&quot;&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only&quot; alt=&quot;OpenBB Platform logo&quot; width=&quot;600&quot;&gt;
&lt;br /&gt;
&lt;br /&gt;

[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;label=Follow%20%40openbb_finance)](https://x.com/openbb_finance)
[![Discord Shield](https://img.shields.io/discord/831165782750789672)](https://discord.com/invite/xPHTuHCmuV)
[![Open in Dev Containers](https://img.shields.io/static/v1?label=Dev%20Containers&amp;message=Open&amp;color=blue&amp;logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB)
&lt;a href=&quot;https://codespaces.new/OpenBB-finance/OpenBB&quot;&gt;
  &lt;img src=&quot;https://github.com/codespaces/badge.svg&quot; height=&quot;20&quot; /&gt;
&lt;/a&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb&quot;&gt;
  &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open In Colab&quot;/&gt;
&lt;/a&gt;
[![PyPI](https://img.shields.io/pypi/v/openbb?color=blue&amp;label=PyPI%20Package)](https://pypi.org/project/openbb/)

The first financial Platform that is free and fully open source.

The OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.

Sign up to the [OpenBB Hub](https://my.openbb.co/login) to get the most out of the OpenBB ecosystem.

---

If you are looking for our **FREE** AI-powered Research and Analytics Workspace, you can find it here: [pro.openbb.co](https://pro.openbb.co).

&lt;a href=&quot;https://pro.openbb.co&quot;&gt;
  &lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://openbb.co/api/image?src=https%3A%2F%2Fopenbb-cms.directus.app%2Fassets%2Ff431ed60-5e46-439a-a9f7-4b06e72d0720.png&amp;width=2400&amp;height=1552&amp;fit=cover&amp;position=center&amp;background[]=0&amp;background[]=0&amp;background[]=0&amp;background[]=0&amp;quality=100&amp;compressionLevel=9&amp;loop=0&amp;delay=100&amp;crop=null&quot; alt=&quot;Logo&quot; width=&quot;600&quot;&gt;
  &lt;/div&gt;
&lt;/a&gt;

We also have an open source AI financial analyst agent that can access all of the data within OpenBB, and that repo can be found [here](https://github.com/OpenBB-finance/openbb-agents).

---

&lt;!-- TABLE OF CONTENTS --&gt;
&lt;details closed=&quot;closed&quot;&gt;
  &lt;summary&gt;&lt;h2 style=&quot;display: inline-block&quot;&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt;
  &lt;ol&gt;
    &lt;li&gt;&lt;a href=&quot;#1-installation&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#2-contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#3-license&quot;&gt;License&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#4-disclaimer&quot;&gt;Disclaimer&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#5-contacts&quot;&gt;Contacts&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#6-star-history&quot;&gt;Star History&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#7-contributors&quot;&gt;Contributors&lt;/a&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/details&gt;

## 1. Installation

The OpenBB Platform can be installed as a [PyPI package](https://pypi.org/project/openbb/) by running `pip install openbb`

or by cloning the repository directly with `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process in the [OpenBB Documentation](https://docs.openbb.co/platform/installation).

### OpenBB Platform CLI installation

The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.

It can be installed by running `pip install openbb-cli`

or by cloning the repository directly with  `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process in the [OpenBB Documentation](https://docs.openbb.co/cli/installation).

## 2. Contributing

There are three main ways of contributing to this project. (Hopefully you have starred the project by now â­ï¸)

### Become a Contributor

* More information on our [Contributing Documentation](https://docs.openbb.co/platform/developer_guide/contributing).

### Create a GitHub ticket

Before creating a ticket make sure the one you are creating doesn&#039;t exist already [here](https://github.com/OpenBB-finance/OpenBB/issues)

* [Report bug](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.md&amp;title=%5BBug%5D)
* [Suggest improvement](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=enhancement&amp;template=enhancement.md&amp;title=%5BIMPROVE%5D)
* [Request a feature](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=new+feature&amp;template=feature_request.md&amp;title=%5BFR%5D)

### Provide feedback

We are most active on [our Discord](https://openbb.co/discord), but feel free to reach out to us in any of [our social media](https://openbb.co/links) for feedback.

## 3. License

Distributed under the AGPLv3 License. See
[LICENSE](https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE) for more information.

## 4. Disclaimer

Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment
amount, and may not be suitable for all investors.

Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.

The data contained in the OpenBB Platform is not necessarily accurate.

OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.

All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.

Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.

## 5. Contacts

If you have any questions about the platform or anything OpenBB, feel free to email us at `support@openbb.co`

If you want to say hi, or are interested in partnering with us, feel free to reach us at `hello@openbb.co`

Any of our social media platforms: [openbb.co/links](https://openbb.co/links)

## 6. Star History

This is a proxy of our growth and that we are just getting started.

But for more metrics important to us check [openbb.co/open](https://openbb.co/open).

[![Star History Chart](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)

## 7. Contributors

OpenBB wouldn&#039;t be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.

&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/graphs/contributors&quot;&gt;
   &lt;img src=&quot;https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB&quot; width=&quot;800&quot;/&gt;
&lt;/a&gt;

&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt;
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;

[contributors-shield]: https://img.shields.io/github/contributors/OpenBB-finance/OpenBB.svg?style=for-the-badge
[contributors-url]: https://github.com/OpenBB-finance/OpenBB/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/OpenBB-finance/OpenBB.svg?style=for-the-badge
[forks-url]: https://github.com/OpenBB-finance/OpenBB/network/members
[stars-shield]: https://img.shields.io/github/stars/OpenBB-finance/OpenBB.svg?style=for-the-badge
[stars-url]: https://github.com/OpenBB-finance/OpenBB/stargazers
[issues-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB.svg?style=for-the-badge&amp;color=blue
[issues-url]: https://github.com/OpenBB-finance/OpenBB/issues
[bugs-open-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=yellow
[bugs-open-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aopen
[bugs-closed-shield]: https://img.shields.io/github/issues-closed/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=success
[bugs-closed-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aclosed
[license-shield]: https://img.shields.io/github/license/OpenBB-finance/OpenBB.svg?style=for-the-badge
[license-url]: https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&amp;logo=linkedin&amp;colorB=555
[linkedin-url]: https://linkedin.com/in/DidierRLopes
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[AUTOMATIC1111/stable-diffusion-webui]]></title>
            <link>https://github.com/AUTOMATIC1111/stable-diffusion-webui</link>
            <guid>https://github.com/AUTOMATIC1111/stable-diffusion-webui</guid>
            <pubDate>Wed, 16 Apr 2025 00:04:42 GMT</pubDate>
            <description><![CDATA[Stable Diffusion web UI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">AUTOMATIC1111/stable-diffusion-webui</a></h1>
            <p>Stable Diffusion web UI</p>
            <p>Language: Python</p>
            <p>Stars: 151,259</p>
            <p>Forks: 28,151</p>
            <p>Stars today: 56 stars today</p>
            <h2>README</h2><pre># Stable Diffusion web UI
A web interface for Stable Diffusion, implemented using Gradio library.

![](screenshot.png)

## Features
[Detailed feature showcase with images](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features):
- Original txt2img and img2img modes
- One click install and run script (but you still must install python and git)
- Outpainting
- Inpainting
- Color Sketch
- Prompt Matrix
- Stable Diffusion Upscale
- Attention, specify parts of text that the model should pay more attention to
    - a man in a `((tuxedo))` - will pay more attention to tuxedo
    - a man in a `(tuxedo:1.21)` - alternative syntax
    - select text and press `Ctrl+Up` or `Ctrl+Down` (or `Command+Up` or `Command+Down` if you&#039;re on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)
- Loopback, run img2img processing multiple times
- X/Y/Z plot, a way to draw a 3 dimensional plot of images with different parameters
- Textual Inversion
    - have as many embeddings as you want and use any names you like for them
    - use multiple embeddings with different numbers of vectors per token
    - works with half precision floating point numbers
    - train embeddings on 8GB (also reports of 6GB working)
- Extras tab with:
    - GFPGAN, neural network that fixes faces
    - CodeFormer, face restoration tool as an alternative to GFPGAN
    - RealESRGAN, neural network upscaler
    - ESRGAN, neural network upscaler with a lot of third party models
    - SwinIR and Swin2SR ([see here](https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/2092)), neural network upscalers
    - LDSR, Latent diffusion super resolution upscaling
- Resizing aspect ratio options
- Sampling method selection
    - Adjust sampler eta values (noise multiplier)
    - More advanced noise setting options
- Interrupt processing at any time
- 4GB video card support (also reports of 2GB working)
- Correct seeds for batches
- Live prompt token length validation
- Generation parameters
     - parameters you used to generate images are saved with that image
     - in PNG chunks for PNG, in EXIF for JPEG
     - can drag the image to PNG info tab to restore generation parameters and automatically copy them into UI
     - can be disabled in settings
     - drag and drop an image/text-parameters to promptbox
- Read Generation Parameters Button, loads parameters in promptbox to UI
- Settings page
- Running arbitrary python code from UI (must run with `--allow-code` to enable)
- Mouseover hints for most UI elements
- Possible to change defaults/mix/max/step values for UI elements via text config
- Tiling support, a checkbox to create images that can be tiled like textures
- Progress bar and live image generation preview
    - Can use a separate neural network to produce previews with almost none VRAM or compute requirement
- Negative prompt, an extra text field that allows you to list what you don&#039;t want to see in generated image
- Styles, a way to save part of prompt and easily apply them via dropdown later
- Variations, a way to generate same image but with tiny differences
- Seed resizing, a way to generate same image but at slightly different resolution
- CLIP interrogator, a button that tries to guess prompt from an image
- Prompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midway
- Batch Processing, process a group of files using img2img
- Img2img Alternative, reverse Euler method of cross attention control
- Highres Fix, a convenience option to produce high resolution pictures in one click without usual distortions
- Reloading checkpoints on the fly
- Checkpoint Merger, a tab that allows you to merge up to 3 checkpoints into one
- [Custom scripts](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts) with many extensions from community
- [Composable-Diffusion](https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/), a way to use multiple prompts at once
     - separate prompts using uppercase `AND`
     - also supports weights for prompts: `a cat :1.2 AND a dog AND a penguin :2.2`
- No token limit for prompts (original stable diffusion lets you use up to 75 tokens)
- DeepDanbooru integration, creates danbooru style tags for anime prompts
- [xformers](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers), major speed increase for select cards: (add `--xformers` to commandline args)
- via extension: [History tab](https://github.com/yfszzx/stable-diffusion-webui-images-browser): view, direct and delete images conveniently within the UI
- Generate forever option
- Training tab
     - hypernetworks and embeddings options
     - Preprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)
- Clip skip
- Hypernetworks
- Loras (same as Hypernetworks but more pretty)
- A separate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your prompt
- Can select to load a different VAE from settings screen
- Estimated completion time in progress bar
- API
- Support for dedicated [inpainting model](https://github.com/runwayml/stable-diffusion#inpainting-with-stable-diffusion) by RunwayML
- via extension: [Aesthetic Gradients](https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients), a way to generate images with a specific aesthetic by using clip images embeds (implementation of [https://github.com/vicgalle/stable-diffusion-aesthetic-gradients](https://github.com/vicgalle/stable-diffusion-aesthetic-gradients))
- [Stable Diffusion 2.0](https://github.com/Stability-AI/stablediffusion) support - see [wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#stable-diffusion-20) for instructions
- [Alt-Diffusion](https://arxiv.org/abs/2211.06679) support - see [wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#alt-diffusion) for instructions
- Now without any bad letters!
- Load checkpoints in safetensors format
- Eased resolution restriction: generated image&#039;s dimensions must be a multiple of 8 rather than 64
- Now with a license!
- Reorder elements in the UI from settings screen
- [Segmind Stable Diffusion](https://huggingface.co/segmind/SSD-1B) support

## Installation and Running
Make sure the required [dependencies](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Dependencies) are met and follow the instructions available for:
- [NVidia](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs) (recommended)
- [AMD](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs) GPUs.
- [Intel CPUs, Intel GPUs (both integrated and discrete)](https://github.com/openvinotoolkit/stable-diffusion-webui/wiki/Installation-on-Intel-Silicon) (external wiki page)
- [Ascend NPUs](https://github.com/wangshuai09/stable-diffusion-webui/wiki/Install-and-run-on-Ascend-NPUs) (external wiki page)

Alternatively, use online services (like Google Colab):

- [List of Online Services](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Online-Services)

### Installation on Windows 10/11 with NVidia-GPUs using release package
1. Download `sd.webui.zip` from [v1.0.0-pre](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.0.0-pre) and extract its contents.
2. Run `update.bat`.
3. Run `run.bat`.
&gt; For more details see [Install-and-Run-on-NVidia-GPUs](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs)

### Automatic Installation on Windows
1. Install [Python 3.10.6](https://www.python.org/downloads/release/python-3106/) (Newer version of Python does not support torch), checking &quot;Add Python to PATH&quot;.
2. Install [git](https://git-scm.com/download/win).
3. Download the stable-diffusion-webui repository, for example by running `git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git`.
4. Run `webui-user.bat` from Windows Explorer as normal, non-administrator, user.

### Automatic Installation on Linux
1. Install the dependencies:
```bash
# Debian-based:
sudo apt install wget git python3 python3-venv libgl1 libglib2.0-0
# Red Hat-based:
sudo dnf install wget git python3 gperftools-libs libglvnd-glx
# openSUSE-based:
sudo zypper install wget git python3 libtcmalloc4 libglvnd
# Arch-based:
sudo pacman -S wget git python3
```
If your system is very new, you need to install python3.11 or python3.10:
```bash
# Ubuntu 24.04
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.11

# Manjaro/Arch
sudo pacman -S yay
yay -S python311 # do not confuse with python3.11 package

# Only for 3.11
# Then set up env variable in launch script
export python_cmd=&quot;python3.11&quot;
# or in webui-user.sh
python_cmd=&quot;python3.11&quot;
```
2. Navigate to the directory you would like the webui to be installed and execute the following command:
```bash
wget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh
```
Or just clone the repo wherever you want:
```bash
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
```

3. Run `webui.sh`.
4. Check `webui-user.sh` for options.
### Installation on Apple Silicon

Find the instructions [here](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon).

## Contributing
Here&#039;s how to add code to this repo: [Contributing](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)

## Documentation

The documentation was moved from this README over to the project&#039;s [wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki).

For the purposes of getting Google and other search engines to crawl the wiki, here&#039;s a link to the (not for humans) [crawlable wiki](https://github-wiki-see.page/m/AUTOMATIC1111/stable-diffusion-webui/wiki).

## Credits
Licenses for borrowed code can be found in `Settings -&gt; Licenses` screen, and also in `html/licenses.html` file.

- Stable Diffusion - https://github.com/Stability-AI/stablediffusion, https://github.com/CompVis/taming-transformers, https://github.com/mcmonkey4eva/sd3-ref
- k-diffusion - https://github.com/crowsonkb/k-diffusion.git
- Spandrel - https://github.com/chaiNNer-org/spandrel implementing
  - GFPGAN - https://github.com/TencentARC/GFPGAN.git
  - CodeFormer - https://github.com/sczhou/CodeFormer
  - ESRGAN - https://github.com/xinntao/ESRGAN
  - SwinIR - https://github.com/JingyunLiang/SwinIR
  - Swin2SR - https://github.com/mv-lab/swin2sr
- LDSR - https://github.com/Hafiidz/latent-diffusion
- MiDaS - https://github.com/isl-org/MiDaS
- Ideas for optimizations - https://github.com/basujindal/stable-diffusion
- Cross Attention layer optimization - Doggettx - https://github.com/Doggettx/stable-diffusion, original idea for prompt editing.
- Cross Attention layer optimization - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (originally http://github.com/lstein/stable-diffusion)
- Sub-quadratic Cross Attention layer optimization - Alex Birch (https://github.com/Birch-san/diffusers/pull/1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)
- Textual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (we&#039;re not using his code, but we are using his ideas).
- Idea for SD upscale - https://github.com/jquesnelle/txt2imghd
- Noise generation for outpainting mk2 - https://github.com/parlance-zz/g-diffuser-bot
- CLIP interrogator idea and borrowing some code - https://github.com/pharmapsychotic/clip-interrogator
- Idea for Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch
- xformers - https://github.com/facebookresearch/xformers
- DeepDanbooru - interrogator for anime diffusers https://github.com/KichangKim/DeepDanbooru
- Sampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (https://github.com/Birch-san/diffusers-play/tree/92feee6)
- Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - https://github.com/timothybrooks/instruct-pix2pix
- Security advice - RyotaK
- UniPC sampler - Wenliang Zhao - https://github.com/wl-zhao/UniPC
- TAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesd
- LyCORIS - KohakuBlueleaf
- Restart sampling - lambertae - https://github.com/Newbeeer/diffusion_restart_sampling
- Hypertile - tfernd - https://github.com/tfernd/HyperTile
- Initial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.
- (You)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>