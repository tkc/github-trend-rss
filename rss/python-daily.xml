<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Fri, 16 May 2025 00:04:26 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[xming521/WeClone]]></title>
            <link>https://github.com/xming521/WeClone</link>
            <guid>https://github.com/xming521/WeClone</guid>
            <pubDate>Fri, 16 May 2025 00:04:26 GMT</pubDate>
            <description><![CDATA[ğŸš€ä»èŠå¤©è®°å½•åˆ›é€ æ•°å­—åˆ†èº«çš„ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆğŸ’¡ ä½¿ç”¨èŠå¤©è®°å½•å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹ï¼Œè®©å¤§æ¨¡å‹æœ‰â€œé‚£å‘³å„¿â€ï¼Œå¹¶ç»‘å®šåˆ°èŠå¤©æœºå™¨äººï¼Œå®ç°è‡ªå·±çš„æ•°å­—åˆ†èº«ã€‚ æ•°å­—å…‹éš†/æ•°å­—åˆ†èº«/æ•°å­—æ°¸ç”Ÿ/LLM/èŠå¤©æœºå™¨äºº/LoRA]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/xming521/WeClone">xming521/WeClone</a></h1>
            <p>ğŸš€ä»èŠå¤©è®°å½•åˆ›é€ æ•°å­—åˆ†èº«çš„ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆğŸ’¡ ä½¿ç”¨èŠå¤©è®°å½•å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹ï¼Œè®©å¤§æ¨¡å‹æœ‰â€œé‚£å‘³å„¿â€ï¼Œå¹¶ç»‘å®šåˆ°èŠå¤©æœºå™¨äººï¼Œå®ç°è‡ªå·±çš„æ•°å­—åˆ†èº«ã€‚ æ•°å­—å…‹éš†/æ•°å­—åˆ†èº«/æ•°å­—æ°¸ç”Ÿ/LLM/èŠå¤©æœºå™¨äºº/LoRA</p>
            <p>Language: Python</p>
            <p>Stars: 8,376</p>
            <p>Forks: 657</p>
            <p>Stars today: 1,006 stars today</p>
            <h2>README</h2><pre>![download](https://github.com/user-attachments/assets/5842e84e-004f-4afd-9373-af64e9575b78)
&lt;h3 align=&quot;center&quot;&gt;ğŸš€ä»èŠå¤©è®°å½•åˆ›é€ æ•°å­—åˆ†èº«çš„ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆğŸ’¡&lt;/h3&gt;  

&lt;div align=&quot;center&quot;&gt;

[![GitHub stars](https://img.shields.io/github/stars/xming521/WeClone?style=for-the-badge&amp;logo=github&amp;label=Stars&amp;logoColor=white&amp;color=ffda65)](https://github.com/xming521/WeClone/stargazers)
[![GitHub release](https://img.shields.io/github/v/release/xming521/WeClone?style=for-the-badge&amp;logo=github&amp;label=Release&amp;logoColor=white&amp;color=06d094)](https://github.com/xming521/WeClone/releases)
&lt;a href=&quot;https://qm.qq.com/cgi-bin/qm/qr?k=wNdgbOVT6oFOJ2wlMLsolUXErW9ESLpk&amp;jump_from=webapi&amp;authKey=z/reOp6YLyvR4Tl2k2nYMsLoMC3w9/99ucgKMX0oRGlxDV/WbYnvq2QxODoIkfxn&quot; target=&quot;_blank&quot; style=&quot;text-decoration: none;&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/QQç¾¤-708067078-12B7F5?style=for-the-badge&amp;logo=qq&amp;logoColor=white&quot; alt=&quot;WeCloneâ‘ &quot; title=&quot;WeCloneâ‘ &quot;&gt;
&lt;/a&gt;
[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;logo=telegram&amp;logoColor=white)](https://t.me/+JEdak4m0XEQ3NGNl)

&lt;a href=&quot;https://hellogithub.com/repository/12ab209b56cb4cfd885c8cfd4cfdd53e&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=12ab209b56cb4cfd885c8cfd4cfdd53e&amp;claim_uid=RThlPDoGrFvdMY5&quot; alt=&quot;Featuredï½œHelloGitHub&quot; style=&quot;width: 150px; height: 28px;&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://trendshift.io/repositories/13759&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13759&quot; alt=&quot;xming521%2FWeClone | Trendshift&quot; style=&quot;width: 220px; height: 50px;&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://deepwiki.com/xming521/WeClone&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot;  style=&quot;width: 134px; height: 23px;margin-bottom: 3px;&quot;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://blog.051088.xyz/2025/05/14/WeClone-%E7%94%A8%E5%BE%AE%E4%BF%A1%E8%81%8A%E5%A4%A9%E8%AE%B0%E5%BD%95%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84AI%E6%95%B0%E5%AD%97%E5%88%86%E8%BA%AB/&quot; target=&quot;_blank&quot;&gt;
    Windowséƒ¨ç½²æŒ‡å—
  &lt;/a&gt;
&lt;/p&gt;

## âœ¨æ ¸å¿ƒåŠŸèƒ½
- ğŸ’« æ¶µç›–æ‰“é€ æ•°å­—åˆ†èº«çš„å…¨é“¾è·¯æ–¹æ¡ˆï¼ŒåŒ…æ‹¬èŠå¤©æ•°æ®å¯¼å‡ºã€é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€éƒ¨ç½²
- ğŸ’¬ ä½¿ç”¨å¾®ä¿¡èŠå¤©è®°å½•å¾®è°ƒLLMï¼Œè®©å¤§æ¨¡å‹æœ‰&quot;é‚£å‘³å„¿&quot;
- ğŸ”— ç»‘å®šåˆ°å¾®ä¿¡ã€QQã€Telegramã€ä¼å¾®ã€é£ä¹¦æœºå™¨äººï¼Œå®ç°è‡ªå·±çš„æ•°å­—åˆ†èº«
- ğŸ›¡ï¸ éšç§ä¿¡æ¯è¿‡æ»¤ï¼Œæœ¬åœ°åŒ–å¾®è°ƒéƒ¨ç½²ï¼Œæ•°æ®å®‰å…¨å¯æ§

## ğŸ“‹ç‰¹æ€§ä¸è¯´æ˜

&gt; [!IMPORTANT]
&gt; ### 0.2.1ç‰ˆæœ¬æ”¯æŒäº†å‘½ä»¤è¡Œå·¥å…·ï¼Œä½¿ç”¨å‰éœ€è¦é‡æ–°æ‰§è¡Œ `uv pip install -e .` 

&gt; [!IMPORTANT]
&gt; 0.2.0ç‰ˆæœ¬è¿›è¡Œäº†å…¨é¢é‡æ„ï¼Œæ•°æ®é›†ç›®å½•å’Œè„šæœ¬è·¯å¾„å…¨éƒ¨è¿›è¡Œäº†ä¿®æ”¹ï¼Œæ‹‰å–æ–°ä»£ç åï¼Œ`csv`æ–‡ä»¶å¤¹æ”¾åœ¨`dataset`ä¸‹ï¼Œå¹¶ä¸”éœ€è¦é‡æ–°å®‰è£…ä¾èµ–ã€‚

&gt; [!IMPORTANT]
&gt; - WeCloneä»åœ¨å¿«é€Ÿè¿­ä»£æœŸï¼Œå½“å‰æ•ˆæœä¸ä»£è¡¨æœ€ç»ˆæ•ˆæœã€‚  
&gt; - å¾®è°ƒLLMæ•ˆæœå¾ˆå¤§ç¨‹åº¦å–å†³äºæ¨¡å‹å¤§å°ã€èŠå¤©æ•°æ®çš„æ•°é‡å’Œè´¨é‡ï¼Œç†è®ºä¸Šæ¨¡å‹è¶Šå¤§ï¼Œæ•°æ®è¶Šå¤šï¼Œæ•ˆæœè¶Šå¥½ã€‚   
&gt; - Windowsç¯å¢ƒæœªè¿›è¡Œä¸¥æ ¼æµ‹è¯•ï¼Œå¯ä»¥ä½¿ç”¨WSLä½œä¸ºè¿è¡Œç¯å¢ƒã€‚è¯¦ç»†æ•™ç¨‹å¯ç‚¹å‡»[Windowséƒ¨ç½²æŒ‡å—](https://blog.051088.xyz/2025/05/14/WeClone-%E7%94%A8%E5%BE%AE%E4%BF%A1%E8%81%8A%E5%A4%A9%E8%AE%B0%E5%BD%95%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84AI%E6%95%B0%E5%AD%97%E5%88%86%E8%BA%AB/)æŸ¥çœ‹ã€‚

### ç¡¬ä»¶è¦æ±‚

é¡¹ç›®é»˜è®¤ä½¿ç”¨Qwen2.5-7B-Instructæ¨¡å‹ï¼ŒLoRAæ–¹æ³•å¯¹sfté˜¶æ®µå¾®è°ƒï¼Œå¤§çº¦éœ€è¦16GBæ˜¾å­˜ã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨[LLaMA Factory](https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md#%E6%A8%A1%E5%9E%8B)æ”¯æŒçš„å…¶ä»–æ¨¡å‹å’Œæ–¹æ³•ã€‚

éœ€è¦æ˜¾å­˜çš„ä¼°ç®—å€¼ï¼š
| æ–¹æ³•                             | ç²¾åº¦ |   7B  |  14B  |  30B  |   70B  |   `x`B  |
| ------------------------------- | ---- | ----- | ----- | ----- | ------ | ------- |
| Full (`bf16` or `fp16`)         |  32  | 120GB | 240GB | 600GB | 1200GB | `18x`GB |
| Full (`pure_bf16`)              |  16  |  60GB | 120GB | 300GB |  600GB |  `8x`GB |
| Freeze/LoRA/GaLore/APOLLO/BAdam |  16  |  16GB |  32GB |  64GB |  160GB |  `2x`GB |
| QLoRA                           |   8  |  10GB |  20GB |  40GB |   80GB |   `x`GB |
| QLoRA                           |   4  |   6GB |  12GB |  24GB |   48GB | `x/2`GB |
| QLoRA                           |   2  |   4GB |   8GB |  16GB |   24GB | `x/4`GB |


## ç¯å¢ƒæ­å»º
1.cudaå®‰è£…(å·²å®‰è£…å¯è·³è¿‡ï¼Œ**è¦æ±‚ç‰ˆæœ¬12.4åŠä»¥ä¸Š**)ï¼š[LLaMA Factory](https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/installation.html#cuda) 

2.å»ºè®®ä½¿ç”¨ [uv](https://docs.astral.sh/uv/)å®‰è£…ä¾èµ–ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸å¿«é€Ÿçš„ Python ç¯å¢ƒç®¡ç†å™¨ã€‚å®‰è£…uvåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤åˆ›å»ºä¸€ä¸ªæ–°çš„Pythonç¯å¢ƒå¹¶å®‰è£…ä¾èµ–é¡¹ï¼Œæ³¨æ„è¿™ä¸åŒ…å«éŸ³é¢‘å…‹éš†åŠŸèƒ½çš„ä¾èµ–ï¼š
```bash
git clone https://github.com/xming521/WeClone.git
cd WeClone
uv venv .venv --python=3.10
source .venv/bin/activate # windowsä¸‹æ‰§è¡Œ .venv\Scripts\activate
uv pip install --group main -e . 
```
&gt; [!TIP]
&gt; å¦‚æœè¦ä½¿ç”¨æœ€æ–°çš„æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œéœ€è¦æ‰‹åŠ¨å®‰è£…æœ€æ–°ç‰ˆLLaMA Factoryï¼š`uv pip install --upgrade git+https://github.com/hiyouga/LLaMA-Factory.git`,åŒæ—¶å…¶ä»–ä¾èµ–ç‰ˆæœ¬ä¹Ÿå¯èƒ½éœ€è¦ä¿®æ”¹ï¼Œä¾‹å¦‚vllm pytorch transforms

3.å°†é…ç½®æ–‡ä»¶æ¨¡æ¿å¤åˆ¶ä¸€ä»½å¹¶é‡å‘½åä¸º`settings.jsonc`ï¼Œåç»­é…ç½®ä¿®æ”¹åœ¨æ­¤æ–‡ä»¶è¿›è¡Œï¼š
```bash
cp settings.template.jsonc settings.jsonc
```
&gt; [!NOTE]
&gt; è®­ç»ƒä»¥åŠæ¨ç†ç›¸å…³é…ç½®ç»Ÿä¸€åœ¨æ–‡ä»¶`settings.jsonc`

4.ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æµ‹è¯•CUDAç¯å¢ƒæ˜¯å¦æ­£ç¡®é…ç½®å¹¶å¯è¢«PyTorchè¯†åˆ«ï¼ŒMacä¸éœ€è¦ï¼š
```bash
python -c &quot;import torch; print(&#039;CUDAæ˜¯å¦å¯ç”¨:&#039;, torch.cuda.is_available());&quot;
```

5.ï¼ˆå¯é€‰ï¼‰å®‰è£…FlashAttentionï¼ŒåŠ é€Ÿè®­ç»ƒå’Œæ¨ç†ï¼š`uv pip install flash-attn --no-build-isolation`

## æ¨¡å‹ä¸‹è½½
```bash
git lfs install
git clone https://www.modelscope.cn/Qwen/Qwen2.5-7B-Instruct.git
```
ä¸‹è½½æœ‰é—®é¢˜ä½¿ç”¨å…¶ä»–æ–¹å¼ä¸‹è½½ï¼š[æ¨¡å‹çš„ä¸‹è½½](https://www.modelscope.cn/docs/models/download)


## æ•°æ®å‡†å¤‡

è¯·ä½¿ç”¨[PyWxDump](https://github.com/xaoyaoo/PyWxDump)æå–å¾®ä¿¡èŠå¤©è®°å½•ï¼ˆä¸æ”¯æŒ4.0ç‰ˆæœ¬å¾®ä¿¡ï¼‰ã€‚å¯ä»¥å…ˆå°†æ‰‹æœºçš„èŠå¤©è®°å½•è¿ç§»ï¼ˆå¤‡ä»½ï¼‰åˆ°ç”µè„‘ï¼Œæ•°æ®é‡æ›´å¤šä¸€äº›ã€‚ä¸‹è½½è½¯ä»¶å¹¶è§£å¯†æ•°æ®åº“åï¼Œç‚¹å‡»èŠå¤©å¤‡ä»½ï¼Œå¯¼å‡ºç±»å‹ä¸ºCSVï¼Œå¯ä»¥å¯¼å‡ºå¤šä¸ªè”ç³»äººï¼ˆä¸å»ºè®®ä½¿ç”¨ç¾¤èŠè®°å½•ï¼‰ï¼Œç„¶åå°†å¯¼å‡ºçš„ä½äº`wxdump_tmp/export` çš„ `csv` æ–‡ä»¶å¤¹æ”¾åœ¨`./dataset`ç›®å½•å³å¯ï¼Œä¹Ÿå°±æ˜¯ä¸åŒäººèŠå¤©è®°å½•çš„æ–‡ä»¶å¤¹ä¸€èµ·æ”¾åœ¨ `./dataset/csv`ã€‚   

## æ•°æ®é¢„å¤„ç†

- é¡¹ç›®é»˜è®¤å»é™¤äº†æ•°æ®ä¸­çš„æ‰‹æœºå·ã€èº«ä»½è¯å·ã€é‚®ç®±ã€ç½‘å€ã€‚è¿˜åœ¨`settings.jsonc`ä¸­æä¾›äº†ä¸€ä¸ªç¦ç”¨è¯è¯åº“`blocked_words`ï¼Œå¯ä»¥è‡ªè¡Œæ·»åŠ éœ€è¦è¿‡æ»¤çš„è¯å¥ï¼ˆä¼šé»˜è®¤å»æ‰åŒ…æ‹¬ç¦ç”¨è¯çš„æ•´å¥ï¼‰ã€‚
&gt; [!IMPORTANT]
&gt; ğŸš¨ è¯·ä¸€å®šæ³¨æ„ä¿æŠ¤ä¸ªäººéšç§ï¼Œä¸è¦æ³„éœ²ä¸ªäººä¿¡æ¯ï¼

- æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¯¹æ•°æ®è¿›è¡Œå¤„ç†ï¼Œå¯ä»¥æ ¹æ®è‡ªå·±çš„èŠå¤©é£æ ¼ä¿®æ”¹settings.jsoncçš„`make_dataset_args`ã€‚
```bash
weclone-cli make-dataset
```
- ç›®å‰ä»…æ”¯æŒæ—¶é—´çª—å£ç­–ç•¥ï¼Œæ ¹æ®`single_combine_time_window`å°†å•äººè¿ç»­æ¶ˆæ¯é€šè¿‡é€—å·è¿æ¥åˆå¹¶ä¸ºä¸€å¥ï¼Œæ ¹æ®`qa_match_time_window`åŒ¹é…é—®ç­”å¯¹ã€‚
- å¯ä»¥å¯ç”¨`clean_dataset`ä¸­çš„`enable_clean`é€‰é¡¹ï¼Œå¯¹æ•°æ®è¿›è¡Œæ¸…æ´—ï¼Œä»¥è¾¾åˆ°æ›´å¥½æ•ˆæœã€‚å½“å‰ä½¿ç”¨llm judgeå¯¹èŠå¤©è®°å½•è¿›è¡Œæ‰“åˆ†ï¼Œä½¿ç”¨vllmè¿›è¡Œç¦»çº¿æ¨ç†ã€‚åœ¨å¾—åˆ°`llmæ‰“åˆ†åˆ†æ•°åˆ†å¸ƒæƒ…å†µ`åï¼Œè°ƒæ•´`accept_score`é€‰æ‹©å¯ä»¥æ¥å—çš„åˆ†æ•°ï¼Œå†é€‚å½“é™ä½`train_sft_args`çš„`lora_dropout`å‚æ•°æå‡æ‹Ÿåˆæ•ˆæœã€‚

## é…ç½®å‚æ•°å¹¶å¾®è°ƒæ¨¡å‹

- (å¯é€‰)ä¿®æ”¹ `settings.jsonc` çš„ `model_name_or_path` å’Œ `template` é€‰æ‹©æœ¬åœ°ä¸‹è½½å¥½çš„å…¶ä»–æ¨¡å‹ã€‚  
- ä¿®æ”¹`per_device_train_batch_size`ä»¥åŠ`gradient_accumulation_steps`æ¥è°ƒæ•´æ˜¾å­˜å ç”¨ã€‚  
- å¯ä»¥æ ¹æ®è‡ªå·±æ•°æ®é›†çš„æ•°é‡å’Œè´¨é‡ä¿®æ”¹`train_sft_args`çš„`num_train_epochs`ã€`lora_rank`ã€`lora_dropout`ç­‰å‚æ•°ã€‚

### å•å¡è®­ç»ƒ
```bash
weclone-cli train-sft
```
å¤šå¡ç¯å¢ƒå•å¡è®­ç»ƒï¼Œéœ€è¦å…ˆæ‰§è¡Œ `export CUDA_VISIBLE_DEVICES=0`

### å¤šå¡è®­ç»ƒ
å–æ¶ˆ`settings.jsonc`ä¸­`deepspeed`è¡Œä»£ç æ³¨é‡Šï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¤šå¡è®­ç»ƒï¼š
```bash
uv pip install deepspeed
deepspeed --num_gpus=ä½¿ç”¨æ˜¾å¡æ•°é‡ weclone/train/train_sft.py
```

### ä½¿ç”¨æµè§ˆå™¨demoç®€å•æ¨ç†
å¯ä»¥åœ¨è¿™ä¸€æ­¥æµ‹è¯•å‡ºåˆé€‚çš„temperatureã€top_på€¼ï¼Œä¿®æ”¹settings.jsoncçš„`infer_args`åï¼Œä¾›åç»­æ¨ç†æ—¶ä½¿ç”¨ã€‚
```bash
weclone-cli webchat-demo
```

### ä½¿ç”¨æ¥å£è¿›è¡Œæ¨ç†

```bash
weclone-cli server
```

### ä½¿ç”¨å¸¸è§èŠå¤©é—®é¢˜æµ‹è¯•
ä¸åŒ…å«è¯¢é—®ä¸ªäººä¿¡æ¯çš„é—®é¢˜ï¼Œä»…æœ‰æ—¥å¸¸èŠå¤©ã€‚æµ‹è¯•ç»“æœåœ¨test_result-my.txtã€‚
```bash
weclone-cli server
weclone-cli test-model
```

## ğŸ–¼ï¸ å¾®è°ƒæ•ˆæœ
ä½¿ç”¨Qwen2.5-14B-Instructæ¨¡å‹ï¼Œå¤§æ¦‚3ä¸‡æ¡å¤„ç†åçš„æœ‰æ•ˆæ•°æ®ï¼Œlossé™åˆ°äº†3.5å·¦å³çš„æ•ˆæœã€‚
&lt;details&gt;
&lt;summary&gt;æˆªå›¾&lt;/summary&gt;
&lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 10px;&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/0775ec52-452b-485f-9785-c6eb7b277132&quot; alt=&quot;alt text&quot; style=&quot;width: 48%; min-width: 150px;&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/8c7628b5-da70-4c37-9e51-fdfb0eadd2df&quot; alt=&quot;alt text&quot; style=&quot;width: 48%; min-width: 150px;&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/523aa742-2aa3-40e9-bd67-b98b336e83a8&quot; alt=&quot;alt text&quot; style=&quot;width: 48%; min-width: 150px;&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/dabf0603-dcc4-4a47-b5c3-2bbc036820d9&quot; alt=&quot;alt text&quot; style=&quot;width: 48%; min-width: 150px;&quot;&gt;
&lt;/div&gt;
&lt;/details&gt;


## ğŸ¤– éƒ¨ç½²åˆ°èŠå¤©æœºå™¨äºº

### AstrBot

[AstrBot](https://github.com/AstrBotDevs/AstrBot) æ˜¯æ˜“ä¸Šæ‰‹çš„å¤šå¹³å° LLM èŠå¤©æœºå™¨äººåŠå¼€å‘æ¡†æ¶ âœ¨ å¹³å°æ”¯æŒ QQã€QQé¢‘é“ã€Telegramã€å¾®ä¿¡ã€ä¼å¾®ã€é£ä¹¦ã€‚      

ä½¿ç”¨æ­¥éª¤ï¼š
1. éƒ¨ç½² AstrBot
2. åœ¨ AstrBot ä¸­éƒ¨ç½²æ¶ˆæ¯å¹³å°
3. æ‰§è¡Œ `weclone-cli server` å¯åŠ¨apiæœåŠ¡
4. åœ¨ AstrBot ä¸­æ–°å¢æœåŠ¡æä¾›å•†ï¼Œç±»å‹é€‰æ‹©OpenAIï¼ŒAPI Base URL æ ¹æ®AstrBotéƒ¨ç½²æ–¹å¼å¡«å†™ï¼ˆä¾‹å¦‚dockeréƒ¨ç½²å¯èƒ½ä¸ºhttp://172.17.0.1:8005/v1ï¼‰ ï¼Œæ¨¡å‹å¡«å†™gpt-3.5-turbo,API Keyéšæ„å¡«å†™ä¸€ä¸ª
5. å¾®è°ƒåä¸æ”¯æŒå·¥å…·è°ƒç”¨ï¼Œè¯·å…ˆå…³æ‰é»˜è®¤çš„å·¥å…·ï¼Œæ¶ˆæ¯å¹³å°å‘é€æŒ‡ä»¤ï¼š `/tool off all`ï¼Œå¦åˆ™ä¼šæ²¡æœ‰å¾®è°ƒåçš„æ•ˆæœã€‚ 
6. æ ¹æ®å¾®è°ƒæ—¶ä½¿ç”¨çš„default_systemï¼Œåœ¨ AstrBot ä¸­è®¾ç½®ç³»ç»Ÿæç¤ºè¯ã€‚
![5](https://github.com/user-attachments/assets/19de7072-076a-4cdf-8ae6-46b9b89f536a)
&gt; [!IMPORTANT]
&gt; æ£€æŸ¥api_serviceçš„æ—¥å¿—ï¼Œå°½é‡ä¿è¯å¤§æ¨¡å‹æœåŠ¡è¯·æ±‚çš„å‚æ•°å’Œå¾®è°ƒæ—¶ä¸€è‡´ï¼Œtoolæ’ä»¶èƒ½åŠ›éƒ½å…³æ‰ã€‚
7. è°ƒæ•´é‡‡æ ·å‚æ•°ï¼Œä¾‹å¦‚temperatureã€top_pã€top_kç­‰
[é…ç½®è‡ªå®šä¹‰çš„æ¨¡å‹å‚æ•°](https://astrbot.app/config/model-config.html#%E9%85%8D%E7%BD%AE%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0)

### LangBot

[LangBot](https://github.com/RockChinQ/LangBot) æ˜¯ä¸€ä¸ªå¼€æºçš„æ¥å…¥å…¨çƒå¤šç§å³æ—¶é€šä¿¡å¹³å°çš„ LLM æœºå™¨äººå¹³å°ï¼Œé€‚åˆå„ç§åœºæ™¯ä½¿ç”¨ã€‚

1. [éƒ¨ç½² LangBot](https://github.com/RockChinQ/LangBot#-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8)
2. åœ¨ LangBot ä¸­æ·»åŠ ä¸€ä¸ªæœºå™¨äºº
4. åœ¨æ¨¡å‹é¡µæ·»åŠ æ–°æ¨¡å‹ï¼Œåç§°`gpt-3.5-turbo`ï¼Œä¾›åº”å•†é€‰æ‹© OpenAIï¼Œå¡«å†™ è¯·æ±‚ URL ä¸º WeClone çš„åœ°å€ï¼Œè¯¦ç»†è¿æ¥æ–¹å¼å¯ä»¥å‚è€ƒ[æ–‡æ¡£](https://docs.langbot.app/zh/workshop/network-details.html)ï¼ŒAPI Key ä»»æ„å¡«å†™ã€‚

&lt;img width=&quot;400px&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/fc167dea-7c93-4d94-9c5f-db709d0320ba&quot; /&gt;

6. åœ¨æµæ°´çº¿é…ç½®ä¸­é€‰æ‹©åˆšæ‰æ·»åŠ çš„æ¨¡å‹ï¼Œæˆ–ä¿®æ”¹æç¤ºè¯é…ç½®

&lt;img width=&quot;400px&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/dbb0fd0a-f760-42db-acd0-bb99c859b52e&quot; /&gt;

## ğŸ“Œ è·¯çº¿å›¾
- [ ] æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ï¼šåŒ…æ‹¬ä¸Šä¸‹æ–‡å¯¹è¯ã€èŠå¤©å¯¹è±¡ä¿¡æ¯ã€æ—¶é—´ç­‰ + æ€è€ƒ
- [ ] Memory æ”¯æŒ
- [ ] æ”¯æŒå¤šæ¨¡æ€
- [ ] æ•°æ®å¢å¼º
- [ ] æ”¯æŒGUI

## é—®é¢˜è§£å†³
- å¾®è°ƒé—®é¢˜ï¼š[LLaMA-Factory| FAQs | å¸¸è§é—®é¢˜](https://github.com/hiyouga/LLaMA-Factory/issues/4614) æˆ–è€…æ›´æ–¹ä¾¿çš„ [![æ›´æ–¹ä¾¿çš„Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/hiyouga/LLaMA-Factory)

## â¤ï¸ è´¡çŒ®ä»£ç 

æ¬¢è¿ä»»ä½• Issues/Pull Requestsï¼

ä½ å¯ä»¥é€šè¿‡æŸ¥çœ‹Issuesæˆ–å¸®åŠ©å®¡æ ¸ PRï¼ˆæ‹‰å–è¯·æ±‚ï¼‰æ¥è´¡çŒ®ã€‚å¯¹äºæ–°åŠŸèƒ½çš„æ·»åŠ ï¼Œè¯·å…ˆé€šè¿‡ Issue è®¨è®ºã€‚   
è¿è¡Œ`uv pip install --group dev -e .`å®‰è£…å¼€å‘ä¾èµ–ã€‚   
é¡¹ç›®ä½¿ç”¨`pytest`æµ‹è¯•(æµ‹è¯•è„šæœ¬å¾…å®Œå–„)ï¼Œ`pyright`æ£€æŸ¥ç±»å‹ï¼Œ`ruff`æ£€æŸ¥ä»£ç æ ¼å¼ã€‚


## âš ï¸ å…è´£å£°æ˜
&gt; [!CAUTION]
&gt; è¯·å‹¿ç”¨äºéæ³•ç”¨é€”ï¼Œå¦åˆ™åæœè‡ªè´Ÿã€‚
&lt;details&gt;
&lt;summary&gt;1. ä½¿ç”¨ç›®çš„&lt;/summary&gt;

* æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ äº¤æµä½¿ç”¨ï¼Œ**è¯·å‹¿ç”¨äºéæ³•ç”¨é€”**ï¼Œ**è¯·å‹¿ç”¨äºéæ³•ç”¨é€”**ï¼Œ**è¯·å‹¿ç”¨äºéæ³•ç”¨é€”**ï¼Œå¦åˆ™åæœè‡ªè´Ÿã€‚
* ç”¨æˆ·ç†è§£å¹¶åŒæ„ï¼Œä»»ä½•è¿åæ³•å¾‹æ³•è§„ã€ä¾µçŠ¯ä»–äººåˆæ³•æƒç›Šçš„è¡Œä¸ºï¼Œå‡ä¸æœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…æ— å…³ï¼Œåæœç”±ç”¨æˆ·è‡ªè¡Œæ‰¿æ‹…ã€‚

2. ä½¿ç”¨æœŸé™

* æ‚¨åº”è¯¥åœ¨ä¸‹è½½ä¿å­˜ä½¿ç”¨æœ¬é¡¹ç›®çš„24å°æ—¶å†…ï¼Œåˆ é™¤æœ¬é¡¹ç›®çš„æºä»£ç å’Œç¨‹åºï¼›è¶…å‡ºæ­¤æœŸé™çš„ä»»ä½•ä½¿ç”¨è¡Œä¸ºï¼Œä¸€æ¦‚ä¸æœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…æ— å…³ã€‚

3. æ“ä½œè§„èŒƒ

* æœ¬é¡¹ç›®ä»…å…è®¸åœ¨æˆæƒæƒ…å†µä¸‹ä½¿ç”¨æ•°æ®è®­ç»ƒï¼Œä¸¥ç¦ç”¨äºéæ³•ç›®çš„ï¼Œå¦åˆ™è‡ªè¡Œæ‰¿æ‹…æ‰€æœ‰ç›¸å…³è´£ä»»ï¼›ç”¨æˆ·å¦‚å› è¿åæ­¤è§„å®šè€Œå¼•å‘çš„ä»»ä½•æ³•å¾‹è´£ä»»ï¼Œå°†ç”±ç”¨æˆ·è‡ªè¡Œæ‰¿æ‹…ï¼Œä¸æœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…æ— å…³ã€‚
* ä¸¥ç¦ç”¨äºçªƒå–ä»–äººéšç§ï¼Œä¸¥ç¦ç”¨äºçªƒå–ä»–äººéšç§ï¼Œä¸¥ç¦ç”¨äºçªƒå–ä»–äººéšç§ï¼Œå¦åˆ™è‡ªè¡Œæ‰¿æ‹…æ‰€æœ‰ç›¸å…³è´£ä»»ã€‚

4. å…è´£å£°æ˜æ¥å—

* ä¸‹è½½ã€ä¿å­˜ã€è¿›ä¸€æ­¥æµè§ˆæºä»£ç æˆ–è€…ä¸‹è½½å®‰è£…ã€ç¼–è¯‘ä½¿ç”¨æœ¬ç¨‹åºï¼Œè¡¨ç¤ºä½ åŒæ„æœ¬è­¦å‘Šï¼Œå¹¶æ‰¿è¯ºéµå®ˆå®ƒ;

5. ç¦æ­¢ç”¨äºéæ³•æµ‹è¯•æˆ–æ¸—é€

* ç¦æ­¢åˆ©ç”¨æœ¬é¡¹ç›®çš„ç›¸å…³æŠ€æœ¯ä»äº‹éæ³•æµ‹è¯•æˆ–æ¸—é€ï¼Œç¦æ­¢åˆ©ç”¨æœ¬é¡¹ç›®çš„ç›¸å…³ä»£ç æˆ–ç›¸å…³æŠ€æœ¯ä»äº‹ä»»ä½•éæ³•å·¥ä½œï¼Œå¦‚å› æ­¤äº§ç”Ÿçš„ä¸€åˆ‡ä¸è‰¯åæœä¸æœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…æ— å…³ã€‚
* ä»»ä½•å› æ­¤äº§ç”Ÿçš„ä¸è‰¯åæœï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®æ³„éœ²ã€ç³»ç»Ÿç˜«ç—ªã€ä¾µçŠ¯éšç§ç­‰ï¼Œå‡ä¸æœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…æ— å…³ï¼Œè´£ä»»ç”±ç”¨æˆ·è‡ªè¡Œæ‰¿æ‹…ã€‚

6. å…è´£å£°æ˜ä¿®æ”¹

* æœ¬å…è´£å£°æ˜å¯èƒ½æ ¹æ®é¡¹ç›®è¿è¡Œæƒ…å†µå’Œæ³•å¾‹æ³•è§„çš„å˜åŒ–è¿›è¡Œä¿®æ”¹å’Œè°ƒæ•´ã€‚ç”¨æˆ·åº”å®šæœŸæŸ¥é˜…æœ¬é¡µé¢ä»¥è·å–æœ€æ–°ç‰ˆæœ¬çš„å…è´£å£°æ˜ï¼Œä½¿ç”¨æœ¬é¡¹ç›®æ—¶åº”éµå®ˆæœ€æ–°ç‰ˆæœ¬çš„å…è´£å£°æ˜ã€‚

7. å…¶ä»–

* é™¤æœ¬å…è´£å£°æ˜è§„å®šå¤–ï¼Œç”¨æˆ·åœ¨ä½¿ç”¨æœ¬é¡¹ç›®è¿‡ç¨‹ä¸­åº”éµå®ˆç›¸å…³çš„æ³•å¾‹æ³•è§„å’Œé“å¾·è§„èŒƒã€‚å¯¹äºå› ç”¨æˆ·è¿åç›¸å…³è§„å®šè€Œå¼•å‘çš„ä»»ä½•çº çº·æˆ–æŸå¤±ï¼Œæœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚

* è¯·ç”¨æˆ·æ…é‡é˜…è¯»å¹¶ç†è§£æœ¬å…è´£å£°æ˜çš„æ‰€æœ‰å†…å®¹ï¼Œç¡®ä¿åœ¨ä½¿ç”¨æœ¬é¡¹ç›®æ—¶ä¸¥æ ¼éµå®ˆç›¸å…³è§„å®šã€‚

&lt;/details&gt;
è¯·ç”¨æˆ·æ…é‡é˜…è¯»å¹¶ç†è§£æœ¬å…è´£å£°æ˜çš„æ‰€æœ‰å†…å®¹ï¼Œç¡®ä¿åœ¨ä½¿ç”¨æœ¬é¡¹ç›®æ—¶ä¸¥æ ¼éµå®ˆç›¸å…³è§„å®šã€‚

&lt;br&gt;  
&lt;br&gt;  
&lt;br&gt;  

## â­ Star History
&gt; [!TIP] 
&gt; å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œæˆ–è€…æ‚¨å…³æ³¨æœ¬é¡¹ç›®çš„æœªæ¥å‘å±•ï¼Œè¯·ç»™é¡¹ç›® Starï¼Œè°¢è°¢ 

&lt;div align=&quot;center&quot;&gt;

[![Star History Chart](https://api.star-history.com/svg?repos=xming521/WeClone&amp;type=Date)](https://www.star-history.com/#xming521/WeClone&amp;Date)

&lt;/div&gt;


&lt;div align=&quot;center&quot;&gt; å…‹éš†æˆ‘ä»¬ï¼Œä¿ç•™çµé­‚çš„èŠ¬èŠ³ &lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[mem0ai/mem0]]></title>
            <link>https://github.com/mem0ai/mem0</link>
            <guid>https://github.com/mem0ai/mem0</guid>
            <pubDate>Fri, 16 May 2025 00:04:25 GMT</pubDate>
            <description><![CDATA[Memory for AI Agents; SOTA in AI Agent Memory; Announcing OpenMemory MCP - local and secure memory management.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mem0ai/mem0">mem0ai/mem0</a></h1>
            <p>Memory for AI Agents; SOTA in AI Agent Memory; Announcing OpenMemory MCP - local and secure memory management.</p>
            <p>Language: Python</p>
            <p>Stars: 30,432</p>
            <p>Forks: 2,935</p>
            <p>Stars today: 679 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/mem0ai/mem0&quot;&gt;
    &lt;img src=&quot;docs/images/banner-sm.png&quot; width=&quot;800px&quot; alt=&quot;Mem0 - The Memory Layer for Personalized AI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot; style=&quot;display: flex; justify-content: center; gap: 20px; align-items: center;&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/11194&quot; target=&quot;blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/11194&quot; alt=&quot;mem0ai%2Fmem0 | Trendshift&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mem0.ai&quot;&gt;Learn more&lt;/a&gt;
  Â·
  &lt;a href=&quot;https://mem0.dev/DiG&quot;&gt;Join Discord&lt;/a&gt;
  Â·
  &lt;a href=&quot;https://mem0.dev/demo&quot;&gt;Demo&lt;/a&gt;
  Â·
  &lt;a href=&quot;https://mem0.dev/openmemory&quot;&gt;OpenMemory&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mem0.dev/DiG&quot;&gt;
    &lt;img src=&quot;https://dcbadge.vercel.app/api/server/6PzXDgEjG5?style=flat&quot; alt=&quot;Mem0 Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://pepy.tech/project/mem0ai&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/pypi/dm/mem0ai&quot; alt=&quot;Mem0 PyPI - Downloads&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/mem0ai/mem0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/commit-activity/m/mem0ai/mem0?style=flat-square&quot; alt=&quot;GitHub commit activity&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://pypi.org/project/mem0ai&quot; target=&quot;blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/pypi/v/mem0ai?color=%2334D058&amp;label=pypi%20package&quot; alt=&quot;Package version&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/mem0ai&quot; target=&quot;blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/v/mem0ai&quot; alt=&quot;Npm package&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.ycombinator.com/companies/mem0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Y%20Combinator-S24-orange?style=flat-square&quot; alt=&quot;Y Combinator S24&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mem0.ai/research&quot;&gt;&lt;strong&gt;ğŸ“„ Building Production-Ready AI Agents with Scalable Long-Term Memory â†’&lt;/strong&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;âš¡ +26% Accuracy vs. OpenAI Memory â€¢ ğŸš€ 91% Faster â€¢ ğŸ’° 90% Fewer Tokens&lt;/strong&gt;
&lt;/p&gt;

##  ğŸ”¥ Research Highlights
- **+26% Accuracy** over OpenAI Memory on the LOCOMO benchmark
- **91% Faster Responses** than full-context, ensuring low-latency at scale
- **90% Lower Token Usage** than full-context, cutting costs without compromise
- [Read the full paper](https://mem0.ai/research)

# Introduction

[Mem0](https://mem0.ai) (&quot;mem-zero&quot;) enhances AI assistants and agents with an intelligent memory layer, enabling personalized AI interactions. It remembers user preferences, adapts to individual needs, and continuously learns over timeâ€”ideal for customer support chatbots, AI assistants, and autonomous systems.

### Key Features &amp; Use Cases

**Core Capabilities:**
- **Multi-Level Memory**: Seamlessly retains User, Session, and Agent state with adaptive personalization
- **Developer-Friendly**: Intuitive API, cross-platform SDKs, and a fully managed service option

**Applications:**
- **AI Assistants**: Consistent, context-rich conversations
- **Customer Support**: Recall past tickets and user history for tailored help
- **Healthcare**: Track patient preferences and history for personalized care
- **Productivity &amp; Gaming**: Adaptive workflows and environments based on user behavior

## ğŸš€ Quickstart Guide &lt;a name=&quot;quickstart&quot;&gt;&lt;/a&gt;

Choose between our hosted platform or self-hosted package:

### Hosted Platform

Get up and running in minutes with automatic updates, analytics, and enterprise security.

1. Sign up on [Mem0 Platform](https://app.mem0.ai)
2. Embed the memory layer via SDK or API keys

### Self-Hosted (Open Source)

Install the sdk via pip:

```bash
pip install mem0ai
```

Install sdk via npm:
```bash
npm install mem0ai
```

### Basic Usage

Mem0 requires an LLM to function, with `gpt-4o-mini` from OpenAI as the default. However, it supports a variety of LLMs; for details, refer to our [Supported LLMs documentation](https://docs.mem0.ai/components/llms/overview).

First step is to instantiate the memory:

```python
from openai import OpenAI
from mem0 import Memory

openai_client = OpenAI()
memory = Memory()

def chat_with_memories(message: str, user_id: str = &quot;default_user&quot;) -&gt; str:
    # Retrieve relevant memories
    relevant_memories = memory.search(query=message, user_id=user_id, limit=3)
    memories_str = &quot;\n&quot;.join(f&quot;- {entry[&#039;memory&#039;]}&quot; for entry in relevant_memories[&quot;results&quot;])

    # Generate Assistant response
    system_prompt = f&quot;You are a helpful AI. Answer the question based on query and memories.\nUser Memories:\n{memories_str}&quot;
    messages = [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_prompt}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: message}]
    response = openai_client.chat.completions.create(model=&quot;gpt-4o-mini&quot;, messages=messages)
    assistant_response = response.choices[0].message.content

    # Create new memories from the conversation
    messages.append({&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: assistant_response})
    memory.add(messages, user_id=user_id)

    return assistant_response

def main():
    print(&quot;Chat with AI (type &#039;exit&#039; to quit)&quot;)
    while True:
        user_input = input(&quot;You: &quot;).strip()
        if user_input.lower() == &#039;exit&#039;:
            print(&quot;Goodbye!&quot;)
            break
        print(f&quot;AI: {chat_with_memories(user_input)}&quot;)

if __name__ == &quot;__main__&quot;:
    main()
```

For detailed integration steps, see the [Quickstart](https://docs.mem0.ai/quickstart) and [API Reference](https://docs.mem0.ai/api-reference).

## ğŸ”— Integrations &amp; Demos

- **ChatGPT with Memory**: Personalized chat powered by Mem0 ([Live Demo](https://mem0.dev/demo))
- **Browser Extension**: Store memories across ChatGPT, Perplexity, and Claude ([Chrome Extension](https://chromewebstore.google.com/detail/onihkkbipkfeijkadecaafbgagkhglop?utm_source=item-share-cb))
- **Langgraph Support**: Build a customer bot with Langgraph + Mem0 ([Guide](https://docs.mem0.ai/integrations/langgraph))
- **CrewAI Integration**: Tailor CrewAI outputs with Mem0 ([Example](https://docs.mem0.ai/integrations/crewai))

## ğŸ“š Documentation &amp; Support

- Full docs: https://docs.mem0.ai
- Community: [Discord](https://mem0.dev/DiG) Â· [Twitter](https://x.com/mem0ai)
- Contact: founders@mem0.ai

## Citation

We now have a paper you can cite:

```bibtex
@article{mem0,
  title={Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory},
  author={Chhikara, Prateek and Khant, Dev and Aryan, Saket and Singh, Taranjeet and Yadav, Deshraj},
  journal={arXiv preprint arXiv:2504.19413},
  year={2025}
}
```

## âš–ï¸ License

Apache 2.0 â€” see the [LICENSE](LICENSE) file for details.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[mikumifa/biliTickerBuy]]></title>
            <link>https://github.com/mikumifa/biliTickerBuy</link>
            <guid>https://github.com/mikumifa/biliTickerBuy</guid>
            <pubDate>Fri, 16 May 2025 00:04:24 GMT</pubDate>
            <description><![CDATA[bç«™ ä¼šå‘˜è´­ æŠ¢ç¥¨ æ¼«å±• è„šæœ¬ bilibili å›¾å½¢åŒ– çº¯æ¥å£ éªŒè¯ç é¢„æ¼”ç»ƒä¹ ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mikumifa/biliTickerBuy">mikumifa/biliTickerBuy</a></h1>
            <p>bç«™ ä¼šå‘˜è´­ æŠ¢ç¥¨ æ¼«å±• è„šæœ¬ bilibili å›¾å½¢åŒ– çº¯æ¥å£ éªŒè¯ç é¢„æ¼”ç»ƒä¹ </p>
            <p>Language: Python</p>
            <p>Stars: 1,482</p>
            <p>Forks: 221</p>
            <p>Stars today: 89 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/mikumifa/biliTickerBuy&quot; target=&quot;_blank&quot;&gt;
    &lt;img width=&quot;160&quot; src=&quot;assets/icon.ico&quot; alt=&quot;logo&quot;&gt;
  &lt;/a&gt;
  &lt;h2 id=&quot;koishi&quot;&gt;biliTickerBuy&lt;/h1&gt;

&lt;p&gt;
  &lt;!-- GitHub Downloads --&gt;
  &lt;a href=&quot;https://github.com/mikumifa/biliTickerBuy/releases&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/downloads/mikumifa/biliTickerBuy/total&quot; alt=&quot;GitHub all releases&quot;&gt;
  &lt;/a&gt;
  &lt;!-- GitHub Release Version --&gt;
  &lt;a href=&quot;https://github.com/mikumifa/biliTickerBuy/releases&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/v/release/mikumifa/biliTickerBuy&quot; alt=&quot;GitHub release (with filter)&quot;&gt;
  &lt;/a&gt;
  &lt;!-- GitHub Issues --&gt;
  &lt;a href=&quot;https://github.com/mikumifa/biliTickerBuy/issues&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/issues/mikumifa/biliTickerBuy&quot; alt=&quot;GitHub issues&quot;&gt;
  &lt;/a&gt;
  &lt;!-- GitHub Stars --&gt;
  &lt;a href=&quot;https://github.com/mikumifa/biliTickerBuy/stargazers&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/stars/mikumifa/biliTickerBuy&quot; alt=&quot;GitHub Repo stars&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;a href=&quot;https://trendshift.io/repositories/11145&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/11145&quot; alt=&quot;mikumifa%2FbiliTickerBuy | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

è¿™æ˜¯ä¸€ä¸ªå¼€æºå…è´¹ï¼Œç®€å•æ˜“ç”¨çš„Bç«™ä¼šå‘˜è´­è¾…åŠ©å·¥å…·
&lt;/div&gt;






## ğŸ’» å¿«é€Ÿå®‰è£…

[ä¸‹è½½é“¾æ¥](https://github.com/mikumifa/biliTickerBuy/releases) 

## ğŸ‘€ ä½¿ç”¨è¯´æ˜ä¹¦
å‰å¾€é£ä¹¦ï¼š https://n1x87b5cqay.feishu.cn/wiki/Eg4xwt3Dbiah02k1WqOcVk2YnMd

## â— é¡¹ç›®é—®é¢˜

ç¨‹åºä½¿ç”¨é—®é¢˜ï¼š [ç‚¹æ­¤é“¾æ¥å‰å¾€discussions](https://github.com/mikumifa/biliTickerBuy/discussions)

åé¦ˆç¨‹åºBUGæˆ–è€…ææ–°åŠŸèƒ½å»ºè®®ï¼š [ç‚¹æ­¤é“¾æ¥å‘é¡¹ç›®æå‡ºåé¦ˆBUG](https://github.com/mikumifa/biliTickerBuy/issues/new/choose)



## ğŸ¤© é¡¹ç›®è´¡çŒ®è€…

&lt;a href=&quot;https://github.com/mikumifa/biliTickerBuy/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=mikumifa/biliTickerBuy&amp;preview=true&amp;max=&amp;columns=&quot; /&gt;
&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;

## â­ï¸ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=mikumifa/biliTickerBuy&amp;type=Date)](https://www.star-history.com/#mikumifa/biliTickerBuy&amp;Date)

## ğŸ“© å…è´£å£°æ˜

è¯¦è§[MIT License](./LICENSE)ï¼Œåˆ‡å‹¿è¿›è¡Œç›ˆåˆ©ï¼Œæ‰€é€ æˆçš„åæœä¸æœ¬äººæ— å…³ã€‚

## ğŸ’° æèµ 

å¦‚æœä½ æƒ³æ”¯æŒè¿™ä¸ªé¡¹ç›®çš„è¯ [çˆ±å‘ç”µ](https://afdian.com/a/mikumifa)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[airweave-ai/airweave]]></title>
            <link>https://github.com/airweave-ai/airweave</link>
            <guid>https://github.com/airweave-ai/airweave</guid>
            <pubDate>Fri, 16 May 2025 00:04:23 GMT</pubDate>
            <description><![CDATA[Airweave lets agents search any app]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/airweave-ai/airweave">airweave-ai/airweave</a></h1>
            <p>Airweave lets agents search any app</p>
            <p>Language: Python</p>
            <p>Stars: 1,947</p>
            <p>Forks: 195</p>
            <p>Stars today: 399 stars today</p>
            <h2>README</h2><pre>&lt;img width=&quot;1673&quot; alt=&quot;airweave-lettermark&quot; style=&quot;padding-bottom: 12px;&quot; src=&quot;https://github.com/user-attachments/assets/e79a9af7-2e93-4888-9cf4-0f700f19fe05&quot;/&gt;


&lt;div align=&quot;center&quot;&gt;

[![Ruff](https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml/badge.svg)](https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml)
[![ESLint](https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml/badge.svg)](https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml)
[![Backend Tests](https://github.com/airweave-ai/airweave/actions/workflows/tests.yml/badge.svg?branch=main)](https://github.com/airweave-ai/airweave/actions/workflows/tests.yml)
[![Codecov](https://codecov.io/gh/airweave-ai/airweave/branch/main/graph/badge.svg)](https://codecov.io/gh/airweave-ai/airweave)
[![Discord](https://img.shields.io/discord/1323415085011701870?label=Discord&amp;logo=discord&amp;logoColor=white&amp;style=flat-square)](https://discord.com/invite/484HY9Ehxt)

&lt;/div&gt;

# Airweave

**Airweave is a tool that lets agents semantically search any app.** It&#039;s MCP compatible and seamlessly connects any app, database, or API, to transform their contents into agent-ready knowledge.

&lt;div align=&quot;center&quot;&gt;
  
### ğŸ¥ Watch Demo

https://github.com/user-attachments/assets/abdf85cb-a8f5-4b6c-b5a3-d4b5177e6bda

&lt;/div&gt;

## Overview

Airweave simplifies the process of making information retrievable for your agent. Whether you have structured or unstructured data, Airweave helps you break it into processable entities, store the data and make it retrievable through REST and MCP endpoints.

## Table of Contents

- [Airweave](#airweave)
    - [ğŸ¥ Watch Demo](#-watch-demo)
  - [Overview](#overview)
  - [Table of Contents](#table-of-contents)
  - [ğŸš€ Quick Start](#-quick-start)
  - [ğŸ”Œ Supported Integrations](#-supported-integrations)
  - [ğŸ’» Usage](#-usage)
    - [Frontend](#frontend)
    - [API](#api)
  - [ğŸ“¦ SDKs](#-sdks)
    - [Python](#python)
    - [TypeScript/JavaScript](#typescriptjavascript)
  - [ğŸ”‘ Key Features](#-key-features)
  - [ğŸ”§ Technology Stack](#-technology-stack)
  - [ğŸ›£ï¸ Roadmap](#ï¸-roadmap)
  - [ğŸ‘¥ Contributing](#-contributing)
  - [ğŸ“„ License](#-license)
  - [ğŸ”— Connect](#-connect)

## ğŸš€ Quick Start

Make sure docker and docker-compose are installed, then...

```bash
# 1. Clone the repository
git clone https://github.com/airweave-ai/airweave.git
cd airweave

# 2. Build and run
chmod +x start.sh
./start.sh
```

That&#039;s it! Access the dashboard at http://localhost:8080

## ğŸ”Œ Supported Integrations

&lt;!-- START_APP_GRID --&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;div style=&quot;display: inline-block; text-align: center; padding: 4px;&quot;&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/asana.svg&quot; alt=&quot;Asana&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/calendly.svg&quot; alt=&quot;Calendly&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/chat-gpt.svg&quot; alt=&quot;Chat-gpt&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/clickup.svg&quot; alt=&quot;Clickup&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/confluence.svg&quot; alt=&quot;Confluence&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/dropbox.svg&quot; alt=&quot;Dropbox&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/elasticsearch.svg&quot; alt=&quot;Elasticsearch&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/facebook.svg&quot; alt=&quot;Facebook&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/github.svg&quot; alt=&quot;Github&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/gmail.svg&quot; alt=&quot;Gmail&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/google_calendar.svg&quot; alt=&quot;Google Calendar&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/google_drive.svg&quot; alt=&quot;Google Drive&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/hubspot.svg&quot; alt=&quot;Hubspot&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/intercom.svg&quot; alt=&quot;Intercom&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/jira.svg&quot; alt=&quot;Jira&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/linear.svg&quot; alt=&quot;Linear&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/linkedin.svg&quot; alt=&quot;Linkedin&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/mailchimp.svg&quot; alt=&quot;Mailchimp&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/monday.svg&quot; alt=&quot;Monday&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/mysql.svg&quot; alt=&quot;Mysql&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/notion.svg&quot; alt=&quot;Notion&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/onedrive.svg&quot; alt=&quot;Onedrive&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/oracle.svg&quot; alt=&quot;Oracle&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/outlook_calendar.svg&quot; alt=&quot;Outlook Calendar&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/outlook_mail.svg&quot; alt=&quot;Outlook Mail&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/perplexity.svg&quot; alt=&quot;Perplexity&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/postgresql.svg&quot; alt=&quot;Postgresql&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/salesforce.svg&quot; alt=&quot;Salesforce&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/slack.svg&quot; alt=&quot;Slack&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/sql_server.svg&quot; alt=&quot;Sql Server&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/sqlite.svg&quot; alt=&quot;Sqlite&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/stripe.svg&quot; alt=&quot;Stripe&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
    &lt;span style=&quot;width: 40px; display: inline-block; margin: 4px;&quot;&gt;&lt;/span&gt;&lt;span style=&quot;width: 40px; display: inline-block; margin: 4px;&quot;&gt;&lt;/span&gt;&lt;img src=&quot;frontend/src/components/icons/apps/todoist.svg&quot; alt=&quot;Todoist&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/trello.svg&quot; alt=&quot;Trello&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/whatsapp.svg&quot; alt=&quot;Whatsapp&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/zendesk.svg&quot; alt=&quot;Zendesk&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
  &lt;/div&gt;
&lt;/p&gt;

&lt;!-- END_APP_GRID --&gt;

## ğŸ’» Usage

### Frontend
- Access the UI at `http://localhost:8080`
- Connect sources, configure syncs, and query data

### API
- Swagger docs: `http://localhost:8001/docs`
- Create connections, trigger syncs, and search data

## ğŸ“¦ SDKs

### Python

```bash
pip install airweave-sdk
```

```python
from airweave import AirweaveClient

client = AirweaveClient(api_key=&quot;your-api-key&quot;)

# List all sources
sources = client.sources.list()

# Create a sync job
job = client.sync.create_sync(
  name=&quot;My first sync&quot;,
  source_connection_id=source_id,
  run_immediately=True
)
```

### TypeScript/JavaScript

```bash
npm install @airweave/sdk
# or
yarn add @airweave/sdk
```

```typescript
import { AirweaveClient } from &quot;@airweave/sdk&quot;;

const client = new AirweaveClient({
  apiKey: &quot;your-api-key&quot;,
});

// List sources
const sources = await client.sources.list();

// Create a sync job
const job = await client.sync.create_sync({
  name: &quot;My first sync&quot;,
  source_connection_id: sourceId,
  run_immediately: true,
});
```

## ğŸ”‘ Key Features

- **Data synchronization** from 25+ sources with minimal config
- **Entity extraction** and transformation pipeline
- **Multi-tenant** architecture with OAuth2
- **Incremental updates** using content hashing
- **Semantic search** for agent queries
- **Versioning** for data changes
- **White-labeling** support for SaaS builders

## ğŸ”§ Technology Stack

- **Frontend**: React/TypeScript with ShadCN
- **Backend**: FastAPI (Python)
- **Databases**: PostgreSQL (metadata), Qdrant (vectors)
- **Deployment**: Docker Compose (dev), Kubernetes (prod)

## ğŸ›£ï¸ Roadmap

- Additional source integrations
- Redis worker queues for large-scale syncs
- Webhooks for event-driven syncs
- Kubernetes support via Helm charts

## ğŸ‘¥ Contributing

We welcome contributions! Please check [CONTRIBUTING.md](https://github.com/airweave-ai/airweave/blob/main/CONTRIBUTING.md) for details.

## ğŸ“„ License

Airweave is released under the [MIT](LICENSE) license.

## ğŸ”— Connect

- **[Discord](https://discord.com/invite/484HY9Ehxt)** - Get help and discuss features
- **[GitHub Issues](https://github.com/airweave-ai/airweave/issues)** - Report bugs or request features
- **[Twitter](https://x.com/airweave_ai)** - Follow for updates
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[openai/simple-evals]]></title>
            <link>https://github.com/openai/simple-evals</link>
            <guid>https://github.com/openai/simple-evals</guid>
            <pubDate>Fri, 16 May 2025 00:04:22 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/simple-evals">openai/simple-evals</a></h1>
            <p></p>
            <p>Language: Python</p>
            <p>Stars: 3,351</p>
            <p>Forks: 325</p>
            <p>Stars today: 205 stars today</p>
            <h2>README</h2><pre># Overview
This repository contains a lightweight library for evaluating language models.
We are open sourcing it so we can be transparent about the accuracy numbers we&#039;re publishing alongside our latest models.

## Benchmark Results

| Model                        | Prompt        | MMLU   | GPQA [^8]   | MATH [^6]| HumanEval | MGSM[^5] | DROP[^5]&lt;br&gt;(F1, 3-shot) | SimpleQA
|:----------------------------:|:-------------:|:------:|:------:|:--------:|:---------:|:------:|:--------------------------:|:---------:|
| **o3**                         |               |        |        |          |           |        |                             |                      |           |
| o3-high [^10]                | n/a [^7]      |  93.3  |  83.4  |   98.1   |  88.4     |  92.0  |  89.8                      |  48.6     |
| o3 [^9] [^10]                | n/a           |  92.9  |  82.8  |   97.8   |  87.4     |  92.3  |  80.6                      |  49.4     |
| o3-low [^10]                 | n/a           |  92.8  |  78.6  |   96.9   |  87.3     |  91.9  |  82.3                      |  49.4     |
| **o4-mini**                    |               |        |        |          |           |        |                             |                      |
| o4-mini-high [^9] [^10]      | n/a           |  90.3  |  81.3  |   98.2   |  99.3     |  93.5  |  78.1                      |  19.3     |
| o4-mini [^9] [^10]           | n/a           |  90.0  |  77.6  |   97.5   |  97.3     |  93.7  |  77.7                      |  20.2     |
| o4-mini-low [^10]            | n/a           |  89.5  |  73.6  |   96.2   |  95.9     |  93.0  |  76.0                      |  20.2     |
| **o3-mini**                    |               |        |        |          |           |        |                             |                      |           |
| o3-mini-high                 | n/a           |  86.9  |  77.2  |   97.9   |  97.6     |  92.0  |  80.6                      |  13.8     |
| o3-mini                      | n/a           |  85.9  |  74.9  |   97.3   |  96.3     |  90.8  |  79.2                      |  13.4     |
| o3-mini-low                  | n/a           |  84.9  |  67.6  |   95.8   |  94.5     |  89.4  |  77.6                      |  13.0     |
| **o1**                         |               |        |        |          |           |        |                             |                      |
|  o1                          | n/a           |  91.8  |  75.7  |   96.4   |    -      |  89.3  |  90.2                      |  42.6     |
| o1-preview                   | n/a           |  90.8  |  73.3  |   85.5   |  92.4     |  90.8  |  74.8                      |  42.4     |
| o1-mini                      | n/a           |  85.2  |  60.0  |   90.0   |  92.4     |  89.9  |  83.9                      |  07.6     |
| **GPT-4.1**                            |               |        |        |          |           |        |                             |                      |           |
| gpt-4.1-2025-04-14           | assistant [^2]|  90.2  |  66.3  |   82.1   |   94.5    |  86.9  |  79.4                      | 41.6      |
| gpt-4.1-mini-2025-04-14      | assistant     |  87.5  |  65.0  |   81.4   |   93.8    |  88.2  |  81.0                      | 16.8      |
| gpt-4.1-nano-2025-04-14      | assistant     |  80.1  |  50.3  |   62.3   |   87.0    |  73.0  |  82.2                      | 07.6      |
| **GPT-4o**                     |               |        |        |          |           |        |                             |                      |           |
| gpt-4o-2024-11-20            | assistant     |  85.7  |  46.0  |   68.5   |   90.2    |  90.3  |  81.5                      | 38.8      |
| gpt-4o-2024-08-06            | assistant     |  88.7  |  53.1  |   75.9   |   90.2    |  90.0  |  79.8                      | 40.1      |
| gpt-4o-2024-05-13            | assistant     |  87.2  |  49.9  |   76.6   |   91.0    |  89.9  |  83.7                      | 39.0      |
| gpt-4o-mini-2024-07-18       | assistant     |  82.0  |  40.2  |   70.2   |   87.2    |  87.0  |  79.7                      | 09.5      |
| **GPT-4.5-preview**          |               |        |        |          |           |        |                            |           |
| gpt-4.5-preview-2025-02-27   | assistant     |  90.8  |  69.5  |   87.1   |   88.6    |  86.9  |  83.4                      | 62.5      |
| **GPT-4 Turbo and GPT-4**    |               |        |        |          |           |        |                            |           |
| gpt-4-turbo-2024-04-09       | assistant     |  86.7  |  49.3  |   73.4   |   88.2    |  89.6  |  86.0                      | 24.2      |
| gpt-4-0125-preview           | assistant     |  85.4  |  41.4  |   64.5   |   86.6    |  85.1  |  81.5                      | n/a       |
| gpt-4-1106-preview           | assistant     |  84.7  |  42.5  |   64.3   |   83.7    |  87.1  |  83.2                      | n/a       |
| **Other Models (Reported)**   |               |        |        |        |           |        |                           |
| [Claude 3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet) | unknown |  88.3  |  59.4  |  71.1  |   92.0    | 91.6 | 87.1 |  28.9 |
| [Claude 3 Opus](https://www.anthropic.com/news/claude-3-family) | unknown |  86.8  |  50.4  |  60.1  |   84.9    |   90.7   |  83.1 |  23.5 |
| [Llama 3.1 405b](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md) | unknown |  88.6  |  50.7  |  73.8  |   89.0    | 91.6 |  84.8                   | n/a
| [Llama 3.1 70b](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md) | unknown |  82.0  |  41.7  |  68.0  |   80.5    |  86.9  |  79.6                   | n/a
| [Llama 3.1 8b](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md) | unknown |  68.4  |  30.4  |  51.9  |   72.6    |  68.9  |  59.5                   | n/a
| [Grok 2](https://x.ai/blog/grok-2) | unknown | 87.5 | 56.0 | 76.1 | 88.4 | n/a | n/a | n/a
| [Grok 2 mini](https://x.ai/blog/grok-2) | unknown | 86.2 | 51.0 | 73.0 | 85.7 | n/a | n/a | n/a
| [Gemini 1.0 Ultra](https://goo.gle/GeminiV1-5) | unknown | 83.7 | n/a | 53.2 | 74.4 | 79.0 | 82.4 | n/a
| [Gemini 1.5 Pro](https://goo.gle/GeminiV1-5) | unknown | 81.9 | n/a | 58.5 | 71.9 | 88.7 | 78.9 | n/a
| [Gemini 1.5 Flash](https://goo.gle/GeminiV1-5) | unknown | 77.9 | 38.6 | 40.9 | 71.5 | 75.5 | 78.4 | n/a

## Background

Evals are sensitive to prompting, and there&#039;s significant variation in the formulations used in recent publications and libraries.
Some use few-shot prompts or role playing prompts (&quot;You are an expert software programmer...&quot;).
These approaches are carryovers from evaluating *base models* (rather than instruction/chat-tuned models) and from models that were worse at following instructions.

For this library, we are emphasizing the *zero-shot, chain-of-thought* setting, with simple instructions like &quot;Solve the following multiple choice problem&quot;. We believe that this prompting technique is a better reflection of the models&#039; performance in realistic usage.

**We will not be actively maintaining this repository and monitoring PRs and Issues.** In particular, we&#039;re not accepting new evals. Here are the changes we might accept.
- Bug fixes (hopefully not needed!)
- Adding adapters for new models
- Adding new rows to the table below with eval results, given new models and new system prompts.

This repository is NOT intended as a replacement for https://github.com/openai/evals, which is designed to be a comprehensive collection of a large number of evals.

## Evals

This repository currently contains the following evals:

- MMLU: Measuring Massive Multitask Language Understanding, reference: https://arxiv.org/abs/2009.03300, https://github.com/hendrycks/test, [MIT License](https://github.com/hendrycks/test/blob/master/LICENSE)
- MATH: Measuring Mathematical Problem Solving With the MATH Dataset, reference: https://arxiv.org/abs/2103.03874, https://github.com/hendrycks/math, [MIT License](https://github.com/idavidrein/gpqa/blob/main/LICENSE)
- GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark, reference: https://arxiv.org/abs/2311.12022, https://github.com/idavidrein/gpqa/,  [MIT License](https://github.com/idavidrein/gpqa/blob/main/LICENSE)
- DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs, reference: https://arxiv.org/abs/1903.00161, https://allenai.org/data/drop, [Apache License 2.0](https://github.com/allenai/allennlp-models/blob/main/LICENSE)
- MGSM: Multilingual Grade School Math Benchmark (MGSM), Language Models are Multilingual Chain-of-Thought Reasoners, reference: https://arxiv.org/abs/2210.03057, https://github.com/google-research/url-nlp, [Creative Commons Attribution 4.0 International Public License (CC-BY)](https://github.com/google-research/url-nlp/blob/main/LICENSE)
- HumanEval: Evaluating Large Language Models Trained on Code, reference https://arxiv.org/abs/2107.03374, https://github.com/openai/human-eval, [MIT License](https://github.com/openai/human-eval/blob/master/LICENSE)
- SimpleQA: Measuring short-form factuality in large language models, reference: https://openai.com/index/introducing-simpleqa, [MIT License](https://github.com/openai/simple-evals/blob/main/LICENSE)
- BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents, reference: https://openai.com/index/browsecomp, [MIT License](https://github.com/openai/simple-evals/blob/main/LICENSE)
- HealthBench: Evaluating Large Language Models Towards Improved Human Health, reference: https://openai.com/index/healthbench, [MIT License](https://github.com/openai/simple-evals/blob/main/LICENSE)

## Samplers

We have implemented sampling interfaces for the following language model APIs:

- OpenAI: https://platform.openai.com/docs/overview
- Claude: https://www.anthropic.com/api

Make sure to set the `*_API_KEY` environment variables before using these APIs.

## Setup

Due to the optional dependencies, we&#039;re not providing a unified setup mechanism. Instead, we&#039;re providing instructions for each eval and sampler.

For [HumanEval](https://github.com/openai/human-eval/) (python programming)
```bash
git clone https://github.com/openai/human-eval
pip install -e human-eval
```

For the [OpenAI API](https://pypi.org/project/openai/):
```bash
pip install openai
```

For the [Anthropic API](https://docs.anthropic.com/claude/docs/quickstart-guide):
```bash
pip install anthropic
```

## Running the evals
```bash
python -m simple-evals.simple_evals --list-models
```
This will list all the models that you can evaluate.

To run the evaluations, you can use the following command:
```bash
python -m simple-evals.simple_evals --model &lt;model_name&gt; --examples &lt;num_examples&gt;
```
This will launch evaluations through the OpenAI API.

## Notes

[^1]:chatgpt system message: &quot;You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\nKnowledge cutoff: 2023-12\nCurrent date: 2024-04-01&quot;
[^2]:assistant system message in [OpenAI API doc](https://platform.openai.com/docs/api-reference/introduction): &quot;You are a helpful assistant.&quot; .
[^3]:claude-3 empty system message: suggested by Anthropic API doc, and we have done limited experiments due to [rate limit](https://docs.anthropic.com/claude/reference/rate-limits) issues, but we welcome PRs with alternative choices.
[^4]:claude-3 lmsys system message: system message in LMSYS [Fast-chat open source code](https://github.com/lm-sys/FastChat/blob/7899355ebe32117fdae83985cf8ee476d2f4243f/fastchat/conversation.py#L894): &quot;The assistant is Claude, created by Anthropic. The current date is {{currentDateTime}}. Claude&#039;s knowledge base was last updated ... &quot;. We have done limited experiments due to [rate limit](https://docs.anthropic.com/claude/reference/rate-limits) issues, but we welcome PRs with alternative choices.
[^5]:We believe these evals are saturated for our newer models, but are reporting them for completeness.
[^6]:For newer models (anything on or after o1) we evaluate on [MATH-500](https://github.com/openai/prm800k/tree/main/prm800k/math_splits), which is a newer, IID version of MATH.
[^7]:o-series models do not support using a system prompt.
[^8]:Includes an answer regex tweak for GPQA benchmark.
[^9]:The default reasoning level for o3-mini is &quot;medium&quot;.
[^10]:These results are with no tools enabled for o3 or o4-mini

## Legal Stuff
By contributing to evals, you are agreeing to make your evaluation logic and data under the same MIT license as this repository. You must have adequate rights to upload any data used in an eval. OpenAI reserves the right to use this data in future service improvements to our product. Contributions to OpenAI evals will be subject to our usual Usage Policies: https://platform.openai.com/docs/usage-policies.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[facebookresearch/fairchem]]></title>
            <link>https://github.com/facebookresearch/fairchem</link>
            <guid>https://github.com/facebookresearch/fairchem</guid>
            <pubDate>Fri, 16 May 2025 00:04:21 GMT</pubDate>
            <description><![CDATA[FAIR Chemistry's library of machine learning methods for chemistry]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/facebookresearch/fairchem">facebookresearch/fairchem</a></h1>
            <p>FAIR Chemistry's library of machine learning methods for chemistry</p>
            <p>Language: Python</p>
            <p>Stars: 1,210</p>
            <p>Forks: 306</p>
            <p>Stars today: 73 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt; &lt;code&gt;fairchem&lt;/code&gt; by FAIR Chemistry &lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;559&quot; height=&quot;200&quot; src=&quot;https://github.com/FAIR-Chem/fairchem/assets/45150244/5872c21c-8f39-41af-b703-af9817f0affe&quot;?
&lt;/p&gt;


&lt;h4 align=&quot;center&quot;&gt;

![tests](https://github.com/FAIR-Chem/fairchem/actions/workflows/test.yml/badge.svg?branch=main)
![PyPI - Version](https://img.shields.io/pypi/v/fairchem-core)
![Static Badge](https://img.shields.io/badge/python-3.10%2B-blue)

[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://github.com/codespaces/new/FAIR-Chem/fairchem?quickstart=1)

`fairchem` is the [FAIR](https://ai.meta.com/research/) Chemistry&#039;s centralized repository of all its data, models,
demos, and application efforts for materials science and quantum chemistry.

&gt; :warning: **FAIRChem version 2 is a breaking change from version 1 and is not compatible with our previous pretrained models and code.**
&gt; If you want to use an older model or code from version 1 you will need to install [version 1](https://pypi.org/project/fairchem-core/1.10.0/),
&gt; as detailed [here](#looking-for-fairchem-v1-models-and-code).

### Read our latest release post!
Read about the [UMA model and dataset](https://ai.meta.com/blog/meta-fair-science-new-open-source-releases/) release.

[![Meta FAIR Science Release](https://github.com/user-attachments/assets/acddd09b-ed6f-4d05-9a4b-9ba5e2301150)](https://ai.meta.com/blog/meta-fair-science-new-open-source-releases/?ref=shareable)

### Try the demo!
If you want to explore model capabilities check out our
[educational demo](https://facebook-fairchem-uma-demo.hf.space/)

[![Educational Demo](https://github.com/user-attachments/assets/7005d1bb-4459-403d-b299-d41fdd8c48ec)](https://facebook-fairchem-uma-demo.hf.space/)


### Installation
Install fairchem-core using pip,
```bash
pip install git+https://github.com/facebookresearch/fairchem.git@fairchem_core-2.0.0#subdirectory=packages/fairchem-core
```
**The PyPI install (pip install fairchem-core) is not available right now as we are waiting for a few dependencies to release their PyPI packages, will update this soon when it&#039;s available!**

### Quick Start
The easiest way to use pretrained models is via the [ASE](https://wiki.fysik.dtu.dk/ase/) `FAIRChemCalculator`.
A single uma model can be used for a wide range of applications in chemistry and materials science by picking the
appropriate task name for domain specific prediction.

#### Instantiate a calculator from a pretrained model
Make sure you have a Hugging Face account, have already applied for model access to the 
[UMA model repository](https://huggingface.co/facebook/UMA), and have logged in to Hugging Face using an access token.

#### Set the task for your application and calculate

- **oc20:** use this for catalysis
- **omat:** use this for inorganic materials
- **omol:** use this for molecules
- **odac:** use this for MOFs
- **omc:** use this for molecular crystals

Relax adsorbate on a catalytic surface,
```python
from ase.build import fcc100, add_adsorbate, molecule
from ase.optimize import LBFGS
from fairchem.core import FAIRChemCalculator

calc = FAIRChemCalculator(hf_hub_filename=&quot;uma_sm.pt&quot;, device=&quot;cuda&quot;, task_name=&quot;oc20&quot;)

# Set up your system as an ASE atoms object
slab = fcc100(&quot;Cu&quot;, (3, 3, 3), vacuum=8, periodic=True)
adsorbate = molecule(&quot;CO&quot;)
add_adsorbate(slab, adsorbate, 2.0, &quot;bridge&quot;)

slab.calc = calc

# Set up LBFGS dynamics object
opt = LBFGS(slab)
opt.run(0.05, 100)
```

Or relax an inorganic crystal,
```python
from ase.build import bulk
from ase.optimize import FIRE
from ase.filters import FrechetCellFilter
from fairchem.core import FAIRChemCalculator

calc = FAIRChemCalculator(hf_hub_filename=&quot;uma_sm.pt&quot;, device=&quot;cuda&quot;, task_name=&quot;omat&quot;)

atoms = bulk(&quot;Fe&quot;)
atoms.calc = calc

opt = LBFGS(FrechetCellFilter(atoms))
opt.run(0.05, 100)
```

Run molecular MD,
```python
from ase import units
from ase.io import Trajectory
from ase.md.langevin import Langevin
from ase.build import molecule
from fairchem.core import FAIRChemCalculator

calc = FAIRChemCalculator(hf_hub_filename=&quot;uma_sm.pt&quot;, device=&quot;cuda&quot;, task_name=&quot;omol&quot;)

atoms = molecule(&quot;H2O&quot;)
atoms.calc = calc

dyn = Langevin(
    atoms,
    timestep=0.1 * units.fs,
    temperature_K=400,
    friction=0.001 / units.fs,
)
trajectory = Trajectory(&quot;my_md.traj&quot;, &quot;w&quot;, atoms)
dyn.attach(trajectory.write, interval=1)
dyn.run(steps=1000)
```


### Looking for Fairchem V1, models and code?
Fairchem V2 is a major upgrade and we completely rewrote the trainer, fine-tuning, models and calculators. 

We plan to bring back the following models compatible with Fairchem V2 soon:
* Gemnet-OC
* EquiformersV2
* ESEN

We will also be releasing more detailed documentation on how to use Fairchem V2, stay tuned! 

The old OCPCalculator, trainer code will NOT be revived. We apologize for the inconvenience and please raise Issues if you need help!
In the meantime, you can still use models from fairchem version 1, by installing version 1,

```bash
pip install fairchem-core==1.10
```

And using the `OCPCalculator`
```python
from fairchem.core import OCPCalculator

calc = OCPCalculator(
    model_name=&quot;EquiformerV2-31M-S2EF-OC20-All+MD&quot;,
    local_cache=&quot;pretrained_models&quot;,
    cpu=False,
)
```

### LICENSE
`fairchem` is available under a [MIT License](LICENSE.md).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[happycola233/tchMaterial-parser]]></title>
            <link>https://github.com/happycola233/tchMaterial-parser</link>
            <guid>https://github.com/happycola233/tchMaterial-parser</guid>
            <pubDate>Fri, 16 May 2025 00:04:20 GMT</pubDate>
            <description><![CDATA[å›½å®¶ä¸­å°å­¦æ™ºæ…§æ•™è‚²å¹³å° ç”µå­è¯¾æœ¬ä¸‹è½½å·¥å…·ï¼Œå¸®åŠ©æ‚¨ä»æ™ºæ…§æ•™è‚²å¹³å°ä¸­è·å–ç”µå­è¯¾æœ¬çš„ PDF æ–‡ä»¶ç½‘å€å¹¶è¿›è¡Œä¸‹è½½ï¼Œè®©æ‚¨æ›´æ–¹ä¾¿åœ°è·å–è¯¾æœ¬å†…å®¹ã€‚]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/happycola233/tchMaterial-parser">happycola233/tchMaterial-parser</a></h1>
            <p>å›½å®¶ä¸­å°å­¦æ™ºæ…§æ•™è‚²å¹³å° ç”µå­è¯¾æœ¬ä¸‹è½½å·¥å…·ï¼Œå¸®åŠ©æ‚¨ä»æ™ºæ…§æ•™è‚²å¹³å°ä¸­è·å–ç”µå­è¯¾æœ¬çš„ PDF æ–‡ä»¶ç½‘å€å¹¶è¿›è¡Œä¸‹è½½ï¼Œè®©æ‚¨æ›´æ–¹ä¾¿åœ°è·å–è¯¾æœ¬å†…å®¹ã€‚</p>
            <p>Language: Python</p>
            <p>Stars: 1,041</p>
            <p>Forks: 119</p>
            <p>Stars today: 261 stars today</p>
            <h2>README</h2><pre># [å›½å®¶ä¸­å°å­¦æ™ºæ…§æ•™è‚²å¹³å°](https://basic.smartedu.cn/tchMaterial/) ç”µå­è¯¾æœ¬ä¸‹è½½å·¥å…·

![Python Version](https://img.shields.io/badge/Python-3.x-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Made With Loveâ¤ï¸](https://img.shields.io/badge/Made_With-%E2%9D%A4-red.svg)

&gt; [!TIP]
&gt; ğŸš€æœ€æ–°ç‰ˆæœ¬ v3.0 ç°å·²å‘å¸ƒï¼Œæ¬¢è¿ä½“éªŒï¼

æœ¬å·¥å…·å¯ä»¥å¸®åŠ©æ‚¨ä»[**å›½å®¶ä¸­å°å­¦æ™ºæ…§æ•™è‚²å¹³å°**](https://basic.smartedu.cn/tchMaterial/)è·å–ç”µå­è¯¾æœ¬çš„ PDF æ–‡ä»¶ç½‘å€å¹¶è¿›è¡Œä¸‹è½½ï¼Œè®©æ‚¨æ›´æ–¹ä¾¿åœ°è·å–è¯¾æœ¬å†…å®¹ã€‚

&gt; [!NOTE]
&gt;
&gt; è‡ª**2025 å¹´ 2 æœˆ**èµ·ï¼Œå›½å®¶ä¸­å°å­¦æ™ºæ…§æ•™è‚²å¹³å°**éœ€è¦ç™»å½•**æ‰èƒ½è®¿é—®ç”µå­è¯¾æœ¬èµ„æºï¼Œç”¨æˆ·éœ€æä¾› **Access Token**ï¼ˆå³ç™»å½•å‡­æ®ï¼‰æ‰å¯æ­£å¸¸ä½¿ç”¨æœ¬å·¥å…·çš„ä¸‹è½½åŠŸèƒ½ã€‚
&gt;
&gt; **ğŸ‘‰è¯·å…ˆæŒ‰ç…§[ä¸‹æ–¹æŒ‡å—](#2-è®¾ç½®-access-token)è®¾ç½® Access Tokenï¼Œå¦åˆ™ç¨‹åºå°†æ— æ³•è§£æèµ„æºï¼**

## âœ¨å·¥å…·ç‰¹ç‚¹

- **æ”¯æŒ Access Token ç™»å½•**ğŸ”‘ï¼šæ”¯æŒç”¨æˆ·æ‰‹åŠ¨è¾“å…¥ Access Tokenï¼Œåœ¨ Windows æ“ä½œç³»ç»Ÿä¸‹ä¼šå­˜å…¥æ³¨å†Œè¡¨ï¼Œä¸‹æ¬¡å¯åŠ¨å¯è‡ªåŠ¨åŠ è½½ã€‚
- **æ”¯æŒæ‰¹é‡ä¸‹è½½**ğŸ“šï¼šä¸€æ¬¡è¾“å…¥å¤šä¸ªç”µå­è¯¾æœ¬é¢„è§ˆé¡µé¢ç½‘å€ï¼Œå³å¯æ‰¹é‡ä¸‹è½½ PDF è¯¾æœ¬æ–‡ä»¶ã€‚
- **è‡ªåŠ¨æ–‡ä»¶å‘½å**ğŸ“‚ï¼šç¨‹åºä¼šè‡ªåŠ¨ä½¿ç”¨æ•™æåç§°ä½œä¸ºæ–‡ä»¶åï¼Œæ–¹ä¾¿ç®¡ç†ä¸‹è½½çš„è¯¾æœ¬æ–‡ä»¶ã€‚
- **é«˜ DPI é€‚é…**ğŸ–¥ï¸ï¼šä¼˜åŒ– UI ä»¥é€‚é…é«˜åˆ†è¾¨ç‡å±å¹•ï¼Œé¿å…ç•Œé¢æ¨¡ç³Šé—®é¢˜ã€‚
- **ä¸‹è½½è¿›åº¦å¯è§†åŒ–**ğŸ“Šï¼šå®æ—¶æ˜¾ç¤ºä¸‹è½½è¿›åº¦ï¼Œæ”¯æŒæš‚åœ/æ¢å¤æ“ä½œã€‚
- **è·¨å¹³å°æ”¯æŒ**ğŸ’»ï¼šæ”¯æŒ Windowsã€Linuxã€macOS ç­‰æ“ä½œç³»ç»Ÿï¼ˆéœ€è¦å›¾å½¢ç•Œé¢ï¼‰ã€‚

![ç¨‹åºæˆªå›¾](./res/PixPin_2025-03-14_23-44-26.png)

## â¬‡ï¸ä¸‹è½½ä¸å®‰è£…æ–¹æ³•

### GitHub Releases é¡µé¢

ç”±äºæˆ‘ä»¬çš„ç²¾åŠ›æœ‰é™ï¼Œæœ¬é¡¹ç›®çš„ [GitHub Releases é¡µé¢](https://github.com/happycola233/tchMaterial-parser/releases)**ä»…ä¼šå‘å¸ƒé€‚ç”¨äº Windows ä¸ Linux æ“ä½œç³»ç»Ÿçš„ x64 æ¶æ„**çš„ç¨‹åºã€‚

åœ¨ä¸‹è½½å®Œæˆä¹‹åï¼Œå³å¯è¿è¡Œæœ¬ç¨‹åºï¼Œä¸éœ€è¦é¢å¤–çš„å®‰è£…æ­¥éª¤ã€‚

### Arch ç”¨æˆ·è½¯ä»¶ä»“åº“ï¼ˆAURï¼‰

å¯¹äº **Arch Linux** æ“ä½œç³»ç»Ÿï¼Œæœ¬ç¨‹åºå·²å‘å¸ƒè‡³[Arch ç”¨æˆ·è½¯ä»¶ä»“åº“](https://aur.archlinux.org/packages/tchmaterial-parser)ï¼Œå› æ­¤æ‚¨è¿˜å¯ä»¥é€šè¿‡åœ¨ç»ˆç«¯ä¸­è¾“å…¥ä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š

```sh
yay -S tchmaterial-parser
```

æ„Ÿè°¢ [@iamzhz](https://github.com/iamzhz) åˆ¶ä½œäº†æœ¬å·¥å…·çš„å‘è¡ŒåŒ…ï¼ˆ[#26](../../issues/26)ï¼‰ï¼

## ğŸ› ï¸ä½¿ç”¨æ–¹æ³•

### 1. è¾“å…¥æ•™æé“¾æ¥ğŸ“¥

å°†ç”µå­è¯¾æœ¬çš„**é¢„è§ˆé¡µé¢ç½‘å€**ç²˜è´´åˆ°ç¨‹åºæ–‡æœ¬æ¡†ä¸­ï¼Œæ”¯æŒå¤šä¸ª URLï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰ã€‚

**ç¤ºä¾‹ç½‘å€**ï¼š

```text
https://basic.smartedu.cn/tchMaterial/detail?contentType=assets_document&amp;contentId=XXXXXX&amp;catalogType=tchMaterial&amp;subCatalog=tchMaterial
```

### 2. è®¾ç½® Access TokenğŸ”‘

è‹¥æ‚¨ç¬¬ä¸€æ¬¡ä½¿ç”¨æœ¬ç¨‹åºï¼Œéœ€ç‚¹å‡» â€œ**è®¾ç½® Token**â€ æŒ‰é’®ï¼Œç²˜è´´ Access Token å¹¶ä¿å­˜ã€‚

1. **æ‰“å¼€æµè§ˆå™¨**ï¼Œè®¿é—®[å›½å®¶ä¸­å°å­¦æ™ºæ…§æ•™è‚²å¹³å°](https://auth.smartedu.cn/uias/login)å¹¶**ç™»å½•è´¦å·**ã€‚
2. æŒ‰ä¸‹ **F12** æˆ– **Ctrl+Shift+I**ï¼Œæˆ–å³é”®â€”â€”æ£€æŸ¥ï¼ˆå®¡æŸ¥å…ƒç´ ï¼‰æ‰“å¼€**å¼€å‘è€…å·¥å…·**ï¼Œé€‰æ‹©**æ§åˆ¶å°ï¼ˆConsoleï¼‰**ã€‚
3. åœ¨æ§åˆ¶å°ç²˜è´´ä»¥ä¸‹ä»£ç åå›è½¦ï¼ˆEnterï¼‰ï¼š

   ```js
   (function() {
     const authKey = Object.keys(localStorage).find(key =&gt; key.startsWith(&quot;ND_UC_AUTH&quot;));
     if (!authKey) {
       console.error(&quot;æœªæ‰¾åˆ° Access Tokenï¼Œè¯·ç¡®ä¿å·²ç™»å½•ï¼&quot;);
       return;
     }
     const tokenData = JSON.parse(localStorage.getItem(authKey));
     const accessToken = JSON.parse(tokenData.value).access_token;
     console.log(&quot;%cAccess Token: &quot;, &quot;color: green; font-weight: bold&quot;, accessToken);
   })();
   ```
  
4. å¤åˆ¶æ§åˆ¶å°è¾“å‡ºçš„ **Access Token**ï¼Œç„¶ååœ¨æœ¬ç¨‹åºä¸­ç‚¹å‡» â€œ**è®¾ç½® Token**â€ æŒ‰é’®ï¼Œç²˜è´´å¹¶ä¿å­˜ Tokenã€‚

&gt; [!NOTE]
&gt; Access Token å¯èƒ½ä¼šè¿‡æœŸï¼Œè‹¥ä¸‹è½½å¤±è´¥æç¤º **401 Unauthorized**ï¼Œè¯·é‡æ–°è·å–å¹¶è®¾ç½®æ–°çš„ Tokenã€‚

### 3. å¼€å§‹ä¸‹è½½ğŸš€

ç‚¹å‡» â€œ**ä¸‹è½½**â€ æŒ‰é’®ï¼Œç¨‹åºå°†è‡ªåŠ¨è§£æå¹¶ä¸‹è½½ PDF è¯¾æœ¬ã€‚

æœ¬å·¥å…·æ”¯æŒ**æ‰¹é‡ä¸‹è½½**ï¼Œæ‰€æœ‰ PDF æ–‡ä»¶ä¼šè‡ªåŠ¨æŒ‰è¯¾æœ¬åç§°å‘½åå¹¶ä¿å­˜åœ¨é€‰å®šç›®å½•ä¸­ã€‚

## â“å¸¸è§é—®é¢˜

### 1. ä¸ºä»€ä¹ˆä¸‹è½½å¤±è´¥ï¼Ÿâš ï¸

- æ£€æŸ¥æ˜¯å¦å·²[**æ­£ç¡®è®¾ç½® Access Token**](#2-è®¾ç½®-access-token)ğŸ”‘ï¼Œä¸”æ²¡æœ‰è¿‡æœŸã€‚
- **ç¡®è®¤ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸**ğŸŒï¼Œæœ‰æ—¶ç½‘ç»œä¸ç¨³å®šå¯èƒ½å¯¼è‡´ä¸‹è½½å¤±è´¥ã€‚
- **ç¡®ä¿è¾“å…¥çš„ç½‘å€æœ‰æ•ˆ**ğŸ”—ï¼Œéƒ¨åˆ†æ—§èµ„æºå¯èƒ½å·²è¢«ç§»é™¤ã€‚

### 2. Access Token ä¿å­˜åœ¨å“ªé‡Œï¼ŸğŸ’¾

- **Windows æ“ä½œç³»ç»Ÿ**ï¼šToken ä¼šå­˜å‚¨åœ¨**æ³¨å†Œè¡¨** `HKEY_CURRENT_USER\Software\tchMaterial-parser` é¡¹ä¸­çš„ `AccessToken` å€¼ã€‚
- **Linux æ“ä½œç³»ç»Ÿ**: Token ä¼šå­˜å‚¨åœ¨ `~/.config/tchMaterial-parser/data.json` çš„æ–‡ä»¶ä¸­ã€‚
- **macOS ç­‰æ“ä½œç³»ç»Ÿ**ï¼šToken ä»…åœ¨è¿è¡Œæ—¶ä¸´æ—¶å­˜å‚¨äºå†…å­˜ï¼Œä¸ä¼šè‡ªåŠ¨ä¿å­˜ï¼Œç¨‹åºé‡å¯åéœ€é‡æ–°è¾“å…¥ï¼Œç›®å‰æˆ‘ä»¬æ­£åœ¨åŠªåŠ›æ”¹è¿›è¯¥åŠŸèƒ½ã€‚

### 3. Token ä¼šä¸ä¼šæ³„éœ²ï¼ŸğŸ”

- æœ¬ç¨‹åº**ä¸ä¼šä¸Šä¼ ** Tokenï¼Œä¹Ÿä¸ä¼šå­˜å‚¨åœ¨äº‘ç«¯ï¼Œä»…ç”¨äºæœ¬åœ°è¯·æ±‚æˆæƒã€‚
- **è¯·å‹¿åœ¨å…¬å¼€åœºåˆåˆ†äº« Token**ï¼Œä»¥å…æ‚¨çš„è´¦å·è¢«ä»–äººä½¿ç”¨ï¼Œé€ æˆä¸¥é‡åæœã€‚

## â­Star History

[![Star History Chart](https://api.star-history.com/svg?repos=happycola233/tchMaterial-parser&amp;type=Date)](https://star-history.com/#happycola233/tchMaterial-parser&amp;Date)

## ğŸ¤è´¡çŒ®æŒ‡å—

å¦‚æœæ‚¨å‘ç° Bug æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œæ¬¢è¿æäº¤ **Issue** æˆ– **Pull Request**ï¼Œè®©æˆ‘ä»¬ä¸€èµ·å®Œå–„æœ¬å·¥å…·ï¼

## ğŸ“œè®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº [MIT è®¸å¯è¯](LICENSE)ï¼Œæ¬¢è¿è‡ªç”±ä½¿ç”¨å’ŒäºŒæ¬¡å¼€å‘ã€‚

## ğŸ’Œå‹æƒ…é“¾æ¥

- ğŸ“šæ‚¨ä¹Ÿå¯ä»¥åœ¨ [ChinaTextbook](https://github.com/TapXWorld/ChinaTextbook) é¡¹ç›®ä¸­ä¸‹è½½å½’æ¡£çš„æ•™æ PDFã€‚
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[trycua/cua]]></title>
            <link>https://github.com/trycua/cua</link>
            <guid>https://github.com/trycua/cua</guid>
            <pubDate>Fri, 16 May 2025 00:04:19 GMT</pubDate>
            <description><![CDATA[c/ua is the Docker Container for Computer-Use AI Agents.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/trycua/cua">trycua/cua</a></h1>
            <p>c/ua is the Docker Container for Computer-Use AI Agents.</p>
            <p>Language: Python</p>
            <p>Stars: 6,817</p>
            <p>Forks: 269</p>
            <p>Stars today: 304 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; alt=&quot;Cua logo&quot; height=&quot;150&quot; srcset=&quot;img/logo_white.png&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; alt=&quot;Cua logo&quot; height=&quot;150&quot; srcset=&quot;img/logo_black.png&quot;&gt;
    &lt;img alt=&quot;Cua logo&quot; height=&quot;150&quot; src=&quot;img/logo_black.png&quot;&gt;
  &lt;/picture&gt;

  [![Python](https://img.shields.io/badge/Python-333333?logo=python&amp;logoColor=white&amp;labelColor=333333)](#)
  [![Swift](https://img.shields.io/badge/Swift-F05138?logo=swift&amp;logoColor=white)](#)
  [![macOS](https://img.shields.io/badge/macOS-000000?logo=apple&amp;logoColor=F0F0F0)](#)
  [![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?&amp;logo=discord&amp;logoColor=white)](https://discord.com/invite/mVnXXpdE85)
  &lt;br&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/13685&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13685&quot; alt=&quot;trycua%2Fcua | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

**c/ua** (pronounced &quot;koo-ah&quot;) enables AI agents to control full operating systems in high-performance virtual containers with near-native speed on Apple Silicon.

&lt;div align=&quot;center&quot;&gt;
  &lt;video src=&quot;https://github.com/user-attachments/assets/c619b4ea-bb8e-4382-860e-f3757e36af20&quot; width=&quot;800&quot; controls&gt;&lt;/video&gt;
&lt;/div&gt;

# ğŸš€ Quick Start

Get started with a Computer-Use Agent UI and a VM with a single command:


```bash
/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/scripts/playground.sh)&quot;
```


This script will:
- Install Lume CLI for VM management (if needed)
- Pull the latest macOS CUA image (if needed)
- Set up Python environment and install/update required packages
- Launch the Computer-Use Agent UI

#### Supported [Agent Loops](https://github.com/trycua/cua/blob/main/libs/agent/README.md#agent-loops)
- [UITARS-1.5](https://github.com/trycua/cua/blob/main/libs/agent/README.md#agent-loops) - Run locally on Apple Silicon with MLX, or use cloud providers
- [OpenAI CUA](https://github.com/trycua/cua/blob/main/libs/agent/README.md#agent-loops) - Use OpenAI&#039;s Computer-Use Preview model
- [Anthropic CUA](https://github.com/trycua/cua/blob/main/libs/agent/README.md#agent-loops) - Use Anthropic&#039;s Computer-Use capabilities
- [OmniParser-v2.0](https://github.com/trycua/cua/blob/main/libs/agent/README.md#agent-loops) - Control UI with [Set-of-Marks prompting](https://som-gpt4v.github.io/) using any vision model

### System Requirements

- Mac with Apple Silicon (M1/M2/M3/M4 series)
- macOS 15 (Sequoia) or newer
- Disk space for VM images (30GB+ recommended)


# ğŸ’» For Developers

### Step 1: Install Lume CLI

```bash
/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh)&quot;
```

Lume CLI manages high-performance macOS/Linux VMs with near-native speed on Apple Silicon.

### Step 2: Pull the macOS CUA Image

```bash
lume pull macos-sequoia-cua:latest
```

The macOS CUA image contains the default Mac apps and the Computer Server for easy automation.

### Step 3: Install Python SDK

```bash
pip install &quot;cua-computer[all]&quot; &quot;cua-agent[all]&quot;
```

Alternatively, see the [Developer Guide](./docs/Developer-Guide.md) for building from source.

### Step 4: Use in Your Code

```python
from computer import Computer
from agent import ComputerAgent, LLM

async def main():
    # Start a local macOS VM with a 1024x768 display
    async with Computer(os_type=&quot;macos&quot;, display=&quot;1024x768&quot;) as computer:

        # Example: Direct control of a macOS VM with Computer
        await computer.interface.left_click(100, 200)
        await computer.interface.type_text(&quot;Hello, world!&quot;)
        screenshot_bytes = await computer.interface.screenshot()
        
        # Example: Create and run an agent locally using mlx-community/UI-TARS-1.5-7B-6bit
        agent = ComputerAgent(
          computer=computer,
          loop=&quot;UITARS&quot;,
          model=LLM(provider=&quot;MLXVLM&quot;, name=&quot;mlx-community/UI-TARS-1.5-7B-6bit&quot;)
        )
        await agent.run(&quot;Find the trycua/cua repository on GitHub and follow the quick start guide&quot;)

main()
```

For ready-to-use examples, check out our [Notebooks](./notebooks/) collection.

### Lume CLI Reference

```bash
# Install Lume CLI and background service
curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh | bash

# List all VMs
lume ls

# Pull a VM image
lume pull macos-sequoia-cua:latest

# Create a new VM
lume create my-vm --os macos --cpu 4 --memory 8GB --disk-size 50GB

# Run a VM (creates and starts if it doesn&#039;t exist)
lume run macos-sequoia-cua:latest

# Stop a VM
lume stop macos-sequoia-cua_latest

# Delete a VM
lume delete macos-sequoia-cua_latest
```

### Lumier CLI Reference

For advanced container-like virtualization, check out [Lumier](./libs/lumier/README.md) - a Docker interface for macOS and Linux VMs.

```bash
# Install Lume CLI and background service
curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh | bash

# Run macOS in a Docker container
docker run -it --rm \
    --name lumier-vm \
    -p 8006:8006 \
    -v $(pwd)/storage:/storage \
    -v $(pwd)/shared:/shared \
    -e VM_NAME=lumier-vm \
    -e VERSION=ghcr.io/trycua/macos-sequoia-cua:latest \
    -e CPU_CORES=4 \
    -e RAM_SIZE=8192 \
    -e HOST_STORAGE_PATH=$(pwd)/storage \
    -e HOST_SHARED_PATH=$(pwd)/shared \
    trycua/lumier:latest
```

## Resources

- [How to use the MCP Server with Claude Desktop or other MCP clients](./libs/mcp-server/README.md) - One of the easiest ways to get started with C/ua
- [How to use OpenAI Computer-Use, Anthropic, OmniParser, or UI-TARS for your Computer-Use Agent](./libs/agent/README.md)
- [How to use Lume CLI for managing desktops](./libs/lume/README.md)
- [Training Computer-Use Models: Collecting Human Trajectories with C/ua (Part 1)](https://www.trycua.com/blog/training-computer-use-models-trajectories-1)
- [Build Your Own Operator on macOS (Part 1)](https://www.trycua.com/blog/build-your-own-operator-on-macos-1)

## Modules

| Module | Description | Installation |
|--------|-------------|---------------|
| [**Lume**](./libs/lume/README.md) | VM management for macOS/Linux using Apple&#039;s Virtualization.Framework | `curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh \| bash` |
| [**Lumier**](./libs/lumier/README.md) | Docker interface for macOS and Linux VMs | `docker pull trycua/lumier:latest` |
| [**Computer**](./libs/computer/README.md) | Interface for controlling virtual machines | `pip install &quot;cua-computer[all]&quot;` |
| [**Agent**](./libs/agent/README.md) | AI agent framework for automating tasks | `pip install &quot;cua-agent[all]&quot;` |
| [**MCP Server**](./libs/mcp-server/README.md) | MCP server for using CUA with Claude Desktop | `pip install cua-mcp-server` |
| [**SOM**](./libs/som/README.md) | Self-of-Mark library for Agent | `pip install cua-som` |
| [**PyLume**](./libs/pylume/README.md) | Python bindings for Lume | `pip install pylume` |
| [**Computer Server**](./libs/computer-server/README.md) | Server component for Computer | `pip install cua-computer-server` |
| [**Core**](./libs/core/README.md) | Core utilities | `pip install cua-core` |

## Computer Interface Reference

For complete examples, see [computer_examples.py](./examples/computer_examples.py) or [computer_nb.ipynb](./notebooks/computer_nb.ipynb)

```python
# Mouse Actions
await computer.interface.left_click(x, y)       # Left click at coordinates
await computer.interface.right_click(x, y)      # Right click at coordinates
await computer.interface.double_click(x, y)     # Double click at coordinates
await computer.interface.move_cursor(x, y)      # Move cursor to coordinates
await computer.interface.drag_to(x, y, duration)  # Drag to coordinates
await computer.interface.get_cursor_position()  # Get current cursor position

# Keyboard Actions
await computer.interface.type_text(&quot;Hello&quot;)     # Type text
await computer.interface.press_key(&quot;enter&quot;)     # Press a single key
await computer.interface.hotkey(&quot;command&quot;, &quot;c&quot;) # Press key combination

# Screen Actions
await computer.interface.screenshot()           # Take a screenshot
await computer.interface.get_screen_size()      # Get screen dimensions

# Clipboard Actions
await computer.interface.set_clipboard(text)    # Set clipboard content
await computer.interface.copy_to_clipboard()    # Get clipboard content

# File System Operations
await computer.interface.file_exists(path)      # Check if file exists
await computer.interface.directory_exists(path) # Check if directory exists
await computer.interface.run_command(cmd)       # Run shell command

# Accessibility
await computer.interface.get_accessibility_tree() # Get accessibility tree
```

## ComputerAgent Reference

For complete examples, see [agent_examples.py](./examples/agent_examples.py) or [agent_nb.ipynb](./notebooks/agent_nb.ipynb)

```python
# Import necessary components
from agent import ComputerAgent, LLM, AgentLoop, LLMProvider

# UI-TARS-1.5 agent for local execution with MLX
ComputerAgent(loop=AgentLoop.UITARS, model=LLM(provider=LLMProvider.MLXVLM, name=&quot;mlx-community/UI-TARS-1.5-7B-6bit&quot;))   
# OpenAI Computer-Use agent using OPENAI_API_KEY  
ComputerAgent(loop=AgentLoop.OPENAI, model=LLM(provider=LLMProvider.OPENAI, name=&quot;computer-use-preview&quot;))
# Anthropic Claude agent using ANTHROPIC_API_KEY
ComputerAgent(loop=AgentLoop.ANTHROPIC, model=LLM(provider=LLMProvider.ANTHROPIC))

# OmniParser loop for UI control using Set-of-Marks (SOM) prompting and any vision LLM
ComputerAgent(loop=AgentLoop.OMNI, model=LLM(provider=LLMProvider.OLLAMA, name=&quot;gemma3:12b-it-q4_K_M&quot;))      
# OpenRouter example using OAICOMPAT provider
ComputerAgent(
    loop=AgentLoop.OMNI,
    model=LLM(
        provider=LLMProvider.OAICOMPAT, 
        name=&quot;openai/gpt-4o-mini&quot;,
        provider_base_url=&quot;https://openrouter.ai/api/v1&quot;
    ),
    api_key=&quot;your-openrouter-api-key&quot;
)
```

## Demos

Check out these demos of the Computer-Use Agent in action:

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;MCP Server: Work with Claude Desktop and Tableau&lt;/b&gt;&lt;/summary&gt;
&lt;br&gt;
&lt;div align=&quot;center&quot;&gt;
    &lt;video src=&quot;https://github.com/user-attachments/assets/9f573547-5149-493e-9a72-396f3cff29df&quot; width=&quot;800&quot; controls&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;AI-Gradio: Multi-app workflow with browser, VS Code and terminal&lt;/b&gt;&lt;/summary&gt;
&lt;br&gt;
&lt;div align=&quot;center&quot;&gt;
    &lt;video src=&quot;https://github.com/user-attachments/assets/723a115d-1a07-4c8e-b517-88fbdf53ed0f&quot; width=&quot;800&quot; controls&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Notebook: Fix GitHub issue in Cursor&lt;/b&gt;&lt;/summary&gt;
&lt;br&gt;
&lt;div align=&quot;center&quot;&gt;
    &lt;video src=&quot;https://github.com/user-attachments/assets/f67f0107-a1e1-46dc-aa9f-0146eb077077&quot; width=&quot;800&quot; controls&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;/details&gt;

## Community

Join our [Discord community](https://discord.com/invite/mVnXXpdE85) to discuss ideas, get assistance, or share your demos!

## License

Cua is open-sourced under the MIT License - see the [LICENSE](LICENSE) file for details.

Microsoft&#039;s OmniParser, which is used in this project, is licensed under the Creative Commons Attribution 4.0 International License (CC-BY-4.0) - see the [OmniParser LICENSE](https://github.com/microsoft/OmniParser/blob/master/LICENSE) file for details.

## Contributing

We welcome contributions to CUA! Please refer to our [Contributing Guidelines](CONTRIBUTING.md) for details.

## Trademarks

Apple, macOS, and Apple Silicon are trademarks of Apple Inc. Ubuntu and Canonical are registered trademarks of Canonical Ltd. Microsoft is a registered trademark of Microsoft Corporation. This project is not affiliated with, endorsed by, or sponsored by Apple Inc., Canonical Ltd., or Microsoft Corporation.

## Stargazers

Thank you to all our supporters!

[![Stargazers over time](https://starchart.cc/trycua/cua.svg?variant=adaptive)](https://starchart.cc/trycua/cua)

## Contributors

&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt;
&lt;!-- prettier-ignore-start --&gt;
&lt;!-- markdownlint-disable --&gt;
&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/f-trycua&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/195596869?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;f-trycua&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;f-trycua&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-f-trycua&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://pepicrft.me&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/663605?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Pedro PiÃ±era BuendÃ­a&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Pedro PiÃ±era BuendÃ­a&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-pepicrft&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://iamit.in&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/5647941?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Amit Kumar&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Amit Kumar&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-aktech&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://productsway.com/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/870029?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Dung Duc Huynh (Kaka)&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Dung Duc Huynh (Kaka)&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-jellydn&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://zaydkrunz.com&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/70227235?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Zayd Krunz&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Zayd Krunz&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-ShrootBuck&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/PrashantRaj18198&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/23168997?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Prashant Raj&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Prashant Raj&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-PrashantRaj18198&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.mobile.dev&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/847683?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Leland Takamine&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Leland Takamine&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-Leland-Takamine&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/ddupont808&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/3820588?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;ddupont&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;ddupont&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-ddupont808&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/Lizzard1123&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/46036335?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Ethan Gutierrez&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ethan Gutierrez&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-Lizzard1123&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://ricterz.me&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/5282759?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Ricter Zheng&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ricter Zheng&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-RicterZ&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.trytruffle.ai/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/50844303?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Rahul Karajgikar&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Rahul Karajgikar&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-rahulkarajgikar&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/trospix&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/81363696?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;trospix&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;trospix&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-trospix&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://wavee.world/invitation/b96d00e6-b802-4a1b-8a66-2e3854a01ffd&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/22633385?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Ikko Eltociear Ashimine&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ikko Eltociear Ashimine&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-eltociear&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/dp221125&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/10572119?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;í•œì„í˜¸(MilKyo)&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;í•œì„í˜¸(MilKyo)&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-dp221125&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.encona.com/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/891558?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Rahim Nathwani&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Rahim Nathwani&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-rahimnathwani&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://mjspeck.github.io/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/20689127?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Matt Speck&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Matt Speck&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-mjspeck&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/FinnBorge&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/9272726?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;FinnBorge&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;FinnBorge&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-FinnBorge&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/jklapacz&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/5343758?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Jakub Klapacz&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jakub Klapacz&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-jklapacz&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;!-- markdownlint-restore --&gt;
&lt;!-- prettier-ignore-end --&gt;

&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[xaoyaoo/PyWxDump]]></title>
            <link>https://github.com/xaoyaoo/PyWxDump</link>
            <guid>https://github.com/xaoyaoo/PyWxDump</guid>
            <pubDate>Fri, 16 May 2025 00:04:18 GMT</pubDate>
            <description><![CDATA[è·å–å¾®ä¿¡ä¿¡æ¯ï¼›è¯»å–æ•°æ®åº“ï¼Œæœ¬åœ°æŸ¥çœ‹èŠå¤©è®°å½•å¹¶å¯¼å‡ºä¸ºcsvã€htmlç­‰æ ¼å¼ç”¨äºAIè®­ç»ƒï¼Œè‡ªåŠ¨å›å¤ç­‰ã€‚æ”¯æŒå¤šè´¦æˆ·ä¿¡æ¯è·å–ï¼Œæ”¯æŒæ‰€æœ‰å¾®ä¿¡ç‰ˆæœ¬ã€‚]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/xaoyaoo/PyWxDump">xaoyaoo/PyWxDump</a></h1>
            <p>è·å–å¾®ä¿¡ä¿¡æ¯ï¼›è¯»å–æ•°æ®åº“ï¼Œæœ¬åœ°æŸ¥çœ‹èŠå¤©è®°å½•å¹¶å¯¼å‡ºä¸ºcsvã€htmlç­‰æ ¼å¼ç”¨äºAIè®­ç»ƒï¼Œè‡ªåŠ¨å›å¤ç­‰ã€‚æ”¯æŒå¤šè´¦æˆ·ä¿¡æ¯è·å–ï¼Œæ”¯æŒæ‰€æœ‰å¾®ä¿¡ç‰ˆæœ¬ã€‚</p>
            <p>Language: Python</p>
            <p>Stars: 7,920</p>
            <p>Forks: 1,234</p>
            <p>Stars today: 252 stars today</p>
            <h2>README</h2><pre>[![ä¸­æ–‡](https://img.shields.io/badge/README-ä¸­æ–‡-494cad.svg)](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/README_CN.md) [![English](https://img.shields.io/badge/README-English-494cad.svg)](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/README_EN.md)

# &lt;center&gt;PyWxDump&lt;/center&gt;

[![Python](https://img.shields.io/badge/Python-3-blue.svg)](https://www.python.org/)
[![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/xaoyaoo/pywxdump)](https://github.com/xaoyaoo/PyWxDump)
[![GitHub all releases](https://img.shields.io/github/downloads/xaoyaoo/pywxdump/total)](https://github.com/xaoyaoo/PyWxDump)
[![GitHub stars](https://img.shields.io/github/stars/xaoyaoo/PyWxDump.svg)](https://github.com/xaoyaoo/PyWxDump)
[![GitHub forks](https://img.shields.io/github/forks/xaoyaoo/PyWxDump.svg)](https://github.com/xaoyaoo/PyWxDump/fork)
[![GitHub issues](https://img.shields.io/github/issues/xaoyaoo/PyWxDump)](https://github.com/xaoyaoo/PyWxDump/issues)

[![PyPI](https://img.shields.io/pypi/v/pywxdump)](https://pypi.org/project/pywxdump/)
[![Wheel](https://img.shields.io/pypi/wheel/pywxdump)](https://pypi.org/project/pywxdump/)
[![PyPI-Downloads](https://img.shields.io/pypi/dm/pywxdump)](https://pypistats.org/packages/pywxdump)
[![GitHub license](https://img.shields.io/pypi/l/pywxdump)](https://github.com/xaoyaoo/PyWxDump/blob/master/LICENSE)

* Welcome to provide more ideas or code to improve this project together.

### If you are a novice, please pay attention to the Official Accounts: `é€é¥ä¹‹èŠ¯` (the QR code is below), and reply: `PyWxDump` to get a picture text tutorial.

### If you have any questions, please check first: [FAQ](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/FAQ.md) Whether there is an answer, or follow the Official Accounts to reply: `FAQ`.

QQ GROUPï¼š[276392799](https://s.xaoyo.top/gOLUDl) or [276392799](https://s.xaoyo.top/bgNcRa)ï¼ˆPASSWORD,please read:[UserGuide.md](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/UserGuide.md)ï¼‰.

&lt;div&gt;
  &lt;img align=&quot;&quot; width=&quot;200&quot;  src=&quot;https://github.com/xaoyaoo/PyWxDump/blob/master/doc/img/qrcode_gh.jpg&quot; alt=&quot;the Official Accounts&quot; title=&quot;the Official Accounts&quot; height=&quot;200&quot;/&gt;
&lt;/div&gt;

# I. Project Introduction

## 1. Brief Introduction

[PyWxDump](https://github.com/xaoyaoo/PyWxDump) is a tool for obtaining wx account information (nicknames/accounts/phones/emails/database keys), decrypting databases, viewing wx chat, and exporting chat as html backups.

* &lt;strong&gt;&lt;big&gt;Super eager for stars, if you&#039;ve come across this project, please give me a [![Star](https://img.shields.io/github/stars/xaoyaoo/PyWxDump.svg?style=social&amp;label=Star)](https://github.com/xaoyaoo/PyWxDump/)! Thank you so much~ &lt;/big&gt;&lt;/strong&gt;

## 2. Feature

#### 2.1 Core

* (1) Get the **base address offset** of WeChat nickname, WeChat account, WeChat phone number, WeChat email, and WeChat KEY
* (2) Get the WeChat nickname, WeChat account, WeChat phone number, WeChat email, WeChat KEY, WeChat original ID (wxid_******), and WeChat folder path of the currently logged-in WeChat
* (3) Decrypt WeChat database based on key
* (4) Combine multiple types of databases for unified viewing

#### 2.2 Extend Function

* (1) View chat history through the web
* (2) Support exporting chat logs as html, csv, and backing up WeChat chat logs
* (3) Remote viewing of WeChat chat history (must be network accessible, such as a local area network)

#### 2.3 Document Class

* (1) Provide descriptions of some fields in the database
* (2) Provide CE to obtain the base address offset method
* (3) Provide a decryption method for MAC database

#### 2.4 Other functions

* (1) Added a minimalist version of [pywxdumpmini](https://github.com/xaoyaoo/pywxdumpmini), which provides only the ability to obtain database keys and database locations
* (2) Support multiple WeChat opening scenarios, obtain multiple user information, etc.

**Utilize the scene**

1. Network security...
2. Daily backup archiving
3. View chat history remotely (view chat history through the web)
4. Wait...............

## 3. Update plan

* 1.Analyze chat logs of each person and generate word clouds.
* ~~2.Analyze the number of chats per person per day and generate a line chart (day-number of chats)~~
* ~~3.Analyze the monthly and annual chat volume of different people and generate a line chart~~
* ~~4.Generate annual visualization reports~~
* 8.Increase support for enterprise WeChat
* 12.Viewing and backing up of the circle of friends
* ~~13.Clean up WeChat storage space and reduce the space occupied by WeChat (hopefully by selecting a person or group and finding out the media files involved in the chat logs of this group, such as pictures, videos, files, voice recordings, etc., and selectively (such as time periods) or batch-wise clearing them from the computer&#039;s cache by group conversation.)~~
* 14.Automatically send messages to specified people through UI control

## 4. Other

[PyWxDump](https://github.com/xaoyaoo/PyWxDump) is a refactored python language version of [SharpWxDump](https://github.com/AdminTest0/SharpWxDump), with many new features added.

* Project address: https://github.com/xaoyaoo/PyWxDump
* Currently tested only under Windows, there may be issues under mac and Linux.
* If you find any missing or incorrect information, bugs, or suggestions for improvement in the [WX_OFFS.json](https://github.com/xaoyaoo/PyWxDump/tree/master/pywxdump/WX_OFFS.json), please submit an issue on GitHub.
* For common issues, please refer to [FAQ](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/FAQ.md), and for the update log, please refer to [CHANGELOG](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/CHANGELOG.md)
* Web UI repository location [wxdump_web](https://github.com/xaoyaoo/wxdump_web )
* If you are interested in the implementation principle of wxdump, please pay attention to the Official Accounts: `é€é¥ä¹‹èŠ¯`, reply: `åŸç†` to get the principle analysis.
* [:sparkling\_heart: Support Me]( https://github.com/xaoyaoo/xaoyaoo/blob/main/donate.md)

## 5. Star History

&lt;details&gt;
&lt;summary&gt;click to expand&lt;/summary&gt;

[![Star History Chart](https://api.star-history.com/svg?repos=xaoyaoo/pywxdump&amp;type=Date)](https://star-history.com/#xaoyaoo/pywxdump&amp;Date)

&lt;/details&gt;

# â…¡. Instructions For Use

* Detailed instructions, see: [UserGuide.md](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/UserGuide.md)

* the minimalist version, see: [pywxdumpmini](https://github.com/xaoyaoo/pywxdumpmini)

* If you want to modify the UI, clone the [wx_dump_web](https://github.com/xaoyaoo/wxdump_web) and modify it as needed (the UI is developed using VUE+ElementUI)

ã€noteã€‘:

* For obtaining the base address using cheat engine, refer to [CE obtaining base address.md](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/CEè·å–åŸºå€.md)
  (This method can be replaced by the `wxdump bias` command, and is only used for learning principles.)
* For database parsing, refer to [wx database brief.md](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/wxæ•°æ®åº“ç®€è¿°.md)

# â…¢. Disclaimer (VERY VERY VERY IMPORTANT ! ! ! ! ! !)

### 1. Purpose of use

* This project is only for learning and communication purposes, **please do not use it for illegal purposes**, **please do not use it for illegal purposes**, **please do not use it for illegal purposes**, otherwise the consequences will be borne by yourself.
* Users understand and agree that any violation of laws and regulations, infringement of the legitimate rights and interests of others, is unrelated to this project and its developers, and the consequences are borne by the user themselves.

### 2. Usage Period

* You should delete the source code and (compiled) program of this project within 24 hours of downloading, saving, compiling, and using it; any use beyond this period is not related to this project or its developer.

### 3. Operation specifications

* This project only allows backup and viewing of the database under authorization. It is strictly prohibited for illegal purposes, otherwise all related responsibilities will be borne by the user. Any legal liability incurred by the user due to violation of this regulation will be borne by the user, and is unrelated to this project and its developer.
* It is strictly prohibited to use it to steal others&#039; privacy. Otherwise, all relevant responsibilities shall be borne by yourself.
* It is strictly prohibited to conduct secondary development, otherwise all related responsibilities shall be borne by yourself.

### 4. Acceptance of Disclaimer

* Downloading, saving, further browsing the source code, or downloading, installing, compiling, and using this program indicates that you agree with this warning and promise to abide by it;

### 5. Forbidden for illegal testing or penetration

* It is prohibited to use the relevant technologies of this project to engage in illegal testing or penetration, and it is prohibited to use the relevant codes or related technologies of this project to engage in any illegal work. Any adverse consequences arising therefrom are not related to this project and its developers.
* Any resulting adverse consequences, including but not limited to data leakage, system failure, and privacy infringement, are not related to this project or its developers and are the responsibility of the user.

### 6. Modification of disclaimer

* This disclaimer may be modified and adjusted based on the project&#039;s operating conditions and changes in laws and regulations. Users should regularly check this page for the latest version of the disclaimer, and should comply with the latest version of the disclaimer when using this project.

### 7. Others

* In addition to the provisions of this disclaimer, users should comply with relevant laws, regulations, and ethical norms during the use of this project. The project and its developers will not be held responsible for any disputes or losses caused by users&#039; violation of relevant regulations.

* Users are requested to carefully read and understand all contents of this disclaimer, and ensure that they strictly comply with relevant regulations when using this project.

# â…£. Acknowledgments

[![PyWxDump CONTRIBUTORS](https://contrib.rocks/image?repo=xaoyaoo/PyWxDump)](https://github.com/xaoyaoo/PyWxDump/graphs/contributors)  

UI CONTRIBUTORS:    

[![UI CONTRIBUTORS](https://contrib.rocks/image?repo=xaoyaoo/wxdump_web)](https://github.com/xaoyaoo/wxdump_web/graphs/contributors)

otherContributors:

[643104191](https://github.com/643104191) (add [ctypes_utils](https://github.com/xaoyaoo/PyWxDump/blob/9e3e4cb5aec2b9b445c8283d61c58863f4129c6e/pywxdump/wx_info/ctypes_utils.py), Accelerated the acquisition of wxinfo; [9e3e4cb](https://github.com/xaoyaoo/PyWxDump/commit/9e3e4cb5aec2b9b445c8283d61c58863f4129c6e))

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Zeyi-Lin/HivisionIDPhotos]]></title>
            <link>https://github.com/Zeyi-Lin/HivisionIDPhotos</link>
            <guid>https://github.com/Zeyi-Lin/HivisionIDPhotos</guid>
            <pubDate>Fri, 16 May 2025 00:04:17 GMT</pubDate>
            <description><![CDATA[âš¡ï¸HivisionIDPhotos: a lightweight and efficient AI ID photos tools. ä¸€ä¸ªè½»é‡çº§çš„AIè¯ä»¶ç…§åˆ¶ä½œç®—æ³•ã€‚]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Zeyi-Lin/HivisionIDPhotos">Zeyi-Lin/HivisionIDPhotos</a></h1>
            <p>âš¡ï¸HivisionIDPhotos: a lightweight and efficient AI ID photos tools. ä¸€ä¸ªè½»é‡çº§çš„AIè¯ä»¶ç…§åˆ¶ä½œç®—æ³•ã€‚</p>
            <p>Language: Python</p>
            <p>Stars: 16,110</p>
            <p>Forks: 1,739</p>
            <p>Stars today: 107 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;img alt=&quot;hivision_logo&quot; src=&quot;assets/hivision_logo.png&quot; width=120 height=120&gt;
&lt;h1&gt;HivisionIDPhoto&lt;/h1&gt;

[English](README_EN.md) / ä¸­æ–‡ / [æ—¥æœ¬èª](README_JP.md) / [í•œêµ­ì–´](README_KO.md)

[![][release-shield]][release-link]
[![][dockerhub-shield]][dockerhub-link]
[![][github-stars-shield]][github-stars-link]
[![][github-issues-shield]][github-issues-link]
[![][github-contributors-shield]][github-contributors-link]
[![][github-forks-shield]][github-forks-link]
[![][license-shield]][license-link]  
[![][wechat-shield]][wechat-link]
[![][spaces-shield]][spaces-link]
[![][swanhub-demo-shield]][swanhub-demo-link]
[![][modelscope-shield]][modelscope-link]
[![][modelers-shield]][modelers-link]
[![][compshare-shield]][compshare-link]

[![][trendshift-shield]][trendshift-link]
[![][hellogithub-shield]][hellogithub-link]

&lt;img src=&quot;assets/demoImage.jpg&quot; width=900&gt;

&lt;/div&gt;

&gt; **ç›¸å…³é¡¹ç›®**ï¼š
&gt;
&gt; - [SwanLab](https://github.com/SwanHubX/SwanLab)ï¼šä¸€ä¸ªå¼€æºã€ç°ä»£åŒ–è®¾è®¡çš„æ·±åº¦å­¦ä¹ è®­ç»ƒè·Ÿè¸ªä¸å¯è§†åŒ–å·¥å…·ï¼ŒåŒæ—¶æ”¯æŒäº‘ç«¯/ç¦»çº¿ä½¿ç”¨ï¼Œå›½å†…å¥½ç”¨çš„Wandbå¹³æ›¿ï¼›é€‚é…30+ä¸»æµæ¡†æ¶ï¼ˆPyTorchã€HuggingFace Transformersã€LLaMA Factoryã€Lightningç­‰ï¼‰ï¼Œæ¬¢è¿ä½¿ç”¨ï¼


&lt;br&gt;

# ç›®å½•

- [æœ€è¿‘æ›´æ–°](#-æœ€è¿‘æ›´æ–°)
- [é¡¹ç›®ç®€ä»‹](#-é¡¹ç›®ç®€ä»‹)
- [ç¤¾åŒº](#-ç¤¾åŒº)
- [å‡†å¤‡å·¥ä½œ](#-å‡†å¤‡å·¥ä½œ)
- [Demoå¯åŠ¨](#-è¿è¡Œ-gradio-demo)
- [Pythonæ¨ç†](#-python-æ¨ç†)
- [APIæœåŠ¡éƒ¨ç½²](#ï¸-éƒ¨ç½²-api-æœåŠ¡)
- [Dockeréƒ¨ç½²](#-docker-éƒ¨ç½²)
- [è”ç³»æˆ‘ä»¬](#-è”ç³»æˆ‘ä»¬)
- [FAQ](#faq)
- [æ„Ÿè°¢æ”¯æŒ](#-æ„Ÿè°¢æ”¯æŒ)
- [License](#-lincese)
- [å¼•ç”¨](#-å¼•ç”¨)

&lt;br&gt;

# ğŸ¤© æœ€è¿‘æ›´æ–°

- åœ¨çº¿ä½“éªŒï¼š [![SwanHub Demo](https://img.shields.io/static/v1?label=Demo&amp;message=SwanHub%20Demo&amp;color=blue)](https://swanhub.co/ZeYiLin/HivisionIDPhotos/demo)ã€[![Spaces](https://img.shields.io/badge/ğŸ¤—-Open%20in%20Spaces-blue)](https://huggingface.co/spaces/TheEeeeLin/HivisionIDPhotos)ã€[![][modelscope-shield]][modelscope-link]ã€[![][compshare-shield]][compshare-link]

- 2024.11.20: Gradio Demoå¢åŠ **æ‰“å°æ’ç‰ˆ**é€‰é¡¹å¡ï¼Œæ”¯æŒå…­å¯¸ã€äº”å¯¸ã€A4ã€3Rã€4Räº”ç§æ’ç‰ˆå°ºå¯¸
- 2024.11.16: APIæ¥å£å¢åŠ ç¾é¢œå‚æ•°
- 2024.09.25: å¢åŠ **äº”å¯¸ç›¸çº¸**å’Œ**JPEGä¸‹è½½**é€‰é¡¹ï½œé»˜è®¤ç…§ç‰‡ä¸‹è½½æ”¯æŒ300DPI
- 2024.09.24: APIæ¥å£å¢åŠ base64å›¾åƒä¼ å…¥é€‰é¡¹ | Gradio Demoå¢åŠ **æ’ç‰ˆç…§è£å‰ªçº¿**åŠŸèƒ½
- 2024.09.22: Gradio Demoå¢åŠ **é‡å…½æ¨¡å¼**ï¼Œå¯è®¾ç½®å†…å­˜åŠ è½½ç­–ç•¥ | APIæ¥å£å¢åŠ **dpiã€face_alignment**å‚æ•°
- 2024.09.18: Gradio Demoå¢åŠ **åˆ†äº«æ¨¡ç‰ˆç…§**åŠŸèƒ½ã€å¢åŠ **ç¾å¼è¯ä»¶ç…§**èƒŒæ™¯é€‰é¡¹
- 2024.09.17: Gradio Demoå¢åŠ **è‡ªå®šä¹‰åº•è‰²-HEXè¾“å…¥**åŠŸèƒ½ | **ï¼ˆç¤¾åŒºè´¡çŒ®ï¼‰C++ç‰ˆæœ¬** - [HivisionIDPhotos-cpp](https://github.com/zjkhahah/HivisionIDPhotos-cpp) è´¡çŒ® by [zjkhahah](https://github.com/zjkhahah)
- 2024.09.16: Gradio Demoå¢åŠ **äººè„¸æ—‹è½¬å¯¹é½**åŠŸèƒ½ï¼Œè‡ªå®šä¹‰å°ºå¯¸è¾“å…¥æ”¯æŒ**æ¯«ç±³**å•ä½

&lt;br&gt;

# é¡¹ç›®ç®€ä»‹

&gt; ğŸš€ è°¢è°¢ä½ å¯¹æˆ‘ä»¬çš„å·¥ä½œæ„Ÿå…´è¶£ã€‚æ‚¨å¯èƒ½è¿˜æƒ³æŸ¥çœ‹æˆ‘ä»¬åœ¨å›¾åƒé¢†åŸŸçš„å…¶ä»–æˆæœï¼Œæ¬¢è¿æ¥ä¿¡:zeyi.lin@swanhub.co.

HivisionIDPhoto æ—¨åœ¨å¼€å‘ä¸€ç§å®ç”¨ã€ç³»ç»Ÿæ€§çš„è¯ä»¶ç…§æ™ºèƒ½åˆ¶ä½œç®—æ³•ã€‚

å®ƒåˆ©ç”¨ä¸€å¥—å®Œå–„çš„AIæ¨¡å‹å·¥ä½œæµç¨‹ï¼Œå®ç°å¯¹å¤šç§ç”¨æˆ·æ‹ç…§åœºæ™¯çš„è¯†åˆ«ã€æŠ å›¾ä¸è¯ä»¶ç…§ç”Ÿæˆã€‚

**HivisionIDPhoto å¯ä»¥åšåˆ°ï¼š**

1. è½»é‡çº§æŠ å›¾ï¼ˆçº¯ç¦»çº¿ï¼Œä»…éœ€ **CPU** å³å¯å¿«é€Ÿæ¨ç†ï¼‰
2. æ ¹æ®ä¸åŒå°ºå¯¸è§„æ ¼ç”Ÿæˆä¸åŒçš„æ ‡å‡†è¯ä»¶ç…§ã€å…­å¯¸æ’ç‰ˆç…§
3. æ”¯æŒ çº¯ç¦»çº¿ æˆ– ç«¯äº‘ æ¨ç†
4. ç¾é¢œ
5. æ™ºèƒ½æ¢æ­£è£…ï¼ˆwaitingï¼‰

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;assets/demo.png&quot; width=900&gt;
&lt;/div&gt;

---

å¦‚æœ HivisionIDPhoto å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯· star è¿™ä¸ª repo æˆ–æ¨èç»™ä½ çš„æœ‹å‹ï¼Œè§£å†³è¯ä»¶ç…§åº”æ€¥åˆ¶ä½œé—®é¢˜ï¼

&lt;br&gt;

# ğŸ  ç¤¾åŒº

æˆ‘ä»¬åˆ†äº«äº†ä¸€äº›ç”±ç¤¾åŒºæ„å»ºçš„HivisionIDPhotosçš„æœ‰è¶£åº”ç”¨å’Œæ‰©å±•ï¼š

| [HivisionIDPhotos-ComfyUI][community-hivision-comfyui] | [HivisionIDPhotos-wechat-weapp][community-hivision-wechat] |
| :----------------------------------------------------------------------------------------------------------------------------------------------: | :------------------------------------------------------------------------------------------------------------------------------: |
| &lt;a href=&quot;https://github.com/AIFSH/HivisionIDPhotos-ComfyUI&quot;&gt; &lt;img src=&quot;assets/comfyui.png&quot; width=&quot;900&quot; alt=&quot;ComfyUI workflow&quot;&gt; &lt;/a&gt;  | &lt;a href=&quot;https://github.com/no1xuan/HivisionIDPhotos-wechat-weapp&quot;&gt; &lt;img src=&quot;assets/community-wechat-miniprogram.png&quot; width=&quot;900&quot; alt=&quot;ComfyUI workflow&quot;&gt; &lt;/a&gt;  |
|ComfyUIè¯ä»¶ç…§å¤„ç†å·¥ä½œæµ | è¯ä»¶ç…§å¾®ä¿¡å°ç¨‹åºï¼ˆJAVAåç«¯+åŸç”Ÿå‰ç«¯ï¼‰ |

| [HivisionIDPhotos-Uniapp][community-hivision-uniapp] | [HivisionIDPhotos-web](https://github.com/jkm199/HivisionIDPhotos-web)|
| :------------------------------------------------------------------------------------------------------------------------------: | :------------------------------------------------------------------------------------------------------------------------------: |
| &lt;a href=&quot;https://github.com/soulerror/HivisionIDPhotos-Uniapp&quot;&gt; &lt;img src=&quot;assets/community-uniapp-wechat-miniprogram.png&quot; width=&quot;900&quot; alt=&quot;HivisionIDPhotos-uniapp&quot;&gt; &lt;/a&gt;  | &lt;a href=&quot;https://github.com/jkm199/HivisionIDPhotos-web&quot;&gt; &lt;img src=&quot;assets/community-web.png&quot; width=&quot;900&quot; alt=&quot;HivisionIDPhotos-uniapp&quot;&gt; &lt;/a&gt;  |
| è¯ä»¶ç…§å¾®ä¿¡å°ç¨‹åºï¼ˆuniappï¼‰| è¯ä»¶ç…§åº”ç”¨ç½‘é¡µç‰ˆ |


- [HivisionIDPhotos-cpp](https://github.com/zjkhahah/HivisionIDPhotos-cpp): HivisionIDphotos C++ç‰ˆæœ¬ï¼Œç”± [zjkhahah](https://github.com/zjkhahah) æ„å»º
- [ai-idphoto](https://github.com/wmlcjj/ai-idphoto): [HivisionIDPhotos-wechat-weapp](https://github.com/no1xuan/HivisionIDPhotos-wechat-weapp) çš„uniappå¤šç«¯å…¼å®¹ç‰ˆï¼Œç”± [wmlcjj](https://github.com/wmlcjj) è´¡çŒ®
- [HivisionIDPhotos-uniapp-WeChat-gpto1](https://github.com/jkm199/HivisionIDPhotos-uniapp-WeChat-gpto1/): ç”±gpt-o1è¾…åŠ©å®Œæˆå¼€å‘çš„è¯ä»¶ç…§å¾®ä¿¡å°ç¨‹åºï¼Œç”± [jkm199](https://github.com/jkm199) è´¡çŒ®
- [HivisionIDPhotos-windows-GUI](https://github.com/zhaoyun0071/HivisionIDPhotos-windows-GUI)ï¼šWindowså®¢æˆ·ç«¯åº”ç”¨ï¼Œç”± [zhaoyun0071](https://github.com/zhaoyun0071) æ„å»º
- [HivisionIDPhotos-NAS](https://github.com/ONG-Leo/HivisionIDPhotos-NAS): ç¾¤æ™–NASéƒ¨ç½²ä¸­æ–‡æ•™ç¨‹ï¼Œç”± [ONG-Leo](https://github.com/ONG-Leo) è´¡çŒ®


&lt;br&gt;

# ğŸ”§ å‡†å¤‡å·¥ä½œ

ç¯å¢ƒå®‰è£…ä¸ä¾èµ–ï¼š
- Python &gt;= 3.7ï¼ˆé¡¹ç›®ä¸»è¦æµ‹è¯•åœ¨ python 3.10ï¼‰
- OS: Linux, Windows, MacOS

## 1. å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/Zeyi-Lin/HivisionIDPhotos.git
cd  HivisionIDPhotos
```

## 2. å®‰è£…ä¾èµ–ç¯å¢ƒ

&gt; å»ºè®® conda åˆ›å»ºä¸€ä¸ª python3.10 è™šæ‹Ÿç¯å¢ƒåï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤

```bash
pip install -r requirements.txt
pip install -r requirements-app.txt
```

## 3. ä¸‹è½½äººåƒæŠ å›¾æ¨¡å‹æƒé‡æ–‡ä»¶

**æ–¹å¼ä¸€ï¼šè„šæœ¬ä¸‹è½½**

```bash
python scripts/download_model.py --models all
# å¦‚éœ€æŒ‡å®šä¸‹è½½æŸä¸ªæ¨¡å‹
# python scripts/download_model.py --models modnet_photographic_portrait_matting
```

**æ–¹å¼äºŒï¼šç›´æ¥ä¸‹è½½**

æ¨¡å‹å‡å­˜åˆ°é¡¹ç›®çš„`hivision/creator/weights`ç›®å½•ä¸‹ï¼š

| äººåƒæŠ å›¾æ¨¡å‹ | ä»‹ç» | ä¸‹è½½ |
| -- | -- | -- |
| MODNet | [MODNet](https://github.com/ZHKKKe/MODNet)å®˜æ–¹æƒé‡ | [ä¸‹è½½](https://github.com/Zeyi-Lin/HivisionIDPhotos/releases/download/pretrained-model/modnet_photographic_portrait_matting.onnx)(24.7MB)|
| hivision_modnet | å¯¹çº¯è‰²æ¢åº•é€‚é…æ€§æ›´å¥½çš„æŠ å›¾æ¨¡å‹ | [ä¸‹è½½](https://github.com/Zeyi-Lin/HivisionIDPhotos/releases/download/pretrained-model/hivision_modnet.onnx)(24.7MB) |
| rmbg-1.4 | [BRIA AI](https://huggingface.co/briaai/RMBG-1.4) å¼€æºçš„æŠ å›¾æ¨¡å‹ | [ä¸‹è½½](https://huggingface.co/briaai/RMBG-1.4/resolve/main/onnx/model.onnx?download=true)(176.2MB)åé‡å‘½åä¸º`rmbg-1.4.onnx` |
| birefnet-v1-lite | [ZhengPeng7](https://github.com/ZhengPeng7/BiRefNet) å¼€æºçš„æŠ å›¾æ¨¡å‹ï¼Œæ‹¥æœ‰æœ€å¥½çš„åˆ†å‰²ç²¾åº¦ | [ä¸‹è½½](https://github.com/ZhengPeng7/BiRefNet/releases/download/v1/BiRefNet-general-bb_swin_v1_tiny-epoch_232.onnx)(224MB)åé‡å‘½åä¸º`birefnet-v1-lite.onnx` |

&gt; å¦‚æœä¸‹è½½ç½‘é€Ÿä¸é¡ºåˆ©ï¼šå‰å¾€[SwanHub](https://swanhub.co/ZeYiLin/HivisionIDPhotos_models/tree/main)ä¸‹è½½ã€‚


## 4. äººè„¸æ£€æµ‹æ¨¡å‹é…ç½®ï¼ˆå¯é€‰ï¼‰

| æ‹“å±•äººè„¸æ£€æµ‹æ¨¡å‹ | ä»‹ç» | ä½¿ç”¨æ–‡æ¡£ |
| -- | -- | -- |
| MTCNN | **ç¦»çº¿**äººè„¸æ£€æµ‹æ¨¡å‹ï¼Œé«˜æ€§èƒ½CPUæ¨ç†ï¼ˆæ¯«ç§’çº§ï¼‰ï¼Œä¸ºé»˜è®¤æ¨¡å‹ï¼Œæ£€æµ‹ç²¾åº¦è¾ƒä½ | Cloneæ­¤é¡¹ç›®åç›´æ¥ä½¿ç”¨ |
| RetinaFace | **ç¦»çº¿**äººè„¸æ£€æµ‹æ¨¡å‹ï¼ŒCPUæ¨ç†é€Ÿåº¦ä¸­ç­‰ï¼ˆç§’çº§ï¼‰ï¼Œç²¾åº¦è¾ƒé«˜| [ä¸‹è½½](https://github.com/Zeyi-Lin/HivisionIDPhotos/releases/download/pretrained-model/retinaface-resnet50.onnx)åæ”¾åˆ°`hivision/creator/retinaface/weights`ç›®å½•ä¸‹ |
| Face++ | æ—·è§†æ¨å‡ºçš„åœ¨çº¿äººè„¸æ£€æµ‹APIï¼Œæ£€æµ‹ç²¾åº¦è¾ƒé«˜ï¼Œ[å®˜æ–¹æ–‡æ¡£](https://console.faceplusplus.com.cn/documents/4888373) | [ä½¿ç”¨æ–‡æ¡£](docs/face++_CN.md)|

## 5. æ€§èƒ½å‚è€ƒ

&gt; æµ‹è¯•ç¯å¢ƒä¸ºMac M1 Max 64GBï¼ŒéGPUåŠ é€Ÿï¼Œæµ‹è¯•å›¾ç‰‡åˆ†è¾¨ç‡ä¸º 512x715(1) ä¸ 764Ã—1146(2)ã€‚

| æ¨¡å‹ç»„åˆ | å†…å­˜å ç”¨ | æ¨ç†æ—¶é•¿(1) | æ¨ç†æ—¶é•¿(2) |
| -- | -- | -- | -- |
| MODNet + mtcnn | 410MB | 0.207s | 0.246s |
| MODNet + retinaface | 405MB | 0.571s | 0.971s |
| birefnet-v1-lite + retinaface | 6.20GB | 7.063s | 7.128s |

## 6. GPUæ¨ç†åŠ é€Ÿï¼ˆå¯é€‰ï¼‰

åœ¨å½“å‰ç‰ˆæœ¬ï¼Œå¯è¢«è‹±ä¼Ÿè¾¾GPUåŠ é€Ÿçš„æ¨¡å‹ä¸º`birefnet-v1-lite`ï¼Œå¹¶è¯·ç¡®ä¿ä½ æœ‰16GBå·¦å³çš„æ˜¾å­˜ã€‚

å¦‚éœ€ä½¿ç”¨è‹±ä¼Ÿè¾¾GPUåŠ é€Ÿæ¨ç†ï¼Œåœ¨ç¡®ä¿ä½ å·²ç»å®‰è£…[CUDA](https://developer.nvidia.com/cuda-downloads)ä¸[cuDNN](https://developer.nvidia.com/cudnn)åï¼Œæ ¹æ®[onnxruntime-gpuæ–‡æ¡£](https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#cuda-12x)æ‰¾åˆ°å¯¹åº”çš„`onnxruntime-gpu`ç‰ˆæœ¬å®‰è£…ï¼Œä»¥åŠæ ¹æ®[pytorchå®˜ç½‘](https://pytorch.org/get-started/locally/)æ‰¾åˆ°å¯¹åº”çš„`torch`ç‰ˆæœ¬å®‰è£…ã€‚

```bash
# å‡å¦‚ä½ çš„ç”µè„‘å®‰è£…çš„æ˜¯CUDA 12.x, cuDNN 8
# å®‰è£…torchæ˜¯å¯é€‰çš„ï¼Œå¦‚æœä½ å§‹ç»ˆé…ç½®ä¸å¥½cuDNNï¼Œé‚£ä¹ˆè¯•è¯•å®‰è£…torch
pip install onnxruntime-gpu==1.18.0
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

å®Œæˆå®‰è£…åï¼Œè°ƒç”¨`birefnet-v1-lite`æ¨¡å‹å³å¯åˆ©ç”¨GPUåŠ é€Ÿæ¨ç†ã€‚

&gt; TIPS: CUDA æ”¯æŒå‘ä¸‹å…¼å®¹ã€‚æ¯”å¦‚ä½ çš„ CUDA ç‰ˆæœ¬ä¸º 12.6ï¼Œ`torch` å®˜æ–¹ç›®å‰æ”¯æŒçš„æœ€é«˜ç‰ˆæœ¬ä¸º 12.4ï¼ˆ&lt;12.6ï¼‰ï¼Œ`torch`ä»å¯ä»¥æ­£å¸¸ä½¿ç”¨CUDAã€‚

&lt;br&gt;

# âš¡ï¸ è¿è¡Œ Gradio Demo

```bash
python app.py
```

è¿è¡Œç¨‹åºå°†ç”Ÿæˆä¸€ä¸ªæœ¬åœ° Web é¡µé¢ï¼Œåœ¨é¡µé¢ä¸­å¯å®Œæˆè¯ä»¶ç…§çš„æ“ä½œä¸äº¤äº’ã€‚

&lt;img src=&quot;assets/harry.png&quot; width=900&gt;

&lt;br&gt;

# ğŸš€ Python æ¨ç†

æ ¸å¿ƒå‚æ•°ï¼š

- `-i`: è¾“å…¥å›¾åƒè·¯å¾„
- `-o`: ä¿å­˜å›¾åƒè·¯å¾„
- `-t`: æ¨ç†ç±»å‹ï¼Œæœ‰idphotoã€human_mattingã€add_backgroundã€generate_layout_photoså¯é€‰
- `--matting_model`: äººåƒæŠ å›¾æ¨¡å‹æƒé‡é€‰æ‹©
- `--face_detect_model`: äººè„¸æ£€æµ‹æ¨¡å‹é€‰æ‹©

æ›´å¤šå‚æ•°å¯é€šè¿‡`python inference.py --help`æŸ¥çœ‹

## 1. è¯ä»¶ç…§åˆ¶ä½œ

è¾“å…¥ 1 å¼ ç…§ç‰‡ï¼Œè·å¾— 1 å¼ æ ‡å‡†è¯ä»¶ç…§å’Œ 1 å¼ é«˜æ¸…è¯ä»¶ç…§çš„ 4 é€šé“é€æ˜ png

```python
python inference.py -i demo/images/test0.jpg -o ./idphoto.png --height 413 --width 295
```

## 2. äººåƒæŠ å›¾

è¾“å…¥ 1 å¼ ç…§ç‰‡ï¼Œè·å¾— 1å¼  4 é€šé“é€æ˜ png

```python
python inference.py -t human_matting -i demo/images/test0.jpg -o ./idphoto_matting.png --matting_model hivision_modnet
```

## 3. é€æ˜å›¾å¢åŠ åº•è‰²

è¾“å…¥ 1 å¼  4 é€šé“é€æ˜ pngï¼Œè·å¾— 1 å¼ å¢åŠ äº†åº•è‰²çš„ 3é€šé“å›¾åƒ

```python
python inference.py -t add_background -i ./idphoto.png -o ./idphoto_ab.jpg  -c 4f83ce -k 30 -r 1
```

## 4. å¾—åˆ°å…­å¯¸æ’ç‰ˆç…§

è¾“å…¥ 1 å¼  3 é€šé“ç…§ç‰‡ï¼Œè·å¾— 1 å¼ å…­å¯¸æ’ç‰ˆç…§

```python
python inference.py -t generate_layout_photos -i ./idphoto_ab.jpg -o ./idphoto_layout.jpg  --height 413 --width 295 -k 200
```

## 5. è¯ä»¶ç…§è£å‰ª

è¾“å…¥ 1 å¼  4 é€šé“ç…§ç‰‡ï¼ˆæŠ å›¾å¥½çš„å›¾åƒï¼‰ï¼Œè·å¾— 1 å¼ æ ‡å‡†è¯ä»¶ç…§å’Œ 1 å¼ é«˜æ¸…è¯ä»¶ç…§çš„ 4 é€šé“é€æ˜ png

```python
python inference.py -t idphoto_crop -i ./idphoto_matting.png -o ./idphoto_crop.png --height 413 --width 295
```


&lt;br&gt;

# âš¡ï¸ éƒ¨ç½² API æœåŠ¡

## å¯åŠ¨åç«¯

```
python deploy_api.py
```

## è¯·æ±‚ API æœåŠ¡

è¯¦ç»†è¯·æ±‚æ–¹å¼è¯·å‚è€ƒ [API æ–‡æ¡£](docs/api_CN.md)ï¼ŒåŒ…å«ä»¥ä¸‹è¯·æ±‚ç¤ºä¾‹ï¼š
- [cURL](docs/api_CN.md#curl-è¯·æ±‚ç¤ºä¾‹)
- [Python](docs/api_CN.md#python-è¯·æ±‚ç¤ºä¾‹)

&lt;br&gt;

# ğŸ³ Docker éƒ¨ç½²

## 1. æ‹‰å–æˆ–æ„å»ºé•œåƒ

&gt; ä»¥ä¸‹æ–¹å¼ä¸‰é€‰ä¸€

**æ–¹å¼ä¸€ï¼šæ‹‰å–æœ€æ–°é•œåƒï¼š**

```bash
docker pull linzeyi/hivision_idphotos
```

**æ–¹å¼äºŒï¼šDockrfile ç›´æ¥æ„å»ºé•œåƒï¼š**

åœ¨ç¡®ä¿å°†è‡³å°‘ä¸€ä¸ª[æŠ å›¾æ¨¡å‹æƒé‡æ–‡ä»¶](#3-ä¸‹è½½æƒé‡æ–‡ä»¶)æ”¾åˆ°`hivision/creator/weights`ä¸‹åï¼Œåœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œï¼š

```bash
docker build -t linzeyi/hivision_idphotos .
```

**æ–¹å¼ä¸‰ï¼šDocker compose æ„å»ºï¼š**

åœ¨ç¡®ä¿å°†è‡³å°‘ä¸€ä¸ª[æŠ å›¾æ¨¡å‹æƒé‡æ–‡ä»¶](#3-ä¸‹è½½æƒé‡æ–‡ä»¶)æ”¾åˆ°`hivision/creator/weights`ä¸‹åï¼Œåœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹æ‰§è¡Œï¼š

```bash
docker compose build
```

## 2. è¿è¡ŒæœåŠ¡

**å¯åŠ¨ Gradio Demo æœåŠ¡**

è¿è¡Œä¸‹é¢çš„å‘½ä»¤ï¼Œåœ¨ä½ çš„æœ¬åœ°è®¿é—® [http://127.0.0.1:7860](http://127.0.0.1:7860/) å³å¯ä½¿ç”¨ã€‚

```bash
docker run -d -p 7860:7860 linzeyi/hivision_idphotos
```

**å¯åŠ¨ API åç«¯æœåŠ¡**

```bash
docker run -d -p 8080:8080 linzeyi/hivision_idphotos python3 deploy_api.py
```

**ä¸¤ä¸ªæœåŠ¡åŒæ—¶å¯åŠ¨**

```bash
docker compose up -d
```

## ç¯å¢ƒå˜é‡

æœ¬é¡¹ç›®æä¾›äº†ä¸€äº›é¢å¤–çš„é…ç½®é¡¹ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡è¿›è¡Œè®¾ç½®ï¼š

| ç¯å¢ƒå˜é‡ | ç±»å‹	| æè¿° | ç¤ºä¾‹ |
|--|--|--|--|
| FACE_PLUS_API_KEY	 | å¯é€‰	| è¿™æ˜¯ä½ åœ¨ Face++ æ§åˆ¶å°ç”³è¯·çš„ API å¯†é’¥	 | `7-fZStDJÂ·Â·Â·Â·` |
| FACE_PLUS_API_SECRET	 | å¯é€‰	| Face++ APIå¯†é’¥å¯¹åº”çš„Secret | `VTee824EÂ·Â·Â·Â·` |
| RUN_MODE | å¯é€‰ | è¿è¡Œæ¨¡å¼ï¼Œå¯é€‰å€¼ä¸º`beast`(é‡å…½æ¨¡å¼)ã€‚é‡å…½æ¨¡å¼ä¸‹äººè„¸æ£€æµ‹å’ŒæŠ å›¾æ¨¡å‹å°†ä¸é‡Šæ”¾å†…å­˜ï¼Œä»è€Œè·å¾—æ›´å¿«çš„äºŒæ¬¡æ¨ç†é€Ÿåº¦ã€‚å»ºè®®å†…å­˜16GBä»¥ä¸Šå°è¯•ã€‚ | `beast` |
| DEFAULT_LANG | å¯é€‰ | Gradio Demoå¯åŠ¨æ—¶çš„é»˜è®¤è¯­è¨€| `en` |

dockerä½¿ç”¨ç¯å¢ƒå˜é‡ç¤ºä¾‹ï¼š
```bash
docker run  -d -p 7860:7860 \
    -e FACE_PLUS_API_KEY=7-fZStDJÂ·Â·Â·Â· \
    -e FACE_PLUS_API_SECRET=VTee824EÂ·Â·Â·Â· \
    -e RUN_MODE=beast \
    -e DEFAULT_LANG=en \
    linzeyi/hivision_idphotos  
```

&lt;br&gt;

# FAQ

## 1. å¦‚ä½•ä¿®æ”¹é¢„è®¾å°ºå¯¸å’Œé¢œè‰²ï¼Ÿ

- å°ºå¯¸ï¼šä¿®æ”¹[size_list_CN.csv](demo/assets/size_list_CN.csv)åå†æ¬¡è¿è¡Œ `app.py` å³å¯ï¼Œå…¶ä¸­ç¬¬ä¸€åˆ—ä¸ºå°ºå¯¸åï¼Œç¬¬äºŒåˆ—ä¸ºé«˜åº¦ï¼Œç¬¬ä¸‰åˆ—ä¸ºå®½åº¦ã€‚
- é¢œè‰²ï¼šä¿®æ”¹[color_list_CN.csv](demo/assets/color_list_CN.csv)åå†æ¬¡è¿è¡Œ `app.py` å³å¯ï¼Œå…¶ä¸­ç¬¬ä¸€åˆ—ä¸ºé¢œè‰²åï¼Œç¬¬äºŒåˆ—ä¸ºHexå€¼ã€‚

## 2. å¦‚ä½•ä¿®æ”¹æ°´å°å­—ä½“ï¼Ÿ

1. å°†å­—ä½“æ–‡ä»¶æ”¾åˆ°`hivision/plugin/font`æ–‡ä»¶å¤¹ä¸‹
2. ä¿®æ”¹`hivision/plugin/watermark.py`çš„`font_file`å‚æ•°å€¼ä¸ºå­—ä½“æ–‡ä»¶å

## 3. å¦‚ä½•æ·»åŠ ç¤¾äº¤åª’ä½“æ¨¡æ¿ç…§ï¼Ÿ

1. å°†æ¨¡æ¿å›¾ç‰‡æ”¾åˆ°`hivision/plugin/template/assets`æ–‡ä»¶å¤¹ä¸‹ã€‚æ¨¡æ¿å›¾ç‰‡æ˜¯ä¸€ä¸ª4é€šé“çš„é€æ˜pngã€‚
2. åœ¨`hivision/plugin/template/assets/template_config.json`æ–‡ä»¶ä¸­æ·»åŠ æœ€æ–°çš„æ¨¡æ¿ä¿¡æ¯ï¼Œå…¶ä¸­`width`ä¸ºæ¨¡æ¿å›¾å®½åº¦(px)ï¼Œ`height`ä¸ºæ¨¡æ¿å›¾é«˜åº¦(px)ï¼Œ`anchor_points`ä¸ºæ¨¡æ¿ä¸­é€æ˜åŒºåŸŸçš„å››ä¸ªè§’çš„åæ ‡(px)ï¼›`rotation`ä¸ºé€æ˜åŒºåŸŸç›¸å¯¹äºå‚ç›´æ–¹å‘çš„æ—‹è½¬è§’åº¦ï¼Œ&gt;0ä¸ºé€†æ—¶é’ˆï¼Œ&lt;0ä¸ºé¡ºæ—¶é’ˆã€‚
3. åœ¨`demo/processor.py`çš„`_generate_image_template`å‡½æ•°ä¸­çš„`TEMPLATE_NAME_LIST`å˜é‡æ·»åŠ æœ€æ–°çš„æ¨¡æ¿å

&lt;img src=&quot;assets/social_template.png&quot; width=&quot;500&quot;&gt;

## 4. å¦‚ä½•ä¿®æ”¹Gradio Demoçš„é¡¶éƒ¨å¯¼èˆªæ ï¼Ÿ

- ä¿®æ”¹`demo/assets/title.md`

## 5. å¦‚ä½•æ·»åŠ /ä¿®æ”¹ã€Œæ‰“å°æ’ç‰ˆã€ä¸­çš„å°ºå¯¸ï¼Ÿ

- ä¿®æ”¹`demo/locales.py`ä¸­çš„`print_switch`å­—å…¸ï¼Œæ·»åŠ /ä¿®æ”¹æ–°çš„å°ºå¯¸åç§°å’Œå°ºå¯¸å‚æ•°ï¼Œç„¶åé‡æ–°è¿è¡Œ`python app.py`

&lt;br&gt;

# ğŸ“§ è”ç³»æˆ‘ä»¬

å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·å‘é‚®ä»¶è‡³ zeyi.lin@swanhub.co

&lt;br&gt;

# ğŸ™ æ„Ÿè°¢æ”¯æŒ

[![Stargazers repo roster for @Zeyi-Lin/HivisionIDPhotos](https://reporoster.com/stars/Zeyi-Lin/HivisionIDPhotos)](https://github.com/Zeyi-Lin/HivisionIDPhotos/stargazers)

[![Forkers repo roster for @Zeyi-Lin/HivisionIDPhotos](https://reporoster.com/forks/Zeyi-Lin/HivisionIDPhotos)](https://github.com/Zeyi-Lin/HivisionIDPhotos/network/members)

[![Star History Chart](https://api.star-history.com/svg?repos=Zeyi-Lin/HivisionIDPhotos&amp;type=Date)](https://star-history.com/#Zeyi-Lin/HivisionIDPhotos&amp;Date)

è´¡çŒ®è€…ä»¬ï¼š

&lt;a href=&quot;https://github.com/Zeyi-Lin/HivisionIDPhotos/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=Zeyi-Lin/HivisionIDPhotos&quot; /&gt;
&lt;/a&gt;

[Zeyi-Lin](https://github.com/Zeyi-Lin)ã€[SAKURA-CAT](https://github.com/SAKURA-CAT)ã€[Feudalman](https://github.com/Feudalman)ã€[swpfY](https://github.com/swpfY)ã€[Kaikaikaifang](https://github.com/Kaikaikaifang)ã€[ShaohonChen](https://github.com/ShaohonChen)ã€[KashiwaByte](https://github.com/KashiwaByte)

&lt;br&gt;

# ğŸ“œ Lincese

This repository is licensed under the [Apache-2.0 License](LICENSE).

&lt;br&gt;

# ğŸ“š å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶æˆ–é¡¹ç›®ä¸­ä½¿ç”¨äº†HivisionIDPhotosï¼Œè¯·è€ƒè™‘å¼•ç”¨æˆ‘ä»¬çš„å·¥ä½œã€‚æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹BibTeXæ¡ç›®ï¼š

```bibtex
@misc{hivisionidphotos,
      title={{HivisionIDPhotos: A Lightweight and Efficient AI ID Photos Tool}},
      author={Zeyi Lin and SwanLab Team},
      year={2024},
      publisher={GitHub},
      url = {\url{https://github.com/Zeyi-Lin/HivisionIDPhotos}},
}
```




[github-stars-shield]: https://img.shields.io/github/stars/zeyi-lin/hivisionidphotos?color=ffcb47&amp;labelColor=black&amp;style=flat-square
[github-stars-link]: https://github.com/zeyi-lin/hivisionidphotos/stargazers

[swanhub-demo-shield]: https://swanhub.co/git/repo/SwanHub%2FAuto-README/file/preview?ref=main&amp;path=swanhub.svg
[swanhub-demo-link]: https://swanhub.co/ZeYiLin/HivisionIDPhotos/demo

[spaces-shield]: https://img.shields.io/badge/ğŸ¤—-Open%20in%20Spaces-blue
[spaces-link]: https://huggingface.co/spaces/TheEeeeLin/HivisionIDPhotos

&lt;!-- å¾®ä¿¡ç¾¤é“¾æ¥ --&gt;
[wechat-shield]: https://img.shields.io/badge/WeChat-å¾®ä¿¡-4cb55e
[wechat-link]: https://docs.qq.com/doc/DUkpBdk90eWZFS2JW

&lt;!-- Github Release --&gt;
[release-shield]: https://img.shields.io/github/v/release/zeyi-lin/hivisionidphotos?color=369eff&amp;labelColor=black&amp;logo=github&amp;style=flat-square
[release-link]: https://github.com/zeyi-lin/hivisionidphotos/releases

[license-shield]: https://img.shields.io/badge/license-apache%202.0-white?labelColor=black&amp;style=flat-square
[license-link]: https://github.com/Zeyi-Lin/HivisionIDPhotos/blob/master/LICENSE

[github-issues-shield]: https://img.shields.io/github/issues/zeyi-lin/hivisionidphotos?color=ff80eb&amp;labelColor=black&amp;style=flat-square
[github-issues-link]: https://github.com/zeyi-lin/hivisionidphotos/issues

[dockerhub-shield]: https://img.shields.io/docker/v/linzeyi/hivision_idphotos?color=369eff&amp;label=docker&amp;labelColor=black&amp;logoColor=white&amp;style=flat-square
[dockerhub-link]: https://hub.docker.com/r/linzeyi/hivision_idphotos/tags

[trendshift-shield]: https://trendshift.io/api/badge/repositories/11622
[trendshift-link]: https://trendshift.io/repositories/11622

[hellogithub-shield]: https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=8ea1457289fb4062ba661e5299e733d6&amp;claim_uid=Oh5UaGjfrblg0yZ
[hellogithub-link]: https://hellogithub.com/repository/8ea1457289fb4062ba661e5299e733d6

[github-contributors-shield]: https://img.shields.io/github/contributors/zeyi-lin/hivisionidphotos?color=c4f042&amp;labelColor=black&amp;style=flat-square
[github-contributors-link]: https://github.com/zeyi-lin/hivisionidphotos/graphs/contributors

[github-forks-shield]: https://img.shields.io/github/forks/zeyi-lin/hivisionidphotos?color=8ae8ff&amp;labelColor=black&amp;style=flat-square
[github-forks-link]: https://github.com/zeyi-lin/hivisionidphotos/network/members

[modelscope-shield]: https://img.shields.io/badge/Demo_on_ModelScope-purple?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIzIiBoZWlnaHQ9IjIwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCiA8Zz4KICA8dGl0bGU+TGF5ZXIgMTwvdGl0bGU+CiAgPHBhdGggaWQ9InN2Z18xNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTAsODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTUiIGZpbGw9IiM2MjRhZmYiIGQ9Im05OS4xNCwxMTUuNDlsMjUuNjUsMGwwLDI1LjY1bC0yNS42NSwwbDAsLTI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTYiIGZpbGw9IiM2MjRhZmYiIGQ9Im0xNzYuMDksMTQxLjE0bC0yNS42NDk5OSwwbDAsMjIuMTlsNDcuODQsMGwwLC00Ny44NGwtMjIuMTksMGwwLDI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTciIGZpbGw9IiMzNmNmZDEiIGQ9Im0xMjQuNzksODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTgiIGZpbGw9IiMzNmNmZDEiIGQ9Im0wLDY0LjE5bDI1LjY1LDBsMCwyNS42NWwtMjUuNjUsMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzE5IiBmaWxsPSIjNjI0YWZmIiBkPSJtMTk4LjI4LDg5Ljg0bDI1LjY0OTk5LDBsMCwyNS42NDk5OWwtMjUuNjQ5OTksMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIwIiBmaWxsPSIjMzZjZmQxIiBkPSJtMTk4LjI4LDY0LjE5bDI1LjY0OTk5LDBsMCwyNS42NWwtMjUuNjQ5OTksMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIxIiBmaWxsPSIjNjI0YWZmIiBkPSJtMTUwLjQ0LDQybDAsMjIuMTlsMjUuNjQ5OTksMGwwLDI1LjY1bDIyLjE5LDBsMCwtNDcuODRsLTQ3Ljg0LDB6Ii8+CiAgPHBhdGggaWQ9InN2Z18yMiIgZmlsbD0iIzM2Y2ZkMSIgZD0ibTczLjQ5LDg5Ljg0bDI1LjY1LDBsMCwyNS42NDk5OWwtMjUuNjUsMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIzIiBmaWxsPSIjNjI0YWZmIiBkPSJtNDcuODQsNjQuMTlsMjUuNjUsMGwwLC0yMi4xOWwtNDcuODQsMGwwLDQ3Ljg0bDIyLjE5LDBsMCwtMjUuNjV6Ii8+CiAgPHBhdGggaWQ9InN2Z18yNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTQ3Ljg0LDExNS40OWwtMjIuMTksMGwwLDQ3Ljg0bDQ3Ljg0LDBsMCwtMjIuMTlsLTI1LjY1LDBsMCwtMjUuNjV6Ii8+CiA8L2c+Cjwvc3ZnPg==&amp;labelColor=white
[modelscope-link]: https://modelscope.cn/studios/SwanLab/HivisionIDPhotos

[modelers-shield]: https://img.shields.io/badge/Demo_on_Modelers-c42a2a?logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMjQiIGhlaWdodD0iNjQiIHZpZXdCb3g9IjAgMCAxMjQgNjQiIGZpbGw9Im5vbmUiPgo8cGF0aCBkPSJNNDIuNzc4MyAwSDI2LjU5NzdWMTUuNzc4N0g0Mi43NzgzVjBaIiBmaWxsPSIjREUwNDI5Ii8+CjxwYXRoIGQ9Ik0xNi41MDg4IDQuMTc5MkgwLjMyODEyNVYxOS45NTc5SDE2LjUwODhWNC4xNzkyWiIgZmlsbD0iIzI0NDk5QyIvPgo8cGF0aCBkPSJNMTIzLjk1MiA0LjE3OTJIMTA3Ljc3MVYxOS45NTc5SDEyMy45NTJWNC4xNzkyWiIgZmlsbD0iIzI0NDk5QyIvPgo8cGF0aCBkPSJNMTYuNTA4OCA0NS40NjE5SDAuMzI4MTI1VjYxLjI0MDZIMTYuNTA4OFY0NS40NjE5WiIgZmlsbD0iIzI0NDk5QyIvPgo8cGF0aCBkPSJNMTIzLjk1MiA0NS40NjE5SDEwNy43NzFWNjEuMjQwNkgxMjMuOTUyVjQ1LjQ2MTlaIiBmaWxsPSIjMjQ0OTlDIi8+CjxwYXRoIGQ9Ik0zMi43MDggMTUuNzc4OEgxNi41MjczVjMxLjU1NzVIMzIuNzA4VjE1Ljc3ODhaIiBmaWxsPSIjREUwNDI5Ii8+CjxwYXRoIGQ9Ik01Mi44NDg2IDE1Ljc3ODhIMzYuNjY4VjMxLjU1NzVINTIuODQ4NlYxNS43Nzg4WiIgZmlsbD0iI0RFMDQyOSIvPgo8cGF0aCBkPSJNOTcuNzIzNyAwSDgxLjU0M1YxNS43Nzg3SDk3LjcyMzdWMFoiIGZpbGw9IiNERTA0MjkiLz4KPHBhdGggZD0iTTg3LjY1MzQgMTUuNzc4OEg3MS40NzI3VjMxLjU1NzVIODcuNjUzNFYxNS43Nzg4WiIgZmlsbD0iI0RFMDQyOSIvPgo8cGF0aCBkPSJNMTA3Ljc5NCAxNS43Nzg4SDkxLjYxMzNWMzEuNTU3NUgxMDcuNzk0VjE1Ljc3ODhaIiBmaWxsPSIjREUwNDI5Ii8+CjxwYXRoIGQ9Ik0yNC42NzQ4IDMxLjU1NzZIOC40OTQxNFY0Ny4zMzYzSDI0LjY3NDhWMzEuNTU3NloiIGZpbGw9IiNERTA0MjkiLz4KPHBhdGggZD0iTTYwLjg3OTkgMzEuNTU3Nkg0NC42OTkyVjQ3LjMzNjNINjAuODc5OVYzMS41NTc2WiIgZmlsbD0iI0RFMDQyOSIvPgo8cGF0aCBkPSJNNzkuNjIwMSAzMS41NTc2SDYzLjQzOTVWNDcuMzM2M0g3OS42MjAxVjMxLjU1NzZaIiBmaWxsPSIjREUwNDI5Ii8+CjxwYXRoIGQ9Ik0xMTUuODI1IDMxLjU1NzZIOTkuNjQ0NVY0Ny4zMzYzSDExNS44MjVWMzEuNTU3NloiIGZpbGw9IiNERTA0MjkiLz4KPHBhdGggZD0iTTcwLjI1NDkgNDcuMzM1OUg1NC4wNzQyVjYzLjExNDdINzAuMjU0OVY0Ny4zMzU5WiIgZmlsbD0iI0RFMDQyOSIvPgo8L3N2Zz4=&amp;labelColor=white
[modelers-link]: https://modelers.cn/spaces/SwanLab/HivisionIDPhotos

[compshare-shield]: https://www-s.ucloud.cn/2025/02/dbef8b07ea3d316006d9c22765c3cd53_1740104342584.svg
[compshare-link]: https://www.compshare.cn/images-detail?ImageID=compshareImage-17jacgm4ju16&amp;ytag=HG_GPU_HivisionIDPhotos

&lt;!-- ç¤¾åŒºé¡¹ç›®é“¾æ¥ --&gt;
[community-hivision-comfyui]: https://github.com/AIFSH/HivisionIDPhotos-ComfyUI
[community-hivision-wechat]: https://github.com/no1xuan/HivisionIDPhotos-wechat-weapp
[community-hivision-uniapp]: https://github.com/soulerror/HivisionIDPhotos-Uniapp
[community-hivision-cpp]: https://github.com/zjkhahah/HivisionIDPhotos-cpp
[community-hivision-windows-gui]: https://github.com/zhaoyun0071/HivisionIDPhotos-windows-GUI
[community-hivision-nas]: https://github.com/ONG-Leo/HivisionIDPhotos-NAS</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Stability-AI/stable-audio-tools]]></title>
            <link>https://github.com/Stability-AI/stable-audio-tools</link>
            <guid>https://github.com/Stability-AI/stable-audio-tools</guid>
            <pubDate>Fri, 16 May 2025 00:04:16 GMT</pubDate>
            <description><![CDATA[Generative models for conditional audio generation]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Stability-AI/stable-audio-tools">Stability-AI/stable-audio-tools</a></h1>
            <p>Generative models for conditional audio generation</p>
            <p>Language: Python</p>
            <p>Stars: 3,123</p>
            <p>Forks: 317</p>
            <p>Stars today: 45 stars today</p>
            <h2>README</h2><pre># stable-audio-tools
Training and inference code for audio generation models

# Install

The library can be installed from PyPI with:
```bash
$ pip install stable-audio-tools
```

To run the training scripts or inference code, you&#039;ll want to clone this repository, navigate to the root, and run:
```bash
$ pip install .
```

# Requirements
Requires PyTorch 2.5 or later for Flash Attention and Flex Attention support

Development for the repo is done in Python 3.10

# Interface

A basic Gradio interface is provided to test out trained models. 

For example, to create an interface for the [`stable-audio-open-1.0`](https://huggingface.co/stabilityai/stable-audio-open-1.0) model, once you&#039;ve accepted the terms for the model on Hugging Face, you can run:
```bash
$ python3 ./run_gradio.py --pretrained-name stabilityai/stable-audio-open-1.0
```

The `run_gradio.py` script accepts the following command line arguments:

- `--pretrained-name`
  - Hugging Face repository name for a Stable Audio Tools model
  - Will prioritize `model.safetensors` over `model.ckpt` in the repo
  - Optional, used in place of `model-config` and `ckpt-path` when using pre-trained model checkpoints on Hugging Face
- `--model-config`
  - Path to the model config file for a local model
- `--ckpt-path`
  - Path to unwrapped model checkpoint file for a local model
- `--pretransform-ckpt-path` 
  - Path to an unwrapped pretransform checkpoint, replaces the pretransform in the model, useful for testing out fine-tuned decoders
  - Optional
- `--share`
  - If true, a publicly shareable link will be created for the Gradio demo
  - Optional
- `--username` and `--password`
  - Used together to set a login for the Gradio demo
  - Optional
- `--model-half`
  - If true, the model weights to half-precision
  - Optional

# Training

## Prerequisites
Before starting your training run, you&#039;ll need a model config file, as well as a dataset config file. For more information about those, refer to the Configurations section below

The training code also requires a Weights &amp; Biases account to log the training outputs and demos. Create an account and log in with:
```bash
$ wandb login
```

## Start training
To start a training run, run the `train.py` script in the repo root with:
```bash
$ python3 ./train.py --dataset-config /path/to/dataset/config --model-config /path/to/model/config --name harmonai_train
```

The `--name` parameter will set the project name for your Weights and Biases run.

## Training wrappers and model unwrapping
`stable-audio-tools` uses PyTorch Lightning to facilitate multi-GPU and multi-node training. 

When a model is being trained, it is wrapped in a &quot;training wrapper&quot;, which is a `pl.LightningModule` that contains all of the relevant objects needed only for training. That includes things like discriminators for autoencoders, EMA copies of models, and all of the optimizer states.

The checkpoint files created during training include this training wrapper, which greatly increases the size of the checkpoint file.

`unwrap_model.py` in the repo root will take in a wrapped model checkpoint and save a new checkpoint file including only the model itself.

That can be run with from the repo root with:
```bash
$ python3 ./unwrap_model.py --model-config /path/to/model/config --ckpt-path /path/to/wrapped/ckpt --name model_unwrap
```

Unwrapped model checkpoints are required for:
  - Inference scripts
  - Using a model as a pretransform for another model (e.g. using an autoencoder model for latent diffusion)
  - Fine-tuning a pre-trained model with a modified configuration (i.e. partial initialization)

## Fine-tuning
Fine-tuning a model involves continuning a training run from a pre-trained checkpoint. 

To continue a training run from a wrapped model checkpoint, you can pass in the checkpoint path to `train.py` with the `--ckpt-path` flag.

To start a fresh training run using a pre-trained unwrapped model, you can pass in the unwrapped checkpoint to `train.py` with the `--pretrained-ckpt-path` flag.

## Additional training flags

Additional optional flags for `train.py` include:
- `--config-file`
  - The path to the defaults.ini file in the repo root, required if running `train.py` from a directory other than the repo root
- `--pretransform-ckpt-path`
  - Used in various model types such as latent diffusion models to load a pre-trained autoencoder. Requires an unwrapped model checkpoint.
- `--save-dir`
  - The directory in which to save the model checkpoints
- `--checkpoint-every`
  - The number of steps between saved checkpoints.
  - *Default*: 10000
- `--batch-size`
  - Number of samples per-GPU during training. Should be set as large as your GPU VRAM will allow.
  - *Default*: 8
- `--num-gpus`
  - Number of GPUs per-node to use for training
  - *Default*: 1
- `--num-nodes`
  - Number of GPU nodes being used for training
  - *Default*: 1
- `--accum-batches`
  - Enables and sets the number of batches for gradient batch accumulation. Useful for increasing effective batch size when training on smaller GPUs.
- `--strategy`
  - Multi-GPU strategy for distributed training. Setting to `deepspeed` will enable DeepSpeed ZeRO Stage 2.
  - *Default*: `ddp` if `--num_gpus` &gt; 1, else None
- `--precision`
  - floating-point precision to use during training
  - *Default*: 16
- `--num-workers`
  - Number of CPU workers used by the data loader
- `--seed`
  - RNG seed for PyTorch, helps with deterministic training

# Configurations
Training and inference code for `stable-audio-tools` is based around JSON configuration files that define model hyperparameters, training settings, and information about your training dataset.

## Model config
The model config file defines all of the information needed to load a model for training or inference. It also contains the training configuration needed to fine-tune a model or train from scratch.

The following properties are defined in the top level of the model configuration:

- `model_type`
  - The type of model being defined, currently limited to one of `&quot;autoencoder&quot;, &quot;diffusion_uncond&quot;, &quot;diffusion_cond&quot;, &quot;diffusion_cond_inpaint&quot;, &quot;diffusion_autoencoder&quot;, &quot;lm&quot;`.
- `sample_size`
  - The length of the audio provided to the model during training, in samples. For diffusion models, this is also the raw audio sample length used for inference.
- `sample_rate`
  - The sample rate of the audio provided to the model during training, and generated during inference, in Hz.
- `audio_channels`
  - The number of channels of audio provided to the model during training, and generated during inference. Defaults to 2. Set to 1 for mono.
- `model`
  - The specific configuration for the model being defined, varies based on `model_type`
- `training`
  - The training configuration for the model, varies based on `model_type`. Provides parameters for training as well as demos.

## Dataset config
`stable-audio-tools` currently supports two kinds of data sources: local directories of audio files, and WebDataset datasets stored in Amazon S3. More information can be found in [the dataset config documentation](docs/datasets.md)

# Todo
- [ ] Add troubleshooting section
- [ ] Add contribution guidelines 
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[sinaptik-ai/pandas-ai]]></title>
            <link>https://github.com/sinaptik-ai/pandas-ai</link>
            <guid>https://github.com/sinaptik-ai/pandas-ai</guid>
            <pubDate>Fri, 16 May 2025 00:04:15 GMT</pubDate>
            <description><![CDATA[Chat with your database or your datalake (SQL, CSV, parquet). PandasAI makes data analysis conversational using LLMs and RAG.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sinaptik-ai/pandas-ai">sinaptik-ai/pandas-ai</a></h1>
            <p>Chat with your database or your datalake (SQL, CSV, parquet). PandasAI makes data analysis conversational using LLMs and RAG.</p>
            <p>Language: Python</p>
            <p>Stars: 20,135</p>
            <p>Forks: 1,910</p>
            <p>Stars today: 35 stars today</p>
            <h2>README</h2><pre># ![PandaAI](assets/logo.png)

[![Release](https://img.shields.io/pypi/v/pandasai?label=Release&amp;style=flat-square)](https://pypi.org/project/pandasai/)
[![CI](https://github.com/sinaptik-ai/pandas-ai/actions/workflows/ci-core.yml/badge.svg)](https://github.com/sinaptik-ai/pandas-ai/actions/workflows/ci-core.yml/badge.svg)
[![CD](https://github.com/sinaptik-ai/pandas-ai/actions/workflows/cd.yml/badge.svg)](https://github.com/sinaptik-ai/pandas-ai/actions/workflows/cd.yml/badge.svg)
[![Coverage](https://codecov.io/gh/sinaptik-ai/pandas-ai/branch/main/graph/badge.svg)](https://codecov.io/gh/sinaptik-ai/pandas-ai)
[![Discord](https://dcbadge.vercel.app/api/server/kF7FqH2FwS?style=flat&amp;compact=true)](https://discord.gg/KYKj9F2FRH)
[![Downloads](https://static.pepy.tech/badge/pandasai)](https://pepy.tech/project/pandasai) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ZnO-njhL7TBOYPZaqvMvGtsjckZKrv2E?usp=sharing)

PandaAI is a Python platform that makes it easy to ask questions to your data in natural language. It helps non-technical users to interact with their data in a more natural way, and it helps technical users to save time, and effort when working with data.

# ğŸ”§ Getting started

You can find the full documentation for PandaAI [here](https://pandas-ai.readthedocs.io/en/latest/).

You can either decide to use PandaAI in your Jupyter notebooks, Streamlit apps, or use the client and server architecture from the repo.

## â˜ï¸ Using the platform

The library can be used alongside our powerful data platform, making end-to-end conversational data analytics possible with as little as a few lines of code.

Load your data, save them as a dataframe, and push them to the platform

```python
import pandasai as pai

pai.api_key.set(&quot;your-pai-api-key&quot;)

file = pai.read_csv(&quot;./filepath.csv&quot;)

dataset = pai.create(path=&quot;your-organization/dataset-name&quot;,
    df=file,
    name=&quot;dataset-name&quot;,
    description=&quot;dataset-description&quot;)

dataset.push()
```

Your team can now access and query this data using natural language through the platform.

![PandaAI](assets/demo.gif)

## ğŸ“š Using the library

### Python Requirements

Python version `3.8+ &lt;3.12`

### ğŸ“¦ Installation

You can install the PandaAI library using pip or poetry.

With pip:

```bash
pip install &quot;pandasai&gt;=3.0.0b2&quot;
```

With poetry:

```bash
poetry add &quot;pandasai&gt;=3.0.0b2&quot;
```

### ğŸ’» Usage

#### Ask questions

```python
import pandasai as pai

# Sample DataFrame
df = pai.DataFrame({
    &quot;country&quot;: [&quot;United States&quot;, &quot;United Kingdom&quot;, &quot;France&quot;, &quot;Germany&quot;, &quot;Italy&quot;, &quot;Spain&quot;, &quot;Canada&quot;, &quot;Australia&quot;, &quot;Japan&quot;, &quot;China&quot;],
    &quot;revenue&quot;: [5000, 3200, 2900, 4100, 2300, 2100, 2500, 2600, 4500, 7000]
})

# By default, unless you choose a different LLM, it will use BambooLLM.
# You can get your free API key signing up at https://app.pandabi.ai (you can also configure it in your .env file)
pai.api_key.set(&quot;your-pai-api-key&quot;)

df.chat(&#039;Which are the top 5 countries by sales?&#039;)
```

```
China, United States, Japan, Germany, Australia
```

---

Or you can ask more complex questions:

```python
df.chat(
    &quot;What is the total sales for the top 3 countries by sales?&quot;
)
```

```
The total sales for the top 3 countries by sales is 16500.
```

#### Visualize charts

You can also ask PandaAI to generate charts for you:

```python
df.chat(
    &quot;Plot the histogram of countries showing for each one the gd. Use different colors for each bar&quot;,
)
```

![Chart](assets/histogram-chart.png?raw=true)

#### Multiple DataFrames

You can also pass in multiple dataframes to PandaAI and ask questions relating them.

```python
import pandasai as pai

employees_data = {
    &#039;EmployeeID&#039;: [1, 2, 3, 4, 5],
    &#039;Name&#039;: [&#039;John&#039;, &#039;Emma&#039;, &#039;Liam&#039;, &#039;Olivia&#039;, &#039;William&#039;],
    &#039;Department&#039;: [&#039;HR&#039;, &#039;Sales&#039;, &#039;IT&#039;, &#039;Marketing&#039;, &#039;Finance&#039;]
}

salaries_data = {
    &#039;EmployeeID&#039;: [1, 2, 3, 4, 5],
    &#039;Salary&#039;: [5000, 6000, 4500, 7000, 5500]
}

employees_df = pai.DataFrame(employees_data)
salaries_df = pai.DataFrame(salaries_data)

# By default, unless you choose a different LLM, it will use BambooLLM.
# You can get your free API key signing up at https://app.pandabi.ai (you can also configure it in your .env file)
pai.api_key.set(&quot;your-pai-api-key&quot;)

pai.chat(&quot;Who gets paid the most?&quot;, employees_df, salaries_df)
```

```
Olivia gets paid the most.
```

#### Docker Sandbox

You can run PandaAI in a Docker sandbox, providing a secure, isolated environment to execute code safely and mitigate the risk of malicious attacks.

##### Python Requirements

```bash
pip install &quot;pandasai-docker&quot;
```

##### Usage

```python
import pandasai as pai
from pandasai_docker import DockerSandbox

# Initialize the sandbox
sandbox = DockerSandbox()
sandbox.start()

employees_data = {
    &#039;EmployeeID&#039;: [1, 2, 3, 4, 5],
    &#039;Name&#039;: [&#039;John&#039;, &#039;Emma&#039;, &#039;Liam&#039;, &#039;Olivia&#039;, &#039;William&#039;],
    &#039;Department&#039;: [&#039;HR&#039;, &#039;Sales&#039;, &#039;IT&#039;, &#039;Marketing&#039;, &#039;Finance&#039;]
}

salaries_data = {
    &#039;EmployeeID&#039;: [1, 2, 3, 4, 5],
    &#039;Salary&#039;: [5000, 6000, 4500, 7000, 5500]
}

employees_df = pai.DataFrame(employees_data)
salaries_df = pai.DataFrame(salaries_data)

# By default, unless you choose a different LLM, it will use BambooLLM.
# You can get your free API key signing up at https://app.pandabi.ai (you can also configure it in your .env file)
pai.api_key.set(&quot;your-pai-api-key&quot;)

pai.chat(&quot;Who gets paid the most?&quot;, employees_df, salaries_df, sandbox=sandbox)

# Don&#039;t forget to stop the sandbox when done
sandbox.stop()
```

```
Olivia gets paid the most.
```

You can find more examples in the [examples](examples) directory.

## ğŸ“œ License

PandaAI is available under the MIT expat license, except for the `pandasai/ee` directory of this repository, which has its [license here](https://github.com/sinaptik-ai/pandas-ai/blob/main/ee/LICENSE).

If you are interested in managed PandaAI Cloud or self-hosted Enterprise Offering, [contact us](https://getpanda.ai/pricing).

## Resources

&gt; **Beta Notice**  
&gt; Release v3 is currently in beta. The following documentation and examples reflect the features and functionality in progress and may change before the final release.

- [Docs](https://pandas-ai.readthedocs.io/en/latest/) for comprehensive documentation
- [Examples](examples) for example notebooks
- [Discord](https://discord.gg/KYKj9F2FRH) for discussion with the community and PandaAI team

## ğŸ¤ Contributing

Contributions are welcome! Please check the outstanding issues and feel free to open a pull request.
For more information, please check out the [contributing guidelines](CONTRIBUTING.md).

### Thank you!

[![Contributors](https://contrib.rocks/image?repo=sinaptik-ai/pandas-ai)](https://github.com/sinaptik-ai/pandas-ai/graphs/contributors)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[emcie-co/parlant]]></title>
            <link>https://github.com/emcie-co/parlant</link>
            <guid>https://github.com/emcie-co/parlant</guid>
            <pubDate>Fri, 16 May 2025 00:04:14 GMT</pubDate>
            <description><![CDATA[Parlant is the open-source engine for controlled, compliant, and purposeful generative AI conversations. It gives you the power of LLMs without the unpredictability.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/emcie-co/parlant">emcie-co/parlant</a></h1>
            <p>Parlant is the open-source engine for controlled, compliant, and purposeful generative AI conversations. It gives you the power of LLMs without the unpredictability.</p>
            <p>Language: Python</p>
            <p>Stars: 2,857</p>
            <p>Forks: 286</p>
            <p>Stars today: 82 stars today</p>
            <h2>README</h2><pre>
&lt;div align=&quot;center&quot;&gt;
&lt;!--&lt;img alt=&quot;Parlant Banner&quot; src=&quot;https://github.com/emcie-co/parlant/blob/develop/banner.png?raw=true&quot; /&gt;--&gt;


&lt;h1&gt;Parlant&lt;/h1&gt;
  &lt;h3&gt;The Conversation Modeling Engine&lt;/h3&gt;

Parlant is the open-source framework for safe, compliant, and custom generative AI conversations. It gives you the power of LLMs without the unpredictability.

  &lt;a href=&quot;https://trendshift.io/repositories/12768&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/12768&quot; alt=&quot;emcie-co%2Fparlant | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;


  &lt;p&gt;
    &lt;a href=&quot;https://www.parlant.io/&quot; target=&quot;_blank&quot;&gt;Website&lt;/a&gt; â€”
    &lt;a href=&quot;https://www.parlant.io/docs/quickstart/introduction&quot; target=&quot;_blank&quot;&gt;Introduction&lt;/a&gt; â€”
    &lt;a href=&quot;https://www.parlant.io/docs/tutorial/getting-started&quot; target=&quot;_blank&quot;&gt;Tutorial&lt;/a&gt; â€”
    &lt;a href=&quot;https://www.parlant.io/docs/about&quot; target=&quot;_blank&quot;&gt;About&lt;/a&gt;
  &lt;/p&gt;


  
  &lt;p&gt;
    &lt;a href=&quot;https://pypi.org/project/parlant/&quot; alt=&quot;Parlant on PyPi&quot;&gt;&lt;img alt=&quot;PyPI - Version&quot; src=&quot;https://img.shields.io/pypi/v/parlant&quot;&gt;&lt;/a&gt;
    &lt;img alt=&quot;PyPI - Python Version&quot; src=&quot;https://img.shields.io/pypi/pyversions/parlant&quot;&gt;
    &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;&lt;img alt=&quot;Apache 2 License&quot; src=&quot;https://img.shields.io/badge/license-Apache%202.0-blue.svg&quot; /&gt;&lt;/a&gt;
    &lt;img alt=&quot;GitHub commit activity&quot; src=&quot;https://img.shields.io/github/commit-activity/w/emcie-co/parlant?label=commits&quot;&gt;
    &lt;img alt=&quot;PyPI - Downloads&quot; src=&quot;https://img.shields.io/pypi/dm/parlant&quot;&gt;
    &lt;a href=&quot;https://discord.gg/duxWqxKk6J&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1312378700993663007?style=flat&amp;logo=discord&amp;logoColor=white&amp;label=discord&quot;&gt;
&lt;/a&gt;
  &lt;/p&gt;

&lt;/div&gt;

## YouTube Video Intro
[![Parlant Introduction](https://github.com/emcie-co/parlant/blob/develop/yt-preview.png?raw=true)](https://www.youtube.com/watch?v=_39ERIb0100)

1. Install
```bash
pip install parlant
```

2. Start the server and start interact with the default agent
```bash
parlant-server run
# Now visit http://localhost:8800
```

3. Add behavioral guidelines and let Parlant do the rest
```bash
parlant guideline create \
    --condition &quot;the user greets you&quot; \
    --action &quot;thank them for checking out Parlant&quot;
# Now start a new conversation and greet the agent
```

## Quick Demo
&lt;img alt=&quot;Parlant Banner&quot; src=&quot;https://github.com/emcie-co/parlant/blob/develop/ParlantGIF.gif?raw=true&quot; /&gt;


## What is Conversation Modeling?
You&#039;ve built an AI agentâ€”that&#039;s great! However, when you actually test it, you see it&#039;s not handling many customer interactions properly, and your business experts are displeased with it. What do you do?

Enter Conversation Modeling (CM): a new powerful and reliable approach to controlling how your agents interact with your users.

A conversation model is a structured, domain-specific set of principles, actions, objectives, and terms that an agent applies to a given conversation.

### Why Conversation Modeling?

The problem of getting your AI agent to say what _you_ want it to say is a hard one, experienced by virtually anyone building customer-facing agents. Here&#039;s how Conversation Modeling compares to other approaches to solving this problem.

- **Flow engines** _force_ the user to interact according to predefined flows. In contrast, a **CM engine** dynamically _adapts_ to a user&#039;s natural interaction patterns while conforming to your rules.

- **Free-form prompt engineering** leads to _inconsistency_, frequently failing to uphold requirements. Conversely, a **CM engine** leverages structure to _enforce_ conformance to a Conversation Model.


## Who uses Parlant?
Parlant is used to deliver complex conversational agents that reliably follow your business protocols in use cases such as:
- ğŸ¦ Regulated financial services
- ğŸ¥ Healthcare communications
- ğŸ“œ Legal assistance
- ğŸ›¡ï¸ Compliance-focused use cases
- ğŸ¯ Brand-sensitive customer service
- ğŸ¤ Personal advocacy and representation

## How is Parlant used?
Developers and data-scientists are using Parlant to:

- ğŸ¤– Create custom-tailored conversational agents quickly and easily
- ğŸ‘£ Define behavioral guidelines for agents to follow (Parlant ensures they are followed reliably)
- ğŸ› ï¸ Attach tools with specific guidance on how to properly use them in different contexts
- ğŸ“– Manage their agentsâ€™ glossary to ensure strict interpretation of terms in a conversational context
- ğŸ‘¤ Add customer-specific information to deliver personalized interactions

#### How does Parlant work?
```mermaid
graph TD
    API(Parlant REST API) --&gt;|React to Session Trigger| Engine[AI Response Engine]
    Engine --&gt;|Load Domain Terminology| GlossaryStore
    Engine --&gt;|Match Guidelines| GuidelineMatcher
    Engine --&gt;|Infer &amp; Call Tools| ToolCaller
    Engine --&gt;|Tailor Guided Message| MessageComposer
```

When an agent needs to respond to a customer, Parlant&#039;s engine evaluates the situation, checks relevant guidelines, gathers necessary information through your tools, and continuously re-evaluates its approach based on your guidelines as new information emerges. When it&#039;s time to generate a message, Parlant implements self-critique mechanisms to ensure that the agent&#039;s responses precisely align with your intended behavior as given by the contextually-matched guidelines.

***ğŸ“š More technical docs on the architecture and API are available under [docs/](./docs)***.

## ğŸ“¦ Quickstart
Parlant comes pre-built with responsive session (conversation) management, a detection mechanism for incoherence and contradictions in guidelines, content-filtering, jailbreak protection, an integrated sandbox UI for behavioral testing, native API clients in Python and TypeScript, and other goodies.

```bash
$ pip install parlant
$ parlant-server run
$ # Open the sandbox UI at http://localhost:8800 and play
```

## ğŸ™‹â€â™‚ï¸ğŸ™‹â€â™€ï¸ Who Is Parlant For?
Parlant is the right tool for the job if you&#039;re building an LLM-based chat agent, and:

1. ğŸ¯ Your use case places a **high importance on behavioral precision and consistency**, particularly in customer-facing scenarios
1. ğŸ”„ Your agent is expected to undergo **continuous behavioral refinements and changes**, and you need a way to implement those changes efficiently and confidently
1. ğŸ“ˆ You&#039;re expected to maintain a **growing set of behavioral guidelines**, and you need to maintain them coherently and with version-tracking
1. ğŸ’¬ Conversational UX and user-engagmeent is an important concern for your use case, and you want to easily **control the flow and tone of conversations**

## â­ Star Us: Your Support Goes a Long Way!
[![Star History Chart](https://api.star-history.com/svg?repos=emcie-co/parlant&amp;type=Date)](https://star-history.com/#emcie-co/parlant&amp;Date)

## ğŸ¤” What Makes Parlant Different?

In a word: **_Guidance._** ğŸ§­ğŸš¦ğŸ¤

Parlant&#039;s engine revolves around solving one key problem: How can we _reliably guide_ customer-facing agents to behave in alignment with our needs and intentions.

Hence Parlant&#039;s fundamentally different approach to agent building: [Managed Guidelines](https://www.parlant.io/docs/concepts/customization/guidelines):

```bash
parlant guideline create \
  --condition &quot;the customer wants to return an item&quot; \
  --action &quot;get the order number and item name and then help them return it&quot;
```

By giving structure to behavioral guidelines, and _granularizing_ guidelines (i.e. making each behavioral guideline a first-class entity in the engine), Parlant&#039;s engine is able to offer unprecedented control, quality, and efficiency in building LLM-based agents:

1. ğŸ›¡ï¸ **Reliability:** Running focused self-critique in real-time, per guideline, to ensure it is actually followed
1. ğŸ’¡ **Explainability:** Providing feedback around its interpretation of guidelines in each real-life context, which helps in troubleshooting and improvement
1. ğŸ”§ **Maintainability:** Helping you maintain a coherent set of guidelines by detecting and alerting you to possible contradictions (gross or subtle) in your instructions

## ğŸ¤– Works with all major LLM providers
- [OpenAI](https://platform.openai.com/docs/overview) (also via [Azure](https://learn.microsoft.com/en-us/azure/ai-services/openai/))
- [Gemini](https://ai.google.dev/)
- [Meta Llama 3](https://www.llama.com/) (via [Together AI](https://www.together.ai/) or [Cerebras](https://cerebras.ai/))
- [Anthropic](https://www.anthropic.com/api) (also via [AWS Bedrock](https://aws.amazon.com/bedrock/))
- And more are added regularly

## ğŸ“š Learning Parlant

To start learning and building with Parlant, visit our [documentation portal](https://parlant.io/docs/quickstart/introduction).

Need help? Ask us anything on [Discord](https://discord.gg/duxWqxKk6J). We&#039;re happy to answer questions and help you get up and running!

## ğŸ’» Usage Example
Adding a guideline for an agentâ€”for example, to ask a counter-question to get more info when a customer asks a question:
```bash
parlant guideline create \
    --condition &quot;a free-tier customer is asking how to use our product&quot; \
    --action &quot;first seek to understand what they&#039;re trying to achieve&quot;
```

## ğŸ‘‹ Contributing
We use the Linux-standard Developer Certificate of Origin ([DCO.md](DCO.md)), so that, by contributing, you confirm that you have the rights to submit your contribution under the Apache 2.0 license (i.e., that the code you&#039;re contributing is truly yours to share with the project).

Please consult [CONTRIBUTING.md](CONTRIBUTING.md) for more details.

Can&#039;t wait to get involved? Join us on [Discord](https://discord.gg/duxWqxKk6J) and let&#039;s discuss how you can help shape Parlant. We&#039;re excited to work with contributors directly while we set up our formal processes!

Otherwise, feel free to start a discussion or open an issue here on GitHubâ€”freestyle ğŸ˜.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[LibreTranslate/LibreTranslate]]></title>
            <link>https://github.com/LibreTranslate/LibreTranslate</link>
            <guid>https://github.com/LibreTranslate/LibreTranslate</guid>
            <pubDate>Fri, 16 May 2025 00:04:13 GMT</pubDate>
            <description><![CDATA[Free and Open Source Machine Translation API. Self-hosted, offline capable and easy to setup.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/LibreTranslate/LibreTranslate">LibreTranslate/LibreTranslate</a></h1>
            <p>Free and Open Source Machine Translation API. Self-hosted, offline capable and easy to setup.</p>
            <p>Language: Python</p>
            <p>Stars: 11,421</p>
            <p>Forks: 1,110</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre># LibreTranslate

[Try it online!](https://libretranslate.com) | [API Docs](https://libretranslate.com/docs) | [Community Forum](https://community.libretranslate.com/) | [Bluesky](https://bsky.app/profile/libretranslate.com)

[![Python versions](https://img.shields.io/pypi/pyversions/libretranslate)](https://pypi.org/project/libretranslate) [![Run tests](https://github.com/LibreTranslate/LibreTranslate/workflows/Run%20tests/badge.svg)](https://github.com/LibreTranslate/LibreTranslate/actions?query=workflow%3A%22Run+tests%22) [![Build and Publish Docker Image](https://github.com/LibreTranslate/LibreTranslate/actions/workflows/publish-docker.yml/badge.svg)](https://github.com/LibreTranslate/LibreTranslate/actions/workflows/publish-docker.yml) [![Publish package](https://github.com/LibreTranslate/LibreTranslate/actions/workflows/publish-package.yml/badge.svg)](https://github.com/LibreTranslate/LibreTranslate/actions/workflows/publish-package.yml) [![Awesome Humane Tech](https://raw.githubusercontent.com/humanetech-community/awesome-humane-tech/main/humane-tech-badge.svg?sanitize=true)](https://codeberg.org/teaserbot-labs/delightful-humane-design)

Free and Open Source Machine Translation API, entirely self-hosted. Unlike other APIs, it doesn&#039;t rely on proprietary providers such as Google or Azure to perform translations. Instead, its translation engine is powered by the open source [Argos Translate](https://github.com/argosopentech/argos-translate) library.

![Translation](https://github.com/user-attachments/assets/457696b5-dbff-40ab-a18e-7bfb152c5121)

## API Examples

### Simple

Request:

```javascript
const res = await fetch(&quot;https://libretranslate.com/translate&quot;, {
  method: &quot;POST&quot;,
  body: JSON.stringify({
    q: &quot;Hello!&quot;,
    source: &quot;en&quot;,
    target: &quot;es&quot;,
  }),
  headers: { &quot;Content-Type&quot;: &quot;application/json&quot; },
});

console.log(await res.json());
```

Response:

```javascript
{
    &quot;translatedText&quot;: &quot;Â¡Hola!&quot;
}
```

List of language codes: https://libretranslate.com/languages

### Auto Detect Language

Request:

```javascript
const res = await fetch(&quot;https://libretranslate.com/translate&quot;, {
  method: &quot;POST&quot;,
  body: JSON.stringify({
    q: &quot;Ciao!&quot;,
    source: &quot;auto&quot;,
    target: &quot;en&quot;,
  }),
  headers: { &quot;Content-Type&quot;: &quot;application/json&quot; },
});

console.log(await res.json());
```

Response:

```javascript
{
    &quot;detectedLanguage&quot;: {
        &quot;confidence&quot;: 83,
        &quot;language&quot;: &quot;it&quot;
    },
    &quot;translatedText&quot;: &quot;Bye!&quot;
}
```

### HTML

Request:

```javascript
const res = await fetch(&quot;https://libretranslate.com/translate&quot;, {
  method: &quot;POST&quot;,
  body: JSON.stringify({
    q: &#039;&lt;p class=&quot;green&quot;&gt;Hello!&lt;/p&gt;&#039;,
    source: &quot;en&quot;,
    target: &quot;es&quot;,
    format: &quot;html&quot;,
  }),
  headers: { &quot;Content-Type&quot;: &quot;application/json&quot; },
});

console.log(await res.json());
```

Response:

```javascript
{
    &quot;translatedText&quot;: &quot;&lt;p class=\&quot;green\&quot;&gt;Â¡Hola!&lt;/p&gt;&quot;
}
```

### Alternative Translations

Request:

```javascript
const res = await fetch(&quot;https://libretranslate.com/translate&quot;, {
  method: &quot;POST&quot;,
  body: JSON.stringify({
    q: &quot;Hello&quot;,
    source: &quot;en&quot;,
    target: &quot;it&quot;,
    format: &quot;text&quot;,
    alternatives: 3,
  }),
  headers: { &quot;Content-Type&quot;: &quot;application/json&quot; },
});

console.log(await res.json());
```

Response:

```javascript
{
    &quot;alternatives&quot;: [
        &quot;Salve&quot;,
        &quot;Pronto&quot;
    ],
    &quot;translatedText&quot;: &quot;Ciao&quot;
}
```

## Install and Run

You can run your own API server with just a few lines of setup!

Make sure you have Python installed (3.8 or higher is recommended), then simply run:

```bash
pip install libretranslate
libretranslate [args]
```

Then open a web browser to &lt;http://localhost:5000&gt;

By default LibreTranslate will install support for all available languages. To only load certain languages and reduce startup time, you can use the **--load-only** argument:

```bash
libretranslate --load-only en,es,fr
```

Check also all other [arguments](#settings--flags) below.

On Ubuntu 20.04 you can also use the install script available at &lt;https://github.com/argosopentech/LibreTranslate-init&gt;

## Run with Docker

You can also run the application with [docker](https://docker.com):

### Linux/macOS

```bash
./run.sh [args]
```

### Windows

```bash
run.bat [args]
```

## Build and Run

See [CONTRIBUTING.md](./CONTRIBUTING.md) for information on how to build and run the project yourself.

### CUDA

You can use hardware acceleration to speed up translations on a GPU machine with CUDA 12.4.1 and [nvidia-docker](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html) installed.

Run this version with:

```bash
docker compose -f docker-compose.cuda.yml up -d --build
```

## Arguments

Arguments passed to the process or set via environment variables are split into two kinds.

- Settings or runtime flags used to toggle specific runmodes or disable parts of the application. These act as toggle when added or removed.

- Configuration parameters to set various limits and configure the application. These require a parameter to be passed to function, if removed the default parameters are used.

### Settings / Flags

| Argument                      | Description                                                                                                 | Default Setting                    | Env. name                      |
| ----------------------------- | ----------------------------------------------------------------------------------------------------------- | ---------------------------------- | ------------------------------ |
| --debug                       | Enable debug environment                                                                                    | `Disabled`                         | LT_DEBUG                       |
| --ssl                         | Whether to enable SSL                                                                                       | `Disabled`                         | LT_SSL                         |
| --api-keys                    | Enable API keys database for per-client rate limits when --req-limit is reached                             | `Don&#039;t use API keys`               | LT_API_KEYS                    |
| --require-api-key-origin      | Require use of an API key for programmatic access to the API, unless the request origin matches this domain | `No restrictions on domain origin` | LT_REQUIRE_API_KEY_ORIGIN      |
| --require-api-key-secret      | Require use of an API key for programmatic access to the API, unless the client also sends a secret match   | `No secrets required`              | LT_REQUIRE_API_KEY_SECRET      |
| --require-api-key-fingerprint | Require use of an API key for programmatic access to the API, unless the client also matches a fingerprint  | `No fingerprinting required`       | LT_REQUIRE_API_KEY_FINGERPRINT |
| --under-attack                | Enable under attack mode. When enabled, requests must be made with an API key                               | `Disabled`                         | LT_UNDER_ATTACK                |
| --suggestions                 | Allow user suggestions                                                                                      | `Disabled`                         | LT_SUGGESTIONS                 |
| --disable-files-translation   | Disable files translation                                                                                   | `File translation allowed`         | LT_DISABLE_FILES_TRANSLATION   |
| --disable-web-ui              | Disable web ui                                                                                              | `Web Ui enabled`                   | LT_DISABLE_WEB_UI              |
| --update-models               | Update language models at startup                                                                           | `Only on if no models found`       | LT_UPDATE_MODELS               |
| --metrics                     | Enable the /metrics endpoint for exporting [Prometheus](https://prometheus.io/) usage metrics               | `Disabled`                         | LT_METRICS                     |

### Configuration Parameters

| Argument                   | Description                                                                                                                                                                                                 | Default Parameter                     | Env. name                   |
| -------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------- | --------------------------- |
| --host                     | Set host to bind the server to                                                                                                                                                                              | `127.0.0.1`                           | LT_HOST                     |
| --port                     | Set port to bind the server to                                                                                                                                                                              | `5000`                                | LT_PORT                     |
| --char-limit               | Set character limit                                                                                                                                                                                         | `No limit`                            | LT_CHAR_LIMIT               |
| --req-limit                | Set maximum number of requests per minute per client (outside of limits set by api keys)                                                                                                                    | `No limit`                            | LT_REQ_LIMIT                |
| --req-limit-storage        | Storage URI to use for request limit data storage. See [Flask Limiter](https://flask-limiter.readthedocs.io/en/stable/configuration.html)                                                                   | `memory://`                           | LT_REQ_LIMIT_STORAGE        |
| --req-time-cost            | Considers a time cost (in seconds) for request limiting purposes. If a request takes 10 seconds and this value is set to 5, the request cost is either 2 or the actual request cost (whichever is greater). | `No time cost`                        | LT_REQ_TIME_COST            |
| --batch-limit              | Set maximum number of texts to translate in a batch request                                                                                                                                                 | `No limit`                            | LT_BATCH_LIMIT              |
| --ga-id                    | Enable Google Analytics on the API client page by providing an ID                                                                                                                                           | `Empty (no tracking)`                 | LT_GA_ID                    |
| --frontend-language-source | Set frontend default language - source                                                                                                                                                                      | `auto`                                | LT_FRONTEND_LANGUAGE_SOURCE |
| --frontend-language-target | Set frontend default language - target                                                                                                                                                                      | `locale` (match site&#039;s locale)        | LT_FRONTEND_LANGUAGE_TARGET |
| --frontend-timeout         | Set frontend translation timeout                                                                                                                                                                            | `500`                                 | LT_FRONTEND_TIMEOUT         |
| --api-keys-db-path         | Use a specific path inside the container for the local database. Can be absolute or relative                                                                                                                | `db/api_keys.db`                      | LT_API_KEYS_DB_PATH         |
| --api-keys-remote          | Use this remote endpoint to query for valid API keys instead of using the local database                                                                                                                    | `Empty (use local db instead)`        | LT_API_KEYS_REMOTE          |
| --get-api-key-link         | Show a link in the UI where to direct users to get an API key                                                                                                                                               | `Empty (no link shown on web ui)`     | LT_GET_API_KEY_LINK         |
| --shared-storage           | Shared storage URI to use for multi-process data sharing (e.g. when using gunicorn)                                                                                                                         | `memory://`                           | LT_SHARED_STORAGE           |
| --secondary                | Mark this instance as a secondary instance to avoid conflicts with the primary node in multi-node setups                                                                                                    | `Primary node`                        | LT_SECONDARY                |
| --load-only                | Set available languages                                                                                                                                                                                     | `Empty (use all from argostranslate)` | LT_LOAD_ONLY                |
| --threads                  | Set number of threads                                                                                                                                                                                       | `4`                                   | LT_THREADS                  |
| --metrics-auth-token       | Protect the /metrics endpoint by allowing only clients that have a valid Authorization Bearer token                                                                                                         | `Empty (no auth required)`            | LT_METRICS_AUTH_TOKEN       |
| --url-prefix               | Add prefix to URL: example.com:5000/url-prefix/                                                                                                                                                             | `/`                                   | LT_URL_PREFIX               |

### Notes:

- Each argument has an equivalent environment variable that can be used instead. The env. variables overwrite the default values but have lower priority than the command arguments and are particularly useful if used with Docker. The environment variable names are the upper-snake-case of the equivalent command argument&#039;s name with a `LT` prefix.

- To configure requirement for api key to use, set `--req-limit` to `0` and add the `--api-keys` flag. Requests made without a proper api key will be rejected.

- Setting `--update-models` will update models regardless of whether updates are available or not.

## Update

### Software

If you installed with pip:

`pip install -U libretranslate`

If you&#039;re using docker:

`docker pull libretranslate/libretranslate`

### Language Models

Start the program with the `--update-models` argument. For example: `libretranslate --update-models` or `./run.sh --update-models`.

Alternatively you can also run the `scripts/install_models.py` script.

## Run with WSGI and Gunicorn

```bash
pip install gunicorn
gunicorn --bind 0.0.0.0:5000 &#039;wsgi:app&#039;
```

You can pass application arguments directly to Gunicorn via:

```bash
gunicorn --bind 0.0.0.0:5000 &#039;wsgi:app(api_keys=True)&#039;
```

## Kubernetes Deployment

See [Medium article by JM Robles](https://jmrobles.medium.com/libretranslate-your-own-translation-service-on-kubernetes-b46c3e1af630) and the improved [k8s.yaml](https://github.com/LibreTranslate/LibreTranslate/blob/main/k8s.yaml) by @rasos.

### Helm Chart

Based on @rasos work you can now install LibreTranslate on Kubernetes using Helm.

A Helm chart is now available in the [helm-chart](https://github.com/LibreTranslate/helm-chart/) repository where you can find more details.

You can quickly install LibreTranslate on Kubernetes using Helm with the following command:

```bash
helm repo add libretranslate https://libretranslate.github.io/helm-chart/
helm repo update
helm search repo libretranslate

helm install libretranslate libretranslate/libretranslate --namespace libretranslate --create-namespace
```

## Manage API Keys

LibreTranslate supports per-user limit quotas, e.g. you can issue API keys to users so that they can enjoy higher requests limits per minute (if you also set `--req-limit`). By default all users are rate-limited based on `--req-limit`, but passing an optional `api_key` parameter to the REST endpoints allows a user to enjoy higher request limits. You can also specify different character limits that bypass the default `--char-limit` value on a per-key basis.

To use API keys simply start LibreTranslate with the `--api-keys` option. If you modified the API keys database path with the option `--api-keys-db-path`, you must specify the path with the same argument flag when using the `ltmanage keys` command.

### Add New Keys

To issue a new API key with 120 requests per minute limits:

```bash
ltmanage keys add 120
```

To issue a new API key with 120 requests per minute and a maximum of 5,000 characters per request:

```bash
ltmanage keys add 120 --char-limit 5000
```

If you changed the API keys database path:

```bash
ltmanage keys --api-keys-db-path path/to/db/dbName.db add 120
```

### Remove Keys

```bash
ltmanage keys remove &lt;api-key&gt;
```

### View Keys

```bash
ltmanage keys
```

## Prometheus Metrics

LibreTranslate has Prometheus [exporter](https://prometheus.io/docs/instrumenting/exporters/) capabilities when you pass the `--metrics` argument at startup (disabled by default). When metrics are enabled, a `/metrics` endpoint is mounted on the instance:

&lt;http://localhost:5000/metrics&gt;

```promql
# HELP libretranslate_http_requests_in_flight Multiprocess metric
# TYPE libretranslate_http_requests_in_flight gauge
libretranslate_http_requests_in_flight{api_key=&quot;&quot;,endpoint=&quot;/translate&quot;,request_ip=&quot;127.0.0.1&quot;} 0.0
# HELP libretranslate_http_request_duration_seconds Multiprocess metric
# TYPE libretranslate_http_request_duration_seconds summary
libretranslate_http_request_duration_seconds_count{api_key=&quot;&quot;,endpoint=&quot;/translate&quot;,request_ip=&quot;127.0.0.1&quot;,status=&quot;200&quot;} 0.0
libretranslate_http_request_duration_seconds_sum{api_key=&quot;&quot;,endpoint=&quot;/translate&quot;,request_ip=&quot;127.0.0.1&quot;,status=&quot;200&quot;} 0.0
```

You can then configure `prometheus.yml` to read the metrics:

```yaml
scrape_configs:
  - job_name: &quot;libretranslate&quot;

    # Needed only if you use --metrics-auth-token
    #authorization:
    #credentials: &quot;mytoken&quot;

    static_configs:
      - targets: [&quot;localhost:5000&quot;]
```

To secure the `/metrics` endpoint you can also use `--metrics-auth-token mytoken`.

If you use Gunicorn, make sure to create a directory for storing multiprocess data metrics and set `PROMETHEUS_MULTIPROC_DIR`:

```bash
mkdir -p /tmp/prometheus_data
rm /tmp/prometheus_data/*
export PROMETHEUS_MULTIPROC_DIR=/tmp/prometheus_data
gunicorn -c scripts/gunicorn_conf.py --bind 0.0.0.0:5000 &#039;wsgi:app(metrics=True)&#039;
```

## Language Bindings

You can use the LibreTranslate API using the following bindings:

- Rust: &lt;https://github.com/DefunctLizard/libretranslate-rs&gt;
- Node.js: &lt;https://

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[mlflow/mlflow]]></title>
            <link>https://github.com/mlflow/mlflow</link>
            <guid>https://github.com/mlflow/mlflow</guid>
            <pubDate>Fri, 16 May 2025 00:04:12 GMT</pubDate>
            <description><![CDATA[Open source platform for the machine learning lifecycle]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mlflow/mlflow">mlflow/mlflow</a></h1>
            <p>Open source platform for the machine learning lifecycle</p>
            <p>Language: Python</p>
            <p>Stars: 20,524</p>
            <p>Forks: 4,523</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre># MLflow: A Machine Learning Lifecycle Platform

[![Latest Docs](https://img.shields.io/badge/docs-latest-success.svg?style=for-the-badge)](https://mlflow.org/docs/latest/index.html)
[![Apache 2 License](https://img.shields.io/badge/license-Apache%202-brightgreen.svg?style=for-the-badge&amp;logo=apache)](https://github.com/mlflow/mlflow/blob/master/LICENSE.txt)
[![Total Downloads](https://img.shields.io/pypi/dw/mlflow?style=for-the-badge&amp;logo=pypi&amp;logoColor=white)](https://pepy.tech/project/mlflow)
[![Slack](https://img.shields.io/badge/slack-@mlflow--users-CF0E5B.svg?logo=slack&amp;logoColor=white&amp;labelColor=3F0E40&amp;style=for-the-badge)](https://mlflow.org/community/#slack)
[![Twitter](https://img.shields.io/twitter/follow/MLflow?style=for-the-badge&amp;labelColor=00ACEE&amp;logo=twitter&amp;logoColor=white)](https://twitter.com/MLflow)

MLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in handling the complexities of the machine learning process. MLflow focuses on the full lifecycle for machine learning projects, ensuring that each phase is manageable, traceable, and reproducible

---

The core components of MLflow are:

- [Experiment Tracking](https://mlflow.org/docs/latest/tracking.html) ğŸ“: A set of APIs to log models, params, and results in ML experiments and compare them using an interactive UI.
- [Model Packaging](https://mlflow.org/docs/latest/models.html) ğŸ“¦: A standard format for packaging a model and its metadata, such as dependency versions, ensuring reliable deployment and strong reproducibility.
- [Model Registry](https://mlflow.org/docs/latest/model-registry.html) ğŸ’¾: A centralized model store, set of APIs, and UI, to collaboratively manage the full lifecycle of MLflow Models.
- [Serving](https://mlflow.org/docs/latest/deployment/index.html) ğŸš€: Tools for seamless model deployment to batch and real-time scoring on platforms like Docker, Kubernetes, Azure ML, and AWS SageMaker.
- [Evaluation](https://mlflow.org/docs/latest/model-evaluation/index.html) ğŸ“Š: A suite of automated model evaluation tools, seamlessly integrated with experiment tracking to record model performance and visually compare results across multiple models.
- [Observability](https://mlflow.org/docs/latest/llms/tracing/index.html) ğŸ”: Tracing integrations with various GenAI libraries and a Python SDK for manual instrumentation, offering smoother debugging experience and supporting online monitoring.

&lt;img src=&quot;https://mlflow.org/img/hero.png&quot; alt=&quot;MLflow Hero&quot; width=100%&gt;

## Installation

To install the MLflow Python package, run the following command:

```
pip install mlflow
```

Alternatively, you can install MLflow from on different package hosting platforms:

|               |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| ------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| PyPI          | [![PyPI - mlflow](https://img.shields.io/pypi/v/mlflow.svg?style=for-the-badge&amp;logo=pypi&amp;logoColor=white&amp;label=mlflow)](https://pypi.org/project/mlflow/) [![PyPI - mlflow-skinny](https://img.shields.io/pypi/v/mlflow-skinny.svg?style=for-the-badge&amp;logo=pypi&amp;logoColor=white&amp;label=mlflow-skinny)](https://pypi.org/project/mlflow-skinny/)                                                                                                                                                                                                                                                                                                                                          |
| conda-forge   | [![Conda - mlflow](https://img.shields.io/conda/vn/conda-forge/mlflow.svg?style=for-the-badge&amp;logo=anaconda&amp;label=mlflow)](https://anaconda.org/conda-forge/mlflow) [![Conda - mlflow-skinny](https://img.shields.io/conda/vn/conda-forge/mlflow.svg?style=for-the-badge&amp;logo=anaconda&amp;label=mlflow-skinny)](https://anaconda.org/conda-forge/mlflow-skinny)                                                                                                                                                                                                                                                                                                                             |
| CRAN          | [![CRAN - mlflow](https://img.shields.io/cran/v/mlflow.svg?style=for-the-badge&amp;logo=r&amp;label=mlflow)](https://cran.r-project.org/package=mlflow)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| Maven Central | [![Maven Central - mlflow-client](https://img.shields.io/maven-central/v/org.mlflow/mlflow-client.svg?style=for-the-badge&amp;logo=apache-maven&amp;label=mlflow-client)](https://mvnrepository.com/artifact/org.mlflow/mlflow-client) [![Maven Central - mlflow-parent](https://img.shields.io/maven-central/v/org.mlflow/mlflow-parent.svg?style=for-the-badge&amp;logo=apache-maven&amp;label=mlflow-parent)](https://mvnrepository.com/artifact/org.mlflow/mlflow-parent) [![Maven Central - mlflow-spark](https://img.shields.io/maven-central/v/org.mlflow/mlflow-spark.svg?style=for-the-badge&amp;logo=apache-maven&amp;label=mlflow-spark)](https://mvnrepository.com/artifact/org.mlflow/mlflow-spark) |

## Documentation ğŸ“˜

Official documentation for MLflow can be found at [here](https://mlflow.org/docs/latest/index.html).

## Running Anywhere ğŸŒ

You can run MLflow on many different environments, including local development, Amazon SageMaker, AzureML, and Databricks. Please refer to [this guidance](https://mlflow.org/docs/latest/index.html#running-mlflow-anywhere) for how to setup MLflow on your environment.

## Usage

### Experiment Tracking ([Doc](https://mlflow.org/docs/latest/tracking.html))

The following examples trains a simple regression model with scikit-learn, while enabling MLflow&#039;s [autologging](https://mlflow.org/docs/latest/tracking/autolog.html) feature for experiment tracking.

```python
import mlflow

from sklearn.model_selection import train_test_split
from sklearn.datasets import load_diabetes
from sklearn.ensemble import RandomForestRegressor

# Enable MLflow&#039;s automatic experiment tracking for scikit-learn
mlflow.sklearn.autolog()

# Load the training dataset
db = load_diabetes()
X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)

rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)
# MLflow triggers logging automatically upon model fitting
rf.fit(X_train, y_train)
```

Once the above code finishes, run the following command in a separate terminal and access the MLflow UI via the printed URL. An MLflow **Run** should be automatically created, which tracks the training dataset, hyper parameters, performance metrics, the trained model, dependencies, and even more.

```
mlflow ui
```

### Serving Models ([Doc](https://mlflow.org/docs/latest/deployment/index.html))

You can deploy the logged model to a local inference server by a one-line command using the MLflow CLI. Visit the documentation for how to deploy models to other hosting platforms.

```bash
mlflow models serve --model-uri runs:/&lt;run-id&gt;/model
```

### Evaluating Models ([Doc](https://mlflow.org/docs/latest/model-evaluation/index.html))

The following example runs automatic evaluation for question-answering tasks with several built-in metrics.

```python
import mlflow
import pandas as pd

# Evaluation set contains (1) input question (2) model outputs (3) ground truth
df = pd.DataFrame(
    {
        &quot;inputs&quot;: [&quot;What is MLflow?&quot;, &quot;What is Spark?&quot;],
        &quot;outputs&quot;: [
            &quot;MLflow is an innovative fully self-driving airship powered by AI.&quot;,
            &quot;Sparks is an American pop and rock duo formed in Los Angeles.&quot;,
        ],
        &quot;ground_truth&quot;: [
            &quot;MLflow is an open-source platform for managing the end-to-end machine learning (ML) &quot;
            &quot;lifecycle.&quot;,
            &quot;Apache Spark is an open-source, distributed computing system designed for big data &quot;
            &quot;processing and analytics.&quot;,
        ],
    }
)
eval_dataset = mlflow.data.from_pandas(
    df, predictions=&quot;outputs&quot;, targets=&quot;ground_truth&quot;
)

# Start an MLflow Run to record the evaluation results to
with mlflow.start_run(run_name=&quot;evaluate_qa&quot;):
    # Run automatic evaluation with a set of built-in metrics for question-answering models
    results = mlflow.evaluate(
        data=eval_dataset,
        model_type=&quot;question-answering&quot;,
    )

print(results.tables[&quot;eval_results_table&quot;])
```

### Observability ([Doc](https://mlflow.org/docs/latest/llms/tracing/index.html))

MLflow Tracing provides LLM observability for various GenAI libraries such as OpenAI, LangChain, LlamaIndex, DSPy, AutoGen, and more. To enable auto-tracing, call `mlflow.xyz.autolog()` before running your models. Refer to the documentation for customization and manual instrumentation.

```python
import mlflow
from openai import OpenAI

# Enable tracing for OpenAI
mlflow.openai.autolog()

# Query OpenAI LLM normally
response = OpenAI().chat.completions.create(
    model=&quot;gpt-4o-mini&quot;,
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hi!&quot;}],
    temperature=0.1,
)
```

Then navigate to the &quot;Traces&quot; tab in the MLflow UI to find the trace records OpenAI query.

## Community

- For help or questions about MLflow usage (e.g. &quot;how do I do X?&quot;) visit the [docs](https://mlflow.org/docs/latest/index.html)
  or [Stack Overflow](https://stackoverflow.com/questions/tagged/mlflow).
- Alternatively, you can ask the question to our AI-powered chat bot. Visit the doc website and click on the **&quot;Ask AI&quot;** button at the right bottom to start chatting with the bot.
- To report a bug, file a documentation issue, or submit a feature request, please [open a GitHub issue](https://github.com/mlflow/mlflow/issues/new/choose).
- For release announcements and other discussions, please subscribe to our mailing list (mlflow-users@googlegroups.com)
  or join us on [Slack](https://mlflow.org/slack).

## Contributing

We happily welcome contributions to MLflow! We are also seeking contributions to items on the
[MLflow Roadmap](https://github.com/mlflow/mlflow/milestone/3). Please see our
[contribution guide](CONTRIBUTING.md) to learn more about contributing to MLflow.

## Core Members

MLflow is currently maintained by the following core members with significant contributions from hundreds of exceptionally talented community members.

- [Ben Wilson](https://github.com/BenWilson2)
- [Corey Zumar](https://github.com/dbczumar)
- [Daniel Lok](https://github.com/daniellok-db)
- [Gabriel Fu](https://github.com/gabrielfu)
- [Harutaka Kawamura](https://github.com/harupy)
- [Serena Ruan](https://github.com/serena-ruan)
- [Weichen Xu](https://github.com/WeichenXu123)
- [Yuki Watanabe](https://github.com/B-Step62)
- [Tomu Hirata](https://github.com/TomeHirata)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Azure/Azure-Sentinel]]></title>
            <link>https://github.com/Azure/Azure-Sentinel</link>
            <guid>https://github.com/Azure/Azure-Sentinel</guid>
            <pubDate>Fri, 16 May 2025 00:04:11 GMT</pubDate>
            <description><![CDATA[Cloud-native SIEM for intelligent security analytics for your entire enterprise.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Azure/Azure-Sentinel">Azure/Azure-Sentinel</a></h1>
            <p>Cloud-native SIEM for intelligent security analytics for your entire enterprise.</p>
            <p>Language: Python</p>
            <p>Stars: 5,043</p>
            <p>Forks: 3,185</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>
# Microsoft Sentinel and Microsoft 365 Defender 
Welcome to the unified Microsoft Sentinel and Microsoft 365 Defender repository! This repository contains out of the box detections, exploration queries, hunting queries, workbooks, playbooks and much more to help you get ramped up with Microsoft Sentinel and provide you security content to secure your environment and hunt for threats. The hunting queries also include Microsoft 365 Defender hunting queries for advanced hunting scenarios in both Microsoft 365 Defender and Microsoft Sentinel. You can also submit to [issues](https://github.com/Azure/Azure-Sentinel/issues) for any samples or resources you would like to see here as you onboard to Microsoft Sentinel. This repository welcomes contributions and refer to this repository&#039;s [wiki](https://aka.ms/threathunters) to get started. For questions and feedback, please contact [AzureSentinel@microsoft.com](AzureSentinel@microsoft.com) 

# Resources
* [Microsoft Sentinel documentation](https://go.microsoft.com/fwlink/?linkid=2073774&amp;clcid=0x409)
* [Microsoft 365 Defender documentation](https://docs.microsoft.com/microsoft-365/security/defender/microsoft-365-defender?view=o365-worldwide)
* [Security Community Webinars](https://aka.ms/securitywebinars)
* [Getting started with GitHub](https://help.github.com/en#dotcom)

We value your feedback. Here are some channels to help surface your questions or feedback:
1. General product specific Q&amp;A for SIEM and SOAR - Join in the [Microsoft Sentinel Tech Community conversations](https://techcommunity.microsoft.com/t5/microsoft-sentinel/bd-p/MicrosoftSentinel)
2. General product specific Q&amp;A for XDR - Join in the [Microsoft 365 Defender Tech Community conversations](https://techcommunity.microsoft.com/t5/microsoft-365-defender/bd-p/MicrosoftThreatProtection)
3. Product specific feature requests - Upvote or post new on [Microsoft Sentinel feedback forums](https://feedback.azure.com/d365community/forum/37638d17-0625-ec11-b6e6-000d3a4f07b8)
4. Report product or contribution bugs - File a GitHub Issue using [Bug template](https://github.com/Azure/Azure-Sentinel/issues/new?assignees=&amp;labels=&amp;template=bug_report.md&amp;title=)
5. General feedback on community and contribution process - File a GitHub Issue using [Feature Request template](https://github.com/Azure/Azure-Sentinel/issues/new?assignees=&amp;labels=&amp;template=feature_request.md&amp;title=)


# Contribution guidelines

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.microsoft.com.

## Add in your new or updated contributions to GitHub
Note: If you are a first time contributor to this repository, [General GitHub Fork the repo guidance](https://docs.github.com/github/getting-started-with-github/fork-a-repo) before cloning or [Specific steps for the Sentinel repo](https://github.com/Azure/Azure-Sentinel/blob/master/GettingStarted.md). 

## General Steps
Brand new or update to a contribution via these methods:
* Submit for review directly on GitHub website 
    * Browse to the folder you want to upload your file to
    * Choose Upload Files and browse to your file. 
    * You will be required to create your own branch and then submit the Pull Request for review.
* Use [GitHub Desktop](https://docs.github.com/en/desktop/overview/getting-started-with-github-desktop) or [Visual Studio](https://visualstudio.microsoft.com/vs/) or [VSCode](https://code.visualstudio.com/?wt.mc_id=DX_841432)
    * [Fork the repo](https://docs.github.com/github/getting-started-with-github/fork-a-repo)  
    * [Clone the repo](https://help.github.com/en/github/creating-cloning-and-archiving-repositories/cloning-a-repository)
    * [Create your own branch](https://help.github.com/en/desktop/contributing-to-projects/creating-a-branch-for-your-work)
    * Do your additions/updates in GitHub Desktop
    * Be sure to merge master back to your branch before you push. 
    * [Push your changes to GitHub](https://help.github.com/en/github/using-git/pushing-commits-to-a-remote-repository)

## Pull Request
* After you push your changes, you will need to submit the [Pull Request (PR)](https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/about-pull-requests)
* Details about the Proposed Changes are required, be sure to include a minimal level of detail so a review can clearly understand the reason for the change and what he change is related to in the code.
* After submission, check the [Pull Request](https://github.com/Azure/Azure-Sentinel/pulls) for comments
* Make changes as suggested and update your branch or explain why no change is needed. Resolve the comment when done.

### Pull Request Detection Template Structure Validation Check
As part of the PR checks we run a structure validation to make sure all required parts of the YAML structure are included.  For Detections, there is a new section that must be included.  See the [contribution guidelines](https://github.com/Azure/Azure-Sentinel/wiki/Contribute-to-Sentinel-GitHub-Community-of-Queries#now-onto-the-how) for more information.  If this section or any other required section is not included, then a validation error will occur similar to the below.
The example is specifically if the YAML is missing the entityMappings section:

```
A total of 1 test files matched the specified pattern.
[xUnit.net 00:00:00.95]     Kqlvalidations.Tests.DetectionTemplateStructureValidationTests.Validate_DetectionTemplates_HaveValidTemplateStructure(detectionsYamlFileName: &quot;ExcessiveBlockedTrafficGeneratedbyUser.yaml&quot;) [FAIL]
  X Kqlvalidations.Tests.DetectionTemplateStructureValidationTests.Validate_DetectionTemplates_HaveValidTemplateStructure(detectionsYamlFileName: &quot;ExcessiveBlockedTrafficGeneratedbyUser.yaml&quot;) [104ms]
  Error Message:
   Expected object to be &lt;null&gt;, but found System.ComponentModel.DataAnnotations.ValidationException with message &quot;An old mapping for entity &#039;AccountCustomEntity&#039; does not have a matching new mapping entry.&quot;
```

### Pull Request KQL Validation Check
As part of the PR checks we run a syntax validation of the KQL queries defined in the template. If this check fails go to Azure Pipeline (by pressing on the errors link on the checks tab in your PR)
![Azurepipeline](.github/Media/Azurepipeline.png)
In the pipeline you can see which test failed and what is the cause:
![Pipeline Tests Tab](.github/Media/PipelineTestsTab.png)

Example error message:
```
A total of 1 test files matched the specified pattern.
[xUnit.net 00:00:01.81]     Kqlvalidations.Tests.KqlValidationTests.Validate_DetectionQueries_HaveValidKql(detectionsYamlFileName: &quot;ExcessiveBlockedTrafficGeneratedbyUser.yaml&quot;) [FAIL]
  X Kqlvalidations.Tests.KqlValidationTests.Validate_DetectionQueries_HaveValidKql(detectionsYamlFileName: &quot;ExcessiveBlockedTrafficGeneratedbyUser.yaml&quot;) [21ms]
  Error Message:
   Template Id:fa0ab69c-7124-4f62-acdd-61017cf6ce89 is not valid Errors:The name &#039;SymantecEndpointProtection&#039; does not refer to any known table, tabular variable or function., Code: &#039;KS204&#039;, Severity: &#039;Error&#039;, Location: &#039;67..93&#039;,The name &#039;SymantecEndpointProtection&#039; does not refer to any known table, tabular variable or function., Code: &#039;KS204&#039;, Severity: &#039;Error&#039;, Location: &#039;289..315&#039;
```
If you are using custom logs table (a table which is not defined on all workspaces by default) you should verify
your table schema is defined in json file in the folder *Azure-Sentinel\\.script\tests\KqlvalidationsTests\CustomTables*

**Example for table tablexyz.json**
```json
{
  &quot;Name&quot;: &quot;tablexyz&quot;,
  &quot;Properties&quot;: [
    {
      &quot;Name&quot;: &quot;SomeDateTimeColumn&quot;,
      &quot;Type&quot;: &quot;DateTime&quot;
    },
    {
      &quot;Name&quot;: &quot;SomeStringColumn&quot;,
      &quot;Type&quot;: &quot;String&quot;
    },
    {
      &quot;Name&quot;: &quot;SomeDynamicColumn&quot;,
      &quot;Type&quot;: &quot;Dynamic&quot;
    }
  ]
}
```
### Run KQL Validation Locally
In order to run the KQL validation before submitting Pull Request in you local machine:
* You need to have **.Net Core 3.1 SDK** installed [How to download .Net](https://dotnet.microsoft.com/download) (Supports all platforms)
* Open Shell and navigate to  `Azure-Sentinel\\.script\tests\KqlvalidationsTests\`
* Execute `dotnet test`

Example of output (in Ubuntu):
```
Welcome to .NET Core 3.1!
---------------------
SDK Version: 3.1.403

Telemetry
---------
The .NET Core tools collect usage data in order to help us improve your experience. The data is anonymous. It is collected by Microsoft and shared with the community. You can opt-out of telemetry by setting the DOTNET_CLI_TELEMETRY_OPTOUT environment variable to &#039;1&#039; or &#039;true&#039; using your favorite shell.

Read more about .NET Core CLI Tools telemetry: https://aka.ms/dotnet-cli-telemetry

----------------
Explore documentation: https://aka.ms/dotnet-docs
Report issues and find source on GitHub: https://github.com/dotnet/core
Find out what&#039;s new: https://aka.ms/dotnet-whats-new
Learn about the installed HTTPS developer cert: https://aka.ms/aspnet-core-https
Use &#039;dotnet --help&#039; to see available commands or visit: https://aka.ms/dotnet-cli-docs
Write your first app: https://aka.ms/first-net-core-app
--------------------------------------------------------------------------------------
Test run for /mnt/c/git/Azure-Sentinel/.script/tests/KqlvalidationsTests/bin/Debug/netcoreapp3.1/Kqlvalidations.Tests.dll(.NETCoreApp,Version=v3.1)
Microsoft (R) Test Execution Command Line Tool Version 16.7.0
Copyright (c) Microsoft Corporation.  All rights reserved.

Starting test execution, please wait...

A total of 1 test files matched the specified pattern.

Test Run Successful.
Total tests: 171
     Passed: 171
 Total time: 25.7973 Seconds
```

### Detection schema validation tests
Similarly to KQL Validation, there is an automatic validation of the schema of a detection.
The schema validation includes the detection&#039;s frequency and period, the detection&#039;s trigger type and threshold, validity of connectors Ids ([valid connectors Ids list](https://github.com/Azure/Azure-Sentinel/blob/master/.script/tests/detectionTemplateSchemaValidation/ValidConnectorIds.json)), etc.
A wrong format or missing attributes will result with an informative check failure, which should guide you through the resolution of the issue, but make sure to look into the format of already approved detection.

### Run Detection Schema Validation Locally
In order to run the KQL validation before submitting Pull Request in you local machine:
* You need to have **.Net Core 3.1 SDK** installed [How to download .Net](https://dotnet.microsoft.com/download) (Supports all platforms)
* Open Shell and navigate to  `Azure-Sentinel\\.script\tests\DetectionTemplateSchemaValidation\`
* Execute `dotnet test`


When you submit a pull request, a CLA-bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

For information on what you can contribute and further details, refer to the [&quot;get started&quot;](https://github.com/Azure/Azure-Sentinel/wiki#get-started) section on the project&#039;s [wiki](https://aka.ms/threathunters).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[mikumifa/cppTickerBuy]]></title>
            <link>https://github.com/mikumifa/cppTickerBuy</link>
            <guid>https://github.com/mikumifa/cppTickerBuy</guid>
            <pubDate>Fri, 16 May 2025 00:04:10 GMT</pubDate>
            <description><![CDATA[cpp cp30 æ¼«å±• æ´»åŠ¨ æŠ¢ç¥¨ æ— å·®åˆ« åŒäººå±•]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mikumifa/cppTickerBuy">mikumifa/cppTickerBuy</a></h1>
            <p>cpp cp30 æ¼«å±• æ´»åŠ¨ æŠ¢ç¥¨ æ— å·®åˆ« åŒäººå±•</p>
            <p>Language: Python</p>
            <p>Stars: 518</p>
            <p>Forks: 54</p>
            <p>Stars today: 49 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/mikumifa/cppTickerBuy&quot; target=&quot;_blank&quot;&gt;
    &lt;img width=&quot;160&quot; src=&quot;icon.ico&quot; alt=&quot;logo&quot;&gt;
  &lt;/a&gt;
  &lt;h1 id=&quot;koishi&quot;&gt;cppTickerBuy&lt;/h1&gt;

![GitHub all releases](https://img.shields.io/github/downloads/mikumifa/cppTickerBuy/total)
![GitHub release (with filter)](https://img.shields.io/github/v/release/mikumifa/cppTickerBuy)
![GitHub issues](https://img.shields.io/github/issues/mikumifa/cppTickerBuy)
![GitHub Repo stars](https://img.shields.io/github/stars/mikumifa/cppTickerBuy)

&lt;/div&gt;

å¼€æºå…è´¹ï¼Œç®€å•æ˜“ç”¨ï¼Œå›¾å½¢ç•Œé¢, é€Ÿåº¦æå¿«çš„CPPæŠ¢ç¥¨è¾…åŠ©å·¥å…·


## å¿«é€Ÿå®‰è£…

Windows ä¸‹è½½æœ€æ–°çš„releaseæ–‡ä»¶ (cppTickerBuy.zip) [ä¸‹è½½é“¾æ¥](https://github.com/mikumifa/cppTickerBuy/releases)
&gt; **NOTE**
&gt;
&gt; å¦‚æœä½ å¯¹Githubä¸€ç‚¹ä¹Ÿä¸äº†è§£, ä¸çŸ¥é“åœ¨å“ªä¸‹è½½
&gt;
&gt; è¿™é‡Œæœ‰ä¸€ä»½å°ç™½æŒ‡å— [ç‚¹æˆ‘å‰å¾€å°ç™½æŒ‡å—](https://github.com/mikumifa/biliTickerBuy/wiki/%E5%B0%8F%E7%99%BD%E4%B8%8B%E8%BD%BD%E6%8C%87%E5%8D%97)

## ä½¿ç”¨è¯´æ˜ä¹¦
é‡æ„äº†UIï¼Œå¯åŠ¨ç»ˆç«¯ç¬¬ä¸€è¡Œä¼šæ˜¾ç¤º

```
Running on local URL:  http://127.0.0.1:xxx
```

è®¿é—®å¯¹åº”çš„ç½‘å€å³å¯

ä½¿ç”¨æºç æ‰‹åŠ¨å¯åŠ¨ `main.py` æ—¶å¯å¸¦æœ‰å¦‚ä¸‹å‚æ•°ï¼š

- `--share` é€‰æ‹©æ˜¯å¦åˆ›å»ºsharelinkï¼Œéœ€ä¼ å…¥å¸ƒå°”å€¼ `True/False` ï¼Œé»˜è®¤ä¸º `False`

è¯´æ˜ä¹¦æš‚æ—¶æ²¡æ—¶é—´å†™ï¼Œç”¨ä»¥å‰çš„é¡¹ç›®ä»£æ›¿ä¸€ä¸‹
[ç‚¹æˆ‘å‰å¾€æ›´åŠ è¯¦ç»†çš„ä½¿ç”¨è¯´æ˜ä¹¦](https://github.com/mikumifa/biliTickerBuy/wiki/%E6%8A%A2%E7%A5%A8%E8%AF%B4%E6%98%8E)


## é¡¹ç›®é—®é¢˜

ç¨‹åºä½¿ç”¨é—®é¢˜ï¼š [ç‚¹æ­¤é“¾æ¥å‰å¾€discussions](https://github.com/mikumifa/cppTickerBuy/discussions)

åé¦ˆç¨‹åºBUGæˆ–è€…ææ–°åŠŸèƒ½å»ºè®®ï¼š [ç‚¹æ­¤é“¾æ¥å‘é¡¹ç›®æå‡ºåé¦ˆBUG](https://github.com/mikumifa/cppTickerBuy/issues/new/choose)

## å…¶ä»–å¯ç”¨è„šæœ¬

| é“¾æ¥                                                      | ä¸»è¦ç‰¹è‰²               |
| --------------------------------------------------------- | ---------------------- |
| https://github.com/Koileo/ticket_for_allcpp | èƒ½åŒæ—¶å¼€å¤šå¼ ç¥¨               |



## é¡¹ç›®è´¡çŒ®è€…

&lt;!-- readme: collaborators,contributors -start --&gt;
&lt;table&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;a href=&quot;https://github.com/mikumifa&quot;&gt;
                    &lt;img src=&quot;https://avatars.githubusercontent.com/u/99951454?v=4&quot; width=&quot;100;&quot; alt=&quot;mikumifa&quot;/&gt;
                    &lt;br /&gt;
                    &lt;sub&gt;&lt;b&gt;mikumifa&lt;/b&gt;&lt;/sub&gt;
                &lt;/a&gt;
            &lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;a href=&quot;https://github.com/WittF&quot;&gt;
                    &lt;img src=&quot;https://avatars.githubusercontent.com/u/108567138?v=4&quot; width=&quot;100;&quot; alt=&quot;WittF&quot;/&gt;
                    &lt;br /&gt;
                    &lt;sub&gt;&lt;b&gt;W1ttF&lt;/b&gt;&lt;/sub&gt;
                &lt;/a&gt;
            &lt;/td&gt;
		&lt;/tr&gt;
	&lt;tbody&gt;
&lt;/table&gt;
&lt;!-- readme: collaborators,contributors -end --&gt;


## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=mikumifa/cppTickerBuy&amp;type=Date)](https://star-history.com/#mikumifa/cppTickerBuy&amp;Date)

## å…è´£å£°æ˜

è¯¦è§[MIT License](./LICENSE)ï¼Œåˆ‡å‹¿è¿›è¡Œç›ˆåˆ©ï¼Œæ‰€é€ æˆçš„åæœä¸æœ¬äººæ— å…³ã€‚

## æèµ 

å¦‚æœä½ æƒ³æ”¯æŒè¿™ä¸ªé¡¹ç›®çš„è¯ [çˆ±å‘ç”µ](https://afdian.com/a/mikumifa)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>