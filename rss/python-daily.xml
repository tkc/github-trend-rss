<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Fri, 03 Oct 2025 00:04:24 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[google/tunix]]></title>
            <link>https://github.com/google/tunix</link>
            <guid>https://github.com/google/tunix</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:24 GMT</pubDate>
            <description><![CDATA[A JAX-native LLM Post-Training Library]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google/tunix">google/tunix</a></h1>
            <p>A JAX-native LLM Post-Training Library</p>
            <p>Language: Python</p>
            <p>Stars: 877</p>
            <p>Forks: 79</p>
            <p>Stars today: 131 stars today</p>
            <h2>README</h2><pre># Tunix: A JAX-native LLM Post-Training Library

&lt;div align=&quot;left&quot;&gt;

&lt;a href=&quot;https://tunix.readthedocs.io/en/latest/index.html&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/documentation-blue&quot;&gt;&lt;/a&gt;

&lt;/div&gt;

**Tunix(Tune-in-JAX)** is a JAX based library designed to streamline the
post-training of Large Language Models. It provides efficient and scalable
supports for:

- **Supervised Fine-Tuning**
- **Reinforcement Learning (RL)**
- **Knowledge Distillation**

Tunix leverages the power of JAX for accelerated computation and seamless
integration with JAX-based modeling framework
[Flax NNX](https://flax.readthedocs.io/en/latest/nnx_basics.html).

**Current Status: Early Development**

Tunix is in early development. We&#039;re actively working to expand its
capabilities, usability and improve its performance. Stay tuned for upcoming
updates and new features!

## Key Features &amp; Highlights

Tunix is still under development, here&#039;s a glimpse of the current features:

- **Supervised Fine-Tuning:**
  - Full Weights Fine-Tuning
  - Parameter-Efficient Fine-Tuning (PEFT) with LoRA/Q-LoRA Layers
- **Reinforcement Learning (RL):**
  - Proximal Policy Optimization (PPO)
  - Group Relative Policy Optimization (GRPO)
  - Token-level Group Sequence Policy Optimization (GSPO-token)
- **Preference Fine-Tuning:**
  - Preference alignments with Direct Preference Optimization (DPO)
- **Knowledge Distillation:**
  - Logit Strategy: A classic approach where the student learns to match the
    teacher&#039;s output probability distribution.
  - Attention Transfer &amp; Projection Strategies: Methods to align the attention
    mechanisms between the student and teacher models.
  - Feature Pooling &amp; Projection Strategies: General techniques for matching
    intermediate feature representations, even between models of different
    architectures.
- **Modularity:**
  - Components are designed to be reusable and composable
  - Easy to customize and extend
- **Efficiency:**
  - Native support of common model sharding strategies such as DP, FSDP and TP
  - Designed for distributed training on accelerators (TPU)

## Upcoming

- **Agentic RL Training:**
  - Async Rollout
  - Multi-turn &amp; multi-step support
  - Tool usage
- **Advanced Algorithms:**
  - Addtional state-of-the-art RL and distillation algorithms
- **Scalability:**
  - Multi-host distributed training
  - Optimized rollout with vLLM
- **User Guides:**
  - More advanced RL recipe

## Installation

You can install Tunix in several ways:

1. From PyPI (recommended):

```sh
pip install &quot;tunix[prod]&quot;
```

2. Directly from GitHub (latest main branch)

```sh
pip install git+https://github.com/google/tunix
```

3. From source (editable install) If you plan to modify the codebase and run it
   in development mode:

```sh
git clone https://github.com/google/tunix.git
cd tunix
pip install -e &quot;.[dev]&quot;

```

## Getting Started

To get started, we have a bunch of detailed examples and tutorials.

- [PEFT Gemma with QLoRA](https://github.com/google/tunix/blob/main/examples/qlora_demo.ipynb)
- [Training Gemma on grade school Math problems using GRPO](https://github.com/google/tunix/blob/main/examples/grpo_demo.ipynb)
- [Logit Distillation using Gemma models](https://github.com/google/tunix/blob/main/examples/logit_distillation.ipynb)

To setup Jupyter notebook on single host GCP TPU VM, please refer to the
[setup script](https://github.com/google/tunix/blob/main/scripts/setup_notebook_tpu_single_host.sh).

We plan to provide clear, concise documentation and more examples in the near
future.

## Contributing and Feedbacks

We welcome contributions! As Tunix is in early development, the contribution
process is still being formalized. A rough draft of the contribution process is
present [here](https://github.com/google/tunix/blob/main/CONTRIBUTING.md). In
the meantime, you can make feature requests, report issues and ask questions in
our
[Tunix GitHub discussion forum](https://github.com/google/tunix/discussions).

## Collaborations and Partnership

[GRL](https://github.com/lmgame-org/GRL/blob/tunix_integration_dev/README.md)
(Game Reinforcement Learning), developed by
[Hao AI Lab](https://hao-ai-lab.github.io/) from UCSD, is an open-source
framework for post-training large language models through multi-turn RL on
challenging games. In collaboration with Tunix, GRL integrates seamless TPU
support—letting users quickly run scalable, reproducible RL experiments (like
PPO rollouts on Qwen2.5-0.5B-Instruct) on TPU v4 meshes with
[minimal setup](https://github.com/lmgame-org/GRL/blob/tunix_integration_dev/README.md#5-launch-the-quick-test-defaults-to-qwen2505b-supports-4-tpu-v4-with-mesh-22).
This partnership empowers the community to push LLM capabilities further,
combining Tunix’s optimized TPU runtime with GRL’s flexible game RL pipeline for
cutting-edge research and easy reproducibility.

## Stay Tuned!

Thank you for your interest in Tunix. We&#039;re working hard to bring you a powerful
and efficient library for LLM post-training. Please follow our progress and
check back for updates!

## Acknowledgements

Thank you to all our wonderful contributors!

[![Contributors](https://contrib.rocks/image?repo=google/tunix)](https://github.com/google/tunix/graphs/contributors)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[pathwaycom/pathway]]></title>
            <link>https://github.com/pathwaycom/pathway</link>
            <guid>https://github.com/pathwaycom/pathway</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:23 GMT</pubDate>
            <description><![CDATA[Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pathwaycom/pathway">pathwaycom/pathway</a></h1>
            <p>Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.</p>
            <p>Language: Python</p>
            <p>Stars: 43,982</p>
            <p>Forks: 1,341</p>
            <p>Stars today: 95 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pathway.com/&quot;&gt;
    &lt;img src=&quot;https://pathway.com/logo-light.svg&quot;/&gt;
  &lt;/a&gt;
  &lt;br /&gt;&lt;br /&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/10388&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/10388&quot; alt=&quot;pathwaycom%2Fpathway | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
  &lt;br /&gt;&lt;br /&gt;
&lt;/div&gt;
&lt;p align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml&quot;&gt;
        &lt;img src=&quot;https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml/badge.svg&quot; alt=&quot;ubuntu&quot;/&gt;
        &lt;br&gt;
        &lt;a href=&quot;https://github.com/pathwaycom/pathway/actions/workflows/release.yml&quot;&gt;
        &lt;img src=&quot;https://github.com/pathwaycom/pathway/actions/workflows/release.yml/badge.svg&quot; alt=&quot;Last release&quot;/&gt;&lt;/a&gt;
        &lt;a href=&quot;https://badge.fury.io/py/pathway&quot;&gt;&lt;img src=&quot;https://badge.fury.io/py/pathway.svg&quot; alt=&quot;PyPI version&quot; height=&quot;18&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://badge.fury.io/py/pathway&quot;&gt;&lt;img src=&quot;https://static.pepy.tech/badge/pathway&quot; alt=&quot;PyPI downloads&quot; height=&quot;18&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://github.com/pathwaycom/pathway/blob/main/LICENSE.txt&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/license-BSL-green&quot; alt=&quot;License: BSL&quot;/&gt;&lt;/a&gt;
      &lt;br&gt;
        &lt;a href=&quot;https://discord.gg/pathway&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1042405378304004156?logo=discord&quot;
            alt=&quot;chat on Discord&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=pathway_com&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/pathwaycom&quot;
            alt=&quot;follow on Twitter&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://linkedin.com/company/pathway&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/pathway-0077B5?style=social&amp;logo=linkedin&quot; alt=&quot;follow on LinkedIn&quot;&gt;&lt;/a&gt;
      &lt;a href=&quot;https://github.com/dylanhogg/awesome-python/blob/main/README.md&quot;&gt;
      &lt;img src=&quot;https://awesome.re/badge.svg&quot; alt=&quot;Awesome Python&quot;&gt;&lt;/a&gt;
      &lt;a href=&quot;https://gurubase.io/g/pathway&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Gurubase-Ask%20Pathway%20Guru-006BFF&quot; alt=&quot;Pathway Guru&quot;&gt;&lt;/a&gt;
    &lt;br&gt;
    &lt;a href=&quot;#getting-started&quot;&gt;Getting Started&lt;/a&gt; |
    &lt;a href=&quot;#deployment&quot;&gt;Deployment&lt;/a&gt; |
    &lt;a href=&quot;#resources&quot;&gt;Documentation and Support&lt;/a&gt; |
    &lt;a href=&quot;https://pathway.com/blog/&quot;&gt;Blog&lt;/a&gt; |
    &lt;a href=&quot;#license&quot;&gt;License&lt;/a&gt;

  
&lt;/p&gt;

# Pathway&lt;a id=&quot;pathway&quot;&gt; Live Data Framework&lt;/a&gt;

[Pathway](https://pathway.com) is a Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.

Pathway comes with an **easy-to-use Python API**, allowing you to seamlessly integrate your favorite Python ML libraries.
Pathway code is versatile and robust: **you can use it in both development and production environments, handling both batch and streaming data effectively**.
The same code can be used for local development, CI/CD tests, running batch jobs, handling stream replays, and processing data streams.

Pathway is powered by a **scalable Rust engine** based on Differential Dataflow and performs incremental computation.
Your Pathway code, despite being written in Python, is run by the Rust engine, enabling multithreading, multiprocessing, and distributed computations.
All the pipeline is kept in memory and can be easily deployed with **Docker and Kubernetes**.

You can install Pathway with pip:
```
pip install -U pathway
```

For any questions, you will find the community and team behind the project [on Discord](https://discord.com/invite/pathway).

## Use-cases and templates

Ready to see what Pathway can do?

[Try one of our easy-to-run examples](https://pathway.com/developers/templates)!

Available in both notebook and docker formats, these ready-to-launch examples can be launched in just a few clicks. Pick one and start your hands-on experience with Pathway today!

### Event processing and real-time analytics pipelines
With its unified engine for batch and streaming and its full Python compatibility, Pathway makes data processing as easy as possible. It&#039;s the ideal solution for a wide range of data processing pipelines, including:

- [Showcase: Real-time ETL.](https://pathway.com/developers/templates/kafka-etl)
- [Showcase: Event-driven pipelines with alerting.](https://pathway.com/developers/templates/realtime-log-monitoring)
- [Showcase: Realtime analytics.](https://pathway.com/developers/templates/linear_regression_with_kafka)
- [Docs: Switch from batch to streaming.](https://pathway.com/developers/user-guide/connecting-to-data/switch-from-batch-to-streaming)



### AI Pipelines

Pathway provides dedicated LLM tooling to build live LLM and RAG pipelines. Wrappers for most common LLM services and utilities are included, making working with LLMs and RAGs pipelines incredibly easy. Check out our [LLM xpack documentation](https://pathway.com/developers/user-guide/llm-xpack/overview).

Don&#039;t hesitate to try one of our runnable examples featuring LLM tooling.
You can find such examples [here](https://pathway.com/developers/user-guide/llm-xpack/llm-examples).

  - [Template: Unstructured data to SQL on-the-fly.](https://pathway.com/developers/templates/unstructured-to-structured)
  - [Template: Private RAG with Ollama and Mistral AI](https://pathway.com/developers/templates/private-rag-ollama-mistral)
  - [Template: Adaptive RAG](https://pathway.com/developers/templates/adaptive-rag)
  - [Template: Multimodal RAG with gpt-4o](https://pathway.com/developers/templates/multimodal-rag)

## Features

- **A wide range of connectors**: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector.
- **Stateless and stateful transformations**: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data.
- **Persistence**: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!
- **Consistency**: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the &quot;at least once&quot; consistency while the enterprise version provides the &quot;exactly once&quot; consistency.
- **Scalable Rust engine**: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can easily do multithreading, multiprocessing, and distributed computations.
- **LLM helpers**: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents.


## Getting started&lt;a id=&quot;getting-started&quot;&gt;&lt;/a&gt;

### Installation&lt;a id=&quot;installation&quot;&gt;&lt;/a&gt;

Pathway requires Python 3.10 or above.

You can install the current release of Pathway using `pip`:

```
$ pip install -U pathway
```

⚠️ Pathway is available on MacOS and Linux. Users of other systems should run Pathway on a Virtual Machine.


### Example: computing the sum of positive values in real time.&lt;a id=&quot;example&quot;&gt;&lt;/a&gt;

```python
import pathway as pw

# Define the schema of your data (Optional)
class InputSchema(pw.Schema):
  value: int

# Connect to your data using connectors
input_table = pw.io.csv.read(
  &quot;./input/&quot;,
  schema=InputSchema
)

#Define your operations on the data
filtered_table = input_table.filter(input_table.value&gt;=0)
result_table = filtered_table.reduce(
  sum_value = pw.reducers.sum(filtered_table.value)
)

# Load your results to external systems
pw.io.jsonlines.write(result_table, &quot;output.jsonl&quot;)

# Run the computation
pw.run()
```

Run Pathway [in Google Colab](https://colab.research.google.com/drive/1aBIJ2HCng-YEUOMrr0qtj0NeZMEyRz55?usp=sharing).

You can find more examples [here](https://github.com/pathwaycom/pathway/tree/main/examples).


## Deployment&lt;a id=&quot;deployment&quot;&gt;&lt;/a&gt;

### Locally&lt;a id=&quot;running-pathway-locally&quot;&gt;&lt;/a&gt;

To use Pathway, you only need to import it:

```python
import pathway as pw
```

Now, you can easily create your processing pipeline, and let Pathway handle the updates. Once your pipeline is created, you can launch the computation on streaming data with a one-line command:

```python
pw.run()
```

You can then run your Pathway project (say, `main.py`) just like a normal Python script: `$ python main.py`.
Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages. 

&lt;img src=&quot;https://d14l3brkh44201.cloudfront.net/pathway-dashboard.png&quot; width=&quot;1326&quot; alt=&quot;Pathway dashboard&quot;/&gt;

Alternatively, you can use the pathway&#039;ish version:

```
$ pathway spawn python main.py
```

Pathway natively supports multithreading.
To launch your application with 3 threads, you can do as follows:
```
$ pathway spawn --threads 3 python main.py
```

To jumpstart a Pathway project, you can use our [cookiecutter template](https://github.com/pathwaycom/cookiecutter-pathway).


### Docker&lt;a id=&quot;docker&quot;&gt;&lt;/a&gt;

You can easily run Pathway using docker.

#### Pathway image

You can use the [Pathway docker image](https://hub.docker.com/r/pathwaycom/pathway), using a Dockerfile:

```dockerfile
FROM pathwaycom/pathway:latest

WORKDIR /app

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD [ &quot;python&quot;, &quot;./your-script.py&quot; ]
```

You can then build and run the Docker image:

```console
docker build -t my-pathway-app .
docker run -it --rm --name my-pathway-app my-pathway-app
```

#### Run a single Python script

When dealing with single-file projects, creating a full-fledged `Dockerfile`
might seem unnecessary. In such scenarios, you can execute a
Python script directly using the Pathway Docker image. For example:

```console
docker run -it --rm --name my-pathway-app -v &quot;$PWD&quot;:/app pathwaycom/pathway:latest python my-pathway-app.py
```

#### Python docker image

You can also use a standard Python image and install Pathway using pip with a Dockerfile:

```dockerfile
FROM --platform=linux/x86_64 python:3.10

RUN pip install -U pathway
COPY ./pathway-script.py pathway-script.py

CMD [&quot;python&quot;, &quot;-u&quot;, &quot;pathway-script.py&quot;]
```

### Kubernetes and cloud&lt;a id=&quot;k8s&quot;&gt;&lt;/a&gt;

Docker containers are ideally suited for deployment on the cloud with Kubernetes.
If you want to scale your Pathway application, you may be interested in our Pathway for Enterprise.
Pathway for Enterprise is specially tailored towards end-to-end data processing and real time intelligent analytics.
It scales using distributed computing on the cloud and supports distributed Kubernetes deployment, with external persistence setup.

You can easily deploy Pathway using services like Render: see [how to deploy Pathway in a few clicks](https://pathway.com/developers/user-guide/deployment/render-deploy/).

If you are interested, don&#039;t hesitate to [contact us](mailto:contact@pathway.com) to learn more.

## Performance&lt;a id=&quot;performance&quot;&gt;&lt;/a&gt;

Pathway is made to outperform state-of-the-art technologies designed for streaming and batch data processing tasks, including: Flink, Spark, and Kafka Streaming. It also makes it possible to implement a lot of algorithms/UDF&#039;s in streaming mode which are not readily supported by other streaming frameworks (especially: temporal joins, iterative graph algorithms, machine learning routines).

If you are curious, here are [some benchmarks to play with](https://github.com/pathwaycom/pathway-benchmarks).

&lt;img src=&quot;https://github.com/pathwaycom/pathway-benchmarks/raw/main/images/bm-wordcount-lineplot.png&quot; width=&quot;1326&quot; alt=&quot;WordCount Graph&quot;/&gt;

## Documentation and Support&lt;a id=&quot;resources&quot;&gt;&lt;/a&gt;

The entire documentation of Pathway is available at [pathway.com/developers/](https://pathway.com/developers/user-guide/introduction/welcome), including the [API Docs](https://pathway.com/developers/api-docs/pathway).

If you have any question, don&#039;t hesitate to [open an issue on GitHub](https://github.com/pathwaycom/pathway/issues), join us on [Discord](https://discord.com/invite/pathway), or send us an email at [contact@pathway.com](mailto:contact@pathway.com).

## License&lt;a id=&quot;license&quot;&gt;&lt;/a&gt;

Pathway is distributed on a [BSL 1.1 License](https://github.com/pathwaycom/pathway/blob/main/LICENSE.txt) which allows for unlimited non-commercial use, as well as use of the Pathway package [for most commercial purposes](https://pathway.com/license/), free of charge. Code in this repository automatically converts to Open Source (Apache 2.0 License) after 4 years. Some [public repos](https://github.com/pathwaycom) which are complementary to this one (examples, libraries, connectors, etc.) are licensed as Open Source, under the MIT license.


## Contribution guidelines&lt;a id=&quot;contribution-guidelines&quot;&gt;&lt;/a&gt;

If you develop a library or connector which you would like to integrate with this repo, we suggest releasing it first as a separate repo on a MIT/Apache 2.0 license. 

For all concerns regarding core Pathway functionalities, Issues are encouraged. For further information, don&#039;t hesitate to engage with Pathway&#039;s [Discord community](https://discord.gg/pathway).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[anthropics/claude-agent-sdk-python]]></title>
            <link>https://github.com/anthropics/claude-agent-sdk-python</link>
            <guid>https://github.com/anthropics/claude-agent-sdk-python</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:22 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/anthropics/claude-agent-sdk-python">anthropics/claude-agent-sdk-python</a></h1>
            <p></p>
            <p>Language: Python</p>
            <p>Stars: 1,979</p>
            <p>Forks: 251</p>
            <p>Stars today: 267 stars today</p>
            <h2>README</h2><pre># Claude Agent SDK for Python

Python SDK for Claude Agent. See the [Claude Agent SDK documentation](https://docs.anthropic.com/en/docs/claude-code/sdk/sdk-python) for more information.

## Installation

```bash
pip install claude-agent-sdk
```

**Prerequisites:**
- Python 3.10+
- Node.js
- Claude Code: `npm install -g @anthropic-ai/claude-code`

## Quick Start

```python
import anyio
from claude_agent_sdk import query

async def main():
    async for message in query(prompt=&quot;What is 2 + 2?&quot;):
        print(message)

anyio.run(main)
```

## Basic Usage: query()

`query()` is an async function for querying Claude Code. It returns an `AsyncIterator` of response messages. See [src/claude_agent_sdk/query.py](src/claude_agent_sdk/query.py).

```python
from claude_agent_sdk import query, ClaudeAgentOptions, AssistantMessage, TextBlock

# Simple query
async for message in query(prompt=&quot;Hello Claude&quot;):
    if isinstance(message, AssistantMessage):
        for block in message.content:
            if isinstance(block, TextBlock):
                print(block.text)

# With options
options = ClaudeAgentOptions(
    system_prompt=&quot;You are a helpful assistant&quot;,
    max_turns=1
)

async for message in query(prompt=&quot;Tell me a joke&quot;, options=options):
    print(message)
```

### Using Tools

```python
options = ClaudeAgentOptions(
    allowed_tools=[&quot;Read&quot;, &quot;Write&quot;, &quot;Bash&quot;],
    permission_mode=&#039;acceptEdits&#039;  # auto-accept file edits
)

async for message in query(
    prompt=&quot;Create a hello.py file&quot;,
    options=options
):
    # Process tool use and results
    pass
```

### Working Directory

```python
from pathlib import Path

options = ClaudeAgentOptions(
    cwd=&quot;/path/to/project&quot;  # or Path(&quot;/path/to/project&quot;)
)
```

## ClaudeSDKClient

`ClaudeSDKClient` supports bidirectional, interactive conversations with Claude
Code. See [src/claude_agent_sdk/client.py](src/claude_agent_sdk/client.py).

Unlike `query()`, `ClaudeSDKClient` additionally enables **custom tools** and **hooks**, both of which can be defined as Python functions.

### Custom Tools (as In-Process SDK MCP Servers)

A **custom tool** is a Python function that you can offer to Claude, for Claude to invoke as needed.

Custom tools are implemented in-process MCP servers that run directly within your Python application, eliminating the need for separate processes that regular MCP servers require.

For an end-to-end example, see [MCP Calculator](examples/mcp_calculator.py).

#### Creating a Simple Tool

```python
from claude_agent_sdk import tool, create_sdk_mcp_server, ClaudeAgentOptions, ClaudeSDKClient

# Define a tool using the @tool decorator
@tool(&quot;greet&quot;, &quot;Greet a user&quot;, {&quot;name&quot;: str})
async def greet_user(args):
    return {
        &quot;content&quot;: [
            {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: f&quot;Hello, {args[&#039;name&#039;]}!&quot;}
        ]
    }

# Create an SDK MCP server
server = create_sdk_mcp_server(
    name=&quot;my-tools&quot;,
    version=&quot;1.0.0&quot;,
    tools=[greet_user]
)

# Use it with Claude
options = ClaudeAgentOptions(
    mcp_servers={&quot;tools&quot;: server},
    allowed_tools=[&quot;mcp__tools__greet&quot;]
)

async with ClaudeSDKClient(options=options) as client:
    await client.query(&quot;Greet Alice&quot;)

    # Extract and print response
    async for msg in client.receive_response():
        print(msg)
```

#### Benefits Over External MCP Servers

- **No subprocess management** - Runs in the same process as your application
- **Better performance** - No IPC overhead for tool calls
- **Simpler deployment** - Single Python process instead of multiple
- **Easier debugging** - All code runs in the same process
- **Type safety** - Direct Python function calls with type hints

#### Migration from External Servers

```python
# BEFORE: External MCP server (separate process)
options = ClaudeAgentOptions(
    mcp_servers={
        &quot;calculator&quot;: {
            &quot;type&quot;: &quot;stdio&quot;,
            &quot;command&quot;: &quot;python&quot;,
            &quot;args&quot;: [&quot;-m&quot;, &quot;calculator_server&quot;]
        }
    }
)

# AFTER: SDK MCP server (in-process)
from my_tools import add, subtract  # Your tool functions

calculator = create_sdk_mcp_server(
    name=&quot;calculator&quot;,
    tools=[add, subtract]
)

options = ClaudeAgentOptions(
    mcp_servers={&quot;calculator&quot;: calculator}
)
```

#### Mixed Server Support

You can use both SDK and external MCP servers together:

```python
options = ClaudeAgentOptions(
    mcp_servers={
        &quot;internal&quot;: sdk_server,      # In-process SDK server
        &quot;external&quot;: {                # External subprocess server
            &quot;type&quot;: &quot;stdio&quot;,
            &quot;command&quot;: &quot;external-server&quot;
        }
    }
)
```

### Hooks

A **hook** is a Python function that the Claude Code *application* (*not* Claude) invokes at specific points of the Claude agent loop. Hooks can provide deterministic processing and automated feedback for Claude. Read more in [Claude Code Hooks Reference](https://docs.anthropic.com/en/docs/claude-code/hooks).

For more examples, see examples/hooks.py.

#### Example

```python
from claude_agent_sdk import ClaudeAgentOptions, ClaudeSDKClient, HookMatcher

async def check_bash_command(input_data, tool_use_id, context):
    tool_name = input_data[&quot;tool_name&quot;]
    tool_input = input_data[&quot;tool_input&quot;]
    if tool_name != &quot;Bash&quot;:
        return {}
    command = tool_input.get(&quot;command&quot;, &quot;&quot;)
    block_patterns = [&quot;foo.sh&quot;]
    for pattern in block_patterns:
        if pattern in command:
            return {
                &quot;hookSpecificOutput&quot;: {
                    &quot;hookEventName&quot;: &quot;PreToolUse&quot;,
                    &quot;permissionDecision&quot;: &quot;deny&quot;,
                    &quot;permissionDecisionReason&quot;: f&quot;Command contains invalid pattern: {pattern}&quot;,
                }
            }
    return {}

options = ClaudeAgentOptions(
    allowed_tools=[&quot;Bash&quot;],
    hooks={
        &quot;PreToolUse&quot;: [
            HookMatcher(matcher=&quot;Bash&quot;, hooks=[check_bash_command]),
        ],
    }
)

async with ClaudeSDKClient(options=options) as client:
    # Test 1: Command with forbidden pattern (will be blocked)
    await client.query(&quot;Run the bash command: ./foo.sh --help&quot;)
    async for msg in client.receive_response():
        print(msg)

    print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)

    # Test 2: Safe command that should work
    await client.query(&quot;Run the bash command: echo &#039;Hello from hooks example!&#039;&quot;)
    async for msg in client.receive_response():
        print(msg)
```


## Types

See [src/claude_agent_sdk/types.py](src/claude_agent_sdk/types.py) for complete type definitions:
- `ClaudeAgentOptions` - Configuration options
- `AssistantMessage`, `UserMessage`, `SystemMessage`, `ResultMessage` - Message types
- `TextBlock`, `ToolUseBlock`, `ToolResultBlock` - Content blocks

## Error Handling

```python
from claude_agent_sdk import (
    ClaudeSDKError,      # Base error
    CLINotFoundError,    # Claude Code not installed
    CLIConnectionError,  # Connection issues
    ProcessError,        # Process failed
    CLIJSONDecodeError,  # JSON parsing issues
)

try:
    async for message in query(prompt=&quot;Hello&quot;):
        pass
except CLINotFoundError:
    print(&quot;Please install Claude Code&quot;)
except ProcessError as e:
    print(f&quot;Process failed with exit code: {e.exit_code}&quot;)
except CLIJSONDecodeError as e:
    print(f&quot;Failed to parse response: {e}&quot;)
```

See [src/claude_agent_sdk/_errors.py](src/claude_agent_sdk/_errors.py) for all error types.

## Available Tools

See the [Claude Code documentation](https://docs.anthropic.com/en/docs/claude-code/settings#tools-available-to-claude) for a complete list of available tools.

## Examples

See [examples/quick_start.py](examples/quick_start.py) for a complete working example.

See [examples/streaming_mode.py](examples/streaming_mode.py) for comprehensive examples involving `ClaudeSDKClient`. You can even run interactive examples in IPython from [examples/streaming_mode_ipython.py](examples/streaming_mode_ipython.py).

## Migrating from Claude Code SDK

If you&#039;re upgrading from the Claude Code SDK (versions &lt; 0.1.0), please see the [CHANGELOG.md](CHANGELOG.md#010) for details on breaking changes and new features, including:

- `ClaudeCodeOptions` → `ClaudeAgentOptions` rename
- Merged system prompt configuration
- Settings isolation and explicit control
- New programmatic subagents and session forking features

## License

MIT
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Lightricks/LTX-Video]]></title>
            <link>https://github.com/Lightricks/LTX-Video</link>
            <guid>https://github.com/Lightricks/LTX-Video</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:21 GMT</pubDate>
            <description><![CDATA[Official repository for LTX-Video]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Lightricks/LTX-Video">Lightricks/LTX-Video</a></h1>
            <p>Official repository for LTX-Video</p>
            <p>Language: Python</p>
            <p>Stars: 8,191</p>
            <p>Forks: 731</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# LTX-Video

[![Website](https://img.shields.io/badge/Website-LTXV-181717?logo=google-chrome)](https://www.lightricks.com/ltxv)
[![Model](https://img.shields.io/badge/HuggingFace-Model-orange?logo=huggingface)](https://huggingface.co/Lightricks/LTX-Video)
[![Demo](https://img.shields.io/badge/Demo-Try%20Now-brightgreen?logo=vercel)](https://app.ltx.studio/motion-workspace?videoModel=ltxv-13b)
[![Paper](https://img.shields.io/badge/Paper-arXiv-B31B1B?logo=arxiv)](https://arxiv.org/abs/2501.00103)
[![Trainer](https://img.shields.io/badge/LTXV-Trainer-9146FF?logo=github)](https://github.com/Lightricks/LTX-Video-Trainer)
[![Discord](https://img.shields.io/badge/Join-Discord-5865F2?logo=discord)](https://discord.gg/Mn8BRgUKKy)

This is the official repository for LTX-Video.

&lt;/div&gt;

## Table of Contents

- [Introduction](#introduction)
- [What&#039;s new](#news)
- [Models](#models)
- [Quick Start Guide](#quick-start-guide)
  - [Online demo](#online-inference)
  - [Run locally](#run-locally)
    - [Installation](#installation)
    - [Inference](#inference)
  - [ComfyUI Integration](#comfyui-integration)
  - [Diffusers Integration](#diffusers-integration)
- [Model User Guide](#model-user-guide)
- [Community Contribution](#community-contribution)
- [Training](#training)
- [Control Models](#control-models)
- [Join Us!](#join-us-)
- [Acknowledgement](#acknowledgement)

# Introduction

LTX-Video is the first DiT-based video generation model that can generate high-quality videos in *real-time*.
It can generate 30 FPS videos at 1216×704 resolution, faster than it takes to watch them.
The model is trained on a large-scale dataset of diverse videos and can generate high-resolution videos
with realistic and diverse content.

The model supports image-to-video, keyframe-based animation, video extension (both forward and backward), video-to-video transformations, and any combination of these features.

### Image-to-video examples
| | | |
|:---:|:---:|:---:|
| ![example1](./docs/_static/ltx-video_i2v_example_00001.gif) | ![example2](./docs/_static/ltx-video_i2v_example_00002.gif) | ![example3](./docs/_static/ltx-video_i2v_example_00003.gif) |
| ![example4](./docs/_static/ltx-video_i2v_example_00004.gif) | ![example5](./docs/_static/ltx-video_i2v_example_00005.gif) |  ![example6](./docs/_static/ltx-video_i2v_example_00006.gif) |
| ![example7](./docs/_static/ltx-video_i2v_example_00007.gif) |  ![example8](./docs/_static/ltx-video_i2v_example_00008.gif) | ![example9](./docs/_static/ltx-video_i2v_example_00009.gif) |

### Controlled video examples
| | | |
|:---:|:---:|:---:|
| ![control0](./docs/_static/ltx-video_ic_2v_example_00000.gif) | ![control1](./docs/_static/ltx-video_ic_2v_example_00001.gif) | ![control2](./docs/_static/ltx-video_ic_2v_example_00002.gif) |

| | |
|:---:|:---:|
| ![control3](./docs/_static/ltx-video_ic_2v_example_00003.gif) | ![control4](./docs/_static/ltx-video_ic_2v_example_00004.gif) |

# News

## July, 16th, 2025: New Distilled models v0.9.8 with up to 60 seconds of video:
- Long shot generation in LTXV-13B!
  * LTX-Video now supports up to 60 seconds of video.
  * Compatible also with the official IC-LoRAs.
  * Try now in [ComfyUI](https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example_workflows/ltxv-13b-i2v-long-multi-prompt.json).
- Release a new distilled models:
  * 13B distilled model [ltxv-13b-0.9.8-distilled](https://github.com/Lightricks/LTX-Video/blob/main/configs/ltxv-13b-0.9.8-distilled.yaml)
  * 2B distilled model [ltxv-2b-0.9.8-distilled](https://github.com/Lightricks/LTX-Video/blob/main/configs/ltxv-2b-0.9.8-distilled.yaml)
  * Both models are distilled from the same base model [ltxv-13b-0.9.8-dev](https://github.com/Lightricks/LTX-Video/blob/main/configs/ltxv-13b-0.9.8-dev.yaml) and are compatible for use together in the same multiscale pipeline.
  * Improved prompt understanding and detail generation
  * Includes corresponding FP8 weights and workflows.
- Release a new detailer model [LTX-Video-ICLoRA-detailer-13B-0.9.8](https://huggingface.co/Lightricks/LTX-Video-ICLoRA-detailer-13b-0.9.8)
  * Available in [ComfyUI](https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example_workflows/ltxv-13b-upscale.json).

## July, 8th, 2025: New Control Models Released!
- Released three new control models for LTX-Video on HuggingFace:
    * **Depth Control**: [LTX-Video-ICLoRA-depth-13b-0.9.7](https://huggingface.co/Lightricks/LTX-Video-ICLoRA-depth-13b-0.9.7)
    * **Pose Control**: [LTX-Video-ICLoRA-pose-13b-0.9.7](https://huggingface.co/Lightricks/LTX-Video-ICLoRA-pose-13b-0.9.7)
    * **Canny Control**: [LTX-Video-ICLoRA-canny-13b-0.9.7](https://huggingface.co/Lightricks/LTX-Video-ICLoRA-canny-13b-0.9.7)


## May, 14th, 2025: New distilled model 13B v0.9.7:
- Release a new 13B distilled model [ltxv-13b-0.9.7-distilled](https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-13b-0.9.7-distilled.safetensors)
    * Amazing for iterative work - generates HD videos in 10 seconds, with low-res preview after just 3 seconds (on H100)!
    * Does not require classifier-free guidance and spatio-temporal guidance.
    * Supports sampling with 8 (recommended), or less diffusion steps.
    * Also released a LoRA version of the distilled model, [ltxv-13b-0.9.7-distilled-lora128](https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-13b-0.9.7-distilled-lora128.safetensors)
        * Requires only 1GB of VRAM
        * Can be used with the full 13B model for fast inference
- Release a new quantized distilled model [ltxv-13b-0.9.7-distilled-fp8](https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-13b-0.9.7-distilled-fp8.safetensors) for *real-time* generation (on H100) with even less VRAM

## May, 5th, 2025: New model 13B v0.9.7:
- Release a new 13B model [ltxv-13b-0.9.7-dev](https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-13b-0.9.7-dev.safetensors)
- Release a new quantized model [ltxv-13b-0.9.7-dev-fp8](https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-13b-0.9.7-dev-fp8.safetensors) for faster inference with less VRam
- Release a new upscalers
  * [ltxv-temporal-upscaler-0.9.7](https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-temporal-upscaler-0.9.7.safetensors)
  * [ltxv-spatial-upscaler-0.9.7](https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-spatial-upscaler-0.9.7.safetensors)
- Breakthrough prompt adherence and physical understanding.
- New Pipeline for multi-scale video rendering for fast and high quality results


## April, 15th, 2025: New checkpoints v0.9.6:
- Release a new checkpoint [ltxv-2b-0.9.6-dev-04-25](https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-2b-0.9.6-dev-04-25.safetensors) with improved quality
- Release a new distilled model [ltxv-2b-0.9.6-distilled-04-25](https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-2b-0.9.6-distilled-04-25.safetensors)
    * 15x faster inference than non-distilled model.
    * Does not require classifier-free guidance and spatio-temporal guidance.
    * Supports sampling with 8 (recommended), or less diffusion steps.
- Improved prompt adherence, motion quality and fine details.
- New default resolution and FPS: 1216 × 704 pixels at 30 FPS
    * Still real time on H100 with the distilled model.
    * Other resolutions and FPS are still supported.
- Support stochastic inference (can improve visual quality when using the distilled model)

## March, 5th, 2025: New checkpoint v0.9.5
- New license for commercial use ([OpenRail-M](https://huggingface.co/Lightricks/LTX-Video/ltx-video-2b-v0.9.5.license.txt))
- Release a new checkpoint v0.9.5 with improved quality
- Support keyframes and video extension
- Support higher resolutions
- Improved prompt understanding
- Improved VAE
- New online web app in [LTX-Studio](https://app.ltx.studio/ltx-video)
- Automatic prompt enhancement

## February, 20th, 2025: More inference options
- Improve STG (Spatiotemporal Guidance) for LTX-Video
- Support MPS on macOS with PyTorch 2.3.0
- Add support for 8-bit model, LTX-VideoQ8
- Add TeaCache for LTX-Video
- Add [ComfyUI-LTXTricks](#comfyui-integration)
- Add Diffusion-Pipe

## December 31st, 2024: Research paper
- Release the [research paper](https://arxiv.org/abs/2501.00103)

## December 20th, 2024: New checkpoint v0.9.1
- Release a new checkpoint v0.9.1 with improved quality
- Support for STG / PAG
- Support loading checkpoints of LTX-Video in Diffusers format (conversion is done on-the-fly)
- Support offloading unused parts to CPU
- Support the new timestep-conditioned VAE decoder
- Reference contributions from the community in the readme file
- Relax transformers dependency

## November 21th, 2024: Initial release v0.9.0
- Initial release of LTX-Video
- Support text-to-video and image-to-video generation


# Models &amp; Workflows

| Name                    | Notes                                                                                      | inference.py config                                                                                                                                      | ComfyUI workflow (Recommended) |
|-------------------------|--------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------|
| ltxv-13b-0.9.8-dev                   | Highest quality, requires more VRAM                                                        | [ltxv-13b-0.9.8-dev.yaml](https://github.com/Lightricks/LTX-Video/blob/main/configs/ltxv-13b-0.9.8-dev.yaml)                                             | [ltxv-13b-i2v-base.json](https://github.com/Lightricks/ComfyUI-LTXVideo/blob/master/example_workflows/ltxv-13b-i2v-base.json)             |
| [ltxv-13b-0.9.8-mix](https://app.ltx.studio/motion-workspace?videoModel=ltxv-13b)            | Mix ltxv-13b-dev and ltxv-13b-distilled in the same multi-scale rendering workflow for balanced speed-quality | N/A                                             | [ltxv-13b-i2v-mixed-multiscale.json](https://github.com/Lightricks/ComfyUI-LTXVideo/blob/master/example_workflows/ltxv-13b-i2v-mixed-multiscale.json)             |
 [ltxv-13b-0.9.8-distilled](https://app.ltx.studio/motion-workspace?videoModel=ltxv)        | Faster, less VRAM usage, slight quality reduction compared to 13b. Ideal for rapid iterations | [ltxv-13b-0.9.8-distilled.yaml](https://github.com/Lightricks/LTX-Video/blob/main/configs/ltxv-13b-0.9.8-distilled.yaml)                                    | [ltxv-13b-dist-i2v-base.json](https://github.com/Lightricks/ComfyUI-LTXVideo/blob/master/example_workflows/13b-distilled/ltxv-13b-dist-i2v-base.json) |
ltxv-2b-0.9.8-distilled        | Smaller model, slight quality reduction compared to 13b distilled. Ideal for fast generation with light VRAM usage | [ltxv-2b-0.9.8-distilled.yaml](https://github.com/Lightricks/LTX-Video/blob/main/configs/ltxv-2b-0.9.8-distilled.yaml)                                    | N/A |
| ltxv-13b-0.9.8-dev-fp8               | Quantized version of ltxv-13b | [ltxv-13b-0.9.8-dev-fp8.yaml](https://github.com/Lightricks/LTX-Video/blob/main/configs/ltxv-13b-0.9.8-dev-fp8.yaml) | [ltxv-13b-i2v-base-fp8.json](https://github.com/Lightricks/ComfyUI-LTXVideo/blob/master/example_workflows/ltxv-13b-i2v-base-fp8.json) |
| ltxv-13b-0.9.8-distilled-fp8     | Quantized version of ltxv-13b-distilled | [ltxv-13b-0.9.8-distilled-fp8.yaml](https://github.com/Lightricks/LTX-Video/blob/main/configs/ltxv-13b-0.9.8-distilled-fp8.yaml) | [ltxv-13b-dist-i2v-base-fp8.json](https://github.com/Lightricks/ComfyUI-LTXVideo/blob/master/example_workflows/13b-distilled/ltxv-13b-dist-i2v-base-fp8.json) |
| ltxv-2b-0.9.8-distilled-fp8     | Quantized version of ltxv-2b-distilled | [ltxv-2b-0.9.8-distilled-fp8.yaml](https://github.com/Lightricks/LTX-Video/blob/main/configs/ltxv-2b-0.9.8-distilled-fp8.yaml) | N/A |
| ltxv-2b-0.9.6                     | Good quality, lower VRAM requirement than ltxv-13b                                         | [ltxv-2b-0.9.6-dev.yaml](https://github.com/Lightricks/LTX-Video/blob/main/configs/ltxv-2b-0.9.6-dev.yaml)                                                 | [ltxvideo-i2v.json](https://github.com/Lightricks/ComfyUI-LTXVideo/blob/master/example_workflows/low_level/ltxvideo-i2v.json)             |
| ltxv-2b-0.9.6-distilled         | 15× faster, real-time capable, fewer steps needed, no STG/CFG required                     | [ltxv-2b-0.9.6-distilled.yaml](https://github.com/Lightricks/LTX-Video/blob/main/configs/ltxv-2b-0.9.6-distilled.yaml)                                     | [ltxvideo-i2v-distilled.json](https://github.com/Lightricks/ComfyUI-LTXVideo/blob/master/example_workflows/low_level/ltxvideo-i2v-distilled.json)             |


# Quick Start Guide

## Online inference
The model is accessible right away via the following links:
- [LTX-Studio image-to-video (13B-mix)](https://app.ltx.studio/motion-workspace?videoModel=ltxv-13b)
- [LTX-Studio image-to-video (13B distilled)](https://app.ltx.studio/motion-workspace?videoModel=ltxv)
- [Fal.ai image-to-video (13B full)](https://fal.ai/models/fal-ai/ltx-video-13b-dev/image-to-video)
- [Fal.ai image-to-video (13B distilled)](https://fal.ai/models/fal-ai/ltx-video-13b-distilled/image-to-video)
- [Replicate image-to-video](https://replicate.com/lightricks/ltx-video)

## Run locally

### Installation
The codebase was tested with Python 3.10.5, CUDA version 12.2, and supports PyTorch &gt;= 2.1.2.
On macOS, MPS was tested with PyTorch 2.3.0, and should support PyTorch == 2.3 or &gt;= 2.6.

```bash
git clone https://github.com/Lightricks/LTX-Video.git
cd LTX-Video

# create env
python -m venv env
source env/bin/activate
python -m pip install -e .\[inference\]
```

#### FP8 Kernels (optional)

[FP8 kernels](https://github.com/Lightricks/LTXVideo-Q8-Kernels) developed for LTX-Video provide performance boost on supported graphics cards (Ada architecture and later). To install FP8 kernels, follow the instructions in that repository.

### Inference

📝 **Note:** For best results, we recommend using our [ComfyUI](#comfyui-integration) workflow. We&#039;re working on updating the inference.py script to match the high quality and output fidelity of ComfyUI.

To use our model, please follow the inference code in [inference.py](./inference.py):

#### For image-to-video generation:

```bash
python inference.py --prompt &quot;PROMPT&quot; --conditioning_media_paths IMAGE_PATH --conditioning_start_frames 0 --height HEIGHT --width WIDTH --num_frames NUM_FRAMES --seed SEED --pipeline_config configs/ltxv-13b-0.9.8-distilled.yaml
```

#### Extending a video:

📝 **Note:** Input video segments must contain a multiple of 8 frames plus 1 (e.g., 9, 17, 25, etc.), and the target frame number should be a multiple of 8.


```bash
python inference.py --prompt &quot;PROMPT&quot; --conditioning_media_paths VIDEO_PATH --conditioning_start_frames START_FRAME --height HEIGHT --width WIDTH --num_frames NUM_FRAMES --seed SEED --pipeline_config configs/ltxv-13b-0.9.8-distilled.yaml
```

#### For video generation with multiple conditions:

You can now generate a video conditioned on a set of images and/or short video segments.
Simply provide a list of paths to the images or video segments you want to condition on, along with their target frame numbers in the generated video. You can also specify the conditioning strength for each item (default: 1.0).

```bash
python inference.py --prompt &quot;PROMPT&quot; --conditioning_media_paths IMAGE_OR_VIDEO_PATH_1 IMAGE_OR_VIDEO_PATH_2 --conditioning_start_frames TARGET_FRAME_1 TARGET_FRAME_2 --height HEIGHT --width WIDTH --num_frames NUM_FRAMES --seed SEED --pipeline_config configs/ltxv-13b-0.9.8-distilled.yaml
```

### Using as a library

```python
from ltx_video.inference import infer, InferenceConfig

infer(
    InferenceConfig(
        pipeline_config=&quot;configs/ltxv-13b-0.9.8-distilled.yaml&quot;,
        prompt=PROMPT,
        height=HEIGHT,
        width=WIDTH,
        num_frames=NUM_FRAMES,
        output_path=&quot;output.mp4&quot;,
    )
)
```

## ComfyUI Integration
To use our model with ComfyUI, please follow the instructions at [https://github.com/Lightricks/ComfyUI-LTXVideo/](https://github.com/Lightricks/ComfyUI-LTXVideo/).

## Diffusers Integration
To use our model with the Diffusers Python library, check out the [official documentation](https://huggingface.co/docs/diffusers/main/en/api/pipelines/ltx_video).

Diffusers also support an 8-bit version of LTX-Video, [see details below](#ltx-videoq8)

# Model User Guide

## 📝 Prompt Engineering

When writing prompts, focus on detailed, chronological descriptions of actions and scenes. Include specific movements, appearances, camera angles, and environmental details - all in a single flowing paragraph. Start directly with the action, and keep descriptions literal and precise. Think like a cinematographer describing a shot list. Keep within 200 words. For best results, build your prompts using this structure:

* Start with main action in a single sentence
* Add specific details about movements and gestures
* Describe character/object appearances precisely
* Include background and environment details
* Specify camera angles and movements
* Describe lighting and colors
* Note any changes or sudden events
* See [examples](#introduction) for more inspiration.

### Automatic Prompt Enhancement

When using `LTXVideoPipeline` directly, you can enable prompt enhancement by setting `enhance_prompt=True`.

## 🎮 Parameter Guide

* Resolution Preset: Higher resolutions for detailed scenes, lower for faster generation and simpler scenes. The model works on resolutions that are divisible by 32 and number of frames that are divisible by 8 + 1 (e.g. 257). In case the resolution or number of frames are not divisible by 32 or 8 + 1, the input will be padded with -1 and then cropped to the desired resolution and number of frames. The model works best on resolutions under 720 x 1280 and number of frames below 257
* Seed: Save seed values to recreate specific styles or compositions you like
* Guidance Scale: 3-3.5 are the recommended values
* Inference Steps: More steps (40+) for quality, fewer steps (20-30) for speed

📝 For advanced parameters usage, please see `python inference.py --help`

## Community Contribution

### ComfyUI-LTXTricks 🛠️

A community project providing additional nodes for enhanced control over the LTX Video model. It includes implementations of advanced techniques like RF-Inversion, RF-Edit, FlowEdit, and more. These nodes enable workflows such as Image and Video to Video (I+V2V), enhanced sampling via Spatiotemporal Skip Guidance (STG), and interpolation with precise frame settings.

- **Repository:** [ComfyUI-LTXTricks](https://github.com/logtd/ComfyUI-LTXTricks)
- **Features:**
  - 🔄 **RF-Inversion:** Implements [RF-Inversion](https://rf-inversion.github.io/) with an [example workflow here](https://github.com/logtd/ComfyUI-LTXTricks/blob/main/example_workflows/example_ltx_inversion.json).
  - ✂️ **RF-Edit:** Implements [RF-Solver-Edit](https://github.com/wangjiangshan0725/RF-Solver-Edit) with an [example workflow here](https://github.com/logtd/ComfyUI-LTXTricks/blob/main/example_workflows/example_ltx_rf_edit.json).
  - 🌊 **FlowEdit:** Implements [FlowEdit](https://github.com/fallenshock/FlowEdit) with an [example workflow here](https://github.com/logtd/ComfyUI-LTXTricks/blob/main/example_workflows/example_ltx_flow_edit.json).
  - 🎥 **I+V2V:** Enables Video to Video with a reference image. [Example workflow](https://github.com/logtd/ComfyUI-LTXTricks/blob/main/example_workflows/example_ltx_iv2v.json).
  - ✨ **Enhance:** Partial implementation of [STGuidance](https://junhahyung.github.io/STGuidance/). [Example workflow](https://github.com/logtd/ComfyUI-LTXTricks/blob/main/example_workflows/example_ltxv_stg.json).
  - 🖼️ **Interpolation

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[harry0703/MoneyPrinterTurbo]]></title>
            <link>https://github.com/harry0703/MoneyPrinterTurbo</link>
            <guid>https://github.com/harry0703/MoneyPrinterTurbo</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:20 GMT</pubDate>
            <description><![CDATA[利用AI大模型，一键生成高清短视频 Generate short videos with one click using AI LLM.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/harry0703/MoneyPrinterTurbo">harry0703/MoneyPrinterTurbo</a></h1>
            <p>利用AI大模型，一键生成高清短视频 Generate short videos with one click using AI LLM.</p>
            <p>Language: Python</p>
            <p>Stars: 45,474</p>
            <p>Forks: 6,357</p>
            <p>Stars today: 1,178 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;h1 align=&quot;center&quot;&gt;MoneyPrinterTurbo 💸&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&quot; alt=&quot;Stargazers&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&quot; alt=&quot;Issues&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/network/members&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/forks/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&quot; alt=&quot;Forks&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3&gt;简体中文 | &lt;a href=&quot;README-en.md&quot;&gt;English&lt;/a&gt;&lt;/h3&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/8731&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/8731&quot; alt=&quot;harry0703%2FMoneyPrinterTurbo | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;br&gt;
只需提供一个视频 &lt;b&gt;主题&lt;/b&gt; 或 &lt;b&gt;关键词&lt;/b&gt; ，就可以全自动生成视频文案、视频素材、视频字幕、视频背景音乐，然后合成一个高清的短视频。
&lt;br&gt;

&lt;h4&gt;Web界面&lt;/h4&gt;

![](docs/webui.jpg)

&lt;h4&gt;API界面&lt;/h4&gt;

![](docs/api.jpg)

&lt;/div&gt;

## 特别感谢 🙏

由于该项目的 **部署** 和 **使用**，对于一些小白用户来说，还是 **有一定的门槛**，在此特别感谢
**录咖（AI智能 多媒体服务平台）** 网站基于该项目，提供的免费`AI视频生成器`服务，可以不用部署，直接在线使用，非常方便。

- 中文版：https://reccloud.cn
- 英文版：https://reccloud.com

![](docs/reccloud.cn.jpg)

## 感谢赞助 🙏

感谢佐糖 https://picwish.cn 对该项目的支持和赞助，使得该项目能够持续的更新和维护。

佐糖专注于**图像处理领域**，提供丰富的**图像处理工具**，将复杂操作极致简化，真正实现让图像处理更简单。

![picwish.jpg](docs/picwish.jpg)

## 功能特性 🎯

- [x] 完整的 **MVC架构**，代码 **结构清晰**，易于维护，支持 `API` 和 `Web界面`
- [x] 支持视频文案 **AI自动生成**，也可以**自定义文案**
- [x] 支持多种 **高清视频** 尺寸
    - [x] 竖屏 9:16，`1080x1920`
    - [x] 横屏 16:9，`1920x1080`
- [x] 支持 **批量视频生成**，可以一次生成多个视频，然后选择一个最满意的
- [x] 支持 **视频片段时长** 设置，方便调节素材切换频率
- [x] 支持 **中文** 和 **英文** 视频文案
- [x] 支持 **多种语音** 合成，可 **实时试听** 效果
- [x] 支持 **字幕生成**，可以调整 `字体`、`位置`、`颜色`、`大小`，同时支持`字幕描边`设置
- [x] 支持 **背景音乐**，随机或者指定音乐文件，可设置`背景音乐音量`
- [x] 视频素材来源 **高清**，而且 **无版权**，也可以使用自己的 **本地素材**
- [x] 支持 **OpenAI**、**Moonshot**、**Azure**、**gpt4free**、**one-api**、**通义千问**、**Google Gemini**、**Ollama**、**DeepSeek**、 **文心一言**, **Pollinations** 等多种模型接入
    - 中国用户建议使用 **DeepSeek** 或 **Moonshot** 作为大模型提供商（国内可直接访问，不需要VPN。注册就送额度，基本够用）


### 后期计划 📅

- [ ] GPT-SoVITS 配音支持
- [ ] 优化语音合成，利用大模型，使其合成的声音，更加自然，情绪更加丰富
- [ ] 增加视频转场效果，使其看起来更加的流畅
- [ ] 增加更多视频素材来源，优化视频素材和文案的匹配度
- [ ] 增加视频长度选项：短、中、长
- [ ] 支持更多的语音合成服务商，比如 OpenAI TTS
- [ ] 自动上传到YouTube平台

## 视频演示 📺

### 竖屏 9:16

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;&lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;▶️&lt;/g-emoji&gt; 《如何增加生活的乐趣》&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;▶️&lt;/g-emoji&gt; 《金钱的作用》&lt;br&gt;更真实的合成声音&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;▶️&lt;/g-emoji&gt; 《生命的意义是什么》&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/a84d33d5-27a2-4aba-8fd0-9fb2bd91c6a6&quot;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/af2f3b0b-002e-49fe-b161-18ba91c055e8&quot;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/112c9564-d52b-4472-99ad-970b75f66476&quot;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

### 横屏 16:9

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;&lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;▶️&lt;/g-emoji&gt;《生命的意义是什么》&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;▶️&lt;/g-emoji&gt;《为什么要运动》&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/346ebb15-c55f-47a9-a653-114f08bb8073&quot;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/271f2fae-8283-44a0-8aa0-0ed8f9a6fa87&quot;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

## 配置要求 📦

- 建议最低 CPU **4核** 或以上，内存 **4G** 或以上，显卡非必须
- Windows 10 或 MacOS 11.0 以上系统


## 快速开始 🚀

### 在 Google Colab 中运行
免去本地环境配置，点击直接在 Google Colab 中快速体验 MoneyPrinterTurbo

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harry0703/MoneyPrinterTurbo/blob/main/docs/MoneyPrinterTurbo.ipynb)


### Windows一键启动包

下载一键启动包，解压直接使用（路径不要有 **中文**、**特殊字符**、**空格**）

- 百度网盘（v1.2.6）: https://pan.baidu.com/s/1wg0UaIyXpO3SqIpaq790SQ?pwd=sbqx 提取码: sbqx
- Google Drive (v1.2.6): https://drive.google.com/file/d/1HsbzfT7XunkrCrHw5ncUjFX8XX4zAuUh/view?usp=sharing

下载后，建议先**双击执行** `update.bat` 更新到**最新代码**，然后双击 `start.bat` 启动

启动后，会自动打开浏览器（如果打开是空白，建议换成 **Chrome** 或者 **Edge** 打开）

## 安装部署 📥

### 前提条件

- 尽量不要使用 **中文路径**，避免出现一些无法预料的问题
- 请确保你的 **网络** 是正常的，VPN需要打开`全局流量`模式

#### ① 克隆代码

```shell
git clone https://github.com/harry0703/MoneyPrinterTurbo.git
```

#### ② 修改配置文件（可选，建议启动后也可以在 WebUI 里面配置）

- 将 `config.example.toml` 文件复制一份，命名为 `config.toml`
- 按照 `config.toml` 文件中的说明，配置好 `pexels_api_keys` 和 `llm_provider`，并根据 llm_provider 对应的服务商，配置相关的
  API Key

### Docker部署 🐳

#### ① 启动Docker

如果未安装 Docker，请先安装 https://www.docker.com/products/docker-desktop/

如果是Windows系统，请参考微软的文档：

1. https://learn.microsoft.com/zh-cn/windows/wsl/install
2. https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers

```shell
cd MoneyPrinterTurbo
docker-compose up
```

&gt; 注意：最新版的docker安装时会自动以插件的形式安装docker compose，启动命令调整为docker compose up

#### ② 访问Web界面

打开浏览器，访问 http://0.0.0.0:8501

#### ③ 访问API文档

打开浏览器，访问 http://0.0.0.0:8080/docs 或者 http://0.0.0.0:8080/redoc

### 手动部署 📦

&gt; 视频教程

- 完整的使用演示：https://v.douyin.com/iFhnwsKY/
- 如何在Windows上部署：https://v.douyin.com/iFyjoW3M

#### ① 创建虚拟环境

建议使用 [conda](https://conda.io/projects/conda/en/latest/user-guide/install/index.html) 创建 python 虚拟环境

```shell
git clone https://github.com/harry0703/MoneyPrinterTurbo.git
cd MoneyPrinterTurbo
conda create -n MoneyPrinterTurbo python=3.11
conda activate MoneyPrinterTurbo
pip install -r requirements.txt
```

#### ② 安装好 ImageMagick

- Windows:
    - 下载 https://imagemagick.org/script/download.php 选择Windows版本，切记一定要选择 **静态库** 版本，比如
      ImageMagick-7.1.1-32-Q16-x64-**static**.exe
    - 安装下载好的 ImageMagick，**注意不要修改安装路径**
    - 修改 `配置文件 config.toml` 中的 `imagemagick_path` 为你的 **实际安装路径**

- MacOS:
  ```shell
  brew install imagemagick
  ````
- Ubuntu
  ```shell
  sudo apt-get install imagemagick
  ```
- CentOS
  ```shell
  sudo yum install ImageMagick
  ```

#### ③ 启动Web界面 🌐

注意需要到 MoneyPrinterTurbo 项目 `根目录` 下执行以下命令

###### Windows

```bat
webui.bat
```

###### MacOS or Linux

```shell
sh webui.sh
```

启动后，会自动打开浏览器（如果打开是空白，建议换成 **Chrome** 或者 **Edge** 打开）

#### ④ 启动API服务 🚀

```shell
python main.py
```

启动后，可以查看 `API文档` http://127.0.0.1:8080/docs 或者 http://127.0.0.1:8080/redoc 直接在线调试接口，快速体验。

## 语音合成 🗣

所有支持的声音列表，可以查看：[声音列表](./docs/voice-list.txt)

2024-04-16 v1.1.2 新增了9种Azure的语音合成声音，需要配置API KEY，该声音合成的更加真实。

## 字幕生成 📜

当前支持2种字幕生成方式：

- **edge**: 生成`速度快`，性能更好，对电脑配置没有要求，但是质量可能不稳定
- **whisper**: 生成`速度慢`，性能较差，对电脑配置有一定要求，但是`质量更可靠`。

可以修改 `config.toml` 配置文件中的 `subtitle_provider` 进行切换

建议使用 `edge` 模式，如果生成的字幕质量不好，再切换到 `whisper` 模式

&gt; 注意：

1. whisper 模式下需要到 HuggingFace 下载一个模型文件，大约 3GB 左右，请确保网络通畅
2. 如果留空，表示不生成字幕。

&gt; 由于国内无法访问 HuggingFace，可以使用以下方法下载 `whisper-large-v3` 的模型文件

下载地址：

- 百度网盘: https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9
- 夸克网盘：https://pan.quark.cn/s/3ee3d991d64b

模型下载后解压，整个目录放到 `.\MoneyPrinterTurbo\models` 里面，
最终的文件路径应该是这样: `.\MoneyPrinterTurbo\models\whisper-large-v3`

```
MoneyPrinterTurbo  
  ├─models
  │   └─whisper-large-v3
  │          config.json
  │          model.bin
  │          preprocessor_config.json
  │          tokenizer.json
  │          vocabulary.json
```

## 背景音乐 🎵

用于视频的背景音乐，位于项目的 `resource/songs` 目录下。
&gt; 当前项目里面放了一些默认的音乐，来自于 YouTube 视频，如有侵权，请删除。

## 字幕字体 🅰

用于视频字幕的渲染，位于项目的 `resource/fonts` 目录下，你也可以放进去自己的字体。

## 常见问题 🤔

### ❓RuntimeError: No ffmpeg exe could be found

通常情况下，ffmpeg 会被自动下载，并且会被自动检测到。
但是如果你的环境有问题，无法自动下载，可能会遇到如下错误：

```
RuntimeError: No ffmpeg exe could be found.
Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.
```

此时你可以从 https://www.gyan.dev/ffmpeg/builds/ 下载ffmpeg，解压后，设置 `ffmpeg_path` 为你的实际安装路径即可。

```toml
[app]
# 请根据你的实际路径设置，注意 Windows 路径分隔符为 \\
ffmpeg_path = &quot;C:\\Users\\harry\\Downloads\\ffmpeg.exe&quot;
```

### ❓ImageMagick的安全策略阻止了与临时文件@/tmp/tmpur5hyyto.txt相关的操作

可以在ImageMagick的配置文件policy.xml中找到这些策略。
这个文件通常位于 /etc/ImageMagick-`X`/ 或 ImageMagick 安装目录的类似位置。
修改包含`pattern=&quot;@&quot;`的条目，将`rights=&quot;none&quot;`更改为`rights=&quot;read|write&quot;`以允许对文件的读写操作。

### ❓OSError: [Errno 24] Too many open files

这个问题是由于系统打开文件数限制导致的，可以通过修改系统的文件打开数限制来解决。

查看当前限制

```shell
ulimit -n
```

如果过低，可以调高一些，比如

```shell
ulimit -n 10240
```

### ❓Whisper 模型下载失败，出现如下错误

LocalEntryNotfoundEror: Cannot find an appropriate cached snapshotfolderfor the specified revision on the local disk and
outgoing trafic has been disabled.
To enablerepo look-ups and downloads online, pass &#039;local files only=False&#039; as input.

或者

An error occured while synchronizing the model Systran/faster-whisper-large-v3 from the Hugging Face Hub:
An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the
specified revision on the local disk. Please check your internet connection and try again.
Trying to load the model directly from the local cache, if it exists.

解决方法：[点击查看如何从网盘手动下载模型](#%E5%AD%97%E5%B9%95%E7%94%9F%E6%88%90-)

## 反馈建议 📢

- 可以提交 [issue](https://github.com/harry0703/MoneyPrinterTurbo/issues)
  或者 [pull request](https://github.com/harry0703/MoneyPrinterTurbo/pulls)。

## 许可证 📝

点击查看 [`LICENSE`](LICENSE) 文件

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=harry0703/MoneyPrinterTurbo&amp;type=Date)](https://star-history.com/#harry0703/MoneyPrinterTurbo&amp;Date)</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[hsliuping/TradingAgents-CN]]></title>
            <link>https://github.com/hsliuping/TradingAgents-CN</link>
            <guid>https://github.com/hsliuping/TradingAgents-CN</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:19 GMT</pubDate>
            <description><![CDATA[基于多智能体LLM的中文金融交易框架 - TradingAgents中文增强版]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hsliuping/TradingAgents-CN">hsliuping/TradingAgents-CN</a></h1>
            <p>基于多智能体LLM的中文金融交易框架 - TradingAgents中文增强版</p>
            <p>Language: Python</p>
            <p>Stars: 7,776</p>
            <p>Forks: 1,893</p>
            <p>Stars today: 258 stars today</p>
            <h2>README</h2><pre># TradingAgents 中文增强版

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/)
[![Version](https://img.shields.io/badge/Version-cn--0.1.15-green.svg)](./VERSION)
[![Documentation](https://img.shields.io/badge/docs-中文文档-green.svg)](./docs/)
[![Original](https://img.shields.io/badge/基于-TauricResearch/TradingAgents-orange.svg)](https://github.com/TauricResearch/TradingAgents)

&gt; 🚀 **最新版本 cn-0.1.15**: 开发者体验与LLM生态系统大升级！新增千帆大模型支持、完整开发工具链、学术研究资料、企业级工作流规范！
&gt;
&gt; 🎯 **核心功能**: 原生OpenAI支持 | Google AI全面集成 | 自定义端点配置 | 智能模型选择 | 多LLM提供商支持 | 模型选择持久化 | Docker容器化部署 | 专业报告导出 | 完整A股支持 | 中文本地化

基于多智能体大语言模型的**中文金融交易决策框架**。专为中文用户优化，提供完整的A股/港股/美股分析能力。

## 🙏 致敬源项目

感谢 [Tauric Research](https://github.com/TauricResearch) 团队创造的革命性多智能体交易框架 [TradingAgents](https://github.com/TauricResearch/TradingAgents)！

**🎯 我们的使命**: 为中国用户提供完整的中文化体验，支持A股/港股市场，集成国产大模型，推动AI金融技术在中文社区的普及应用。

## 🆕 v0.1.15 重大更新

### 🤖 LLM生态系统大升级

- **千帆大模型支持**: 新增百度千帆(ERNIE)大模型完整集成
- **LLM适配器重构**: 统一的OpenAI兼容适配器架构
- **多厂商支持**: 支持更多国产大模型提供商
- **集成指南**: 完整的LLM集成开发文档和测试工具

### 📚 学术研究支持

- **TradingAgents论文**: 完整的中文翻译版本和深度解读
- **技术博客**: 详细的技术分析和实现原理解读
- **学术资料**: PDF论文和相关研究资料
- **引用支持**: 标准的学术引用格式和参考文献

### 🛠️ 开发者体验升级

- **开发工作流**: 标准化的开发流程和分支管理规范
- **安装验证**: 完整的安装测试和验证脚本
- **文档重构**: 结构化的文档系统和快速开始指南
- **PR模板**: 标准化的Pull Request模板和代码审查流程

### 🔧 企业级工具链

- **分支保护**: GitHub分支保护策略和安全规则
- **紧急程序**: 完整的紧急处理和故障恢复程序
- **测试框架**: 增强的测试覆盖和验证工具
- **部署指南**: 企业级部署和配置管理

## 📋 v0.1.14 功能回顾

### 👥 用户权限管理系统

- **完整用户管理**: 新增用户注册、登录、权限控制功能
- **角色权限**: 支持多级用户角色和权限管理
- **会话管理**: 安全的用户会话和状态管理
- **用户活动日志**: 完整的用户操作记录和审计功能

### 🔐 Web用户认证系统

- **登录组件**: 现代化的用户登录界面
- **认证管理器**: 统一的用户认证和授权管理
- **安全增强**: 密码加密、会话安全等安全机制
- **用户仪表板**: 个性化的用户活动仪表板

### 🗄️ 数据管理优化

- **MongoDB集成增强**: 改进的MongoDB连接和数据管理
- **数据目录重组**: 优化的数据存储结构和管理
- **数据迁移脚本**: 完整的数据迁移和备份工具
- **缓存优化**: 提升数据加载和分析结果缓存性能

### 🧪 测试覆盖增强

- **功能测试脚本**: 新增6个专项功能测试脚本
- **工具处理器测试**: Google工具处理器修复验证
- **引导自动隐藏测试**: UI交互功能测试
- **在线工具配置测试**: 工具配置和选择逻辑测试
- **真实场景测试**: 实际使用场景的端到端测试
- **美股独立性测试**: 美股分析功能独立性验证

---

## 🆕 v0.1.13 重大更新

### 🤖 原生OpenAI端点支持

- **自定义OpenAI端点**: 支持配置任意OpenAI兼容的API端点
- **灵活模型选择**: 可以使用任何OpenAI格式的模型，不限于官方模型
- **智能适配器**: 新增原生OpenAI适配器，提供更好的兼容性和性能
- **配置管理**: 统一的端点和模型配置管理系统

### 🧠 Google AI生态系统全面集成

- **三大Google AI包支持**: langchain-google-genai、google-generativeai、google-genai
- **9个验证模型**: gemini-2.5-pro, gemini-2.5-flash, gemini-2.0-flash等最新模型
- **Google工具处理器**: 专门的Google AI工具调用处理器
- **智能降级机制**: 高级功能失败时自动降级到基础功能

### 🔧 LLM适配器架构优化

- **GoogleOpenAIAdapter**: 新增Google AI的OpenAI兼容适配器
- **统一接口**: 所有LLM提供商使用统一的调用接口
- **错误处理增强**: 改进的异常处理和自动重试机制
- **性能监控**: 添加LLM调用性能监控和统计

### 🎨 Web界面智能优化

- **智能模型选择**: 根据可用性自动选择最佳模型
- **KeyError修复**: 彻底解决模型选择中的KeyError问题
- **UI响应优化**: 改进模型切换的响应速度和用户体验
- **错误提示**: 更友好的错误提示和解决建议

## 🆕 v0.1.12 重大更新

### 🧠 智能新闻分析模块

- **智能新闻过滤器**: 基于AI的新闻相关性评分和质量评估
- **多层次过滤机制**: 基础过滤、增强过滤、集成过滤三级处理
- **新闻质量评估**: 自动识别和过滤低质量、重复、无关新闻
- **统一新闻工具**: 整合多个新闻源，提供统一的新闻获取接口

### 🔧 技术修复和优化

- **DashScope适配器修复**: 解决工具调用兼容性问题
- **DeepSeek死循环修复**: 修复新闻分析师的无限循环问题
- **LLM工具调用增强**: 提升工具调用的可靠性和稳定性
- **新闻检索器优化**: 增强新闻数据获取和处理能力

### 📚 完善测试和文档

- **全面测试覆盖**: 新增15+个测试文件，覆盖所有新功能
- **详细技术文档**: 新增8个技术分析报告和修复文档
- **用户指南完善**: 新增新闻过滤使用指南和最佳实践
- **演示脚本**: 提供完整的新闻过滤功能演示

### 🗂️ 项目结构优化

- **文档分类整理**: 按功能将文档分类到docs子目录
- **示例代码归位**: 演示脚本统一到examples目录
- **根目录整洁**: 保持根目录简洁，提升项目专业度

## 🎯 核心特性

### 🤖 多智能体协作架构

- **专业分工**: 基本面、技术面、新闻面、社交媒体四大分析师
- **结构化辩论**: 看涨/看跌研究员进行深度分析
- **智能决策**: 交易员基于所有输入做出最终投资建议
- **风险管理**: 多层次风险评估和管理机制

## 🖥️ Web界面展示

### 📸 界面截图

&gt; 🎨 **现代化Web界面**: 基于Streamlit构建的响应式Web应用，提供直观的股票分析体验

#### 🏠 主界面 - 分析配置

![1755003162925](images/README/1755003162925.png)

![1755002619976](images/README/1755002619976.png)

*智能配置面板，支持多市场股票分析，5级研究深度选择*

#### 📊 实时分析进度

![1755002731483](images/README/1755002731483.png)

*实时进度跟踪，可视化分析过程，智能时间预估*

#### 📈 分析结果展示

![1755002901204](images/README/1755002901204.png)

![1755002924844](images/README/1755002924844.png)

![1755002939905](images/README/1755002939905.png)

![1755002968608](images/README/1755002968608.png)

![1755002985903](images/README/1755002985903.png)

![1755003004403](images/README/1755003004403.png)

![1755003019759](images/README/1755003019759.png)

![1755003033939](images/README/1755003033939.png)

![1755003048242](images/README/1755003048242.png)

![1755003064598](images/README/1755003064598.png)

![1755003090603](images/README/1755003090603.png)

*专业投资报告，多维度分析结果，一键导出功能*

### 🎯 核心功能特色

#### 📋 **智能分析配置**

- **🌍 多市场支持**: 美股、A股、港股一站式分析
- **🎯 5级研究深度**: 从2分钟快速分析到25分钟全面研究
- **🤖 智能体选择**: 市场技术、基本面、新闻、社交媒体分析师
- **📅 灵活时间设置**: 支持历史任意时间点分析

#### 🚀 **实时进度跟踪**

- **📊 可视化进度**: 实时显示分析进展和剩余时间
- **🔄 智能步骤识别**: 自动识别当前分析阶段
- **⏱️ 准确时间预估**: 基于历史数据的智能时间计算
- **💾 状态持久化**: 页面刷新不丢失分析进度

#### 📈 **专业结果展示**

- **🎯 投资决策**: 明确的买入/持有/卖出建议
- **📊 多维分析**: 技术面、基本面、新闻面综合评估
- **🔢 量化指标**: 置信度、风险评分、目标价位
- **📄 专业报告**: 支持Markdown/Word/PDF格式导出

#### 🤖 **多LLM模型管理**

- **🌐 4大提供商**: DashScope、DeepSeek、Google AI、OpenRouter
- **🎯 60+模型选择**: 从经济型到旗舰级模型全覆盖
- **💾 配置持久化**: URL参数存储，刷新保持设置
- **⚡ 快速切换**: 5个热门模型一键选择按钮

### 🎮 Web界面操作指南

#### 🚀 **快速开始流程**

1. **启动应用**: `python start_web.py` 或 `docker-compose up -d`
2. **访问界面**: 浏览器打开 `http://localhost:8501`
3. **配置模型**: 侧边栏选择LLM提供商和模型
4. **输入股票**: 输入股票代码（如 AAPL、000001、0700.HK）
5. **选择深度**: 根据需求选择1-5级研究深度
6. **开始分析**: 点击&quot;🚀 开始分析&quot;按钮
7. **查看结果**: 实时跟踪进度，查看分析报告
8. **导出报告**: 一键导出专业格式报告

#### 📊 **支持的股票代码格式**

- **🇺🇸 美股**: `AAPL`, `TSLA`, `MSFT`, `NVDA`, `GOOGL`
- **🇨🇳 A股**: `000001`, `600519`, `300750`, `002415`
- **🇭🇰 港股**: `0700.HK`, `9988.HK`, `3690.HK`, `1810.HK`

#### 🎯 **研究深度说明**

- **1级 (2-4分钟)**: 快速概览，基础技术指标
- **2级 (4-6分钟)**: 标准分析，技术+基本面
- **3级 (6-10分钟)**: 深度分析，加入新闻情绪 ⭐ **推荐**
- **4级 (10-15分钟)**: 全面分析，多轮智能体辩论
- **5级 (15-25分钟)**: 最深度分析，完整研究报告

#### 💡 **使用技巧**

- **🔄 实时刷新**: 分析过程中可随时刷新页面，进度不丢失
- **📱 移动适配**: 支持手机和平板设备访问
- **🎨 深色模式**: 自动适配系统主题设置
- **⌨️ 快捷键**: 支持Enter键快速提交分析
- **📋 历史记录**: 自动保存最近的分析配置

&gt; 📖 **详细指南**: 完整的Web界面使用说明请参考 [🖥️ Web界面详细使用指南](docs/usage/web-interface-detailed-guide.md)

## 🎯 功能特性

### 🚀  智能新闻分析✨ **v0.1.12重大升级**


| 功能特性               | 状态        | 详细说明                                 |
| ---------------------- | ----------- | ---------------------------------------- |
| **🧠 智能新闻分析**    | 🆕 v0.1.12  | AI新闻过滤，质量评估，相关性分析         |
| **🔧 新闻过滤器**      | 🆕 v0.1.12  | 多层次过滤，基础/增强/集成三级处理       |
| **📰 统一新闻工具**    | 🆕 v0.1.12  | 整合多源新闻，统一接口，智能检索         |
| **🤖 多LLM提供商**     | 🆕 v0.1.11  | 4大提供商，60+模型，智能分类管理         |
| **💾 模型选择持久化**  | 🆕 v0.1.11  | URL参数存储，刷新保持，配置分享          |
| **🎯 快速选择按钮**    | 🆕 v0.1.11  | 一键切换热门模型，提升操作效率           |
| **📊 实时进度显示**    | ✅ v0.1.10  | 异步进度跟踪，智能步骤识别，准确时间计算 |
| **💾 智能会话管理**    | ✅ v0.1.10  | 状态持久化，自动降级，跨页面恢复         |
| **🎯 一键查看报告**    | ✅ v0.1.10  | 分析完成后一键查看，智能结果恢复         |
| **🖥️ Streamlit界面** | ✅ 完整支持 | 现代化响应式界面，实时交互和数据可视化   |
| **⚙️ 配置管理**      | ✅ 完整支持 | Web端API密钥管理，模型选择，参数配置     |

### 🎨 CLI用户体验 ✨ **v0.1.9优化**


| 功能特性                | 状态        | 详细说明                             |
| ----------------------- | ----------- | ------------------------------------ |
| **🖥️ 界面与日志分离** | ✅ 完整支持 | 用户界面清爽美观，技术日志独立管理   |
| **🔄 智能进度显示**     | ✅ 完整支持 | 多阶段进度跟踪，防止重复提示         |
| **⏱️ 时间预估功能**   | ✅ 完整支持 | 智能分析阶段显示预计耗时             |
| **🌈 Rich彩色输出**     | ✅ 完整支持 | 彩色进度指示，状态图标，视觉效果提升 |

### 🧠 LLM模型支持 ✨ **v0.1.13全面升级**


| 模型提供商        | 支持模型                     | 特色功能                | 新增功能 |
| ----------------- | ---------------------------- | ----------------------- | -------- |
| **🇨🇳 阿里百炼** | qwen-turbo/plus/max          | 中文优化，成本效益高    | ✅ 集成  |
| **🇨🇳 DeepSeek** | deepseek-chat                | 工具调用，性价比极高    | ✅ 集成  |
| **🌍 Google AI**  | **9个验证模型**              | 最新Gemini 2.5系列      | 🆕 升级  |
| ├─**最新旗舰**  | gemini-2.5-pro/flash         | 最新旗舰，超快响应      | 🆕 新增  |
| ├─**稳定推荐**  | gemini-2.0-flash             | 推荐使用，平衡性能      | 🆕 新增  |
| ├─**经典强大**  | gemini-1.5-pro/flash         | 经典稳定，高质量分析    | ✅ 集成  |
| └─**轻量快速**  | gemini-2.5-flash-lite        | 轻量级任务，快速响应    | 🆕 新增  |
| **🌐 原生OpenAI** | **自定义端点支持**           | 任意OpenAI兼容端点      | 🆕 新增  |
| **🌐 OpenRouter** | **60+模型聚合平台**          | 一个API访问所有主流模型 | ✅ 集成  |
| ├─**OpenAI**    | o4-mini-high, o3-pro, GPT-4o | 最新o系列，推理专业版   | ✅ 集成  |
| ├─**Anthropic** | Claude 4 Opus/Sonnet/Haiku   | 顶级性能，平衡版本      | ✅ 集成  |
| ├─**Meta**      | Llama 4 Maverick/Scout       | 最新Llama 4系列         | ✅ 集成  |
| └─**自定义**    | 任意OpenRouter模型ID         | 无限扩展，个性化选择    | ✅ 集成  |

**🎯 快速选择**: 5个热门模型快速按钮 | **💾 持久化**: URL参数存储，刷新保持 | **🔄 智能切换**: 一键切换不同提供商

### 📊 数据源与市场


| 市场类型      | 数据源                   | 覆盖范围                     |
| ------------- | ------------------------ | ---------------------------- |
| **🇨🇳 A股**  | Tushare, AkShare, 通达信 | 沪深两市，实时行情，财报数据 |
| **🇭🇰 港股** | AkShare, Yahoo Finance   | 港交所，实时行情，基本面     |
| **🇺🇸 美股** | FinnHub, Yahoo Finance   | NYSE, NASDAQ，实时数据       |
| **📰 新闻**   | Google News              | 实时新闻，多语言支持         |

### 🤖 智能体团队

**分析师团队**: 📈市场分析 | 💰基本面分析 | 📰新闻分析 | 💬情绪分析
**研究团队**: 🐂看涨研究员 | 🐻看跌研究员 | 🎯交易决策员
**管理层**: 🛡️风险管理员 | 👔研究主管

## 🚀 快速开始

### 🐳 Docker部署 (推荐)

```bash
# 1. 克隆项目
git clone https://github.com/hsliuping/TradingAgents-CN.git
cd TradingAgents-CN

# 2. 配置环境变量
cp .env.example .env
# 编辑 .env 文件，填入API密钥

# 3. 启动服务
# 首次启动或代码变更时（需要构建镜像）
docker-compose up -d --build

# 日常启动（镜像已存在，无代码变更）
docker-compose up -d

# 智能启动（自动判断是否需要构建）
# Windows环境
powershell -ExecutionPolicy Bypass -File scripts\smart_start.ps1

# Linux/Mac环境
chmod +x scripts/smart_start.sh &amp;&amp; ./scripts/smart_start.sh

# 4. 访问应用
# Web界面: http://localhost:8501
```

### 💻 本地部署

```bash
# 1. 升级pip (重要！避免安装错误)
python -m pip install --upgrade pip

# 2. 安装依赖
pip install -e .

# 3. 启动应用
python start_web.py

# 4. 访问 http://localhost:8501
```

### 📊 开始分析

1. **选择模型**: DeepSeek V3 / 通义千问 / Gemini
2. **输入股票**: `000001` (A股) / `AAPL` (美股) / `0700.HK` (港股)
3. **开始分析**: 点击&quot;🚀 开始分析&quot;按钮
4. **实时跟踪**: 观察实时进度和分析步骤
5. **查看报告**: 点击&quot;📊 查看分析报告&quot;按钮
6. **导出报告**: 支持Word/PDF/Markdown格式

## 🔐 用户权限管理

### 🔑 默认账号信息

系统提供以下默认账号，首次启动时自动创建：

| 用户名 | 密码 | 角色 | 权限说明 |
|--------|------|------|----------|
| **admin** | **admin123** | 管理员 | 完整系统权限，用户管理，系统配置 |
| **user** | **user123** | 普通用户 | 股票分析，报告查看，基础功能 |

&gt; ⚠️ **安全提醒**: 首次登录后请立即修改默认密码！

### 🛡️ 权限控制体系

- **🔐 登录认证**: 基于用户名密码的安全认证
- **👥 角色管理**: 管理员、普通用户等多级权限
- **⏰ 会话管理**: 自动超时保护，安全登出
- **📊 操作日志**: 完整的用户活动记录

### 🛠️ 用户管理工具

系统提供完整的命令行用户管理工具：

#### Windows 用户
```powershell
# 使用 PowerShell 脚本
.\scripts\user_manager.ps1 list                    # 列出所有用户
.\scripts\user_manager.ps1 change-password admin   # 修改密码
.\scripts\user_manager.ps1 create newuser trader  # 创建新用户
.\scripts\user_manager.ps1 delete olduser         # 删除用户

# 或使用批处理文件
.\scripts\user_manager.bat list
```

#### Python 脚本（跨平台）
```bash
# 直接使用 Python 脚本
python scripts/user_password_manager.py list
python scripts/user_password_manager.py change-password admin
python scripts/user_password_manager.py create newuser --role trader
python scripts/user_password_manager.py delete olduser
python scripts/user_password_manager.py reset  # 重置为默认配置
```

### 📋 支持的用户操作

- **📝 列出用户**: 查看所有用户及其角色权限
- **🔑 修改密码**: 安全的密码更新机制
- **👤 创建用户**: 支持自定义角色和权限
- **🗑️ 删除用户**: 安全的用户删除功能
- **🔄 重置配置**: 恢复默认用户设置

### 📁 配置文件位置

用户配置存储在：`web/config/users.json`

&gt; 📚 **详细文档**: 完整的用户管理指南请参考 [scripts/USER_MANAGEMENT.md](scripts/USER_MANAGEMENT.md)

### 🚧 当前版本限制

- ❌ 暂不支持在线用户注册
- ❌ 暂不支持Web界面的角色管理
- ✅ 支持完整的命令行用户管理
- ✅ 支持完整的权限控制框架

---

## 🎯 核心优势

- **🧠 智能新闻分析**: v0.1.12新增AI驱动的新闻过滤和质量评估系统
- **🔧 多层次过滤**: 基础、增强、集成三级新闻过滤机制
- **📰 统一新闻工具**: 整合多源新闻，提供统一的智能检索接口
- **🆕 多LLM集成**: v0.1.11新增4大提供商，60+模型，一站式AI体验
- **💾 配置持久化**: 模型选择真正持久化，URL参数存储，刷新保持
- **🎯 快速切换**: 5个热门模型快速按钮，一键切换不同AI
- **🆕 实时进度**: v0.1.10异步进度跟踪，告别黑盒等待
- **💾 智能会话**: 状态持久化，页面刷新不丢失分析结果
- **🔐 用户权限**: v0.1.14新增完整的用户认证和权限管理体系
- **🇨🇳 中国优化**: A股/港股数据 + 国产LLM + 中文界面
- **🐳 容器化**: Docker一键部署，环境隔离，快速扩展
- **📄 专业报告**: 多格式导出，自动生成投资建议
- **🛡️ 稳定可靠**: 多层数据源，智能降级，错误恢复

## 🔧 技术架构

**核心技术**: Python 3.10+ | LangChain | Streamlit | MongoDB | Redis
**AI模型**: DeepSeek V3 | 阿里百炼 | Google AI | OpenRouter(60+模型) | OpenAI
**数据源**: Tushare | AkShare | FinnHub | Yahoo Finance
**部署**: Docker | Docker Compose | 本地部署

## 📚 文档和支持

- **📖 完整文档**: [docs/](./docs/) - 安装指南、使用教程、API文档
- **🚨 故障排除**: [troubleshooting/](./docs/troubleshooting/) - 常见问题解决方案
- **🔄 更新日志**: [CHANGELOG.md](./docs/releases/CHANGELOG.md) - 详细版本历史
- **🚀 快速开始**: [QUICKSTART.md](./QUICKSTART.md) - 5分钟快速部署指南

## 🆚 中文增强特色

**相比原版新增**: 智能新闻分析 | 多层次新闻过滤 | 新闻质量评估 | 统一新闻工具 | 多LLM提供商集成 | 模型选择持久化 | 快速切换按钮 | | 实时进度显示 | 智能会话管理 | 中文界面 | A股数据 | 国产LLM | Docker部署 | 专业报告导出 | 统一日志管理 | Web配置界面 | 成本优化

**Docker部署包含的服务**:

- 🌐 **Web应用**: TradingAgents-CN主程序
- 🗄️ **MongoDB**: 数据持久化存储
- ⚡ **Redis**: 高速缓存
- 📊 **MongoDB Express**: 数据库管理界面
- 🎛️ **Redis Commander**: 缓存管理界面

#### 💻 方式二：本地部署

**适用场景**: 开发环境、自定义配置、离线使用

### 环境要求

- Python 3.10+ (推荐 3.11)
- 4GB+ RAM (推荐 8GB+)
- 稳定的网络连接

### 安装步骤

```bash
# 1. 克隆项目
git clone https://github.com/hsliuping/TradingAgents-CN.git
cd TradingAgents-CN

# 2. 创建虚拟环境
python -m venv env
# Windows
env\Scripts\activate
# Linux/macOS
source env/bin/activate

# 3. 升级pip
python -m pip install --upgrade pip

# 4. 安装所有依赖
pip install -r requirements.txt
#或者使用pip install -e .
pip install -e .

# 注意：requirements.txt已包含所有必需依赖：
# - 数据库支持 (MongoDB + Redis)
# - 多市场数据源 (Tushare, AKShare, FinnHub等)
# - Web界面和报告导出功能
```

### 配置API密钥

#### 🇨🇳 推荐：使用阿里百炼（国产大模型）

```bash
# 复制配置模板
cp .env.example .env

# 编辑 .env 文件，配置以下必需的API密钥：
DASHSCOPE_API_KEY=your_dashscope_api_key_here
FINNHUB_API_KEY=your_finnhub_api_key_here

# 推荐：Tushare API（专业A股数据）
TUSHARE_TOKEN=your_tushare_token_here
TUSHARE_ENABLED=true

# 可选：其他AI模型API
GOOGLE_API_KEY=your_google_api_key_here
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# 数据库配置（可选，提升性能）
# 本地部署使用标准端口
MONGODB_ENABLED=false  # 设为true启用MongoDB
REDIS_ENABLED=false    # 设为true启用Redis
MONGODB_HOST=localhost
MONGODB_PORT=27017     # 标准MongoDB端口
REDIS_HOST=localhost
REDIS_PORT=6379        # 标准Redis端口

# Docker部署时需要修改主机名
# MONGODB_HOST=mongodb
# REDIS_HOST=redis
```

#### 📋 部署模式配置说明

**本地部署模式**：

```bash
# 数据库配置（本地部署）
MONGODB_ENABLED=true
REDIS_ENABLED=true
MONGODB_HOST=localhost      # 本地主机
MONGODB_PORT=27017         # 标准端口
REDIS_HOST=localhost       # 本地主机
REDIS_PORT=6379           # 标准端口
```

**Docker部署模式**：

```bash
# 数据库配置（Docker部署）
MONGODB_ENABLED=true
REDIS_ENABLED=true
MONGODB_HOST=mongodb       # Docker容器服务名
MONGODB_PORT=27017        # 标准端口
REDIS_HOST=redis          # Docker容器服务名
REDIS_PORT=6379          # 标准端口
```

&gt; 💡 **配置提示**：
&gt;
&gt; - 本地部署：需要手动启动MongoDB和Redis服务
&gt; - Docker部署：数据库服务通过docker-compose自动启动
&gt; - 端口冲突：如果本地已有数据库服务，可修改docker-compose.yml中的端口映射

#### 🌍 可选：使用国外模型

```bash
# OpenAI (需要科学上网)
OPENAI_API_KEY=your_openai_api_key

# Anthropic (需要科学上网)
ANTHROPIC_API_KEY=your_anthropic_api_key
```

### 🗄️ 数据库配置（MongoDB + Redis）

#### 高性能数据存储支持

本项目支持 **MongoDB** 和 **Redis** 数据库，提供：

- **📊 股票数据缓存**: 减少API调用，提升响应速度
- **🔄 智能降级机制**: MongoDB → API → 本地缓存的多层数据源
- **⚡ 高性能缓存**: Redis缓存热点数据，毫秒级响应
- **🛡️ 数据持久化**: MongoDB存储历史数据，支持离线分析

#### 数据库部署方式

**🐳 Docker部署（推荐）**

如果您使用Docker部署，数据库已自动包含在内：

```bash
# Docker部署会自动启动所有服务，包括：
docker-compose up -d --build
# - Web应用 (端口8501)
# - MongoDB (端口27017)
# - Redis (端口6379)
# - 数据库管理界面 (端口8081, 8082)
```

**💻 本地部署 - 数据库配置**

如果您使用本地部署，可以选择以下方式：

**方式一：仅启动数据库服务**

```bash
# 仅启动 MongoDB + Redis 服务（不启动Web应用）
docker-compose up -d mongodb redis mongo-express redis-commander

# 查看服务状态
docker-compose ps

# 停止服务
docker-compose down
```

**方式二：完全本地安装**

```bash
# 数据库依赖已包含在requirements.txt中，无需额外安装

# 启动 MongoDB (默认端口 27017)
mongod --dbpath ./data/mongodb

# 启动 Redis (默认端口 6379)
redis-server
```

&gt; ⚠️ **重要说明**:
&gt;
&gt; - **🐳 Docker部署**: 数据库自动包含，无需额外配置
&gt; - **💻 本地部署**: 可选择仅启动数据库服务或完全本地安装
&gt; - **📋 推荐**: 使用Docker部署以获得最佳体验和一致性

#### 数据库配置选项

**环境变量配置**（推荐）：

```bash
# MongoDB 配置
MONGODB_HOST=localhost
MONGODB_PORT=27017
MONGODB_DATABASE=trading_agents
MONGODB_USERNAME=admin
MONGODB_PASSWORD=your_password

# Redis 配置
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password
REDIS_DB=0
```

**配置文件方式**：

```python
# config/database_config.py
DATABASE_CONFIG = {
    &#039;mongodb&#039;: {
        &#039;host&#039;: &#039;localhost&#039;,
        &#039;port&#039;: 27017,
        &#039;database&#039;: &#039;trading_agents&#039;,
        &#039;username&#039;: &#039;admin&#039;,
        &#039;password&#039;: &#039;your_password&#039;
    },
    &#039;redis&#039;: {
        &#039;host&#039;: &#039;localhost&#039;,
        &#039;port&#039;: 6379,
        &#039;password&#039;: &#039;your_redis_password&#039;,
        &#039;db&#039;: 0
    }
}
```

#### 数据库功能特性

**MongoDB 功能**：

- ✅ 股票基础信息存储
- ✅ 历史价格数据缓存
- ✅ 分析结果持久化
- ✅ 用户配置管理
- ✅ 自动数据同步

**Redis 功能**：

- ⚡ 实时价格数据缓存
- ⚡ API响应结果缓存
- ⚡ 会话状态管理
- ⚡ 热点数据预加载
- ⚡ 分布式锁支持

#### 智能降级机制

系统采用多层数据源降级策略，确保高可用性：

```
📊 数据获取流程：
1. 🔍 检查 Redis 缓存 (毫秒级)
2. 📚 查询 MongoDB 存储 (秒级)
3. 🌐 调用通达信API (秒级)
4. 💾 本地文件缓存 (备用)
5. ❌ 返回错误信息
```

**配置降级策略**：

```python
# 在 .env 文件中配置
ENABLE_MONGODB=true
ENABLE_REDIS=true
ENABLE_FALLBACK=true

# 缓存过期时间（秒）
REDIS_CACHE_TTL=300
MONGODB_CACHE_TTL=3600
```

#### 性能优化建议

**生产环境配置**：

```bash
# MongoDB 优化
MONGODB_MAX_POOL_SIZE=50
MONGODB_MIN_POOL_SIZE=5
MONGODB_MAX_IDLE_TIME=30000

# Redis 优化
REDIS_MAX_CONNECTIONS=20
REDIS_CONNECTION_POOL_SIZE=10
REDIS_SOCKET_TIMEOUT=5
```

#### 数据库管理工具

```bash
# 初始化数据库
python scripts/setup/init_database.py

# 系统状态检查
python scripts/validation/check_system_status.py

# 清理缓存工具
python scripts/maintenance/cleanup_cache.py --days 7
```

#### 故障排除

**常见问题解决**：

1. **🪟 Windows 10 ChromaDB兼容性问题**

   **问题现象**：在Windows 10上出现 `Configuration error: An instance of Chroma already exists for ephemeral with different settings` 错误，而Windows 11正常。

   **快速解决方案**：

   ```bash
   # 方案1：禁用内存功能（推荐）
   # 在 .env 文件中添加：
   MEMORY_ENABLED=false

   # 方案2：使用专用修复脚本
   powershell -ExecutionPolicy Bypass -File scripts\fix_chromadb_win10.ps1

   # 方案3：管理员权限运行
   # 右键PowerShell -&gt; &quot;以管理员身份运行&quot;
   ```

   **详细解决方案**：参考 [Windows 10兼容性指南](docs/troubleshooting/windows10-chromadb-fix.md)
2. **MongoDB连接失败**

   **Docker部署**：

   ```bash
   # 检查服务状态
   docker-compose logs mongodb

   # 重启服务
   docker-compose restart mongodb
   ```

   **本地部署**：

   ```bash
   # 检查MongoDB进程
   ps aux | grep mongod

   # 重启MongoDB
   sudo systemctl restart mongod  # Linux
   brew services restart mongodb  # macOS
   ```
3. **Redis连接超时**

   ```bash
   # 检查Redis状态
   redis-cli ping

   # 清理Redis缓存
   redis-cli flushdb
   ```
4. **缓存问题**

   ```bash
   # 检查系统状态和缓存
   python scripts/validation/check_system_status.py

   # 清理过期缓存
   python scripts/maintenance/cleanup_cache.py --days 7
   ```

&gt; 💡 **提示**: 即使不配置数据库，系统仍可正常运行，会自动降级到API直接调用模式。数据库配置是可选的性能优化功能。

&gt; 📚 **详细文档**: 更多数据库配置信息请参考 [数据库架构文档](docs/architecture/database-architecture.md)

### 📤 报告导出功能

#### 新增功能：专业分析报告导出

本项目现已支持将股票分析结果导出为多种专业格式：

**支持的导出格式**：

- **📄 Markdown (.md)** - 轻量级标记语言，适合技术用户和版本控制
- **📝 Word (.docx)** - Microsoft Word文档，适合商务报告和进一步编辑
- **📊 PDF (.pdf)** - 便携式文档格式，适合正式分享和打印

**报告内容结构**：

- 🎯 **投资决策摘要** - 买入/持有/卖出建议，置信度，风险评分
- 📊 **详细分析报告** - 技术分析，基本面分析，市场情绪，新闻事件
- ⚠️ **风险提示** - 完整的投资风险声明和免责条款
- 📋 **配置信息** - 分析参数，模型信息，生成时间

**使用方法**：

1. 完成股票分析后，在结果页面底部找到&quot;📤 导出报告&quot;部分
2. 选择需要的格式：Markdown、Word或PDF
3. 点击导出按钮，系统自动生成并提供下载

**安装导出依赖**：

```bash
# 安装Python依赖
pip install markdown pypandoc

# 安装系统工具（用于PDF导出）
# Windows: choco install pandoc wkhtmltopdf
# macOS: brew install pandoc wkhtmltopdf
# Linux: sudo apt-get install pandoc wkhtmltopdf
```

&gt; 📚 **详细文档**: 完整的导出功能使用指南请参考 [导出功能指南](docs/EXPORT_GUIDE.md)

### 🚀 启动应用

#### 🐳 Docker启动（推荐）

如果您使用Docker部署，应用已经自动启动：

```bash
# 应用已在Docker中运行，直接访问：
# Web界面: http://localhost:8501
# 数据库管理: http://localhost:8081
# 缓存管理: http://localhost:8082

# 查看运行状态
docker-compose ps

# 查看日志
docker-compose logs -f web
```

#### 💻 本地启动

如果您使用本地部署：

```bash
# 1. 激活虚拟环境
# Windows
.\env\Scripts\activate
# Linux/macOS
source env/bin/activate

# 2. 安装项目到虚拟环境（重要！）
pip install -e .

# 3. 启动Web管理界面
# 方法1：使用项目启动脚本（推荐）
python start_web.py

# 方法2：使用原始启动脚本
python web/run_web.py

# 方法3：直接使用streamlit（需要先安装项目）
streamlit run web/app.py
```

然后在浏览器中访问 `http://loc

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[swisskyrepo/PayloadsAllTheThings]]></title>
            <link>https://github.com/swisskyrepo/PayloadsAllTheThings</link>
            <guid>https://github.com/swisskyrepo/PayloadsAllTheThings</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:18 GMT</pubDate>
            <description><![CDATA[A list of useful payloads and bypass for Web Application Security and Pentest/CTF]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/swisskyrepo/PayloadsAllTheThings">swisskyrepo/PayloadsAllTheThings</a></h1>
            <p>A list of useful payloads and bypass for Web Application Security and Pentest/CTF</p>
            <p>Language: Python</p>
            <p>Stars: 70,364</p>
            <p>Forks: 16,005</p>
            <p>Stars today: 38 stars today</p>
            <h2>README</h2><pre># Payloads All The Things

A list of useful payloads and bypasses for Web Application Security.
Feel free to improve with your payloads and techniques!

You can also contribute with a :beers: IRL, or using the sponsor button.

[![Sponsor](https://img.shields.io/static/v1?label=Sponsor&amp;message=%E2%9D%A4&amp;logo=GitHub&amp;link=https://github.com/sponsors/swisskyrepo)](https://github.com/sponsors/swisskyrepo)
[![Tweet](https://img.shields.io/twitter/url/http/shields.io.svg?style=social)](https://twitter.com/intent/tweet?text=Payloads%20All%20The%20Things,%20a%20list%20of%20useful%20payloads%20and%20bypasses%20for%20Web%20Application%20Security%20-%20by%20@pentest_swissky&amp;url=https://github.com/swisskyrepo/PayloadsAllTheThings/)

An alternative display version is available at [PayloadsAllTheThingsWeb](https://swisskyrepo.github.io/PayloadsAllTheThings/).

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/swisskyrepo/PayloadsAllTheThings/master/.github/banner.png&quot; alt=&quot;banner&quot;&gt;
&lt;/p&gt;

## :book: Documentation

Every section contains the following files, you can use the `_template_vuln` folder to create a new chapter:

- README.md - vulnerability description and how to exploit it, including several payloads
- Intruder - a set of files to give to Burp Intruder
- Images - pictures for the README.md
- Files - some files referenced in the README.md

You might also like the other projects from the AllTheThings family :

- [InternalAllTheThings](https://swisskyrepo.github.io/InternalAllTheThings/) - Active Directory and Internal Pentest Cheatsheets
- [HardwareAllTheThings](https://swisskyrepo.github.io/HardwareAllTheThings/) - Hardware/IOT Pentesting Wiki

You want more? Check the [Books](https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/_LEARNING_AND_SOCIALS/BOOKS.md) and [YouTube channel](https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/_LEARNING_AND_SOCIALS/YOUTUBE.md) selections.

## :technologist: Contributions

Be sure to read [CONTRIBUTING.md](https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/CONTRIBUTING.md)

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/swisskyrepo/PayloadsAllTheThings/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=swisskyrepo/PayloadsAllTheThings&amp;max=36&quot; alt=&quot;sponsors-list&quot; &gt;
&lt;/a&gt;
&lt;/p&gt;

Thanks again for your contribution! :heart:

## :beers: Sponsors

This project is proudly sponsored by these companies.

| Logo | Description |
| --- | --- |
| [&lt;img src=&quot;https://avatars.githubusercontent.com/u/34724717?s=40&amp;v=4&quot; alt=&quot;sponsor-serpapi&quot;&gt;](https://serpapi.com) | **SerpApi** is a real time API to access Google search results. It solves the issues of having to rent proxies, solving captchas, and JSON parsing. |
| [&lt;img src=&quot;https://avatars.githubusercontent.com/u/50994705?s=40&amp;v=4&quot; alt=&quot;sponsor-projectdiscovery&quot;&gt;](https://projectdiscovery.io/) | **ProjectDiscovery** - Detect real, exploitable vulnerabilities. Harness the power of Nuclei for fast and accurate findings without false positives. |
| [&lt;img src=&quot;https://avatars.githubusercontent.com/u/48131541?s=40&amp;v=4&quot; alt=&quot;sponsor-vaadata&quot;&gt;](https://www.vaadata.com/) | **VAADATA** - Ethical Hacking Services |
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[YILING0013/AI_NovelGenerator]]></title>
            <link>https://github.com/YILING0013/AI_NovelGenerator</link>
            <guid>https://github.com/YILING0013/AI_NovelGenerator</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:17 GMT</pubDate>
            <description><![CDATA[使用ai生成多章节的长篇小说，自动衔接上下文、伏笔]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/YILING0013/AI_NovelGenerator">YILING0013/AI_NovelGenerator</a></h1>
            <p>使用ai生成多章节的长篇小说，自动衔接上下文、伏笔</p>
            <p>Language: Python</p>
            <p>Stars: 2,311</p>
            <p>Forks: 454</p>
            <p>Stars today: 178 stars today</p>
            <h2>README</h2><pre># 📖 自动小说生成工具

&gt;- 当前没有什么精力维护该项目，本身该项目并无任何收益，以及临近毕业，有很多内容要忙，如果后面有时间的话，再考虑基于更新的技术去重构吧。——2025/9/24

&lt;div align=&quot;center&quot;&gt;
  
✨ **核心功能** ✨

| 功能模块          | 关键能力                          |
|-------------------|----------------------------------|
| 🎨 小说设定工坊    | 世界观架构 / 角色设定 / 剧情蓝图   |
| 📖 智能章节生成    | 多阶段生成保障剧情连贯性           |
| 🧠 状态追踪系统    | 角色发展轨迹 / 伏笔管理系统         |
| 🔍 语义检索引擎    | 基于向量的长程上下文一致性维护      |
| 📚 知识库集成      | 支持本地文档参考         |
| ✅ 自动审校机制    | 检测剧情矛盾与逻辑冲突          |
| 🖥 可视化工作台    | 全流程GUI操作，配置/生成/审校一体化 |

&lt;/div&gt;

&gt; 一款基于大语言模型的多功能小说生成器，助您高效创作逻辑严谨、设定统一的长篇故事

---

## 📑 目录导航
1. [环境准备](#-环境准备)  
2. [项目架构](#-项目架构)  
3. [配置指南](#⚙️-配置指南)  
4. [运行说明](#🚀-运行说明)  
5. [使用教程](#📘-使用教程)  
6. [疑难解答](#❓-疑难解答)  

---

## 🛠 环境准备
确保满足以下运行条件：
- **Python 3.9+** 运行环境（推荐3.10-3.12之间）
- **pip** 包管理工具
- 有效API密钥：
  - 云端服务：OpenAI / DeepSeek 等
  - 本地服务：Ollama 等兼容 OpenAI 的接口

---


## 📥 安装说明
1. **下载项目**  
   - 通过 [GitHub](https://github.com) 下载项目 ZIP 文件，或使用以下命令克隆本项目：
     ```bash
     git clone https://github.com/YILING0013/AI_NovelGenerator
     ```

2. **安装编译工具（可选）**  
   - 如果对某些包无法正常安装，访问 [Visual Studio Build Tools](https://visualstudio.microsoft.com/zh-hans/visual-cpp-build-tools/) 下载并安装C++编译工具，用于构建部分模块包；
   - 安装时，默认只包含 MSBuild 工具，需手动勾选左上角列表栏中的 **C++ 桌面开发** 选项。

3. **安装依赖并运行**  
   - 打开终端，进入项目源文件目录：
     ```bash
     cd AI_NovelGenerator
     ```
   - 安装项目依赖：
     ```bash
     pip install -r requirements.txt
     ```
   - 安装完成后，运行主程序：
     ```bash
     python main.py
     ```

&gt;如果缺失部分依赖，后续**手动执行**
&gt;```bash
&gt;pip install XXX
&gt;```
&gt;进行安装即可

## 🗂 项目架构
```
novel-generator/
├── main.py                      # 入口文件, 运行 GUI
├── consistency_checker.py       # 一致性检查, 防止剧情冲突
|—— chapter_directory_parser.py  # 目录解析
|—— embedding_adapters.py        # Embedding 接口封装
|—— llm_adapters.py              # LLM 接口封装
├── prompt_definitions.py        # 定义 AI 提示词
├── utils.py                     # 常用工具函数, 文件操作
├── config_manager.py            # 管理配置 (API Key, Base URL)
├── config.json                  # 用户配置文件 (可选)
├── novel_generator/             # 章节生成核心逻辑
├── ui/                          # 图形界面
└── vectorstore/                 # (可选) 本地向量数据库存储
```

---

## ⚙️ 配置指南
### 📌 基础配置（config.json）
```json
{
    &quot;api_key&quot;: &quot;sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&quot;,
    &quot;base_url&quot;: &quot;https://api.openai.com/v1&quot;,
    &quot;interface_format&quot;: &quot;OpenAI&quot;,
    &quot;model_name&quot;: &quot;gpt-4o-mini&quot;,
    &quot;temperature&quot;: 0.7,
    &quot;max_tokens&quot;: 4096,
    &quot;embedding_api_key&quot;: &quot;sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&quot;,
    &quot;embedding_interface_format&quot;: &quot;OpenAI&quot;,
    &quot;embedding_url&quot;: &quot;https://api.openai.com/v1&quot;,
    &quot;embedding_model_name&quot;: &quot;text-embedding-ada-002&quot;,
    &quot;embedding_retrieval_k&quot;: 4,
    &quot;topic&quot;: &quot;星穹铁道主角星穿越到原神提瓦特大陆，拯救提瓦特大陆，并与其中的角色展开爱恨情仇的小说&quot;,
    &quot;genre&quot;: &quot;玄幻&quot;,
    &quot;num_chapters&quot;: 120,
    &quot;word_number&quot;: 4000,
    &quot;filepath&quot;: &quot;D:/AI_NovelGenerator/filepath&quot;
}
```

### 🔧 配置说明
1. **生成模型配置**
   - `api_key`: 大模型服务的API密钥
   - `base_url`: API终端地址（本地服务填Ollama等地址）
   - `interface_format`: 接口模式
   - `model_name`: 主生成模型名称（如gpt-4, claude-3等）
   - `temperature`: 创意度参数（0-1，越高越有创造性）
   - `max_tokens`: 模型最大回复长度

2. **Embedding模型配置**
   - `embedding_model_name`: 模型名称（如Ollama的nomic-embed-text）
   - `embedding_url`: 服务地址
   - `embedding_retrieval_k`: 

3. **小说参数配置**
   - `topic`: 核心故事主题
   - `genre`: 作品类型
   - `num_chapters`: 总章节数
   - `word_number`: 单章目标字数
   - `filepath`: 生成文件存储路径

---

## 🚀 运行说明
### **方式 1：使用 Python 解释器**
```bash
python main.py
```
执行后，GUI 将会启动，你可以在图形界面中进行各项操作。

### **方式 2：打包为可执行文件**
如果你想在无 Python 环境的机器上使用本工具，可以使用 **PyInstaller** 进行打包：

```bash
pip install pyinstaller
pyinstaller main.spec
```
打包完成后，会在 `dist/` 目录下生成可执行文件（如 Windows 下的 `main.exe`）。

---

## 📘 使用教程
1. **启动后，先完成基本参数设置：**  
   - **API Key &amp; Base URL**（如 `https://api.openai.com/v1`）  
   - **模型名称**（如 `gpt-3.5-turbo`、`gpt-4o` 等）  
   - **Temperature** (0~1，决定文字创意程度)  
   - **主题(Topic)**（如 “废土世界的 AI 叛乱”）  
   - **类型(Genre)**（如 “科幻”/“魔幻”/“都市幻想”）  
   - **章节数**、**每章字数**（如 10 章，每章约 3000 字）  
   - **保存路径**（建议创建一个新的输出文件夹）

2. **点击「Step1. 生成设定」**  
   - 系统将基于主题、类型、章节数等信息，生成：  
     - `Novel_setting.txt`：包含世界观、角色信息、雷点暗线等。  
   - 可以在生成后的 `Novel_setting.txt` 中查看或修改设定内容。

3. **点击「Step2. 生成目录」**  
   - 系统会根据已完成的 `Novel_setting.txt` 内容，为全部章节生成：  
     - `Novel_directory.txt`：包括每章标题和简要提示。  
   - 可以在生成后的文件中查看、修改或补充章节标题和描述。

4. **点击「Step3. 生成章节草稿」**  
   - 在生成章节之前，你可以：  
     - **设置章节号**（如写第 1 章，就填 `1`）  
     - **在“本章指导”输入框**中提供对本章剧情的任何期望或提示  
   - 点击按钮后，系统将：  
     - 自动读取前文设定、`Novel_directory.txt`、以及已定稿章节  
     - 调用向量检索回顾剧情，保证上下文连贯  
     - 生成本章大纲 (`outline_X.txt`) 及正文 (`chapter_X.txt`)  
   - 生成完成后，你可在左侧的文本框查看、编辑本章草稿内容。

5. **点击「Step4. 定稿当前章节」**  
   - 系统将：  
     - **更新全局摘要**（写入 `global_summary.txt`）  
     - **更新角色状态**（写入 `character_state.txt`）  
     - **更新向量检索库**（保证后续章节可以调用最新信息）  
     - **更新剧情要点**（如 `plot_arcs.txt`）  
   - 定稿完成后，你可以在 `chapter_X.txt` 中看到定稿后的文本。

6. **一致性检查（可选）**  
   - 点击「[可选] 一致性审校」按钮，对最新章节进行冲突检测，如角色逻辑、剧情前后矛盾等。  
   - 若有冲突，会在日志区输出详细提示。

7. **重复第 4-6 步** 直到所有章节生成并定稿！

&gt; **向量检索配置提示**  
&gt; 1. embedding模型需要显示指定接口和模型名称；
&gt; 2. 使用**本地Ollama**的**Embedding**时需提前启动Ollama服务：  
&gt;    ```bash
&gt;    ollama serve  # 启动服务
&gt;    ollama pull nomic-embed-text  # 下载/启用模型
&gt;    ```
&gt; 3. 切换不同Embedding模型后建议清空vectorstore目录
&gt; 4. 云端Embedding需确保对应API权限已开通

---

## ❓ 疑难解答
### Q1: Expecting value: line 1 column 1 (char 0)

该问题大概率由于API未正确响应造成，也许响应了一个html？其它内容，导致出现该报错；


### Q2: HTTP/1.1 504 Gateway Timeout？
确认接口是否稳定；

### Q3: 如何切换不同的Embedding提供商？
在GUI界面中对应输入即可。

---

如有更多问题或需求，欢迎在**项目 Issues** 中提出。
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Cinnamon/kotaemon]]></title>
            <link>https://github.com/Cinnamon/kotaemon</link>
            <guid>https://github.com/Cinnamon/kotaemon</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:16 GMT</pubDate>
            <description><![CDATA[An open-source RAG-based tool for chatting with your documents.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Cinnamon/kotaemon">Cinnamon/kotaemon</a></h1>
            <p>An open-source RAG-based tool for chatting with your documents.</p>
            <p>Language: Python</p>
            <p>Stars: 24,460</p>
            <p>Forks: 2,000</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# kotaemon

An open-source clean &amp; customizable RAG UI for chatting with your documents. Built with both end users and
developers in mind.

![Preview](https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/preview-graph.png)

&lt;a href=&quot;https://trendshift.io/repositories/11607&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/11607&quot; alt=&quot;Cinnamon%2Fkotaemon | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

[Live Demo #1](https://huggingface.co/spaces/cin-model/kotaemon) |
[Live Demo #2](https://huggingface.co/spaces/cin-model/kotaemon-demo) |
[Online Install](https://cinnamon.github.io/kotaemon/online_install/) |
[Colab Notebook (Local RAG)](https://colab.research.google.com/drive/1eTfieec_UOowNizTJA1NjawBJH9y_1nn)

[User Guide](https://cinnamon.github.io/kotaemon/) |
[Developer Guide](https://cinnamon.github.io/kotaemon/development/) |
[Feedback](https://github.com/Cinnamon/kotaemon/issues) |
[Contact](mailto:kotaemon.support@cinnamon.is)

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/release/python-31013/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
&lt;a href=&quot;https://github.com/Cinnamon/kotaemon/pkgs/container/kotaemon&quot; target=&quot;_blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/docker_pull-kotaemon:latest-brightgreen&quot; alt=&quot;docker pull ghcr.io/cinnamon/kotaemon:latest&quot;&gt;&lt;/a&gt;
![download](https://img.shields.io/github/downloads/Cinnamon/kotaemon/total.svg?label=downloads&amp;color=blue)
&lt;a href=&#039;https://huggingface.co/spaces/cin-model/kotaemon-demo&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#039;&gt;&lt;/a&gt;
&lt;a href=&quot;https://hellogithub.com/en/repository/d3141471a0244d5798bc654982b263eb&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=d3141471a0244d5798bc654982b263eb&amp;claim_uid=RLiD9UZ1rEHNaMf&amp;theme=small&quot; alt=&quot;Featured｜HelloGitHub&quot; /&gt;&lt;/a&gt;

&lt;/div&gt;

&lt;!-- start-intro --&gt;

## Introduction

This project serves as a functional RAG UI for both end users who want to do QA on their
documents and developers who want to build their own RAG pipeline.
&lt;br&gt;

```yml
+----------------------------------------------------------------------------+
| End users: Those who use apps built with `kotaemon`.                       |
| (You use an app like the one in the demo above)                            |
|     +----------------------------------------------------------------+     |
|     | Developers: Those who built with `kotaemon`.                   |     |
|     | (You have `import kotaemon` somewhere in your project)         |     |
|     |     +----------------------------------------------------+     |     |
|     |     | Contributors: Those who make `kotaemon` better.    |     |     |
|     |     | (You make PR to this repo)                         |     |     |
|     |     +----------------------------------------------------+     |     |
|     +----------------------------------------------------------------+     |
+----------------------------------------------------------------------------+
```

### For end users

- **Clean &amp; Minimalistic UI**: A user-friendly interface for RAG-based QA.
- **Support for Various LLMs**: Compatible with LLM API providers (OpenAI, AzureOpenAI, Cohere, etc.) and local LLMs (via `ollama` and `llama-cpp-python`).
- **Easy Installation**: Simple scripts to get you started quickly.

### For developers

- **Framework for RAG Pipelines**: Tools to build your own RAG-based document QA pipeline.
- **Customizable UI**: See your RAG pipeline in action with the provided UI, built with &lt;a href=&#039;https://github.com/gradio-app/gradio&#039;&gt;Gradio &lt;img src=&#039;https://img.shields.io/github/stars/gradio-app/gradio&#039;&gt;&lt;/a&gt;.
- **Gradio Theme**: If you use Gradio for development, check out our theme here: [kotaemon-gradio-theme](https://github.com/lone17/kotaemon-gradio-theme).

## Key Features

- **Host your own document QA (RAG) web-UI**: Support multi-user login, organize your files in private/public collections, collaborate and share your favorite chat with others.

- **Organize your LLM &amp; Embedding models**: Support both local LLMs &amp; popular API providers (OpenAI, Azure, Ollama, Groq).

- **Hybrid RAG pipeline**: Sane default RAG pipeline with hybrid (full-text &amp; vector) retriever and re-ranking to ensure best retrieval quality.

- **Multi-modal QA support**: Perform Question Answering on multiple documents with figures and tables support. Support multi-modal document parsing (selectable options on UI).

- **Advanced citations with document preview**: By default the system will provide detailed citations to ensure the correctness of LLM answers. View your citations (incl. relevant score) directly in the _in-browser PDF viewer_ with highlights. Warning when retrieval pipeline return low relevant articles.

- **Support complex reasoning methods**: Use question decomposition to answer your complex/multi-hop question. Support agent-based reasoning with `ReAct`, `ReWOO` and other agents.

- **Configurable settings UI**: You can adjust most important aspects of retrieval &amp; generation process on the UI (incl. prompts).

- **Extensible**: Being built on Gradio, you are free to customize or add any UI elements as you like. Also, we aim to support multiple strategies for document indexing &amp; retrieval. `GraphRAG` indexing pipeline is provided as an example.

![Preview](https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/preview.png)

## Installation

&gt; If you are not a developer and just want to use the app, please check out our easy-to-follow [User Guide](https://cinnamon.github.io/kotaemon/). Download the `.zip` file from the [latest release](https://github.com/Cinnamon/kotaemon/releases/latest) to get all the newest features and bug fixes.

### System requirements

1. [Python](https://www.python.org/downloads/) &gt;= 3.10
2. [Docker](https://www.docker.com/): optional, if you [install with Docker](#with-docker-recommended)
3. [Unstructured](https://docs.unstructured.io/open-source/installation/full-installation#full-installation) if you want to process files other than `.pdf`, `.html`, `.mhtml`, and `.xlsx` documents. Installation steps differ depending on your operating system. Please visit the link and follow the specific instructions provided there.

### With Docker (recommended)

1. We support both `lite` &amp; `full` version of Docker images. With `full` version, the extra packages of `unstructured` will be installed, which can support additional file types (`.doc`, `.docx`, ...) but the cost is larger docker image size. For most users, the `lite` image should work well in most cases.

   - To use the `full` version.

     ```bash
     docker run \
     -e GRADIO_SERVER_NAME=0.0.0.0 \
     -e GRADIO_SERVER_PORT=7860 \
     -v ./ktem_app_data:/app/ktem_app_data \
     -p 7860:7860 -it --rm \
     ghcr.io/cinnamon/kotaemon:main-full
     ```

   - To use the `full` version with bundled **Ollama** for _local / private RAG_.

     ```bash
     # change image name to
     docker run &lt;...&gt; ghcr.io/cinnamon/kotaemon:main-ollama
     ```

   - To use the `lite` version.

   ```bash
    # change image name to
    docker run &lt;...&gt; ghcr.io/cinnamon/kotaemon:main-lite
   ```

2. We currently support and test two platforms: `linux/amd64` and `linux/arm64` (for newer Mac). You can specify the platform by passing `--platform` in the `docker run` command. For example:

   ```bash
   # To run docker with platform linux/arm64
   docker run \
   -e GRADIO_SERVER_NAME=0.0.0.0 \
   -e GRADIO_SERVER_PORT=7860 \
   -v ./ktem_app_data:/app/ktem_app_data \
   -p 7860:7860 -it --rm \
   --platform linux/arm64 \
   ghcr.io/cinnamon/kotaemon:main-lite
   ```

3. Once everything is set up correctly, you can go to `http://localhost:7860/` to access the WebUI.

4. We use [GHCR](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry) to store docker images, all images can be found [here.](https://github.com/Cinnamon/kotaemon/pkgs/container/kotaemon)

### Without Docker

1. Clone and install required packages on a fresh python environment.

   ```shell
   # optional (setup env)
   conda create -n kotaemon python=3.10
   conda activate kotaemon

   # clone this repo
   git clone https://github.com/Cinnamon/kotaemon
   cd kotaemon

   pip install -e &quot;libs/kotaemon[all]&quot;
   pip install -e &quot;libs/ktem&quot;
   ```

2. Create a `.env` file in the root of this project. Use `.env.example` as a template

   The `.env` file is there to serve use cases where users want to pre-config the models before starting up the app (e.g. deploy the app on HF hub). The file will only be used to populate the db once upon the first run, it will no longer be used in consequent runs.

3. (Optional) To enable in-browser `PDF_JS` viewer, download [PDF_JS_DIST](https://github.com/mozilla/pdf.js/releases/download/v4.0.379/pdfjs-4.0.379-dist.zip) then extract it to `libs/ktem/ktem/assets/prebuilt`

&lt;img src=&quot;https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/pdf-viewer-setup.png&quot; alt=&quot;pdf-setup&quot; width=&quot;300&quot;&gt;

4. Start the web server:

   ```shell
   python app.py
   ```

   - The app will be automatically launched in your browser.
   - Default username and password are both `admin`. You can set up additional users directly through the UI.

   ![Chat tab](https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/chat-tab.png)

5. Check the `Resources` tab and `LLMs and Embeddings` and ensure that your `api_key` value is set correctly from your `.env` file. If it is not set, you can set it there.

### Setup GraphRAG

&gt; [!NOTE]
&gt; Official MS GraphRAG indexing only works with OpenAI or Ollama API.
&gt; We recommend most users to use NanoGraphRAG implementation for straightforward integration with Kotaemon.

&lt;details&gt;

&lt;summary&gt;Setup Nano GRAPHRAG&lt;/summary&gt;

- Install nano-GraphRAG: `pip install nano-graphrag`
- `nano-graphrag` install might introduce version conflicts, see [this issue](https://github.com/Cinnamon/kotaemon/issues/440)
  - To quickly fix: `pip uninstall hnswlib chroma-hnswlib &amp;&amp; pip install chroma-hnswlib`
- Launch Kotaemon with `USE_NANO_GRAPHRAG=true` environment variable.
- Set your default LLM &amp; Embedding models in Resources setting and it will be recognized automatically from NanoGraphRAG.

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;Setup LIGHTRAG&lt;/summary&gt;

- Install LightRAG: `pip install git+https://github.com/HKUDS/LightRAG.git`
- `LightRAG` install might introduce version conflicts, see [this issue](https://github.com/Cinnamon/kotaemon/issues/440)
  - To quickly fix: `pip uninstall hnswlib chroma-hnswlib &amp;&amp; pip install chroma-hnswlib`
- Launch Kotaemon with `USE_LIGHTRAG=true` environment variable.
- Set your default LLM &amp; Embedding models in Resources setting and it will be recognized automatically from LightRAG.

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;Setup MS GRAPHRAG&lt;/summary&gt;

- **Non-Docker Installation**: If you are not using Docker, install GraphRAG with the following command:

  ```shell
  pip install &quot;graphrag&lt;=0.3.6&quot; future
  ```

- **Setting Up API KEY**: To use the GraphRAG retriever feature, ensure you set the `GRAPHRAG_API_KEY` environment variable. You can do this directly in your environment or by adding it to a `.env` file.
- **Using Local Models and Custom Settings**: If you want to use GraphRAG with local models (like `Ollama`) or customize the default LLM and other configurations, set the `USE_CUSTOMIZED_GRAPHRAG_SETTING` environment variable to true. Then, adjust your settings in the `settings.yaml.example` file.

&lt;/details&gt;

### Setup Local Models (for local/private RAG)

See [Local model setup](docs/local_model.md).

### Setup multimodal document parsing (OCR, table parsing, figure extraction)

These options are available:

- [Azure Document Intelligence (API)](https://azure.microsoft.com/en-us/products/ai-services/ai-document-intelligence)
- [Adobe PDF Extract (API)](https://developer.adobe.com/document-services/docs/overview/pdf-extract-api/)
- [Docling (local, open-source)](https://github.com/DS4SD/docling)
  - To use Docling, first install required dependencies: `pip install docling`

Select corresponding loaders in `Settings -&gt; Retrieval Settings -&gt; File loader`

### Customize your application

- By default, all application data is stored in the `./ktem_app_data` folder. You can back up or copy this folder to transfer your installation to a new machine.

- For advanced users or specific use cases, you can customize these files:

  - `flowsettings.py`
  - `.env`

#### `flowsettings.py`

This file contains the configuration of your application. You can use the example
[here](flowsettings.py) as the starting point.

&lt;details&gt;

&lt;summary&gt;Notable settings&lt;/summary&gt;

```python
# setup your preferred document store (with full-text search capabilities)
KH_DOCSTORE=(Elasticsearch | LanceDB | SimpleFileDocumentStore)

# setup your preferred vectorstore (for vector-based search)
KH_VECTORSTORE=(ChromaDB | LanceDB | InMemory | Milvus | Qdrant)

# Enable / disable multimodal QA
KH_REASONINGS_USE_MULTIMODAL=True

# Setup your new reasoning pipeline or modify existing one.
KH_REASONINGS = [
    &quot;ktem.reasoning.simple.FullQAPipeline&quot;,
    &quot;ktem.reasoning.simple.FullDecomposeQAPipeline&quot;,
    &quot;ktem.reasoning.react.ReactAgentPipeline&quot;,
    &quot;ktem.reasoning.rewoo.RewooAgentPipeline&quot;,
]
```

&lt;/details&gt;

#### `.env`

This file provides another way to configure your models and credentials.

&lt;details&gt;

&lt;summary&gt;Configure model via the .env file&lt;/summary&gt;

- Alternatively, you can configure the models via the `.env` file with the information needed to connect to the LLMs. This file is located in the folder of the application. If you don&#039;t see it, you can create one.

- Currently, the following providers are supported:

  - **OpenAI**

    In the `.env` file, set the `OPENAI_API_KEY` variable with your OpenAI API key in order
    to enable access to OpenAI&#039;s models. There are other variables that can be modified,
    please feel free to edit them to fit your case. Otherwise, the default parameter should
    work for most people.

    ```shell
    OPENAI_API_BASE=https://api.openai.com/v1
    OPENAI_API_KEY=&lt;your OpenAI API key here&gt;
    OPENAI_CHAT_MODEL=gpt-3.5-turbo
    OPENAI_EMBEDDINGS_MODEL=text-embedding-ada-002
    ```

  - **Azure OpenAI**

    For OpenAI models via Azure platform, you need to provide your Azure endpoint and API
    key. Your might also need to provide your developments&#039; name for the chat model and the
    embedding model depending on how you set up Azure development.

    ```shell
    AZURE_OPENAI_ENDPOINT=
    AZURE_OPENAI_API_KEY=
    OPENAI_API_VERSION=2024-02-15-preview
    AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-35-turbo
    AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT=text-embedding-ada-002
    ```

  - **Local Models**

    - Using `ollama` OpenAI compatible server:

      - Install [ollama](https://github.com/ollama/ollama) and start the application.

      - Pull your model, for example:

        ```shell
        ollama pull llama3.1:8b
        ollama pull nomic-embed-text
        ```

      - Set the model names on web UI and make it as default:

        ![Models](https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/models.png)

    - Using `GGUF` with `llama-cpp-python`

      You can search and download a LLM to be ran locally from the [Hugging Face Hub](https://huggingface.co/models). Currently, these model formats are supported:

      - GGUF

        You should choose a model whose size is less than your device&#039;s memory and should leave
        about 2 GB. For example, if you have 16 GB of RAM in total, of which 12 GB is available,
        then you should choose a model that takes up at most 10 GB of RAM. Bigger models tend to
        give better generation but also take more processing time.

        Here are some recommendations and their size in memory:

      - [Qwen1.5-1.8B-Chat-GGUF](https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat-GGUF/resolve/main/qwen1_5-1_8b-chat-q8_0.gguf?download=true): around 2 GB

        Add a new LlamaCpp model with the provided model name on the web UI.

  &lt;/details&gt;

### Adding your own RAG pipeline

#### Custom Reasoning Pipeline

1. Check the default pipeline implementation in [here](libs/ktem/ktem/reasoning/simple.py). You can make quick adjustment to how the default QA pipeline work.
2. Add new `.py` implementation in `libs/ktem/ktem/reasoning/` and later include it in `flowssettings` to enable it on the UI.

#### Custom Indexing Pipeline

- Check sample implementation in `libs/ktem/ktem/index/file/graph`

&gt; (more instruction WIP).

&lt;!-- end-intro --&gt;

## Citation

Please cite this project as

```BibTeX
@misc{kotaemon2024,
    title = {Kotaemon - An open-source RAG-based tool for chatting with any content.},
    author = {The Kotaemon Team},
    year = {2024},
    howpublished = {\url{https://github.com/Cinnamon/kotaemon}},
}
```

## Star History

&lt;a href=&quot;https://star-history.com/#Cinnamon/kotaemon&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=Cinnamon/kotaemon&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=Cinnamon/kotaemon&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=Cinnamon/kotaemon&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

## Contribution

Since our project is actively being developed, we greatly value your feedback and contributions. Please see our [Contributing Guide](https://github.com/Cinnamon/kotaemon/blob/main/CONTRIBUTING.md) to get started. Thank you to all our contributors!

&lt;a href=&quot;https://github.com/Cinnamon/kotaemon/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=Cinnamon/kotaemon&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[bregman-arie/devops-exercises]]></title>
            <link>https://github.com/bregman-arie/devops-exercises</link>
            <guid>https://github.com/bregman-arie/devops-exercises</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:15 GMT</pubDate>
            <description><![CDATA[Linux, Jenkins, AWS, SRE, Prometheus, Docker, Python, Ansible, Git, Kubernetes, Terraform, OpenStack, SQL, NoSQL, Azure, GCP, DNS, Elastic, Network, Virtualization. DevOps Interview Questions]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bregman-arie/devops-exercises">bregman-arie/devops-exercises</a></h1>
            <p>Linux, Jenkins, AWS, SRE, Prometheus, Docker, Python, Ansible, Git, Kubernetes, Terraform, OpenStack, SQL, NoSQL, Azure, GCP, DNS, Elastic, Network, Virtualization. DevOps Interview Questions</p>
            <p>Language: Python</p>
            <p>Stars: 79,052</p>
            <p>Forks: 17,855</p>
            <p>Stars today: 75 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;images/devops_exercises.png&quot;/&gt;&lt;/p&gt;

:information_source: &amp;nbsp;This repo contains questions and exercises on various technical topics, sometimes related to DevOps and SRE

:bar_chart: &amp;nbsp;There are currently **2624** exercises and questions

:warning: &amp;nbsp;You can use these for preparing for an interview but most of the questions and exercises don&#039;t represent an actual interview. Please read [FAQ page](faq.md) for more details

:stop_sign: &amp;nbsp;If you are interested in pursuing a career as DevOps engineer, learning some of the concepts mentioned here would be useful, but you should know it&#039;s not about learning all the topics and technologies mentioned in this repository

:pencil: &amp;nbsp;You can add more exercises by submitting pull requests :) Read about contribution guidelines [here](CONTRIBUTING.md)

****

&lt;!-- ALL-TOPICS-LIST:START --&gt;
&lt;!-- prettier-ignore-start --&gt;
&lt;!-- markdownlint-disable --&gt;
&lt;center&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/devops/README.md&quot;&gt;&lt;img src=&quot;images/devops.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;DevOps&quot; /&gt;&lt;br /&gt;&lt;b&gt;DevOps&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/git/README.md&quot;&gt;&lt;img src=&quot;images/git.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Git&quot;/&gt;&lt;br /&gt;&lt;b&gt;Git&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#network&quot;&gt;&lt;img src=&quot;images/network.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Network&quot;/&gt;&lt;br /&gt;&lt;b&gt;Network&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#hardware&quot;&gt;&lt;img src=&quot;images/hardware.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Hardware&quot;/&gt;&lt;br /&gt;&lt;b&gt;Hardware&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/kubernetes/README.md&quot;&gt;&lt;img src=&quot;images/kubernetes.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;kubernetes&quot;/&gt;&lt;br /&gt;&lt;b&gt;Kubernetes&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/software_development/README.md&quot;&gt;&lt;img src=&quot;images/programming.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;programming&quot;/&gt;&lt;br /&gt;&lt;b&gt;Software Development&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/bregman-arie/python-exercises&quot;&gt;&lt;img src=&quot;images/python.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Python&quot;/&gt;&lt;br /&gt;&lt;b&gt;Python&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/bregman-arie/go-exercises&quot;&gt;&lt;img src=&quot;images/Go.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;go&quot;/&gt;&lt;br /&gt;&lt;b&gt;Go&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/perl/README.md&quot;&gt;&lt;img src=&quot;images/perl.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;perl&quot;/&gt;&lt;br /&gt;&lt;b&gt;Perl&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#regex&quot;&gt;&lt;img src=&quot;images/regex.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;RegEx&quot;/&gt;&lt;br /&gt;&lt;b&gt;Regex&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/cloud/README.md&quot;&gt;&lt;img src=&quot;images/cloud.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Cloud&quot;/&gt;&lt;br /&gt;&lt;b&gt;Cloud&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/aws/README.md&quot;&gt;&lt;img src=&quot;images/aws.png&quot; width=&quot;100px;&quot; height=&quot;75px;&quot; alt=&quot;aws&quot;/&gt;&lt;br /&gt;&lt;b&gt;AWS&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/azure/README.md&quot;&gt;&lt;img src=&quot;images/azure.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;azure&quot;/&gt;&lt;br /&gt;&lt;b&gt;Azure&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/gcp/README.md&quot;&gt;&lt;img src=&quot;images/googlecloud.png&quot; width=&quot;70px;&quot; height=&quot;70px;&quot; alt=&quot;Google Cloud Platform&quot;/&gt;&lt;br /&gt;&lt;b&gt;Google Cloud Platform&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#openstack/README.md&quot;&gt;&lt;img src=&quot;images/openstack.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;openstack&quot;/&gt;&lt;br /&gt;&lt;b&gt;OpenStack&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#operating-system&quot;&gt;&lt;img src=&quot;images/os.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Operating System&quot;/&gt;&lt;br /&gt;&lt;b&gt;Operating System&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/linux/README.md&quot;&gt;&lt;img src=&quot;images/logos/linux.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Linux&quot;/&gt;&lt;br /&gt;&lt;b&gt;Linux&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#virtualization&quot;&gt;&lt;img src=&quot;images/virtualization.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Virtualization&quot;/&gt;&lt;br /&gt;&lt;b&gt;Virtualization&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/dns/README.md&quot;&gt;&lt;img src=&quot;images/dns.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;DNS&quot;/&gt;&lt;br /&gt;&lt;b&gt;DNS&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/shell/README.md&quot;&gt;&lt;img src=&quot;images/bash.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Bash&quot;/&gt;&lt;br /&gt;&lt;b&gt;Shell Scripting&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/databases/README.md&quot;&gt;&lt;img src=&quot;images/databases.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Databases&quot;/&gt;&lt;br /&gt;&lt;b&gt;Databases&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#sql&quot;&gt;&lt;img src=&quot;images/sql.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;sql&quot;/&gt;&lt;br /&gt;&lt;b&gt;SQL&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#mongo&quot;&gt;&lt;img src=&quot;images/mongo.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Mongo&quot;/&gt;&lt;br /&gt;&lt;b&gt;Mongo&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#testing&quot;&gt;&lt;img src=&quot;images/testing.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Testing&quot;/&gt;&lt;br /&gt;&lt;b&gt;Testing&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#big-data&quot;&gt;&lt;img src=&quot;images/big-data.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Big Data&quot;/&gt;&lt;br /&gt;&lt;b&gt;Big Data&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;

  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/cicd/README.md&quot;&gt;&lt;img src=&quot;images/cicd.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;cicd&quot;/&gt;&lt;br /&gt;&lt;b&gt;CI/CD&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#certificates&quot;&gt;&lt;img src=&quot;images/certificates.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Certificates&quot;/&gt;&lt;br /&gt;&lt;b&gt;Certificates&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/containers/README.md&quot;&gt;&lt;img src=&quot;images/containers.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Containers&quot;/&gt;&lt;br /&gt;&lt;b&gt;Containers&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/openshift/README.md&quot;&gt;&lt;img src=&quot;images/openshift.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;OpenShift&quot;/&gt;&lt;br /&gt;&lt;b&gt;OpenShift&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#storage&quot;&gt;&lt;img src=&quot;images/storage.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Storage&quot;/&gt;&lt;br /&gt;&lt;b&gt;Storage&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/terraform/README.md&quot;&gt;&lt;img src=&quot;images/terraform.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Terraform&quot;/&gt;&lt;br /&gt;&lt;b&gt;Terraform&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#puppet&quot;&gt;&lt;img src=&quot;images/puppet.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;puppet&quot;/&gt;&lt;br /&gt;&lt;b&gt;Puppet&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#distributed&quot;&gt;&lt;img src=&quot;images/distributed.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Distributed&quot;/&gt;&lt;br /&gt;&lt;b&gt;Distributed&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#questions-you-ask&quot;&gt;&lt;img src=&quot;images/you.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;you&quot;/&gt;&lt;br /&gt;&lt;b&gt;Questions you can ask&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/ansible/README.md&quot;&gt;&lt;img src=&quot;images/ansible.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;ansible&quot;/&gt;&lt;br /&gt;&lt;b&gt;Ansible&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/observability/README.md&quot;&gt;&lt;img src=&quot;images/observability.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;observability&quot;/&gt;&lt;br /&gt;&lt;b&gt;Observability&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#prometheus&quot;&gt;&lt;img src=&quot;images/prometheus.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Prometheus&quot;/&gt;&lt;br /&gt;&lt;b&gt;Prometheus&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/circleci/README.md&quot;&gt;&lt;img src=&quot;images/logos/circleci.png&quot; width=&quot;70px;&quot; height=&quot;70px;&quot; alt=&quot;Circle CI&quot;/&gt;&lt;br /&gt;&lt;b&gt;Circle CI&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/datadog/README.md&quot;&gt;&lt;img src=&quot;images/logos/datadog.png&quot; width=&quot;80px;&quot; height=&quot;80px;&quot; alt=&quot;DataDog&quot;/&gt;&lt;br /&gt;&lt;b&gt;&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/grafana/README.md&quot;&gt;&lt;img src=&quot;images/logos/grafana.png&quot; width=&quot;80px;&quot; height=&quot;80px;&quot; alt=&quot;Grafana&quot;/&gt;&lt;br /&gt;&lt;b&gt;Grafana&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/argo/README.md&quot;&gt;&lt;img src=&quot;images/logos/argo.png&quot; width=&quot;80px;&quot; height=&quot;80px;&quot; alt=&quot;Argo&quot;/&gt;&lt;br /&gt;&lt;b&gt;Argo&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/soft_skills/README.md&quot;&gt;&lt;img src=&quot;images/HR.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;HR&quot;/&gt;&lt;br /&gt;&lt;b&gt;Soft Skills&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/security/README.md&quot;&gt;&lt;img src=&quot;images/security.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;security&quot;/&gt;&lt;br /&gt;&lt;b&gt;Security&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#system-design&quot;&gt;&lt;img src=&quot;images/design.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Design&quot;/&gt;&lt;br /&gt;&lt;b&gt;System Design&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
   &lt;/tr&gt;

   &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/chaos_engineering/README.md&quot;&gt;&lt;img src=&quot;images/logos/chaos_engineering.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Chaos Engineering&quot;/&gt;&lt;br /&gt;&lt;b&gt;Chaos Engineering&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#Misc&quot;&gt;&lt;img src=&quot;images/general.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Misc&quot;/&gt;&lt;br /&gt;&lt;b&gt;Misc&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#elastic&quot;&gt;&lt;img src=&quot;images/elastic.png&quot; width=&quot;75px;&quot; height=&quot;75px;&quot; alt=&quot;Elastic&quot;/&gt;&lt;br /&gt;&lt;b&gt;Elastic&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/kafka/README.md&quot;&gt;&lt;img src=&quot;images/logos/kafka.png&quot; width=&quot;85px;&quot; height=&quot;80px;&quot; alt=&quot;Kafka&quot;/&gt;&lt;br /&gt;&lt;b&gt;Kafka&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;topics/node/node_questions_basic.md&quot;&gt;&lt;img src=&quot;images/nodejs.png&quot; width=&quot;85px;&quot; height=&quot;80px;&quot; alt=&quot;NodeJs&quot;/&gt;&lt;br /&gt;&lt;b&gt;NodeJs&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
   &lt;/tr&gt;
   
&lt;/table&gt;
&lt;/center&gt;
&lt;!-- markdownlint-enable --&gt;
&lt;!-- prettier-ignore-end --&gt;
&lt;!-- ALL-TOPICS-LIST:END --&gt;

## DevOps Applications

&lt;table&gt;
&lt;tr&gt;
  &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://play.google.com/store/apps/details?id=com.codingshell.kubeprep&quot;&gt;&lt;img src=&quot;images/apps/kubeprep.png&quot; width=&quot;200px;&quot; height=&quot;300px;&quot; alt=&quot;KubePrep&quot;/&gt;&lt;br /&gt;&lt;b&gt;KubePrep&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://play.google.com/store/apps/details?id=com.codingshell.linuxmaster&quot;&gt;&lt;img src=&quot;images/apps/linux_master.png&quot; width=&quot;200px;&quot; height=&quot;300px;&quot; alt=&quot;Linux Master&quot;/&gt;&lt;br /&gt;&lt;b&gt;Linux Master&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://play.google.com/store/apps/details?id=com.codingshell.system_design_hero&quot;&gt;&lt;img src=&quot;images/apps/system_design_hero.png&quot; width=&quot;200px;&quot; height=&quot;300px;&quot; alt=&quot;Sytem Design Hero&quot;/&gt;&lt;br /&gt;&lt;b&gt;System Design Hero&lt;/b&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;


## Network

&lt;details&gt;
&lt;summary&gt;In general, what do you need in order to communicate?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

  - A common language (for the two ends to understand)
  - A way to address who you want to communicate with
  - A Connection (so the content of the communication can reach the recipients)

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is TCP/IP?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

A set of protocols that define how two or more devices can communicate with each other.

To learn more about TCP/IP, read [here](http://www.penguintutor.com/linux/basic-network-reference)

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is Ethernet?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

Ethernet simply refers to the most common type of Local Area Network (LAN) used today. A LAN—in contrast to a WAN (Wide Area Network), which spans a larger geographical area—is a connected network of computers in a small area, like your office, college campus, or even home.

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is a MAC address? What is it used for?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

A MAC address is a unique identification number or code used to identify individual devices on the network.

Packets that are sent on the ethernet are always coming from a MAC address and sent to a MAC address. If a network adapter is receiving a packet, it is comparing the packet’s destination MAC address to the adapter’s own MAC address.

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;When is this MAC address used?: ff:ff:ff:ff:ff:ff&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

When a device sends a packet to the broadcast MAC address (FF:FF:FF:FF:FF:FF​), it is delivered to all stations on the local network. Ethernet broadcasts are used to resolve IP addresses to MAC addresses (by ARP) at the data link layer.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is an IP address?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

An Internet Protocol address (IP address) is a numerical label assigned to each device connected to a computer network that uses the Internet Protocol for communication.An IP address serves two main functions: host or network interface identification and location addressing.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Explain the subnet mask and give an example&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

A Subnet mask is a 32-bit number that masks an IP address and divides the IP addresses into network addresses and host addresses. Subnet Mask is made by setting network bits to all &quot;1&quot;s and setting host bits to all &quot;0&quot;s. Within a given network, out of the total usable host addresses, two are always reserved for specific purposes and cannot be allocated to any host. These are the first address, which is reserved as a network address (a.k.a network ID), and the last address used for network broadcast.

[Example](https://github.com/philemonnwanne/projects/tree/main/exercises/exe-09)

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is a private IP address? In which scenarios/system designs, one should use it?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;
Private IP addresses are assigned to the hosts in the same network to communicate with one another. As the name &quot;private&quot; suggests, the devices having the private IP addresses assigned can&#039;t be reached by the devices from any external network. For example, if I am living in a hostel and I want my hostel mates to join the game server I have hosted, I will ask them to join via my server&#039;s private IP address, since the network is local to the hostel.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is a public IP address? In which scenarios/system designs, one should use it?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;
A public IP address is a public-facing IP address. In the event that you were hosting a game server that you want your friends to join, you will give your friends your public IP address to allow their computers to identify and locate your network and server in order for the connection to take place. One time that you would not need to use a public-facing IP address is in the event that you were playing with friends who were connected to the same network as you, in that case, you would use a private IP address. In order for someone to be able to connect to your server that is located internally, you will have to set up a port forward to tell your router to allow traffic from the public domain into your network and vice versa.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Explain the OSI model. What layers there are? What each layer is responsible for?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

- Application: user end (HTTP is here)
- Presentation: establishes context between application-layer entities (Encryption is here)
- Session: establishes, manages, and terminates the connections
- Transport: transfers variable-length data sequences from a source to a destination host (TCP &amp; UDP are here)
- Network: transfers datagrams from one network to another (IP is here)
- Data link: provides a link between two directly connected nodes (MAC is here)
- Physical: the electrical and physical spec of the data connection (Bits are here)

You can read more about the OSI model in [penguintutor.com](http://www.penguintutor.com/linux/basic-network-reference)
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;For each of the following determines to which OSI layer it belongs:

  * Error correction
  * Packets routing
  * Cables and electrical signals
  * MAC address
  * IP address
  * Terminate connections
  * 3 way handshake&lt;/summary&gt;&lt;br&gt;&lt;b&gt;
  * Error correction - Data link
  * Packets routing - Network
  * Cables and electrical signals - Physical
  * MAC address - Data link
  * IP address - Network
  * Terminate connections - Session
  * 3-way handshake - Transport
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What delivery schemes are you familiar with?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

Unicast: One-to-one communication where there is one sender and one receiver.

Broadcast: Sending a message to everyone in the network. The address ff:ff:ff:ff:ff:ff is used for broadcasting.
           Two common protocols which use broadcast are ARP and DHCP.

Multicast: Sending a message to a group of subscribers. It can be one-to-many or many-to-many.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is CSMA/CD? Is it used in modern ethernet networks?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

CSMA/CD stands for Carrier Sense Multiple Access / Collision Detection.
Its primary focus is to manage access to a shared medium/bus where only one host can transmit at a given point in time.

CSMA/CD algorithm:

1. Before sending a frame, it checks whether another host is already transmitting a frame.
2. If no one is transmitting, it starts transmitting the frame.
3. If two hosts transmit at the same time, we have a collision.
4. Both hosts stop sending the frame and they send everyone a &#039;jam signal&#039; notifying everyone that a collision occurred
5. They are waiting for a random time before sending it again
6. Once each host waited for a random time, they try to send the frame again and so the cycle starts again
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Describe the following network devices and the difference between them:

  * router
  * switch
  * hub&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

A router, switch, and hub are all network devices used to connect devices in a local area network (LAN). However, each device operates differently and has its specific use cases. Here is a brief description of each device and the differences between them:

1. Router: a network device that connects multiple network segments together. It operates at the network layer (Layer 3) of the OSI model and uses routing protocols to direct data between networks. Routers use IP addresses to identify devices and route data packets to the correct destination.
2. Switch: a network device that connects multiple devices on a LAN. It operates at the data link layer (Layer 2) of the OSI model and uses MAC addresses to identify devices and direct data packets to the correct destination. Switches allow devices on the same network to communicate with each other more efficiently and can prevent data collisions that can occur when multiple devices send data simultaneously.
3. Hub: a network device that connects multiple devices through a single cable and is used to connect multiple devices without segmenting a network. However, unlike a switch, it operates at the physical layer (Layer 1) of the OSI model and simply broadcasts data packets to all devices connected to it, regardless of whether the device is the intended recipient or not. This means that data collisions can occur, and the network&#039;s efficiency can suffer as a result. Hubs are generally not used in modern network setups, as switches are more efficient and provide better network performance.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is a &quot;Collision Domain&quot;?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;
A collision domain is a network segment in which devices can potentially interfere with each other by attempting to transmit data at the same time. When two devices transmit data at the same time, it can cause a collision, resulting in lost or corrupted data. In a collision domain, all devices share the same bandwidth, and any device can potentially interfere with the transmission of data by other devices.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is a &quot;Broadcast Domain&quot;?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;
A broadcast domain is a network segment in which all devices can communicate with each other by sending broadcast messages. A broadcast message is a message that is sent to all devices in a network rather than a specific device. In a broadcast domain, all devices can receive and process broadcast messages, regardless of whether the message was intended for them or not.
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;three computers connected to a switch. How many collision domains are there? How many broadcast domains?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

Three collision domains and one broadcast domain
&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;How does a router work?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

A router is a physical or virtual appliance that passes information between two or more packet-switched computer networks. A router inspects a given data packet&#039;s destination Internet Protocol address (IP address), calculates the best way for it to reach its destination, and then forwards it accordingly.

&lt;/b&gt;&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;What is NAT?&lt;/summary&gt;&lt;br&gt;&lt;b&gt;

 Netw

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[EbookFoundation/free-programming-books]]></title>
            <link>https://github.com/EbookFoundation/free-programming-books</link>
            <guid>https://github.com/EbookFoundation/free-programming-books</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:14 GMT</pubDate>
            <description><![CDATA[📚 Freely available programming books]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/EbookFoundation/free-programming-books">EbookFoundation/free-programming-books</a></h1>
            <p>📚 Freely available programming books</p>
            <p>Language: Python</p>
            <p>Stars: 371,303</p>
            <p>Forks: 64,469</p>
            <p>Stars today: 132 stars today</p>
            <h2>README</h2><pre># List of Free Learning Resources In Many Languages

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)&amp;#160;
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)&amp;#160;
[![Hacktoberfest 2025 stats](https://img.shields.io/github/hacktoberfest/2025/EbookFoundation/free-programming-books?label=Hacktoberfest+2025)](https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged+created%3A2025-10-01..2025-10-31)

&lt;/div&gt;

Search the list at [https://ebookfoundation.github.io/free-programming-books-search/](https://ebookfoundation.github.io/free-programming-books-search/) [![https://ebookfoundation.github.io/free-programming-books-search/](https://img.shields.io/website?style=flat&amp;logo=www&amp;logoColor=whitesmoke&amp;label=Dynamic%20search%20site&amp;down_color=red&amp;down_message=down&amp;up_color=green&amp;up_message=up&amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books-search%2F)](https://ebookfoundation.github.io/free-programming-books-search/).

This page is available as an easy-to-read website. Access it by clicking on [![https://ebookfoundation.github.io/free-programming-books/](https://img.shields.io/website?style=flat&amp;logo=www&amp;logoColor=whitesmoke&amp;label=Static%20site&amp;down_color=red&amp;down_message=down&amp;up_color=green&amp;up_message=up&amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books%2F)](https://ebookfoundation.github.io/free-programming-books/).

&lt;div align=&quot;center&quot;&gt;
  &lt;form action=&quot;https://ebookfoundation.github.io/free-programming-books-search&quot;&gt;
    &lt;input type=&quot;text&quot; id=&quot;fpbSearch&quot; name=&quot;search&quot; required placeholder=&quot;Search Book or Author&quot;/&gt;
    &lt;label for=&quot;submit&quot;&gt; &lt;/label&gt;
    &lt;input type=&quot;submit&quot; id=&quot;submit&quot; name=&quot;submit&quot; value=&quot;Search&quot; /&gt;
  &lt;/form&gt;
&lt;/div&gt;

## Intro

This list was originally a clone of [StackOverflow - List of Freely Available Programming Books](https://web.archive.org/web/20140606191453/http://stackoverflow.com/questions/194812/list-of-freely-available-programming-books/392926) with contributions from Karan Bhangui and George Stocker.

The list was moved to GitHub by Victor Felder for collaborative updating and maintenance. It has grown to become one of [GitHub&#039;s most popular repositories](https://octoverse.github.com/).

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

[![GitHub repo forks](https://img.shields.io/github/forks/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Forks)](https://github.com/EbookFoundation/free-programming-books/network)&amp;#160;
[![GitHub repo stars](https://img.shields.io/github/stars/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Stars)](https://github.com/EbookFoundation/free-programming-books/stargazers)&amp;#160;
[![GitHub repo contributors](https://img.shields.io/github/contributors-anon/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Contributors)](https://github.com/EbookFoundation/free-programming-books/graphs/contributors)    
[![GitHub org sponsors](https://img.shields.io/github/sponsors/EbookFoundation?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Sponsors)](https://github.com/sponsors/EbookFoundation)&amp;#160;
[![GitHub repo watchers](https://img.shields.io/github/watchers/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Watchers)](https://github.com/EbookFoundation/free-programming-books/watchers)&amp;#160;
[![GitHub repo size](https://img.shields.io/github/repo-size/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Repo%20Size)](https://github.com/EbookFoundation/free-programming-books/archive/refs/heads/main.zip)

&lt;/div&gt;

The [Free Ebook Foundation](https://ebookfoundation.org) now administers the repo, a not-for-profit organization devoted to promoting the creation, distribution, archiving, and sustainability of free ebooks. [Donations](https://ebookfoundation.org/contributions.html) to the Free Ebook Foundation are tax-deductible in the US.


## How To Contribute

Please read [CONTRIBUTING](docs/CONTRIBUTING.md). If you&#039;re new to GitHub, [welcome](docs/HOWTO.md)! Remember to abide by our adapted from ![Contributor Covenant 1.3](https://img.shields.io/badge/Contributor%20Covenant-1.3-4baaaa.svg) [Code of Conduct](docs/CODE_OF_CONDUCT.md) too ([translations](#translations) also available).

Click on these badges to see how you might be able to help:

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

[![GitHub repo Issues](https://img.shields.io/github/issues/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=red&amp;label=Issues)](https://github.com/EbookFoundation/free-programming-books/issues)&amp;#160;
[![GitHub repo Good Issues for newbies](https://img.shields.io/github/issues/EbookFoundation/free-programming-books/good%20first%20issue?style=flat&amp;logo=github&amp;logoColor=green&amp;label=Good%20First%20issues)](https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)&amp;#160;
[![GitHub Help Wanted issues](https://img.shields.io/github/issues/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;logo=github&amp;logoColor=b545d1&amp;label=%22Help%20Wanted%22%20issues)](https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)    
[![GitHub repo PRs](https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=orange&amp;label=PRs)](https://github.com/EbookFoundation/free-programming-books/pulls)&amp;#160;
[![GitHub repo Merged PRs](https://img.shields.io/github/issues-search/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=green&amp;label=Merged%20PRs&amp;query=is%3Amerged)](https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged)&amp;#160;
[![GitHub Help Wanted PRs](https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;logo=github&amp;logoColor=b545d1&amp;label=%22Help%20Wanted%22%20PRs)](https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)

&lt;/div&gt;

## How To Share

&lt;div align=&quot;left&quot; markdown=&quot;1&quot;&gt;
&lt;a href=&quot;https://www.facebook.com/share.php?u=https%3A%2F%2Fgithub.com%2FEbookFoundation%2Ffree-programming-books&amp;p[images][0]=&amp;p[title]=Free%20Programming%20Books&amp;p[summary]=&quot;&gt;Share on Facebook&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;http://www.linkedin.com/shareArticle?mini=true&amp;url=https://github.com/EbookFoundation/free-programming-books&amp;title=Free%20Programming%20Books&amp;summary=&amp;source=&quot;&gt;Share on LinkedIn&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;https://toot.kytta.dev/?text=https://github.com/EbookFoundation/free-programming-books&quot;&gt;Share on Mastodon/Fediverse&lt;/a&gt;&lt;br&gt;    
&lt;a href=&quot;https://t.me/share/url?url=https://github.com/EbookFoundation/free-programming-books&quot;&gt;Share on Telegram&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;https://twitter.com/intent/tweet?text=https://github.com/EbookFoundation/free-programming-books%0AFree%20Programming%20Books&quot;&gt;Share on 𝕏 (Twitter)&lt;/a&gt;&lt;br&gt;
&lt;/div&gt;

## Resources

This project lists books and other resources grouped by genres:

### Books

[English, By Programming Language](books/free-programming-books-langs.md)

[English, By Subject](books/free-programming-books-subjects.md)

#### Other Languages

+ [Arabic / al arabiya / العربية](books/free-programming-books-ar.md)
+ [Armenian / Հայերեն](books/free-programming-books-hy.md)
+ [Azerbaijani / Азәрбајҹан дили / آذربايجانجا ديلي](books/free-programming-books-az.md)
+ [Bengali / বাংলা](books/free-programming-books-bn.md)
+ [Bulgarian / български](books/free-programming-books-bg.md)
+ [Burmese / မြန်မာဘာသာ](books/free-programming-books-my.md)
+ [Chinese / 中文](books/free-programming-books-zh.md)
+ [Czech / čeština / český jazyk](books/free-programming-books-cs.md)
+ [Catalan / catalan/ català](books/free-programming-books-ca.md)
+ [Danish / dansk](books/free-programming-books-da.md)
+ [Dutch / Nederlands](books/free-programming-books-nl.md)
+ [Estonian / eesti keel](books/free-programming-books-et.md)
+ [Finnish / suomi / suomen kieli](books/free-programming-books-fi.md)
+ [French / français](books/free-programming-books-fr.md)
+ [German / Deutsch](books/free-programming-books-de.md)
+ [Greek / ελληνικά](books/free-programming-books-el.md)
+ [Hebrew / עברית](books/free-programming-books-he.md)
+ [Hindi / हिन्दी](books/free-programming-books-hi.md)
+ [Hungarian / magyar / magyar nyelv](books/free-programming-books-hu.md)
+ [Indonesian / Bahasa Indonesia](books/free-programming-books-id.md)
+ [Italian / italiano](books/free-programming-books-it.md)
+ [Japanese / 日本語](books/free-programming-books-ja.md)
+ [Korean / 한국어](books/free-programming-books-ko.md)
+ [Latvian / Latviešu](books/free-programming-books-lv.md)
+ [Malayalam / മലയാളം](books/free-programming-books-ml.md)
+ [Norwegian / Norsk](books/free-programming-books-no.md)
+ [Persian / Farsi (Iran) / فارسى](books/free-programming-books-fa_IR.md)
+ [Polish / polski / język polski / polszczyzna](books/free-programming-books-pl.md)
+ [Portuguese (Brazil)](books/free-programming-books-pt_BR.md)
+ [Portuguese (Portugal)](books/free-programming-books-pt_PT.md)
+ [Romanian (Romania) / limba română / român](books/free-programming-books-ro.md)
+ [Russian / Русский язык](books/free-programming-books-ru.md)
+ [Serbian / српски језик / srpski jezik](books/free-programming-books-sr.md)
+ [Slovak / slovenčina](books/free-programming-books-sk.md)
+ [Spanish / español / castellano](books/free-programming-books-es.md)
+ [Swedish / Svenska](books/free-programming-books-sv.md)
+ [Tamil / தமிழ்](books/free-programming-books-ta.md)
+ [Telugu / తెలుగు](books/free-programming-books-te.md)
+ [Thai / ไทย](books/free-programming-books-th.md)
+ [Turkish / Türkçe](books/free-programming-books-tr.md)
+ [Ukrainian / Українська](books/free-programming-books-uk.md)
+ [Vietnamese / Tiếng Việt](books/free-programming-books-vi.md)

### Cheat Sheets

+ [All Languages](more/free-programming-cheatsheets.md)

### Free Online Courses

+ [Arabic / al arabiya / العربية](courses/free-courses-ar.md)
+ [Bengali / বাংলা](courses/free-courses-bn.md)
+ [Bulgarian / български](courses/free-courses-bg.md)
+ [Burmese / မြန်မာဘာသာ](courses/free-courses-my.md)
+ [Chinese / 中文](courses/free-courses-zh.md)
+ [English](courses/free-courses-en.md)
+ [Finnish / suomi / suomen kieli](courses/free-courses-fi.md)
+ [French / français](courses/free-courses-fr.md)
+ [German / Deutsch](courses/free-courses-de.md)
+ [Greek / ελληνικά](courses/free-courses-el.md)
+ [Hebrew / עברית](courses/free-courses-he.md)
+ [Hindi / हिंदी](courses/free-courses-hi.md)
+ [Indonesian / Bahasa Indonesia](courses/free-courses-id.md)
+ [Italian / italiano](courses/free-courses-it.md)
+ [Japanese / 日本語](courses/free-courses-ja.md)
+ [Kannada/ಕನ್ನಡ](courses/free-courses-kn.md)
+ [Kazakh / қазақша](courses/free-courses-kk.md)
+ [Khmer / ភាសាខ្មែរ](courses/free-courses-km.md)
+ [Korean / 한국어](courses/free-courses-ko.md)
+ [Malayalam / മലയാളം](courses/free-courses-ml.md)
+ [Marathi / मराठी](courses/free-courses-mr.md)
+ [Nepali / नेपाली](courses/free-courses-ne.md)
+ [Norwegian / Norsk](courses/free-courses-no.md)
+ [Persian / Farsi (Iran) / فارسى](courses/free-courses-fa_IR.md)
+ [Polish / polski / język polski / polszczyzna](courses/free-courses-pl.md)
+ [Portuguese (Brazil)](courses/free-courses-pt_BR.md)
+ [Portuguese (Portugal)](courses/free-courses-pt_PT.md)
+ [Russian / Русский язык](courses/free-courses-ru.md)
+ [Sinhala / සිංහල](courses/free-courses-si.md)
+ [Spanish / español / castellano](courses/free-courses-es.md)
+ [Swedish / svenska](courses/free-courses-sv.md)
+ [Tamil / தமிழ்](courses/free-courses-ta.md)
+ [Telugu / తెలుగు](courses/free-courses-te.md)
+ [Thai / ภาษาไทย](courses/free-courses-th.md)
+ [Turkish / Türkçe](courses/free-courses-tr.md)
+ [Ukrainian / Українська](courses/free-courses-uk.md)
+ [Urdu / اردو](courses/free-courses-ur.md)
+ [Vietnamese / Tiếng Việt](courses/free-courses-vi.md)


### Interactive Programming Resources

+ [Chinese / 中文](more/free-programming-interactive-tutorials-zh.md)
+ [English](more/free-programming-interactive-tutorials-en.md)
+ [German / Deutsch](more/free-programming-interactive-tutorials-de.md)
+ [Japanese / 日本語](more/free-programming-interactive-tutorials-ja.md)
+ [Russian / Русский язык](more/free-programming-interactive-tutorials-ru.md)


### Problem Sets and Competitive Programming

+ [Problem Sets](more/problem-sets-competitive-programming.md)


### Podcast - Screencast

Free Podcasts and Screencasts:

+ [Arabic / al Arabiya / العربية](casts/free-podcasts-screencasts-ar.md)
+ [Burmese / မြန်မာဘာသာ](casts/free-podcasts-screencasts-my.md)
+ [Chinese / 中文](casts/free-podcasts-screencasts-zh.md)
+ [Czech / čeština / český jazyk](casts/free-podcasts-screencasts-cs.md)
+ [Dutch / Nederlands](casts/free-podcasts-screencasts-nl.md)
+ [English](casts/free-podcasts-screencasts-en.md)
+ [Finnish / Suomi](casts/free-podcasts-screencasts-fi.md)
+ [French / français](casts/free-podcasts-screencasts-fr.md)
+ [German / Deutsch](casts/free-podcasts-screencasts-de.md)
+ [Hebrew / עברית](casts/free-podcasts-screencasts-he.md)
+ [Indonesian / Bahasa Indonesia](casts/free-podcasts-screencasts-id.md)
+ [Persian / Farsi (Iran) / فارسى](casts/free-podcasts-screencasts-fa_IR.md)
+ [Polish / polski / język polski / polszczyzna](casts/free-podcasts-screencasts-pl.md)
+ [Portuguese (Brazil)](casts/free-podcasts-screencasts-pt_BR.md)
+ [Portuguese (Portugal)](casts/free-podcasts-screencasts-pt_PT.md)
+ [Russian / Русский язык](casts/free-podcasts-screencasts-ru.md)
+ [Sinhala / සිංහල](casts/free-podcasts-screencasts-si.md)
+ [Spanish / español / castellano](casts/free-podcasts-screencasts-es.md)
+ [Swedish / Svenska](casts/free-podcasts-screencasts-sv.md)
+ [Turkish / Türkçe](casts/free-podcasts-screencasts-tr.md)
+ [Ukrainian / Українська](casts/free-podcasts-screencasts-uk.md)


### Programming Playgrounds

Write, compile, and run your code within a browser. Try it out!

+ [Chinese / 中文](more/free-programming-playgrounds-zh.md)
+ [English](more/free-programming-playgrounds.md)
+ [German / Deutsch](more/free-programming-playgrounds-de.md)

## Translations

Volunteers have translated many of our Contributing, How-to, and Code of Conduct documents into languages covered by our lists.

+ English
  + [Code of Conduct](docs/CODE_OF_CONDUCT.md)
  + [Contributing](docs/CONTRIBUTING.md)
  + [How-to](docs/HOWTO.md)
+ ... *[More languages](docs/README.md#translations)* ...

You might notice that there are [some missing translations here](docs/README.md#translations) - perhaps you would like to help out by [contributing a translation](docs/CONTRIBUTING.md#help-out-by-contributing-a-translation)?


## License

Each file included in this repository is licensed under the [CC BY License](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[getredash/redash]]></title>
            <link>https://github.com/getredash/redash</link>
            <guid>https://github.com/getredash/redash</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:13 GMT</pubDate>
            <description><![CDATA[Make Your Company Data Driven. Connect to any data source, easily visualize, dashboard and share your data.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/getredash/redash">getredash/redash</a></h1>
            <p>Make Your Company Data Driven. Connect to any data source, easily visualize, dashboard and share your data.</p>
            <p>Language: Python</p>
            <p>Stars: 27,829</p>
            <p>Forks: 4,519</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img title=&quot;Redash&quot; src=&#039;https://redash.io/assets/images/logo.png&#039; width=&quot;200px&quot;/&gt;
&lt;/p&gt;

[![Documentation](https://img.shields.io/badge/docs-redash.io/help-brightgreen.svg)](https://redash.io/help/)
[![GitHub Build](https://github.com/getredash/redash/actions/workflows/ci.yml/badge.svg)](https://github.com/getredash/redash/actions)

Redash is designed to enable anyone, regardless of the level of technical sophistication, to harness the power of data big and small. SQL users leverage Redash to explore, query, visualize, and share data from any data sources. Their work in turn enables anybody in their organization to use the data. Every day, millions of users at thousands of organizations around the world use Redash to develop insights and make data-driven decisions.

Redash features:

1. **Browser-based**: Everything in your browser, with a shareable URL.
2. **Ease-of-use**: Become immediately productive with data without the need to master complex software.
3. **Query editor**: Quickly compose SQL and NoSQL queries with a schema browser and auto-complete.
4. **Visualization and dashboards**: Create [beautiful visualizations](https://redash.io/help/user-guide/visualizations/visualization-types) with drag and drop, and combine them into a single dashboard.
5. **Sharing**: Collaborate easily by sharing visualizations and their associated queries, enabling peer review of reports and queries.
6. **Schedule refreshes**: Automatically update your charts and dashboards at regular intervals you define.
7. **Alerts**: Define conditions and be alerted instantly when your data changes.
8. **REST API**: Everything that can be done in the UI is also available through REST API.
9. **Broad support for data sources**: Extensible data source API with native support for a long list of common databases and platforms.

&lt;img src=&quot;https://raw.githubusercontent.com/getredash/website/8e820cd02c73a8ddf4f946a9d293c54fd3fb08b9/website/_assets/images/redash-anim.gif&quot; width=&quot;80%&quot;/&gt;

## Getting Started

* [Setting up Redash instance](https://redash.io/help/open-source/setup) (includes links to ready-made AWS/GCE images).
* [Documentation](https://redash.io/help/).

## Supported Data Sources

Redash supports more than 35 SQL and NoSQL [data sources](https://redash.io/help/data-sources/supported-data-sources). It can also be extended to support more. Below is a list of built-in sources:

- Amazon Athena
- Amazon CloudWatch / Insights
- Amazon DynamoDB
- Amazon Redshift
- ArangoDB
- Axibase Time Series Database
- Apache Cassandra
- ClickHouse
- CockroachDB
- Couchbase
- CSV
- Databricks
- DB2 by IBM
- Dgraph
- Apache Drill
- Apache Druid
- e6data
- Eccenca Corporate Memory
- Elasticsearch
- Exasol
- Microsoft Excel
- Firebolt
- Databend
- Google Analytics
- Google BigQuery
- Google Spreadsheets
- Graphite
- Greenplum
- Apache Hive
- Apache Impala
- InfluxDB
- InfluxDBv2
- IBM Netezza Performance Server
- JIRA (JQL)
- JSON
- Apache Kylin
- OmniSciDB (Formerly MapD)
- MariaDB
- MemSQL
- Microsoft Azure Data Warehouse / Synapse
- Microsoft Azure SQL Database
- Microsoft Azure Data Explorer / Kusto
- Microsoft SQL Server
- MongoDB
- MySQL
- Oracle
- Apache Phoenix
- Apache Pinot
- PostgreSQL
- Presto
- Prometheus
- Python
- Qubole
- Rockset
- RisingWave
- Salesforce
- ScyllaDB
- Shell Scripts
- Snowflake
- SPARQL
- SQLite
- TiDB
- Tinybird
- TreasureData
- Trino
- Uptycs
- Vertica
- Yandex AppMetrrica
- Yandex Metrica

## Getting Help

* Issues: https://github.com/getredash/redash/issues
* Discussion Forum: https://github.com/getredash/redash/discussions/
* Development Discussion: https://discord.gg/tN5MdmfGBp

## Reporting Bugs and Contributing Code

* Want to report a bug or request a feature? Please open [an issue](https://github.com/getredash/redash/issues/new).
* Want to help us build **_Redash_**? Fork the project, edit in a [dev environment](https://github.com/getredash/redash/wiki/Local-development-setup) and make a pull request. We need all the help we can get!

## Security

Please email security@redash.io to report any security vulnerabilities. We will acknowledge receipt of your vulnerability and strive to send you regular updates about our progress. If you&#039;re curious about the status of your disclosure please feel free to email us again. If you want to encrypt your disclosure email, you can use [this PGP key](https://keybase.io/arikfr/key.asc).

## License

BSD-2-Clause.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[SigmaHQ/sigma]]></title>
            <link>https://github.com/SigmaHQ/sigma</link>
            <guid>https://github.com/SigmaHQ/sigma</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:12 GMT</pubDate>
            <description><![CDATA[Main Sigma Rule Repository]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/SigmaHQ/sigma">SigmaHQ/sigma</a></h1>
            <p>Main Sigma Rule Repository</p>
            <p>Language: Python</p>
            <p>Stars: 9,673</p>
            <p>Forks: 2,428</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># Sigma - Generic Signature Format for SIEM Systems

&lt;a href=&quot;https://sigmahq.io/&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;br /&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./images/sigma_logo_dark.png&quot;&gt;
  &lt;img width=&quot;454&quot; alt=&quot;Sigma Logo&quot; src=&quot;./images/sigma_logo_light.png&quot;&gt;
&lt;/picture&gt;
&lt;/p&gt;
&lt;/a&gt;
&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/SigmaHQ/sigma/actions?query=branch%3Amaster&quot;&gt;&lt;img src=&quot;https://github.com/SigmaHQ/sigma/actions/workflows/sigma-test.yml/badge.svg?branch=master&quot; alt=&quot;Sigma Build Status&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://sigmahq.io/&quot;&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/SigmaHQ/sigmahq.github.io@master/images/Sigma%20Official%20Badge.svg&quot; alt=&quot;Sigma Official Badge&quot;&gt;&lt;/a&gt; &lt;img alt=&quot;GitHub Repo stars&quot; src=&quot;https://img.shields.io/github/stars/SigmaHQ/sigma&quot;&gt;
&lt;img alt=&quot;GitHub all releases&quot; src=&quot;https://img.shields.io/github/downloads/SigmaHq/Sigma/total&quot;&gt;
&lt;br /&gt;
&lt;a href=&quot;https://opensourcesecurityindex.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
&lt;img style=&quot;width: 170px;&quot; src=&quot;https://opensourcesecurityindex.io/badge.svg&quot; alt=&quot;Open Source Security Index - Fastest Growing Open Source Security Projects&quot; width=&quot;170&quot; /&gt;
&lt;/a&gt;
&lt;/p&gt;

Welcome to the Sigma main rule repository. The place where detection engineers, threat hunters and all defensive security practitioners collaborate on detection rules. The repository offers more than 3000 detection rules of different type and aims to make reliable detections accessible to all at no cost.

Currently the repository offers three types of rules:

* [Generic Detection Rules](./rules/) - Are threat agnostic, their aim is to detect a behavior or an implementation of a technique or procedure that was, can or will be used by a potential threat actor.
* [Threat Hunting Rules](./rules-threat-hunting/) - Are broader in scope and are meant to give the analyst a starting point to hunt for potential suspicious or malicious activity
* [Emerging Threat Rules](./rules-emerging-threats/) - Are rules that cover specific threats, that are timely and relevant for certain periods of time. These threats include specific APT campaigns, exploitation of Zero-Day vulnerabilities, specific malware used during an attack,...etc.

## Explore Sigma

To start exploring the Sigma ecosystem, please visit the official website [sigmahq.io](https://sigmahq.io)

### What is Sigma

Sigma is a generic and open signature format that allows you to describe relevant log events in a straightforward manner. The rule format is very flexible, easy to write and applicable to any type of log file.

The main purpose of this project is to provide a structured form in which researchers or analysts can describe their once developed detection methods and make them shareable with others.

Sigma is for log files what [Snort](https://www.snort.org/) is for network traffic and [YARA](https://github.com/VirusTotal/yara) is for files.

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./images/Sigma_description_dark.png&quot;&gt;
  &lt;img alt=&quot;Sigma Description - A diagram showing Yaml Files (Sigma Rules) moving through a Sigma Convertor, and coming out as many SIEM logos, showing how Sigma rules can be converted to many different available SIEM query languages&quot; src=&quot;./images/Sigma_description_light.png&quot;&gt;
&lt;/picture&gt;

### Why Sigma

Today, everyone collects log data for analysis. People start working on their own, processing numerous white papers, blog posts and log analysis guidelines, extracting the necessary information and build their own searches and dashboard. Some of their searches and correlations are great and very useful but they lack a standardized format in which they can share their work with others.

Others provide excellent analyses, include IOCs and YARA rules to detect the malicious files and network connections, but have no way to describe a specific or generic detection method in log events. Sigma is meant to be an open standard in which such detection mechanisms can be defined, shared and collected in order to improve the detection capabilities for everyone.

### 🌟 Key Features

* A continuously growing list of detection and hunting rules, peer reviewed by a community of professional Detection Engineers.
* Vendor agnostic detection rules.
* Easily shareable across communities and reports

## 🏗️ Rule Creation

To start writing Sigma rules please check the following guides:

* [Rule Creation Guide](https://github.com/SigmaHQ/sigma/wiki/Rule-Creation-Guide)
* [How to Write Sigma Rules - Nextron Systems](https://www.nextron-systems.com/2018/02/10/write-sigma-rules/)

## 🔎 Contributing &amp; Making PRs

Please refer to the [CONTRIBUTING](./CONTRIBUTING.md) guide for detailed instructions on how you can start contributing new rules.

## 📦 Rule Packages

You can download the latest rule packages from the [release page](https://github.com/SigmaHQ/sigma/releases/latest) and start leveraging Sigma rules today.

## 🧬 Rule Usage and Conversion

* You can start converting Sigma rules today using [Sigma CLI](https://github.com/SigmaHQ/sigma-cli) or [sigconverter.io](https://sigconverter.io) the GUI interface

* To integrate Sigma rules in your own toolchain or products use [pySigma](https://github.com/SigmaHQ/pySigma).

## 🚨 Reporting False Positives or New Rule Ideas

If you find a false positive or would like to propose a new detection rule idea but do not have the time to create one, please create a new issue on the [GitHub repository](https://github.com/SigmaHQ/sigma/issues/new/choose) by selecting one of the available templates.

## 📚 Resources &amp; Further Reading

* [Hack.lu 2017 Sigma - Generic Signatures for Log Events by Thomas Patzke](https://www.youtube.com/watch?v=OheVuE9Ifhs)
* [MITRE ATT&amp;CK® and Sigma Alerting SANS Webcast Recording](https://www.sans.org/webcasts/mitre-att-ck-sigma-alerting-110010 &quot;MITRE ATT&amp;CK® and Sigma Alerting&quot;)
* [Sigma - Generic Signatures for SIEM Systems by Florian Roth](https://www.slideshare.net/secret/gvgxeXoKblXRcA)

## Projects or Products that use or integrate Sigma rules
* [AlphaSOC](https://docs.alphasoc.com/detections_and_findings/sigma_community/) - Leverages Sigma rules to increase coverage across all supported log sources
* [alterix](https://github.com/mtnmunuklu/alterix) - Converts Sigma rules to the query language of CRYPTTECH&#039;s SIEM
* [AttackIQ](https://www.attackiq.com/2024/01/10/sigmaiq-attackiqs-latest-innovation-for-actionable-detections/) - Sigma Rules integrated in AttackIQ&#039;s platform, and [SigmAIQ](https://github.com/AttackIQ/SigmAIQ) for Sigma rule conversion and LLM apps
* [Atomic Threat Coverage](https://github.com/atc-project/atomic-threat-coverage) (Since December 2018)
* [AttackRuleMap - Mapping of Atomic Red Team tests and Sigma Rules](https://attackrulemap.com/)
* [Confluent Sigma](https://github.com/confluentinc/confluent-sigma) - Kafka Streams supported Sigma rules
* [Detection Studio](https://detection.studio/?ref=sigmahq_readme) - Convert Sigma rules to any supported SIEM.
* [IBM QRadar](https://community.ibm.com/community/user/security/blogs/gladys-koskas1/2023/08/02/qradar-natively-supports-sigma-for-rules-creation)
* [Impede Detection Platform](https://impede.ai/)
* [Joe Sandbox](https://www.joesecurity.org/blog/8225577975210857708)
* [LimaCharlie](https://limacharlie.io/)
* [MISP](http://www.misp-project.org/2017/03/26/MISP.2.4.70.released.html) (Since Version 2.4.70, March 2017)
* [Nextron&#039;s Aurora Agent](https://www.nextron-systems.com/aurora/)
* [Nextron&#039;s THOR Scanner](https://www.nextron-systems.com/thor/) - Scan with Sigma rules on endpoints
* [RANK VASA](https://globenewswire.com/news-release/2019/03/04/1745907/0/en/RANK-Software-to-Help-MSSPs-Scale-Cybersecurity-Offerings.html)
* [Security Onion](https://docs.securityonion.net/en/latest/sigma.html)
* [Sekoia.io XDR](https://www.sekoia.io) - XDR supporting Sigma and Sigma Correlation rules languages
* [sigma2stix](https://github.com/muchdogesec/sigma2stix) - Converts the entire SigmaHQ Ruleset into STIX 2.1 Objects.
  * A versioned archive of sigma2stix STIX 2.1 data is also available to [download here](https://github.com/muchdogesec/cti_knowledge_base_store/tree/main/sigma-rules).
* [SIΣGMA](https://github.com/3CORESec/SIEGMA) - SIEM consumable generator that utilizes Sigma for query conversion
* [SOC Prime](https://tdm.socprime.com/sigma/)
* [TA-Sigma-Searches](https://github.com/dstaulcu/TA-Sigma-Searches) (Splunk App)
* [TimeSketch](https://github.com/google/timesketch/commit/0c6c4b65a6c0f2051d074e87bbb2da2424fa6c35)
* [ypsilon](https://github.com/P4T12ICK/ypsilon) - Automated Use Case Testing

## 📜 Maintainers

* [Nasreddine Bencherchali (@nas_bench)](https://twitter.com/nas_bench)
* [Florian Roth (@cyb3rops)](https://twitter.com/cyb3rops)
* [Christian Burkard (@phantinuss)](https://twitter.com/phantinuss)
* [François Hubaut (@frack113)](https://twitter.com/frack113)
* [Thomas Patzke (@blubbfiction)](https://twitter.com/blubbfiction)

## Credits

This project would&#039;ve never reached this height without the help of the hundreds of contributors. Thanks to all past and present contributors for their help.

## Licenses

The content of this repository is released under the [Detection Rule License (DRL) 1.1](https://github.com/SigmaHQ/Detection-Rule-License).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[getsentry/sentry]]></title>
            <link>https://github.com/getsentry/sentry</link>
            <guid>https://github.com/getsentry/sentry</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:11 GMT</pubDate>
            <description><![CDATA[Developer-first error tracking and performance monitoring]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/getsentry/sentry">getsentry/sentry</a></h1>
            <p>Developer-first error tracking and performance monitoring</p>
            <p>Language: Python</p>
            <p>Stars: 42,092</p>
            <p>Forks: 4,447</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://sentry.io/?utm_source=github&amp;utm_medium=logo&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://sentry-brand.storage.googleapis.com/sentry-wordmark-dark-280x84.png&quot; alt=&quot;Sentry&quot; width=&quot;280&quot; height=&quot;84&quot; /&gt;
    &lt;/a&gt;
  &lt;/p&gt;
  &lt;p align=&quot;center&quot;&gt;
    Users and logs provide clues. Sentry provides answers.
  &lt;/p&gt;
&lt;/p&gt;

# What&#039;s Sentry?

Sentry is the debugging platform that helps every developer detect, trace, and fix issues. Code breaks, fix it faster.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/getsentry/sentry/raw/master/.github/screenshots/issue-details.png&quot; width=&quot;270&quot; /&gt;
  &lt;img src=&quot;https://github.com/getsentry/sentry/raw/master/.github/screenshots/seer.png&quot; width=&quot;270&quot; /&gt;
  &lt;img src=&quot;https://github.com/getsentry/sentry/raw/master/.github/screenshots/insights.png&quot; width=&quot;270&quot; /&gt;
  &lt;img src=&quot;https://github.com/getsentry/sentry/raw/master/.github/screenshots/traces.png&quot; width=&quot;270&quot; /&gt;
  &lt;img src=&quot;https://github.com/getsentry/sentry/raw/master/.github/screenshots/trace-explorer.png&quot; width=&quot;270&quot; /&gt;
  &lt;img src=&quot;https://github.com/getsentry/sentry/raw/master/.github/screenshots/replays.png&quot; width=&quot;270&quot; /&gt;
  &lt;img src=&quot;https://github.com/getsentry/sentry/raw/master/.github/screenshots/insights.png&quot; width=&quot;270&quot; /&gt;
  &lt;img src=&quot;https://github.com/getsentry/sentry/raw/master/.github/screenshots/logs.png&quot; width=&quot;270&quot; /&gt;
  &lt;img src=&quot;https://github.com/getsentry/sentry/raw/master/.github/screenshots/uptime.png&quot; width=&quot;270&quot; /&gt;
&lt;/p&gt;

## Official Sentry SDKs

- [JavaScript](https://github.com/getsentry/sentry-javascript)
- [Electron](https://github.com/getsentry/sentry-electron/)
- [React-Native](https://github.com/getsentry/sentry-react-native)
- [Python](https://github.com/getsentry/sentry-python)
- [Ruby](https://github.com/getsentry/sentry-ruby)
- [PHP](https://github.com/getsentry/sentry-php)
- [Laravel](https://github.com/getsentry/sentry-laravel)
- [Go](https://github.com/getsentry/sentry-go)
- [Rust](https://github.com/getsentry/sentry-rust)
- [Java/Kotlin](https://github.com/getsentry/sentry-java)
- [Objective-C/Swift](https://github.com/getsentry/sentry-cocoa)
- [C\#/F\#](https://github.com/getsentry/sentry-dotnet)
- [C/C++](https://github.com/getsentry/sentry-native)
- [Dart/Flutter](https://github.com/getsentry/sentry-dart)
- [Perl](https://github.com/getsentry/perl-raven)
- [Clojure](https://github.com/getsentry/sentry-clj/)
- [Elixir](https://github.com/getsentry/sentry-elixir)
- [Unity](https://github.com/getsentry/sentry-unity)
- [Unreal Engine](https://github.com/getsentry/sentry-unreal)
- [Godot Engine](https://github.com/getsentry/sentry-godot)
- [PowerShell](https://github.com/getsentry/sentry-powershell)

# Resources

- [Documentation](https://docs.sentry.io/)
- [Discussions](https://github.com/getsentry/sentry/discussions) (Bugs, feature requests,
  general questions)
- [Discord](https://discord.gg/PXa5Apfe7K)
- [Contributing](https://docs.sentry.io/internal/contributing/)
- [Bug Tracker](https://github.com/getsentry/sentry/issues)
- [Code](https://github.com/getsentry/sentry)
- [Transifex](https://explore.transifex.com/getsentry/sentry/) (Translate
  Sentry\!)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[apify/crawlee-python]]></title>
            <link>https://github.com/apify/crawlee-python</link>
            <guid>https://github.com/apify/crawlee-python</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:10 GMT</pubDate>
            <description><![CDATA[Crawlee—A web scraping and browser automation library for Python to build reliable crawlers. Extract data for AI, LLMs, RAG, or GPTs. Download HTML, PDF, JPG, PNG, and other files from websites. Works with BeautifulSoup, Playwright, and raw HTTP. Both headful and headless mode. With proxy rotation.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/apify/crawlee-python">apify/crawlee-python</a></h1>
            <p>Crawlee—A web scraping and browser automation library for Python to build reliable crawlers. Extract data for AI, LLMs, RAG, or GPTs. Download HTML, PDF, JPG, PNG, and other files from websites. Works with BeautifulSoup, Playwright, and raw HTTP. Both headful and headless mode. With proxy rotation.</p>
            <p>Language: Python</p>
            <p>Stars: 6,717</p>
            <p>Forks: 477</p>
            <p>Stars today: 74 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://crawlee.dev&quot;&gt;
        &lt;picture&gt;
          &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/apify/crawlee-python/master/website/static/img/crawlee-dark.svg?sanitize=true&quot;&gt;
          &lt;img alt=&quot;Crawlee&quot; src=&quot;https://raw.githubusercontent.com/apify/crawlee-python/master/website/static/img/crawlee-light.svg?sanitize=true&quot; width=&quot;500&quot;&gt;
        &lt;/picture&gt;
    &lt;/a&gt;
    &lt;br&gt;
    &lt;small&gt;A web scraping and browser automation library&lt;/small&gt;
&lt;/h1&gt;

&lt;p align=center&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/11169&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/11169&quot; alt=&quot;apify%2Fcrawlee-python | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=center&gt;
    &lt;a href=&quot;https://badge.fury.io/py/crawlee&quot; rel=&quot;nofollow&quot;&gt;
        &lt;img src=&quot;https://badge.fury.io/py/crawlee.svg&quot; alt=&quot;PyPI version&quot; style=&quot;max-width: 100%;&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://pypi.org/project/crawlee/&quot; rel=&quot;nofollow&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/pypi/dm/crawlee&quot; alt=&quot;PyPI - Downloads&quot; style=&quot;max-width: 100%;&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://pypi.org/project/crawlee/&quot; rel=&quot;nofollow&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/pypi/pyversions/crawlee&quot; alt=&quot;PyPI - Python Version&quot; style=&quot;max-width: 100%;&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/jyEM2PRvMU&quot; rel=&quot;nofollow&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/801163717915574323?label=discord&quot; alt=&quot;Chat on discord&quot; style=&quot;max-width: 100%;&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

Crawlee covers your crawling and scraping end-to-end and **helps you build reliable scrapers. Fast.**

Your crawlers will appear almost human-like and fly under the radar of modern bot protections even with the default configuration. Crawlee gives you the tools to crawl the web for links, scrape data and persistently store it in machine-readable formats, without having to worry about the technical details. And thanks to rich configuration options, you can tweak almost any aspect of Crawlee to suit your project&#039;s needs if the default settings don&#039;t cut it.

&gt; 👉 **View full documentation, guides and examples on the [Crawlee project website](https://crawlee.dev/python/)** 👈

We also have a TypeScript implementation of the Crawlee, which you can explore and utilize for your projects. Visit our GitHub repository for more information [Crawlee for JS/TS on GitHub](https://github.com/apify/crawlee).

## Installation

We recommend visiting the [Introduction tutorial](https://crawlee.dev/python/docs/introduction) in Crawlee documentation for more information.

Crawlee is available as [`crawlee`](https://pypi.org/project/crawlee/) package on PyPI. This package includes the core functionality, while additional features are available as optional extras to keep dependencies and package size minimal.

To install Crawlee with all features, run the following command:

```sh
python -m pip install &#039;crawlee[all]&#039;
```

Then, install the [Playwright](https://playwright.dev/) dependencies:

```sh
playwright install
```

Verify that Crawlee is successfully installed:

```sh
python -c &#039;import crawlee; print(crawlee.__version__)&#039;
```

For detailed installation instructions see the [Setting up](https://crawlee.dev/python/docs/introduction/setting-up) documentation page.

### With Crawlee CLI

The quickest way to get started with Crawlee is by using the Crawlee CLI and selecting one of the prepared templates. First, ensure you have [uv](https://pypi.org/project/uv/) installed:

```sh
uv --help
```

If [uv](https://pypi.org/project/uv/) is not installed, follow the official [installation guide](https://docs.astral.sh/uv/getting-started/installation/).

Then, run the CLI and choose from the available templates:

```sh
uvx &#039;crawlee[cli]&#039; create my-crawler
```

If you already have `crawlee` installed, you can spin it up by running:

```sh
crawlee create my-crawler
```

## Examples

Here are some practical examples to help you get started with different types of crawlers in Crawlee. Each example demonstrates how to set up and run a crawler for specific use cases, whether you need to handle simple HTML pages or interact with JavaScript-heavy sites. A crawler run will create a `storage/` directory in your current working directory.

### BeautifulSoupCrawler

The [`BeautifulSoupCrawler`](https://crawlee.dev/python/api/class/BeautifulSoupCrawler) downloads web pages using an HTTP library and provides HTML-parsed content to the user. By default it uses [`HttpxHttpClient`](https://crawlee.dev/python/api/class/HttpxHttpClient) for HTTP communication and [BeautifulSoup](https://pypi.org/project/beautifulsoup4/) for parsing HTML. It is ideal for projects that require efficient extraction of data from HTML content. This crawler has very good performance since it does not use a browser. However, if you need to execute client-side JavaScript, to get your content, this is not going to be enough and you will need to use [`PlaywrightCrawler`](https://crawlee.dev/python/api/class/PlaywrightCrawler). Also if you want to use this crawler, make sure you install `crawlee` with `beautifulsoup` extra.

```python
import asyncio

from crawlee.crawlers import BeautifulSoupCrawler, BeautifulSoupCrawlingContext


async def main() -&gt; None:
    crawler = BeautifulSoupCrawler(
        # Limit the crawl to max requests. Remove or increase it for crawling all links.
        max_requests_per_crawl=10,
    )

    # Define the default request handler, which will be called for every request.
    @crawler.router.default_handler
    async def request_handler(context: BeautifulSoupCrawlingContext) -&gt; None:
        context.log.info(f&#039;Processing {context.request.url} ...&#039;)

        # Extract data from the page.
        data = {
            &#039;url&#039;: context.request.url,
            &#039;title&#039;: context.soup.title.string if context.soup.title else None,
        }

        # Push the extracted data to the default dataset.
        await context.push_data(data)

        # Enqueue all links found on the page.
        await context.enqueue_links()

    # Run the crawler with the initial list of URLs.
    await crawler.run([&#039;https://crawlee.dev&#039;])


if __name__ == &#039;__main__&#039;:
    asyncio.run(main())
```

### PlaywrightCrawler

The [`PlaywrightCrawler`](https://crawlee.dev/python/api/class/PlaywrightCrawler) uses a headless browser to download web pages and provides an API for data extraction. It is built on [Playwright](https://playwright.dev/), an automation library designed for managing headless browsers. It excels at retrieving web pages that rely on client-side JavaScript for content generation, or tasks requiring interaction with JavaScript-driven content. For scenarios where JavaScript execution is unnecessary or higher performance is required, consider using the [`BeautifulSoupCrawler`](https://crawlee.dev/python/api/class/BeautifulSoupCrawler). Also if you want to use this crawler, make sure you install `crawlee` with `playwright` extra.

```python
import asyncio

from crawlee.crawlers import PlaywrightCrawler, PlaywrightCrawlingContext


async def main() -&gt; None:
    crawler = PlaywrightCrawler(
        # Limit the crawl to max requests. Remove or increase it for crawling all links.
        max_requests_per_crawl=10,
    )

    # Define the default request handler, which will be called for every request.
    @crawler.router.default_handler
    async def request_handler(context: PlaywrightCrawlingContext) -&gt; None:
        context.log.info(f&#039;Processing {context.request.url} ...&#039;)

        # Extract data from the page.
        data = {
            &#039;url&#039;: context.request.url,
            &#039;title&#039;: await context.page.title(),
        }

        # Push the extracted data to the default dataset.
        await context.push_data(data)

        # Enqueue all links found on the page.
        await context.enqueue_links()

    # Run the crawler with the initial list of requests.
    await crawler.run([&#039;https://crawlee.dev&#039;])


if __name__ == &#039;__main__&#039;:
    asyncio.run(main())
```

### More examples

Explore our [Examples](https://crawlee.dev/python/docs/examples) page in the Crawlee documentation for a wide range of additional use cases and demonstrations.

## Features

Why Crawlee is the preferred choice for web scraping and crawling?

### Why use Crawlee instead of just a random HTTP library with an HTML parser?

- Unified interface for **HTTP &amp; headless browser** crawling.
- Automatic **parallel crawling** based on available system resources.
- Written in Python with **type hints** - enhances DX (IDE autocompletion) and reduces bugs (static type checking).
- Automatic **retries** on errors or when you’re getting blocked.
- Integrated **proxy rotation** and session management.
- Configurable **request routing** - direct URLs to the appropriate handlers.
- Persistent **queue for URLs** to crawl.
- Pluggable **storage** of both tabular data and files.
- Robust **error handling**.

### Why to use Crawlee rather than Scrapy?

- **Asyncio-based** – Leveraging the standard [Asyncio](https://docs.python.org/3/library/asyncio.html) library, Crawlee delivers better performance and seamless compatibility with other modern asynchronous libraries.
- **Type hints** – Newer project built with modern Python, and complete type hint coverage for a better developer experience.
- **Simple integration** – Crawlee crawlers are regular Python scripts, requiring no additional launcher executor. This flexibility allows to integrate a crawler directly into other applications.
- **State persistence** – Supports state persistence during interruptions, saving time and costs by avoiding the need to restart scraping pipelines from scratch after an issue.
- **Organized data storages** – Allows saving of multiple types of results in a single scraping run. Offers several storing options (see [datasets](https://crawlee.dev/python/api/class/Dataset) &amp; [key-value stores](https://crawlee.dev/python/api/class/KeyValueStore)).

## Running on the Apify platform

Crawlee is open-source and runs anywhere, but since it&#039;s developed by [Apify](https://apify.com), it&#039;s easy to set up on the Apify platform and run in the cloud. Visit the [Apify SDK website](https://docs.apify.com/sdk/python/) to learn more about deploying Crawlee to the Apify platform.

## Support

If you find any bug or issue with Crawlee, please [submit an issue on GitHub](https://github.com/apify/crawlee-python/issues). For questions, you can ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/apify), in GitHub Discussions or you can join our [Discord server](https://discord.com/invite/jyEM2PRvMU).

## Contributing

Your code contributions are welcome, and you&#039;ll be praised for eternity! If you have any ideas for improvements, either submit an issue or create a pull request. For contribution guidelines and the code of conduct, see [CONTRIBUTING.md](https://github.com/apify/crawlee-python/blob/master/CONTRIBUTING.md).

## License

This project is licensed under the Apache License 2.0 - see the [LICENSE](https://github.com/apify/crawlee-python/blob/master/LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[h2y/Shadowrocket-ADBlock-Rules]]></title>
            <link>https://github.com/h2y/Shadowrocket-ADBlock-Rules</link>
            <guid>https://github.com/h2y/Shadowrocket-ADBlock-Rules</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:09 GMT</pubDate>
            <description><![CDATA[提供多款 Shadowrocket 规则，带广告过滤功能。用于 iOS 未越狱设备选择性地自动翻墙。]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/h2y/Shadowrocket-ADBlock-Rules">h2y/Shadowrocket-ADBlock-Rules</a></h1>
            <p>提供多款 Shadowrocket 规则，带广告过滤功能。用于 iOS 未越狱设备选择性地自动翻墙。</p>
            <p>Language: Python</p>
            <p>Stars: 15,981</p>
            <p>Forks: 2,329</p>
            <p>Stars today: 39 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[emcie-co/parlant]]></title>
            <link>https://github.com/emcie-co/parlant</link>
            <guid>https://github.com/emcie-co/parlant</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:08 GMT</pubDate>
            <description><![CDATA[LLM agents built for control. Designed for real-world use. Deployed in minutes.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/emcie-co/parlant">emcie-co/parlant</a></h1>
            <p>LLM agents built for control. Designed for real-world use. Deployed in minutes.</p>
            <p>Language: Python</p>
            <p>Stars: 13,090</p>
            <p>Forks: 1,053</p>
            <p>Stars today: 266 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/emcie-co/parlant/blob/develop/docs/LogoTransparentLight.png?raw=true&quot;&gt;
  &lt;img alt=&quot;Parlant - AI Agent Framework&quot; src=&quot;https://github.com/emcie-co/parlant/blob/develop/docs/LogoTransparentDark.png?raw=true&quot; width=400 /&gt;
&lt;/picture&gt;

&lt;h3&gt;Finally, LLM agents that actually follow instructions&lt;/h3&gt;

&lt;p&gt;
  &lt;a href=&quot;https://www.parlant.io/&quot; target=&quot;_blank&quot;&gt;🌐 Website&lt;/a&gt; •
  &lt;a href=&quot;https://www.parlant.io/docs/quickstart/installation&quot; target=&quot;_blank&quot;&gt;⚡ Quick Start&lt;/a&gt; •
  &lt;a href=&quot;https://discord.gg/duxWqxKk6J&quot; target=&quot;_blank&quot;&gt;💬 Discord&lt;/a&gt; •
  &lt;a href=&quot;https://www.parlant.io/docs/quickstart/examples&quot; target=&quot;_blank&quot;&gt;📖 Examples&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
  &lt;a href=&quot;https://zdoc.app/de/emcie-co/parlant&quot;&gt;Deutsch&lt;/a&gt; |
  &lt;a href=&quot;https://zdoc.app/es/emcie-co/parlant&quot;&gt;Español&lt;/a&gt; |
  &lt;a href=&quot;https://zdoc.app/fr/emcie-co/parlant&quot;&gt;français&lt;/a&gt; |
  &lt;a href=&quot;https://zdoc.app/ja/emcie-co/parlant&quot;&gt;日本語&lt;/a&gt; |
  &lt;a href=&quot;https://zdoc.app/ko/emcie-co/parlant&quot;&gt;한국어&lt;/a&gt; |
  &lt;a href=&quot;https://zdoc.app/pt/emcie-co/parlant&quot;&gt;Português&lt;/a&gt; |
  &lt;a href=&quot;https://zdoc.app/ru/emcie-co/parlant&quot;&gt;Русский&lt;/a&gt; |
  &lt;a href=&quot;https://zdoc.app/zh/emcie-co/parlant&quot;&gt;中文&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;
  &lt;a href=&quot;https://pypi.org/project/parlant/&quot;&gt;&lt;img alt=&quot;PyPI&quot; src=&quot;https://img.shields.io/pypi/v/parlant?color=blue&quot;&gt;&lt;/a&gt;
  &lt;img alt=&quot;Python 3.10+&quot; src=&quot;https://img.shields.io/badge/python-3.10+-blue&quot;&gt;
  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;&lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/badge/license-Apache%202.0-green&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/duxWqxKk6J&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1312378700993663007?color=7289da&amp;logo=discord&amp;logoColor=white&quot;&gt;&lt;/a&gt;
  &lt;img alt=&quot;GitHub Repo stars&quot; src=&quot;https://img.shields.io/github/stars/emcie-co/parlant?style=social&quot;&gt;
&lt;/p&gt;

&lt;a href=&quot;https://trendshift.io/repositories/12768&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://trendshift.io/api/badge/repositories/12768&quot; alt=&quot;Trending on TrendShift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
&lt;/a&gt;

&lt;/div&gt;

## 🎯 The Problem Every AI Developer Faces

You build an AI agent. It works great in testing. Then real users start talking to it and...

- ❌ It ignores your carefully crafted system prompts
- ❌ It hallucinates responses in critical moments
- ❌ It can&#039;t handle edge cases consistently
- ❌ Each conversation feels like a roll of the dice

**Sound familiar?** You&#039;re not alone. This is the #1 pain point for developers building production AI agents.

## ⚡ The Solution: Stop Fighting Prompts, Teach Principles

Parlant flips the script on AI agent development. Instead of hoping your LLM will follow instructions, **Parlant ensures it**.

```python
# Traditional approach: Cross your fingers 🤞
system_prompt = &quot;You are a helpful assistant. Please follow these 47 rules...&quot;

# Parlant approach: Ensured compliance ✅
await agent.create_guideline(
    condition=&quot;Customer asks about refunds&quot;,
    action=&quot;Check order status first to see if eligible&quot;,
    tools=[check_order_status],
)
```

#### Parlant gives you all the structure you need to build customer-facing agents that behave exactly as your business requires:

- **[Journeys](https://parlant.io/docs/concepts/customization/journeys)**:
  Define clear customer journeys and how your agent should respond at each step.

- **[Behavioral Guidelines](https://parlant.io/docs/concepts/customization/guidelines)**:
  Easily craft agent behavior; Parlant will match the relevant elements contextually.

- **[Tool Use](https://parlant.io/docs/concepts/customization/tools)**:
  Attach external APIs, data fetchers, or backend services to specific interaction events.

- **[Domain Adaptation](https://parlant.io/docs/concepts/customization/glossary)**:
  Teach your agent domain-specific terminology and craft personalized responses.

- **[Canned Responses](https://parlant.io/docs/concepts/customization/canned-responses)**:
  Use response templates to eliminate hallucinations and guarantee style consistency.

- **[Explainability](https://parlant.io/docs/advanced/explainability)**:
  Understand why and when each guideline was matched and followed.

&lt;div align=&quot;center&quot;&gt;

## 🚀 Get Your Agent Running in 60 Seconds

&lt;/div&gt;

```bash
pip install parlant
```

```python
import parlant.sdk as p

@p.tool
async def get_weather(context: p.ToolContext, city: str) -&gt; p.ToolResult:
    # Your weather API logic here
    return p.ToolResult(f&quot;Sunny, 72°F in {city}&quot;)

@p.tool
async def get_datetime(context: p.ToolContext) -&gt; p.ToolResult:
    from datetime import datetime
    return p.ToolResult(datetime.now())

async def main():
    async with p.Server() as server:
        agent = await server.create_agent(
            name=&quot;WeatherBot&quot;,
            description=&quot;Helpful weather assistant&quot;
        )

        # Have the agent&#039;s context be updated on every response (though
        # update interval is customizable) using a context variable.
        await agent.create_variable(name=&quot;current-datetime&quot;, tool=get_datetime)

        # Control and guide agent behavior with natural language
        await agent.create_guideline(
            condition=&quot;User asks about weather&quot;,
            action=&quot;Get current weather and provide a friendly response with suggestions&quot;,
            tools=[get_weather]
        )

        # Add other (reliably enforced) behavioral modeling elements
        # ...

        # 🎉 Test playground ready at http://localhost:8800
        # Integrate the official React widget into your app,
        # or follow the tutorial to build your own frontend!

if __name__ == &quot;__main__&quot;:
    import asyncio
    asyncio.run(main())
```

**That&#039;s it!** Your agent is running with ensured rule-following behavior.

## 🎬 See It In Action

&lt;img alt=&quot;Parlant Demo&quot; src=&quot;https://github.com/emcie-co/parlant/blob/develop/docs/demo.gif?raw=true&quot; width=&quot;100%&quot; /&gt;

## 🔥 Why Developers Are Switching to Parlant

&lt;table width=&quot;100%&quot;&gt;
&lt;tr&gt;
  &lt;td width=&quot;50%&quot;&gt;

### 🏗️ **Traditional AI Frameworks**

  &lt;/td&gt;
  &lt;td width=&quot;50%&quot;&gt;

### ⚡ **Parlant**

  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;50%&quot;&gt;

- Write complex system prompts
- Hope the LLM follows them
- Debug unpredictable behaviors
- Scale by prompt engineering
- Cross fingers for reliability

&lt;/td&gt;
&lt;td width=&quot;50%&quot;&gt;

- Define rules in natural language
- **Ensured** rule compliance
- Predictable, consistent behavior
- Scale by adding guidelines
- Production-ready from day one

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

## 🎯 Perfect For Your Use Case

&lt;div align=&quot;center&quot;&gt;

|  **Financial Services**  |     **Healthcare**      |       **E-commerce**        |       **Legal Tech**       |
| :----------------------: | :---------------------: | :-------------------------: | :------------------------: |
| Compliance-first design  |   HIPAA-ready agents    |  Customer service at scale  |   Precise legal guidance   |
| Built-in risk management | Patient data protection | Order processing automation | Document review assistance |

&lt;/div&gt;

## 🛠️ Enterprise-Grade Features

- **🧭 Conversational Journeys** - Lead the customer step-by-step to a goal
- **🎯 Dynamic Guideline Matching** - Context-aware rule application
- **🔧 Reliable Tool Integration** - APIs, databases, external services
- **📊 Conversation Analytics** - Deep insights into agent behavior
- **🔄 Iterative Refinement** - Continuously improve agent responses
- **🛡️ Built-in Guardrails** - Prevent hallucination and off-topic responses
- **📱 React Widget** - [Drop-in chat UI for any web app](https://github.com/emcie-co/parlant-chat-react)
- **🔍 Full Explainability** - Understand every decision your agent makes

## 📈 Join 8,000+ Developers Building Better AI

&lt;div align=&quot;center&quot;&gt;

**Companies using Parlant:**

_Financial institutions • Healthcare providers • Legal firms • E-commerce platforms_

[![Star History Chart](https://api.star-history.com/svg?repos=emcie-co/parlant&amp;type=Date)](https://star-history.com/#emcie-co/parlant&amp;Date)

&lt;/div&gt;

## 🌟 What Developers Are Saying

&gt; _&quot;By far the most elegant conversational AI framework that I&#039;ve come across! Developing with Parlant is pure joy.&quot;_ **— Vishal Ahuja, Senior Lead, Customer-Facing Conversational AI @ JPMorgan Chase**

## 🏃‍♂️ Quick Start Paths

&lt;table border=&quot;0&quot;&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;🎯 I want to test it myself&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://www.parlant.io/docs/quickstart/installation&quot;&gt;→ 5-minute quickstart&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;🛠️ I want to see an example&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://www.parlant.io/docs/quickstart/examples&quot;&gt;→ Healthcare agent example&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;🚀 I want to get involved&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://discord.gg/duxWqxKk6J&quot;&gt;→ Join our Discord community&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

## 🤝 Community &amp; Support

- 💬 **[Discord Community](https://discord.gg/duxWqxKk6J)** - Get help from the team and community
- 📖 **[Documentation](https://parlant.io/docs/quickstart/installation)** - Comprehensive guides and examples
- 🐛 **[GitHub Issues](https://github.com/emcie-co/parlant/issues)** - Bug reports and feature requests
- 📧 **[Direct Support](https://parlant.io/contact)** - Direct line to our engineering team

## 📄 License

Apache 2.0 - Use it anywhere, including commercial projects.

---

&lt;div align=&quot;center&quot;&gt;

**Ready to build AI agents that actually work?**

⭐ **Star this repo** • 🚀 **[Try Parlant now](https://parlant.io/)** • 💬 **[Join Discord](https://discord.gg/duxWqxKk6J)**

_Built with ❤️ by the team at [Emcie](https://emcie.co)_

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[OpenBB-finance/OpenBB]]></title>
            <link>https://github.com/OpenBB-finance/OpenBB</link>
            <guid>https://github.com/OpenBB-finance/OpenBB</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:07 GMT</pubDate>
            <description><![CDATA[Financial data platform for analysts, quants and AI agents.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/OpenBB-finance/OpenBB">OpenBB-finance/OpenBB</a></h1>
            <p>Financial data platform for analysts, quants and AI agents.</p>
            <p>Language: Python</p>
            <p>Stars: 52,871</p>
            <p>Forks: 5,051</p>
            <p>Stars today: 66 stars today</p>
            <h2>README</h2><pre>&lt;br /&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/platform-light.svg?raw=true#gh-light-mode-only&quot; alt=&quot;OpenBB Platform logo&quot; width=&quot;600&quot;&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only&quot; alt=&quot;OpenBB Platform logo&quot; width=&quot;600&quot;&gt;
&lt;br /&gt;
&lt;br /&gt;

[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;label=Follow%20%40openbb_finance)](https://x.com/openbb_finance)
[![Discord Shield](https://img.shields.io/discord/831165782750789672)](https://discord.com/invite/xPHTuHCmuV)
[![Open in Dev Containers](https://img.shields.io/static/v1?label=Dev%20Containers&amp;message=Open&amp;color=blue&amp;logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB)
&lt;a href=&quot;https://codespaces.new/OpenBB-finance/OpenBB&quot;&gt;
  &lt;img src=&quot;https://github.com/codespaces/badge.svg&quot; height=&quot;20&quot; /&gt;
&lt;/a&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb&quot;&gt;
  &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open In Colab&quot;/&gt;
&lt;/a&gt;
[![PyPI](https://img.shields.io/pypi/v/openbb?color=blue&amp;label=PyPI%20Package)](https://pypi.org/project/openbb/)

The first financial Platform that is open source.

The OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.

Get started with: `pip install openbb`

```python
from openbb import obb
output = obb.equity.price.historical(&quot;AAPL&quot;)
df = output.to_dataframe()
```

You can sign up to the [OpenBB Hub](https://my.openbb.co/login) to get the most out of the OpenBB ecosystem.

Data integrations available can be found here: &lt;https://docs.openbb.co/platform/reference&gt;

---

## OpenBB Workspace

While the OpenBB Platform is all about an integration to dozens of different data vendors, the interface is either Python or a CLI.

If you want an enterprise UI to visualize this datasets and use AI agents on top, you can find OpenBB Workspace at &lt;https://pro.openbb.co&gt;.

&lt;a href=&quot;https://pro.openbb.co&quot;&gt;
  &lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png&quot; alt=&quot;Logo&quot; width=&quot;1000&quot;&gt;
  &lt;/div&gt;
&lt;/a&gt;

Data integration:

- You can learn more about adding data to the OpenBB workspace from the [docs](https://docs.openbb.co/workspace) or [this open source repository](https://github.com/OpenBB-finance/backends-for-openbb).

AI Agents integration:

- You can learn more about adding AI agents to the OpenBB workspace from [this open source repository](https://github.com/OpenBB-finance/agents-for-openbb).

### Integrating OpenBB Platform to the OpenBB Workspace

Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.

#### Run OpenBB Platform backend

- Install the packages.

```sh
pip install &quot;openbb[all]&quot;
```

- Start the API server over localhost.

```sh
openbb-api
```

This will launch a FastAPI server, via Uvicorn, at `127.0.0.1:6900`.

You can check that it works by going to &lt;http://127.0.0.1:6900&gt;.

#### Integrate OpenBB Platform backend to OpenBB Workspace

Sign-in to the [OpenBB Workspace](https://pro.openbb.co/), and follow the following steps:

![CleanShot 2025-05-17 at 09 51 56@2x](https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069)

1. Go to the &quot;Apps&quot; tab
2. Click on &quot;Connect backend&quot;
3. Fill in the form with:
   Name: OpenBB Platform
   URL: &lt;http://127.0.0.1:6900&gt;
4. Click on &quot;Test&quot;. You should get a &quot;Test successful&quot; with the number of apps found.
5. Click on &quot;Add&quot;.

That&#039;s it.

---

&lt;!-- TABLE OF CONTENTS --&gt;
&lt;details closed=&quot;closed&quot;&gt;
  &lt;summary&gt;&lt;h2 style=&quot;display: inline-block&quot;&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt;
  &lt;ol&gt;
    &lt;li&gt;&lt;a href=&quot;#1-installation&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#2-contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#3-license&quot;&gt;License&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#4-disclaimer&quot;&gt;Disclaimer&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#5-contacts&quot;&gt;Contacts&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#6-star-history&quot;&gt;Star History&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#7-contributors&quot;&gt;Contributors&lt;/a&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/details&gt;

## 1. Installation

The OpenBB Platform can be installed as a [PyPI package](https://pypi.org/project/openbb/) by running `pip install openbb`

or by cloning the repository directly with `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process, in the [OpenBB Documentation](https://docs.openbb.co/platform/installation).

### OpenBB Platform CLI installation

The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.

It can be installed by running `pip install openbb-cli`

or by cloning the repository directly with  `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process in the [OpenBB Documentation](https://docs.openbb.co/cli/installation).

## 2. Contributing

There are three main ways of contributing to this project. (Hopefully you have starred the project by now ⭐️)

### Become a Contributor

- More information on our [Contributing Documentation](https://docs.openbb.co/platform/developer_guide/misc/contributing).

### Create a GitHub ticket

Before creating a ticket make sure the one you are creating doesn&#039;t exist already [here](https://github.com/OpenBB-finance/OpenBB/issues)

- [Report bug](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.md&amp;title=%5BBug%5D)
- [Suggest improvement](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=enhancement&amp;template=enhancement.md&amp;title=%5BIMPROVE%5D)
- [Request a feature](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=new+feature&amp;template=feature_request.md&amp;title=%5BFR%5D)

### Provide feedback

We are most active on [our Discord](https://openbb.co/discord), but feel free to reach out to us in any of [our social media](https://openbb.co/links) for feedback.

## 3. License

Distributed under the AGPLv3 License. See
[LICENSE](https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE) for more information.

## 4. Disclaimer

Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment
amount, and may not be suitable for all investors.

Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.

The data contained in the OpenBB Platform is not necessarily accurate.

OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.

All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.

Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.

## 5. Contacts

If you have any questions about the platform or anything OpenBB, feel free to email us at `support@openbb.co`

If you want to say hi, or are interested in partnering with us, feel free to reach us at `hello@openbb.co`

Any of our social media platforms: [openbb.co/links](https://openbb.co/links)

## 6. Star History

This is a proxy of our growth and that we are just getting started.

But for more metrics important to us check [openbb.co/open](https://openbb.co/open).

[![Star History Chart](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)

## 7. Contributors

OpenBB wouldn&#039;t be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.

&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/graphs/contributors&quot;&gt;
   &lt;img src=&quot;https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB&quot; width=&quot;800&quot;/&gt;
&lt;/a&gt;

&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt;
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;

[contributors-shield]: https://img.shields.io/github/contributors/OpenBB-finance/OpenBB.svg?style=for-the-badge
[contributors-url]: https://github.com/OpenBB-finance/OpenBB/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/OpenBB-finance/OpenBB.svg?style=for-the-badge
[forks-url]: https://github.com/OpenBB-finance/OpenBB/network/members
[stars-shield]: https://img.shields.io/github/stars/OpenBB-finance/OpenBB.svg?style=for-the-badge
[stars-url]: https://github.com/OpenBB-finance/OpenBB/stargazers
[issues-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB.svg?style=for-the-badge&amp;color=blue
[issues-url]: https://github.com/OpenBB-finance/OpenBB/issues
[bugs-open-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=yellow
[bugs-open-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aopen
[bugs-closed-shield]: https://img.shields.io/github/issues-closed/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=success
[bugs-closed-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aclosed
[license-shield]: https://img.shields.io/github/license/OpenBB-finance/OpenBB.svg?style=for-the-badge
[license-url]: https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&amp;logo=linkedin&amp;colorB=555
[linkedin-url]: https://linkedin.com/in/DidierRLopes
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[airweave-ai/airweave]]></title>
            <link>https://github.com/airweave-ai/airweave</link>
            <guid>https://github.com/airweave-ai/airweave</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:06 GMT</pubDate>
            <description><![CDATA[Airweave lets agents search any app]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/airweave-ai/airweave">airweave-ai/airweave</a></h1>
            <p>Airweave lets agents search any app</p>
            <p>Language: Python</p>
            <p>Stars: 3,315</p>
            <p>Forks: 417</p>
            <p>Stars today: 158 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;frontend/public/logo-airweave-darkbg.svg&quot;/&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;frontend/public/logo-airweave-lightbg.svg&quot;/&gt;
  &lt;img width=&quot;1673&quot; alt=&quot;airweave-lettermark&quot; style=&quot;padding-bottom: 12px;&quot; src=&quot;frontend/public/logo-airweave-darkbg.svg&quot;/&gt;
&lt;/picture&gt;

&lt;div align=&quot;center&quot;&gt;

# Make Any App Searchable for AI Agents

[![Ruff](https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml/badge.svg)](https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml)
[![ESLint](https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml/badge.svg)](https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml)
[![System Tests](https://github.com/airweave-ai/airweave/actions/workflows/test-public-api.yml/badge.svg)](https://github.com/airweave-ai/airweave/actions/workflows/test-public-api.yml)
[![Codecov](https://codecov.io/gh/airweave-ai/airweave/branch/main/graph/badge.svg)](https://codecov.io/gh/airweave-ai/airweave)
[![Discord](https://img.shields.io/discord/1323415085011701870?label=Discord&amp;logo=discord&amp;logoColor=white&amp;style=flat-square)](https://discord.gg/gDuebsWGkn)
&lt;br&gt;
&lt;div style=&quot;padding-top: 16px;&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/13748&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13748&quot; alt=&quot;airweave-ai%2Fairweave | Trendshift&quot; style=&quot;width: 250px; height: 55px; margin-right: 24px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://www.ycombinator.com/launches/NX7-airweave-let-agents-search-any-app&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://www.ycombinator.com/launches/NX7-airweave-let-agents-search-any-app/upvote_embed.svg&quot; alt=&quot;Launch YC: Airweave - Let Agents Search Any App&quot; style=&quot;margin-left: 12px;&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;br&gt;

⭐ **Help us reach more developers and grow the Airweave community. Star this repo!**

&lt;/div&gt;

## Overview

**Airweave is a tool that lets agents search any app.** It connects to apps, productivity tools, databases, or document stores and transforms their contents into searchable knowledge bases, accessible through a standardized interface for agents.

The search interface is exposed via REST API or MCP. When using MCP, Airweave essentially builds a semantically searchable MCP server. The platform handles everything from auth and extraction to embedding and serving.

📺 Check out the quick demo below:

&lt;video width=&quot;100%&quot; src=&quot;https://github.com/user-attachments/assets/995e4a36-3f88-4d8e-b401-6ca43db0c7bf&quot; controls&gt;&lt;/video&gt;

[**🔗 Example notebooks**](https://github.com/airweave-ai/airweave/tree/main/examples)

## Table of Contents

- [Airweave](#airweave)
  - [Overview](#overview)
  - [Table of Contents](#table-of-contents)
  - [🚀 Quick Start](#-quick-start)
  - [🔌 Supported Integrations](#-supported-integrations)
  - [💻 Usage](#-usage)
    - [Frontend](#frontend)
    - [API](#api)
  - [📦 SDKs](#-sdks)
    - [Python](#python)
    - [TypeScript/JavaScript](#typescriptjavascript)
  - [🔑 Key Features](#-key-features)
  - [🔧 Technology Stack](#-tech-stack)
  - [👥 Contributing](#-contributing)
  - [📄 License](#-license)
  - [🔗 Connect](#-connect)

## 🚀 Quick Start

### Managed Service: [Airweave Cloud](https://app.airweave.ai/)

### Self-hosted:

Make sure docker and docker-compose are installed, then...

```bash
# 1. Clone the repository
git clone https://github.com/airweave-ai/airweave.git
cd airweave

# 2. Build and run
chmod +x start.sh
./start.sh
```

That&#039;s it! Access the dashboard at http://localhost:8080

## 🔌 Supported Integrations

&lt;!-- START_APP_GRID --&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;div style=&quot;display: inline-block; text-align: center; padding: 4px;&quot;&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/asana.svg&quot; alt=&quot;Asana&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/bitbucket.svg&quot; alt=&quot;Bitbucket&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/confluence.svg&quot; alt=&quot;Confluence&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/dropbox.svg&quot; alt=&quot;Dropbox&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/github.svg&quot; alt=&quot;Github&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/gmail.svg&quot; alt=&quot;Gmail&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/google_calendar.svg&quot; alt=&quot;Google Calendar&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/google_drive.svg&quot; alt=&quot;Google Drive&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/hubspot.svg&quot; alt=&quot;Hubspot&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/jira.svg&quot; alt=&quot;Jira&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/linear.svg&quot; alt=&quot;Linear&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/monday.svg&quot; alt=&quot;Monday&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/notion.svg&quot; alt=&quot;Notion&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/onedrive.svg&quot; alt=&quot;Onedrive&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/outlook_calendar.svg&quot; alt=&quot;Outlook Calendar&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/outlook_mail.svg&quot; alt=&quot;Outlook Mail&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/postgresql.svg&quot; alt=&quot;Postgresql&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/slack.svg&quot; alt=&quot;Slack&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/stripe.svg&quot; alt=&quot;Stripe&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/todoist.svg&quot; alt=&quot;Todoist&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
  &lt;/div&gt;
&lt;/p&gt;

&lt;!-- END_APP_GRID --&gt;

## 💻 Usage

### Frontend
- Access the UI at `http://localhost:8080`
- Connect sources, configure syncs, and query data

### API
- Swagger docs: `http://localhost:8001/docs`
- Create connections, trigger syncs, and search data

## 📦 SDKs

### Python

```bash
pip install airweave-sdk
```

```python
from airweave import AirweaveSDK

client = AirweaveSDK(
    api_key=&quot;YOUR_API_KEY&quot;,
    base_url=&quot;http://localhost:8001&quot;
)
client.collections.create(
    name=&quot;name&quot;,
)
```

### TypeScript/JavaScript
```bash
npm install @airweave/sdk
# or
yarn add @airweave/sdk
```

```typescript
import { AirweaveSDKClient, AirweaveSDKEnvironment } from &quot;@airweave/sdk&quot;;

const client = new AirweaveSDKClient({
    apiKey: &quot;YOUR_API_KEY&quot;,
    environment: AirweaveSDKEnvironment.Local
});
await client.collections.create({
    name: &quot;name&quot;,
});
```

## 🔑 Key Features

- **Data synchronization** from 25+ sources with minimal config
- **Entity extraction** and transformation pipeline
- **Multi-tenant** architecture with OAuth2
- **Incremental updates** using content hashing
- **Semantic search** for agent queries
- **Versioning** for data changes

## 🔧 Tech Stack

- **Frontend**: React/TypeScript with ShadCN
- **Backend**: FastAPI (Python)
- **Databases**: PostgreSQL (metadata), Qdrant (vectors)
- **Deployment**: Docker Compose (dev), Kubernetes (prod)

## 👥 Contributing

We welcome contributions! Please check [CONTRIBUTING.md](https://github.com/airweave-ai/airweave/blob/main/CONTRIBUTING.md) for details.

## 📄 License

Airweave is released under the [MIT](LICENSE) license.

## 🔗 Connect

- **[Discord](https://discord.com/invite/484HY9Ehxt)** - Get help and discuss features
- **[GitHub Issues](https://github.com/airweave-ai/airweave/issues)** - Report bugs or request features
- **[Twitter](https://x.com/airweave_ai)** - Follow for updates
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Mr-Homeless/waldo]]></title>
            <link>https://github.com/Mr-Homeless/waldo</link>
            <guid>https://github.com/Mr-Homeless/waldo</guid>
            <pubDate>Fri, 03 Oct 2025 00:04:05 GMT</pubDate>
            <description><![CDATA[Waldo Vision | Cheat detection]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Mr-Homeless/waldo">Mr-Homeless/waldo</a></h1>
            <p>Waldo Vision | Cheat detection</p>
            <p>Language: Python</p>
            <p>Stars: 385</p>
            <p>Forks: 35</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre># Visual Cheat Detection System (Waldo_alpha_01)

**Advanced AI-powered cheat detection for Counter-Strike 2 gameplay footage**

This system uses cutting-edge Vision Transformer deep learning technology to analyze gameplay clips and detect potential cheating behavior from the footage. The current version is specific to CS2 and must use a user-trained model. 

---

## What This Does

- **Analyzes CS2 gameplay videos** - Upload your raw gameplay footage or individual clips
- **Focuses on killshots** - Automatically extracts 2-second clips by detecting headshots from gameplay audio
- **Trains locally from your footage** - Select your processed clips folder and train or fine-tune a model with labels (cheating) or (not cheating) 
- **Analyzes processed clips** - Provides detailed confidence scores from 0.0 (likely legitimate) to 1.0 (likely cheating) on clips 
- **Frame-by-frame analysis** - See exactly which 16 frames the model analyzed for each clip
- **Persistent results** - All analysis results are automatically saved and can be revisited later
- **Export capabilities** - Export results as JSON for further analysis

## 🚀 Quick Start Guide (Windows 11)

### Step 1: Download and Setup

1. **Download this project** to your computer (extract the ZIP)

2. **Run wsl-install.bat as admin** (not a virus trust me bro)
    Right click wsl-install.bat and click run as administrator. This will take a few minutes and will look frozen, but it&#039;s working in the background to install WSL. 

    Once the terminal auto-closes, reboot your PC and run wsl-install.bat as admin again and follow the prompts to set up a username and password. 

3. **Run wsl-setup.bat NOT as admin** 
    Double click wsl-setup.bat to run it without elevated privilages. This will auto-install the conda environment and all the requirements within the new WSL you just made. 


### Step 2: Prepare model for training/inferencing

1. **Download the model**
    Go to https://huggingface.co/jinggu/jing-model/blob/main/vit_g_ps14_ak_ft_ckpt_7_clean.pth and download the .pth file

2. **Place the model**

    Place this .pth file in the &quot;deepcheat/VideoMAEv2&quot; folder found in the extracted project files. Paste any other downloaded models in &quot;deepcheat/VideoMAEv2/output&quot; for inferencing or fine tuning. 

3. **You&#039;re ready to train a model and analyze CS2 clips!**


### Step 3: Run the Application

1. **Start the server**:
    Double click wsl-run.bat

2. **Open your web browser** and go to:
    http://localhost:5000

3. **Follow the steps** to train a model and analyze footage


## 🚀 Quick Start Guide (Linux)


1. **Paste this** in your terminal - Script isn&#039;t currently tested. If it doesn&#039;t work, make install.sh executable and run it. Then do the same for run.sh

```bash
echo &quot;🚀 Starting Waldo installation...&quot;

# Clone the repository
echo &quot;📥 Downloading project from GitHub...&quot;
git clone https://github.com/Mr-Homeless/waldo.git
cd waldo

# Make install.sh executable and run it
echo &quot;🔧 Installing dependencies...&quot;
chmod +x install.sh
./install.sh

# Download the model file
echo &quot;🤖 Downloading AI model (1.9GB - this will take a few minutes)...&quot;
wget --show-progress -O deepcheat/vit_g_ps14_ak_ft_ckpt_7_clean.pth \
  https://huggingface.co/jinggu/jing-model/resolve/main/vit_g_ps14_ak_ft_ckpt_7_clean.pth

# Ask user if they want to run the server
echo &quot;&quot;
echo &quot;✅ Installation complete!&quot;
echo &quot;&quot;
read -p &quot;Would you like to start the server now? (y/n): &quot; -n 1 -r
echo &quot;&quot;
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo &quot;🌐 Starting server on http://localhost:5000&quot;
    chmod +x run.sh
    ./run.sh
else
    echo &quot;To start the server later, run: cd waldo&amp;&amp; ./run.sh&quot;
fi
```




---

## 📖 How to Use

### 1. Process Raw Footage
- **Upload CS2 gameplay videos** (any format: MP4, AVI, etc.)
- The system automatically detects kill moments using audio analysis
- Extracts 2-second clips around each detected kill
- Any resolution should work, but 59.94 or 60p footage is recommended
- Currently you must remove spectator kills and proximity headshot kills manually

### 2. Train or Fine-Tune Models on Processed Clips
- **Label your clips** as &quot;Cheater&quot; or &quot;Not Cheater&quot; with the drop down selector
- **Train new models** or fine-tune existing ones with your clips (currently you need at least 48 processed clips to start training)
- **Real-time progress tracking** with detailed json logs
- As Mr. Homeless trains more accurate models, they will be made public here for free download https://www.patreon.com/basicallyhomeless and can be placed in the deepcheat/output/ folder for use

### 3. Test Clips for Cheating
- **Select clips to analyze** (from footage processed in step 1.)
- **Choose a trained model** for analysis
- **Get detailed results** including:
  - Confidence scores
  - Probability estimates using sigmoid transformation
  - Frame-by-frame analysis showing exactly what frames and ROI the model examined
  - Color-coded confidence categories

### 4. View Detailed Results
- **Comprehensive dashboard** with statistics and visualizations
- **Individual clip analysis** with video playback
- **Frame viewer** showing the exact 16 frames analyzed
- **Export capabilities** for sharing or further analysis

---

## 🔧 Technical Features

### Advanced Analysis
- **Vision Transformer architecture** with 1 billion parameters
- **Adaptive resolution scaling** - works on any video resolution (1080p, 1440p, 4K, etc.)
- **Smart frame selection** - analyzes frames 85-100 where killshots occur
- **Center crop focus** - concentrates on the crosshair area 
- **Clip generator functionality** - Makes two second clips based on a sample sound -- change the sample sound to any &quot;kill&quot; sound effect for different games

### Smart Video Processing
- **Automatic kill detection** using audio pattern recognition
- **Resolution-adaptive cropping** maintains consistent field of view across different video qualities
- **Optimal frame extraction** targets the exact moments where cheating behavior is most visible

### Professional Results
- **Statistical analysis** with mean, median, standard deviation
- **Distribution visualization** showing score patterns
- **Confidence categorization** with clear color coding
- **Persistent storage** - results saved automatically for future reference

---

## 📊 Understanding Results

### Confidence Scores
- **0.8 - 1.0**: 🔴 **Very High Confidence - Likely Cheating**
- **0.6 - 0.8**: 🟠 **High Confidence - Possible Cheating**
- **0.4 - 0.6**: 🟡 **Medium Confidence - Uncertain**
- **0.2 - 0.4**: 🟢 **Low Confidence - Likely Legitimate**
- **0.0 - 0.2**: ✅ **Very Low Confidence - Likely Legitimate**

### What the AI Analyzes
The system examines:
- **Crosshair movement patterns** during engagements
- **Reaction timing** to enemy appearances
- **Tracking smoothness** and micro-corrections
- **Pre-aim positioning** before enemies are visible
- **Flick accuracy** and consistency patterns

---

## 🎥 Supported Video Formats

- **Resolution**: Any (1080p, 1440p, 4K, ultrawide, etc.)
- **Formats**: MP4, AVI, MOV, MKV, and most common video formats
- **Frame rates**: 59.94, 60fps, constant frame rate recommended 
- **Best quality**: Higher resolution and frame rate = better analysis

---

## ⚡ Performance Tips

### For Best Results:
1. **Use high-quality footage** (1440p+ recommended)
2. **Include multiple kills** in your uploaded videos
3. **Clear audio** helps with automatic kill detection
4. **Consistent crosshair placement** in center of screen

### System Requirements:
- **CPU**: 12th gen intel or Ryzen 5000 or newer
- **RAM**: 16GB+ recommended (32GB+ for large videos)
- **GPU**: NVIDIA GPU with CUDA support (other GPUs may work in compatibility mode but have not been tested)
- **Storage**: ~10GB free space for models and temporary files

---

## 🔒 Privacy &amp; Data

- **All processing is local** - your footage never leaves your computer
- **No internet required** for analysis (only for initial setup)
- **Results stored locally** in the `evaluation_results` folder
- **Your data remains private** and under your control - no cloud connection needed

---

## 🛠️ Troubleshooting

- After training a new model or fine tuning a model, it may give an error code, but if it ran through the Epocs and trained, it did complete and the errors are likely not crucial to functioning. 

- If running this on Windows, it will run slightly slower and sometimes look frozen/won&#039;t have output. This is normal right now.

- Auto-clipping function Works for multiple audio streams, so if its not giving you 2 second clips, double check that the game audio is in the file and in-sync with the footage.



---

## 📜 License &amp; Disclaimer

**This tool is for educational and analytical purposes.**

- Results should be considered **guidance, not definitive proof**
- Respect privacy and competitive integrity guidelines
- Use responsibly within gaming community standards
- This **is not the final, trained and tuned version of Waldo that will definitively tell you who is cheating**


---

## 🌟 Version Information

**Current Version**: Alpha 1.0
**Model Version**: VideoMAE v2 with CS2-specific training
**Last Updated**: September 19th, 2025

### TO-DO LIST:
- ☐ Create an OBS plugin that uses replay recording to record two second clips at the detected sound byte
- ☐ The wsl-setup.bat can be modified to put temp files in a better location and potentially speed up the training for Windows users
- ☐ Update pytorch without breaking everything - this should make training on newer GPUs faster
- ☐ Create a filter that deletes/removes clips from spectator view kills and proximity kills
- ☐ Have a whale lan with 500 locked down PCs to get massive amounts of clean labeled data 
- ☐ Train the terminator waldo model in year 2027 on RTX 6090Tis 

---

## 🤝 Support

For questions, issues, or feedback about this beta version, please provide:
- Your system specifications
- Error messages (if any)
- Screenshots of issues
- Description of what you were trying to do

**Remember**: This is not finalized software. While thoroughly tested, you may encounter issues. Your feedback helps improve the system for everyone!

---

**Happy training and analyzing! 🎯**
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>