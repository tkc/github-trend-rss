<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Wed, 04 Jun 2025 00:04:44 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[nautechsystems/nautilus_trader]]></title>
            <link>https://github.com/nautechsystems/nautilus_trader</link>
            <guid>https://github.com/nautechsystems/nautilus_trader</guid>
            <pubDate>Wed, 04 Jun 2025 00:04:44 GMT</pubDate>
            <description><![CDATA[A high-performance algorithmic trading platform and event-driven backtester]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nautechsystems/nautilus_trader">nautechsystems/nautilus_trader</a></h1>
            <p>A high-performance algorithmic trading platform and event-driven backtester</p>
            <p>Language: Python</p>
            <p>Stars: 7,033</p>
            <p>Forks: 936</p>
            <p>Stars today: 380 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader-logo.png&quot; width=&quot;500&quot;&gt;

[![codecov](https://codecov.io/gh/nautechsystems/nautilus_trader/branch/master/graph/badge.svg?token=DXO9QQI40H)](https://codecov.io/gh/nautechsystems/nautilus_trader)
[![codspeed](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/nautechsystems/nautilus_trader)
![pythons](https://img.shields.io/pypi/pyversions/nautilus_trader)
![pypi-version](https://img.shields.io/pypi/v/nautilus_trader)
![pypi-format](https://img.shields.io/pypi/format/nautilus_trader?color=blue)
[![Downloads](https://pepy.tech/badge/nautilus-trader)](https://pepy.tech/project/nautilus-trader)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/NautilusTrader)

| Branch    | Version                                                                                                                                                                                                                     | Status                                                                                                                                                                                            |
| :-------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `master`  | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fmaster%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html)  | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |
| `nightly` | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fnightly%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html) | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |
| `develop` | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fdevelop%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html) | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=develop)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |

| Platform           | Rust    | Python     |
| :----------------- | :------ | :--------- |
| `Linux (x86_64)`   | 1.87.0+ | 3.11-3.13  |
| `Linux (ARM64)`    | 1.87.0+ | 3.11-3.13  |
| `macOS (ARM64)`    | 1.87.0+ | 3.11-3.13  |
| `Windows (x86_64)` | 1.87.0+ | 3.11-3.13  |

- **Docs**: &lt;https://nautilustrader.io/docs/&gt;
- **Website**: &lt;https://nautilustrader.io&gt;
- **Support**: [support@nautilustrader.io](mailto:support@nautilustrader.io)

## Introduction

NautilusTrader is an open-source, high-performance, production-grade algorithmic trading platform,
providing quantitative traders with the ability to backtest portfolios of automated trading strategies
on historical data with an event-driven engine, and also deploy those same strategies live, with no code changes.

The platform is *AI-first*, designed to develop and deploy algorithmic trading strategies within a highly performant
and robust Python-native environment. This helps to address the parity challenge of keeping the Python research/backtest
environment consistent with the production live trading environment.

NautilusTrader&#039;s design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting Python-native, mission-critical, trading system backtesting
and live deployment workloads.

The platform is also universal, and asset-class-agnostic ‚Äî  with any REST API or WebSocket feed able to be integrated via modular
adapters. It supports high-frequency trading across a wide range of asset classes and instrument types
including FX, Equities, Futures, Options, Crypto and Betting, enabling seamless operations across multiple venues simultaneously.

![nautilus-trader](https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader.png &quot;nautilus-trader&quot;)

## Features

- **Fast**: Core is written in Rust with asynchronous networking using [tokio](https://crates.io/crates/tokio).
- **Reliable**: Rust-powered type- and thread-safety, with optional Redis-backed state persistence.
- **Portable**: OS independent, runs on Linux, macOS, and Windows. Deploy using Docker.
- **Flexible**: Modular adapters mean any REST API or WebSocket feed can be integrated.
- **Advanced**: Time in force `IOC`, `FOK`, `GTC`, `GTD`, `DAY`, `AT_THE_OPEN`, `AT_THE_CLOSE`, advanced order types and conditional triggers. Execution instructions `post-only`, `reduce-only`, and icebergs. Contingency orders including `OCO`, `OUO`, `OTO`.
- **Customizable**: Add user-defined custom components, or assemble entire systems from scratch leveraging the [cache](https://nautilustrader.io/docs/latest/concepts/cache) and [message bus](https://nautilustrader.io/docs/latest/concepts/message_bus).
- **Backtesting**: Run with multiple venues, instruments and strategies simultaneously using historical quote tick, trade tick, bar, order book and custom data with nanosecond resolution.
- **Live**: Use identical strategy implementations between backtesting and live deployments.
- **Multi-venue**: Multiple venue capabilities facilitate market-making and statistical arbitrage strategies.
- **AI Training**: Backtest engine fast enough to be used to train AI trading agents (RL/ES).

![Alt text](https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-art.png &quot;nautilus&quot;)

&gt; *nautilus - from ancient Greek &#039;sailor&#039; and naus &#039;ship&#039;.*
&gt;
&gt; *The nautilus shell consists of modular chambers with a growth factor which approximates a logarithmic spiral.
&gt; The idea is that this can be translated to the aesthetics of design and architecture.*

## Why NautilusTrader?

- **Highly performant event-driven Python**: Native binary core components.
- **Parity between backtesting and live trading**: Identical strategy code.
- **Reduced operational risk**: Enhanced risk management functionality, logical accuracy, and type safety.
- **Highly extendable**: Message bus, custom components and actors, custom data, custom adapters.

Traditionally, trading strategy research and backtesting might be conducted in Python
using vectorized methods, with the strategy then needing to be reimplemented in a more event-driven way
using C++, C#, Java or other statically typed language(s). The reasoning here is that vectorized backtesting code cannot
express the granular time and event dependent complexity of real-time trading, where compiled languages have
proven to be more suitable due to their inherently higher performance, and type safety.

One of the key advantages of NautilusTrader here, is that this reimplementation step is now circumvented - as the critical core components of the platform
have all been written entirely in [Rust](https://www.rust-lang.org/) or [Cython](https://cython.org/).
This means we&#039;re using the right tools for the job, where systems programming languages compile performant binaries,
with CPython C extension modules then able to offer a Python-native environment, suitable for professional quantitative traders and trading firms.

## Why Python?

Python was originally created decades ago as a simple scripting language with a clean straightforward syntax.
It has since evolved into a fully fledged general purpose object-oriented programming language.
Based on the TIOBE index, Python is currently the most popular programming language in the world.
Not only that, Python has become the *de facto lingua franca* of data science, machine learning, and artificial intelligence.

developer/user communities.
However, Python has performance and typing limitations for large-scale, latency-sensitive systems. Cython addresses many of these issues by introducing static typing into Python&#039;s rich ecosystem of libraries and communities.

## Why Rust?

[Rust](https://www.rust-lang.org/) is a multi-paradigm programming language designed for performance and safety, especially safe
concurrency. Rust is &quot;blazingly fast&quot; and memory-efficient (comparable to C and C++) with no garbage collector.
It can power mission-critical systems, run on embedded devices, and easily integrates with other languages.

Rust‚Äôs rich type system and ownership model guarantees memory-safety and thread-safety deterministically ‚Äî
eliminating many classes of bugs at compile-time.

The project increasingly utilizes Rust for core performance-critical components. Python bindings are implemented via Cython and [PyO3](https://pyo3.rs)‚Äîno Rust toolchain is required at install time.

This project makes the [Soundness Pledge](https://raphlinus.github.io/rust/2020/01/18/soundness-pledge.html):

&gt; ‚ÄúThe intent of this project is to be free of soundness bugs.
&gt; The developers will do their best to avoid them, and welcome help in analyzing and fixing them.‚Äù

&gt; [!NOTE]
&gt;
&gt; **MSRV:** NautilusTrader relies heavily on improvements in the Rust language and compiler.
&gt; As a result, the Minimum Supported Rust Version (MSRV) is generally equal to the latest stable release of Rust.

## Integrations

NautilusTrader is modularly designed to work with *adapters*, enabling connectivity to trading venues
and data providers by translating their raw APIs into a unified interface and normalized domain model.

The following integrations are currently supported; see [docs/integrations/](https://nautilustrader.io/docs/latest/integrations/) for details:

| Name                                                                         | ID                    | Type                    | Status                                                  | Docs                                        |
| :--------------------------------------------------------------------------- | :-------------------- | :---------------------- | :------------------------------------------------------ | :------------------------------------------ |
| [Betfair](https://betfair.com)                                               | `BETFAIR`             | Sports Betting Exchange | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/betfair.md)       |
| [Binance](https://binance.com)                                               | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/binance.md)       |
| [Binance US](https://binance.us)                                             | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/binance.md)       |
| [Binance Futures](https://www.binance.com/en/futures)                        | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/binance.md)       |
| [Bybit](https://www.bybit.com)                                               | `BYBIT`               | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/bybit.md)         |
| [Coinbase International](https://www.coinbase.com/en/international-exchange) | `COINBASE_INTX`       | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/coinbase_intx.md) |
| [Databento](https://databento.com)                                           | `DATABENTO`           | Data Provider           | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/databento.md)     |
| [dYdX](https://dydx.exchange/)                                               | `DYDX`                | Crypto Exchange (DEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/dydx.md)          |
| [Interactive Brokers](https://www.interactivebrokers.com)                    | `INTERACTIVE_BROKERS` | Brokerage (multi-venue) | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/ib.md)            |
| [OKX](https://okx.com)                                                       | `OKX`                 | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/building-orange) | [Guide](docs/integrations/okx.md)           |
| [Polymarket](https://polymarket.com)                                         | `POLYMARKET`          | Prediction Market (DEX) | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/polymarket.md)    |
| [Tardis](https://tardis.dev)                                                 | `TARDIS`              | Crypto Data Provider    | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/tardis.md)        |

- **ID**: The default client ID for the integrations adapter clients.
- **Type**: The type of integration (often the venue type).

### Status

- `building`: Under construction and likely not in a usable state.
- `beta`: Completed to a minimally working state and in a beta testing phase.
- `stable`: Stabilized feature set and API, the integration has been tested by both developers and users to a reasonable level (some bugs may still remain).

See the [Integrations](https://nautilustrader.io/docs/latest/integrations/index.html) documentation for further details.

## Versioning and releases

**NautilusTrader is still under active development**. Some features may be incomplete, and while
the API is becoming more stable, breaking changes can occur between releases.
We strive to document these changes in the release notes on a **best-effort basis**.

We aim to follow a **bi-weekly release schedule**, though experimental or larger features may cause delays.

### Branches

We aim to maintain a stable, passing build across all branches.

- `master`: Reflects the source code for the latest released version; recommended for production use.
- `nightly`: Daily snapshots of the `develop` branch for early testing; merged at **14:00 UTC** or on demand.
- `develop`: Active development branch for contributors and feature work.

&gt; [!NOTE]
&gt;
&gt; Our [roadmap](/ROADMAP.md) aims to achieve a **stable API for version 2.x** (likely after the Rust port).
&gt; Once this milestone is reached, we plan to implement a formal deprecation process for any API changes.
&gt; This approach allows us to maintain a rapid development pace for now.

## Precision mode

NautilusTrader supports two precision modes for its core value types (`Price`, `Quantity`, `Money`),
which differ in their internal bit-width and maximum decimal precision.

- **High-precision**: 128-bit integers with up to 16 decimals of precision, and a larger value range.
- **Standard-precision**: 64-bit integers with up to 9 decimals of precision, and a smaller value range.

&gt; [!NOTE]
&gt;
&gt; By default, the official Python wheels **ship** in high-precision (128-bit) mode on Linux and macOS.
&gt; On Windows, only standard-precision (64-bit) is available due to the lack of native 128-bit integer support.
&gt; For the Rust crates, the default is standard-precision unless you explicitly enable the `high-precision` feature flag.

See the [Installation Guide](https://nautilustrader.io/docs/latest/getting_started/installation) for further details.

**Rust feature flag**: To enable high-precision mode in Rust, add the `high-precision` feature to your Cargo.toml:

```toml
[dependencies]
nautilus_model = { version = &quot;*&quot;, features = [&quot;high-precision&quot;] }
```

## Installation

We recommend using the latest supported version of Python and installing [nautilus_trader](https://pypi.org/project/nautilus_trader/) inside a virtual environment to isolate dependencies.

**There are two supported ways to install**:

1. Pre-built binary wheel from PyPI *or* the Nautech Systems package index.
2. Build from source.

&gt; [!TIP]
&gt;
&gt; We highly recommend installing using the [uv](https://docs.astral.sh/uv) package manager with a &quot;vanilla&quot; CPython.
&gt;
&gt; Conda and other Python distributions *may* work but aren‚Äôt officially supported.

### From PyPI

To install the latest binary wheel (or sdist package) from PyPI using Python&#039;s pip package manager:

```bash
pip install -U nautilus_trader
```

### From the Nautech Systems package index

The Nautech Systems package index (`packages.nautechsystems.io`) is [PEP-503](https://peps.python.org/pep-0503/) compliant and hosts both stable and development binary wheels for `nautilus_trader`.
This enables users to install either the latest stable release or pre-release versions for testing.

#### Stable wheels

Stable wheels correspond to official releases of `nautilus_trader` on PyPI, and use standard versioning.

To install the latest stable release:

```bash
pip install -U nautilus_trader --index-url=https://packages.nautechsystems.io/simple
```

#### Development wheels

Development wheels are published from both the `nightly` and `develop` branches,
allowing users to test features and fixes ahead of stable releases.

**Note**: Wheels from the `develop` branch are only built for the Linux x86_64 platform to save time
and compute resources, while `nightly` wheels support additional platforms as shown below.

| Platform           | Nightly | Develop |
| :----------------- | :------ | :------ |
| `Linux (x86_64)`   | ‚úì       | ‚úì       |
| `Linux (ARM64)`    | ‚úì       | -       |
| `macOS (ARM64)`    | ‚úì       | -       |
| `Windows (x86_64)` | ‚úì       | -       |

This process also helps preserve compute resources and ensures easy access to the exact binaries tested in CI pipelines,
while adhering to [PEP-440](https://peps.python.org/pep-0440/) versioning standards:

- `develop` wheels use the version format `dev{date}+{build_number}` (e.g., `1.208.0.dev20241212+7001`).
- `nightly` wheels use the version format `a{date}` (alpha) (e.g., `1.208.0a20241212`).

&gt; [!WARNING]
&gt;
&gt; We don&#039;t recommend using development wheels in production environments, such as live trading controlling real capital.

#### Installation commands

By default, pip installs the latest stable release. Adding the `--pre` flag ensures that pre-release versions, including development wheels, are considered.

To install the latest available pre-release (including development wheels):

```bash
pip install -U nautilus_trader --pre --index-url=https://packages.nautechsystems.io/simple
```

To install a specific development wheel (e.g., `1.208.0a20241212` for December 12, 2024):

```bash
pip install nautilus_trader==1.208.0a20241212 --index-url=https://packages.nautechsystems.io/simple
```

#### Available versions

You can view all available versions of `nautilus_trader` on the [package index](https://packages.nautechsystems.io/simple/nautilus-trader/index.html).

To programmatically fetch and list available versions:

```bash
curl -s https://packages.nautechsystems.io/simple/nautilus-trader/index.html | grep -oP &#039;(?&lt;=&lt;a href=&quot;)[^&quot;]+(?=&quot;)&#039; | awk -F&#039;#&#039; &#039;{print $1}&#039; | sort
```

#### Branch updates

- `develop` branch wheels (`.dev`): Are built and published continuously with every merged commit.
- `nightly` branch wheels (`a`): Are built and published daily when `develop` branch is automatic

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[frdel/agent-zero]]></title>
            <link>https://github.com/frdel/agent-zero</link>
            <guid>https://github.com/frdel/agent-zero</guid>
            <pubDate>Wed, 04 Jun 2025 00:04:43 GMT</pubDate>
            <description><![CDATA[Agent Zero AI framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/frdel/agent-zero">frdel/agent-zero</a></h1>
            <p>Agent Zero AI framework</p>
            <p>Language: Python</p>
            <p>Stars: 8,074</p>
            <p>Forks: 1,641</p>
            <p>Stars today: 372 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# `Agent Zero`

[![Agent Zero Website](https://img.shields.io/badge/Website-agent--zero.ai-0A192F?style=for-the-badge&amp;logo=vercel&amp;logoColor=white)](https://agent-zero.ai) [![Thanks to Sponsors](https://img.shields.io/badge/GitHub%20Sponsors-Thanks%20to%20Sponsors-FF69B4?style=for-the-badge&amp;logo=githubsponsors&amp;logoColor=white)](https://github.com/sponsors/frdel) [![Follow on X](https://img.shields.io/badge/X-Follow-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white)](https://x.com/Agent0ai) [![Join our Discord](https://img.shields.io/badge/Discord-Join%20our%20server-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.gg/B8KZKNsPpj) [![Subscribe on YouTube](https://img.shields.io/badge/YouTube-Subscribe-red?style=for-the-badge&amp;logo=youtube&amp;logoColor=white)](https://www.youtube.com/@AgentZeroFW) [![Connect on LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white)](https://www.linkedin.com/in/jan-tomasek/) [![Follow on Warpcast](https://img.shields.io/badge/Warpcast-Follow-5A32F3?style=for-the-badge)](https://warpcast.com/agent-zero)

[Introduction](#a-personal-organic-agentic-framework-that-grows-and-learns-with-you) ‚Ä¢
[Installation](./docs/installation.md) ‚Ä¢
[Hacking Edition](#hacking-edition) ‚Ä¢
[How to update](./docs/installation.md#how-to-update-agent-zero) ‚Ä¢
[Documentation](./docs/README.md) ‚Ä¢
[Usage](./docs/usage.md)

&lt;/div&gt;


[![Showcase](/docs/res/showcase-thumb.png)](https://youtu.be/lazLNcEYsiQ)





## A personal, organic agentic framework that grows and learns with you

- Agent Zero is not a predefined agentic framework. It is designed to be dynamic, organically growing, and learning as you use it.
- Agent Zero is fully transparent, readable, comprehensible, customizable, and interactive.
- Agent Zero uses the computer as a tool to accomplish its (your) tasks.

# üí° Key Features

1. **General-purpose Assistant**

- Agent Zero is not pre-programmed for specific tasks (but can be). It is meant to be a general-purpose personal assistant. Give it a task, and it will gather information, execute commands and code, cooperate with other agent instances, and do its best to accomplish it.
- It has a persistent memory, allowing it to memorize previous solutions, code, facts, instructions, etc., to solve tasks faster and more reliably in the future.

![Agent 0 Working](/docs/res/ui-screen-2.png)

2. **Computer as a Tool**

- Agent Zero uses the operating system as a tool to accomplish its tasks. It has no single-purpose tools pre-programmed. Instead, it can write its own code and use the terminal to create and use its own tools as needed.
- The only default tools in its arsenal are online search, memory features, communication (with the user and other agents), and code/terminal execution. Everything else is created by the agent itself or can be extended by the user.
- Tool usage functionality has been developed from scratch to be the most compatible and reliable, even with very small models.
- **Default Tools:** Agent Zero includes tools like knowledge, webpage content, code execution, and communication.
- **Creating Custom Tools:** Extend Agent Zero&#039;s functionality by creating your own custom tools.
- **Instruments:** Instruments are a new type of tool that allow you to create custom functions and procedures that can be called by Agent Zero.

3. **Multi-agent Cooperation**

- Every agent has a superior agent giving it tasks and instructions. Every agent then reports back to its superior.
- In the case of the first agent in the chain (Agent 0), the superior is the human user; the agent sees no difference.
- Every agent can create its subordinate agent to help break down and solve subtasks. This helps all agents keep their context clean and focused.

![Multi-agent](docs/res/physics.png)
![Multi-agent 2](docs/res/physics-2.png)

4. **Completely Customizable and Extensible**

- Almost nothing in this framework is hard-coded. Nothing is hidden. Everything can be extended or changed by the user.
- The whole behavior is defined by a system prompt in the **prompts/default/agent.system.md** file. Change this prompt and change the framework dramatically.
- The framework does not guide or limit the agent in any way. There are no hard-coded rails that agents have to follow.
- Every prompt, every small message template sent to the agent in its communication loop can be found in the **prompts/** folder and changed.
- Every default tool can be found in the **python/tools/** folder and changed or copied to create new predefined tools.

![Prompts](/docs/res/prompts.png)

5. **Communication is Key**

- Give your agent a proper system prompt and instructions, and it can do miracles.
- Agents can communicate with their superiors and subordinates, asking questions, giving instructions, and providing guidance. Instruct your agents in the system prompt on how to communicate effectively.
- The terminal interface is real-time streamed and interactive. You can stop and intervene at any point. If you see your agent heading in the wrong direction, just stop and tell it right away.
- There is a lot of freedom in this framework. You can instruct your agents to regularly report back to superiors asking for permission to continue. You can instruct them to use point-scoring systems when deciding when to delegate subtasks. Superiors can double-check subordinates&#039; results and dispute. The possibilities are endless.

## üöÄ Things you can build with Agent Zero

- **Development Projects** - `&quot;Create a React dashboard with real-time data visualization&quot;`

- **Data Analysis** - `&quot;Analyze last quarter&#039;s NVIDIA sales data and create trend reports&quot;`

- **Content Creation** - `&quot;Write a technical blog post about microservices&quot;`

- **System Admin** - `&quot;Set up a monitoring system for our web servers&quot;`

- **Research** - `&quot;Gather and summarize five recent AI papers about CoT prompting&quot;`

# Hacking Edition
- Agent Zero also offers a Hacking Edition based on Kali linux with modified prompts for cybersecurity tasks
- The setup is the same as the regular version, just use the frdel/agent-zero-run:hacking image instead of frdel/agent-zero-run


# ‚öôÔ∏è Installation

Click to open a video to learn how to install Agent Zero:

[![Easy Installation guide](/docs/res/easy_ins_vid.png)](https://www.youtube.com/watch?v=L1_peV8szf8)

A detailed setup guide for Windows, macOS, and Linux with a video can be found in the Agent Zero Documentation at [this page](./docs/installation.md).

### ‚ö° Quick Start

```bash
# Pull and run with Docker

docker pull frdel/agent-zero-run
docker run -p 50001:80 frdel/agent-zero-run

# Visit http://localhost:50001 to start
```

## üê≥ Fully Dockerized, with Speech-to-Text and TTS

![Settings](docs/res/settings-page-ui.png)

- Customizable settings allow users to tailor the agent&#039;s behavior and responses to their needs.
- The Web UI output is very clean, fluid, colorful, readable, and interactive; nothing is hidden.
- You can load or save chats directly within the Web UI.
- The same output you see in the terminal is automatically saved to an HTML file in **logs/** folder for every session.

![Time example](/docs/res/time_example.jpg)

- Agent output is streamed in real-time, allowing users to read along and intervene at any time.
- No coding is required; only prompting and communication skills are necessary.
- With a solid system prompt, the framework is reliable even with small models, including precise tool usage.

## üëÄ Keep in Mind

1. **Agent Zero Can Be Dangerous!**

- With proper instruction, Agent Zero is capable of many things, even potentially dangerous actions concerning your computer, data, or accounts. Always run Agent Zero in an isolated environment (like Docker) and be careful what you wish for.

2. **Agent Zero Is Prompt-based.**

- The whole framework is guided by the **prompts/** folder. Agent guidelines, tool instructions, messages, utility AI functions, it&#039;s all there.


## üìö Read the Documentation

| Page | Description |
|-------|-------------|
| [Installation](./docs/installation.md) | Installation, setup and configuration |
| [Usage](./docs/usage.md) | Basic and advanced usage |
| [Architecture](./docs/architecture.md) | System design and components |
| [Contributing](./docs/contribution.md) | How to contribute |
| [Troubleshooting](./docs/troubleshooting.md) | Common issues and their solutions |

## Coming soon

- **MCP**
- **Knowledge and RAG Tools**

## üéØ Changelog

### v0.8.4.1
- Various bugfixes related to context management
- Message formatting improvements
- Scheduler improvements
- New model provider
- Input tool fix
- Compatibility and stability improvements

### v0.8.4
[Release video](https://youtu.be/QBh_h_D_E24)

- **Remote access (mobile)**

### v0.8.3.1
[Release video](https://youtu.be/AGNpQ3_GxFQ)

- **Automatic embedding**


### v0.8.3
[Release video](https://youtu.be/bPIZo0poalY)

- ***Planning and scheduling***

### v0.8.2
[Release video](https://youtu.be/xMUNynQ9x6Y)

- **Multitasking in terminal**
- **Chat names**

### v0.8.1
[Release video](https://youtu.be/quv145buW74)

- **Browser Agent**
- **UX Improvements**

### v0.8
[Release video](https://youtu.be/cHDCCSr1YRI)

- **Docker Runtime**
- **New Messages History and Summarization System**
- **Agent Behavior Change and Management**
- **Text-to-Speech (TTS) and Speech-to-Text (STT)**
- **Settings Page in Web UI**
- **SearXNG Integration Replacing Perplexity + DuckDuckGo**
- **File Browser Functionality**
- **KaTeX Math Visualization Support**
- **In-chat File Attachments**

### v0.7
[Release video](https://youtu.be/U_Gl0NPalKA)

- **Automatic Memory**
- **UI Improvements**
- **Instruments**
- **Extensions Framework**
- **Reflection Prompts**
- **Bug Fixes**

## ü§ù Community and Support

- [Join our Discord](https://discord.gg/B8KZKNsPpj) for live discussions or [visit our Skool Community](https://www.skool.com/agent-zero).
- [Follow our YouTube channel](https://www.youtube.com/@AgentZeroFW) for hands-on explanations and tutorials
- [Report Issues](https://github.com/frdel/agent-zero/issues) for bug fixes and features
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[donnemartin/system-design-primer]]></title>
            <link>https://github.com/donnemartin/system-design-primer</link>
            <guid>https://github.com/donnemartin/system-design-primer</guid>
            <pubDate>Wed, 04 Jun 2025 00:04:42 GMT</pubDate>
            <description><![CDATA[Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/donnemartin/system-design-primer">donnemartin/system-design-primer</a></h1>
            <p>Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.</p>
            <p>Language: Python</p>
            <p>Stars: 303,489</p>
            <p>Forks: 50,226</p>
            <p>Stars today: 860 stars today</p>
            <h2>README</h2><pre>*[English](README.md) ‚àô [Êó•Êú¨Ë™û](README-ja.md) ‚àô [ÁÆÄ‰Ωì‰∏≠Êñá](README-zh-Hans.md) ‚àô [ÁπÅÈ´î‰∏≠Êñá](README-zh-TW.md) | [ÿßŸÑÿπŸéÿ±Ÿéÿ®ŸêŸäŸéŸëÿ©‚Äé](https://github.com/donnemartin/system-design-primer/issues/170) ‚àô [‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ](https://github.com/donnemartin/system-design-primer/issues/220) ‚àô [Portugu√™s do Brasil](https://github.com/donnemartin/system-design-primer/issues/40) ‚àô [Deutsch](https://github.com/donnemartin/system-design-primer/issues/186) ‚àô [ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨](https://github.com/donnemartin/system-design-primer/issues/130) ‚àô [◊¢◊ë◊®◊ô◊™](https://github.com/donnemartin/system-design-primer/issues/272) ‚àô [Italiano](https://github.com/donnemartin/system-design-primer/issues/104) ‚àô [ÌïúÍµ≠Ïñ¥](https://github.com/donnemartin/system-design-primer/issues/102) ‚àô [ŸÅÿßÿ±ÿ≥€å](https://github.com/donnemartin/system-design-primer/issues/110) ‚àô [Polski](https://github.com/donnemartin/system-design-primer/issues/68) ‚àô [—Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫](https://github.com/donnemartin/system-design-primer/issues/87) ‚àô [Espa√±ol](https://github.com/donnemartin/system-design-primer/issues/136) ‚àô [‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢](https://github.com/donnemartin/system-design-primer/issues/187) ‚àô [T√ºrk√ße](https://github.com/donnemartin/system-design-primer/issues/39) ‚àô [ti·∫øng Vi·ªát](https://github.com/donnemartin/system-design-primer/issues/127) ‚àô [Fran√ßais](https://github.com/donnemartin/system-design-primer/issues/250) | [Add Translation](https://github.com/donnemartin/system-design-primer/issues/28)*

**Help [translate](TRANSLATIONS.md) this guide!**

# The System Design Primer

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/jj3A5N8.png&quot;&gt;
  &lt;br/&gt;
&lt;/p&gt;

## Motivation

&gt; Learn how to design large-scale systems.
&gt;
&gt; Prep for the system design interview.

### Learn how to design large-scale systems

Learning how to design scalable systems will help you become a better engineer.

System design is a broad topic.  There is a **vast amount of resources scattered throughout the web** on system design principles.

This repo is an **organized collection** of resources to help you learn how to build systems at scale.

### Learn from the open source community

This is a continually updated, open source project.

[Contributions](#contributing) are welcome!

### Prep for the system design interview

In addition to coding interviews, system design is a **required component** of the **technical interview process** at many tech companies.

**Practice common system design interview questions** and **compare** your results with **sample solutions**: discussions, code, and diagrams.

Additional topics for interview prep:

* [Study guide](#study-guide)
* [How to approach a system design interview question](#how-to-approach-a-system-design-interview-question)
* [System design interview questions, **with solutions**](#system-design-interview-questions-with-solutions)
* [Object-oriented design interview questions, **with solutions**](#object-oriented-design-interview-questions-with-solutions)
* [Additional system design interview questions](#additional-system-design-interview-questions)

## Anki flashcards

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/zdCAkB3.png&quot;&gt;
  &lt;br/&gt;
&lt;/p&gt;

The provided [Anki flashcard decks](https://apps.ankiweb.net/) use spaced repetition to help you retain key system design concepts.

* [System design deck](https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design.apkg)
* [System design exercises deck](https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design%20Exercises.apkg)
* [Object oriented design exercises deck](https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/OO%20Design.apkg)

Great for use while on-the-go.

### Coding Resource: Interactive Coding Challenges

Looking for resources to help you prep for the [**Coding Interview**](https://github.com/donnemartin/interactive-coding-challenges)?

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/b4YtAEN.png&quot;&gt;
  &lt;br/&gt;
&lt;/p&gt;

Check out the sister repo [**Interactive Coding Challenges**](https://github.com/donnemartin/interactive-coding-challenges), which contains an additional Anki deck:

* [Coding deck](https://github.com/donnemartin/interactive-coding-challenges/tree/master/anki_cards/Coding.apkg)

## Contributing

&gt; Learn from the community.

Feel free to submit pull requests to help:

* Fix errors
* Improve sections
* Add new sections
* [Translate](https://github.com/donnemartin/system-design-primer/issues/28)

Content that needs some polishing is placed [under development](#under-development).

Review the [Contributing Guidelines](CONTRIBUTING.md).

## Index of system design topics

&gt; Summaries of various system design topics, including pros and cons.  **Everything is a trade-off**.
&gt;
&gt; Each section contains links to more in-depth resources.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/jrUBAF7.png&quot;&gt;
  &lt;br/&gt;
&lt;/p&gt;

* [System design topics: start here](#system-design-topics-start-here)
    * [Step 1: Review the scalability video lecture](#step-1-review-the-scalability-video-lecture)
    * [Step 2: Review the scalability article](#step-2-review-the-scalability-article)
    * [Next steps](#next-steps)
* [Performance vs scalability](#performance-vs-scalability)
* [Latency vs throughput](#latency-vs-throughput)
* [Availability vs consistency](#availability-vs-consistency)
    * [CAP theorem](#cap-theorem)
        * [CP - consistency and partition tolerance](#cp---consistency-and-partition-tolerance)
        * [AP - availability and partition tolerance](#ap---availability-and-partition-tolerance)
* [Consistency patterns](#consistency-patterns)
    * [Weak consistency](#weak-consistency)
    * [Eventual consistency](#eventual-consistency)
    * [Strong consistency](#strong-consistency)
* [Availability patterns](#availability-patterns)
    * [Fail-over](#fail-over)
    * [Replication](#replication)
    * [Availability in numbers](#availability-in-numbers)
* [Domain name system](#domain-name-system)
* [Content delivery network](#content-delivery-network)
    * [Push CDNs](#push-cdns)
    * [Pull CDNs](#pull-cdns)
* [Load balancer](#load-balancer)
    * [Active-passive](#active-passive)
    * [Active-active](#active-active)
    * [Layer 4 load balancing](#layer-4-load-balancing)
    * [Layer 7 load balancing](#layer-7-load-balancing)
    * [Horizontal scaling](#horizontal-scaling)
* [Reverse proxy (web server)](#reverse-proxy-web-server)
    * [Load balancer vs reverse proxy](#load-balancer-vs-reverse-proxy)
* [Application layer](#application-layer)
    * [Microservices](#microservices)
    * [Service discovery](#service-discovery)
* [Database](#database)
    * [Relational database management system (RDBMS)](#relational-database-management-system-rdbms)
        * [Master-slave replication](#master-slave-replication)
        * [Master-master replication](#master-master-replication)
        * [Federation](#federation)
        * [Sharding](#sharding)
        * [Denormalization](#denormalization)
        * [SQL tuning](#sql-tuning)
    * [NoSQL](#nosql)
        * [Key-value store](#key-value-store)
        * [Document store](#document-store)
        * [Wide column store](#wide-column-store)
        * [Graph Database](#graph-database)
    * [SQL or NoSQL](#sql-or-nosql)
* [Cache](#cache)
    * [Client caching](#client-caching)
    * [CDN caching](#cdn-caching)
    * [Web server caching](#web-server-caching)
    * [Database caching](#database-caching)
    * [Application caching](#application-caching)
    * [Caching at the database query level](#caching-at-the-database-query-level)
    * [Caching at the object level](#caching-at-the-object-level)
    * [When to update the cache](#when-to-update-the-cache)
        * [Cache-aside](#cache-aside)
        * [Write-through](#write-through)
        * [Write-behind (write-back)](#write-behind-write-back)
        * [Refresh-ahead](#refresh-ahead)
* [Asynchronism](#asynchronism)
    * [Message queues](#message-queues)
    * [Task queues](#task-queues)
    * [Back pressure](#back-pressure)
* [Communication](#communication)
    * [Transmission control protocol (TCP)](#transmission-control-protocol-tcp)
    * [User datagram protocol (UDP)](#user-datagram-protocol-udp)
    * [Remote procedure call (RPC)](#remote-procedure-call-rpc)
    * [Representational state transfer (REST)](#representational-state-transfer-rest)
* [Security](#security)
* [Appendix](#appendix)
    * [Powers of two table](#powers-of-two-table)
    * [Latency numbers every programmer should know](#latency-numbers-every-programmer-should-know)
    * [Additional system design interview questions](#additional-system-design-interview-questions)
    * [Real world architectures](#real-world-architectures)
    * [Company architectures](#company-architectures)
    * [Company engineering blogs](#company-engineering-blogs)
* [Under development](#under-development)
* [Credits](#credits)
* [Contact info](#contact-info)
* [License](#license)

## Study guide

&gt; Suggested topics to review based on your interview timeline (short, medium, long).

![Imgur](images/OfVllex.png)

**Q: For interviews, do I need to know everything here?**

**A: No, you don&#039;t need to know everything here to prepare for the interview**.

What you are asked in an interview depends on variables such as:

* How much experience you have
* What your technical background is
* What positions you are interviewing for
* Which companies you are interviewing with
* Luck

More experienced candidates are generally expected to know more about system design.  Architects or team leads might be expected to know more than individual contributors.  Top tech companies are likely to have one or more design interview rounds.

Start broad and go deeper in a few areas.  It helps to know a little about various key system design topics.  Adjust the following guide based on your timeline, experience, what positions you are interviewing for, and which companies you are interviewing with.

* **Short timeline** - Aim for **breadth** with system design topics.  Practice by solving **some** interview questions.
* **Medium timeline** - Aim for **breadth** and **some depth** with system design topics.  Practice by solving **many** interview questions.
* **Long timeline** - Aim for **breadth** and **more depth** with system design topics.  Practice by solving **most** interview questions.

| | Short | Medium | Long |
|---|---|---|---|
| Read through the [System design topics](#index-of-system-design-topics) to get a broad understanding of how systems work | :+1: | :+1: | :+1: |
| Read through a few articles in the [Company engineering blogs](#company-engineering-blogs) for the companies you are interviewing with | :+1: | :+1: | :+1: |
| Read through a few [Real world architectures](#real-world-architectures) | :+1: | :+1: | :+1: |
| Review [How to approach a system design interview question](#how-to-approach-a-system-design-interview-question) | :+1: | :+1: | :+1: |
| Work through [System design interview questions with solutions](#system-design-interview-questions-with-solutions) | Some | Many | Most |
| Work through [Object-oriented design interview questions with solutions](#object-oriented-design-interview-questions-with-solutions) | Some | Many | Most |
| Review [Additional system design interview questions](#additional-system-design-interview-questions) | Some | Many | Most |

## How to approach a system design interview question

&gt; How to tackle a system design interview question.

The system design interview is an **open-ended conversation**.  You are expected to lead it.

You can use the following steps to guide the discussion.  To help solidify this process, work through the [System design interview questions with solutions](#system-design-interview-questions-with-solutions) section using the following steps.

### Step 1: Outline use cases, constraints, and assumptions

Gather requirements and scope the problem.  Ask questions to clarify use cases and constraints.  Discuss assumptions.

* Who is going to use it?
* How are they going to use it?
* How many users are there?
* What does the system do?
* What are the inputs and outputs of the system?
* How much data do we expect to handle?
* How many requests per second do we expect?
* What is the expected read to write ratio?

### Step 2: Create a high level design

Outline a high level design with all important components.

* Sketch the main components and connections
* Justify your ideas

### Step 3: Design core components

Dive into details for each core component.  For example, if you were asked to [design a url shortening service](solutions/system_design/pastebin/README.md), discuss:

* Generating and storing a hash of the full url
    * [MD5](solutions/system_design/pastebin/README.md) and [Base62](solutions/system_design/pastebin/README.md)
    * Hash collisions
    * SQL or NoSQL
    * Database schema
* Translating a hashed url to the full url
    * Database lookup
* API and object-oriented design

### Step 4: Scale the design

Identify and address bottlenecks, given the constraints.  For example, do you need the following to address scalability issues?

* Load balancer
* Horizontal scaling
* Caching
* Database sharding

Discuss potential solutions and trade-offs.  Everything is a trade-off.  Address bottlenecks using [principles of scalable system design](#index-of-system-design-topics).

### Back-of-the-envelope calculations

You might be asked to do some estimates by hand.  Refer to the [Appendix](#appendix) for the following resources:

* [Use back of the envelope calculations](http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html)
* [Powers of two table](#powers-of-two-table)
* [Latency numbers every programmer should know](#latency-numbers-every-programmer-should-know)

### Source(s) and further reading

Check out the following links to get a better idea of what to expect:

* [How to ace a systems design interview](https://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/)
* [The system design interview](http://www.hiredintech.com/system-design)
* [Intro to Architecture and Systems Design Interviews](https://www.youtube.com/watch?v=ZgdS0EUmn70)
* [System design template](https://leetcode.com/discuss/career/229177/My-System-Design-Template)

## System design interview questions with solutions

&gt; Common system design interview questions with sample discussions, code, and diagrams.
&gt;
&gt; Solutions linked to content in the `solutions/` folder.

| Question | |
|---|---|
| Design Pastebin.com (or Bit.ly) | [Solution](solutions/system_design/pastebin/README.md) |
| Design the Twitter timeline and search (or Facebook feed and search) | [Solution](solutions/system_design/twitter/README.md) |
| Design a web crawler | [Solution](solutions/system_design/web_crawler/README.md) |
| Design Mint.com | [Solution](solutions/system_design/mint/README.md) |
| Design the data structures for a social network | [Solution](solutions/system_design/social_graph/README.md) |
| Design a key-value store for a search engine | [Solution](solutions/system_design/query_cache/README.md) |
| Design Amazon&#039;s sales ranking by category feature | [Solution](solutions/system_design/sales_rank/README.md) |
| Design a system that scales to millions of users on AWS | [Solution](solutions/system_design/scaling_aws/README.md) |
| Add a system design question | [Contribute](#contributing) |

### Design Pastebin.com (or Bit.ly)

[View exercise and solution](solutions/system_design/pastebin/README.md)

![Imgur](images/4edXG0T.png)

### Design the Twitter timeline and search (or Facebook feed and search)

[View exercise and solution](solutions/system_design/twitter/README.md)

![Imgur](images/jrUBAF7.png)

### Design a web crawler

[View exercise and solution](solutions/system_design/web_crawler/README.md)

![Imgur](images/bWxPtQA.png)

### Design Mint.com

[View exercise and solution](solutions/system_design/mint/README.md)

![Imgur](images/V5q57vU.png)

### Design the data structures for a social network

[View exercise and solution](solutions/system_design/social_graph/README.md)

![Imgur](images/cdCv5g7.png)

### Design a key-value store for a search engine

[View exercise and solution](solutions/system_design/query_cache/README.md)

![Imgur](images/4j99mhe.png)

### Design Amazon&#039;s sales ranking by category feature

[View exercise and solution](solutions/system_design/sales_rank/README.md)

![Imgur](images/MzExP06.png)

### Design a system that scales to millions of users on AWS

[View exercise and solution](solutions/system_design/scaling_aws/README.md)

![Imgur](images/jj3A5N8.png)

## Object-oriented design interview questions with solutions

&gt; Common object-oriented design interview questions with sample discussions, code, and diagrams.
&gt;
&gt; Solutions linked to content in the `solutions/` folder.

&gt;**Note: This section is under development**

| Question | |
|---|---|
| Design a hash map | [Solution](solutions/object_oriented_design/hash_table/hash_map.ipynb)  |
| Design a least recently used cache | [Solution](solutions/object_oriented_design/lru_cache/lru_cache.ipynb)  |
| Design a call center | [Solution](solutions/object_oriented_design/call_center/call_center.ipynb)  |
| Design a deck of cards | [Solution](solutions/object_oriented_design/deck_of_cards/deck_of_cards.ipynb)  |
| Design a parking lot | [Solution](solutions/object_oriented_design/parking_lot/parking_lot.ipynb)  |
| Design a chat server | [Solution](solutions/object_oriented_design/online_chat/online_chat.ipynb)  |
| Design a circular array | [Contribute](#contributing)  |
| Add an object-oriented design question | [Contribute](#contributing) |

## System design topics: start here

New to system design?

First, you&#039;ll need a basic understanding of common principles, learning about what they are, how they are used, and their pros and cons.

### Step 1: Review the scalability video lecture

[Scalability Lecture at Harvard](https://www.youtube.com/watch?v=-W9F__D3oY4)

* Topics covered:
    * Vertical scaling
    * Horizontal scaling
    * Caching
    * Load balancing
    * Database replication
    * Database partitioning

### Step 2: Review the scalability article

[Scalability](https://web.archive.org/web/20221030091841/http://www.lecloud.net/tagged/scalability/chrono)

* Topics covered:
    * [Clones](https://web.archive.org/web/20220530193911/https://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones)
    * [Databases](https://web.archive.org/web/20220602114024/https://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database)
    * [Caches](https://web.archive.org/web/20230126233752/https://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache)
    * [Asynchronism](https://web.archive.org/web/20220926171507/https://www.lecloud.net/post/9699762917/scalability-for-dummies-part-4-asynchronism)

### Next steps

Next, we&#039;ll look at high-level trade-offs:

* **Performance** vs **scalability**
* **Latency** vs **throughput**
* **Availability** vs **consistency**

Keep in mind that **everything is a trade-off**.

Then we&#039;ll dive into more specific topics such as DNS, CDNs, and load balancers.

## Performance vs scalability

A service is **scalable** if it results in increased **performance** in a manner proportional to resources added. Generally, increasing performance means serving more units of work, but it can also be to handle larger units of work, such as when datasets grow.&lt;sup&gt;&lt;a href=http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html&gt;1&lt;/a&gt;&lt;/sup&gt;

Another way to look at performance vs scalability:

* If you have a **performance** problem, your system is slow for a single user.
* If you have a **scalability** problem, your system is fast for a single user but slow under heavy load.

### Source(s) and further reading

* [A word on scalability](http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html)
* [Scalability, availability, s

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[black-forest-labs/flux]]></title>
            <link>https://github.com/black-forest-labs/flux</link>
            <guid>https://github.com/black-forest-labs/flux</guid>
            <pubDate>Wed, 04 Jun 2025 00:04:41 GMT</pubDate>
            <description><![CDATA[Official inference repo for FLUX.1 models]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/black-forest-labs/flux">black-forest-labs/flux</a></h1>
            <p>Official inference repo for FLUX.1 models</p>
            <p>Language: Python</p>
            <p>Stars: 22,064</p>
            <p>Forks: 1,570</p>
            <p>Stars today: 48 stars today</p>
            <h2>README</h2><pre># FLUX
by Black Forest Labs: https://blackforestlabs.ai. Documentation for our API can be found here: [docs.bfl.ml](https://docs.bfl.ml/).

![grid](assets/grid.jpg)

This repo contains minimal inference code to run image generation &amp; editing with our Flux models.

## Local installation

```bash
cd $HOME &amp;&amp; git clone https://github.com/black-forest-labs/flux
cd $HOME/flux
python3.10 -m venv .venv
source .venv/bin/activate
pip install -e &quot;.[all]&quot;
```

### Local installation with TensorRT support

If you would like to install the repository with [TensorRT](https://github.com/NVIDIA/TensorRT) support, you currently need to install a PyTorch image from NVIDIA instead. First install [enroot](https://github.com/NVIDIA/enroot), next follow the steps below:

```bash
cd $HOME &amp;&amp; git clone https://github.com/black-forest-labs/flux
enroot import &#039;docker://$oauthtoken@nvcr.io#nvidia/pytorch:25.01-py3&#039;
enroot create -n pti2501 nvidia+pytorch+25.01-py3.sqsh
enroot start --rw -m ${PWD}/flux:/workspace/flux -r pti2501
cd flux
pip install -e &quot;.[tensorrt]&quot; --extra-index-url https://pypi.nvidia.com
```

### Models

We are offering an extensive suite of models. For more information about the invidual models, please refer to the link under **Usage**.

| Name                        | Usage                                                      | HuggingFace repo                                               | License                                                               |
| --------------------------- | ---------------------------------------------------------- | -------------------------------------------------------------- | --------------------------------------------------------------------- |
| `FLUX.1 [schnell]`          | [Text to Image](docs/text-to-image.md)                     | https://huggingface.co/black-forest-labs/FLUX.1-schnell        | [apache-2.0](model_licenses/LICENSE-FLUX1-schnell)                    |
| `FLUX.1 [dev]`              | [Text to Image](docs/text-to-image.md)                     | https://huggingface.co/black-forest-labs/FLUX.1-dev            | [FLUX.1-dev Non-Commercial License](model_licenses/LICENSE-FLUX1-dev) |
| `FLUX.1 Fill [dev]`         | [In/Out-painting](docs/fill.md)                            | https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev       | [FLUX.1-dev Non-Commercial License](model_licenses/LICENSE-FLUX1-dev) |
| `FLUX.1 Canny [dev]`        | [Structural Conditioning](docs/structural-conditioning.md) | https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev      | [FLUX.1-dev Non-Commercial License](model_licenses/LICENSE-FLUX1-dev) |
| `FLUX.1 Depth [dev]`        | [Structural Conditioning](docs/structural-conditioning.md) | https://huggingface.co/black-forest-labs/FLUX.1-Depth-dev      | [FLUX.1-dev Non-Commercial License](model_licenses/LICENSE-FLUX1-dev) |
| `FLUX.1 Canny [dev] LoRA`   | [Structural Conditioning](docs/structural-conditioning.md) | https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev-lora | [FLUX.1-dev Non-Commercial License](model_licenses/LICENSE-FLUX1-dev) |
| `FLUX.1 Depth [dev] LoRA`   | [Structural Conditioning](docs/structural-conditioning.md) | https://huggingface.co/black-forest-labs/FLUX.1-Depth-dev-lora | [FLUX.1-dev Non-Commercial License](model_licenses/LICENSE-FLUX1-dev) |
| `FLUX.1 Redux [dev]`        | [Image variation](docs/image-variation.md)                 | https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev      | [FLUX.1-dev Non-Commercial License](model_licenses/LICENSE-FLUX1-dev) |
| `FLUX.1 [pro]`              | [Text to Image](docs/text-to-image.md)                     | [Available in our API.](https://docs.bfl.ml/)                  |                                                                       |
| `FLUX1.1 [pro]`             | [Text to Image](docs/text-to-image.md)                     | [Available in our API.](https://docs.bfl.ml/)                  |                                                                       |
| `FLUX1.1 [pro] Ultra/raw`   | [Text to Image](docs/text-to-image.md)                     | [Available in our API.](https://docs.bfl.ml/)                  |                                                                       |
| `FLUX.1 Fill [pro]`         | [In/Out-painting](docs/fill.md)                            | [Available in our API.](https://docs.bfl.ml/)                  |                                                                       |
| `FLUX.1 Canny [pro]`        | [Structural Conditioning](docs/structural-conditioning.md) | [Available in our API.](https://docs.bfl.ml/)                  |                                                                       |
| `FLUX.1 Depth [pro]`        | [Structural Conditioning](docs/structural-conditioning.md) | [Available in our API.](https://docs.bfl.ml/)                  |                                                                       |
| `FLUX1.1 Redux [pro]`       | [Image variation](docs/image-variation.md)                 | [Available in our API.](https://docs.bfl.ml/)                  |                                                                       |
| `FLUX1.1 Redux [pro] Ultra` | [Image variation](docs/image-variation.md)                 | [Available in our API.](https://docs.bfl.ml/)                  |                                                                       |

The weights of the autoencoder are also released under [apache-2.0](https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md) and can be found in the HuggingFace repos above.

## API usage

Our API offers access to our models. It is documented here:
[docs.bfl.ml](https://docs.bfl.ml/).

In this repository we also offer an easy python interface. To use this, you
first need to register with the API on [api.bfl.ml](https://api.bfl.ml/), and
create a new API key.

To use the API key either run `export BFL_API_KEY=&lt;your_key_here&gt;` or provide
it via the `api_key=&lt;your_key_here&gt;` parameter. It is also expected that you
have installed the package as above.

Usage from python:

```python
from flux.api import ImageRequest

# this will create an api request directly but not block until the generation is finished
request = ImageRequest(&quot;A beautiful beach&quot;, name=&quot;flux.1.1-pro&quot;)
# or: request = ImageRequest(&quot;A beautiful beach&quot;, name=&quot;flux.1.1-pro&quot;, api_key=&quot;your_key_here&quot;)

# any of the following will block until the generation is finished
request.url
# -&gt; https:&lt;...&gt;/sample.jpg
request.bytes
# -&gt; b&quot;...&quot; bytes for the generated image
request.save(&quot;outputs/api.jpg&quot;)
# saves the sample to local storage
request.image
# -&gt; a PIL image
```

Usage from the command line:

```bash
$ python -m flux.api --prompt=&quot;A beautiful beach&quot; url
https:&lt;...&gt;/sample.jpg

# generate and save the result
$ python -m flux.api --prompt=&quot;A beautiful beach&quot; save outputs/api

# open the image directly
$ python -m flux.api --prompt=&quot;A beautiful beach&quot; image show
```

## Citation

If you find the provided code or models useful for your research, consider citing them as:

```bib
@misc{flux2024,
    author={Black Forest Labs},
    title={FLUX},
    year={2024},
    howpublished={\url{https://github.com/black-forest-labs/flux}},
}
```
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[elebumm/RedditVideoMakerBot]]></title>
            <link>https://github.com/elebumm/RedditVideoMakerBot</link>
            <guid>https://github.com/elebumm/RedditVideoMakerBot</guid>
            <pubDate>Wed, 04 Jun 2025 00:04:40 GMT</pubDate>
            <description><![CDATA[Create Reddit Videos with just‚ú® one command ‚ú®]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/elebumm/RedditVideoMakerBot">elebumm/RedditVideoMakerBot</a></h1>
            <p>Create Reddit Videos with just‚ú® one command ‚ú®</p>
            <p>Language: Python</p>
            <p>Stars: 7,592</p>
            <p>Forks: 2,010</p>
            <p>Stars today: 249 stars today</p>
            <h2>README</h2><pre># Reddit Video Maker Bot üé•

All done WITHOUT video editing or asset compiling. Just pure ‚ú®programming magic‚ú®.

Created by Lewis Menelaws &amp; [TMRRW](https://tmrrwinc.ca)

&lt;a target=&quot;_blank&quot; href=&quot;https://tmrrwinc.ca&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://user-images.githubusercontent.com/6053155/170528535-e274dc0b-7972-4b27-af22-637f8c370133.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://user-images.githubusercontent.com/6053155/170528582-cb6671e7-5a2f-4bd4-a048-0e6cfa54f0f7.png&quot;&gt;
  &lt;img src=&quot;https://user-images.githubusercontent.com/6053155/170528582-cb6671e7-5a2f-4bd4-a048-0e6cfa54f0f7.png&quot; width=&quot;350&quot;&gt;
&lt;/picture&gt;

&lt;/a&gt;

## Video Explainer

[![lewisthumbnail](https://user-images.githubusercontent.com/6053155/173631669-1d1b14ad-c478-4010-b57d-d79592a789f2.png)
](https://www.youtube.com/watch?v=3gjcY_00U1w)

## Motivation ü§î

These videos on TikTok, YouTube and Instagram get MILLIONS of views across all platforms and require very little effort.
The only original thing being done is the editing and gathering of all materials...

... but what if we can automate that process? ü§î

## Disclaimers üö®

- **At the moment**, this repository won&#039;t attempt to upload this content through this bot. It will give you a file that
  you will then have to upload manually. This is for the sake of avoiding any sort of community guideline issues.

## Requirements

- Python 3.10
- Playwright (this should install automatically in installation)

## Installation üë©‚Äçüíª

1. Clone this repository
2. Run `pip install -r requirements.txt`
3. Run `python -m playwright install` and `python -m playwright install-deps`

**EXPERIMENTAL!!!!**

On macOS and Linux (debian, arch, fedora and centos, and based on those), you can run an install script that will automatically install steps 1 to 3. (requires bash)

`bash &lt;(curl -sL https://raw.githubusercontent.com/elebumm/RedditVideoMakerBot/master/install.sh)`

This can also be used to update the installation

4. Run `python main.py`
5. Visit [the Reddit Apps page.](https://www.reddit.com/prefs/apps), and set up an app that is a &quot;script&quot;. Paste any URL in redirect URL. Ex:`https://jasoncameron.dev`
6. The bot will ask you to fill in your details to connect to the Reddit API, and configure the bot to your liking
7. Enjoy üòé
8. If you need to reconfigure the bot, simply open the `config.toml` file and delete the lines that need to be changed. On the next run of the bot, it will help you reconfigure those options.

(Note if you got an error installing or running the bot try first rerunning the command with a three after the name e.g. python3 or pip3)

If you want to read more detailed guide about the bot, please refer to the [documentation](https://reddit-video-maker-bot.netlify.app/)

## Video

https://user-images.githubusercontent.com/66544866/173453972-6526e4e6-c6ef-41c5-ab40-5d275e724e7c.mp4

## Contributing &amp; Ways to improve üìà

In its current state, this bot does exactly what it needs to do. However, improvements can always be made!

I have tried to simplify the code so anyone can read it and start contributing at any skill level. Don&#039;t be shy :) contribute!

- [ ] Creating better documentation and adding a command line interface.
- [x] Allowing the user to choose background music for their videos.
- [x] Allowing users to choose a reddit thread instead of being randomized.
- [x] Allowing users to choose a background that is picked instead of the Minecraft one.
- [x] Allowing users to choose between any subreddit.
- [x] Allowing users to change voice.
- [x] Checks if a video has already been created
- [x] Light and Dark modes
- [x] NSFW post filter

Please read our [contributing guidelines](CONTRIBUTING.md) for more detailed information.

### For any questions or support join the [Discord](https://discord.gg/qfQSx45xCV) server

## Developers and maintainers.

Elebumm (Lewis#6305) - https://github.com/elebumm (Founder)

Jason Cameron - https://github.com/JasonLovesDoggo (Maintainer)

Simon (OpenSourceSimon) - https://github.com/OpenSourceSimon

CallumIO (c.#6837) - https://github.com/CallumIO

Verq (Verq#2338) - https://github.com/CordlessCoder

LukaHietala (Pix.#0001) - https://github.com/LukaHietala

Freebiell (Freebie#3263) - https://github.com/FreebieII

Aman Raza (electro199#8130) - https://github.com/electro199

Cyteon (cyteon) - https://github.com/cyteon


## LICENSE
[Roboto Fonts](https://fonts.google.com/specimen/Roboto/about) are licensed under [Apache License V2](https://www.apache.org/licenses/LICENSE-2.0)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[yeongpin/cursor-free-vip]]></title>
            <link>https://github.com/yeongpin/cursor-free-vip</link>
            <guid>https://github.com/yeongpin/cursor-free-vip</guid>
            <pubDate>Wed, 04 Jun 2025 00:04:39 GMT</pubDate>
            <description><![CDATA[[Support 0.49.x]ÔºàReset Cursor AI MachineID & Bypass Higher Token LimitÔºâ Cursor Ai ÔºåËá™Âä®ÈáçÁΩÆÊú∫Âô®ID Ôºå ÂÖçË¥πÂçáÁ∫ß‰ΩøÁî®ProÂäüËÉΩ: You've reached your trial request limit. / Too many free trial accounts used on this machine. Please upgrade to pro. We have this limit in place to prevent abuse. Please let us know if you believe this is a mistake.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/yeongpin/cursor-free-vip">yeongpin/cursor-free-vip</a></h1>
            <p>[Support 0.49.x]ÔºàReset Cursor AI MachineID & Bypass Higher Token LimitÔºâ Cursor Ai ÔºåËá™Âä®ÈáçÁΩÆÊú∫Âô®ID Ôºå ÂÖçË¥πÂçáÁ∫ß‰ΩøÁî®ProÂäüËÉΩ: You've reached your trial request limit. / Too many free trial accounts used on this machine. Please upgrade to pro. We have this limit in place to prevent abuse. Please let us know if you believe this is a mistake.</p>
            <p>Language: Python</p>
            <p>Stars: 28,501</p>
            <p>Forks: 3,590</p>
            <p>Stars today: 223 stars today</p>
            <h2>README</h2><pre># ‚û§ Cursor Free VIP

&lt;div align=&quot;center&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/logo.png&quot; alt=&quot;Cursor Pro Logo&quot; width=&quot;200&quot; style=&quot;border-radius: 6px;&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;

[![Release](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/release/yeongpin/cursor-free-vip)](https://github.com/yeongpin/cursor-free-vip/releases/latest)
[![License: CC BY-NC-ND 4.0](https://img.shields.io/badge/License-CC_BY--NC--ND_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-nd/4.0/)
[![Stars](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/stars/yeongpin/cursor-free-vip)](https://github.com/yeongpin/cursor-free-vip/stargazers)
[![Downloads](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/yeongpin/cursor-free-vip/total)](https://github.com/yeongpin/cursor-free-vip/releases/latest)
&lt;a href=&quot;https://buymeacoffee.com/yeongpin&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Buy Me a Coffee&quot; src=&quot;https://img.shields.io/badge/Buy%20Me%20a%20Coffee-Support%20Me-FFDA33&quot;&gt;&lt;/a&gt;
 [&lt;img src=&quot;https://devin.ai/assets/deepwiki-badge.png&quot; alt=&quot;Ask DeepWiki.com&quot; height=&quot;20&quot;/&gt;](https://deepwiki.com/yeongpin/cursor-free-vip)

&lt;/p&gt;


&lt;a href=&quot;https://trendshift.io/repositories/13425&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13425&quot; alt=&quot;yeongpin%2Fcursor-free-vip | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;br&gt;
&lt;a href=&quot;https://www.buymeacoffee.com/yeongpin&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://img.buymeacoffee.com/button-api/?text=buy me a coffee&amp;emoji=‚òï&amp;slug=yeongpin&amp;button_colour=ffda33&amp;font_colour=000000&amp;font_family=Bree&amp;outline_colour=000000&amp;coffee_colour=FFDD00&amp;latest=2&quot; width=&quot;160&quot; height=&#039;55&#039; alt=&quot;Buy Me a Coffee&quot;/&gt;
&lt;/a&gt;


&lt;h4&gt;Support Latest 0.49.x Version | ÊîØÊåÅÊúÄÊñ∞ 0.49.x ÁâàÊú¨&lt;/h4&gt;

This tool is for educational purposes, currently the repo does not violate any laws. Please support the original project.
This tool will not generate any fake email accounts and OAuth access.

Supports Windows, macOS and Linux.

For optimal performance, run with privileges and always stay up to date.

ÈÄôÊòØ‰∏ÄÊ¨æÁî®ÊñºÂ≠∏ÁøíÂíåÁ†îÁ©∂ÁöÑÂ∑•ÂÖ∑ÔºåÁõÆÂâç repo Ê≤íÊúâÈÅïÂèç‰ªª‰ΩïÊ≥ïÂæã„ÄÇË´ãÊîØÊåÅÂéü‰ΩúËÄÖ„ÄÇ
ÈÄôÊ¨æÂ∑•ÂÖ∑‰∏çÊúÉÁîüÊàê‰ªª‰ΩïÂÅáÁöÑÈõªÂ≠êÈÉµ‰ª∂Â∏≥Êà∂Âíå OAuth Ë®™Âïè„ÄÇ

ÊîØÊåÅ Windows„ÄÅmacOS Âíå Linux„ÄÇ

Â∞çÊñºÊúÄ‰Ω≥ÊÄßËÉΩÔºåË´ã‰ª•ÁÆ°ÁêÜÂì°Ë∫´‰ªΩÈÅãË°å‰∏¶ÂßãÁµÇ‰øùÊåÅÊúÄÊñ∞„ÄÇ


&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/product_2025-04-16_10-40-21.png&quot; alt=&quot;new&quot; width=&quot;800&quot; style=&quot;border-radius: 6px;&quot;/&gt;&lt;br&gt;
&lt;/p&gt;

&lt;/div&gt;

## üîÑ Change Log | Êõ¥Êñ∞Êó•Âøó

[Watch Change Log | Êü•ÁúãÊõ¥Êñ∞Êó•Âøó](CHANGELOG.md)

## ‚ú® Features | ÂäüËÉΩÁâπÈªû

* Support Windows macOS and Linux systems&lt;br&gt;ÊîØÊåÅ Windows„ÄÅmacOS Âíå Linux Á≥ªÁµ±&lt;br&gt;

* Reset Cursor&#039;s configuration&lt;br&gt;ÈáçÁΩÆ Cursor ÁöÑÈÖçÁΩÆ&lt;br&gt;

* Multi-language support (English, ÁÆÄ‰Ωì‰∏≠Êñá, ÁπÅÈ´î‰∏≠Êñá, Vietnamese)&lt;br&gt;Â§öË™ûË®ÄÊîØÊåÅÔºàËã±Êñá„ÄÅÁÆÄ‰Ωì‰∏≠Êñá„ÄÅÁπÅÈ´î‰∏≠Êñá„ÄÅË∂äÂçóË™ûÔºâ&lt;br&gt;

## üíª System Support | Á≥ªÁµ±ÊîØÊåÅ

| Operating System | Architecture      | Supported |
|------------------|-------------------|-----------|
| Windows          | x64, x86          | ‚úÖ         |
| macOS            | Intel, Apple Silicon | ‚úÖ      |
| Linux            | x64, x86, ARM64   | ‚úÖ         |

## üëÄ How to use | Â¶Ç‰Ωï‰ΩøÁî®

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;‚≠ê Auto Run Script | ËÖ≥Êú¨Ëá™ÂãïÂåñÈÅãË°å&lt;/b&gt;&lt;/summary&gt;

### **Linux/macOS**

```bash
curl -fsSL https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.sh -o install.sh &amp;&amp; chmod +x install.sh &amp;&amp; ./install.sh
```

### **Archlinux**

Install via [AUR](https://aur.archlinux.org/packages/cursor-free-vip-git)

```bash
yay -S cursor-free-vip-git
```

### **Windows**

```powershell
irm https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.ps1 | iex
```

&lt;/details&gt;

If you want to stop the script, please press Ctrl+C&lt;br&gt;Ë¶ÅÂÅúÊ≠¢ËÖ≥Êú¨ÔºåË´ãÊåâ Ctrl+C

## ‚ùó Note | Ê≥®ÊÑè‰∫ãÈ†Ö

üìù Config | Êñá‰ª∂ÈÖçÁΩÆ
`Win / Macos / Linux Path | Ë∑ØÂæë [Documents/.cursor-free-vip/config.ini]`
&lt;details&gt;
&lt;summary&gt;&lt;b&gt;‚≠ê Config | Êñá‰ª∂ÈÖçÁΩÆ&lt;/b&gt;&lt;/summary&gt;

```
[Chrome]
# Default Google Chrome Path | ÈªòË™çGoogle Chrome ÈÅäË¶ΩÂô®Ë∑ØÂæë
chromepath = C:\Program Files\Google/Chrome/Application/chrome.exe

[Turnstile]
# Handle Turnstile Wait Time | Á≠âÂæÖ‰∫∫Ê©üÈ©óË≠âÊôÇÈñì
handle_turnstile_time = 2
# Handle Turnstile Wait Random Time (must merge 1-3 or 1,3) | Á≠âÂæÖ‰∫∫Ê©üÈ©óË≠âÈö®Ê©üÊôÇÈñìÔºàÂøÖÈ†àÊòØ 1-3 ÊàñËÄÖ 1,3 ÈÄôÊ®£ÁöÑÁµÑÂêàÔºâ
handle_turnstile_random_time = 1-3

[OSPaths]
# Storage Path | Â≠òÂÑ≤Ë∑ØÂæë
storage_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/storage.json
# SQLite Path | SQLiteË∑ØÂæë
sqlite_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/state.vscdb
# Machine ID Path | Ê©üÂô®IDË∑ØÂæë
machine_id_path = /Users/username/Library/Application Support/Cursor/machineId
# For Linux users: ~/.config/cursor/machineid

[Timing]
# Min Random Time | ÊúÄÂ∞èÈö®Ê©üÊôÇÈñì
min_random_time = 0.1
# Max Random Time | ÊúÄÂ§ßÈö®Ê©üÊôÇÈñì
max_random_time = 0.8
# Page Load Wait | È†ÅÈù¢Âä†ËºâÁ≠âÂæÖÊôÇÈñì
page_load_wait = 0.1-0.8
# Input Wait | Ëº∏ÂÖ•Á≠âÂæÖÊôÇÈñì
input_wait = 0.3-0.8
# Submit Wait | Êèê‰∫§Á≠âÂæÖÊôÇÈñì
submit_wait = 0.5-1.5
# Verification Code Input | È©óË≠âÁ¢ºËº∏ÂÖ•Á≠âÂæÖÊôÇÈñì
verification_code_input = 0.1-0.3
# Verification Success Wait | È©óË≠âÊàêÂäüÁ≠âÂæÖÊôÇÈñì
verification_success_wait = 2-3
# Verification Retry Wait | È©óË≠âÈáçË©¶Á≠âÂæÖÊôÇÈñì
verification_retry_wait = 2-3
# Email Check Initial Wait | ÈÉµ‰ª∂Ê™¢Êü•ÂàùÂßãÁ≠âÂæÖÊôÇÈñì
email_check_initial_wait = 4-6
# Email Refresh Wait | ÈÉµ‰ª∂Âà∑Êñ∞Á≠âÂæÖÊôÇÈñì
email_refresh_wait = 2-4
# Settings Page Load Wait | Ë®≠ÁΩÆÈ†ÅÈù¢Âä†ËºâÁ≠âÂæÖÊôÇÈñì
settings_page_load_wait = 1-2
# Failed Retry Time | Â§±ÊïóÈáçË©¶ÊôÇÈñì
failed_retry_time = 0.5-1
# Retry Interval | ÈáçË©¶ÈñìÈöî
retry_interval = 8-12
# Max Timeout | ÊúÄÂ§ßË∂ÖÊôÇÊôÇÈñì
max_timeout = 160

[Utils]
# Check Update | Ê™¢Êü•Êõ¥Êñ∞
check_update = True
# Show Account Info | È°ØÁ§∫Ë≥¨Ëôü‰ø°ÊÅØ
show_account_info = True

[TempMailPlus]
# Enable TempMailPlus | ÂïìÁî® TempMailPlusÔºà‰ªª‰ΩïËΩâÁôºÂà∞TempMailPlusÁöÑÈÉµ‰ª∂ÈÉΩÊîØÊåÅÁç≤ÂèñÈ©óË≠âÁ¢ºÔºå‰æãÂ¶ÇcloudflareÈÉµ‰ª∂Catch-allÔºâ
enabled = false
# TempMailPlus Email | TempMailPlus ÈõªÂ≠êÈÉµ‰ª∂
email = xxxxx@mailto.plus
# TempMailPlus pin | TempMailPlus pinÁ¢º
epin = 

[WindowsPaths]
storage_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\storage.json
sqlite_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\state.vscdb
machine_id_path = C:\Users\yeongpin\AppData\Roaming\Cursor\machineId
cursor_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app
updater_path = C:\Users\yeongpin\AppData\Local\cursor-updater
update_yml_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app-update.yml
product_json_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app\product.json

[Browser]
default_browser = opera
chrome_path = C:\Program Files\Google\Chrome\Application\chrome.exe
edge_path = C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe
firefox_path = C:\Program Files\Mozilla Firefox\firefox.exe
brave_path = C:\Program Files\BraveSoftware/Brave-Browser/Application/brave.exe
chrome_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe
edge_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\msedgedriver.exe
firefox_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\geckodriver.exe
brave_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe
opera_path = C:\Users\yeongpin\AppData\Local\Programs\Opera\opera.exe
opera_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe

[OAuth]
show_selection_alert = False
timeout = 120
max_attempts = 3
```

&lt;/details&gt;

* Use administrator privileges to run the script &lt;br&gt;Ë´ã‰ΩøÁî®ÁÆ°ÁêÜÂì°Ë∫´‰ªΩÈÅãË°åËÖ≥Êú¨

* Confirm that Cursor is closed before running the script &lt;br&gt;Ë´ãÁ¢∫‰øùÂú®ÈÅãË°åËÖ≥Êú¨ÂâçÂ∑≤Á∂ìÈóúÈñâ Cursor&lt;br&gt;

* This tool is only for learning and research purposes &lt;br&gt;Ê≠§Â∑•ÂÖ∑ÂÉÖ‰æõÂ≠∏ÁøíÂíåÁ†îÁ©∂‰ΩøÁî®&lt;br&gt;

* Please comply with the relevant software usage terms when using this tool &lt;br&gt;‰ΩøÁî®Êú¨Â∑•ÂÖ∑ÊôÇË´ãÈÅµÂÆàÁõ∏ÈóúËªü‰ª∂‰ΩøÁî®Ê¢ùÊ¨æ

## üö® Common Issues | Â∏∏Ë¶ãÂïèÈ°å

|                   Â¶ÇÊûúÈÅáÂà∞Ê¨äÈôêÂïèÈ°åÔºåË´ãÁ¢∫‰øùÔºö                    |                   Ê≠§ËÖ≥Êú¨‰ª•ÁÆ°ÁêÜÂì°Ë∫´‰ªΩÈÅãË°å                    |
|:--------------------------------------------------:|:------------------------------------------------:|
| If you encounter permission issues, please ensure: | This script is run with administrator privileges |
| Error &#039;User is not authorized&#039; | This means your account was banned for using temporary (disposal) mail. Ensure using a non-temporary mail service |
## ü§© Contribution | Ë≤¢Áçª

Ê≠°ËøéÊèê‰∫§ Issue Âíå Pull RequestÔºÅ


&lt;a href=&quot;https://github.com/yeongpin/cursor-free-vip/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=yeongpin/cursor-free-vip&amp;preview=true&amp;max=&amp;columns=&quot; /&gt;
&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;

## üì© Disclaimer | ÂÖçË≤¨ËÅ≤Êòé

Êú¨Â∑•ÂÖ∑ÂÉÖ‰æõÂ≠∏ÁøíÂíåÁ†îÁ©∂‰ΩøÁî®Ôºå‰ΩøÁî®Êú¨Â∑•ÂÖ∑ÊâÄÁî¢ÁîüÁöÑ‰ªª‰ΩïÂæåÊûúÁî±‰ΩøÁî®ËÄÖËá™Ë°åÊâøÊìî„ÄÇ &lt;br&gt;

This tool is only for learning and research purposes, and any consequences arising from the use of this tool are borne
by the user.

## üí∞ Buy Me a Coffee | Ë´ãÊàëÂñùÊùØÂíñÂï°

&lt;div align=&quot;center&quot;&gt;
  &lt;table&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;img src=&quot;./images/provi-code.jpg&quot; alt=&quot;buy_me_a_coffee&quot; width=&quot;280&quot;/&gt;&lt;br&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;img src=&quot;./images/paypal.png&quot; alt=&quot;buy_me_a_coffee&quot; width=&quot;280&quot;/&gt;&lt;br&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

## ‚≠ê Star History | ÊòüÊòüÊï∏

&lt;div align=&quot;center&quot;&gt;

[![Star History Chart](https://api.star-history.com/svg?repos=yeongpin/cursor-free-vip&amp;type=Date)](https://star-history.com/#yeongpin/cursor-free-vip&amp;Date)

&lt;/div&gt;

## üìù License | ÊéàÊ¨ä

Êú¨È†ÖÁõÆÊé°Áî® [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/) ÊéàÊ¨ä„ÄÇ
Please refer to the [LICENSE](LICENSE.md) file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[BerriAI/litellm]]></title>
            <link>https://github.com/BerriAI/litellm</link>
            <guid>https://github.com/BerriAI/litellm</guid>
            <pubDate>Wed, 04 Jun 2025 00:04:38 GMT</pubDate>
            <description><![CDATA[Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq]]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/BerriAI/litellm">BerriAI/litellm</a></h1>
            <p>Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq]</p>
            <p>Language: Python</p>
            <p>Stars: 23,563</p>
            <p>Forks: 3,087</p>
            <p>Stars today: 54 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
        üöÖ LiteLLM
    &lt;/h1&gt;
    &lt;p align=&quot;center&quot;&gt;
        &lt;p align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://render.com/deploy?repo=https://github.com/BerriAI/litellm&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://render.com/images/deploy-to-render-button.svg&quot; alt=&quot;Deploy to Render&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://railway.app/template/HLP0Ub?referralCode=jch2ME&quot;&gt;
          &lt;img src=&quot;https://railway.app/button.svg&quot; alt=&quot;Deploy on Railway&quot;&gt;
        &lt;/a&gt;
        &lt;/p&gt;
        &lt;p align=&quot;center&quot;&gt;Call all LLM APIs using the OpenAI format [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.]
        &lt;br&gt;
    &lt;/p&gt;
&lt;h4 align=&quot;center&quot;&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/simple_proxy&quot; target=&quot;_blank&quot;&gt;LiteLLM Proxy Server (LLM Gateway)&lt;/a&gt; | &lt;a href=&quot;https://docs.litellm.ai/docs/hosted&quot; target=&quot;_blank&quot;&gt; Hosted Proxy (Preview)&lt;/a&gt; | &lt;a href=&quot;https://docs.litellm.ai/docs/enterprise&quot;target=&quot;_blank&quot;&gt;Enterprise Tier&lt;/a&gt;&lt;/h4&gt;
&lt;h4 align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://pypi.org/project/litellm/&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/pypi/v/litellm.svg&quot; alt=&quot;PyPI Version&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://www.ycombinator.com/companies/berriai&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/Y%20Combinator-W23-orange?style=flat-square&quot; alt=&quot;Y Combinator W23&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://wa.link/huol9n&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/static/v1?label=Chat%20on&amp;message=WhatsApp&amp;color=success&amp;logo=WhatsApp&amp;style=flat-square&quot; alt=&quot;Whatsapp&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/wuPM9dRgDw&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/static/v1?label=Chat%20on&amp;message=Discord&amp;color=blue&amp;logo=Discord&amp;style=flat-square&quot; alt=&quot;Discord&quot;&gt;
    &lt;/a&gt;
&lt;/h4&gt;

LiteLLM manages:

- Translate inputs to provider&#039;s `completion`, `embedding`, and `image_generation` endpoints
- [Consistent output](https://docs.litellm.ai/docs/completion/output), text responses will always be available at `[&#039;choices&#039;][0][&#039;message&#039;][&#039;content&#039;]`
- Retry/fallback logic across multiple deployments (e.g. Azure/OpenAI) - [Router](https://docs.litellm.ai/docs/routing)
- Set Budgets &amp; Rate limits per project, api key, model [LiteLLM Proxy Server (LLM Gateway)](https://docs.litellm.ai/docs/simple_proxy)

[**Jump to LiteLLM Proxy (LLM Gateway) Docs**](https://github.com/BerriAI/litellm?tab=readme-ov-file#openai-proxy---docs) &lt;br&gt;
[**Jump to Supported LLM Providers**](https://github.com/BerriAI/litellm?tab=readme-ov-file#supported-providers-docs)

üö® **Stable Release:** Use docker images with the `-stable` tag. These have undergone 12 hour load tests, before being published. [More information about the release cycle here](https://docs.litellm.ai/docs/proxy/release_cycle)

Support for more providers. Missing a provider or LLM Platform, raise a [feature request](https://github.com/BerriAI/litellm/issues/new?assignees=&amp;labels=enhancement&amp;projects=&amp;template=feature_request.yml&amp;title=%5BFeature%5D%3A+).

# Usage ([**Docs**](https://docs.litellm.ai/docs/))

&gt; [!IMPORTANT]
&gt; LiteLLM v1.0.0 now requires `openai&gt;=1.0.0`. Migration guide [here](https://docs.litellm.ai/docs/migration)  
&gt; LiteLLM v1.40.14+ now requires `pydantic&gt;=2.0.0`. No changes required.

&lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/BerriAI/litellm/blob/main/cookbook/liteLLM_Getting_Started.ipynb&quot;&gt;
  &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open In Colab&quot;/&gt;
&lt;/a&gt;

```shell
pip install litellm
```

```python
from litellm import completion
import os

## set ENV variables
os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your-openai-key&quot;
os.environ[&quot;ANTHROPIC_API_KEY&quot;] = &quot;your-anthropic-key&quot;

messages = [{ &quot;content&quot;: &quot;Hello, how are you?&quot;,&quot;role&quot;: &quot;user&quot;}]

# openai call
response = completion(model=&quot;openai/gpt-4o&quot;, messages=messages)

# anthropic call
response = completion(model=&quot;anthropic/claude-3-sonnet-20240229&quot;, messages=messages)
print(response)
```

### Response (OpenAI Format)

```json
{
    &quot;id&quot;: &quot;chatcmpl-565d891b-a42e-4c39-8d14-82a1f5208885&quot;,
    &quot;created&quot;: 1734366691,
    &quot;model&quot;: &quot;claude-3-sonnet-20240229&quot;,
    &quot;object&quot;: &quot;chat.completion&quot;,
    &quot;system_fingerprint&quot;: null,
    &quot;choices&quot;: [
        {
            &quot;finish_reason&quot;: &quot;stop&quot;,
            &quot;index&quot;: 0,
            &quot;message&quot;: {
                &quot;content&quot;: &quot;Hello! As an AI language model, I don&#039;t have feelings, but I&#039;m operating properly and ready to assist you with any questions or tasks you may have. How can I help you today?&quot;,
                &quot;role&quot;: &quot;assistant&quot;,
                &quot;tool_calls&quot;: null,
                &quot;function_call&quot;: null
            }
        }
    ],
    &quot;usage&quot;: {
        &quot;completion_tokens&quot;: 43,
        &quot;prompt_tokens&quot;: 13,
        &quot;total_tokens&quot;: 56,
        &quot;completion_tokens_details&quot;: null,
        &quot;prompt_tokens_details&quot;: {
            &quot;audio_tokens&quot;: null,
            &quot;cached_tokens&quot;: 0
        },
        &quot;cache_creation_input_tokens&quot;: 0,
        &quot;cache_read_input_tokens&quot;: 0
    }
}
```

Call any model supported by a provider, with `model=&lt;provider_name&gt;/&lt;model_name&gt;`. There might be provider-specific details here, so refer to [provider docs for more information](https://docs.litellm.ai/docs/providers)

## Async ([Docs](https://docs.litellm.ai/docs/completion/stream#async-completion))

```python
from litellm import acompletion
import asyncio

async def test_get_response():
    user_message = &quot;Hello, how are you?&quot;
    messages = [{&quot;content&quot;: user_message, &quot;role&quot;: &quot;user&quot;}]
    response = await acompletion(model=&quot;openai/gpt-4o&quot;, messages=messages)
    return response

response = asyncio.run(test_get_response())
print(response)
```

## Streaming ([Docs](https://docs.litellm.ai/docs/completion/stream))

liteLLM supports streaming the model response back, pass `stream=True` to get a streaming iterator in response.  
Streaming is supported for all models (Bedrock, Huggingface, TogetherAI, Azure, OpenAI, etc.)

```python
from litellm import completion
response = completion(model=&quot;openai/gpt-4o&quot;, messages=messages, stream=True)
for part in response:
    print(part.choices[0].delta.content or &quot;&quot;)

# claude 2
response = completion(&#039;anthropic/claude-3-sonnet-20240229&#039;, messages, stream=True)
for part in response:
    print(part)
```

### Response chunk (OpenAI Format)

```json
{
    &quot;id&quot;: &quot;chatcmpl-2be06597-eb60-4c70-9ec5-8cd2ab1b4697&quot;,
    &quot;created&quot;: 1734366925,
    &quot;model&quot;: &quot;claude-3-sonnet-20240229&quot;,
    &quot;object&quot;: &quot;chat.completion.chunk&quot;,
    &quot;system_fingerprint&quot;: null,
    &quot;choices&quot;: [
        {
            &quot;finish_reason&quot;: null,
            &quot;index&quot;: 0,
            &quot;delta&quot;: {
                &quot;content&quot;: &quot;Hello&quot;,
                &quot;role&quot;: &quot;assistant&quot;,
                &quot;function_call&quot;: null,
                &quot;tool_calls&quot;: null,
                &quot;audio&quot;: null
            },
            &quot;logprobs&quot;: null
        }
    ]
}
```

## Logging Observability ([Docs](https://docs.litellm.ai/docs/observability/callbacks))

LiteLLM exposes pre defined callbacks to send data to Lunary, MLflow, Langfuse, DynamoDB, s3 Buckets, Helicone, Promptlayer, Traceloop, Athina, Slack

```python
from litellm import completion

## set env variables for logging tools (when using MLflow, no API key set up is required)
os.environ[&quot;LUNARY_PUBLIC_KEY&quot;] = &quot;your-lunary-public-key&quot;
os.environ[&quot;HELICONE_API_KEY&quot;] = &quot;your-helicone-auth-key&quot;
os.environ[&quot;LANGFUSE_PUBLIC_KEY&quot;] = &quot;&quot;
os.environ[&quot;LANGFUSE_SECRET_KEY&quot;] = &quot;&quot;
os.environ[&quot;ATHINA_API_KEY&quot;] = &quot;your-athina-api-key&quot;

os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your-openai-key&quot;

# set callbacks
litellm.success_callback = [&quot;lunary&quot;, &quot;mlflow&quot;, &quot;langfuse&quot;, &quot;athina&quot;, &quot;helicone&quot;] # log input/output to lunary, langfuse, supabase, athina, helicone etc

#openai call
response = completion(model=&quot;openai/gpt-4o&quot;, messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hi üëã - i&#039;m openai&quot;}])
```

# LiteLLM Proxy Server (LLM Gateway) - ([Docs](https://docs.litellm.ai/docs/simple_proxy))

Track spend + Load Balance across multiple projects

[Hosted Proxy (Preview)](https://docs.litellm.ai/docs/hosted)

The proxy provides:

1. [Hooks for auth](https://docs.litellm.ai/docs/proxy/virtual_keys#custom-auth)
2. [Hooks for logging](https://docs.litellm.ai/docs/proxy/logging#step-1---create-your-custom-litellm-callback-class)
3. [Cost tracking](https://docs.litellm.ai/docs/proxy/virtual_keys#tracking-spend)
4. [Rate Limiting](https://docs.litellm.ai/docs/proxy/users#set-rate-limits)

## üìñ Proxy Endpoints - [Swagger Docs](https://litellm-api.up.railway.app/)


## Quick Start Proxy - CLI

```shell
pip install &#039;litellm[proxy]&#039;
```

### Step 1: Start litellm proxy

```shell
$ litellm --model huggingface/bigcode/starcoder

#INFO: Proxy running on http://0.0.0.0:4000
```

### Step 2: Make ChatCompletions Request to Proxy


&gt; [!IMPORTANT]
&gt; üí° [Use LiteLLM Proxy with Langchain (Python, JS), OpenAI SDK (Python, JS) Anthropic SDK, Mistral SDK, LlamaIndex, Instructor, Curl](https://docs.litellm.ai/docs/proxy/user_keys)  

```python
import openai # openai v1.0.0+
client = openai.OpenAI(api_key=&quot;anything&quot;,base_url=&quot;http://0.0.0.0:4000&quot;) # set proxy to base_url
# request sent to model set on litellm proxy, `litellm --model`
response = client.chat.completions.create(model=&quot;gpt-3.5-turbo&quot;, messages = [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;this is a test request, write a short poem&quot;
    }
])

print(response)
```

## Proxy Key Management ([Docs](https://docs.litellm.ai/docs/proxy/virtual_keys))

Connect the proxy with a Postgres DB to create proxy keys

```bash
# Get the code
git clone https://github.com/BerriAI/litellm

# Go to folder
cd litellm

# Add the master key - you can change this after setup
echo &#039;LITELLM_MASTER_KEY=&quot;sk-1234&quot;&#039; &gt; .env

# Add the litellm salt key - you cannot change this after adding a model
# It is used to encrypt / decrypt your LLM API Key credentials
# We recommend - https://1password.com/password-generator/ 
# password generator to get a random hash for litellm salt key
echo &#039;LITELLM_SALT_KEY=&quot;sk-1234&quot;&#039; &gt; .env

source .env

# Start
docker-compose up
```


UI on `/ui` on your proxy server
![ui_3](https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033)

Set budgets and rate limits across multiple projects
`POST /key/generate`

### Request

```shell
curl &#039;http://0.0.0.0:4000/key/generate&#039; \
--header &#039;Authorization: Bearer sk-1234&#039; \
--header &#039;Content-Type: application/json&#039; \
--data-raw &#039;{&quot;models&quot;: [&quot;gpt-3.5-turbo&quot;, &quot;gpt-4&quot;, &quot;claude-2&quot;], &quot;duration&quot;: &quot;20m&quot;,&quot;metadata&quot;: {&quot;user&quot;: &quot;ishaan@berri.ai&quot;, &quot;team&quot;: &quot;core-infra&quot;}}&#039;
```

### Expected Response

```shell
{
    &quot;key&quot;: &quot;sk-kdEXbIqZRwEeEiHwdg7sFA&quot;, # Bearer token
    &quot;expires&quot;: &quot;2023-11-19T01:38:25.838000+00:00&quot; # datetime object
}
```

## Supported Providers ([Docs](https://docs.litellm.ai/docs/providers))

| Provider                                                                            | [Completion](https://docs.litellm.ai/docs/#basic-usage) | [Streaming](https://docs.litellm.ai/docs/completion/stream#streaming-responses) | [Async Completion](https://docs.litellm.ai/docs/completion/stream#async-completion) | [Async Streaming](https://docs.litellm.ai/docs/completion/stream#async-streaming) | [Async Embedding](https://docs.litellm.ai/docs/embedding/supported_embedding) | [Async Image Generation](https://docs.litellm.ai/docs/image_generation) |
|-------------------------------------------------------------------------------------|---------------------------------------------------------|---------------------------------------------------------------------------------|-------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------|-------------------------------------------------------------------------------|-------------------------------------------------------------------------|
| [openai](https://docs.litellm.ai/docs/providers/openai)                             | ‚úÖ                                                       | ‚úÖ                                                                               | ‚úÖ                                                                                   | ‚úÖ                                                                                 | ‚úÖ                                                                             | ‚úÖ                                                                       |
| [Meta - Llama API](https://docs.litellm.ai/docs/providers/meta_llama)                               | ‚úÖ                                                       | ‚úÖ                                                                               | ‚úÖ                                                                                   | ‚úÖ                                                                                 |                                                                              |                                                                        |
| [azure](https://docs.litellm.ai/docs/providers/azure)                               | ‚úÖ                                                       | ‚úÖ                                                                               | ‚úÖ                                                                                   | ‚úÖ                                                                                 | ‚úÖ                                                                             | ‚úÖ                                                                       |
| [AI/ML API](https://docs.litellm.ai/docs/providers/aiml)                               | ‚úÖ                                                       | ‚úÖ                                                                               | ‚úÖ                                                                                   | ‚úÖ                                                                                 | ‚úÖ                                                                             | ‚úÖ                                                                       |
| [aws - sagemaker](https://docs.litellm.ai/docs/providers/aws_sagemaker)             | ‚úÖ                                                       | ‚úÖ                                                                               | ‚úÖ                                                                                   | ‚úÖ                                                                                 | ‚úÖ                                                                             |                                                                         |
| [aws - bedrock](https://docs.litellm.ai/docs/providers/bedrock)                     | ‚úÖ                                                       | ‚úÖ                                                                               | ‚úÖ                                                                                   | ‚úÖ                                                                                 | ‚úÖ                                                                             |                                                                         |
| [google - vertex_ai](https://docs.litellm.ai/docs/providers/vertex)                 | ‚úÖ                                                       | ‚úÖ                                                                               | ‚úÖ                                                                                   | ‚úÖ                                                                                 | ‚úÖ                                                                             | ‚úÖ                                                                       |
| [google - palm](https://docs.litellm.ai/docs/providers/palm)                        | ‚úÖ                                                       | ‚úÖ                                                                               | ‚úÖ                                                                                   | ‚úÖ                                                                                 |                                                                               |                                                                         |
| [google AI Studio - gemini](https://docs.litellm.ai/docs/providers/gemini)          | ‚úÖ                                                       | ‚úÖ                                                                               | ‚úÖ                                                                                   | ‚úÖ                                                                                 |                                                                               |                                                                         |
| [mistral ai api](https://docs.litellm.ai/docs/providers/mistral)                    | ‚úÖ                                                       | ‚úÖ                                                                               | ‚úÖ                                                                                   | ‚úÖ                                                                                 | ‚úÖ                                                                             |                                                                         |
| [cloudflare AI Workers](https://docs.litellm.ai/docs/providers/cloudflare_workers)  | ‚úÖ                                                       | ‚úÖ                                                                               | ‚úÖ                                                                                   | ‚úÖ                                                                                 |                                                                               |                                                                         |
| [cohere](https://docs.litellm.ai/docs/providers/cohere)                             | ‚úÖ                                                       | ‚úÖ                                                                               | ‚úÖ                                                                                   | ‚úÖ                                                                                 | ‚úÖ                                                                             |                                                                         |
| [anthropic](https://docs.litellm.ai/docs/providers/anthropic)                       | ‚úÖ                                                       | ‚úÖ                                                                               | ‚úÖ                                                                                   | ‚úÖ                                                                                 |                                                                               |                                                                         |
| [empower](https://docs.litellm.ai/docs/providers/empower)                    | ‚úÖ                                                      | ‚úÖ                                                                              | ‚úÖ                                                                                  | ‚úÖ                                                                                |
| [huggingface](https://docs.litellm.ai/docs/providers/huggingface)                   | ‚úÖ                                                       | ‚úÖ                                                                               | ‚úÖ                                                                                   | ‚úÖ                                                                                 | ‚úÖ                                                                             |                                                                         |
| [replicate](https://docs.litel

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[MervinPraison/PraisonAI]]></title>
            <link>https://github.com/MervinPraison/PraisonAI</link>
            <guid>https://github.com/MervinPraison/PraisonAI</guid>
            <pubDate>Wed, 04 Jun 2025 00:04:37 GMT</pubDate>
            <description><![CDATA[PraisonAI is a production-ready Multi AI Agents framework, designed to create AI Agents to automate and solve problems ranging from simple tasks to complex challenges. It provides a low-code solution to streamline the building and management of multi-agent LLM systems, emphasising simplicity, customisation, and effective human-agent collaboration.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/MervinPraison/PraisonAI">MervinPraison/PraisonAI</a></h1>
            <p>PraisonAI is a production-ready Multi AI Agents framework, designed to create AI Agents to automate and solve problems ranging from simple tasks to complex challenges. It provides a low-code solution to streamline the building and management of multi-agent LLM systems, emphasising simplicity, customisation, and effective human-agent collaboration.</p>
            <p>Language: Python</p>
            <p>Stars: 4,636</p>
            <p>Forks: 647</p>
            <p>Stars today: 252 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/logo/dark.png&quot; /&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/logo/light.png&quot; /&gt;
    &lt;img alt=&quot;PraisonAI Logo&quot; src=&quot;docs/logo/light.png&quot; /&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/MervinPraison/PraisonAI&quot;&gt;&lt;img src=&quot;https://static.pepy.tech/badge/PraisonAI&quot; alt=&quot;Total Downloads&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/MervinPraison/PraisonAI&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/MervinPraison/PraisonAI&quot; alt=&quot;Latest Stable Version&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/MervinPraison/PraisonAI&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-yellow.svg&quot; alt=&quot;License&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

# Praison AI

&lt;a href=&quot;https://trendshift.io/repositories/9130&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/9130&quot; alt=&quot;MervinPraison%2FPraisonAI | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

PraisonAI is a production-ready Multi-AI Agents framework with self-reflection, designed to create AI Agents to automate and solve problems ranging from simple tasks to complex challenges. By integrating PraisonAI Agents, AG2 (Formerly AutoGen), and CrewAI into a low-code solution, it streamlines the building and management of multi-agent LLM systems, emphasising simplicity, customisation, and effective human-agent collaboration.

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.praison.ai&quot;&gt;
    &lt;p align=&quot;center&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/üìö_Documentation-Visit_docs.praison.ai-blue?style=for-the-badge&amp;logo=bookstack&amp;logoColor=white&quot; alt=&quot;Documentation&quot; /&gt;
    &lt;/p&gt;
  &lt;/a&gt;
&lt;/div&gt;

## Key Features

- ü§ñ Automated AI Agents Creation
- üîÑ Self Reflection AI Agents
- üß† Reasoning AI Agents
- üëÅÔ∏è Multi Modal AI Agents
- ü§ù Multi Agent Collaboration
- üé≠ AI Agent Workflow
- üìö Add Custom Knowledge
- üß† Agents with Short and Long Term Memory
- üìÑ Chat with PDF Agents
- üíª Code Interpreter Agents
- üìö RAG Agents
- ü§î Async &amp; Parallel Processing
- üîÑ Auto Agents
- üî¢ Math Agents
- üéØ Structured Output Agents
- üîó LangChain Integrated Agents
- üìû Callback Agents
- ü§è Mini AI Agents
- üõ†Ô∏è 100+ Custom Tools
- üìÑ YAML Configuration
- üíØ 100+ LLM Support

## Using Python Code

Light weight package dedicated for coding:
```bash
pip install praisonaiagents
```

```bash
export OPENAI_API_KEY=xxxxxxxxxxxxxxxxxxxxxx
```

### 1. Single Agent

Create app.py file and add the code below:
```python
from praisonaiagents import Agent
agent = Agent(instructions=&quot;Your are a helpful AI assistant&quot;)
agent.start(&quot;Write a movie script about a robot in Mars&quot;)
```

Run:
```bash
python app.py
```

### 2. Multi Agents

Create app.py file and add the code below:
```python
from praisonaiagents import Agent, PraisonAIAgents

research_agent = Agent(instructions=&quot;Research about AI&quot;)
summarise_agent = Agent(instructions=&quot;Summarise research agent&#039;s findings&quot;)
agents = PraisonAIAgents(agents=[research_agent, summarise_agent])
agents.start()
```

Run:
```bash
python app.py
```

## Using No Code

### Auto Mode:
```bash
pip install praisonai
export OPENAI_API_KEY=xxxxxxxxxxxxxxxxxxxxxx
praisonai --auto create a movie script about Robots in Mars
```

## Using JavaScript Code

```bash
npm install praisonai
export OPENAI_API_KEY=xxxxxxxxxxxxxxxxxxxxxx
```

```javascript
const { Agent } = require(&#039;praisonai&#039;);
const agent = new Agent({ instructions: &#039;You are a helpful AI assistant&#039; });
agent.start(&#039;Write a movie script about a robot in Mars&#039;);
```

![PraisonAI CLI Demo](docs/demo/praisonai-cli-demo.gif)

## AI Agents Flow

```mermaid
graph LR
    %% Define the main flow
    Start([‚ñ∂ Start]) --&gt; Agent1
    Agent1 --&gt; Process[‚öô Process]
    Process --&gt; Agent2
    Agent2 --&gt; Output([‚úì Output])
    Process -.-&gt; Agent1
    
    %% Define subgraphs for agents and their tasks
    subgraph Agent1[ ]
        Task1[üìã Task]
        AgentIcon1[ü§ñ AI Agent]
        Tools1[üîß Tools]
        
        Task1 --- AgentIcon1
        AgentIcon1 --- Tools1
    end
    
    subgraph Agent2[ ]
        Task2[üìã Task]
        AgentIcon2[ü§ñ AI Agent]
        Tools2[üîß Tools]
        
        Task2 --- AgentIcon2
        AgentIcon2 --- Tools2
    end

    classDef input fill:#8B0000,stroke:#7C90A0,color:#fff
    classDef process fill:#189AB4,stroke:#7C90A0,color:#fff
    classDef tools fill:#2E8B57,stroke:#7C90A0,color:#fff
    classDef transparent fill:none,stroke:none

    class Start,Output,Task1,Task2 input
    class Process,AgentIcon1,AgentIcon2 process
    class Tools1,Tools2 tools
    class Agent1,Agent2 transparent
```

## AI Agents with Tools

Create AI agents that can use tools to interact with external systems and perform actions.

```mermaid
flowchart TB
    subgraph Tools
        direction TB
        T3[Internet Search]
        T1[Code Execution]
        T2[Formatting]
    end

    Input[Input] ---&gt; Agents
    subgraph Agents
        direction LR
        A1[Agent 1]
        A2[Agent 2]
        A3[Agent 3]
    end
    Agents ---&gt; Output[Output]

    T3 --&gt; A1
    T1 --&gt; A2
    T2 --&gt; A3

    style Tools fill:#189AB4,color:#fff
    style Agents fill:#8B0000,color:#fff
    style Input fill:#8B0000,color:#fff
    style Output fill:#8B0000,color:#fff
```

## AI Agents with Memory

Create AI agents with memory capabilities for maintaining context and information across tasks.

```mermaid
flowchart TB
    subgraph Memory
        direction TB
        STM[Short Term]
        LTM[Long Term]
    end

    subgraph Store
        direction TB
        DB[(Vector DB)]
    end

    Input[Input] ---&gt; Agents
    subgraph Agents
        direction LR
        A1[Agent 1]
        A2[Agent 2]
        A3[Agent 3]
    end
    Agents ---&gt; Output[Output]

    Memory &lt;--&gt; Store
    Store &lt;--&gt; A1
    Store &lt;--&gt; A2
    Store &lt;--&gt; A3

    style Memory fill:#189AB4,color:#fff
    style Store fill:#2E8B57,color:#fff
    style Agents fill:#8B0000,color:#fff
    style Input fill:#8B0000,color:#fff
    style Output fill:#8B0000,color:#fff
```

## AI Agents with Different Processes

### Sequential Process

The simplest form of task execution where tasks are performed one after another.

```mermaid
graph LR
    Input[Input] --&gt; A1
    subgraph Agents
        direction LR
        A1[Agent 1] --&gt; A2[Agent 2] --&gt; A3[Agent 3]
    end
    A3 --&gt; Output[Output]

    classDef input fill:#8B0000,stroke:#7C90A0,color:#fff
    classDef process fill:#189AB4,stroke:#7C90A0,color:#fff
    classDef transparent fill:none,stroke:none

    class Input,Output input
    class A1,A2,A3 process
    class Agents transparent
```

### Hierarchical Process

Uses a manager agent to coordinate task execution and agent assignments.

```mermaid
graph TB
    Input[Input] --&gt; Manager
    
    subgraph Agents
        Manager[Manager Agent]
        
        subgraph Workers
            direction LR
            W1[Worker 1]
            W2[Worker 2]
            W3[Worker 3]
        end
        
        Manager --&gt; W1
        Manager --&gt; W2
        Manager --&gt; W3
    end
    
    W1 --&gt; Manager
    W2 --&gt; Manager
    W3 --&gt; Manager
    Manager --&gt; Output[Output]

    classDef input fill:#8B0000,stroke:#7C90A0,color:#fff
    classDef process fill:#189AB4,stroke:#7C90A0,color:#fff
    classDef transparent fill:none,stroke:none

    class Input,Output input
    class Manager,W1,W2,W3 process
    class Agents,Workers transparent
```

### Workflow Process

Advanced process type supporting complex task relationships and conditional execution.

```mermaid
graph LR
    Input[Input] --&gt; Start
    
    subgraph Workflow
        direction LR
        Start[Start] --&gt; C1{Condition}
        C1 --&gt; |Yes| A1[Agent 1]
        C1 --&gt; |No| A2[Agent 2]
        A1 --&gt; Join
        A2 --&gt; Join
        Join --&gt; A3[Agent 3]
    end
    
    A3 --&gt; Output[Output]

    classDef input fill:#8B0000,stroke:#7C90A0,color:#fff
    classDef process fill:#189AB4,stroke:#7C90A0,color:#fff
    classDef decision fill:#2E8B57,stroke:#7C90A0,color:#fff
    classDef transparent fill:none,stroke:none

    class Input,Output input
    class Start,A1,A2,A3,Join process
    class C1 decision
    class Workflow transparent
```

#### Agentic Routing Workflow

Create AI agents that can dynamically route tasks to specialized LLM instances.

```mermaid
flowchart LR
    In[In] --&gt; Router[LLM Call Router]
    Router --&gt; LLM1[LLM Call 1]
    Router --&gt; LLM2[LLM Call 2]
    Router --&gt; LLM3[LLM Call 3]
    LLM1 --&gt; Out[Out]
    LLM2 --&gt; Out
    LLM3 --&gt; Out
    
    style In fill:#8B0000,color:#fff
    style Router fill:#2E8B57,color:#fff
    style LLM1 fill:#2E8B57,color:#fff
    style LLM2 fill:#2E8B57,color:#fff
    style LLM3 fill:#2E8B57,color:#fff
    style Out fill:#8B0000,color:#fff
```

#### Agentic Orchestrator Worker

Create AI agents that orchestrate and distribute tasks among specialized workers.

```mermaid
flowchart LR
    In[In] --&gt; Router[LLM Call Router]
    Router --&gt; LLM1[LLM Call 1]
    Router --&gt; LLM2[LLM Call 2]
    Router --&gt; LLM3[LLM Call 3]
    LLM1 --&gt; Synthesizer[Synthesizer]
    LLM2 --&gt; Synthesizer
    LLM3 --&gt; Synthesizer
    Synthesizer --&gt; Out[Out]
    
    style In fill:#8B0000,color:#fff
    style Router fill:#2E8B57,color:#fff
    style LLM1 fill:#2E8B57,color:#fff
    style LLM2 fill:#2E8B57,color:#fff
    style LLM3 fill:#2E8B57,color:#fff
    style Synthesizer fill:#2E8B57,color:#fff
    style Out fill:#8B0000,color:#fff
```

#### Agentic Autonomous Workflow

Create AI agents that can autonomously monitor, act, and adapt based on environment feedback.

```mermaid
flowchart LR
    Human[Human] &lt;--&gt; LLM[LLM Call]
    LLM --&gt;|ACTION| Environment[Environment]
    Environment --&gt;|FEEDBACK| LLM
    LLM --&gt; Stop[Stop]
    
    style Human fill:#8B0000,color:#fff
    style LLM fill:#2E8B57,color:#fff
    style Environment fill:#8B0000,color:#fff
    style Stop fill:#333,color:#fff
```

#### Agentic Parallelization

Create AI agents that can execute tasks in parallel for improved performance.

```mermaid
flowchart LR
    In[In] --&gt; LLM2[LLM Call 2]
    In --&gt; LLM1[LLM Call 1]
    In --&gt; LLM3[LLM Call 3]
    LLM1 --&gt; Aggregator[Aggregator]
    LLM2 --&gt; Aggregator
    LLM3 --&gt; Aggregator
    Aggregator --&gt; Out[Out]
    
    style In fill:#8B0000,color:#fff
    style LLM1 fill:#2E8B57,color:#fff
    style LLM2 fill:#2E8B57,color:#fff
    style LLM3 fill:#2E8B57,color:#fff
    style Aggregator fill:#fff,color:#000
    style Out fill:#8B0000,color:#fff
```

#### Agentic Prompt Chaining

Create AI agents with sequential prompt chaining for complex workflows.

```mermaid
flowchart LR
    In[In] --&gt; LLM1[LLM Call 1] --&gt; Gate{Gate}
    Gate --&gt;|Pass| LLM2[LLM Call 2] --&gt;|Output 2| LLM3[LLM Call 3] --&gt; Out[Out]
    Gate --&gt;|Fail| Exit[Exit]
    
    style In fill:#8B0000,color:#fff
    style LLM1 fill:#2E8B57,color:#fff
    style LLM2 fill:#2E8B57,color:#fff
    style LLM3 fill:#2E8B57,color:#fff
    style Out fill:#8B0000,color:#fff
    style Exit fill:#8B0000,color:#fff
```

#### Agentic Evaluator Optimizer

Create AI agents that can generate and optimize solutions through iterative feedback.

```mermaid
flowchart LR
    In[In] --&gt; Generator[LLM Call Generator] 
    Generator --&gt;|SOLUTION| Evaluator[LLM Call Evaluator] --&gt;|ACCEPTED| Out[Out]
    Evaluator --&gt;|REJECTED + FEEDBACK| Generator
    
    style In fill:#8B0000,color:#fff
    style Generator fill:#2E8B57,color:#fff
    style Evaluator fill:#2E8B57,color:#fff
    style Out fill:#8B0000,color:#fff
```

#### Repetitive Agents

Create AI agents that can efficiently handle repetitive tasks through automated loops.

```mermaid
flowchart LR
    In[Input] --&gt; LoopAgent[(&quot;Looping Agent&quot;)]
    LoopAgent --&gt; Task[Task]
    Task --&gt; |Next iteration| LoopAgent
    Task --&gt; |Done| Out[Output]
    
    style In fill:#8B0000,color:#fff
    style LoopAgent fill:#2E8B57,color:#fff,shape:circle
    style Task fill:#2E8B57,color:#fff
    style Out fill:#8B0000,color:#fff
```

## Adding Models

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.praison.ai/models&quot;&gt;
    &lt;p align=&quot;center&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/%F0%9F%93%9A_Models-Visit_docs.praison.ai-blue?style=for-the-badge&amp;logo=bookstack&amp;logoColor=white&quot; alt=&quot;Models&quot; /&gt;
    &lt;/p&gt;
  &lt;/a&gt;
&lt;/div&gt;

## Ollama Integration
```bash
export OPENAI_BASE_URL=http://localhost:11434/v1
```

## Groq Integration
Replace xxxx with Groq API KEY:
```bash
export OPENAI_API_KEY=xxxxxxxxxxx
export OPENAI_BASE_URL=https://api.groq.com/openai/v1
```

## No Code Options

## Agents Playbook

### Simple Playbook Example

Create `agents.yaml` file and add the code below:

```yaml
framework: praisonai
topic: Artificial Intelligence
roles:
  screenwriter:
    backstory: &quot;Skilled in crafting scripts with engaging dialogue about {topic}.&quot;
    goal: Create scripts from concepts.
    role: Screenwriter
    tasks:
      scriptwriting_task:
        description: &quot;Develop scripts with compelling characters and dialogue about {topic}.&quot;
        expected_output: &quot;Complete script ready for production.&quot;
```

*To run the playbook:*
```bash
praisonai agents.yaml
```

## Use 100+ Models

- https://docs.praison.ai/models/
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.praison.ai&quot;&gt;
    &lt;p align=&quot;center&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/üìö_Documentation-Visit_docs.praison.ai-blue?style=for-the-badge&amp;logo=bookstack&amp;logoColor=white&quot; alt=&quot;Documentation&quot; /&gt;
    &lt;/p&gt;
  &lt;/a&gt;
&lt;/div&gt;

## Development:

Below is used for development only.

### Using uv
```bash
# Install uv if you haven&#039;t already
pip install uv

# Install from requirements
uv pip install -r pyproject.toml

# Install with extras
uv pip install -r pyproject.toml --extra code
uv pip install -r pyproject.toml --extra &quot;crewai,autogen&quot;
```

## Contributing

- Fork on GitHub: Use the &quot;Fork&quot; button on the repository page.
- Clone your fork: `git clone https://github.com/yourusername/praisonAI.git`
- Create a branch: `git checkout -b new-feature`
- Make changes and commit: `git commit -am &quot;Add some feature&quot;`
- Push to your fork: `git push origin new-feature`
- Submit a pull request via GitHub&#039;s web interface.
- Await feedback from project maintainers.

## Other Features

- üîÑ Use CrewAI or AG2 (Formerly AutoGen) Framework
- üíª Chat with ENTIRE Codebase
- üé® Interactive UIs
- üìÑ YAML-based Configuration
- üõ†Ô∏è Custom Tool Integration
- üîç Internet Search Capability (using Crawl4AI and Tavily)
- üñºÔ∏è Vision Language Model (VLM) Support
- üéôÔ∏è Real-time Voice Interaction

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=MervinPraison/PraisonAI&amp;type=Date)](https://docs.praison.ai)

## Video Tutorials

| Topic | Video |
|-------|--------|
| AI Agents with Self Reflection | [![Self Reflection](https://img.youtube.com/vi/vLXobEN2Vc8/0.jpg)](https://www.youtube.com/watch?v=vLXobEN2Vc8) |
| Reasoning Data Generating Agent | [![Reasoning Data](https://img.youtube.com/vi/fUT332Y2zA8/0.jpg)](https://www.youtube.com/watch?v=fUT332Y2zA8) |
| AI Agents with Reasoning | [![Reasoning](https://img.youtube.com/vi/KNDVWGN3TpM/0.jpg)](https://www.youtube.com/watch?v=KNDVWGN3TpM) |
| Multimodal AI Agents | [![Multimodal](https://img.youtube.com/vi/hjAWmUT1qqY/0.jpg)](https://www.youtube.com/watch?v=hjAWmUT1qqY) |
| AI Agents Workflow | [![Workflow](https://img.youtube.com/vi/yWTH44QPl2A/0.jpg)](https://www.youtube.com/watch?v=yWTH44QPl2A) |
| Async AI Agents | [![Async](https://img.youtube.com/vi/VhVQfgo00LE/0.jpg)](https://www.youtube.com/watch?v=VhVQfgo00LE) |
| Mini AI Agents | [![Mini](https://img.youtube.com/vi/OkvYp5aAGSg/0.jpg)](https://www.youtube.com/watch?v=OkvYp5aAGSg) |
| AI Agents with Memory | [![Memory](https://img.youtube.com/vi/1hVfVxvPnnQ/0.jpg)](https://www.youtube.com/watch?v=1hVfVxvPnnQ) |
| Repetitive Agents | [![Repetitive](https://img.youtube.com/vi/dAYGxsjDOPg/0.jpg)](https://www.youtube.com/watch?v=dAYGxsjDOPg) |
| Introduction | [![Introduction](https://img.youtube.com/vi/Fn1lQjC0GO0/0.jpg)](https://www.youtube.com/watch?v=Fn1lQjC0GO0) |
| Tools Overview | [![Tools Overview](https://img.youtube.com/vi/XaQRgRpV7jo/0.jpg)](https://www.youtube.com/watch?v=XaQRgRpV7jo) |
| Custom Tools | [![Custom Tools](https://img.youtube.com/vi/JSU2Rndh06c/0.jpg)](https://www.youtube.com/watch?v=JSU2Rndh06c) |
| Firecrawl Integration | [![Firecrawl](https://img.youtube.com/vi/UoqUDcLcOYo/0.jpg)](https://www.youtube.com/watch?v=UoqUDcLcOYo) |
| User Interface | [![UI](https://img.youtube.com/vi/tg-ZjNl3OCg/0.jpg)](https://www.youtube.com/watch?v=tg-ZjNl3OCg) |
| Crawl4AI Integration | [![Crawl4AI](https://img.youtube.com/vi/KAvuVUh0XU8/0.jpg)](https://www.youtube.com/watch?v=KAvuVUh0XU8) |
| Chat Interface | [![Chat](https://img.youtube.com/vi/sw3uDqn2h1Y/0.jpg)](https://www.youtube.com/watch?v=sw3uDqn2h1Y) |
| Code Interface | [![Code](https://img.youtube.com/vi/_5jQayO-MQY/0.jpg)](https://www.youtube.com/watch?v=_5jQayO-MQY) |
| Mem0 Integration | [![Mem0](https://img.youtube.com/vi/KIGSgRxf1cY/0.jpg)](https://www.youtube.com/watch?v=KIGSgRxf1cY) |
| Training | [![Training](https://img.youtube.com/vi/aLawE8kwCrI/0.jpg)](https://www.youtube.com/watch?v=aLawE8kwCrI) |
| Realtime Voice Interface | [![Realtime](https://img.youtube.com/vi/frRHfevTCSw/0.jpg)](https://www.youtube.com/watch?v=frRHfevTCSw) |
| Call Interface | [![Call](https://img.youtube.com/vi/m1cwrUG2iAk/0.jpg)](https://www.youtube.com/watch?v=m1cwrUG2iAk) |
| Reasoning Extract Agents | [![Reasoning Extract](https://img.youtube.com/vi/2PPamsADjJA/0.jpg)](https://www.youtube.com/watch?v=2PPamsADjJA) |

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[mofeng-git/One-KVM]]></title>
            <link>https://github.com/mofeng-git/One-KVM</link>
            <guid>https://github.com/mofeng-git/One-KVM</guid>
            <pubDate>Wed, 04 Jun 2025 00:04:36 GMT</pubDate>
            <description><![CDATA[One-KVM ÊòØÂü∫‰∫éÂªâ‰ª∑ËÆ°ÁÆóÊú∫Á°¨‰ª∂Âíå PiKVM ËΩØ‰ª∂‰∫åÊ¨°ÂºÄÂèëÁöÑ BIOS Á∫ßËøúÁ®ãÊéßÂà∂È°πÁõÆ„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mofeng-git/One-KVM">mofeng-git/One-KVM</a></h1>
            <p>One-KVM ÊòØÂü∫‰∫éÂªâ‰ª∑ËÆ°ÁÆóÊú∫Á°¨‰ª∂Âíå PiKVM ËΩØ‰ª∂‰∫åÊ¨°ÂºÄÂèëÁöÑ BIOS Á∫ßËøúÁ®ãÊéßÂà∂È°πÁõÆ„ÄÇ</p>
            <p>Language: Python</p>
            <p>Stars: 1,242</p>
            <p>Forks: 122</p>
            <p>Stars today: 59 stars today</p>
            <h2>README</h2><pre>&lt;h3 align=center&gt;&lt;img src=&quot;https://github.com/mofeng-git/Build-Armbian/assets/62919083/add9743a-0987-4e8a-b2cb-62121f236582&quot; alt=&quot;logo&quot; width=&quot;300&quot;&gt;&lt;br&gt;&lt;/h3&gt;
&lt;h3 align=center&gt;&lt;a href=&quot;https://github.com/mofeng-git/One-KVM/blob/master/README.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; &lt;/h3&gt;
&lt;p align=right&gt;&amp;nbsp;&lt;/p&gt;

### È°πÁõÆ‰ªãÁªç

**One-KVM** ÊòØ‰∏ÄÊ¨æÂü∫‰∫éÁªèÊµéÂÆûÊÉ†ÁöÑÁ°¨‰ª∂ÂíåÂº∫Â§ßÁöÑÂºÄÊ∫ê [PiKVM](https://github.com/pikvm/pikvm) ËΩØ‰ª∂ËøõË°å‰∫åÊ¨°ÂºÄÂèëÁöÑ DIY IP-KVM Ëß£ÂÜ≥ÊñπÊ°à„ÄÇÂÆÉÊó®Âú®‰∏∫ÊÇ®Êèê‰æõ**BIOS Á∫ßÂà´**ÁöÑËøúÁ®ãÊúçÂä°Âô®ÊàñÂ∑•‰ΩúÁ´ôÁÆ°ÁêÜËÉΩÂäõÔºåÂ¶ÇÂêåÊÇ®‰∫≤Ë∫´ÂùêÂú®Â±èÂπïÂâçÊìç‰Ωú‰∏ÄËà¨„ÄÇ

**Ê†∏ÂøÉ‰ºòÂäøÔºö**

*   **ÂÆåÂÖ®Êó†‰æµÂÖ•:** Êó†ÈúÄÂú®ÁõÆÊ†áÊú∫Âô®‰∏äÂÆâË£Ö‰ªª‰ΩïËΩØ‰ª∂ÊàñÈ©±Âä®Ôºå‰∏ç‰æùËµñÊìç‰ΩúÁ≥ªÁªüÔºåÂèØËøúÁ®ãËÆøÈóÆ BIOS/UEFI ËÆæÁΩÆ„ÄÅËøõË°åÁ≥ªÁªüÂÆâË£ÖÊàñÊïÖÈöúÊéíÊü•„ÄÇ
*   **‰ΩéÊàêÊú¨ÂÆûÁé∞:** Âà©Áî®Â∏∏ËßÅÁöÑÂªâ‰ª∑Á°¨‰ª∂ÔºàÂ¶ÇÊóßÂÆâÂçìÁõíÂ≠ê„ÄÅÂºÄÂèëÊùøÁ≠âÔºâÂç≥ÂèØÊê≠Âª∫ÔºåÂ§ßÂπÖÈôç‰Ωé KVM over IP ÁöÑÈó®Êßõ„ÄÇ
*   **ÂäüËÉΩ‰∏∞ÂØå:** Âú® PiKVM Âü∫Á°Ä‰∏äÔºåÂ¢ûÂä†‰∫Ü Docker ÈÉ®ÁΩ≤„ÄÅËßÜÈ¢ëÂΩïÂà∂„ÄÅÁÆÄ‰Ωì‰∏≠ÊñáÁïåÈù¢‰ºòÂåñÁ≠âÂ§öÈ°πÂÆûÁî®ÂäüËÉΩ (ËØ¶ËßÅ‰∏ãÊñπÂäüËÉΩÂØπÊØî)„ÄÇ
*   **ÈÉ®ÁΩ≤ÁÅµÊ¥ª:** ÊîØÊåÅ Docker Âø´ÈÄüÈÉ®ÁΩ≤ÔºåÂπ∂‰∏∫ÁâπÂÆöÁ°¨‰ª∂Âπ≥Âè∞ÔºàÂ¶ÇÁé©ÂÆ¢‰∫ë„ÄÅÊàëÂÆ∂‰∫ëÁ≠âÔºâÊèê‰æõÂºÄÁÆ±Âç≥Áî®ÁöÑÊï¥ÂêàÂåÖ„ÄÇ

Êó†ËÆ∫ÊÇ®ÊòØÈúÄË¶ÅÁÆ°ÁêÜÂÆ∂Â∫≠ÂÆûÈ™åÂÆ§„ÄÅÂäûÂÖ¨ÂÆ§ÊúçÂä°Âô®ÔºåËøòÊòØÂ∏åÊúõ‰∏∫ÁâπÂÆöÂµåÂÖ•ÂºèËÆæÂ§áÊ∑ªÂä†ËøúÁ®ãÁÆ°ÁêÜËÉΩÂäõÔºåOne-KVM ÈÉΩÊèê‰æõ‰∫Ü‰∏Ä‰∏™È´òÊÄß‰ª∑ÊØî‰∏îÂäüËÉΩÂº∫Â§ßÁöÑÈÄâÊã©„ÄÇ

**Âø´ÈÄüËÆøÈóÆ:**

*   **ËØ¶ÁªÜ‰ΩøÁî®ÊñáÊ°£:** [https://one-kvm.mofeng.run](https://one-kvm.mofeng.run)
*   **Âú®Á∫øÊºîÁ§∫:** [https://kvmd-demo.mofeng.run](https://kvmd-demo.mofeng.run)

![One-KVM ÁïåÈù¢Êà™Âõæ](https://github.com/user-attachments/assets/a7848bca-e43c-434e-b812-27a45fad7910)

### ËΩØ‰ª∂ÂäüËÉΩ

Ë°®Ê†º‰ªÖ‰∏∫ One-KVM ‰∏éÂÖ∂‰ªñÂü∫‰∫é PiKVM ÁöÑÈ°πÁõÆÁöÑÂäüËÉΩÂØπÊØîÔºåÊó†‰∏çËâØÂØºÂêëÔºåÂ¶ÇÊúâÈîôÊºèËØ∑ËÅîÁ≥ªÊõ¥Ê≠£„ÄÇ

|         ÂäüËÉΩ          |     One-KVM     |           PiKVM           |   ArmKVM    |   BLIKVM    |
| :-------------------: | :-------------: | :-----------------------: | :---------: | :---------: |
|       Á≥ªÁªüÂºÄÊ∫ê        |        ‚àö        |             ‚àö             |      ‚àö      |      ‚àö      |
|    ÁÆÄ‰Ωì‰∏≠Êñá WebUI     |        ‚àö        |             x             |      ‚àö      |      ‚àö      |
|      ËøúÁ®ãËßÜÈ¢ëÊµÅ       |   MJPEG/H.264   |        MJPEG/H.264        | MJPEG/H.264 | MJPEG/H.264 |
|    H.264 ËßÜÈ¢ëÁºñÁ†Å     |       CPU       |            GPU            |    Êú™Áü•     |     GPU     |
|      ËøúÁ®ãÈü≥È¢ëÊµÅ       |        ‚àö        |             ‚àö             |      ‚àö      |      ‚àö      |
|   ËøúÁ®ãÈº†ÈîÆÊéßÂà∂        |   OTG/CH9329    | OTG/CH9329/Pico/Bluetooth |     OTG     |     OTG     |
|       VNC ÊéßÂà∂        |        ‚àö        |             ‚àö             |      ‚àö      |      ‚àö      |
|     ATX ÁîµÊ∫êÊéßÂà∂      | GPIO/USB ÁªßÁîµÂô® |           GPIO            |    GPIO     |    GPIO     |
| ËôöÊãüÂ≠òÂÇ®È©±Âä®Âô®ÊåÇËΩΩ     |        ‚àö        |             ‚àö             |      ‚àö      |      ‚àö      |
| 2.2G ‰ª•‰∏ä CD-ROM ÊåÇËΩΩ |        x        |             x             |      ‚àö      |      ‚àö      |
|     WOL ËøúÁ®ãÂî§ÈÜí      |        ‚àö        |             ‚àö             |      ‚àö      |      ‚àö      |
|      ÁΩëÈ°µÂâ™ÂàáÊùø       |        ‚àö        |             ‚àö             |      ‚àö      |      ‚àö      |
|     OCR ÊñáÂ≠óËØÜÂà´      |        ‚àö        |             ‚àö             |      ‚àö      |      ‚àö      |
|       ÁΩëÈ°µÁªàÁ´Ø        |        ‚àö        |             ‚àö             |      ‚àö      |      ‚àö      |
|     ÁΩëÁªú‰∏≤Âè£ÁªàÁ´Ø      |        x        |             x             |      ‚àö      |      ‚àö      |
|    HDMI ÂàáÊç¢Âô®ÊîØÊåÅ    |        ‚àö        |             ‚àö             |      ‚àö      |      ‚àö      |
|       ËßÜÈ¢ëÂΩïÂà∂        |        ‚àö        |             x             |      x      |      x      |
|      Docker ÈÉ®ÁΩ≤      |        ‚àö        |             x             |      x      |      x      |
|    ÂÆòÊñπÂïÜ‰∏öÂåñÊàêÂìÅ     |        x        |             ‚àö             |      ‚àö      |      ‚àö      |
|       ÊäÄÊúØÊîØÊåÅ        |        ‚àö        |             ‚àö             |      ‚àö      |      ‚àö      |

### Âø´ÈÄüÂºÄÂßã

Êõ¥Â§öËØ¶ÁªÜÂÜÖÂÆπÂèØ‰ª•Êü•ÈòÖ [One-KVMÊñáÊ°£](https://one-kvm.mofeng.run/)„ÄÇ

**ÊñπÂºè‰∏ÄÔºöDocker ÈïúÂÉèÈÉ®ÁΩ≤ÔºàÊé®ËçêÔºâ**

Docker ÁâàÊú¨ÂèØ‰ª•‰ΩøÁî® OTG Êàñ CH9329 ‰Ωú‰∏∫ËôöÊãü HID ÔºåÊîØÊåÅ amd64„ÄÅarm64„ÄÅarmv7 Êû∂ÊûÑÁöÑ Linux Á≥ªÁªüÂÆâË£Ö„ÄÇ

**ËÑöÊú¨ÈÉ®ÁΩ≤**

```bash
curl -sSL https://one-kvm.mofeng.run/quick_start.sh -o quick_start.sh &amp;&amp; bash quick_start.sh
```

**ÊâãÂä®ÈÉ®ÁΩ≤**

Â¶ÇÊûú‰ΩøÁî® OTG ‰Ωú‰∏∫ËôöÊãü HIDÔºåÂèØ‰ª•‰ΩøÁî®Â¶Ç‰∏ãÈÉ®ÁΩ≤ÂëΩ‰ª§Ôºö
```bash
sudo docker run --name kvmd -itd --privileged=true \
    -v /lib/modules:/lib/modules:ro -v /dev:/dev \
    -v /sys/kernel/config:/sys/kernel/config -e OTG=1 \
    -p 8080:8080 -p 4430:4430 -p 5900:5900 -p 623:623 \
    silentwind0/kvmd
```

Â¶ÇÊûú‰ΩøÁî® CH9329 ‰Ωú‰∏∫ËôöÊãü HIDÔºåÂèØ‰ª•‰ΩøÁî®Â¶Ç‰∏ãÈÉ®ÁΩ≤ÂëΩ‰ª§Ôºö
```bash
sudo docker run --name kvmd -itd \
    --device /dev/video0:/dev/video0 \
    --device /dev/ttyUSB0:/dev/ttyUSB0 \
    --device /dev/snd:/dev/snd \
    -p 8080:8080 -p 4430:4430 -p 5900:5900 -p 623:623 \
    silentwind0/kvmd
```

**ÊñπÂºè‰∫åÔºöÁõ¥Âà∑ One-KVM Êï¥ÂêàÂåÖ**

ÂØπ‰∫éÈÉ®ÂàÜÂπ≥Âè∞Á°¨‰ª∂ÔºåÊú¨È°πÁõÆÂà∂‰Ωú‰∫ÜÊ∑±Â∫¶ÈÄÇÈÖçÁöÑ One-KVM ÊâìÂåÖÈïúÂÉèÔºåÂºÄÁÆ±Âç≥Áî®ÔºåÂà∑Â•ΩÂêéÂêØÂä®ËÆæÂ§áÂ∞±ÂèØ‰ª•ÂºÄÂßã‰ΩøÁî® One-KVM„ÄÇÂÖçË¥π One-KVM Êï¥ÂêàÂåÖ‰πüÂèØ‰ª•Âú®Êú¨È°πÁõÆ Releases È°µÂèØ‰ª•ÊâæÂà∞„ÄÇ

| Êï¥ÂêàÂåÖÈÄÇÈÖçÊ¶ÇÂÜµ | | | |
| :-------------: | :-------------: | :-------------: | :-------------: |
| **Âõ∫‰ª∂ÂûãÂè∑** | **Âõ∫‰ª∂‰ª£Âè∑** | **Á°¨‰ª∂ÊÉÖÂÜµ** | **ÊúÄÊñ∞ÁâàÊú¨** |
| Áé©ÂÆ¢‰∫ë | Onecloud | USB ÈááÈõÜÂç°„ÄÅOTG | 241018 |
| ÁßÅÂÆ∂‰∫ë‰∫å‰ª£ | Cumebox2 | USB ÈááÈõÜÂç°„ÄÅOTG | 241004 |
| Vmare | Vmare-uefi | USB ÈááÈõÜÂç°„ÄÅCH9329 | 241004 |
| Virtualbox | Virtualbox-uefi | USB ÈááÈõÜÂç°„ÄÅCH9329 | 241004 |
| s905l3a  ÈÄöÁî®ÂåÖ | E900v22c | USB ÈááÈõÜÂç°„ÄÅOTG | 241004 |
| ÊàëÂÆ∂‰∫ë | Chainedbox | USB ÈááÈõÜÂç°„ÄÅOTG | 241004 |
| ÈæôËäØ‰πÖ‰πÖÊ¥æ | 2k0300 | USB ÈááÈõÜÂç°„ÄÅCH9329 | 241025 |

### Êñá‰ª∂‰∏ãËΩΩ

GithubÔºöhttps://github.com/mofeng-git/One-KVM/releases

ÂÖçÁôªÂΩïÈ´òÈÄü‰∏ãËΩΩÂú∞ÂùÄÔºöhttps://pan.huang1111.cn/s/mxkx3T1 ÔºàÁî± Huang1111ÂÖ¨ÁõäËÆ°Âàí ËµûÂä©Ôºâ

ÁôæÂ∫¶ÁΩëÁõòÔºàÈúÄÁôªÂΩïÔºâÔºöhttps://pan.baidu.com/s/166-2Y8PBF4SbHXFkGmFJYg?pwd=o9aj

### ËµûÂä©ÊñπÂºè

Ëøô‰∏™È°πÁõÆÂü∫‰∫é‰ºóÂ§öÂºÄÊ∫êÈ°πÁõÆ‰∫åÊ¨°ÂºÄÂèëÔºå‰ΩúËÄÖ‰∏∫Ê≠§Ëä±Ë¥π‰∫ÜÂ§ßÈáèÁöÑÊó∂Èó¥ÂíåÁ≤æÂäõËøõË°åÊµãËØïÂíåÁª¥Êä§„ÄÇËã•Ê≠§È°πÁõÆÂØπÊÇ®ÊúâÁî®ÔºåÊÇ®ÂèØ‰ª•ËÄÉËôëÈÄöËøá **[‰∏∫Áà±ÂèëÁîµ](https://afdian.com/a/silentwind)** ËµûÂä©‰∏ÄÁ¨îÂ∞èÈí±ÊîØÊåÅ‰ΩúËÄÖ„ÄÇ‰ΩúËÄÖÂ∞ÜËÉΩÊúâÊõ¥Â§öÁöÑÈáëÈí±Êù•ÊµãËØïÂíåÁª¥Êä§ One-KVM ÁöÑÂêÑÁßçÈÖçÁΩÆÔºåÂπ∂Âú®È°πÁõÆ‰∏äÊäïÂÖ•Êõ¥Â§öÁöÑÊó∂Èó¥ÂíåÁ≤æÂäõ„ÄÇ

**ÊÑüË∞¢ÂêçÂçï**

&lt;details&gt;

Êµ©ÈæôÁöÑÁîµÂ≠êÂµåÂÖ•Âºè‰πãË∑ØÔºàËµûÂä©Ôºâ

TsukiÔºàËµûÂä©Ôºâ

H_xiaoming

0ËìùËìù0

fairybl

Will

Êµ©ÈæôÁöÑÁîµÂ≠êÂµåÂÖ•Âºè‰πãË∑Ø

Ëá™.Áü•

ËßÇÊ£ã‰∏çËØ≠Ÿ© ‡Ω≤€∂

Áà±ÂèëÁîµÁî®Êà∑_a57a4

Áà±ÂèëÁîµÁî®Êà∑_2c769

ÈúúÂ∫è

[ËøúÊñπ](https://runyf.cn/)ÔºàÈó≤È±ºÁî®Êà∑ÂêçÔºöÂ∞èËøúÊäÄÊúØÂ∫óÈì∫Ôºâ

Áà±ÂèëÁîµÁî®Êà∑_399fc

[ÊñêÊñê„ÅÆ](https://www.mmuaa.com/)

Áà±ÂèëÁîµÁî®Êà∑_09451

Ë∂ÖÈ´òÊ†°Á∫ßÁöÑÈåÜÈ±º

Áà±ÂèëÁîµÁî®Êà∑_08cff

guoke

mgt

ÂßúÊ≤¢Êéµ

ui_beam

Áà±ÂèëÁîµÁî®Êà∑_c0dd7

Áà±ÂèëÁîµÁî®Êà∑_dnjK

ÂøçËÄÖËÉñÁå™

Ê∞∏ÈÅ†„ÅÆÈ°ò„ÅÑ

Áà±ÂèëÁîµÁî®Êà∑_GBrF

Áà±ÂèëÁîµÁî®Êà∑_fd65c

Áà±ÂèëÁîµÁî®Êà∑_vhNa

Áà±ÂèëÁîµÁî®Êà∑_Xu6S

moss

woshididi

Áà±ÂèëÁîµÁî®Êà∑_a0fd1

Áà±ÂèëÁîµÁî®Êà∑_f6bH

......
&lt;/details&gt;

Êú¨È°πÁõÆ‰ΩøÁî®‰∫Ü‰∏ãÂàóÂºÄÊ∫êÈ°πÁõÆÔºö
1. [pikvm/pikvm: Open and inexpensive DIY IP-KVM based on Raspberry Pi (github.com)](https://github.com/pikvm/pikvm)

### È°πÁõÆÁä∂ÊÄÅ

[![Star History Chart](https://api.star-history.com/svg?repos=mofeng-git/One-KVM&amp;type=Date)](https://star-history.com/#mofeng-git/One-KVM&amp;Date)

![Github](https://repobeats.axiom.co/api/embed/7cfaab47e31073107771a7179078aa2a6c3f1108.svg &quot;Repobeats analytics image&quot;)


</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[willccbb/verifiers]]></title>
            <link>https://github.com/willccbb/verifiers</link>
            <guid>https://github.com/willccbb/verifiers</guid>
            <pubDate>Wed, 04 Jun 2025 00:04:35 GMT</pubDate>
            <description><![CDATA[Verifiers for LLM Reinforcement Learning]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/willccbb/verifiers">willccbb/verifiers</a></h1>
            <p>Verifiers for LLM Reinforcement Learning</p>
            <p>Language: Python</p>
            <p>Stars: 1,138</p>
            <p>Forks: 135</p>
            <p>Stars today: 29 stars today</p>
            <h2>README</h2><pre># Verifiers: Reinforcement Learning with LLMs in Verifiable Environments

## Overview

`verifiers` is a set of tools and abstractions for training LLMs with reinforcement learning in **verifiable multi-turn environments** via Group-Relative Policy Optimization. Our implementation of GRPO builds upon the base `transformers` Trainer, and is optimized for efficient async multi-turn inference and training with off-policy overlapping. In addition, `verifiers` includes support for synthetic data generation, SFT warmup on filtered rollouts, and offline evaluation with API clients.

**Core principles**:
RL environments and algorithms should be modular, reusable, and hackable.

- actor = client = OpenAI-compatible LLM endpoint
- environment = instructions + tasks + interaction protocol + rubric
- instructions = system prompts
- tasks = datasets + verifiable targets
- (multi-turn) interaction protocol = tool calls, gameplay, multi-agent systems, end-state determination
- rubric = reward mechanisms for verifying performance on instruction + task objectives
- environments = synthetic data engines = RL trainers = eval harnesses

**Key features:**
- First-class support for multi-turn tool use and agentic RL via `vf.GRPOTrainer`, built on top of `transformers`.
- Direct integration with OpenAI-compatible API clients for synthetic data generation and evaluation, in addition to RL training.
- Utilities for SFT warmup/&quot;cold start&quot; data (see `examples/warmup` scripts)
- Support for both `chat` (messages) and `completion` (text) requests in your rollouts
- `Parser` classes (e.g. `XMLParser`) for standardizing your prompt formats and text extraction.
- `Rubric` classes for managing sets of reward functions.
- `Environment` classes for encapsulating your tasks, parsers, rollout logic, and reward functions, including:
	- `SingleTurnEnv` for &quot;R1-style&quot; reasoning via vLLM&#039;s `chat()` method.
	- `ToolEnv` for multi-turn tool use with custom Python functions.
	- `SmolaToolEnv` for multi-turn tool use with Hugging Face [smolagents](https://huggingface.co/docs/smolagents/en/index) tools.
	- `CodeMathEnv` for interactive Python execution.
	- `MultiTurnEnv` abstract class for implementing custom multi-turn rollout logic on top of vLLM&#039;s `chat()` method -- just override `env_response` and `is_completed` and you&#039;re good to go.
	- `ReasoningGymEnv` -- direct training for any [reasoning-gym](https://github.com/open-thought/reasoning-gym/tree/main/reasoning_gym) task.
	- `Environment` abstract class for implementing whatever rollout logic you can imagine (go nuts!)

Basic usage for a GRPO training script with 4 GPUs (2 inference + 2 training):

```bash
# launch inference server
CUDA_VISIBLE_DEVICES=0,1 vf-vllm --model &#039;Qwen/Qwen2.5-1.5B-Instruct&#039; --tensor-parallel-size 2

# launch training script; copy zero3.yaml or set values globally with `accelerate config`
CUDA_VISIBLE_DEVICES=2,3 accelerate launch --num-processes 2 --config-file configs/zero3.yaml train.py
```

See [GRPO Rules of Thumb](#grpo-rules-of-thumb) for further discussion of hyperparameters and best practices; the easiest way to reduce memory requirements is by reducing `per_device_train_batch_size` and increasing `gradient_accumulation_steps` accordingly.

### Citation

If you use this code in your research, please cite:

```bibtex
@article{brown2025verifiers,
  title={Verifiers: Reinforcement Learning with LLMs in Verifiable Environments},
  author={Brown, William},
  year={2025}
}
```

## Getting Started

### Setup 

To use the latest `main` branch, do:
```bash
git clone https://github.com/willccbb/verifiers.git
cd verifiers
uv sync &amp;&amp; uv pip install flash-attn --no-build-isolation &amp;&amp; uv pip install -e &quot;.[all]&quot;
```

**Troubleshooting:**
- Ensure your `wandb` and `huggingface-cli` logins are set up (or set `report_to=None` in `training_args`). You should also have something set as your `OPENAI_API_KEY` in your environment (can be a dummy key for vLLM). 
- On some setups, inter-GPU communication can [hang](https://github.com/huggingface/trl/issues/2923) during vLLM weight syncing. This can usually be alleviated by setting `NCCL_P2P_DISABLE=1` in your environment.
- If problems persist, please open an [issue](https://github.com/willccbb/verifiers/issues).

### Resource Requirements

`verifiers` currently uses `transformers` Trainer as its primary training backend via `accelerate` (like Hugging Face&#039;s [TRL](https://github.com/huggingface/trl/tree/main/trl)), and is optimized for setups with at least 2 GPUs, scaling up to multiple 8xH100 nodes. 2-GPU setups with sufficient memory to enable small-scale experimentation can be [rented](https://app.primeintellect.ai/dashboard/create-cluster?image=ubuntu_22_cuda_12) for &lt;$1/hr.

Depending on your goals, there are other RL frameworks with native support for multi-turn tool use which you may be interested in exploring as well. If you are looking for maximum efficiency on a single GPU, consider OpenPipe&#039;s [ART](https://github.com/OpenPipe/ART) framework, which builds on top of [Unsloth](https://github.com/unslothai/unsloth). If you are seeking to maximize absolute performance at large scales, consider Nvidia&#039;s [NeMo-RL](https://github.com/NVIDIA/NeMo-RL) or ByteDance&#039;s [veRL](https://github.com/volcengine/verl) (which powers many agent RL projects like [RAGEN](https://github.com/RAGEN-AI/RAGEN) and [SkyRL](https://github.com/NovaSky-AI/SkyRL/tree/main)).

We aim to include support for additional trainer backends in the future, and are open to PRs. Our first-order objective is maintaining ease of use for users (and LLMs), and any potential contributions will be considered with this in mind. 

### Levels of Exploration
 
**Level 0:** Inspect and run the included examples for simple training tasks:
- `verifiers/examples/reverse_text.py`  (`SingleTurnEnv`)
- `verifiers/examples/math_python.py` (`ToolEnv`)

**Level 1:** Implement your own reasoning task with verifiable rewards using `SingleTurnEnv`:

```python
import verifiers as vf
parser = vf.XMLParser([&#039;think&#039;, &#039;answer&#039;]) # &lt;think&gt;...&lt;/think&gt;\n&lt;answer&gt;...&lt;/answer&gt;
rubric = vf.Rubric(
	your_custom_reward_func, # def func(prompt, completion, answer, **kwargs)
	parser.get_format_reward_func(),
weights=[1.0, 0.2])
vf_env = vf.SingleTurnEnv(
	dataset=..., # hf Dataset with &#039;question&#039; + &#039;answer&#039; columns
	system_prompt=f&quot;... Respond in the following format: {parser.get_format_str()}&quot;,
	rubric
)
```

**Level 2:** Evaluate API models in your environment and collect synthetic data:

```python
import os
from openai import OpenAI

client = OpenAI(base_url=&quot;https://api.deepseek.com&quot;, api_key=os.getenv(&#039;DEEPSEEK_API_KEY&#039;))

# evaluation
results = vf_env.evaluate(client, model=&quot;deepseek-chat&quot;, num_samples=100)
print(results[&#039;rewards_avg&#039;])

# datasets
# columns = [&#039;prompt&#039;, &#039;completion&#039;, &#039;answer&#039;, &#039;reward&#039;]
dataset_dsv3 = vf_env.make_dataset(results)
dataset_dsv3 = dataset_dsv3.sort(&quot;reward&quot;, reverse=True).select(range(50))
dataset_dsv3.push_to_hub(&quot;...&quot;)
```

**Level 2.5 (Optional, but recommended for &lt;7B models):** SFT warmup on synthetic data

See `verifiers/examples/sft/reverse_text.py` for an example script using TRL&#039;s SFTTrainer.

**Level 3:** Train a model in your environment using GRPO:

```python
# train.py

model, tokenizer = vf.get_model_and_tokenizer(model_name)
trainer = vf.GRPOTrainer(
    model=model,
    processing_class=tokenizer,
    env=vf_env,
    args=vf.grpo_defaults(run_name=&quot;...&quot;)
)
trainer.train()
```

**Level 4:** Implement your own multi-turn agent environment using `ToolEnv`, `SmolaToolEnv`, or `CodeEnv`:
```python
import verifiers as vf
vf_env = vf.ToolEnv(
	dataset=..., # hf Dataset with &#039;question&#039; + &#039;answer&#039; columns
	system_prompt=...,
	tools=[python, search, ask, calculator] # arbitrary python functions
	max_steps=5
)
```

**Level 5+:** Implement custom interaction protocols using `MultiTurnEnv`, `MultiTurnCompletionEnv`, or `Environment`

```python

class YourMultiTurnEnv(MultiTurnEnv):
    def __init__(self,
                 dataset: Dataset | None,
                 system_prompt: str | None, 
                 parser: Parser | None,
                 rubric: Rubric | None,
				 max_turns: int,
                 **kwargs):
	
  def is_completed(self, messages: list[dict], state: dict, **kwargs: Any) -&gt; bool:
    # return whether or not rollout is completed

  def env_response(self, messages: list[dict], state: dict, **kwargs: Any) -&gt; tuple[dict, dict]:
    # return environment response + updated state for a message-dict sequence

class YourCustomEnv(Environment):
	...
```

### GRPO Rules of Thumb
- RL is [notoriously](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/) sensitive to implementation details, and this applies to LLM GRPO as well. The default hyperparameter config in `vf.grpo_defaults()` is intended as a starting point which should be relatively stable for a broad variety of medium-difficulty tasks, informed by my own experimentation as well as broader community findings. 
- Always start by evaluating the performance of your model and/or API models in your environment 
	- If your model struggles to get non-zero rewards in 10+ trials, the task is likely too hard (consider simplifying, SFT warmup, or adjusting prompts)
	- If your model already gets 80%+ on a task without training, the dataset is likely too easy (consider prefiltering) 
- Tricks which may increase performance/speed, at the cost of risking &quot;collapse&quot;:
	- Setting the KL penalty `beta = 0` (removes the reference model)
	- Increasing the learning rate
	- Increasing the number of update steps per batch (`num_iterations`)
- Tricks which may stabilize training, at the cost of speed/performance
	- Increasing group size per prompt (`num_generations`)
	- Increasing prompts per batch (`per_device_train_batch_size`, `gradient_accumulation_steps`)
	- Decreasing `max_grad_norm` (clipping)
	- Using larger models (14B+)
	- Using more `num_generations` (larger group size)
	- Using LoRA adapters
	- Difficulty filtering (expensive up front)
- Tricks whose benefit remains up-for-debate or context-dependent:
	- High `beta` values (`0.1+`)
	- Dr. GRPO vs GRPO
	- Overlong filtering
	- Masking tool call responses (`mask_env_response` in  `MultiStepEnv`)
- Tricks which are likely a &quot;free lunch&quot;:
	- Learning rate warm-up of at least 10-20 steps (`warmup_steps`)
	- Periodically updating reference models (`sync_ref_model`, `ref_model_sync_steps`) if using a reference model, particularly for 500+ step runs
	- One-step off-policy training (overlapping training + inference) 
- For successful training, you generally want diversity of reward scores within each group of responses for a prompt (see DAPO [paper](https://arxiv.org/pdf/2503.14476), Sec. 3.2)
- The *best* way to increase diversity is to ensure that your tasks are of an appropriate difficulty for your model (not too easy, not too hard)
- See Hugging Face&#039;s [open-r1](https://huggingface.co/spaces/open-r1/README/discussions/20) logbook for lots of discussion, tips, and experimental findings


### Roadmap for v0.1 Release (very soon)

TODO: GitHub header stuff, test coverage, [PyPI](https://pypi.org/project/verifiers/), general release prep

New features for this release:
- Async inference support via OpenAI-compatible vLLM server (with weight syncing enabled)
- Async execution for rollouts + rubrics
- Native support for [reasoning-gym](https://github.com/open-thought/reasoning-gym) environments
- Overlapped training + inference (via off-policy steps)
- Rollout-level reward functions by default (with weight=0.0 supported)
- Direct support for API evaluation + synthetic data collection 
- Complete workflow for API eval -&gt; data collection -&gt; SFT -&gt; RL (GRPO) -&gt; trained model eval
- Full decoupling of rollout + reward logic from GRPOTrainer
- `transformers` Trainer as the base (replacing TRL&#039;s GRPO)
- Direct support for LLM judges via JudgeRubric

Included, but could use more testing:
- Data-parallel vLLM workers
- Multi-node training

Not included, but planned for later releases:
- TextArena environments
- Enigmata environments
- Native MCP tool support
- Multimodal support (image-in, via /v1/chat/completions)
- Tokenizer endpoint exposed for better token-level + turn-level mechanics (edge case handling, token-level rewards)
- More flexible abstractions for dynamic batch construction + rollout reuse
- FSDP (via prime-rl) 







</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[ok-oldking/ok-wuthering-waves]]></title>
            <link>https://github.com/ok-oldking/ok-wuthering-waves</link>
            <guid>https://github.com/ok-oldking/ok-wuthering-waves</guid>
            <pubDate>Wed, 04 Jun 2025 00:04:34 GMT</pubDate>
            <description><![CDATA[È∏£ÊΩÆ ÂêéÂè∞Ëá™Âä®ÊàòÊñó Ëá™Âä®Âà∑Â£∞È™∏ ‰∏ÄÈîÆÊó•Â∏∏ Automation for Wuthering Waves]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ok-oldking/ok-wuthering-waves">ok-oldking/ok-wuthering-waves</a></h1>
            <p>È∏£ÊΩÆ ÂêéÂè∞Ëá™Âä®ÊàòÊñó Ëá™Âä®Âà∑Â£∞È™∏ ‰∏ÄÈîÆÊó•Â∏∏ Automation for Wuthering Waves</p>
            <p>Language: Python</p>
            <p>Stars: 2,849</p>
            <p>Forks: 196</p>
            <p>Stars today: 101 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;h1 align=&quot;center&quot;&gt;
    &lt;img src=&quot;icon.png&quot; width=&quot;200&quot;/&gt;
    &lt;br/&gt;
    ok-ww
  &lt;/h1&gt; 
&lt;h3&gt;&lt;i&gt;Âü∫‰∫éÂõæÂÉèËØÜÂà´ÁöÑÈ∏£ÊΩÆËá™Âä®Âåñ, ‰ΩøÁî®windowsÊé•Âè£Ê®°ÊãüÁî®Êà∑ÁÇπÂáª, Êó†ËØªÂèñÊ∏∏ÊàèÂÜÖÂ≠òÊàñ‰æµÂÖ•‰øÆÊîπÊ∏∏ÊàèÊñá‰ª∂/Êï∞ÊçÆ.&lt;/i&gt;&lt;/h3&gt;
&lt;/div&gt;

![Static Badge](https://img.shields.io/badge/platfrom-Windows-blue?color=blue)
[![GitHub release (with filter)](https://img.shields.io/github/v/release/ok-oldking/ok-wuthering-waves)](https://github.com/ok-oldking/ok-wuthering-waves/releases)
[![GitHub all releases](https://img.shields.io/github/downloads/ok-oldking/ok-wuthering-waves/total)](https://github.com/ok-oldking/ok-wuthering-waves/releases)
[![Discord](https://img.shields.io/discord/296598043787132928?color=5865f2&amp;label=%20Discord)](https://discord.gg/vVyCatEBgA)

### [English Readme](README_en.md) | ‰∏≠ÊñáËØ¥Êòé

ÊºîÁ§∫ÂíåÊïôÁ®ã [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&amp;logo=YouTube&amp;logoColor=white)](https://youtu.be/h6P1KWjdnB4)

# ÂÖçË¥£Â£∞Êòé

Êú¨ËΩØ‰ª∂ÊòØ‰∏Ä‰∏™Â§ñÈÉ®Â∑•ÂÖ∑ÔºåÊó®Âú®Ëá™Âä®ÂåñÈ∏£ÊΩÆÁöÑÊ∏∏ÊàèÁé©Ê≥ï„ÄÇÂÆÉ‰ªÖÈÄöËøáÁé∞ÊúâÁî®Êà∑ÁïåÈù¢‰∏éÊ∏∏Êàè‰∫§‰∫íÔºåÂπ∂ÈÅµÂÆàÁõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑ„ÄÇËØ•ËΩØ‰ª∂ÂåÖÊó®Âú®ÁÆÄÂåñÁî®Êà∑‰∏éÊ∏∏ÊàèÁöÑ‰∫§‰∫íÔºå‰∏ç‰ºöÁ†¥ÂùèÊ∏∏ÊàèÂπ≥Ë°°ÊàñÊèê‰æõ‰∏çÂÖ¨Âπ≥‰ºòÂäøÔºå‰πü‰∏ç‰ºö‰øÆÊîπ‰ªª‰ΩïÊ∏∏ÊàèÊñá‰ª∂Êàñ‰ª£Á†Å„ÄÇ

Êú¨ËΩØ‰ª∂ÂºÄÊ∫ê„ÄÅÂÖçË¥πÔºå‰ªÖ‰æõ‰∏™‰∫∫Â≠¶‰π†‰∫§ÊµÅ‰ΩøÁî®Ôºå‰ªÖÈôê‰∫é‰∏™‰∫∫Ê∏∏ÊàèË¥¶Âè∑Ôºå‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öÊàñËê•Âà©ÊÄßÁõÆÁöÑ„ÄÇÂºÄÂèëËÄÖÂõ¢ÈòüÊã•ÊúâÊú¨È°πÁõÆÁöÑÊúÄÁªàËß£ÈáäÊùÉ„ÄÇ‰ΩøÁî®Êú¨ËΩØ‰ª∂‰∫ßÁîüÁöÑÊâÄÊúâÈóÆÈ¢ò‰∏éÊú¨È°πÁõÆÂèäÂºÄÂèëËÄÖÂõ¢ÈòüÊó†ÂÖ≥„ÄÇËã•ÊÇ®ÂèëÁé∞ÂïÜÂÆ∂‰ΩøÁî®Êú¨ËΩØ‰ª∂ËøõË°å‰ª£ÁªÉÂπ∂Êî∂Ë¥πÔºåËøôÊòØÂïÜÂÆ∂ÁöÑ‰∏™‰∫∫Ë°å‰∏∫ÔºåÊú¨ËΩØ‰ª∂‰∏çÊéàÊùÉÁî®‰∫é‰ª£ÁªÉÊúçÂä°Ôºå‰∫ßÁîüÁöÑÈóÆÈ¢òÂèäÂêéÊûú‰∏éÊú¨ËΩØ‰ª∂Êó†ÂÖ≥„ÄÇÊú¨ËΩØ‰ª∂‰∏çÊéàÊùÉ‰ªª‰Ωï‰∫∫ËøõË°åÂîÆÂçñÔºåÂîÆÂçñÁöÑËΩØ‰ª∂ÂèØËÉΩË¢´Âä†ÂÖ•ÊÅ∂ÊÑè‰ª£Á†ÅÔºåÂØºËá¥Ê∏∏ÊàèË¥¶Âè∑ÊàñÁîµËÑëËµÑÊñôË¢´ÁõóÔºå‰∏éÊú¨ËΩØ‰ª∂Êó†ÂÖ≥„ÄÇ

ËØ∑Ê≥®ÊÑèÔºåÊ†πÊçÆÂ∫ìÊ¥õÁöÑ„ÄäÈ∏£ÊΩÆ„ÄãÂÖ¨Âπ≥ËøêËê•Â£∞Êòé:

```
‰∏•Á¶ÅÂà©Áî®‰ªª‰ΩïÁ¨¨‰∏âÊñπÂ∑•ÂÖ∑Á†¥ÂùèÊ∏∏Êàè‰ΩìÈ™å„ÄÇ
Êàë‰ª¨Â∞Ü‰∏•ÂéâÊâìÂáª‰ΩøÁî®Â§ñÊåÇ„ÄÅÂä†ÈÄüÂô®„ÄÅ‰ΩúÂºäËΩØ‰ª∂„ÄÅÂÆèËÑöÊú¨Á≠âËøùËßÑÂ∑•ÂÖ∑ÁöÑË°å‰∏∫ÔºåËøô‰∫õË°å‰∏∫ÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éËá™Âä®ÊåÇÊú∫„ÄÅÊäÄËÉΩÂä†ÈÄü„ÄÅÊó†ÊïåÊ®°Âºè„ÄÅÁû¨Áßª„ÄÅ‰øÆÊîπÊ∏∏ÊàèÊï∞ÊçÆÁ≠âÊìç‰Ωú„ÄÇ
‰∏ÄÁªèÊü•ËØÅÔºåÊàë‰ª¨Â∞ÜËßÜËøùËßÑÊÉÖÂÜµÂíåÊ¨°Êï∞ÔºåÈááÂèñÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÊâ£Èô§ËøùËßÑÊî∂Áõä„ÄÅÂÜªÁªìÊàñÊ∞∏‰πÖÂ∞ÅÁ¶ÅÊ∏∏ÊàèË¥¶Âè∑Á≠âÊé™ÊñΩ„ÄÇ
```

### ‰ΩøÁî®ÊñπÊ≥ï:‰∏ãËΩΩÁªøËâ≤Áâà7zÂéãÁº©ÂåÖ(250MÂ∑¶Âè≥), Ëß£ÂéãÂêéÂèåÂáªok-ww.exe

* [GitHub‰∏ãËΩΩ](https://github.com/ok-oldking/ok-wuthering-waves/releases), ÂÖçË¥πÁΩëÈ°µÁõ¥Èìæ, ‰∏çË¶ÅÁÇπÂáª‰∏ãËΩΩSource Code,
  ÁÇπÂáª‰∏ãËΩΩ7zÂéãÁº©ÂåÖ
* [MirrorÈÖ±‰∏ãËΩΩÊ∏†ÈÅì](https://mirrorchyan.com/zh/projects?rid=okww), ÂõΩÂÜÖÁΩëÈ°µÁõ¥Èìæ, ‰∏ãËΩΩÈúÄË¶ÅË¥≠‰π∞CD-KEY,
  Â∑≤ÊúâMirrorÈÖ±CD-KEYÂèØÂÖçË¥π‰∏ãËΩΩ
* [Â§∏ÂÖãÁΩëÁõò](https://pan.quark.cn/s/a1052cec4d13), ÂÖçË¥π, ‰ΩÜÈúÄË¶ÅÊ≥®ÂÜåÂπ∂‰∏ãËΩΩÂ§∏ÂÖãÁΩëÁõòÂÆ¢Êà∑Á´Ø
* Âä†ÂÖ•QQÈ¢ëÈÅìÂêé, ËÆ®ËÆ∫ÁªÑ‰∏ãËΩΩ [https://pd.qq.com/s/djmm6l44y](https://pd.qq.com/s/djmm6l44y)

### ÊúâÂ§öÂº∫?

1. 4KÂàÜËæ®ÁéáÊµÅÁïÖËøêË°å,ÊîØÊåÅÊâÄÊúâ16:9ÂàÜËæ®Áéá,1600x900‰ª•‰∏ä, 1280x720‰∏çÊîØÊåÅÊòØÂõ†‰∏∫È∏£ÊΩÆbug, ÂÆÉÁöÑ1280x720Âπ∂‰∏çÊòØ1280x720.
   ÈÉ®ÂàÜÂäüËÉΩ‰πüÂèØ‰ª•Âú®21:9Á≠âÂÆΩÂ±èÂàÜËæ®ÁéáËøêË°å
2. ÂèØÂêéÂè∞ËøêË°å,ÂèØÁ™óÂè£Âåñ,ÂèØÂÖ®Â±è,Â±èÂπïÁº©ÊîæÊØî‰æãÊó†Ë¶ÅÊ±Ç
3. ÂÖ®ËßíËâ≤Ëá™Âä®ËØÜÂà´ÔºåÊó†ÈúÄÈÖçÁΩÆÂá∫ÊãõË°®Ôºå‰∏ÄÈîÆËøêË°å
4. ÂêéÂè∞Ëá™Âä®ÈùôÈü≥Ê∏∏Êàè

### Âá∫Áé∞ÈóÆÈ¢òËØ∑Ê£ÄÊü•

ÊúâÈóÆÈ¢òÁÇπËøôÈáå, Êå®‰∏™Ê£ÄÊü•ÂÜçÊèêÈóÆ:

1. **Ëß£ÂéãÈóÆÈ¢ò:** Â∞ÜÂéãÁº©ÂåÖËß£ÂéãÂà∞‰ªÖÂåÖÂê´Ëã±ÊñáÂ≠óÁ¨¶ÁöÑÁõÆÂΩï‰∏≠„ÄÇ
2. **ÊùÄÊØíËΩØ‰ª∂Âπ≤Êâ∞:** Â∞Ü‰∏ãËΩΩÂíåËß£ÂéãÁõÆÂΩïÊ∑ªÂä†Âà∞ÊÇ®ÁöÑÊùÄÊØíËΩØ‰ª∂/Windows Defender ÁôΩÂêçÂçï‰∏≠„ÄÇ
3. **ÊòæÁ§∫ËÆæÁΩÆ:** ÂÖ≥Èó≠ÊòæÂç°Êª§ÈïúÂíåÈîêÂåñ„ÄÇ‰ΩøÁî®ÈªòËÆ§Ê∏∏Êàè‰∫ÆÂ∫¶Âπ∂Á¶ÅÁî®Âú®Ê∏∏Êàè‰∏äÊòæÁ§∫FPS(Â¶ÇÂ∞èÈ£ûÊú∫)„ÄÇ
4. **Ëá™ÂÆö‰πâÊåâÈîÆÁªëÂÆö:** Â¶ÇÊ≤°Êúâ‰ΩøÁî®ÈªòËÆ§ÊåâÈîÆÔºåËØ∑Âú®APPËÆæÁΩÆ‰∏≠ËÆæÁΩÆ, ‰∏çÂú®ËÆæÁΩÆÈáåÁöÑÊåâÈîÆ‰∏çÊîØÊåÅ„ÄÇ
5. **ÁâàÊú¨ËøáÊóß:** Á°Æ‰øùÊÇ®‰ΩøÁî®ÁöÑÊòØÊúÄÊñ∞ÁâàÊú¨ÁöÑ OK-GI„ÄÇ
6. **ÊÄßËÉΩ:** Âú®Ê∏∏Êàè‰∏≠‰øùÊåÅÁ®≥ÂÆöÁöÑ 60 FPSÔºåÂ¶ÇÊûúÈúÄË¶ÅÔºåÈôç‰ΩéÂàÜËæ®Áéá„ÄÇ
7. **Ê∏∏ÊàèÊñ≠Á∫ø** Â¶ÇÊûúÁªèÂ∏∏ÂèëÁé∞Êñ≠ÂºÄÊúçÂä°Âô®ÈìæÊé•ÁöÑÈóÆÈ¢ò, ÂèØ‰ª•ÂÖàÊâìÂºÄÊ∏∏Êàè5ÂàÜÈíüÂÜçÂºÄÂßãÁé©, ÊàñËÄÖÊñ≠ÂºÄÂêé‰∏çË¶ÅÈÄÄÂá∫Ê∏∏Êàè, ÈáçÊñ∞ÁôªÈôÜ
8. **Ëøõ‰∏ÄÊ≠•Â∏ÆÂä©:** Â¶ÇÊûúÈóÆÈ¢ò‰ªçÁÑ∂Â≠òÂú®ÔºåËØ∑Êèê‰∫§ÈîôËØØÊä•Âëä„ÄÇ

### Python Ê∫êÁ†ÅËøêË°å

‰ªÖÊîØÊåÅPython 3.12

```
#CPUÁâàÊú¨, ‰ΩøÁî®openvino
pip install -r requirements.txt --upgrade #install python dependencies, Êõ¥Êñ∞‰ª£Á†ÅÂêéÂèØËÉΩÈúÄË¶ÅÈáçÊñ∞ËøêË°å
python main.py # run the release version
python main_debug.py # run the debug version
```

```
#GPUÁâàÊú¨, ‰ΩøÁî®onnxruntime-directmlÂä†ÈÄü, Êé®ËçêÂ§ßÊòæÂ≠òÊòæÂç°‰ΩøÁî®, ÂèØ‰ª•Â§ßÁ∫¶Èôç‰Ωé50%ÁöÑCPUÂíåÂÜÖÂ≠òÊ∂àËÄó
pip install -r requirements-direct-ml.txt --upgrade #install python dependencies, Êõ¥Êñ∞‰ª£Á†ÅÂêéÂèØËÉΩÈúÄË¶ÅÈáçÊñ∞ËøêË°å
python main_direct_ml.py # run the release version
python main_direct_ml_debug.py # run the debug version
```

### ÂëΩ‰ª§Ë°åÂèÇÊï∞

```
ok-ww.exe -t 1 -e
```

- -t Êàñ --task ‰ª£Ë°®ÂêØÂä®ÂêéËá™Âä®ÊâßË°åÁ¨¨Âá†‰∏™‰ªªÂä°, 1Â∞±ÊòØÁ¨¨‰∏Ä‰∏™, ‰∏ÄÊù°Èæô‰ªªÂä°
- -e Êàñ --exit Âä†‰∏ä‰ª£Ë°®Â¶ÇÊûúÊâßË°åÂÆå‰ªªÂä°‰πãÂêéËá™Âä®ÈÄÄÂá∫

### Âä†ÂÖ•Êàë‰ª¨

* Áî±‰∫éÂü∫‰∫é[ok-script](https://github.com/ok-oldking/ok-script)ÂºÄÂèëÔºåÈ°πÁõÆ‰ª£Á†Å‰ªÖÊúâ3000Ë°åÔºàPythonÔºâÔºåÁÆÄÂçïÊòìÁª¥Êä§
* È∏£ÊΩÆÊ∞¥Áæ§ 970523295 ËøõÁæ§Á≠îÊ°à:ËÄÅÁéãÂêåÂ≠¶OK
* Áæ§ÈÉΩÊª°‰∫Ü Âä†QQÈ¢ëÈÅì [https://pd.qq.com/s/djmm6l44y](https://pd.qq.com/s/djmm6l44y)
* ÊúâÂÖ¥Ë∂£ÂºÄÂèëÁöÑËØ∑Âä†ÂºÄÂèëËÄÖÁæ§926858895

### Áõ∏ÂÖ≥È°πÁõÆ

* [ok-genshin-impact](https://github.com/ok-oldking/ok-genshin-impact) ÂéüÁ•ûËá™Âä®Âåñ,‰∏ÄÈîÆÊó•Â∏∏,ÂêéÂè∞ÂâßÊÉÖ (
  ÂèØÂêéÂè∞,ÊîØÊåÅÂÖ®Ê∏∏ÊàèËØ≠Ë®Ä,ÊîØÊåÅÂÖ®16:
  9ÂàÜËæ®Áéá)
* [ok-gf2](https://github.com/ok-oldking/ok-gf2) Â∞ëÂâç2ËøΩÊîæËá™Âä®Âåñ,‰∏ÄÈîÆÊó•Â∏∏,Á´ûÊäÄÂú∫,ÂÖµÊ£ãÊé®Êºî,Â∞òÁÉü (ÊîØÊåÅPCÁâàÂêéÂè∞)

## ËµûÂä©ÂïÜ(Sponsors)

- EXEÁ≠æÂêç: Free code signing provided by [SignPath.io](https://signpath.io/), certificate
  by [SignPath Foundation](https://signpath.org/)


### Ëá¥Ë∞¢

[https://github.com/lazydog28/mc_auto_boss](https://github.com/lazydog28/mc_auto_boss) ÂêéÂè∞ÁÇπÂáª‰ª£Á†Å
  
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[av/harbor]]></title>
            <link>https://github.com/av/harbor</link>
            <guid>https://github.com/av/harbor</guid>
            <pubDate>Wed, 04 Jun 2025 00:04:33 GMT</pubDate>
            <description><![CDATA[Effortlessly run LLM backends, APIs, frontends, and services with one command.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/av/harbor">av/harbor</a></h1>
            <p>Effortlessly run LLM backends, APIs, frontends, and services with one command.</p>
            <p>Language: Python</p>
            <p>Stars: 1,764</p>
            <p>Forks: 115</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre>![Harbor project logo](https://github.com/av/harbor/raw/main/docs/harbor-2.png)

[![GitHub Tag](https://img.shields.io/github/v/tag/av/harbor)](https://github.com/av/harbor/releases)
[![NPM Version](https://img.shields.io/npm/v/%40avcodes%2Fharbor?labelColor=red&amp;color=white)](https://www.npmjs.com/package/@avcodes/harbor)
[![PyPI - Version](https://img.shields.io/pypi/v/llm-harbor?labelColor=blue)](https://pypi.org/project/llm-harbor/)
![GitHub repo size](https://img.shields.io/github/repo-size/av/harbor)
![GitHub repo file or directory count](https://img.shields.io/github/directory-file-count/av/harbor?type=file&amp;extension=yml&amp;label=compose%20files&amp;color=orange)
[![Visitors](https://api.visitorbadge.io/api/visitors?path=av%2Fharbor&amp;countColor=%23263759&amp;style=flat)](https://visitorbadge.io/status?path=av%2Fharbor)
![GitHub language count](https://img.shields.io/github/languages/count/av/harbor)
[![Discord](https://img.shields.io/badge/Discord-Harbor-blue?logo=discord&amp;logoColor=white)](https://discord.gg/8nDRphrhSF)
![Harbor Ko-fi](https://img.shields.io/badge/Ko--fi-white?style=social&amp;logo=kofi)

Setup your local LLM stack effortlessly.

```bash
# Starts fully configured Open WebUI and Ollama
harbor up

# Now, Open WebUI can do Web RAG and TTS/STT
harbor up searxng speaches
```

Harbor is a containerized LLM toolkit that allows you to run LLM backends, frontends and related useful services. It consists of a CLI and a companion App.

![Screenshot of Harbor CLI and App together](https://github.com/av/harbor/wiki/harbor-app-3.png)

## Documentation

- [Installing Harbor](https://github.com/av/harbor/wiki/1.0.-Installing-Harbor)&lt;br/&gt;
  Guides to install Harbor CLI and App
- [Harbor User Guide](https://github.com/av/harbor/wiki/1.-Harbor-User-Guide)&lt;br/&gt;
  High-level overview of working with Harbor
- [Harbor App](https://github.com/av/harbor/wiki/1.1-Harbor-App)&lt;br/&gt;
  Overview and manual for the Harbor companion application
- [Harbor Services](https://github.com/av/harbor/wiki/2.-Services)&lt;br/&gt;
  Catalog of services available in Harbor
- [Harbor CLI Reference](https://github.com/av/harbor/wiki/3.-Harbor-CLI-Reference)&lt;br/&gt;
  Read more about Harbor CLI commands and options.
  Read about supported services and the ways to configure them.
- [Join our Discord](https://discord.gg/8nDRphrhSF)&lt;br/&gt;
  Get help, share your experience, and contribute to the project.

## What can Harbor do?

![Diagram outlining Harbor&#039;s service structure](https://raw.githubusercontent.com/wiki/av/harbor/harbor-arch-diag.png)


#### ‚ú¶ Local LLMs

Run LLMs and related services locally, with no or minimal configuration, typically in a single command or click.

```bash
# All backends are pre-connected to Open WebUI
harbor up ollama
harbor up llamacpp
harbor up vllm

# Set and remember args for llama.cpp
harbor llamacpp args -ngl 32
```

####  Cutting Edge Inference

Harbor supports most of the major inference engines as well as a few of the lesser-known ones.

```bash
# We sincerely hope you&#039;ll never try to run all of them at once
harbor up vllm llamacpp tgi litellm tabbyapi aphrodite sglang ktransformers mistralrs airllm
```

#### Tool Use

Enjoy the benefits of MCP ecosystem, extend it to your use-cases.

```bash
# Manage MCPs with a convenient Web UI
harbor up metamcp

# Connect MCPs to Open WebUI
harbor up metamcp mcpo
```

#### Generate Images

Harbor includes ComfyUI + Flux + Open WebUI integration.

```bash
# Use FLUX in Open WebUI in one command
harbor up comfyui
```

#### Local Web RAG / Deep Research

Harbor includes [SearXNG](./docs/2.3.1-Satellite&amp;colon-SearXNG.md) that is pre-connected to a lot of services out of the box: [Perplexica](./docs/2.3.2-Satellite&amp;colon-Perplexica.md), [ChatUI](./docs/2.1.4-Frontend&amp;colon-ChatUI.md), [Morphic](./docs/2.3.34-Satellite-Morphic.md), [Local Deep Research](./docs/2.3.45-Satellite-Local-Deep-Research.md) and more.

```bash
# SearXNG is pre-connected to Open WebUI
harbor up searxng

# And to many other services
harbor up searxng chatui
harbor up searxng morphic
harbor up searxng perplexica
harbor up searxng ldr
```

#### LLM Workflows

Harbor includes multiple services for build LLM-based data and chat workflows: [Dify](./docs/2.3.3-Satellite&amp;colon-Dify.md), [LitLytics](./docs/2.3.21-Satellite&amp;colon-LitLytics.md), [n8n](./docs/2.3.23-Satellite&amp;colon-n8n.md), [Open WebUI Pipelines](./docs/2.3.25-Satellite&amp;colon-Open-WebUI-Pipelines.md), [FloWise](./docs/2.3.31-Satellite&amp;colon-Flowise.md), [LangFlow](./docs/2.3.32-Satellite&amp;colon-LangFlow.md)

```bash
# Use Dify in Open WebUI
harbor up dify
```

#### Talk to your LLM

Setup voice chats with your LLM in a single command. Open WebUI + Speaches

```bash
# Speaches includes OpenAI-compatible SST and TTS
# and connected to Open WebUI out of the box
harbor up speaches
```

#### Chat from the phone

You can access Harbor services from your phone with a QR code. Easily get links for local, LAN or Docker access.

```bash
# Print a QR code to open the service on your phone
harbor qr
# Print a link to open the service on your phone
harbor url webui
```

#### Chat from anywhere

Harbor includes a [built-in tunneling service](./docs/3.-Harbor-CLI-Reference.md#harbor-tunnel-service) to expose your Harbor to the internet.

&gt; [!WARN]
&gt; Be careful exposing your computer to the Internet, it&#039;s not safe.

```bash
# Expose default UI to the internet
harbor tunnel

# Expose a specific service to the internet
# ‚ö†Ô∏è Ensure to configure authentication for the service
harbor tunnel vllm

# Harbor comes with traefik built-in and pre-configured
# for all included services
harbor up traefik
```

#### LLM Scripting

[Harbor Boost](./docs/5.2.-Harbor-Boost.md) allows you to [easily script workflows](./docs/5.2.1.-Harbor-Boost-Custom-Modules.md) and interactions with downstream LLMs.

```bash
# Use Harbor Boost to script LLM workflows
harbor up boost
```

#### Config Profiles

Save and manage configuration profiles for different scenarios. For example - save [llama.cpp](./docs/2.2.2-Backend&amp;colon-llama.cpp.md) args for different models and contexts and switch between them easily.

```bash
# Save and use config profiles
harbor profile save llama4
harbor profile use default
```

#### Command History

Harbor keeps a [local-only history of recent commands](./docs/3.-Harbor-CLI-Reference.md#harbor-history). Look up and re-run easily, standalone from the system shell history.

```bash
# Lookup recently used harbor commands
harbor history
```

#### Eject

Ready to move to your own setup? Harbor [will give you](./docs/3.-Harbor-CLI-Reference.md#harbor-eject) a docker-compose file replicating your setup.

```bash
# Eject from Harbor into a standalone Docker Compose setup
# Will export related services and variables into a standalone file.
harbor eject searxng llamacpp &gt; docker-compose.harbor.yml
```

---

## Services

##### UIs
[Open WebUI](https://github.com/av/harbor/wiki/2.1.1-Frontend:-Open-WebUI) ‚¶ÅÔ∏é
[ComfyUI](https://github.com/av/harbor/wiki/2.1.2-Frontend:-ComfyUI) ‚¶ÅÔ∏é
[LibreChat](https://github.com/av/harbor/wiki/2.1.3-Frontend:-LibreChat) ‚¶ÅÔ∏é
[HuggingFace ChatUI](https://github.com/av/harbor/wiki/2.1.4-Frontend:-ChatUI) ‚¶ÅÔ∏é
[Lobe Chat](https://github.com/av/harbor/wiki/2.1.5-Frontend:-Lobe-Chat) ‚¶ÅÔ∏é
[Hollama](https://github.com/av/harbor/wiki/2.1.6-Frontend:-hollama) ‚¶ÅÔ∏é
[parllama](https://github.com/av/harbor/wiki/2.1.7-Frontend:-parllama) ‚¶ÅÔ∏é
[BionicGPT](https://github.com/av/harbor/wiki/2.1.8-Frontend:-BionicGPT) ‚¶ÅÔ∏é
[AnythingLLM](https://github.com/av/harbor/wiki/2.1.9-Frontend:-AnythingLLM) ‚¶ÅÔ∏é
[Chat Nio](https://github.com/av/harbor/wiki/2.1.10-Frontend:-Chat-Nio) ‚¶ÅÔ∏é
[mikupad](https://github.com/av/harbor/wiki/2.1.11-Frontend:-Mikupad) ‚¶ÅÔ∏é
[oterm](https://github.com/av/harbor/wiki/2.1.12-Frontend-oterm)

##### Backends
[Ollama](https://github.com/av/harbor/wiki/2.2.1-Backend:-Ollama) ‚¶ÅÔ∏é
[llama.cpp](https://github.com/av/harbor/wiki/2.2.2-Backend:-llama.cpp) ‚¶ÅÔ∏é
[vLLM](https://github.com/av/harbor/wiki/2.2.3-Backend:-vLLM) ‚¶ÅÔ∏é
[TabbyAPI](https://github.com/av/harbor/wiki/2.2.4-Backend:-TabbyAPI) ‚¶ÅÔ∏é
[Aphrodite Engine](https://github.com/av/harbor/wiki/2.2.5-Backend:-Aphrodite-Engine) ‚¶ÅÔ∏é
[mistral.rs](https://github.com/av/harbor/wiki/2.2.6-Backend:-mistral.rs) ‚¶ÅÔ∏é
[openedai-speech](https://github.com/av/harbor/wiki/2.2.7-Backend:-openedai-speech) ‚¶ÅÔ∏é
[Speaches](https://github.com/av/harbor/wiki/2.2.14-Backend:-Speaches) ‚¶ÅÔ∏é
[Parler](https://github.com/av/harbor/wiki/2.2.8-Backend:-Parler) ‚¶ÅÔ∏é
[text-generation-inference](https://github.com/av/harbor/wiki/2.2.9-Backend:-text-generation-inference) ‚¶ÅÔ∏é
[LMDeploy](https://github.com/av/harbor/wiki/2.2.10-Backend:-lmdeploy) ‚¶ÅÔ∏é
[AirLLM](https://github.com/av/harbor/wiki/2.2.11-Backend:-AirLLM) ‚¶ÅÔ∏é
[SGLang](https://github.com/av/harbor/wiki/2.2.12-Backend:-SGLang) ‚¶ÅÔ∏é
[KTransformers](https://github.com/av/harbor/wiki/2.2.13-Backend:-KTransformers) ‚¶ÅÔ∏é
[Nexa SDK](https://github.com/av/harbor/wiki/2.2.15-Backend:-Nexa-SDK) ‚¶ÅÔ∏é
[KoboldCpp](https://github.com/av/harbor/wiki/2.2.16-Backend:-KoboldCpp)

##### Satellites
[Harbor Bench](https://github.com/av/harbor/wiki/5.1.-Harbor-Bench) ‚¶ÅÔ∏é
[Harbor Boost](https://github.com/av/harbor/wiki/5.2.-Harbor-Boost) ‚¶ÅÔ∏é
[SearXNG](https://github.com/av/harbor/wiki/2.3.1-Satellite:-SearXNG) ‚¶ÅÔ∏é
[Perplexica](https://github.com/av/harbor/wiki/2.3.2-Satellite:-Perplexica) ‚¶ÅÔ∏é
[Dify](https://github.com/av/harbor/wiki/2.3.3-Satellite:-Dify) ‚¶ÅÔ∏é
[Plandex](https://github.com/av/harbor/wiki/2.3.4-Satellite:-Plandex) ‚¶ÅÔ∏é
[LiteLLM](https://github.com/av/harbor/wiki/2.3.5-Satellite:-LiteLLM) ‚¶ÅÔ∏é
[LangFuse](https://github.com/av/harbor/wiki/2.3.6-Satellite:-langfuse) ‚¶ÅÔ∏é
[Open Interpreter](https://github.com/av/harbor/wiki/2.3.7-Satellite:-Open-Interpreter) ‚¶Å
Ô∏é[cloudflared](https://github.com/av/harbor/wiki/2.3.8-Satellite:-cloudflared) ‚¶ÅÔ∏é
[cmdh](https://github.com/av/harbor/wiki/2.3.9-Satellite:-cmdh) ‚¶ÅÔ∏é
[fabric](https://github.com/av/harbor/wiki/2.3.10-Satellite:-fabric) ‚¶ÅÔ∏é
[txtai RAG](https://github.com/av/harbor/wiki/2.3.11-Satellite:-txtai-RAG) ‚¶ÅÔ∏é
[TextGrad](https://github.com/av/harbor/wiki/2.3.12-Satellite:-TextGrad) ‚¶ÅÔ∏é
[Aider](https://github.com/av/harbor/wiki/2.3.13-Satellite:-aider) ‚¶ÅÔ∏é
[aichat](https://github.com/av/harbor/wiki/2.3.14-Satellite:-aichat) ‚¶ÅÔ∏é
[omnichain](https://github.com/av/harbor/wiki/2.3.16-Satellite:-omnichain) ‚¶ÅÔ∏é
[lm-evaluation-harness](https://github.com/av/harbor/wiki/2.3.17-Satellite:-lm-evaluation-harness) ‚¶ÅÔ∏é
[JupyterLab](https://github.com/av/harbor/wiki/2.3.18-Satellite:-JupyterLab) ‚¶ÅÔ∏é
[ol1](https://github.com/av/harbor/wiki/2.3.19-Satellite:-ol1) ‚¶ÅÔ∏é
[OpenHands](https://github.com/av/harbor/wiki/2.3.20-Satellite:-OpenHands) ‚¶ÅÔ∏é
[LitLytics](https://github.com/av/harbor/wiki/2.3.21-Satellite:-LitLytics) ‚¶ÅÔ∏é
[Repopack](https://github.com/av/harbor/wiki/2.3.22-Satellite:-Repopack) ‚¶ÅÔ∏é
[n8n](https://github.com/av/harbor/wiki/2.3.23-Satellite:-n8n) ‚¶ÅÔ∏é
[Bolt.new](https://github.com/av/harbor/wiki/2.3.24-Satellite:-Bolt.new) ‚¶ÅÔ∏é
[Open WebUI Pipelines](https://github.com/av/harbor/wiki/2.3.25-Satellite:-Open-WebUI-Pipelines) ‚¶ÅÔ∏é
[Qdrant](https://github.com/av/harbor/wiki/2.3.26-Satellite:-Qdrant) ‚¶ÅÔ∏é
[K6](https://github.com/av/harbor/wiki/2.3.27-Satellite:-K6) ‚¶ÅÔ∏é
[Promptfoo](https://github.com/av/harbor/wiki/2.3.28-Satellite:-Promptfoo) ‚¶ÅÔ∏é
[Webtop](https://github.com/av/harbor/wiki/2.3.29-Satellite:-Webtop) ‚¶ÅÔ∏é
[OmniParser](https://github.com/av/harbor/wiki/2.3.30-Satellite:-OmniParser) ‚¶ÅÔ∏é
[Flowise](https://github.com/av/harbor/wiki/2.3.31-Satellite:-Flowise) ‚¶ÅÔ∏é
[Langflow](https://github.com/av/harbor/wiki/2.3.32-Satellite:-LangFlow) ‚¶ÅÔ∏é
[OptiLLM](https://github.com/av/harbor/wiki/2.3.33-Satellite:-OptiLLM) ‚¶ÅÔ∏é
[Morphic](https://github.com/av/harbor/wiki/2.3.34-Satellite-Morphic) ‚¶ÅÔ∏é
[SQL Chat](https://github.com/av/harbor/wiki/2.3.35-Satellite-SQL-Chat) ‚¶ÅÔ∏é
[gptme](https://github.com/av/harbor/wiki/2.3.36-Satellite-gptme) ‚¶ÅÔ∏é
[traefik](https://github.com/av/harbor/wiki/2.3.37-Satellite-traefik) ‚¶ÅÔ∏é
[Latent Scope](https://github.com/av/harbor/wiki/2.3.38-Satellite-Latent-Scope) ‚¶ÅÔ∏é
[RAGLite](https://github.com/av/harbor/wiki/2.3.39-Satellite-RAGLite) ‚¶ÅÔ∏é
[llama-swap](https://github.com/av/harbor/wiki/2.3.40-Satellite-llamaswap) ‚¶ÅÔ∏é
[LibreTranslate](https://github.com/av/harbor/wiki/2.3.41-Satellite-LibreTranslate) ‚¶ÅÔ∏é
[MetaMCP](https://github.com/av/harbor/wiki/2.3.42-Satellite-MetaMCP) ‚¶ÅÔ∏é
[mcpo](https://github.com/av/harbor/wiki/2.3.43-Satellite-mcpo) ‚¶ÅÔ∏é
[SuperGateway](https://github.com/av/harbor/wiki/2.3.44-Satellite-supergateway) ‚¶ÅÔ∏é
[Local Deep Research](https://github.com/av/harbor/wiki/2.3.45-Satellite-Local-Deep-Research) ‚¶ÅÔ∏é
[LocalAI](https://github.com/av/harbor/wiki/2.3.46-Satellite-LocalAI) ‚¶ÅÔ∏é
[AgentZero](https://github.com/av/harbor/wiki/2.3.47-Satellite-Agent-Zero)


See [services documentation](https://github.com/av/harbor/wiki/2.-Services) for a brief overview of each.

## CLI Tour

```bash
# Run Harbor with default services:
# Open WebUI and Ollama
harbor up

# Run Harbor with additional services
# Running SearXNG automatically enables Web RAG in Open WebUI
harbor up searxng

# Speaches includes OpenAI-compatible SST and TTS
# and connected to Open WebUI out of the box
harbor up speaches

# Run additional/alternative LLM Inference backends
# Open Webui is automatically connected to them.
harbor up llamacpp tgi litellm vllm tabbyapi aphrodite sglang ktransformers

# Run different Frontends
harbor up librechat chatui bionicgpt hollama

# Get a free quality boost with
# built-in optimizing proxy
harbor up boost

# Use FLUX in Open WebUI in one command
harbor up comfyui

# Use custom models for supported backends
harbor llamacpp model https://huggingface.co/user/repo/model.gguf

# Access service CLIs without installing them
# Caches are shared between services where possible
harbor hf scan-cache
harbor hf download google/gemma-2-2b-it
harbor ollama list

# Shortcut to HF Hub to find the models
harbor hf find gguf gemma-2
# Use HFDownloader and official HF CLI to download models
harbor hf dl -m google/gemma-2-2b-it -c 10 -s ./hf
harbor hf download google/gemma-2-2b-it

# Where possible, cache is shared between the services
harbor tgi model google/gemma-2-2b-it
harbor vllm model google/gemma-2-2b-it
harbor aphrodite model google/gemma-2-2b-it
harbor tabbyapi model google/gemma-2-2b-it-exl2
harbor mistralrs model google/gemma-2-2b-it
harbor opint model google/gemma-2-2b-it
harbor sglang model google/gemma-2-2b-it

# Convenience tools for docker setup
harbor logs llamacpp
harbor exec llamacpp ./scripts/llama-bench --help
harbor shell vllm

# Tell your shell exactly what you think about it
harbor opint
harbor aider
harbor aichat
harbor cmdh

# Use fabric to LLM-ify your linux pipes
cat ./file.md | harbor fabric --pattern extract_extraordinary_claims | grep &quot;LK99&quot;

# Open services from the CLI
harbor open webui
harbor open llamacpp
# Print yourself a QR to quickly open the
# service on your phone
harbor qr
# Feeling adventurous? Expose your Harbor
# to the internet
harbor tunnel

# Config management
harbor config list
harbor config set webui.host.port 8080

# Create and manage config profiles
harbor profile save l370b
harbor profile use default

# Lookup recently used harbor commands
harbor history

# Eject from Harbor into a standalone Docker Compose setup
# Will export related services and variables into a standalone file.
harbor eject searxng llamacpp &gt; docker-compose.harbor.yml

# Run a built-in LLM benchmark with
# your own tasks
harbor bench run

# Gimmick/Fun Area

# Argument scrambling, below commands are all the same as above
# Harbor doesn&#039;t care if it&#039;s &quot;vllm model&quot; or &quot;model vllm&quot;, it&#039;ll
# figure it out.
harbor model vllm
harbor vllm model

harbor config get webui.name
harbor get config webui_name

harbor tabbyapi shell
harbor shell tabbyapi

# 50% gimmick, 50% useful
# Ask harbor about itself
harbor how to ping ollama container from the webui?
```

## Harbor App Demo

https://github.com/user-attachments/assets/a5cd2ef1-3208-400a-8866-7abd85808503

In the demo, Harbor App is used to launch a default stack with [Ollama](./2.2.1-Backend:-Ollama) and [Open WebUI](./2.1.1-Frontend:-Open-WebUI) services. Later, [SearXNG](./2.3.1-Satellite:-SearXNG) is also started, and WebUI can connect to it for the Web RAG right out of the box. After that, [Harbor Boost](./5.2.-Harbor-Boost) is also started and connected to the WebUI automatically to induce more creative outputs. As a final step, Harbor config is adjusted in the App for the [`klmbr`](./5.2.-Harbor-Boost#klmbr---boost-llm-creativity) module in the [Harbor Boost](./5.2.-Harbor-Boost), which makes the output unparsable for the LLM (yet still undetstandable for humans).

## Why?

- If you&#039;re comfortable with Docker and Linux administration - you likely don&#039;t need Harbor to manage your local LLM environment. However, while growing it - you&#039;re also likely to eventually arrive to a similar solution. I know this for a fact, since that&#039;s exactly how Harbor came to be.
- Harbor is not designed as a deployment solution, but rather as a helper for the local LLM development environment. It&#039;s a good starting point for experimenting with LLMs and related services.
- Workflow/setup centralisation - you can be sure where to find a specific config or service, logs, data and configuration files.
- Convenience factor - single CLI with a lot of services and features, accessible from anywhere on your host.

## Supporters

![@av&#039;s wife](https://ui-avatars.com/api/?size=32&amp;name=KN&amp;rounded=true&amp;background=ffaaaa&amp;color=ff4444)
![@burnth3heretic](https://ui-avatars.com/api/?size=32&amp;name=BTH&amp;rounded=true)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[frappe/erpnext]]></title>
            <link>https://github.com/frappe/erpnext</link>
            <guid>https://github.com/frappe/erpnext</guid>
            <pubDate>Wed, 04 Jun 2025 00:04:32 GMT</pubDate>
            <description><![CDATA[Free and Open Source Enterprise Resource Planning (ERP)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/frappe/erpnext">frappe/erpnext</a></h1>
            <p>Free and Open Source Enterprise Resource Planning (ERP)</p>
            <p>Language: Python</p>
            <p>Stars: 25,440</p>
            <p>Forks: 8,451</p>
            <p>Stars today: 39 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/frappe/design/blob/master/logos/logo-2019/erpnext-logo.png&quot; height=&quot;128&quot;&gt;
    &lt;h2&gt;ERPNext&lt;/h2&gt;
    &lt;p align=&quot;center&quot;&gt;
        &lt;p&gt;ERP made simple&lt;/p&gt;
    &lt;/p&gt;

[![Build Status](https://travis-ci.com/frappe/erpnext.png)](https://travis-ci.com/frappe/erpnext)
[![Open Source Helpers](https://www.codetriage.com/frappe/erpnext/badges/users.svg)](https://www.codetriage.com/frappe/erpnext)
[![Coverage Status](https://coveralls.io/repos/github/frappe/erpnext/badge.svg?branch=develop)](https://coveralls.io/github/frappe/erpnext?branch=develop)

[https://erpnext.com](https://erpnext.com)

&lt;/div&gt;

Includes: Accounting, Inventory, Manufacturing, CRM, Sales, Purchase, Project Management, HRMS. Requires MariaDB.

ERPNext is built on the [Frappe](https://github.com/frappe/frappe) Framework, a full-stack web app framework in Python &amp; JavaScript.

- [User Guide](https://erpnext.com/docs/user)
- [Discussion Forum](https://discuss.erpnext.com/)

---

### Full Install

The Easy Way: our install script for bench will install all dependencies (e.g. MariaDB). See https://github.com/frappe/bench for more details.

New passwords will be created for the ERPNext &quot;Administrator&quot; user, the MariaDB root user, and the frappe user (the script displays the passwords and saves them to ~/frappe_passwords.txt).

### Virtual Image

You can download a virtual image to run ERPNext in a virtual machine on your local system.

- [ERPNext Download](http://erpnext.com/download)

System and user credentials are listed on the download page.

---

## License

GNU/General Public License (see [license.txt](license.txt))

The ERPNext code is licensed as GNU General Public License (v3) and the Documentation is licensed as Creative Commons (CC-BY-SA-3.0) and the copyright is owned by Frappe Technologies Pvt Ltd (Frappe) and Contributors.

---

## Contributing

1. [Issue Guidelines](https://github.com/frappe/erpnext/wiki/Issue-Guidelines)
1. [Report Security Vulnerabilities](https://erpnext.com/report)
1. [Pull Request Requirements](https://github.com/frappe/erpnext/wiki/Contribution-Guidelines)
1. [Translations](https://translate.erpnext.com)
1. [Chart of Accounts](https://charts.erpnext.com)

---

## Logo and Trademark

The brand name ERPNext and the logo are trademarks of Frappe Technologies Pvt. Ltd.

### Introduction

Frappe Technologies Pvt. Ltd. (Frappe) owns and oversees the trademarks for the ERPNext name and logos. We have developed this trademark usage policy with the following goals in mind:

- We‚Äôd like to make it easy for anyone to use the ERPNext name or logo for community-oriented efforts that help spread and improve ERPNext.
- We‚Äôd like to make it clear how ERPNext-related businesses and projects can (and cannot) use the ERPNext name and logo.
- We‚Äôd like to make it hard for anyone to use the ERPNext name and logo to unfairly profit from, trick or confuse people who are looking for official ERPNext resources.

### Frappe Trademark Usage Policy

Permission from Frappe is required to use the ERPNext name or logo as part of any project, product, service, domain or company name.

We will grant permission to use the ERPNext name and logo for projects that meet the following criteria:

- The primary purpose of your project is to promote the spread and improvement of the ERPNext software.
- Your project is non-commercial in nature (it can make money to cover its costs or contribute to non-profit entities, but it cannot be run as a for-profit project or business).
Your project neither promotes nor is associated with entities that currently fail to comply with the GPL license under which ERPNext is distributed.
- If your project meets these criteria, you will be permitted to use the ERPNext name and logo to promote your project in any way you see fit with one exception: Please do not use ERPNext as part of a domain name.

Use of the ERPNext name and logo is additionally allowed in the following situations:

All other ERPNext-related businesses or projects can use the ERPNext name and logo to refer to and explain their services, but they cannot use them as part of a product, project, service, domain, or company name and they cannot use them in any way that suggests an affiliation with or endorsement by ERPNext or Frappe Technologies or the ERPNext open source project. For example, a consulting company can describe its business as ‚Äú123 Web Services, offering ERPNext consulting for small businesses,‚Äù but cannot call its business ‚ÄúThe ERPNext Consulting Company.‚Äù

Similarly, it‚Äôs OK to use the ERPNext logo as part of a page that describes your products or services, but it is not OK to use it as part of your company or product logo or branding itself. Under no circumstances is it permitted to use ERPNext as part of a top-level domain name.

We do not allow the use of the trademark in advertising, including AdSense/AdWords.

Please note that it is not the goal of this policy to limit commercial activity around ERPNext. We encourage ERPNext-based businesses, and we would love to see hundreds of them.

When in doubt about your use of the ERPNext name or logo, please contact Frappe Technologies for clarification.

(inspired by WordPress)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[CollegesChat/university-information]]></title>
            <link>https://github.com/CollegesChat/university-information</link>
            <guid>https://github.com/CollegesChat/university-information</guid>
            <pubDate>Wed, 04 Jun 2025 00:04:31 GMT</pubDate>
            <description><![CDATA[Êî∂ÈõÜÂÖ®ÂõΩÂêÑÈ´òÊ†°ÊãõÁîüÊó∂‰∏ç‰ºöÂÜôÊòéÔºåÂç¥‰ºöÂÆûÂÆûÂú®Âú®ÂΩ±ÂìçÂ§ßÂ≠¶ÁîüÊ¥ªË¥®ÈáèÁöÑË¶ÅÊ±Ç‰∏éÁªÜËäÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/CollegesChat/university-information">CollegesChat/university-information</a></h1>
            <p>Êî∂ÈõÜÂÖ®ÂõΩÂêÑÈ´òÊ†°ÊãõÁîüÊó∂‰∏ç‰ºöÂÜôÊòéÔºåÂç¥‰ºöÂÆûÂÆûÂú®Âú®ÂΩ±ÂìçÂ§ßÂ≠¶ÁîüÊ¥ªË¥®ÈáèÁöÑË¶ÅÊ±Ç‰∏éÁªÜËäÇ</p>
            <p>Language: Python</p>
            <p>Stars: 3,734</p>
            <p>Forks: 489</p>
            <p>Stars today: 51 stars today</p>
            <h2>README</h2><pre># ‰∏Ä‰∫õÂ§ßÂ≠¶ÁöÑÁîüÊ¥ªË¥®Èáè

ËøôÊòØ‰ªÄ‰πàÈ°πÁõÆÔºü

ËøôÊòØ‰∏Ä‰∏™Âèó https://t.me/RiNGNiR/3571 Âíå https://t.me/RiNGNiR/3572 ÂêØÂèëÁöÑÈ°πÁõÆÔºåÊÑèÂú®Êî∂ÈõÜÂÖ®ÂõΩÂêÑÈ´òÊ†°ÊãõÁîüÊó∂‰∏ç‰ºöÂÜôÊòéÔºåÂç¥‰ºöÂÆûÂÆûÂú®Âú®ÂΩ±ÂìçÂ§ßÂ≠¶ÁîüÊ¥ªË¥®ÈáèÁöÑË¶ÅÊ±Ç‰∏éÁªÜËäÇ„ÄÇ

## Êü•ËØ¢ &amp; Ë¥°ÁåÆ &amp; ÊèêÈóÆ
ÈóÆÂç∑ËµÑÊñôÊü•ËØ¢ËØ∑ÂâçÂæÄ [https://colleges.chat](https://colleges.chat) (Êú¨È°πÁõÆËá™Âä®ÁîüÊàêÁöÑ .md ËµÑÊñôÊñá‰ª∂ËØ∑ÂâçÂæÄ [generated ÂàÜÊîØ](https://github.com/CollegesChat/university-information/tree/generated))

Ë¥°ÁåÆ„ÄÅÊèêÈóÆ„ÄÅÈÉ®ÂàÜËµÑÊñôÊü•ËØ¢ËØ∑ÂâçÂæÄ [Discussions](https://github.com/YanWQ-monad/university-information/discussions)

## ÂèÇËÄÉ FAQ

&gt; ‰ª•‰∏ãÂÜÖÂÆπÊëòËá™ https://t.me/RiNGNiR/3571

&gt; ‰∏Ä‰∫õÂæàÂ§ö‰∫∫Â°´Êä•ÂøóÊÑøÊó∂ÂÄô‰∏ç‰ºöÈóÆ‰ΩÜÊòØÁúüÁöÑÂæàÂΩ±ÂìçÂ§ßÂ≠¶ÁîüÊ¥ªË¥®ÈáèÁöÑÈóÆÈ¢ò
&gt; 
&gt; 0. ÂÆøËàçÊòØ‰∏äÂ∫ä‰∏ãÊ°åÂêó
&gt; 1. ÊïôÂÆ§ÂíåÂÆøËàçÊúâÊ≤°ÊúâÁ©∫Ë∞É
&gt; 2. ÊúâÁã¨Á´ãÂç´Êµ¥ÂêóÔºüÊ≤°ÊúâÁã¨Á´ãÊµ¥ÂÆ§ÁöÑËØùÔºåÊæ°Â†ÇÁ¶ªÂÆøËàçÂ§öËøú
&gt; 3. ÊúâÊó©Ëá™‰π†„ÄÅÊôöËá™‰π†Âêó
&gt; 4. ÊúâÊô®Ë∑ëÂêó
&gt; 5. ÊØèÂ≠¶ÊúüË∑ëÊ≠•ÊâìÂç°ÁöÑË¶ÅÊ±ÇÊòØÂ§öÂ∞ëÂÖ¨ÈáåÔºåÂèØ‰ª•È™ëËΩ¶Âêó
&gt; 6. ÂØíÊöëÂÅáÊîæÂ§ö‰πÖÔºåÊØèÂπ¥Â∞èÂ≠¶ÊúüÊúâÂ§öÈïø
&gt; 7. Â≠¶Ê†°ÂÖÅËÆ∏ÁÇπÂ§ñÂçñÂêóÔºåÂèñÂ§ñÂçñÁöÑÂú∞ÊñπÁ¶ªÂÆøËàçÊ•ºÂ§öËøú
&gt; 8. Â≠¶Ê†°ÈôÑËøëÊúâÂú∞ÈìÅÁ´ôÂêó
&gt; 9. ÂÆøËàçÊ•ºÊúâÊ¥óË°£Êú∫Âêó
&gt; 10. Ê†°Âõ≠ÁΩëÊÄé‰πàÊ†∑
&gt; 11. ÊØèÂ§©Êñ≠ÁîµÊñ≠ÁΩëÂêóÔºåÂá†ÁÇπÂºÄÂßãÊñ≠
&gt; 12. È£üÂ†Ç‰ª∑Ê†ºË¥µÂêóÔºå‰ºöÂêÉÂá∫ÂºÇÁâ©Âêó
&gt; 13. Ê¥óÊæ°ÁÉ≠Ê∞¥‰æõÂ∫îÊó∂Èó¥
&gt; 14. Ê†°Âõ≠ÂÜÖÂèØ‰ª•È™ëÁîµÁì∂ËΩ¶ÂêóÔºåÁîµÊ±†Âú®Âì™ËÉΩÂÖÖÁîµ
&gt; 15. ÂÆøËàçÈôêÁîµÊÉÖÂÜµ
&gt; 16. ÈÄöÂÆµËá™‰π†ÊúâÂéªÂ§ÑÂêó
&gt; 17. Â§ß‰∏ÄËÉΩÂ∏¶ÁîµËÑëÂêó
&gt; 18. Â≠¶Ê†°ÈáåÈù¢Áî®‰ªÄ‰πàÂç°ÔºåÈ•≠Â†ÇÊÄéÊ†∑Ê∂àË¥π
&gt; 19. Â≠¶Ê†°‰ºöÁªôÂ≠¶ÁîüÂèëÈì∂Ë°åÂç°Âêó
&gt; 20. Â≠¶Ê†°ÁöÑË∂ÖÂ∏ÇÊÄé‰πàÊ†∑
&gt; 21. Â≠¶Ê†°ÁöÑÊî∂ÂèëÂø´ÈÄíÊîøÁ≠ñÊÄé‰πàÊ†∑
&gt; 22. Â≠¶Ê†°ÈáåÈù¢ÁöÑÂÖ±‰∫´ÂçïËΩ¶Êï∞ÁõÆ‰∏éÁßçÁ±ªÂ¶Ç‰Ωï
&gt; 23. Áé∞Èò∂ÊÆµÂ≠¶Ê†°ÁöÑÈó®Á¶ÅÊÉÖÂÜµÂ¶Ç‰Ωï
&gt; 24. ÂÆøËàçÊôö‰∏äÊü•ÂØùÂêóÔºåÂ∞ÅÂØùÂêóÔºåÊôöÂΩíËÉΩÂõûÂéªÂêó
&gt; 
&gt; ÂæÖË°•ÂÖÖ
&gt; 
&gt; Â§ßÂ≠¶ÁöÑÊù°‰ª∂ÁúüÁöÑ‰∏çÂÉèÂæàÂ§ö‰∫∫ÊÉ≥Ë±°ÁöÑÈÇ£‰πàÂ•ΩÔºåÂ∞§ÂÖ∂ÊòØÂæàÂ§öËÄÅÊ†°Âå∫ÔºåÈô§‰∫ÜÂ≠¶Ê†°Êú¨Ë∫´ÂÆûÂäõ‰ª•Â§ñÔºåËøòÊòØÂª∫ËÆÆÂ§ßÂÆ∂Â§ö‰∫ÜËß£‰∫ÜËß£Ôºå‰∏çÁÑ∂Â§ßÂ≠¶ÁúüÁöÑ‰ºöÂíåÊúçÂàë‰∏ÄÊ†∑

## LICENSE

[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-Hans)

Â¶ÇÊúâÂÖ∂ÂÆÉ LICENSE ‰ºöÊ≥®Êòé„ÄÇ

Â¶ÇÊûúÊúâ‰æµÊùÉ„ÄÅ‰∏çÂÆû‰ø°ÊÅØËØ∑ËÅîÁ≥ªËøõË°åÂà†Èô§„ÄÇ
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[sunnypilot/sunnypilot]]></title>
            <link>https://github.com/sunnypilot/sunnypilot</link>
            <guid>https://github.com/sunnypilot/sunnypilot</guid>
            <pubDate>Wed, 04 Jun 2025 00:04:30 GMT</pubDate>
            <description><![CDATA[sunnypilot is an open source driver assistance system. sunnypilot offers the user a unique driving experience for over 300 supported car makes and models with modified behaviors of driving assist engagements. sunnypilot complies with the safety policy from comma.ai's openpilot as accurately as possible.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sunnypilot/sunnypilot">sunnypilot/sunnypilot</a></h1>
            <p>sunnypilot is an open source driver assistance system. sunnypilot offers the user a unique driving experience for over 300 supported car makes and models with modified behaviors of driving assist engagements. sunnypilot complies with the safety policy from comma.ai's openpilot as accurately as possible.</p>
            <p>Language: Python</p>
            <p>Stars: 1,429</p>
            <p>Forks: 895</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>![](https://user-images.githubusercontent.com/47793918/233812617-beab2e71-57b9-479e-8bff-c3931347ca40.png)

Table of Contents
=======================

* [Join our Discord](#-join-our-discord)
* [What is sunnypilot?](#-what-is-sunnypilot)
* [Running in a car](#-running-on-a-dedicated-device-in-a-car)
* [Read Before Installing](#-read-before-installing)
* [Prohibited Safety Modifications](#-prohibited-safety-modifications)
* [Installation](#-installation)
* [Highlight Features](#-highlight-features)
* [Driving Enhancements](#-driving-enhancements)
* [Branch Definitions](#-branch-definitions)
* [Recommended Branches](#-recommended-branches)
* [How-To&#039;s](#-How-Tos)
* [Pull Requests](#-Pull-Requests)
* [Special Thanks](#-special-thanks)
* [User Data](#-user-data)
* [Licensing](#licensing)
* [Donate](#-support-sunnypilot)

---

&lt;details&gt;&lt;summary&gt;&lt;h3&gt;üí≠ Join our Discord&lt;/h3&gt;&lt;/summary&gt;

---

Join the official sunnypilot Discord server to stay up to date with all the latest features and be a part of shaping the future of sunnypilot!
* https://discord.gg/sunnypilot

  ![](https://dcbadge.vercel.app/api/server/wRW3meAgtx?style=flat) ![Discord Shield](https://discordapp.com/api/guilds/880416502577266699/widget.png?style=shield)

&lt;/details&gt;

&lt;details&gt;&lt;summary&gt;&lt;h3&gt;üåû What is sunnypilot?&lt;/h3&gt;&lt;/summary&gt;

---

[sunnypilot](https://github.com/sunnyhaibin/sunnypilot) is a fork of comma.ai&#039;s openpilot, an open source driver assistance system. sunnypilot offers the user a unique driving experience for over 250+ supported car makes and models with modified behaviors of driving assist engagements. sunnypilot complies with comma.ai&#039;s safety rules as accurately as possible.

&lt;/details&gt;

&lt;details&gt;&lt;summary&gt;&lt;h3&gt;üöò Running on a dedicated device in a car&lt;/h3&gt;&lt;/summary&gt;

---

To use sunnypilot in a car, you need the following:
* A supported device to run this software
    * a [comma three](https://comma.ai/shop/products/three), or
* This software
* One of [the 250+ supported cars](https://github.com/commaai/openpilot/blob/master/docs/CARS.md). We support Honda, Toyota, Hyundai, Nissan, Kia, Chrysler, Lexus, Acura, Audi, VW, Ford and more. If your car is not supported but has adaptive cruise control and lane-keeping assist, it&#039;s likely able to run sunnypilot.
* A [car harness](https://comma.ai/shop/products/car-harness) to connect to your car

Detailed instructions for [how to mount the device in a car](https://comma.ai/setup).

&lt;/details&gt;

&lt;details&gt;&lt;summary&gt;&lt;h3&gt;üö® Read Before Installing&lt;/h3&gt;&lt;/summary&gt;

---

It is recommended to read this **entire page** before proceeding. This will ensure that you fully understand each added feature on sunnypilot, and you are selecting the right branch for your car to have the best driving experience.

This is a fork of [comma.ai&#039;s openpilot](https://github.com/commaai/openpilot). By installing this software, you accept all responsibility for anything that might occur while you use it. All contributors to sunnypilot are not liable. ‚ùó&lt;ins&gt;**Use at your own risk.**&lt;/ins&gt;‚ùó

&lt;/details&gt;

&lt;details&gt;&lt;summary&gt;&lt;h3&gt;‚õî Prohibited Safety Modifications&lt;/h3&gt;&lt;/summary&gt;

---

All [official sunnypilot branches](https://github.com/sunnyhaibin/sunnypilot/branches) strictly adhere to [comma.ai&#039;s safety policy](https://github.com/commaai/openpilot/blob/master/docs/SAFETY.md). Any changes that go against this policy will result in your fork and your device being banned from both comma.ai and sunnypilot channels.

The following changes are a **VIOLATION** of this policy and **ARE NOT** included in any sunnypilot branches:
* Driver Monitoring:
    * ‚ùå &quot;Nerfing&quot; or reducing monitoring parameters.
* Panda safety:
    * ‚ùå No preventing disengaging of &lt;ins&gt;**LONGITUDINAL CONTROL**&lt;/ins&gt; (acceleration/brake) on brake pedal press.
    * ‚ùå No auto re-engaging of &lt;ins&gt;**LONGITUDINAL CONTROL**&lt;/ins&gt; (acceleration/brake) on brake pedal release.
    * ‚ùå No disengaging on ACC MAIN in OFF state.

&lt;/details&gt;


&lt;details&gt;&lt;summary&gt;&lt;h3&gt;‚öí Installation&lt;/h3&gt;&lt;/summary&gt;

---

  &lt;details&gt;&lt;summary&gt;URL (Easy)&lt;/summary&gt;

comma three
------

Please refer to [Recommended Branches](#-recommended-branches) to find your preferred/supported branch. This guide will assume you want to install the latest `release-c3` branch.

* sunnypilot not installed or you installed a version before 0.8.17?
  1. [Factory reset/uninstall](https://github.com/commaai/openpilot/wiki/FAQ#how-can-i-reset-the-device) the previous software if you have another software/fork installed.
  2. After factory reset/uninstall and upon reboot, select `Custom Software` when given the option.
  3. Input the installation URL per [Recommended Branches](#-recommended-branches). Example: ```release-c3.sunnypilot.ai``` [^4] (note: `https://` is not requirement on the comma three)
  4. Complete the rest of the installation following the onscreen instructions.

* sunnypilot already installed and you installed a version after 0.8.17?
  1. On the comma three, go to `Settings` ‚ñ∂Ô∏è `Software`.
  2. At the `Download` option, press `CHECK`. This will fetch the list of latest branches from sunnypilot.
  3. At the `Target Branch` option, press `SELECT` to open the Target Branch selector.
  4. Scroll to select the desired branch per [Recommended Branches](#-recommended-branches). Example: `release-c3`

|    Branch    |         Installation URL         |
|:------------:|:--------------------------------:|
| `release-c3` | https://release-c3.sunnypilot.ai |
| `staging-c3` | https://staging-c3.sunnypilot.ai |
|   `dev-c3`   | https://dev-c3.sunnypilot.ai     |

Requires further assistance with software installation? Join the [sunnypilot Discord server](https://discord.sunnypilot.com) and message us in the `#installation-help` channel.

comma three:
------
* [`release-c3`](https://github.com/sunnyhaibin/openpilot/tree/release-c3):

  ```
  cd /data &amp;&amp; rm -rf ./openpilot &amp;&amp; git clone -b release-c3 --recurse-submodules https://github.com/sunnyhaibin/sunnypilot.git openpilot &amp;&amp; cd openpilot &amp;&amp; sudo reboot
  ```

After running the command to install the desired branch, your comma device should reboot.
  &lt;/details&gt;

&lt;/details&gt;


&lt;details&gt;&lt;summary&gt;&lt;h3&gt;üöó Highlight Features&lt;/h3&gt;&lt;/summary&gt;

---

### Quality of Life Enhancements
- [**Modified Assistive Driving Safety (MADS)**](#modified-assistive-driving-safety-mads) - Automatic Lane Centering (ALC) / Lane Keep Assist System (LKAS) and Adaptive Cruise Control (ACC) / Smart Cruise Control (SCC) can be engaged independently of each other
- [**Dynamic Lane Profile (DLP)**](#dynamic-lane-profile-dlp) - Dynamically switch lane profile (between Laneful and Laneless) based on lane recognition confidence
- [**Enhanced Speed Control**](#enhanced-speed-control) - Automatically adjust cruise control speed using vision model, OpenStreetMap (OSM) data, and/or Speed Limit control (SLC) without user interaction
    * Vision-based Turn Speed Control (V-TSC) - lower speed when going around corners using vision model
    * Map-Data-based Turn Speed Control (M-TSC) - lower speed when going around corners using OSM data[^1]
    * Speed Limit Control (SLC) - Set speed limit based on map data or car interface (if applicable)
    * HKG only: Highway Driving Assist (HDA) status integration - Use cars native speed sign detection to set desired speed (on applicable HKG cars only)
- [**Gap Adjust Cruise (GAC)**](#gap-adjust-cruise) - Allow `GAP`/`INTERVAL`/`DISTANCE` button on the steering wheel or on-screen button to adjust the follow distance from the lead car. See table below for options
- [**Quiet Drive ü§´**](#-quiet-drive) - Toggle to mute all notification sounds (excluding driver safety warnings)
- [**Auto Lane Change Timer**](#Auto-Lane-Change-Timer) - Set a timer to delay the auto lane change operation when the blinker is used. No nudge on the steering wheel is required to auto lane change if a timer is set
- [**Force Car Recognition (FCR)**](#Force-Car-Recognition-) - Use a selector to force your car to be recognized by sunnypilot
- [**Fix sunnypilot No Offroad**](#Fix-sunnypilot-No-Offroad) - Enforce sunnypilot to go offroad and turns off after shutting down the car. This feature fixes non-official devices running sunnypilot without comma power
- [**Enable ACC+MADS with RES+/SET-**](#Enable-ACC+MADS-with-RES+/SET-) - Engage both ACC and MADS with a single press of RES+ or SET- button
- [**Offline OSM Maps**](#Offline-OSM-Maps) - OSM database can now be downloaded locally for offline use[^2]. This enables offline SLC, V-TSC and M-TSC. Currently available for US South, US West, US Northeast, Florida, Taiwan, South Africa and New Zealand
- [**Various Live Tuning**](#Various-Live-Tuning) - Ability to tailor your driving experience on the fly:
    * Enforce Torque Lateral Control - Use the newest [torque controller](https://blog.comma.ai/0815release/#torque-controller) for all vehicles.
    * Torque Lateral Control Live Tune - Ability to adjust the torque controller‚Äôs `FRICTION` and `LAT_ACCEL_FACTOR` values to suit your vehicle.
    * Torque Lateral Controller Self-Tune - Enable automatic turning for the Torque controller.

### Visual Enhancements
* **M.A.D.S Status Icon** - Dedicated icon to display M.A.D.S. engagement status
    * Greenüü¢: M.A.D.S. engaged
    * White‚ö™: M.A.D.S. suspended or disengaged
* **Lane Path Color** - Various lane path colors to display real-time Lane Model and M.A.D.S. engagement status
    * 0.8.14 and later:
        * Blueüîµ: Laneful mode &amp; M.A.D.S. engaged
        * Greenüü¢: Laneless mode &amp; M.A.D.S. engaged
        * Yellowüü°: Experimental e2e &amp; M.A.D.S. engaged
    * Pre 0.8.14:
        * Greenüü¢: Laneful mode &amp; M.A.D.S. engaged
        * Redüî¥: Laneless mode &amp; M.A.D.S. engaged
    * White‚ö™: M.A.D.S. suspended or disengaged
    * Black‚ö´: M.A.D.S. engaged, steering is being manually overridden by user
* **Developer (Dev) UI** - Display various real-time metrics on screen while driving
* **Stand Still Timer** - Display time spent at a stop with M.A.D.S engaged (i.e., at traffic lights, stop signs, traffic congestions)
* **Braking Status** - Current car speed text turns red when the car is braking by the driver or ACC/SCC

### Operational Enhancements
* **Fast Boot** - sunnypilot will fast boot by creating a Prebuilt file
* **Disable Onroad Uploads** - Disable uploads completely when onroad. Necessary to avoid high data usage when connected to Wi-Fi hotspot
* **Brightness Control (Global)** - Manually adjusts the global brightness of the screen
* **Driving Screen Off Timer** - Turns off the device screen or reduces brightness to protect the screen after car starts
* **Driving Screen Off Brightness (%)** - When using the Driving Screen Off feature, the brightness is reduced according to the automatic brightness ratio
* **Max Time Offroad** - Device is automatically turned off after a set time when the engine is turned off (off-road) after driving (on-road)

&lt;/details&gt;

&lt;details&gt;&lt;summary&gt;&lt;h3&gt;üöó Driving Enhancements&lt;/h3&gt;&lt;/summary&gt;

---

### Modified Assistive Driving Safety (MADS)
The goal of Modified Assistive Driving Safety (MADS) is to enhance the user driving experience with modified behaviors of driving assist engagements. This feature complies with comma.ai&#039;s safety rules as accurately as possible with the following changes:
* sunnypilot Automatic Lane Centering (ALC) and ACC/SCC can be engaged independently of each other
* Dedicated button to toggle sunnypilot ALC:
    * `CRUISE (MAIN)` button: All supported cars on sunnypilot
        * `LFA` button: Newer HKG cars with `LFA` button
        * `LKAS` button: Honda, Toyota, Global Subaru
* `SET-` button enables ACC/SCC
* `CANCEL` button only disables ACC/SCC
* `CRUISE (MAIN)` must be `ON` to use ACC/SCC
* `CRUISE (MAIN)` button disables sunnypilot completely when `OFF` **(strictly enforced in panda safety code)**

### Disengage Lateral ALC on Brake Press Mode toggle
Dedicated toggle to handle Lateral state on brake pedal press and release:
1. `ON`: `BRAKE pedal` press will pause Automatic Lane Centering; `BRAKE pedal` release will resume Automatic Lane Centering. Note: `BRAKE pedal` release will NOT resume ACC/SCC/Long control without explicit user engagement **(strictly enforced in panda safety code)**
2. `OFF`: `BRAKE pedal` press will NOT pause Automatic Lane Centering; `BRAKE pedal` release will NOT resume ACC/SCC/Long control without explicit user engagement **(strictly enforced in panda safety code)**

### Miscellaneous
* `TURN SIGNALS` (`Left` or `Right`) will pause Automatic Lane Centering if the vehicle speed is below the [threshold](https://github.com/commaai/openpilot/blob/master/selfdrive/controls/lib/desire_helper.py#L8) for Automatic Lane Change
* Event audible alerts are more relaxed to match manufacturer&#039;s stock behavior
* Critical events trigger disengagement of Automatic Lane Centering completely. The disengagement is enforced in sunnypilot and panda safety

### Dynamic Lane Profile (DLP)

Dynamic Lane Profile (DLP) aims to provide the best driving experience at staying within a lane confidently. Dynamic Lane Profile allows sunnypilot to dynamically switch between lane profiles based on lane recognition confidence level on road.

There are 3 modes to select on the onroad camera screen:
* **Auto Lane**: sunnypilot dynamically chooses between `Laneline` or `Laneless` model
* **Laneline**: sunnypilot uses Laneline model only.
* **Laneless**: sunnypilot uses Laneless model only.

To use Dynamic Lane Profile, do the following:
```
1. sunnypilot Settings -&gt; `SP - Controls` -&gt; Enable Dynamic Lane Profile -&gt; ON toggle
2. Reboot.
3. Before driving, on the onroad camera screen, toggle between the 3 modes by pressing on the button.
4. Drive.
```

### Enhanced Speed Control
This fork now allows supported cars to dynamically adjust the longitudinal plan based on the fetched map data. Big thanks to the Move Fast team for the amazing implementation!

**Supported cars:**
* sunnypilot Longitudinal Control capable
* Stock Longitudinal Control
    * Hyundai/Kia/Genesis (non CAN-FD)
    * Honda Bosch
    * Volkswagen MQB

Certain features are only available with an active data connection, via:
* [comma Prime](https://comma.ai/prime) - Intuitive service provided directly by comma, or
* Personal Hotspot - From your mobile device, or a dedicated hotspot from a cellular carrier.

**Features:**
* Vision-based Turn Speed Control (VTSC) - Use vision path predictions to estimate the appropriate speed to drive through turns ahead - i.e. slowing down for curves
* Map-Data-based Turn Speed Control (MTSC) - Use curvature information from map data to define speed limits to take turns ahead - i.e. slowing down for curves[^1]
* Speed Limit Control (SLC) - Use speed limit signs information from map data and car interface to automatically adapt cruise speed to road limits
    * HKG only: Highway Driving Assist (HDA) status integration - on applicable HKG cars only[^1]
    * Speed Limit Offset - When Speed Limit Control is enabled, set speed limit slightly higher than the actual speed limit for a more natural drive[^1]
* Toggle Hands on Wheel Monitoring - Monitors and alerts the driver when their hands have not been on the steering wheel for an extended time

### Custom Stock Longitudinal Control
While using stock Adaptive/Smart Cruise Control, Custom Stock Longitudinal Control in sunnypilot allows sunnypilot to manipulate and take over the set speed on the car&#039;s dashboard.

**Supported Cars:**
* Hyundai/Kia/Genesis
    * CAN platform
    * CAN-FD platform with 0x1CF broadcasted in CAN traffic
* Honda Bosch
* Volkswagen MQB

**Instruction**

**üìó How to use Custom Longitudinal Control on sunnypilot **

When using Speed Limit, Vision, or Map based Turn control, you will be setting the &quot;MAX&quot; ACC speed on the sunnypilot display instead of the one in the dashboard. The car will then set the ACC setting in the dashboard to the targeted speed, but will never exceed the max speed set on the sunnypilot display. A quick press of the RES+ or SET- buttons will change this speed by 5 MPH or KM/H on the sunnypilot display, while a long deliberate press (about a 1/2 second press) changes it by 1 MPH or KM/H. DO NOT hold the RES+ or SET- buttons for longer that a 1 second. Either make quick or long deliberate presses only.

**‚Äº Where to look when setting ACC speed ‚Äº**

Do not look at the dashboard when setting your ACC max speed. Instead, only look at the one on the sunnypilot display, &quot;MAX&quot;. The reason you need to look at the sunnypilot display is because sunnypilot will be changing the one in the dashboard. It will be adjusting it as needed, never raising it above the one set on the sunnypilot display. ONLY look at the MAX speed on the sunnypilot display when setting the ACC speed instead of the dashboard!

(Courtesy instructions from John, author of jvePilot)

### Gap Adjust Cruise
This fork now allows supported openpilot longitudinal cars to adjust the cruise gap between the car and the lead car.

**Supported cars:**
* sunnypilot Longitudinal Control capable

üö®**PROCEED WITH EXTREME CAUTION AND BE READY TO MANUALLY TAKE OVER AT ALL TIMES**

There are 4 modes to select on the steering wheel and/or the onroad camera screen:
* **Stock Gap**: Stock sunnypilot distance - 1.45 second profile
* **Mild Gap**: Semi-aggressive distance - 1.25 second profile
* üö®**Aggro Gap**üö®: Aggressive distance - 1.0 second profile

**Availability**

|      Car Make       | Stock Gap | Mild Gap | Aggro Gap |
|:-------------------:|:---------:|:--------:|:---------:|
|     Honda/Acura     |     ‚úÖ     |    ‚úÖ     |     ‚úÖ     |
| Hyundai/Kia/Genesis |     ‚úÖ     |    ‚úÖ     |     ‚úÖ     |
|    Toyota/Lexus     |     ‚úÖ     |    ‚úÖ     |     ‚úÖ     |
|  Volkswagen MQB/PQ  |     ‚úÖ     |    ‚úÖ     |     ‚úÖ     |

&lt;/details&gt;


&lt;details&gt;&lt;summary&gt;&lt;h3&gt;‚öí Branch Definitions&lt;/h3&gt;&lt;/summary&gt;

---

|    Tag    | Definition           | Description                                                                                                                                                                                 |
|:---------:|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `release` | Release branches     | Include features that are **verified** by trusted testers and the community. Ready to use. ‚úÖ                                                                                                |
| `staging` | Staging branches     | Include new features that are **tested** by trusted testers and the community. Stability may vary. ‚ö†                                                                                        |
|   `dev`   | Development branches | All features are gathered in respective versions. Reviewed and merged features will be committed to `dev`. Stability may vary. ‚ö†                                                            |
| `master`  | Main branch          | Syncs with [commaai&#039;s openpilot `master`](https://github.com/commaai/openpilot) upstream branch. Accepts all pull requests. Does not include all sunnypilot features. Stability may vary. ‚ö† |

Example:
* [`release-c3`](https://github.com/sunnyhaibin/sunnypilot/tree/release-c3): Latest release branch for comma three that are verified by trusted testers and the community. Ready to use.
* [`staging-c3`](https://github.com/sunnyhaibin/sunnypilot/tree/staging-c3): Latest staging branch for comma three that are tested by trusted testers and the community. Verification required.
* [`dev-c3`](https://github.com/sunnyhaibin/sunnypilot/tree/dev-c3): Latest development branch for comma three that include all sunnypilot features. Testing required.

&lt;/details&gt;

&lt;details&gt;&lt;summary&gt;&lt;h3&gt;‚úÖ Recommended Branches&lt;/h3&gt;&lt;/summary&gt;

---

| Branch                                                                              | Definition                                              | Co

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>