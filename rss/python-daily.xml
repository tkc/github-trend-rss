<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Sat, 17 May 2025 00:04:24 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[xming521/WeClone]]></title>
            <link>https://github.com/xming521/WeClone</link>
            <guid>https://github.com/xming521/WeClone</guid>
            <pubDate>Sat, 17 May 2025 00:04:24 GMT</pubDate>
            <description><![CDATA[🚀从聊天记录创造数字分身的一站式解决方案💡 使用聊天记录微调大语言模型，让大模型有“那味儿”，并绑定到聊天机器人，实现自己的数字分身。 数字克隆/数字分身/数字永生/LLM/聊天机器人/LoRA]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/xming521/WeClone">xming521/WeClone</a></h1>
            <p>🚀从聊天记录创造数字分身的一站式解决方案💡 使用聊天记录微调大语言模型，让大模型有“那味儿”，并绑定到聊天机器人，实现自己的数字分身。 数字克隆/数字分身/数字永生/LLM/聊天机器人/LoRA</p>
            <p>Language: Python</p>
            <p>Stars: 9,629</p>
            <p>Forks: 743</p>
            <p>Stars today: 1,340 stars today</p>
            <h2>README</h2><pre>![download](https://github.com/user-attachments/assets/5842e84e-004f-4afd-9373-af64e9575b78)
&lt;h3 align=&quot;center&quot;&gt;🚀从聊天记录创造数字分身的一站式解决方案💡&lt;/h3&gt;  

&lt;div align=&quot;center&quot;&gt;

[![GitHub stars](https://img.shields.io/github/stars/xming521/WeClone?style=for-the-badge&amp;logo=github&amp;label=Stars&amp;logoColor=white&amp;color=ffda65)](https://github.com/xming521/WeClone/stargazers)
[![GitHub release](https://img.shields.io/github/v/release/xming521/WeClone?style=for-the-badge&amp;logo=github&amp;label=Release&amp;logoColor=white&amp;color=06d094)](https://github.com/xming521/WeClone/releases)
&lt;a href=&quot;https://qm.qq.com/cgi-bin/qm/qr?k=wNdgbOVT6oFOJ2wlMLsolUXErW9ESLpk&amp;jump_from=webapi&amp;authKey=z/reOp6YLyvR4Tl2k2nYMsLoMC3w9/99ucgKMX0oRGlxDV/WbYnvq2QxODoIkfxn&quot; target=&quot;_blank&quot; style=&quot;text-decoration: none;&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/QQ群-708067078-12B7F5?style=for-the-badge&amp;logo=qq&amp;logoColor=white&quot; alt=&quot;WeClone①&quot; title=&quot;WeClone①&quot;&gt;
&lt;/a&gt;
[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;logo=telegram&amp;logoColor=white)](https://t.me/+JEdak4m0XEQ3NGNl)

&lt;a href=&quot;https://hellogithub.com/repository/12ab209b56cb4cfd885c8cfd4cfdd53e&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=12ab209b56cb4cfd885c8cfd4cfdd53e&amp;claim_uid=RThlPDoGrFvdMY5&quot; alt=&quot;Featured｜HelloGitHub&quot; style=&quot;width: 150px; height: 28px;&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://trendshift.io/repositories/13759&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13759&quot; alt=&quot;xming521%2FWeClone | Trendshift&quot; style=&quot;width: 220px; height: 50px;&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://deepwiki.com/xming521/WeClone&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot;  style=&quot;width: 134px; height: 23px;margin-bottom: 3px;&quot;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://blog.051088.xyz/2025/05/14/WeClone-%E7%94%A8%E5%BE%AE%E4%BF%A1%E8%81%8A%E5%A4%A9%E8%AE%B0%E5%BD%95%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84AI%E6%95%B0%E5%AD%97%E5%88%86%E8%BA%AB/&quot; target=&quot;_blank&quot;&gt;
    Windows部署指南
  &lt;/a&gt;
&lt;/p&gt;

## ✨核心功能
- 💫 涵盖打造数字分身的全链路方案，包括聊天数据导出、预处理、模型训练、部署
- 💬 使用微信聊天记录微调LLM，让大模型有&quot;那味儿&quot;
- 🔗 绑定到微信、QQ、Telegram、企微、飞书机器人，实现自己的数字分身
- 🛡️ 隐私信息过滤，本地化微调部署，数据安全可控

## 📋特性与说明

&gt; [!IMPORTANT]
&gt; ### 0.2.1版本支持了命令行工具，使用前需要重新执行 `uv pip install -e .` 

&gt; [!IMPORTANT]
&gt; 0.2.0版本进行了全面重构，数据集目录和脚本路径全部进行了修改，拉取新代码后，`csv`文件夹放在`dataset`下，并且需要重新安装依赖。

&gt; [!IMPORTANT]
&gt; - WeClone仍在快速迭代期，当前效果不代表最终效果。  
&gt; - 微调LLM效果很大程度取决于模型大小、聊天数据的数量和质量，理论上模型越大，数据越多，效果越好。   
&gt; - Windows环境未进行严格测试，可以使用WSL作为运行环境。详细教程可点击[Windows部署指南](https://blog.051088.xyz/2025/05/14/WeClone-%E7%94%A8%E5%BE%AE%E4%BF%A1%E8%81%8A%E5%A4%A9%E8%AE%B0%E5%BD%95%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84AI%E6%95%B0%E5%AD%97%E5%88%86%E8%BA%AB/)查看。

### 硬件要求

项目默认使用Qwen2.5-7B-Instruct模型，LoRA方法对sft阶段微调，大约需要16GB显存。也可以使用[LLaMA Factory](https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md#%E6%A8%A1%E5%9E%8B)支持的其他模型和方法。

需要显存的估算值：
| 方法                             | 精度 |   7B  |  14B  |  30B  |   70B  |   `x`B  |
| ------------------------------- | ---- | ----- | ----- | ----- | ------ | ------- |
| Full (`bf16` or `fp16`)         |  32  | 120GB | 240GB | 600GB | 1200GB | `18x`GB |
| Full (`pure_bf16`)              |  16  |  60GB | 120GB | 300GB |  600GB |  `8x`GB |
| Freeze/LoRA/GaLore/APOLLO/BAdam |  16  |  16GB |  32GB |  64GB |  160GB |  `2x`GB |
| QLoRA                           |   8  |  10GB |  20GB |  40GB |   80GB |   `x`GB |
| QLoRA                           |   4  |   6GB |  12GB |  24GB |   48GB | `x/2`GB |
| QLoRA                           |   2  |   4GB |   8GB |  16GB |   24GB | `x/4`GB |


## 环境搭建
1.cuda安装(已安装可跳过，**要求版本12.4及以上**)：[LLaMA Factory](https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/installation.html#cuda) 

2.建议使用 [uv](https://docs.astral.sh/uv/)安装依赖，这是一个非常快速的 Python 环境管理器。安装uv后，您可以使用以下命令创建一个新的Python环境并安装依赖项，注意这不包含音频克隆功能的依赖：
```bash
git clone https://github.com/xming521/WeClone.git
cd WeClone
uv venv .venv --python=3.10
source .venv/bin/activate # windows下执行 .venv\Scripts\activate
uv pip install --group main -e . 
```
&gt; [!TIP]
&gt; 如果要使用最新的模型进行微调，需要手动安装最新版LLaMA Factory：`uv pip install --upgrade git+https://github.com/hiyouga/LLaMA-Factory.git`,同时其他依赖版本也可能需要修改，例如vllm pytorch transforms

3.将配置文件模板复制一份并重命名为`settings.jsonc`，后续配置修改在此文件进行：
```bash
cp settings.template.jsonc settings.jsonc
```
&gt; [!NOTE]
&gt; 训练以及推理相关配置统一在文件`settings.jsonc`

4.使用以下命令测试CUDA环境是否正确配置并可被PyTorch识别，Mac不需要：
```bash
python -c &quot;import torch; print(&#039;CUDA是否可用:&#039;, torch.cuda.is_available());&quot;
```

5.（可选）安装FlashAttention，加速训练和推理：`uv pip install flash-attn --no-build-isolation`

## 模型下载
```bash
git lfs install
git clone https://www.modelscope.cn/Qwen/Qwen2.5-7B-Instruct.git
```
下载有问题使用其他方式下载：[模型的下载](https://www.modelscope.cn/docs/models/download)


## 数据准备

请使用[PyWxDump](https://github.com/xaoyaoo/PyWxDump)提取微信聊天记录（不支持4.0版本微信）。可以先将手机的聊天记录迁移（备份）到电脑，数据量更多一些。下载软件并解密数据库后，点击聊天备份，导出类型为CSV，可以导出多个联系人（不建议使用群聊记录），然后将导出的位于`wxdump_tmp/export` 的 `csv` 文件夹放在`./dataset`目录即可，也就是不同人聊天记录的文件夹一起放在 `./dataset/csv`。   

## 数据预处理

- 项目默认去除了数据中的手机号、身份证号、邮箱、网址。还在`settings.jsonc`中提供了一个禁用词词库`blocked_words`，可以自行添加需要过滤的词句（会默认去掉包括禁用词的整句）。
&gt; [!IMPORTANT]
&gt; 🚨 请一定注意保护个人隐私，不要泄露个人信息！

- 执行以下命令对数据进行处理，可以根据自己的聊天风格修改settings.jsonc的`make_dataset_args`。
```bash
weclone-cli make-dataset
```
- 目前仅支持时间窗口策略，根据`single_combine_time_window`将单人连续消息通过逗号连接合并为一句，根据`qa_match_time_window`匹配问答对。
- 可以启用`clean_dataset`中的`enable_clean`选项，对数据进行清洗，以达到更好效果。当前使用llm judge对聊天记录进行打分，使用vllm进行离线推理。在得到`llm打分分数分布情况`后，调整`accept_score`选择可以接受的分数，再适当降低`train_sft_args`的`lora_dropout`参数提升拟合效果。

## 配置参数并微调模型

- (可选)修改 `settings.jsonc` 的 `model_name_or_path` 和 `template` 选择本地下载好的其他模型。  
- 修改`per_device_train_batch_size`以及`gradient_accumulation_steps`来调整显存占用。  
- 可以根据自己数据集的数量和质量修改`train_sft_args`的`num_train_epochs`、`lora_rank`、`lora_dropout`等参数。

### 单卡训练
```bash
weclone-cli train-sft
```
多卡环境单卡训练，需要先执行 `export CUDA_VISIBLE_DEVICES=0`

### 多卡训练
取消`settings.jsonc`中`deepspeed`行代码注释，使用以下命令多卡训练：
```bash
uv pip install deepspeed
deepspeed --num_gpus=使用显卡数量 weclone/train/train_sft.py
```

### 使用浏览器demo简单推理
可以在这一步测试出合适的temperature、top_p值，修改settings.jsonc的`infer_args`后，供后续推理时使用。
```bash
weclone-cli webchat-demo
```

### 使用接口进行推理

```bash
weclone-cli server
```

### 使用常见聊天问题测试
不包含询问个人信息的问题，仅有日常聊天。测试结果在test_result-my.txt。
```bash
weclone-cli server
weclone-cli test-model
```

## 🖼️ 微调效果
使用Qwen2.5-14B-Instruct模型，大概3万条处理后的有效数据，loss降到了3.5左右的效果。
&lt;details&gt;
&lt;summary&gt;截图&lt;/summary&gt;
&lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 10px;&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/0775ec52-452b-485f-9785-c6eb7b277132&quot; alt=&quot;alt text&quot; style=&quot;width: 48%; min-width: 150px;&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/8c7628b5-da70-4c37-9e51-fdfb0eadd2df&quot; alt=&quot;alt text&quot; style=&quot;width: 48%; min-width: 150px;&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/523aa742-2aa3-40e9-bd67-b98b336e83a8&quot; alt=&quot;alt text&quot; style=&quot;width: 48%; min-width: 150px;&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/dabf0603-dcc4-4a47-b5c3-2bbc036820d9&quot; alt=&quot;alt text&quot; style=&quot;width: 48%; min-width: 150px;&quot;&gt;
&lt;/div&gt;
&lt;/details&gt;


## 🤖 部署到聊天机器人

### AstrBot

[AstrBot](https://github.com/AstrBotDevs/AstrBot) 是易上手的多平台 LLM 聊天机器人及开发框架 ✨ 平台支持 QQ、QQ频道、Telegram、微信、企微、飞书。      

使用步骤：
1. 部署 AstrBot
2. 在 AstrBot 中部署消息平台
3. 执行 `weclone-cli server` 启动api服务
4. 在 AstrBot 中新增服务提供商，类型选择OpenAI，API Base URL 根据AstrBot部署方式填写（例如docker部署可能为http://172.17.0.1:8005/v1） ，模型填写gpt-3.5-turbo,API Key随意填写一个
5. 微调后不支持工具调用，请先关掉默认的工具，消息平台发送指令： `/tool off all`，否则会没有微调后的效果。 
6. 根据微调时使用的default_system，在 AstrBot 中设置系统提示词。
![5](https://github.com/user-attachments/assets/19de7072-076a-4cdf-8ae6-46b9b89f536a)
&gt; [!IMPORTANT]
&gt; 检查api_service的日志，尽量保证大模型服务请求的参数和微调时一致，tool插件能力都关掉。
7. 调整采样参数，例如temperature、top_p、top_k等
[配置自定义的模型参数](https://astrbot.app/config/model-config.html#%E9%85%8D%E7%BD%AE%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0)

### LangBot

[LangBot](https://github.com/RockChinQ/LangBot) 是一个开源的接入全球多种即时通信平台的 LLM 机器人平台，适合各种场景使用。

1. [部署 LangBot](https://github.com/RockChinQ/LangBot#-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8)
2. 在 LangBot 中添加一个机器人
4. 在模型页添加新模型，名称`gpt-3.5-turbo`，供应商选择 OpenAI，填写 请求 URL 为 WeClone 的地址，详细连接方式可以参考[文档](https://docs.langbot.app/zh/workshop/network-details.html)，API Key 任意填写。

&lt;img width=&quot;400px&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/fc167dea-7c93-4d94-9c5f-db709d0320ba&quot; /&gt;

6. 在流水线配置中选择刚才添加的模型，或修改提示词配置

&lt;img width=&quot;400px&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/dbb0fd0a-f760-42db-acd0-bb99c859b52e&quot; /&gt;

## 📌 路线图
- [ ] 更丰富的上下文：包括上下文对话、聊天对象信息、时间等 + 思考
- [ ] Memory 支持
- [ ] 支持多模态
- [ ] 数据增强
- [ ] 支持GUI

## 问题解决
- 微调问题：[LLaMA-Factory| FAQs | 常见问题](https://github.com/hiyouga/LLaMA-Factory/issues/4614) 或者更方便的 [![更方便的Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/hiyouga/LLaMA-Factory)

## ❤️ 贡献代码

欢迎任何 Issues/Pull Requests！

你可以通过查看Issues或帮助审核 PR（拉取请求）来贡献。对于新功能的添加，请先通过 Issue 讨论。   
运行`uv pip install --group dev -e .`安装开发依赖。   
项目使用`pytest`测试(测试脚本待完善)，`pyright`检查类型，`ruff`检查代码格式。


## ⚠️ 免责声明
&gt; [!CAUTION]
&gt; 请勿用于非法用途，否则后果自负。
&lt;details&gt;
&lt;summary&gt;1. 使用目的&lt;/summary&gt;

* 本项目仅供学习交流使用，**请勿用于非法用途**，**请勿用于非法用途**，**请勿用于非法用途**，否则后果自负。
* 用户理解并同意，任何违反法律法规、侵犯他人合法权益的行为，均与本项目及其开发者无关，后果由用户自行承担。

2. 使用期限

* 您应该在下载保存使用本项目的24小时内，删除本项目的源代码和程序；超出此期限的任何使用行为，一概与本项目及其开发者无关。

3. 操作规范

* 本项目仅允许在授权情况下使用数据训练，严禁用于非法目的，否则自行承担所有相关责任；用户如因违反此规定而引发的任何法律责任，将由用户自行承担，与本项目及其开发者无关。
* 严禁用于窃取他人隐私，严禁用于窃取他人隐私，严禁用于窃取他人隐私，否则自行承担所有相关责任。

4. 免责声明接受

* 下载、保存、进一步浏览源代码或者下载安装、编译使用本程序，表示你同意本警告，并承诺遵守它;

5. 禁止用于非法测试或渗透

* 禁止利用本项目的相关技术从事非法测试或渗透，禁止利用本项目的相关代码或相关技术从事任何非法工作，如因此产生的一切不良后果与本项目及其开发者无关。
* 任何因此产生的不良后果，包括但不限于数据泄露、系统瘫痪、侵犯隐私等，均与本项目及其开发者无关，责任由用户自行承担。

6. 免责声明修改

* 本免责声明可能根据项目运行情况和法律法规的变化进行修改和调整。用户应定期查阅本页面以获取最新版本的免责声明，使用本项目时应遵守最新版本的免责声明。

7. 其他

* 除本免责声明规定外，用户在使用本项目过程中应遵守相关的法律法规和道德规范。对于因用户违反相关规定而引发的任何纠纷或损失，本项目及其开发者不承担任何责任。

* 请用户慎重阅读并理解本免责声明的所有内容，确保在使用本项目时严格遵守相关规定。

&lt;/details&gt;
请用户慎重阅读并理解本免责声明的所有内容，确保在使用本项目时严格遵守相关规定。

&lt;br&gt;  
&lt;br&gt;  
&lt;br&gt;  

## ⭐ Star History
&gt; [!TIP] 
&gt; 如果本项目对您有帮助，或者您关注本项目的未来发展，请给项目 Star，谢谢 

&lt;div align=&quot;center&quot;&gt;

[![Star History Chart](https://api.star-history.com/svg?repos=xming521/WeClone&amp;type=Date)](https://www.star-history.com/#xming521/WeClone&amp;Date)

&lt;/div&gt;


&lt;div align=&quot;center&quot;&gt; 克隆我们，保留灵魂的芬芳 &lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[mem0ai/mem0]]></title>
            <link>https://github.com/mem0ai/mem0</link>
            <guid>https://github.com/mem0ai/mem0</guid>
            <pubDate>Sat, 17 May 2025 00:04:23 GMT</pubDate>
            <description><![CDATA[Memory for AI Agents; SOTA in AI Agent Memory; Announcing OpenMemory MCP - local and secure memory management.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mem0ai/mem0">mem0ai/mem0</a></h1>
            <p>Memory for AI Agents; SOTA in AI Agent Memory; Announcing OpenMemory MCP - local and secure memory management.</p>
            <p>Language: Python</p>
            <p>Stars: 30,929</p>
            <p>Forks: 2,987</p>
            <p>Stars today: 596 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/mem0ai/mem0&quot;&gt;
    &lt;img src=&quot;docs/images/banner-sm.png&quot; width=&quot;800px&quot; alt=&quot;Mem0 - The Memory Layer for Personalized AI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot; style=&quot;display: flex; justify-content: center; gap: 20px; align-items: center;&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/11194&quot; target=&quot;blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/11194&quot; alt=&quot;mem0ai%2Fmem0 | Trendshift&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mem0.ai&quot;&gt;Learn more&lt;/a&gt;
  ·
  &lt;a href=&quot;https://mem0.dev/DiG&quot;&gt;Join Discord&lt;/a&gt;
  ·
  &lt;a href=&quot;https://mem0.dev/demo&quot;&gt;Demo&lt;/a&gt;
  ·
  &lt;a href=&quot;https://mem0.dev/openmemory&quot;&gt;OpenMemory&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mem0.dev/DiG&quot;&gt;
    &lt;img src=&quot;https://dcbadge.vercel.app/api/server/6PzXDgEjG5?style=flat&quot; alt=&quot;Mem0 Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://pepy.tech/project/mem0ai&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/pypi/dm/mem0ai&quot; alt=&quot;Mem0 PyPI - Downloads&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/mem0ai/mem0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/commit-activity/m/mem0ai/mem0?style=flat-square&quot; alt=&quot;GitHub commit activity&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://pypi.org/project/mem0ai&quot; target=&quot;blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/pypi/v/mem0ai?color=%2334D058&amp;label=pypi%20package&quot; alt=&quot;Package version&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/mem0ai&quot; target=&quot;blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/v/mem0ai&quot; alt=&quot;Npm package&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.ycombinator.com/companies/mem0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Y%20Combinator-S24-orange?style=flat-square&quot; alt=&quot;Y Combinator S24&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mem0.ai/research&quot;&gt;&lt;strong&gt;📄 Building Production-Ready AI Agents with Scalable Long-Term Memory →&lt;/strong&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;⚡ +26% Accuracy vs. OpenAI Memory • 🚀 91% Faster • 💰 90% Fewer Tokens&lt;/strong&gt;
&lt;/p&gt;

##  🔥 Research Highlights
- **+26% Accuracy** over OpenAI Memory on the LOCOMO benchmark
- **91% Faster Responses** than full-context, ensuring low-latency at scale
- **90% Lower Token Usage** than full-context, cutting costs without compromise
- [Read the full paper](https://mem0.ai/research)

# Introduction

[Mem0](https://mem0.ai) (&quot;mem-zero&quot;) enhances AI assistants and agents with an intelligent memory layer, enabling personalized AI interactions. It remembers user preferences, adapts to individual needs, and continuously learns over time—ideal for customer support chatbots, AI assistants, and autonomous systems.

### Key Features &amp; Use Cases

**Core Capabilities:**
- **Multi-Level Memory**: Seamlessly retains User, Session, and Agent state with adaptive personalization
- **Developer-Friendly**: Intuitive API, cross-platform SDKs, and a fully managed service option

**Applications:**
- **AI Assistants**: Consistent, context-rich conversations
- **Customer Support**: Recall past tickets and user history for tailored help
- **Healthcare**: Track patient preferences and history for personalized care
- **Productivity &amp; Gaming**: Adaptive workflows and environments based on user behavior

## 🚀 Quickstart Guide &lt;a name=&quot;quickstart&quot;&gt;&lt;/a&gt;

Choose between our hosted platform or self-hosted package:

### Hosted Platform

Get up and running in minutes with automatic updates, analytics, and enterprise security.

1. Sign up on [Mem0 Platform](https://app.mem0.ai)
2. Embed the memory layer via SDK or API keys

### Self-Hosted (Open Source)

Install the sdk via pip:

```bash
pip install mem0ai
```

Install sdk via npm:
```bash
npm install mem0ai
```

### Basic Usage

Mem0 requires an LLM to function, with `gpt-4o-mini` from OpenAI as the default. However, it supports a variety of LLMs; for details, refer to our [Supported LLMs documentation](https://docs.mem0.ai/components/llms/overview).

First step is to instantiate the memory:

```python
from openai import OpenAI
from mem0 import Memory

openai_client = OpenAI()
memory = Memory()

def chat_with_memories(message: str, user_id: str = &quot;default_user&quot;) -&gt; str:
    # Retrieve relevant memories
    relevant_memories = memory.search(query=message, user_id=user_id, limit=3)
    memories_str = &quot;\n&quot;.join(f&quot;- {entry[&#039;memory&#039;]}&quot; for entry in relevant_memories[&quot;results&quot;])

    # Generate Assistant response
    system_prompt = f&quot;You are a helpful AI. Answer the question based on query and memories.\nUser Memories:\n{memories_str}&quot;
    messages = [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_prompt}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: message}]
    response = openai_client.chat.completions.create(model=&quot;gpt-4o-mini&quot;, messages=messages)
    assistant_response = response.choices[0].message.content

    # Create new memories from the conversation
    messages.append({&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: assistant_response})
    memory.add(messages, user_id=user_id)

    return assistant_response

def main():
    print(&quot;Chat with AI (type &#039;exit&#039; to quit)&quot;)
    while True:
        user_input = input(&quot;You: &quot;).strip()
        if user_input.lower() == &#039;exit&#039;:
            print(&quot;Goodbye!&quot;)
            break
        print(f&quot;AI: {chat_with_memories(user_input)}&quot;)

if __name__ == &quot;__main__&quot;:
    main()
```

For detailed integration steps, see the [Quickstart](https://docs.mem0.ai/quickstart) and [API Reference](https://docs.mem0.ai/api-reference).

## 🔗 Integrations &amp; Demos

- **ChatGPT with Memory**: Personalized chat powered by Mem0 ([Live Demo](https://mem0.dev/demo))
- **Browser Extension**: Store memories across ChatGPT, Perplexity, and Claude ([Chrome Extension](https://chromewebstore.google.com/detail/onihkkbipkfeijkadecaafbgagkhglop?utm_source=item-share-cb))
- **Langgraph Support**: Build a customer bot with Langgraph + Mem0 ([Guide](https://docs.mem0.ai/integrations/langgraph))
- **CrewAI Integration**: Tailor CrewAI outputs with Mem0 ([Example](https://docs.mem0.ai/integrations/crewai))

## 📚 Documentation &amp; Support

- Full docs: https://docs.mem0.ai
- Community: [Discord](https://mem0.dev/DiG) · [Twitter](https://x.com/mem0ai)
- Contact: founders@mem0.ai

## Citation

We now have a paper you can cite:

```bibtex
@article{mem0,
  title={Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory},
  author={Chhikara, Prateek and Khant, Dev and Aryan, Saket and Singh, Taranjeet and Yadav, Deshraj},
  journal={arXiv preprint arXiv:2504.19413},
  year={2025}
}
```

## ⚖️ License

Apache 2.0 — see the [LICENSE](LICENSE) file for details.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[happycola233/tchMaterial-parser]]></title>
            <link>https://github.com/happycola233/tchMaterial-parser</link>
            <guid>https://github.com/happycola233/tchMaterial-parser</guid>
            <pubDate>Sat, 17 May 2025 00:04:22 GMT</pubDate>
            <description><![CDATA[国家中小学智慧教育平台 电子课本下载工具，帮助您从智慧教育平台中获取电子课本的 PDF 文件网址并进行下载，让您更方便地获取课本内容。]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/happycola233/tchMaterial-parser">happycola233/tchMaterial-parser</a></h1>
            <p>国家中小学智慧教育平台 电子课本下载工具，帮助您从智慧教育平台中获取电子课本的 PDF 文件网址并进行下载，让您更方便地获取课本内容。</p>
            <p>Language: Python</p>
            <p>Stars: 1,452</p>
            <p>Forks: 160</p>
            <p>Stars today: 406 stars today</p>
            <h2>README</h2><pre># [国家中小学智慧教育平台](https://basic.smartedu.cn/tchMaterial/) 电子课本下载工具

![Python Version](https://img.shields.io/badge/Python-3.x-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Made With Love❤️](https://img.shields.io/badge/Made_With-%E2%9D%A4-red.svg)

&gt; [!TIP]
&gt; 🚀最新版本 v3.0 现已发布，欢迎体验！

本工具可以帮助您从[**国家中小学智慧教育平台**](https://basic.smartedu.cn/tchMaterial/)获取电子课本的 PDF 文件网址并进行下载，让您更方便地获取课本内容。

&gt; [!NOTE]
&gt;
&gt; 自**2025 年 2 月**起，国家中小学智慧教育平台**需要登录**才能访问电子课本资源，用户需提供 **Access Token**（即登录凭据）才可正常使用本工具的下载功能。
&gt;
&gt; **👉请先按照[下方指南](#2-设置-access-token)设置 Access Token，否则程序将无法解析资源！**

## ✨工具特点

- **支持 Access Token 登录**🔑：支持用户手动输入 Access Token，在 Windows 操作系统下会存入注册表，下次启动可自动加载。
- **支持批量下载**📚：一次输入多个电子课本预览页面网址，即可批量下载 PDF 课本文件。
- **自动文件命名**📂：程序会自动使用教材名称作为文件名，方便管理下载的课本文件。
- **高 DPI 适配**🖥️：优化 UI 以适配高分辨率屏幕，避免界面模糊问题。
- **下载进度可视化**📊：实时显示下载进度，支持暂停/恢复操作。
- **跨平台支持**💻：支持 Windows、Linux、macOS 等操作系统（需要图形界面）。

![程序截图](./res/PixPin_2025-03-14_23-44-26.png)

## ⬇️下载与安装方法

### GitHub Releases 页面

由于我们的精力有限，本项目的 [GitHub Releases 页面](https://github.com/happycola233/tchMaterial-parser/releases)**仅会发布适用于 Windows 与 Linux 操作系统的 x64 架构**的程序。

在下载完成之后，即可运行本程序，不需要额外的安装步骤。

### Arch 用户软件仓库（AUR）

对于 **Arch Linux** 操作系统，本程序已发布至[Arch 用户软件仓库](https://aur.archlinux.org/packages/tchmaterial-parser)，因此您还可以通过在终端中输入以下命令安装：

```sh
yay -S tchmaterial-parser
```

感谢 [@iamzhz](https://github.com/iamzhz) 制作了本工具的发行包（[#26](../../issues/26)）！

## 🛠️使用方法

### 1. 输入教材链接📥

将电子课本的**预览页面网址**粘贴到程序文本框中，支持多个 URL（每行一个）。

**示例网址**：

```text
https://basic.smartedu.cn/tchMaterial/detail?contentType=assets_document&amp;contentId=XXXXXX&amp;catalogType=tchMaterial&amp;subCatalog=tchMaterial
```

### 2. 设置 Access Token🔑

若您第一次使用本程序，需点击 “**设置 Token**” 按钮，粘贴 Access Token 并保存。

1. **打开浏览器**，访问[国家中小学智慧教育平台](https://auth.smartedu.cn/uias/login)并**登录账号**。
2. 按下 **F12** 或 **Ctrl+Shift+I**，或右键——检查（审查元素）打开**开发者工具**，选择**控制台（Console）**。
3. 在控制台粘贴以下代码后回车（Enter）：

   ```js
   (function() {
     const authKey = Object.keys(localStorage).find(key =&gt; key.startsWith(&quot;ND_UC_AUTH&quot;));
     if (!authKey) {
       console.error(&quot;未找到 Access Token，请确保已登录！&quot;);
       return;
     }
     const tokenData = JSON.parse(localStorage.getItem(authKey));
     const accessToken = JSON.parse(tokenData.value).access_token;
     console.log(&quot;%cAccess Token: &quot;, &quot;color: green; font-weight: bold&quot;, accessToken);
   })();
   ```
  
4. 复制控制台输出的 **Access Token**，然后在本程序中点击 “**设置 Token**” 按钮，粘贴并保存 Token。

&gt; [!NOTE]
&gt; Access Token 可能会过期，若下载失败提示 **401 Unauthorized**，请重新获取并设置新的 Token。

### 3. 开始下载🚀

点击 “**下载**” 按钮，程序将自动解析并下载 PDF 课本。

本工具支持**批量下载**，所有 PDF 文件会自动按课本名称命名并保存在选定目录中。

## ❓常见问题

### 1. 为什么下载失败？⚠️

- 检查是否已[**正确设置 Access Token**](#2-设置-access-token)🔑，且没有过期。
- **确认网络连接是否正常**🌐，有时网络不稳定可能导致下载失败。
- **确保输入的网址有效**🔗，部分旧资源可能已被移除。

### 2. Access Token 保存在哪里？💾

- **Windows 操作系统**：Token 会存储在**注册表** `HKEY_CURRENT_USER\Software\tchMaterial-parser` 项中的 `AccessToken` 值。
- **Linux 操作系统**: Token 会存储在 `~/.config/tchMaterial-parser/data.json` 的文件中。
- **macOS 等操作系统**：Token 仅在运行时临时存储于内存，不会自动保存，程序重启后需重新输入，目前我们正在努力改进该功能。

### 3. Token 会不会泄露？🔐

- 本程序**不会上传** Token，也不会存储在云端，仅用于本地请求授权。
- **请勿在公开场合分享 Token**，以免您的账号被他人使用，造成严重后果。

## ⭐Star History

[![Star History Chart](https://api.star-history.com/svg?repos=happycola233/tchMaterial-parser&amp;type=Date)](https://star-history.com/#happycola233/tchMaterial-parser&amp;Date)

## 🤝贡献指南

如果您发现 Bug 或有改进建议，欢迎提交 **Issue** 或 **Pull Request**，让我们一起完善本工具！

## 📜许可证

本项目基于 [MIT 许可证](LICENSE)，欢迎自由使用和二次开发。

## 💌友情链接

- 📚您也可以在 [ChinaTextbook](https://github.com/TapXWorld/ChinaTextbook) 项目中下载归档的教材 PDF。
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[trycua/cua]]></title>
            <link>https://github.com/trycua/cua</link>
            <guid>https://github.com/trycua/cua</guid>
            <pubDate>Sat, 17 May 2025 00:04:21 GMT</pubDate>
            <description><![CDATA[c/ua is the Docker Container for Computer-Use AI Agents.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/trycua/cua">trycua/cua</a></h1>
            <p>c/ua is the Docker Container for Computer-Use AI Agents.</p>
            <p>Language: Python</p>
            <p>Stars: 7,132</p>
            <p>Forks: 280</p>
            <p>Stars today: 433 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; alt=&quot;Cua logo&quot; height=&quot;150&quot; srcset=&quot;img/logo_white.png&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; alt=&quot;Cua logo&quot; height=&quot;150&quot; srcset=&quot;img/logo_black.png&quot;&gt;
    &lt;img alt=&quot;Cua logo&quot; height=&quot;150&quot; src=&quot;img/logo_black.png&quot;&gt;
  &lt;/picture&gt;

  [![Python](https://img.shields.io/badge/Python-333333?logo=python&amp;logoColor=white&amp;labelColor=333333)](#)
  [![Swift](https://img.shields.io/badge/Swift-F05138?logo=swift&amp;logoColor=white)](#)
  [![macOS](https://img.shields.io/badge/macOS-000000?logo=apple&amp;logoColor=F0F0F0)](#)
  [![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?&amp;logo=discord&amp;logoColor=white)](https://discord.com/invite/mVnXXpdE85)
  &lt;br&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/13685&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13685&quot; alt=&quot;trycua%2Fcua | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

**c/ua** (pronounced &quot;koo-ah&quot;) enables AI agents to control full operating systems in high-performance virtual containers with near-native speed on Apple Silicon.

&lt;div align=&quot;center&quot;&gt;
  &lt;video src=&quot;https://github.com/user-attachments/assets/c619b4ea-bb8e-4382-860e-f3757e36af20&quot; width=&quot;800&quot; controls&gt;&lt;/video&gt;
&lt;/div&gt;

# 🚀 Quick Start

Get started with a Computer-Use Agent UI and a VM with a single command:


```bash
/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/scripts/playground.sh)&quot;
```


This script will:
- Install Lume CLI for VM management (if needed)
- Pull the latest macOS CUA image (if needed)
- Set up Python environment and install/update required packages
- Launch the Computer-Use Agent UI

#### Supported [Agent Loops](https://github.com/trycua/cua/blob/main/libs/agent/README.md#agent-loops)
- [UITARS-1.5](https://github.com/trycua/cua/blob/main/libs/agent/README.md#agent-loops) - Run locally on Apple Silicon with MLX, or use cloud providers
- [OpenAI CUA](https://github.com/trycua/cua/blob/main/libs/agent/README.md#agent-loops) - Use OpenAI&#039;s Computer-Use Preview model
- [Anthropic CUA](https://github.com/trycua/cua/blob/main/libs/agent/README.md#agent-loops) - Use Anthropic&#039;s Computer-Use capabilities
- [OmniParser-v2.0](https://github.com/trycua/cua/blob/main/libs/agent/README.md#agent-loops) - Control UI with [Set-of-Marks prompting](https://som-gpt4v.github.io/) using any vision model

### System Requirements

- Mac with Apple Silicon (M1/M2/M3/M4 series)
- macOS 15 (Sequoia) or newer
- Disk space for VM images (30GB+ recommended)


# 💻 For Developers

### Step 1: Install Lume CLI

```bash
/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh)&quot;
```

Lume CLI manages high-performance macOS/Linux VMs with near-native speed on Apple Silicon.

### Step 2: Pull the macOS CUA Image

```bash
lume pull macos-sequoia-cua:latest
```

The macOS CUA image contains the default Mac apps and the Computer Server for easy automation.

### Step 3: Install Python SDK

```bash
pip install &quot;cua-computer[all]&quot; &quot;cua-agent[all]&quot;
```

Alternatively, see the [Developer Guide](./docs/Developer-Guide.md) for building from source.

### Step 4: Use in Your Code

```python
from computer import Computer
from agent import ComputerAgent, LLM

async def main():
    # Start a local macOS VM with a 1024x768 display
    async with Computer(os_type=&quot;macos&quot;, display=&quot;1024x768&quot;) as computer:

        # Example: Direct control of a macOS VM with Computer
        await computer.interface.left_click(100, 200)
        await computer.interface.type_text(&quot;Hello, world!&quot;)
        screenshot_bytes = await computer.interface.screenshot()
        
        # Example: Create and run an agent locally using mlx-community/UI-TARS-1.5-7B-6bit
        agent = ComputerAgent(
          computer=computer,
          loop=&quot;UITARS&quot;,
          model=LLM(provider=&quot;MLXVLM&quot;, name=&quot;mlx-community/UI-TARS-1.5-7B-6bit&quot;)
        )
        await agent.run(&quot;Find the trycua/cua repository on GitHub and follow the quick start guide&quot;)

main()
```

For ready-to-use examples, check out our [Notebooks](./notebooks/) collection.

### Lume CLI Reference

```bash
# Install Lume CLI and background service
curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh | bash

# List all VMs
lume ls

# Pull a VM image
lume pull macos-sequoia-cua:latest

# Create a new VM
lume create my-vm --os macos --cpu 4 --memory 8GB --disk-size 50GB

# Run a VM (creates and starts if it doesn&#039;t exist)
lume run macos-sequoia-cua:latest

# Stop a VM
lume stop macos-sequoia-cua_latest

# Delete a VM
lume delete macos-sequoia-cua_latest
```

### Lumier CLI Reference

For advanced container-like virtualization, check out [Lumier](./libs/lumier/README.md) - a Docker interface for macOS and Linux VMs.

```bash
# Install Lume CLI and background service
curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh | bash

# Run macOS in a Docker container
docker run -it --rm \
    --name lumier-vm \
    -p 8006:8006 \
    -v $(pwd)/storage:/storage \
    -v $(pwd)/shared:/shared \
    -e VM_NAME=lumier-vm \
    -e VERSION=ghcr.io/trycua/macos-sequoia-cua:latest \
    -e CPU_CORES=4 \
    -e RAM_SIZE=8192 \
    -e HOST_STORAGE_PATH=$(pwd)/storage \
    -e HOST_SHARED_PATH=$(pwd)/shared \
    trycua/lumier:latest
```

## Resources

- [How to use the MCP Server with Claude Desktop or other MCP clients](./libs/mcp-server/README.md) - One of the easiest ways to get started with C/ua
- [How to use OpenAI Computer-Use, Anthropic, OmniParser, or UI-TARS for your Computer-Use Agent](./libs/agent/README.md)
- [How to use Lume CLI for managing desktops](./libs/lume/README.md)
- [Training Computer-Use Models: Collecting Human Trajectories with C/ua (Part 1)](https://www.trycua.com/blog/training-computer-use-models-trajectories-1)
- [Build Your Own Operator on macOS (Part 1)](https://www.trycua.com/blog/build-your-own-operator-on-macos-1)

## Modules

| Module | Description | Installation |
|--------|-------------|---------------|
| [**Lume**](./libs/lume/README.md) | VM management for macOS/Linux using Apple&#039;s Virtualization.Framework | `curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh \| bash` |
| [**Lumier**](./libs/lumier/README.md) | Docker interface for macOS and Linux VMs | `docker pull trycua/lumier:latest` |
| [**Computer**](./libs/computer/README.md) | Interface for controlling virtual machines | `pip install &quot;cua-computer[all]&quot;` |
| [**Agent**](./libs/agent/README.md) | AI agent framework for automating tasks | `pip install &quot;cua-agent[all]&quot;` |
| [**MCP Server**](./libs/mcp-server/README.md) | MCP server for using CUA with Claude Desktop | `pip install cua-mcp-server` |
| [**SOM**](./libs/som/README.md) | Self-of-Mark library for Agent | `pip install cua-som` |
| [**PyLume**](./libs/pylume/README.md) | Python bindings for Lume | `pip install pylume` |
| [**Computer Server**](./libs/computer-server/README.md) | Server component for Computer | `pip install cua-computer-server` |
| [**Core**](./libs/core/README.md) | Core utilities | `pip install cua-core` |

## Computer Interface Reference

For complete examples, see [computer_examples.py](./examples/computer_examples.py) or [computer_nb.ipynb](./notebooks/computer_nb.ipynb)

```python
# Mouse Actions
await computer.interface.left_click(x, y)       # Left click at coordinates
await computer.interface.right_click(x, y)      # Right click at coordinates
await computer.interface.double_click(x, y)     # Double click at coordinates
await computer.interface.move_cursor(x, y)      # Move cursor to coordinates
await computer.interface.drag_to(x, y, duration)  # Drag to coordinates
await computer.interface.get_cursor_position()  # Get current cursor position

# Keyboard Actions
await computer.interface.type_text(&quot;Hello&quot;)     # Type text
await computer.interface.press_key(&quot;enter&quot;)     # Press a single key
await computer.interface.hotkey(&quot;command&quot;, &quot;c&quot;) # Press key combination

# Screen Actions
await computer.interface.screenshot()           # Take a screenshot
await computer.interface.get_screen_size()      # Get screen dimensions

# Clipboard Actions
await computer.interface.set_clipboard(text)    # Set clipboard content
await computer.interface.copy_to_clipboard()    # Get clipboard content

# File System Operations
await computer.interface.file_exists(path)      # Check if file exists
await computer.interface.directory_exists(path) # Check if directory exists
await computer.interface.run_command(cmd)       # Run shell command

# Accessibility
await computer.interface.get_accessibility_tree() # Get accessibility tree
```

## ComputerAgent Reference

For complete examples, see [agent_examples.py](./examples/agent_examples.py) or [agent_nb.ipynb](./notebooks/agent_nb.ipynb)

```python
# Import necessary components
from agent import ComputerAgent, LLM, AgentLoop, LLMProvider

# UI-TARS-1.5 agent for local execution with MLX
ComputerAgent(loop=AgentLoop.UITARS, model=LLM(provider=LLMProvider.MLXVLM, name=&quot;mlx-community/UI-TARS-1.5-7B-6bit&quot;))   
# OpenAI Computer-Use agent using OPENAI_API_KEY  
ComputerAgent(loop=AgentLoop.OPENAI, model=LLM(provider=LLMProvider.OPENAI, name=&quot;computer-use-preview&quot;))
# Anthropic Claude agent using ANTHROPIC_API_KEY
ComputerAgent(loop=AgentLoop.ANTHROPIC, model=LLM(provider=LLMProvider.ANTHROPIC))

# OmniParser loop for UI control using Set-of-Marks (SOM) prompting and any vision LLM
ComputerAgent(loop=AgentLoop.OMNI, model=LLM(provider=LLMProvider.OLLAMA, name=&quot;gemma3:12b-it-q4_K_M&quot;))      
# OpenRouter example using OAICOMPAT provider
ComputerAgent(
    loop=AgentLoop.OMNI,
    model=LLM(
        provider=LLMProvider.OAICOMPAT, 
        name=&quot;openai/gpt-4o-mini&quot;,
        provider_base_url=&quot;https://openrouter.ai/api/v1&quot;
    ),
    api_key=&quot;your-openrouter-api-key&quot;
)
```

## Demos

Check out these demos of the Computer-Use Agent in action:

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;MCP Server: Work with Claude Desktop and Tableau&lt;/b&gt;&lt;/summary&gt;
&lt;br&gt;
&lt;div align=&quot;center&quot;&gt;
    &lt;video src=&quot;https://github.com/user-attachments/assets/9f573547-5149-493e-9a72-396f3cff29df&quot; width=&quot;800&quot; controls&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;AI-Gradio: Multi-app workflow with browser, VS Code and terminal&lt;/b&gt;&lt;/summary&gt;
&lt;br&gt;
&lt;div align=&quot;center&quot;&gt;
    &lt;video src=&quot;https://github.com/user-attachments/assets/723a115d-1a07-4c8e-b517-88fbdf53ed0f&quot; width=&quot;800&quot; controls&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Notebook: Fix GitHub issue in Cursor&lt;/b&gt;&lt;/summary&gt;
&lt;br&gt;
&lt;div align=&quot;center&quot;&gt;
    &lt;video src=&quot;https://github.com/user-attachments/assets/f67f0107-a1e1-46dc-aa9f-0146eb077077&quot; width=&quot;800&quot; controls&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;/details&gt;

## Community

Join our [Discord community](https://discord.com/invite/mVnXXpdE85) to discuss ideas, get assistance, or share your demos!

## License

Cua is open-sourced under the MIT License - see the [LICENSE](LICENSE) file for details.

Microsoft&#039;s OmniParser, which is used in this project, is licensed under the Creative Commons Attribution 4.0 International License (CC-BY-4.0) - see the [OmniParser LICENSE](https://github.com/microsoft/OmniParser/blob/master/LICENSE) file for details.

## Contributing

We welcome contributions to CUA! Please refer to our [Contributing Guidelines](CONTRIBUTING.md) for details.

## Trademarks

Apple, macOS, and Apple Silicon are trademarks of Apple Inc. Ubuntu and Canonical are registered trademarks of Canonical Ltd. Microsoft is a registered trademark of Microsoft Corporation. This project is not affiliated with, endorsed by, or sponsored by Apple Inc., Canonical Ltd., or Microsoft Corporation.

## Stargazers

Thank you to all our supporters!

[![Stargazers over time](https://starchart.cc/trycua/cua.svg?variant=adaptive)](https://starchart.cc/trycua/cua)

## Contributors

&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt;
&lt;!-- prettier-ignore-start --&gt;
&lt;!-- markdownlint-disable --&gt;
&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/f-trycua&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/195596869?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;f-trycua&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;f-trycua&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-f-trycua&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://pepicrft.me&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/663605?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Pedro Piñera Buendía&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Pedro Piñera Buendía&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-pepicrft&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://iamit.in&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/5647941?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Amit Kumar&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Amit Kumar&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-aktech&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://productsway.com/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/870029?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Dung Duc Huynh (Kaka)&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Dung Duc Huynh (Kaka)&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-jellydn&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://zaydkrunz.com&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/70227235?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Zayd Krunz&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Zayd Krunz&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-ShrootBuck&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/PrashantRaj18198&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/23168997?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Prashant Raj&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Prashant Raj&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-PrashantRaj18198&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.mobile.dev&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/847683?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Leland Takamine&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Leland Takamine&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-Leland-Takamine&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/ddupont808&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/3820588?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;ddupont&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;ddupont&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-ddupont808&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/Lizzard1123&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/46036335?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Ethan Gutierrez&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ethan Gutierrez&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-Lizzard1123&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://ricterz.me&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/5282759?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Ricter Zheng&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ricter Zheng&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-RicterZ&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.trytruffle.ai/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/50844303?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Rahul Karajgikar&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Rahul Karajgikar&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-rahulkarajgikar&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/trospix&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/81363696?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;trospix&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;trospix&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-trospix&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://wavee.world/invitation/b96d00e6-b802-4a1b-8a66-2e3854a01ffd&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/22633385?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Ikko Eltociear Ashimine&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ikko Eltociear Ashimine&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-eltociear&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/dp221125&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/10572119?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;한석호(MilKyo)&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;한석호(MilKyo)&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-dp221125&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.encona.com/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/891558?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Rahim Nathwani&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Rahim Nathwani&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-rahimnathwani&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://mjspeck.github.io/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/20689127?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Matt Speck&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Matt Speck&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-mjspeck&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/FinnBorge&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/9272726?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;FinnBorge&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;FinnBorge&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-FinnBorge&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/jklapacz&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/5343758?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Jakub Klapacz&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jakub Klapacz&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#code-jklapacz&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;!-- markdownlint-restore --&gt;
&lt;!-- prettier-ignore-end --&gt;

&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[xaoyaoo/PyWxDump]]></title>
            <link>https://github.com/xaoyaoo/PyWxDump</link>
            <guid>https://github.com/xaoyaoo/PyWxDump</guid>
            <pubDate>Sat, 17 May 2025 00:04:20 GMT</pubDate>
            <description><![CDATA[获取微信信息；读取数据库，本地查看聊天记录并导出为csv、html等格式用于AI训练，自动回复等。支持多账户信息获取，支持所有微信版本。]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/xaoyaoo/PyWxDump">xaoyaoo/PyWxDump</a></h1>
            <p>获取微信信息；读取数据库，本地查看聊天记录并导出为csv、html等格式用于AI训练，自动回复等。支持多账户信息获取，支持所有微信版本。</p>
            <p>Language: Python</p>
            <p>Stars: 8,031</p>
            <p>Forks: 1,242</p>
            <p>Stars today: 87 stars today</p>
            <h2>README</h2><pre>[![中文](https://img.shields.io/badge/README-中文-494cad.svg)](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/README_CN.md) [![English](https://img.shields.io/badge/README-English-494cad.svg)](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/README_EN.md)

# &lt;center&gt;PyWxDump&lt;/center&gt;

[![Python](https://img.shields.io/badge/Python-3-blue.svg)](https://www.python.org/)
[![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/xaoyaoo/pywxdump)](https://github.com/xaoyaoo/PyWxDump)
[![GitHub all releases](https://img.shields.io/github/downloads/xaoyaoo/pywxdump/total)](https://github.com/xaoyaoo/PyWxDump)
[![GitHub stars](https://img.shields.io/github/stars/xaoyaoo/PyWxDump.svg)](https://github.com/xaoyaoo/PyWxDump)
[![GitHub forks](https://img.shields.io/github/forks/xaoyaoo/PyWxDump.svg)](https://github.com/xaoyaoo/PyWxDump/fork)
[![GitHub issues](https://img.shields.io/github/issues/xaoyaoo/PyWxDump)](https://github.com/xaoyaoo/PyWxDump/issues)

[![PyPI](https://img.shields.io/pypi/v/pywxdump)](https://pypi.org/project/pywxdump/)
[![Wheel](https://img.shields.io/pypi/wheel/pywxdump)](https://pypi.org/project/pywxdump/)
[![PyPI-Downloads](https://img.shields.io/pypi/dm/pywxdump)](https://pypistats.org/packages/pywxdump)
[![GitHub license](https://img.shields.io/pypi/l/pywxdump)](https://github.com/xaoyaoo/PyWxDump/blob/master/LICENSE)

* Welcome to provide more ideas or code to improve this project together.

### If you are a novice, please pay attention to the Official Accounts: `逍遥之芯` (the QR code is below), and reply: `PyWxDump` to get a picture text tutorial.

### If you have any questions, please check first: [FAQ](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/FAQ.md) Whether there is an answer, or follow the Official Accounts to reply: `FAQ`.

QQ GROUP：[276392799](https://s.xaoyo.top/gOLUDl) or [276392799](https://s.xaoyo.top/bgNcRa)（PASSWORD,please read:[UserGuide.md](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/UserGuide.md)）.

&lt;div&gt;
  &lt;img align=&quot;&quot; width=&quot;200&quot;  src=&quot;https://github.com/xaoyaoo/PyWxDump/blob/master/doc/img/qrcode_gh.jpg&quot; alt=&quot;the Official Accounts&quot; title=&quot;the Official Accounts&quot; height=&quot;200&quot;/&gt;
&lt;/div&gt;

# I. Project Introduction

## 1. Brief Introduction

[PyWxDump](https://github.com/xaoyaoo/PyWxDump) is a tool for obtaining wx account information (nicknames/accounts/phones/emails/database keys), decrypting databases, viewing wx chat, and exporting chat as html backups.

* &lt;strong&gt;&lt;big&gt;Super eager for stars, if you&#039;ve come across this project, please give me a [![Star](https://img.shields.io/github/stars/xaoyaoo/PyWxDump.svg?style=social&amp;label=Star)](https://github.com/xaoyaoo/PyWxDump/)! Thank you so much~ &lt;/big&gt;&lt;/strong&gt;

## 2. Feature

#### 2.1 Core

* (1) Get the **base address offset** of WeChat nickname, WeChat account, WeChat phone number, WeChat email, and WeChat KEY
* (2) Get the WeChat nickname, WeChat account, WeChat phone number, WeChat email, WeChat KEY, WeChat original ID (wxid_******), and WeChat folder path of the currently logged-in WeChat
* (3) Decrypt WeChat database based on key
* (4) Combine multiple types of databases for unified viewing

#### 2.2 Extend Function

* (1) View chat history through the web
* (2) Support exporting chat logs as html, csv, and backing up WeChat chat logs
* (3) Remote viewing of WeChat chat history (must be network accessible, such as a local area network)

#### 2.3 Document Class

* (1) Provide descriptions of some fields in the database
* (2) Provide CE to obtain the base address offset method
* (3) Provide a decryption method for MAC database

#### 2.4 Other functions

* (1) Added a minimalist version of [pywxdumpmini](https://github.com/xaoyaoo/pywxdumpmini), which provides only the ability to obtain database keys and database locations
* (2) Support multiple WeChat opening scenarios, obtain multiple user information, etc.

**Utilize the scene**

1. Network security...
2. Daily backup archiving
3. View chat history remotely (view chat history through the web)
4. Wait...............

## 3. Update plan

* 1.Analyze chat logs of each person and generate word clouds.
* ~~2.Analyze the number of chats per person per day and generate a line chart (day-number of chats)~~
* ~~3.Analyze the monthly and annual chat volume of different people and generate a line chart~~
* ~~4.Generate annual visualization reports~~
* 8.Increase support for enterprise WeChat
* 12.Viewing and backing up of the circle of friends
* ~~13.Clean up WeChat storage space and reduce the space occupied by WeChat (hopefully by selecting a person or group and finding out the media files involved in the chat logs of this group, such as pictures, videos, files, voice recordings, etc., and selectively (such as time periods) or batch-wise clearing them from the computer&#039;s cache by group conversation.)~~
* 14.Automatically send messages to specified people through UI control

## 4. Other

[PyWxDump](https://github.com/xaoyaoo/PyWxDump) is a refactored python language version of [SharpWxDump](https://github.com/AdminTest0/SharpWxDump), with many new features added.

* Project address: https://github.com/xaoyaoo/PyWxDump
* Currently tested only under Windows, there may be issues under mac and Linux.
* If you find any missing or incorrect information, bugs, or suggestions for improvement in the [WX_OFFS.json](https://github.com/xaoyaoo/PyWxDump/tree/master/pywxdump/WX_OFFS.json), please submit an issue on GitHub.
* For common issues, please refer to [FAQ](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/FAQ.md), and for the update log, please refer to [CHANGELOG](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/CHANGELOG.md)
* Web UI repository location [wxdump_web](https://github.com/xaoyaoo/wxdump_web )
* If you are interested in the implementation principle of wxdump, please pay attention to the Official Accounts: `逍遥之芯`, reply: `原理` to get the principle analysis.
* [:sparkling\_heart: Support Me]( https://github.com/xaoyaoo/xaoyaoo/blob/main/donate.md)

## 5. Star History

&lt;details&gt;
&lt;summary&gt;click to expand&lt;/summary&gt;

[![Star History Chart](https://api.star-history.com/svg?repos=xaoyaoo/pywxdump&amp;type=Date)](https://star-history.com/#xaoyaoo/pywxdump&amp;Date)

&lt;/details&gt;

# Ⅱ. Instructions For Use

* Detailed instructions, see: [UserGuide.md](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/UserGuide.md)

* the minimalist version, see: [pywxdumpmini](https://github.com/xaoyaoo/pywxdumpmini)

* If you want to modify the UI, clone the [wx_dump_web](https://github.com/xaoyaoo/wxdump_web) and modify it as needed (the UI is developed using VUE+ElementUI)

【note】:

* For obtaining the base address using cheat engine, refer to [CE obtaining base address.md](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/CE获取基址.md)
  (This method can be replaced by the `wxdump bias` command, and is only used for learning principles.)
* For database parsing, refer to [wx database brief.md](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/wx数据库简述.md)

# Ⅲ. Disclaimer (VERY VERY VERY IMPORTANT ! ! ! ! ! !)

### 1. Purpose of use

* This project is only for learning and communication purposes, **please do not use it for illegal purposes**, **please do not use it for illegal purposes**, **please do not use it for illegal purposes**, otherwise the consequences will be borne by yourself.
* Users understand and agree that any violation of laws and regulations, infringement of the legitimate rights and interests of others, is unrelated to this project and its developers, and the consequences are borne by the user themselves.

### 2. Usage Period

* You should delete the source code and (compiled) program of this project within 24 hours of downloading, saving, compiling, and using it; any use beyond this period is not related to this project or its developer.

### 3. Operation specifications

* This project only allows backup and viewing of the database under authorization. It is strictly prohibited for illegal purposes, otherwise all related responsibilities will be borne by the user. Any legal liability incurred by the user due to violation of this regulation will be borne by the user, and is unrelated to this project and its developer.
* It is strictly prohibited to use it to steal others&#039; privacy. Otherwise, all relevant responsibilities shall be borne by yourself.
* It is strictly prohibited to conduct secondary development, otherwise all related responsibilities shall be borne by yourself.

### 4. Acceptance of Disclaimer

* Downloading, saving, further browsing the source code, or downloading, installing, compiling, and using this program indicates that you agree with this warning and promise to abide by it;

### 5. Forbidden for illegal testing or penetration

* It is prohibited to use the relevant technologies of this project to engage in illegal testing or penetration, and it is prohibited to use the relevant codes or related technologies of this project to engage in any illegal work. Any adverse consequences arising therefrom are not related to this project and its developers.
* Any resulting adverse consequences, including but not limited to data leakage, system failure, and privacy infringement, are not related to this project or its developers and are the responsibility of the user.

### 6. Modification of disclaimer

* This disclaimer may be modified and adjusted based on the project&#039;s operating conditions and changes in laws and regulations. Users should regularly check this page for the latest version of the disclaimer, and should comply with the latest version of the disclaimer when using this project.

### 7. Others

* In addition to the provisions of this disclaimer, users should comply with relevant laws, regulations, and ethical norms during the use of this project. The project and its developers will not be held responsible for any disputes or losses caused by users&#039; violation of relevant regulations.

* Users are requested to carefully read and understand all contents of this disclaimer, and ensure that they strictly comply with relevant regulations when using this project.

# Ⅳ. Acknowledgments

[![PyWxDump CONTRIBUTORS](https://contrib.rocks/image?repo=xaoyaoo/PyWxDump)](https://github.com/xaoyaoo/PyWxDump/graphs/contributors)  

UI CONTRIBUTORS:    

[![UI CONTRIBUTORS](https://contrib.rocks/image?repo=xaoyaoo/wxdump_web)](https://github.com/xaoyaoo/wxdump_web/graphs/contributors)

otherContributors:

[643104191](https://github.com/643104191) (add [ctypes_utils](https://github.com/xaoyaoo/PyWxDump/blob/9e3e4cb5aec2b9b445c8283d61c58863f4129c6e/pywxdump/wx_info/ctypes_utils.py), Accelerated the acquisition of wxinfo; [9e3e4cb](https://github.com/xaoyaoo/PyWxDump/commit/9e3e4cb5aec2b9b445c8283d61c58863f4129c6e))

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[virattt/ai-hedge-fund]]></title>
            <link>https://github.com/virattt/ai-hedge-fund</link>
            <guid>https://github.com/virattt/ai-hedge-fund</guid>
            <pubDate>Sat, 17 May 2025 00:04:19 GMT</pubDate>
            <description><![CDATA[An AI Hedge Fund Team]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/virattt/ai-hedge-fund">virattt/ai-hedge-fund</a></h1>
            <p>An AI Hedge Fund Team</p>
            <p>Language: Python</p>
            <p>Stars: 27,732</p>
            <p>Forks: 4,797</p>
            <p>Stars today: 313 stars today</p>
            <h2>README</h2><pre># AI Hedge Fund

This is a proof of concept for an AI-powered hedge fund.  The goal of this project is to explore the use of AI to make trading decisions.  This project is for **educational** purposes only and is not intended for real trading or investment.

This system employs several agents working together:

1. Aswath Damodaran Agent - The Dean of Valuation, focuses on story, numbers, and disciplined valuation
2. Ben Graham Agent - The godfather of value investing, only buys hidden gems with a margin of safety
3. Bill Ackman Agent - An activist investor, takes bold positions and pushes for change
4. Cathie Wood Agent - The queen of growth investing, believes in the power of innovation and disruption
5. Charlie Munger Agent - Warren Buffett&#039;s partner, only buys wonderful businesses at fair prices
6. Michael Burry Agent - The Big Short contrarian who hunts for deep value
7. Peter Lynch Agent - Practical investor who seeks &quot;ten-baggers&quot; in everyday businesses
8. Phil Fisher Agent - Meticulous growth investor who uses deep &quot;scuttlebutt&quot; research 
9. Stanley Druckenmiller Agent - Macro legend who hunts for asymmetric opportunities with growth potential
10. Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price
11. Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals
12. Sentiment Agent - Analyzes market sentiment and generates trading signals
13. Fundamentals Agent - Analyzes fundamental data and generates trading signals
14. Technicals Agent - Analyzes technical indicators and generates trading signals
15. Risk Manager - Calculates risk metrics and sets position limits
16. Portfolio Manager - Makes final trading decisions and generates orders
    
&lt;img width=&quot;1042&quot; alt=&quot;Screenshot 2025-03-22 at 6 19 07 PM&quot; src=&quot;https://github.com/user-attachments/assets/cbae3dcf-b571-490d-b0ad-3f0f035ac0d4&quot; /&gt;


**Note**: the system simulates trading decisions, it does not actually trade.

[![Twitter Follow](https://img.shields.io/twitter/follow/virattt?style=social)](https://twitter.com/virattt)

## Disclaimer

This project is for **educational and research purposes only**.

- Not intended for real trading or investment
- No warranties or guarantees provided
- Past performance does not indicate future results
- Creator assumes no liability for financial losses
- Consult a financial advisor for investment decisions

By using this software, you agree to use it solely for learning purposes.

## Table of Contents
- [Setup](#setup)
  - [Using Poetry](#using-poetry)
  - [Using Docker](#using-docker)
- [Usage](#usage)
  - [Running the Hedge Fund](#running-the-hedge-fund)
  - [Running the Backtester](#running-the-backtester)
- [Project Structure](#project-structure)
- [Contributing](#contributing)
- [Feature Requests](#feature-requests)
- [License](#license)

## Setup

### Using Poetry

Clone the repository:
```bash
git clone https://github.com/virattt/ai-hedge-fund.git
cd ai-hedge-fund
```

1. Install Poetry (if not already installed):
```bash
curl -sSL https://install.python-poetry.org | python3 -
```

2. Install dependencies:
```bash
poetry install
```

3. Set up your environment variables:
```bash
# Create .env file for your API keys
cp .env.example .env
```

4. Set your API keys:
```bash
# For running LLMs hosted by openai (gpt-4o, gpt-4o-mini, etc.)
# Get your OpenAI API key from https://platform.openai.com/
OPENAI_API_KEY=your-openai-api-key

# For running LLMs hosted by groq (deepseek, llama3, etc.)
# Get your Groq API key from https://groq.com/
GROQ_API_KEY=your-groq-api-key

# For getting financial data to power the hedge fund
# Get your Financial Datasets API key from https://financialdatasets.ai/
FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key
```

### Using Docker

1. Make sure you have Docker installed on your system. If not, you can download it from [Docker&#039;s official website](https://www.docker.com/get-started).

2. Clone the repository:
```bash
git clone https://github.com/virattt/ai-hedge-fund.git
cd ai-hedge-fund
```

3. Set up your environment variables:
```bash
# Create .env file for your API keys
cp .env.example .env
```

4. Edit the .env file to add your API keys as described above.

5. Build the Docker image:
```bash
# On Linux/Mac:
./run.sh build

# On Windows:
run.bat build
```

**Important**: You must set `OPENAI_API_KEY`, `GROQ_API_KEY`, `ANTHROPIC_API_KEY`, or `DEEPSEEK_API_KEY` for the hedge fund to work.  If you want to use LLMs from all providers, you will need to set all API keys.

Financial data for AAPL, GOOGL, MSFT, NVDA, and TSLA is free and does not require an API key.

For any other ticker, you will need to set the `FINANCIAL_DATASETS_API_KEY` in the .env file.

## Usage

### Running the Hedge Fund

#### With Poetry
```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA
```

#### With Docker
```bash
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA main

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA main
```

**Example Output:**
&lt;img width=&quot;992&quot; alt=&quot;Screenshot 2025-01-06 at 5 50 17 PM&quot; src=&quot;https://github.com/user-attachments/assets/e8ca04bf-9989-4a7d-a8b4-34e04666663b&quot; /&gt;

You can also specify a `--ollama` flag to run the AI hedge fund using local LLMs.

```bash
# With Poetry:
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --ollama

# With Docker (on Linux/Mac):
./run.sh --ticker AAPL,MSFT,NVDA --ollama main

# With Docker (on Windows):
run.bat --ticker AAPL,MSFT,NVDA --ollama main
```

You can also specify a `--show-reasoning` flag to print the reasoning of each agent to the console.

```bash
# With Poetry:
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --show-reasoning

# With Docker (on Linux/Mac):
./run.sh --ticker AAPL,MSFT,NVDA --show-reasoning main

# With Docker (on Windows):
run.bat --ticker AAPL,MSFT,NVDA --show-reasoning main
```

You can optionally specify the start and end dates to make decisions for a specific time period.

```bash
# With Poetry:
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 

# With Docker (on Linux/Mac):
./run.sh --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 main

# With Docker (on Windows):
run.bat --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 main
```

### Running the Backtester

#### With Poetry
```bash
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA
```

#### With Docker
```bash
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA backtest

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA backtest
```

**Example Output:**
&lt;img width=&quot;941&quot; alt=&quot;Screenshot 2025-01-06 at 5 47 52 PM&quot; src=&quot;https://github.com/user-attachments/assets/00e794ea-8628-44e6-9a84-8f8a31ad3b47&quot; /&gt;


You can optionally specify the start and end dates to backtest over a specific time period.

```bash
# With Poetry:
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01

# With Docker (on Linux/Mac):
./run.sh --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 backtest

# With Docker (on Windows):
run.bat --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 backtest
```

You can also specify a `--ollama` flag to run the backtester using local LLMs.
```bash
# With Poetry:
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA --ollama

# With Docker (on Linux/Mac):
./run.sh --ticker AAPL,MSFT,NVDA --ollama backtest

# With Docker (on Windows):
run.bat --ticker AAPL,MSFT,NVDA --ollama backtest
```


## Project Structure 
```
ai-hedge-fund/
├── src/
│   ├── agents/                   # Agent definitions and workflow
│   │   ├── bill_ackman.py        # Bill Ackman agent
│   │   ├── fundamentals.py       # Fundamental analysis agent
│   │   ├── portfolio_manager.py  # Portfolio management agent
│   │   ├── risk_manager.py       # Risk management agent
│   │   ├── sentiment.py          # Sentiment analysis agent
│   │   ├── technicals.py         # Technical analysis agent
│   │   ├── valuation.py          # Valuation analysis agent
│   │   ├── ...                   # Other agents
│   │   ├── warren_buffett.py     # Warren Buffett agent
│   │   ├── aswath_damodaran.py   # Aswath Damodaran agent
│   │   ├── ...                   # Other agents
│   │   ├── ...                   # Other agents
│   ├── tools/                    # Agent tools
│   │   ├── api.py                # API tools
│   ├── backtester.py             # Backtesting tools
│   ├── main.py # Main entry point
├── pyproject.toml
├── ...
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

**Important**: Please keep your pull requests small and focused.  This will make it easier to review and merge.

## Feature Requests

If you have a feature request, please open an [issue](https://github.com/virattt/ai-hedge-fund/issues) and make sure it is tagged with `enhancement`.

## License

This project is licensed under the MIT License - see the LICENSE file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[public-apis/public-apis]]></title>
            <link>https://github.com/public-apis/public-apis</link>
            <guid>https://github.com/public-apis/public-apis</guid>
            <pubDate>Sat, 17 May 2025 00:04:18 GMT</pubDate>
            <description><![CDATA[A collective list of free APIs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/public-apis/public-apis">public-apis/public-apis</a></h1>
            <p>A collective list of free APIs</p>
            <p>Language: Python</p>
            <p>Stars: 340,199</p>
            <p>Forks: 35,898</p>
            <p>Stars today: 418 stars today</p>
            <h2>README</h2><pre># Try Public APIs for free
The Public APIs repository is manually curated by community members like you and folks working at [APILayer](https://apilayer.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo). It includes an extensive list of public APIs from many domains that you can use for your own products. Consider it a treasure trove of APIs well-managed by the community over the years.

&lt;br &gt;

&lt;p&gt;
    &lt;a href=&quot;https://apilayer.com&quot;&gt;
        &lt;div&gt;
            &lt;img src=&quot;.github/cs1586-APILayerLogoUpdate2022-LJ_v2-HighRes.png&quot; width=&quot;100%&quot; alt=&quot;APILayer Logo&quot; /&gt;
        &lt;/div&gt;
    &lt;/a&gt;
  &lt;/p&gt;

[APILayer](https://apilayer.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo) is the fastest way to integrate APIs into any product. There are a lot of APIs available at [APILayer Marketplace](https://apilayer.com/#bestSellers&amp;utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo).

&lt;br &gt;

## APILayer APIs
| API | Description | Call this API |
|:---|:---|:---|
| [IP Stack](https://ipstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Locate and Identify Website Visitors by IP Address | [&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-55145132-244c-448c-8e6f-8780866e4862?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-55145132-244c-448c-8e6f-8780866e4862%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Marketstack](https://marketstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Free, easy-to-use REST API interface delivering worldwide stock market data in JSON format | [&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-9cbac391-3611-4f50-9bfd-d24ae41c97c1?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-9cbac391-3611-4f50-9bfd-d24ae41c97c1%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Weatherstack](https://weatherstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Retrieve instant, accurate weather information for any location in the world in lightweight JSON format | [&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-276c4312-f682-425d-b6b1-0f82c0a7f2b3?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-276c4312-f682-425d-b6b1-0f82c0a7f2b3%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Numverify](https://numverify.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers ) | Global Phone Number Validation &amp; Lookup JSON API |[&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-0760d25e-b802-412e-b0e4-26e5ca3b9ffa?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-0760d25e-b802-412e-b0e4-26e5ca3b9ffa%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Fixer](https://fixer.io/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Fixer is a simple and lightweight API for current and historical foreign exchange (forex) rates. |[&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-0d9c66b3-5f1a-42ed-a5ca-379217bd629d?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-0d9c66b3-5f1a-42ed-a5ca-379217bd629d%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|

&lt;br &gt;

## Learn more about Public APIs

&lt;strong&gt;Get Involved&lt;/strong&gt;

* [Contributing Guide](CONTRIBUTING.md)
* [API for this project](https://github.com/davemachado/public-api)
* [Issues](https://github.com/public-apis/public-apis/issues)
* [Pull Requests](https://github.com/public-apis/public-apis/pulls)
* [LICENSE](LICENSE) 

&lt;br /&gt;

## Index

* [Animals](#animals)
* [Anime](#anime)
* [Anti-Malware](#anti-malware)
* [Art &amp; Design](#art--design)
* [Authentication &amp; Authorization](#authentication--authorization)
* [Blockchain](#blockchain)
* [Books](#books)
* [Business](#business)
* [Calendar](#calendar)
* [Cloud Storage &amp; File Sharing](#cloud-storage--file-sharing)
* [Continuous Integration](#continuous-integration)
* [Cryptocurrency](#cryptocurrency)
* [Currency Exchange](#currency-exchange)
* [Data Validation](#data-validation)
* [Development](#development)
* [Dictionaries](#dictionaries)
* [Documents &amp; Productivity](#documents--productivity)
* [Email](#email)
* [Entertainment](#entertainment)
* [Environment](#environment)
* [Events](#events)
* [Finance](#finance)
* [Food &amp; Drink](#food--drink)
* [Games &amp; Comics](#games--comics)
* [Geocoding](#geocoding)
* [Government](#government)
* [Health](#health)
* [Jobs](#jobs)
* [Machine Learning](#machine-learning)
* [Music](#music)
* [News](#news)
* [Open Data](#open-data)
* [Open Source Projects](#open-source-projects)
* [Patent](#patent)
* [Personality](#personality)
* [Phone](#phone)
* [Photography](#photography)
* [Programming](#programming)
* [Science &amp; Math](#science--math)
* [Security](#security)
* [Shopping](#shopping)
* [Social](#social)
* [Sports &amp; Fitness](#sports--fitness)
* [Test Data](#test-data)
* [Text Analysis](#text-analysis)
* [Tracking](#tracking)
* [Transportation](#transportation)
* [URL Shorteners](#url-shorteners)
* [Vehicle](#vehicle)
* [Video](#video)
* [Weather](#weather)
&lt;br &gt;

### Animals
API | Description | Auth | HTTPS | CORS 
|:---|:---|:---|:---|:---|
| [AdoptAPet](https://www.adoptapet.com/public/apis/pet_list.html) | Resource to help get pets adopted | `apiKey` | Yes | Yes |
| [Axolotl](https://theaxolotlapi.netlify.app/) | Collection of axolotl pictures and facts | No | Yes | No |
| [Cat Facts](https://alexwohlbruck.github.io/cat-facts/) | Daily cat facts | No | Yes | No | |
| [Cataas](https://cataas.com/) | Cat as a service (cats pictures and gifs) | No | Yes | No |
| [Cats](https://docs.thecatapi.com/) | Pictures of cats from Tumblr | `apiKey` | Yes | No |
| [Dog Facts](https://dukengn.github.io/Dog-facts-API/) | Random dog facts | No | Yes | Yes |
| [Dog Facts](https://kinduff.github.io/dog-api/) | Random facts of Dogs | No | Yes | Yes |
| [Dogs](https://dog.ceo/dog-api/) | Based on the Stanford Dogs Dataset | No | Yes | Yes |
| [eBird](https://documenter.getpostman.com/view/664302/S1ENwy59) | Retrieve recent or notable birding observations within a region | `apiKey` | Yes | No |
| [FishWatch](https://www.fishwatch.gov/developers) | Information and pictures about individual fish species | No | Yes | Yes |
| [HTTP Cat](https://http.cat/) | Cat for every HTTP Status | No | Yes | Yes |
| [HTTP Dog](https://http.dog/) | Dogs for every HTTP response status code | No | Yes | Yes |
| [IUCN](http://apiv3.iucnredlist.org/api/v3/docs) | IUCN Red List of Threatened Species | `apiKey` | No | No |
| [MeowFacts](https://github.com/wh-iterabb-it/meowfacts) | Get random cat facts | No | Yes | No |
| [Movebank](https://github.com/movebank/movebank-api-doc) | Movement and Migration data of animals | No | Yes | Yes |
| [Petfinder](https://www.petfinder.com/developers/) | Petfinder is dedicated to helping pets find homes, another resource to get pets adopted | `apiKey` | Yes | Yes |
| [PlaceBear](https://placebear.com/) | Placeholder bear pictures | No | Yes | Yes |
| [PlaceDog](https://place.dog) | Placeholder Dog pictures | No | Yes | Yes |
| [PlaceKitten](https://placekitten.com/) | Placeholder Kitten pictures | No | Yes | Yes |
| [RandomDog](https://random.dog/woof.json) | Random pictures of dogs | No | Yes | Yes |
| [RandomDuck](https://random-d.uk/api) | Random pictures of ducks | No | Yes | No |
| [RandomFox](https://randomfox.ca/floof/) | Random pictures of foxes | No | Yes | No |
| [RescueGroups](https://userguide.rescuegroups.org/display/APIDG/API+Developers+Guide+Home) | Adoption | No | Yes | Unknown |
| [Shibe.Online](http://shibe.online/) | Random pictures of Shiba Inu, cats or birds | No | Yes | Yes |
| [The Dog](https://thedogapi.com/) | A public service all about Dogs, free to use when making your fancy new App, Website or Service | `apiKey` | Yes | No |
| [xeno-canto](https://xeno-canto.org/explore/api) | Bird recordings | No | Yes | Unknown |
| [Zoo Animals](https://zoo-animal-api.herokuapp.com/) | Facts and pictures of zoo animals | No | Yes | Yes |

**[⬆ Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;

### Anime
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [AniAPI](https://aniapi.com/docs/) | Anime discovery, streaming &amp; syncing with trackers | `OAuth` | Yes | Yes |
| [AniDB](https://wiki.anidb.net/HTTP_API_Definition) | Anime Database | `apiKey` | No | Unknown |
| [AniList](https://github.com/AniList/ApiV2-GraphQL-Docs) | Anime discovery &amp; tracking | `OAuth` | Yes | Unknown |
| [AnimeChan](https://github.com/RocktimSaikia/anime-chan) | Anime quotes (over 10k+) | No | Yes | No |
| [AnimeFacts](https://chandan-02.github.io/anime-facts-rest-api/) | Anime Facts (over 100+) | No | Yes | Yes |
| [AnimeNewsNetwork](https://www.animenewsnetwork.com/encyclopedia/api.php) | Anime industry news | No | Yes | Yes |
| [Catboy](https://catboys.com/api) | Neko images, funny GIFs &amp; more | No | Yes | Yes |
| [Danbooru Anime](https://danbooru.donmai.us/wiki_pages/help:api) | Thousands of anime artist database to find good anime art | `apiKey` | Yes | Yes |
| [Jikan](https://jikan.moe) | Unofficial MyAnimeList API | No | Yes | Yes |
| [Kitsu](https://kitsu.docs.apiary.io/) | Anime discovery platform | `OAuth` | Yes | Yes |
| [MangaDex](https://api.mangadex.org/docs.html) | Manga Database and Community | `apiKey` | Yes | Unknown |
| [Mangapi](https://rapidapi.com/pierre.carcellermeunier/api/mangapi3/) | Translate manga pages from one language to another | `apiKey` | Yes | Unknown |
| [MyAnimeList](https://myanimelist.net/clubs.php?cid=13727) | Anime and Manga Database and Community | `OAuth` | Yes | Unknown |
| [NekosBest](https://docs.nekos.best) | Neko Images &amp; Anime roleplaying GIFs | No | Yes | Yes |
| [Shikimori](https://shikimori.one/api/doc) | Anime discovery, tracking, forum, rates | `OAuth` | Yes | Unknown |
| [Studio Ghibli](https://ghibliapi.herokuapp.com) | Resources from Studio Ghibli films | No | Yes | Yes |
| [Trace Moe](https://soruly.github.io/trace.moe-api/#/) | A useful tool to get the exact scene of an anime from a screenshot | No | Yes | No |
| [Waifu.im](https://waifu.im/docs) | Get waifu pictures from an archive of over 4000 images and multiple tags | No | Yes | Yes |
| [Waifu.pics](https://waifu.pics/docs) | Image sharing platform for anime images | No | Yes | No |

**[⬆ Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;

### Anti-Malware
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [AbuseIPDB](https://docs.abuseipdb.com/) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |
| [AlienVault Open Threat Exchange (OTX)](https://otx.alienvault.com/api) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |
| [CAPEsandbox](https://capev2.readthedocs.io/en/latest/usage/api.html) | Malware execution and analysis | `apiKey` | Yes | Unknown |
| [Google Safe Browsing](https://developers.google.com/safe-browsing/) | Google Link/Domain Flagging | `apiKey` | Yes | Unknown |
| [MalDatabase](https://maldatabase.com/api-doc.html) | Provide malware datasets and threat intelligence feeds | `apiKey` | Yes | Unknown |
| [MalShare](https://malshare.com/doc.php) | Malware Archive / file sourcing | `apiKey` | Yes | No |
| [MalwareBazaar](https://bazaar.abuse.ch/api/) | Collect and share malware samples | `apiKey` | Yes | Unknown |
| [Metacert](https://metacert.com/) | Metacert Link Flagging | `apiKey` | Yes | Unknown |
| [NoPhishy](https://rapidapi.com/Amiichu/api/exerra-phishing-check/) | Check links to see if they&#039;re known phishing attempts | `apiKey` | Yes | Yes |
| [Phisherman](https://phisherman.gg/) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |
| [Scanii](https://docs.scanii.com/) | Simple REST API that can scan submitted documents/files for the presence of threats | `apiKey` | Yes | Yes |
| [URLhaus](https://urlhaus-api.abuse.ch/) | Bulk queries and Download Malware Samples | No | Yes | Yes |
| [URLScan.io](https://urlscan.io/about-api/) | Scan and Analyse URLs | `apiKey` | Yes | Unknown |
| [VirusTotal](https://www.virustotal.com/en/documentation/public-api/) | VirusTotal File/URL Analysis | `apiKey` | Yes | Unknown |
| [Web of Trust](https://support.mywot.com/hc/en-us/sections/360004477734-API-) | IP/domain/URL reputation | `apiKey` | Yes | Unknown | 

**[⬆ Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Art &amp; Design
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [Améthyste](https://api.amethyste.moe/) | Generate images for Discord users | `apiKey` | Yes | Unknown |
| [Art Institute of Chicago](https://api.artic.edu/docs/) | Art | No | Yes | Yes |
| [Colormind](http://colormind.io/api-access/) | Color scheme generator | No | No | Unknown |
| [ColourLovers](http://www.colourlovers.com/api) | Get various patterns, palettes and images | No | No | Unknown |
| [Cooper Hewitt](https://collection.cooperhewitt.org/api) | Smithsonian Design Museum | `apiKey` | Yes | Unknown |
| [Dribbble](https://developer.dribbble.com) | Discover the world’s top designers &amp; creatives | `OAuth` | Yes | Unknown |
| [EmojiHub](https://github.com/cheatsnake/emojihub) | Get emojis by categories and groups | No | Yes | Yes |
| [Europeana](https://pro.europeana.eu/resources/apis/search) | European Museum and Galleries content | `apiKey` | Yes | Unknown |
| [Harvard Art Museums](https://github.com/harvardartmuseums/api-docs) | Art | `apiKey` | No | Unknown |
| [Icon Horse](https://icon.horse) | Favicons for any website, with fallbacks | No | Yes | Yes |
| [Iconfinder](https://developer.iconfinder.com) | Icons | `apiKey` | Yes | Unknown |
| [Icons8](https://img.icons8.com/) | Icons (find &quot;search icon&quot; hyperlink in page) | No | Yes | Unknown |
| [Lordicon](https://lordicon.com/) | Icons with predone Animations | No | Yes | Yes |
| [Metropolitan Museum of Art](https://metmuseum.github.io/) | Met Museum of Art | No | Yes | No |
| [Noun Project](http://api.thenounproject.com/index.html) | Icons | `OAuth` | No | Unknown |
| [PHP-Noise](https://php-noise.com/) | Noise Background Image Generator | No | Yes | Yes |
| [Pixel Encounter](https://pixelencounter.com/api) | SVG Icon Generator | No | Yes | No |
| [Rijksmuseum](https://data.rijksmuseum.nl/object-metadata/api/) | RijksMuseum Data | `apiKey` | Yes | Unknown |
| [Word Cloud](https://wordcloudapi.com/) | Easily create word clouds | `apiKey` | Yes | Unknown |
| [xColors](https://x-colors.herokuapp.com/) | Generate &amp; convert colors | No | Yes | Yes |

**[⬆ Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Authentication &amp; Authorization
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [Auth0](https://auth0.com) | Easy to implement, adaptable authentication and authorization platform | `apiKey` | Yes | Yes |
| [GetOTP](https://otp.dev/en/docs/) | Implement OTP flow quickly | `apiKey` | Yes | No |
| [Micro User Service](https://m3o.com/user) | User management and authentication | `apiKey` | Yes | No |
| [MojoAuth](https://mojoauth.com) | Secure and modern passwordless authentication platform | `apiKey` | Yes | Yes |
| [SAWO Labs](https://sawolabs.com) | Simplify login and improve user experience by integrating passwordless authentication in your app | `apiKey` | Yes | Yes |
| [Stytch](https://stytch.com/) | User infrastructure for modern applications | `apiKey` | Yes | No |
| [Warrant](https://warrant.dev/) | APIs for authorization and access control | `apiKey` | Yes | Yes |

**[⬆ Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Blockchain
| API | Description | Auth | HTTPS | CORS |
|---|:---|:---|:---|:---|
| [Bitquery](https://graphql.bitquery.io/ide) | Onchain GraphQL APIs &amp; DEX APIs | `apiKey` | Yes | Yes |
| [Chainlink](https://chain.link/developer-resources) | Build hybrid smart contracts with Chainlink | No | Yes | Unknown |
| [Chainpoint](https://tierion.com/chainpoint/) | Chainpoint is a global network for anchoring data to the Bitcoin blockchain | No | Yes | Unknown |
| [Covalent](https://www.covalenthq.com/docs/api/) | Multi-blockchain data aggregator platform | `apiKey` | Yes | Unknown |
| [Etherscan](https://etherscan.io/apis) | Ethereum explorer API | `apiKey` | Yes | Yes |
| [Helium](https://docs.helium.com/api/blockchain/introduction/) | Helium is a global, distributed network of Hotspots that create public, long-range wireless coverage | No | Yes | Unknown |
| [Nownodes](https://nownodes.io/) | Blockchain-as-a-service solution that provides high-quality connection via API | `apiKey` | Yes | Unknown |
| [Steem](https://developers.steem.io/) | Blockchain-based blogging and social media website | No | No | No |
| [The Graph](https://thegraph.com) | Indexing protocol for querying networks like Ethereum with GraphQL | `apiKey` | Yes | Unknown |
| [Walltime](https://walltime.info/api.html) | To retrieve Walltime&#039;s market info | No | Yes | Unknown |
| [Watchdata](https://docs.watchdata.io) | Provide simple and reliable API access to Ethereum blockchain | `apiKey` | Yes | Unknown |

**[⬆ Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Books
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [A Bíblia Digital](https://www.abibliadigital.com.br/en) | Do not worry about managing the multiple versions of the Bible | `apiKey` | Yes | No |
| [Bhagavad Gita](https://docs.bhagavadgitaapi.in) | Open Source Shrimad Bhagavad Gita API including 21+ authors translation in Sanskrit/English/Hindi | `apiKey` | Yes | Yes |
| [Bhagavad Gita](https://bhagavadgita.io/api) | Bhagavad Gita text | `OAuth` | Yes | Yes |
| [Bhagavad Gita telugu](https://gita-api.vercel.app) | Bhagavad Gita API in telugu and odia languages | No | Yes | Yes |
| [Bible-api](https://bible-api.com/) | Free Bible API with multiple languages | No | Yes | Yes |
| [British National Bibliography](http://bnb.data.bl.uk/) | Books | No | No | Unknown |
| [Crossref Metadata Search](https://github.com/CrossRef/rest-api-doc) | Books &amp; Articles Metadata | No | Yes | Unknown |
| [Ganjoor](https://api.ganjoor.net) | Classic Persian poetry works including access to related manuscripts, recitations and music tracks | `OAuth` | Yes | Yes |
| [Google Books](https://developers.google.com/books/) | Books | `OAuth` | Yes | Unknown |
| [GurbaniNow](https://github.com/GurbaniNow/api) | Fast and Accurate Gurbani RESTful API | No | Yes | Unknown |
| [Gutendex](https://gutendex.com/) | Web-API for fetching data from Project Gutenberg Books Library | No | Yes | Unknown |
| [Open Library](https://openlibrary.org/developers/api) | Books, book covers and related data | No | Yes | No |
| [Penguin Publishing](http://www.penguinrandomhouse.biz/webservices/rest/) | Books, book covers and related data | No | Yes | Yes |
| [PoetryDB](https://github.com/thundercomb/poetrydb#readme) | Enables you to get instant data from our vast poetry collection | No | Yes | Yes |
| [Quran](https://quran.api-docs.io/) | RESTful Quran API with multiple languages | No | Yes | Yes |
| [Quran Cloud](https://alquran.cloud/api) | A RESTful Quran API to retrieve an Ayah, Surah, Juz or the entire Holy Quran | No | Yes | Yes |
| [Quran-api](https://github.com/fawazahmed0/quran-api#readme) | Free Quran API Service with 90+ different languages and 400+ translations | No | Yes | Yes |
| [Rig Veda](https://aninditabasu.github.io/indica/html/rv.html) | Gods and 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[coleam00/ottomator-agents]]></title>
            <link>https://github.com/coleam00/ottomator-agents</link>
            <guid>https://github.com/coleam00/ottomator-agents</guid>
            <pubDate>Sat, 17 May 2025 00:04:17 GMT</pubDate>
            <description><![CDATA[All the open source AI Agents hosted on the oTTomator Live Agent Studio platform!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/coleam00/ottomator-agents">coleam00/ottomator-agents</a></h1>
            <p>All the open source AI Agents hosted on the oTTomator Live Agent Studio platform!</p>
            <p>Language: Python</p>
            <p>Stars: 1,861</p>
            <p>Forks: 895</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre># What is the Live Agent Studio?

The [Live Agent Studio](https://studio.ottomator.ai) is a community-driven platform developed by [oTTomator](https://ottomator.ai) for you to explore cutting-edge AI agents and learn how to implement them for yourself or your business! All agents on this platform are open source and, over time, will cover a very large variety of use cases.

The goal with the studio is to build an educational platform for you to learn how to do incredible things with AI, while still providing practical value so that you’ll want to use the agents just for the sake of what they can do for you!

This platform is still in beta – expect longer response times under load, a rapidly growing agent library over the coming months, and a lot more content on this platform soon on Cole Medin’s YouTube channel!

# What is this Repository for?

This repository contains the source code/workflow JSON for all the agents on the Live Agent Studio! Every agent being added to the platform is currently be open sourced here so we can not only create a curated collection of cutting-edge agents together as a community, but also learn from one another!

## Tokens

Most agents on the Live Agent Studio cost tokens to use, which are purchasable on the platform. However, when you first sign in you are given some tokens to start so you can use the agents free of charge! The biggest reason agents cost tokens is that we pay for the LLM usage since we host all the agents developed by you and the rest of the community!

[Purchase Tokens](https://studio.ottomator.ai/pricing)

## Future Plans

As the Live Agent Studio develops, it will become the go-to place to stay on top of what is possible with AI agents! Anytime there is a new AI technology, groundbreaking agent research, or a new tool/library to build agents with, it’ll be featured through agents on the platform. It’s a tall order, but we have big plans for the oTTomator community, and we’re confident we can grow to accomplish this!

## FAQ

### I want to build an agent to showcase in the Live Agent Studio! How do I do that?

Head on over here to learn how to build an agent for the platform:

[Developer Guide](https://studio.ottomator.ai/guide)

Also check out [the sample n8n agent](~sample-n8n-agent~) for a starting point of building an n8n agent for the Live Agent Studio, and [the sample Python agent](~sample-python-agent~) for Python.

### How many tokens does it cost to use an agent?

Each agent will charge tokens per prompt. The number of tokens depends on the agent, as some agents use larger LLMs, some call LLMs multiple times, and some use paid APIs.

### Where can I go to talk about all these agents and get help implementing them myself?

Head on over to our Think Tank community and feel free to make a post!

[Think Tank Community](https://thinktank.ottomator.ai)

---

&amp;copy; 2024 Live Agent Studio. All rights reserved.  
Created by oTTomator
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[browser-use/browser-use]]></title>
            <link>https://github.com/browser-use/browser-use</link>
            <guid>https://github.com/browser-use/browser-use</guid>
            <pubDate>Sat, 17 May 2025 00:04:16 GMT</pubDate>
            <description><![CDATA[🌐 Make websites accessible for AI agents. Automate tasks online with ease.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/browser-use/browser-use">browser-use/browser-use</a></h1>
            <p>🌐 Make websites accessible for AI agents. Automate tasks online with ease.</p>
            <p>Language: Python</p>
            <p>Stars: 60,388</p>
            <p>Forks: 6,662</p>
            <p>Stars today: 109 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./static/browser-use-dark.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;./static/browser-use.png&quot;&gt;
  &lt;img alt=&quot;Shows a black Browser Use Logo in light color mode and a white one in dark color mode.&quot; src=&quot;./static/browser-use.png&quot;  width=&quot;full&quot;&gt;
&lt;/picture&gt;

&lt;h1 align=&quot;center&quot;&gt;Enable AI to control your browser 🤖&lt;/h1&gt;

[![GitHub stars](https://img.shields.io/github/stars/gregpr07/browser-use?style=social)](https://github.com/gregpr07/browser-use/stargazers)
[![Discord](https://img.shields.io/discord/1303749220842340412?color=7289DA&amp;label=Discord&amp;logo=discord&amp;logoColor=white)](https://link.browser-use.com/discord)
[![Cloud](https://img.shields.io/badge/Cloud-☁️-blue)](https://cloud.browser-use.com)
[![Documentation](https://img.shields.io/badge/Documentation-📕-blue)](https://docs.browser-use.com)
[![Twitter Follow](https://img.shields.io/twitter/follow/Gregor?style=social)](https://x.com/gregpr07)
[![Twitter Follow](https://img.shields.io/twitter/follow/Magnus?style=social)](https://x.com/mamagnus00)
[![Weave Badge](https://img.shields.io/endpoint?url=https%3A%2F%2Fapp.workweave.ai%2Fapi%2Frepository%2Fbadge%2Forg_T5Pvn3UBswTHIsN1dWS3voPg%2F881458615&amp;labelColor=#EC6341)](https://app.workweave.ai/reports/repository/org_T5Pvn3UBswTHIsN1dWS3voPg/881458615)

🌐 Browser-use is the easiest way to connect your AI agents with the browser.

💡 See what others are building and share your projects in our [Discord](https://link.browser-use.com/discord)! Want Swag? Check out our [Merch store](https://browsermerch.com).

🌤️ Skip the setup - try our &lt;b&gt;hosted version&lt;/b&gt; for instant browser automation! &lt;b&gt;[Try the cloud ☁︎](https://cloud.browser-use.com)&lt;/b&gt;.

# Quick start

With pip (Python&gt;=3.11):

```bash
pip install browser-use
```

For memory functionality (requires Python&lt;3.13 due to PyTorch compatibility):  

```bash
pip install &quot;browser-use[memory]&quot;
```

Install the browser:
```bash
playwright install chromium --with-deps --no-shell
```

Spin up your agent:

```python
import asyncio
from dotenv import load_dotenv
load_dotenv()
from browser_use import Agent
from langchain_openai import ChatOpenAI

async def main():
    agent = Agent(
        task=&quot;Compare the price of gpt-4o and DeepSeek-V3&quot;,
        llm=ChatOpenAI(model=&quot;gpt-4o&quot;),
    )
    await agent.run()

asyncio.run(main())
```

Add your API keys for the provider you want to use to your `.env` file.

```bash
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_KEY=
GOOGLE_API_KEY=
DEEPSEEK_API_KEY=
GROK_API_KEY=
NOVITA_API_KEY=
```

For other settings, models, and more, check out the [documentation 📕](https://docs.browser-use.com).

### Test with UI

You can test browser-use using its [Web UI](https://github.com/browser-use/web-ui) or [Desktop App](https://github.com/browser-use/desktop).

### Test with an interactive CLI

You can also use our `browser-use` interactive CLI (similar to `claude` code):

```bash
pip install browser-use[cli]
browser-use
```

# Demos

&lt;br/&gt;&lt;br/&gt;

[Task](https://github.com/browser-use/browser-use/blob/main/examples/use-cases/shopping.py): Add grocery items to cart, and checkout.

[![AI Did My Groceries](https://github.com/user-attachments/assets/a0ffd23d-9a11-4368-8893-b092703abc14)](https://www.youtube.com/watch?v=L2Ya9PYNns8)

&lt;br/&gt;&lt;br/&gt;

Prompt: Add my latest LinkedIn follower to my leads in Salesforce.

![LinkedIn to Salesforce](https://github.com/user-attachments/assets/50d6e691-b66b-4077-a46c-49e9d4707e07)

&lt;br/&gt;&lt;br/&gt;

[Prompt](https://github.com/browser-use/browser-use/blob/main/examples/use-cases/find_and_apply_to_jobs.py): Read my CV &amp; find ML jobs, save them to a file, and then start applying for them in new tabs, if you need help, ask me.&#039;

https://github.com/user-attachments/assets/171fb4d6-0355-46f2-863e-edb04a828d04

&lt;br/&gt;&lt;br/&gt;

[Prompt](https://github.com/browser-use/browser-use/blob/main/examples/browser/real_browser.py): Write a letter in Google Docs to my Papa, thanking him for everything, and save the document as a PDF.

![Letter to Papa](https://github.com/user-attachments/assets/242ade3e-15bc-41c2-988f-cbc5415a66aa)

&lt;br/&gt;&lt;br/&gt;

[Prompt](https://github.com/browser-use/browser-use/blob/main/examples/custom-functions/save_to_file_hugging_face.py): Look up models with a license of cc-by-sa-4.0 and sort by most likes on Hugging face, save top 5 to file.

https://github.com/user-attachments/assets/de73ee39-432c-4b97-b4e8-939fd7f323b3

&lt;br/&gt;&lt;br/&gt;

## More examples

For more examples see the [examples](examples) folder or join the [Discord](https://link.browser-use.com/discord) and show off your project. You can also see our [`awesome-prompts`](https://github.com/browser-use/awesome-prompts) repo for prompting inspiration.

# Vision

Tell your computer what to do, and it gets it done.

## Roadmap

### Agent

- [ ] Improve agent memory to handle +100 steps
- [ ] Enhance planning capabilities (load website specific context)
- [ ] Reduce token consumption (system prompt, DOM state)

### DOM Extraction

- [ ] Enable detection for all possible UI elements
- [ ] Improve state representation for UI elements so that all LLMs can understand what&#039;s on the page

### Workflows

- [ ] Let user record a workflow - which we can rerun with browser-use as a fallback
- [ ] Make rerunning of workflows work, even if pages change

### User Experience

- [ ] Create various templates for tutorial execution, job application, QA testing, social media, etc. which users can just copy &amp; paste.
- [ ] Improve docs
- [ ] Make it faster

### Parallelization

- [ ] Human work is sequential. The real power of a browser agent comes into reality if we can parallelize similar tasks. For example, if you want to find contact information for 100 companies, this can all be done in parallel and reported back to a main agent, which processes the results and kicks off parallel subtasks again.


## Contributing

We love contributions! Feel free to open issues for bugs or feature requests. To contribute to the docs, check out the `/docs` folder.

## Local Setup

To learn more about the library, check out the [local setup 📕](https://docs.browser-use.com/development/local-setup).


`main` is the primary development branch with frequent changes. For production use, install a stable [versioned release](https://github.com/browser-use/browser-use/releases) instead.

---

## Swag

Want to show off your Browser-use swag? Check out our [Merch store](https://browsermerch.com). Good contributors will receive swag for free 👀.

## Citation

If you use Browser Use in your research or project, please cite:

```bibtex
@software{browser_use2024,
  author = {Müller, Magnus and Žunič, Gregor},
  title = {Browser Use: Enable AI to control your browser},
  year = {2024},
  publisher = {GitHub},
  url = {https://github.com/browser-use/browser-use}
}
```

 &lt;div align=&quot;center&quot;&gt; &lt;img src=&quot;https://github.com/user-attachments/assets/06fa3078-8461-4560-b434-445510c1766f&quot; width=&quot;400&quot;/&gt; 
 
[![Twitter Follow](https://img.shields.io/twitter/follow/Gregor?style=social)](https://x.com/gregpr07)
[![Twitter Follow](https://img.shields.io/twitter/follow/Magnus?style=social)](https://x.com/mamagnus00)
 
 &lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
Made with ❤️ in Zurich and San Francisco
 &lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[donnemartin/system-design-primer]]></title>
            <link>https://github.com/donnemartin/system-design-primer</link>
            <guid>https://github.com/donnemartin/system-design-primer</guid>
            <pubDate>Sat, 17 May 2025 00:04:15 GMT</pubDate>
            <description><![CDATA[Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/donnemartin/system-design-primer">donnemartin/system-design-primer</a></h1>
            <p>Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.</p>
            <p>Language: Python</p>
            <p>Stars: 299,513</p>
            <p>Forks: 49,686</p>
            <p>Stars today: 127 stars today</p>
            <h2>README</h2><pre>*[English](README.md) ∙ [日本語](README-ja.md) ∙ [简体中文](README-zh-Hans.md) ∙ [繁體中文](README-zh-TW.md) | [العَرَبِيَّة‎](https://github.com/donnemartin/system-design-primer/issues/170) ∙ [বাংলা](https://github.com/donnemartin/system-design-primer/issues/220) ∙ [Português do Brasil](https://github.com/donnemartin/system-design-primer/issues/40) ∙ [Deutsch](https://github.com/donnemartin/system-design-primer/issues/186) ∙ [ελληνικά](https://github.com/donnemartin/system-design-primer/issues/130) ∙ [עברית](https://github.com/donnemartin/system-design-primer/issues/272) ∙ [Italiano](https://github.com/donnemartin/system-design-primer/issues/104) ∙ [한국어](https://github.com/donnemartin/system-design-primer/issues/102) ∙ [فارسی](https://github.com/donnemartin/system-design-primer/issues/110) ∙ [Polski](https://github.com/donnemartin/system-design-primer/issues/68) ∙ [русский язык](https://github.com/donnemartin/system-design-primer/issues/87) ∙ [Español](https://github.com/donnemartin/system-design-primer/issues/136) ∙ [ภาษาไทย](https://github.com/donnemartin/system-design-primer/issues/187) ∙ [Türkçe](https://github.com/donnemartin/system-design-primer/issues/39) ∙ [tiếng Việt](https://github.com/donnemartin/system-design-primer/issues/127) ∙ [Français](https://github.com/donnemartin/system-design-primer/issues/250) | [Add Translation](https://github.com/donnemartin/system-design-primer/issues/28)*

**Help [translate](TRANSLATIONS.md) this guide!**

# The System Design Primer

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/jj3A5N8.png&quot;&gt;
  &lt;br/&gt;
&lt;/p&gt;

## Motivation

&gt; Learn how to design large-scale systems.
&gt;
&gt; Prep for the system design interview.

### Learn how to design large-scale systems

Learning how to design scalable systems will help you become a better engineer.

System design is a broad topic.  There is a **vast amount of resources scattered throughout the web** on system design principles.

This repo is an **organized collection** of resources to help you learn how to build systems at scale.

### Learn from the open source community

This is a continually updated, open source project.

[Contributions](#contributing) are welcome!

### Prep for the system design interview

In addition to coding interviews, system design is a **required component** of the **technical interview process** at many tech companies.

**Practice common system design interview questions** and **compare** your results with **sample solutions**: discussions, code, and diagrams.

Additional topics for interview prep:

* [Study guide](#study-guide)
* [How to approach a system design interview question](#how-to-approach-a-system-design-interview-question)
* [System design interview questions, **with solutions**](#system-design-interview-questions-with-solutions)
* [Object-oriented design interview questions, **with solutions**](#object-oriented-design-interview-questions-with-solutions)
* [Additional system design interview questions](#additional-system-design-interview-questions)

## Anki flashcards

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/zdCAkB3.png&quot;&gt;
  &lt;br/&gt;
&lt;/p&gt;

The provided [Anki flashcard decks](https://apps.ankiweb.net/) use spaced repetition to help you retain key system design concepts.

* [System design deck](https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design.apkg)
* [System design exercises deck](https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design%20Exercises.apkg)
* [Object oriented design exercises deck](https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/OO%20Design.apkg)

Great for use while on-the-go.

### Coding Resource: Interactive Coding Challenges

Looking for resources to help you prep for the [**Coding Interview**](https://github.com/donnemartin/interactive-coding-challenges)?

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/b4YtAEN.png&quot;&gt;
  &lt;br/&gt;
&lt;/p&gt;

Check out the sister repo [**Interactive Coding Challenges**](https://github.com/donnemartin/interactive-coding-challenges), which contains an additional Anki deck:

* [Coding deck](https://github.com/donnemartin/interactive-coding-challenges/tree/master/anki_cards/Coding.apkg)

## Contributing

&gt; Learn from the community.

Feel free to submit pull requests to help:

* Fix errors
* Improve sections
* Add new sections
* [Translate](https://github.com/donnemartin/system-design-primer/issues/28)

Content that needs some polishing is placed [under development](#under-development).

Review the [Contributing Guidelines](CONTRIBUTING.md).

## Index of system design topics

&gt; Summaries of various system design topics, including pros and cons.  **Everything is a trade-off**.
&gt;
&gt; Each section contains links to more in-depth resources.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/jrUBAF7.png&quot;&gt;
  &lt;br/&gt;
&lt;/p&gt;

* [System design topics: start here](#system-design-topics-start-here)
    * [Step 1: Review the scalability video lecture](#step-1-review-the-scalability-video-lecture)
    * [Step 2: Review the scalability article](#step-2-review-the-scalability-article)
    * [Next steps](#next-steps)
* [Performance vs scalability](#performance-vs-scalability)
* [Latency vs throughput](#latency-vs-throughput)
* [Availability vs consistency](#availability-vs-consistency)
    * [CAP theorem](#cap-theorem)
        * [CP - consistency and partition tolerance](#cp---consistency-and-partition-tolerance)
        * [AP - availability and partition tolerance](#ap---availability-and-partition-tolerance)
* [Consistency patterns](#consistency-patterns)
    * [Weak consistency](#weak-consistency)
    * [Eventual consistency](#eventual-consistency)
    * [Strong consistency](#strong-consistency)
* [Availability patterns](#availability-patterns)
    * [Fail-over](#fail-over)
    * [Replication](#replication)
    * [Availability in numbers](#availability-in-numbers)
* [Domain name system](#domain-name-system)
* [Content delivery network](#content-delivery-network)
    * [Push CDNs](#push-cdns)
    * [Pull CDNs](#pull-cdns)
* [Load balancer](#load-balancer)
    * [Active-passive](#active-passive)
    * [Active-active](#active-active)
    * [Layer 4 load balancing](#layer-4-load-balancing)
    * [Layer 7 load balancing](#layer-7-load-balancing)
    * [Horizontal scaling](#horizontal-scaling)
* [Reverse proxy (web server)](#reverse-proxy-web-server)
    * [Load balancer vs reverse proxy](#load-balancer-vs-reverse-proxy)
* [Application layer](#application-layer)
    * [Microservices](#microservices)
    * [Service discovery](#service-discovery)
* [Database](#database)
    * [Relational database management system (RDBMS)](#relational-database-management-system-rdbms)
        * [Master-slave replication](#master-slave-replication)
        * [Master-master replication](#master-master-replication)
        * [Federation](#federation)
        * [Sharding](#sharding)
        * [Denormalization](#denormalization)
        * [SQL tuning](#sql-tuning)
    * [NoSQL](#nosql)
        * [Key-value store](#key-value-store)
        * [Document store](#document-store)
        * [Wide column store](#wide-column-store)
        * [Graph Database](#graph-database)
    * [SQL or NoSQL](#sql-or-nosql)
* [Cache](#cache)
    * [Client caching](#client-caching)
    * [CDN caching](#cdn-caching)
    * [Web server caching](#web-server-caching)
    * [Database caching](#database-caching)
    * [Application caching](#application-caching)
    * [Caching at the database query level](#caching-at-the-database-query-level)
    * [Caching at the object level](#caching-at-the-object-level)
    * [When to update the cache](#when-to-update-the-cache)
        * [Cache-aside](#cache-aside)
        * [Write-through](#write-through)
        * [Write-behind (write-back)](#write-behind-write-back)
        * [Refresh-ahead](#refresh-ahead)
* [Asynchronism](#asynchronism)
    * [Message queues](#message-queues)
    * [Task queues](#task-queues)
    * [Back pressure](#back-pressure)
* [Communication](#communication)
    * [Transmission control protocol (TCP)](#transmission-control-protocol-tcp)
    * [User datagram protocol (UDP)](#user-datagram-protocol-udp)
    * [Remote procedure call (RPC)](#remote-procedure-call-rpc)
    * [Representational state transfer (REST)](#representational-state-transfer-rest)
* [Security](#security)
* [Appendix](#appendix)
    * [Powers of two table](#powers-of-two-table)
    * [Latency numbers every programmer should know](#latency-numbers-every-programmer-should-know)
    * [Additional system design interview questions](#additional-system-design-interview-questions)
    * [Real world architectures](#real-world-architectures)
    * [Company architectures](#company-architectures)
    * [Company engineering blogs](#company-engineering-blogs)
* [Under development](#under-development)
* [Credits](#credits)
* [Contact info](#contact-info)
* [License](#license)

## Study guide

&gt; Suggested topics to review based on your interview timeline (short, medium, long).

![Imgur](images/OfVllex.png)

**Q: For interviews, do I need to know everything here?**

**A: No, you don&#039;t need to know everything here to prepare for the interview**.

What you are asked in an interview depends on variables such as:

* How much experience you have
* What your technical background is
* What positions you are interviewing for
* Which companies you are interviewing with
* Luck

More experienced candidates are generally expected to know more about system design.  Architects or team leads might be expected to know more than individual contributors.  Top tech companies are likely to have one or more design interview rounds.

Start broad and go deeper in a few areas.  It helps to know a little about various key system design topics.  Adjust the following guide based on your timeline, experience, what positions you are interviewing for, and which companies you are interviewing with.

* **Short timeline** - Aim for **breadth** with system design topics.  Practice by solving **some** interview questions.
* **Medium timeline** - Aim for **breadth** and **some depth** with system design topics.  Practice by solving **many** interview questions.
* **Long timeline** - Aim for **breadth** and **more depth** with system design topics.  Practice by solving **most** interview questions.

| | Short | Medium | Long |
|---|---|---|---|
| Read through the [System design topics](#index-of-system-design-topics) to get a broad understanding of how systems work | :+1: | :+1: | :+1: |
| Read through a few articles in the [Company engineering blogs](#company-engineering-blogs) for the companies you are interviewing with | :+1: | :+1: | :+1: |
| Read through a few [Real world architectures](#real-world-architectures) | :+1: | :+1: | :+1: |
| Review [How to approach a system design interview question](#how-to-approach-a-system-design-interview-question) | :+1: | :+1: | :+1: |
| Work through [System design interview questions with solutions](#system-design-interview-questions-with-solutions) | Some | Many | Most |
| Work through [Object-oriented design interview questions with solutions](#object-oriented-design-interview-questions-with-solutions) | Some | Many | Most |
| Review [Additional system design interview questions](#additional-system-design-interview-questions) | Some | Many | Most |

## How to approach a system design interview question

&gt; How to tackle a system design interview question.

The system design interview is an **open-ended conversation**.  You are expected to lead it.

You can use the following steps to guide the discussion.  To help solidify this process, work through the [System design interview questions with solutions](#system-design-interview-questions-with-solutions) section using the following steps.

### Step 1: Outline use cases, constraints, and assumptions

Gather requirements and scope the problem.  Ask questions to clarify use cases and constraints.  Discuss assumptions.

* Who is going to use it?
* How are they going to use it?
* How many users are there?
* What does the system do?
* What are the inputs and outputs of the system?
* How much data do we expect to handle?
* How many requests per second do we expect?
* What is the expected read to write ratio?

### Step 2: Create a high level design

Outline a high level design with all important components.

* Sketch the main components and connections
* Justify your ideas

### Step 3: Design core components

Dive into details for each core component.  For example, if you were asked to [design a url shortening service](solutions/system_design/pastebin/README.md), discuss:

* Generating and storing a hash of the full url
    * [MD5](solutions/system_design/pastebin/README.md) and [Base62](solutions/system_design/pastebin/README.md)
    * Hash collisions
    * SQL or NoSQL
    * Database schema
* Translating a hashed url to the full url
    * Database lookup
* API and object-oriented design

### Step 4: Scale the design

Identify and address bottlenecks, given the constraints.  For example, do you need the following to address scalability issues?

* Load balancer
* Horizontal scaling
* Caching
* Database sharding

Discuss potential solutions and trade-offs.  Everything is a trade-off.  Address bottlenecks using [principles of scalable system design](#index-of-system-design-topics).

### Back-of-the-envelope calculations

You might be asked to do some estimates by hand.  Refer to the [Appendix](#appendix) for the following resources:

* [Use back of the envelope calculations](http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html)
* [Powers of two table](#powers-of-two-table)
* [Latency numbers every programmer should know](#latency-numbers-every-programmer-should-know)

### Source(s) and further reading

Check out the following links to get a better idea of what to expect:

* [How to ace a systems design interview](https://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/)
* [The system design interview](http://www.hiredintech.com/system-design)
* [Intro to Architecture and Systems Design Interviews](https://www.youtube.com/watch?v=ZgdS0EUmn70)
* [System design template](https://leetcode.com/discuss/career/229177/My-System-Design-Template)

## System design interview questions with solutions

&gt; Common system design interview questions with sample discussions, code, and diagrams.
&gt;
&gt; Solutions linked to content in the `solutions/` folder.

| Question | |
|---|---|
| Design Pastebin.com (or Bit.ly) | [Solution](solutions/system_design/pastebin/README.md) |
| Design the Twitter timeline and search (or Facebook feed and search) | [Solution](solutions/system_design/twitter/README.md) |
| Design a web crawler | [Solution](solutions/system_design/web_crawler/README.md) |
| Design Mint.com | [Solution](solutions/system_design/mint/README.md) |
| Design the data structures for a social network | [Solution](solutions/system_design/social_graph/README.md) |
| Design a key-value store for a search engine | [Solution](solutions/system_design/query_cache/README.md) |
| Design Amazon&#039;s sales ranking by category feature | [Solution](solutions/system_design/sales_rank/README.md) |
| Design a system that scales to millions of users on AWS | [Solution](solutions/system_design/scaling_aws/README.md) |
| Add a system design question | [Contribute](#contributing) |

### Design Pastebin.com (or Bit.ly)

[View exercise and solution](solutions/system_design/pastebin/README.md)

![Imgur](images/4edXG0T.png)

### Design the Twitter timeline and search (or Facebook feed and search)

[View exercise and solution](solutions/system_design/twitter/README.md)

![Imgur](images/jrUBAF7.png)

### Design a web crawler

[View exercise and solution](solutions/system_design/web_crawler/README.md)

![Imgur](images/bWxPtQA.png)

### Design Mint.com

[View exercise and solution](solutions/system_design/mint/README.md)

![Imgur](images/V5q57vU.png)

### Design the data structures for a social network

[View exercise and solution](solutions/system_design/social_graph/README.md)

![Imgur](images/cdCv5g7.png)

### Design a key-value store for a search engine

[View exercise and solution](solutions/system_design/query_cache/README.md)

![Imgur](images/4j99mhe.png)

### Design Amazon&#039;s sales ranking by category feature

[View exercise and solution](solutions/system_design/sales_rank/README.md)

![Imgur](images/MzExP06.png)

### Design a system that scales to millions of users on AWS

[View exercise and solution](solutions/system_design/scaling_aws/README.md)

![Imgur](images/jj3A5N8.png)

## Object-oriented design interview questions with solutions

&gt; Common object-oriented design interview questions with sample discussions, code, and diagrams.
&gt;
&gt; Solutions linked to content in the `solutions/` folder.

&gt;**Note: This section is under development**

| Question | |
|---|---|
| Design a hash map | [Solution](solutions/object_oriented_design/hash_table/hash_map.ipynb)  |
| Design a least recently used cache | [Solution](solutions/object_oriented_design/lru_cache/lru_cache.ipynb)  |
| Design a call center | [Solution](solutions/object_oriented_design/call_center/call_center.ipynb)  |
| Design a deck of cards | [Solution](solutions/object_oriented_design/deck_of_cards/deck_of_cards.ipynb)  |
| Design a parking lot | [Solution](solutions/object_oriented_design/parking_lot/parking_lot.ipynb)  |
| Design a chat server | [Solution](solutions/object_oriented_design/online_chat/online_chat.ipynb)  |
| Design a circular array | [Contribute](#contributing)  |
| Add an object-oriented design question | [Contribute](#contributing) |

## System design topics: start here

New to system design?

First, you&#039;ll need a basic understanding of common principles, learning about what they are, how they are used, and their pros and cons.

### Step 1: Review the scalability video lecture

[Scalability Lecture at Harvard](https://www.youtube.com/watch?v=-W9F__D3oY4)

* Topics covered:
    * Vertical scaling
    * Horizontal scaling
    * Caching
    * Load balancing
    * Database replication
    * Database partitioning

### Step 2: Review the scalability article

[Scalability](https://web.archive.org/web/20221030091841/http://www.lecloud.net/tagged/scalability/chrono)

* Topics covered:
    * [Clones](https://web.archive.org/web/20220530193911/https://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones)
    * [Databases](https://web.archive.org/web/20220602114024/https://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database)
    * [Caches](https://web.archive.org/web/20230126233752/https://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache)
    * [Asynchronism](https://web.archive.org/web/20220926171507/https://www.lecloud.net/post/9699762917/scalability-for-dummies-part-4-asynchronism)

### Next steps

Next, we&#039;ll look at high-level trade-offs:

* **Performance** vs **scalability**
* **Latency** vs **throughput**
* **Availability** vs **consistency**

Keep in mind that **everything is a trade-off**.

Then we&#039;ll dive into more specific topics such as DNS, CDNs, and load balancers.

## Performance vs scalability

A service is **scalable** if it results in increased **performance** in a manner proportional to resources added. Generally, increasing performance means serving more units of work, but it can also be to handle larger units of work, such as when datasets grow.&lt;sup&gt;&lt;a href=http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html&gt;1&lt;/a&gt;&lt;/sup&gt;

Another way to look at performance vs scalability:

* If you have a **performance** problem, your system is slow for a single user.
* If you have a **scalability** problem, your system is fast for a single user but slow under heavy load.

### Source(s) and further reading

* [A word on scalability](http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html)
* [Scalability, availability, s

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[huggingface/trl]]></title>
            <link>https://github.com/huggingface/trl</link>
            <guid>https://github.com/huggingface/trl</guid>
            <pubDate>Sat, 17 May 2025 00:04:14 GMT</pubDate>
            <description><![CDATA[Train transformer language models with reinforcement learning.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/huggingface/trl">huggingface/trl</a></h1>
            <p>Train transformer language models with reinforcement learning.</p>
            <p>Language: Python</p>
            <p>Stars: 13,765</p>
            <p>Forks: 1,886</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre># TRL - Transformer Reinforcement Learning

&lt;div style=&quot;text-align: center&quot;&gt;
&lt;img src=&quot;https://huggingface.co/datasets/trl-lib/documentation-images/resolve/main/trl_banner_dark.png&quot; alt=&quot;TRL Banner&quot;&gt;
&lt;/div&gt;

&lt;hr&gt; &lt;br&gt;

&lt;h3 align=&quot;center&quot;&gt;
    &lt;p&gt;A comprehensive library to post-train foundation models&lt;/p&gt;
&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/huggingface/trl/blob/main/LICENSE&quot;&gt;&lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/github/license/huggingface/trl.svg?color=blue&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://huggingface.co/docs/trl/index&quot;&gt;&lt;img alt=&quot;Documentation&quot; src=&quot;https://img.shields.io/website?label=documentation&amp;url=https%3A%2F%2Fhuggingface.co%2Fdocs%2Ftrl%2Findex&amp;down_color=red&amp;down_message=offline&amp;up_color=blue&amp;up_message=online&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/huggingface/trl/releases&quot;&gt;&lt;img alt=&quot;GitHub release&quot; src=&quot;https://img.shields.io/github/release/huggingface/trl.svg&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://huggingface.co/trl-lib&quot;&gt;&lt;img alt=&quot;Hugging Face Hub&quot; src=&quot;https://img.shields.io/badge/🤗%20Hub-trl--lib-yellow&quot;&gt;&lt;/a&gt; 
&lt;/p&gt;

## Overview

TRL is a cutting-edge library designed for post-training foundation models using advanced techniques like Supervised Fine-Tuning (SFT), Proximal Policy Optimization (PPO), and Direct Preference Optimization (DPO). Built on top of the [🤗 Transformers](https://github.com/huggingface/transformers) ecosystem, TRL supports a variety of model architectures and modalities, and can be scaled-up across various hardware setups.

## Highlights

- **Trainers**: Various fine-tuning methods are easily accessible via trainers like [`SFTTrainer`](https://huggingface.co/docs/trl/sft_trainer), [`GRPOTrainer`](https://huggingface.co/docs/trl/grpo_trainer), [`DPOTrainer`](https://huggingface.co/docs/trl/dpo_trainer), [`RewardTrainer`](https://huggingface.co/docs/trl/reward_trainer) and more.

- **Efficient and scalable**: 
    - Leverages [🤗 Accelerate](https://github.com/huggingface/accelerate) to scale from single GPU to multi-node clusters using methods like [DDP](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html) and [DeepSpeed](https://github.com/deepspeedai/DeepSpeed).
    - Full integration with [🤗 PEFT](https://github.com/huggingface/peft) enables training on large models with modest hardware via quantization and LoRA/QLoRA.
    - Integrates [🦥 Unsloth](https://github.com/unslothai/unsloth) for accelerating training using optimized kernels.

- **Command Line Interface (CLI)**: A simple interface lets you fine-tune with models without needing to write code.

## Installation

### Python Package

Install the library using `pip`:

```bash
pip install trl
```

### From source

If you want to use the latest features before an official release, you can install TRL from source:

```bash
pip install git+https://github.com/huggingface/trl.git
```

### Repository

If you want to use the examples you can clone the repository with the following command:

```bash
git clone https://github.com/huggingface/trl.git
```

## Quick Start


For more flexibility and control over training, TRL provides dedicated trainer classes to post-train language models or PEFT adapters on a custom dataset. Each trainer in TRL is a light wrapper around the 🤗 Transformers trainer and natively supports distributed training methods like DDP, DeepSpeed ZeRO, and FSDP.

### `SFTTrainer`

Here is a basic example of how to use the [`SFTTrainer`](https://huggingface.co/docs/trl/sft_trainer):

```python
from trl import SFTTrainer
from datasets import load_dataset

dataset = load_dataset(&quot;trl-lib/Capybara&quot;, split=&quot;train&quot;)

trainer = SFTTrainer(
    model=&quot;Qwen/Qwen2.5-0.5B&quot;,
    train_dataset=dataset,
)
trainer.train()
```

### `GRPOTrainer`

[`GRPOTrainer`](https://huggingface.co/docs/trl/grpo_trainer) implements the [Group Relative Policy Optimization (GRPO) algorithm](https://huggingface.co/papers/2402.03300) that is more memory-efficient than PPO and was used to train [Deepseek AI&#039;s R1](https://huggingface.co/deepseek-ai/DeepSeek-R1).

```python
from datasets import load_dataset
from trl import GRPOTrainer

dataset = load_dataset(&quot;trl-lib/tldr&quot;, split=&quot;train&quot;)

# Dummy reward function: count the number of unique characters in the completions
def reward_num_unique_chars(completions, **kwargs):
    return [len(set(c)) for c in completions]

trainer = GRPOTrainer(
    model=&quot;Qwen/Qwen2-0.5B-Instruct&quot;,
    reward_funcs=reward_num_unique_chars,
    train_dataset=dataset,
)
trainer.train()
```

### `DPOTrainer`

[`DPOTrainer`](https://huggingface.co/docs/trl/dpo_trainer) implements the popular [Direct Preference Optimization (DPO) algorithm](https://huggingface.co/papers/2305.18290) that was used to post-train [Llama 3](https://huggingface.co/papers/2407.21783) and many other models. Here is a basic example of how to use the `DPOTrainer`:

```python
from datasets import load_dataset
from transformers import AutoModelForCausalLM, AutoTokenizer
from trl import DPOConfig, DPOTrainer

model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen2.5-0.5B-Instruct&quot;)
tokenizer = AutoTokenizer.from_pretrained(&quot;Qwen/Qwen2.5-0.5B-Instruct&quot;)
dataset = load_dataset(&quot;trl-lib/ultrafeedback_binarized&quot;, split=&quot;train&quot;)
training_args = DPOConfig(output_dir=&quot;Qwen2.5-0.5B-DPO&quot;)
trainer = DPOTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset,
    processing_class=tokenizer
)
trainer.train()
```

### `RewardTrainer`

Here is a basic example of how to use the [`RewardTrainer`](https://huggingface.co/docs/trl/reward_trainer):

```python
from trl import RewardConfig, RewardTrainer
from datasets import load_dataset
from transformers import AutoModelForSequenceClassification, AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(&quot;Qwen/Qwen2.5-0.5B-Instruct&quot;)
model = AutoModelForSequenceClassification.from_pretrained(
    &quot;Qwen/Qwen2.5-0.5B-Instruct&quot;, num_labels=1
)
model.config.pad_token_id = tokenizer.pad_token_id

dataset = load_dataset(&quot;trl-lib/ultrafeedback_binarized&quot;, split=&quot;train&quot;)

training_args = RewardConfig(output_dir=&quot;Qwen2.5-0.5B-Reward&quot;, per_device_train_batch_size=2)
trainer = RewardTrainer(
    args=training_args,
    model=model,
    processing_class=tokenizer,
    train_dataset=dataset,
)
trainer.train()
```

## Command Line Interface (CLI)

You can use the TRL Command Line Interface (CLI) to quickly get started with post-training methods like Supervised Fine-Tuning (SFT) or Direct Preference Optimization (DPO):

**SFT:**

```bash
trl sft --model_name_or_path Qwen/Qwen2.5-0.5B \
    --dataset_name trl-lib/Capybara \
    --output_dir Qwen2.5-0.5B-SFT
```

**DPO:**

```bash
trl dpo --model_name_or_path Qwen/Qwen2.5-0.5B-Instruct \
    --dataset_name argilla/Capybara-Preferences \
    --output_dir Qwen2.5-0.5B-DPO 
```

Read more about CLI in the [relevant documentation section](https://huggingface.co/docs/trl/main/en/clis) or use `--help` for more details.

## Development

If you want to contribute to `trl` or customize it to your needs make sure to read the [contribution guide](https://github.com/huggingface/trl/blob/main/CONTRIBUTING.md) and make sure you make a dev install:

```bash
git clone https://github.com/huggingface/trl.git
cd trl/
pip install -e .[dev]
```

## Citation

```bibtex
@misc{vonwerra2022trl,
  author = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
  title = {TRL: Transformer Reinforcement Learning},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/huggingface/trl}}
}
```

## License

This repository&#039;s source code is available under the [Apache-2.0 License](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[airweave-ai/airweave]]></title>
            <link>https://github.com/airweave-ai/airweave</link>
            <guid>https://github.com/airweave-ai/airweave</guid>
            <pubDate>Sat, 17 May 2025 00:04:13 GMT</pubDate>
            <description><![CDATA[Airweave lets agents search any app]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/airweave-ai/airweave">airweave-ai/airweave</a></h1>
            <p>Airweave lets agents search any app</p>
            <p>Language: Python</p>
            <p>Stars: 2,066</p>
            <p>Forks: 205</p>
            <p>Stars today: 201 stars today</p>
            <h2>README</h2><pre>&lt;img width=&quot;1673&quot; alt=&quot;airweave-lettermark&quot; style=&quot;padding-bottom: 12px;&quot; src=&quot;https://github.com/user-attachments/assets/e79a9af7-2e93-4888-9cf4-0f700f19fe05&quot;/&gt;


&lt;div align=&quot;center&quot;&gt;

[![Ruff](https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml/badge.svg)](https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml)
[![ESLint](https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml/badge.svg)](https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml)
[![Backend Tests](https://github.com/airweave-ai/airweave/actions/workflows/tests.yml/badge.svg?branch=main)](https://github.com/airweave-ai/airweave/actions/workflows/tests.yml)
[![Codecov](https://codecov.io/gh/airweave-ai/airweave/branch/main/graph/badge.svg)](https://codecov.io/gh/airweave-ai/airweave)
[![Discord](https://img.shields.io/discord/1323415085011701870?label=Discord&amp;logo=discord&amp;logoColor=white&amp;style=flat-square)](https://discord.com/invite/484HY9Ehxt)
&lt;br&gt;
&lt;a href=&quot;https://trendshift.io/repositories/13748&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13748&quot; alt=&quot;airweave-ai%2Fairweave | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

# Airweave

**Airweave is a tool that lets agents semantically search any app.** It&#039;s MCP compatible and seamlessly connects any app, database, or API, to transform their contents into agent-ready knowledge.

&lt;div align=&quot;center&quot;&gt;
  
### 🎥 Watch Demo

https://github.com/user-attachments/assets/abdf85cb-a8f5-4b6c-b5a3-d4b5177e6bda

&lt;/div&gt;

## Overview

Airweave simplifies the process of making information retrievable for your agent. Whether you have structured or unstructured data, Airweave helps you break it into processable entities, store the data and make it retrievable through REST and MCP endpoints.

## Table of Contents

- [Airweave](#airweave)
    - [🎥 Watch Demo](#-watch-demo)
  - [Overview](#overview)
  - [Table of Contents](#table-of-contents)
  - [🚀 Quick Start](#-quick-start)
  - [🔌 Supported Integrations](#-supported-integrations)
  - [💻 Usage](#-usage)
    - [Frontend](#frontend)
    - [API](#api)
  - [📦 SDKs](#-sdks)
    - [Python](#python)
    - [TypeScript/JavaScript](#typescriptjavascript)
  - [🔑 Key Features](#-key-features)
  - [🔧 Technology Stack](#-technology-stack)
  - [🛣️ Roadmap](#️-roadmap)
  - [👥 Contributing](#-contributing)
  - [📄 License](#-license)
  - [🔗 Connect](#-connect)

## 🚀 Quick Start

Make sure docker and docker-compose are installed, then...

```bash
# 1. Clone the repository
git clone https://github.com/airweave-ai/airweave.git
cd airweave

# 2. Build and run
chmod +x start.sh
./start.sh
```

That&#039;s it! Access the dashboard at http://localhost:8080

## 🔌 Supported Integrations

&lt;!-- START_APP_GRID --&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;div style=&quot;display: inline-block; text-align: center; padding: 4px;&quot;&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/asana.svg&quot; alt=&quot;Asana&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/calendly.svg&quot; alt=&quot;Calendly&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/chat-gpt.svg&quot; alt=&quot;Chat-gpt&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/clickup.svg&quot; alt=&quot;Clickup&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/confluence.svg&quot; alt=&quot;Confluence&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/dropbox.svg&quot; alt=&quot;Dropbox&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/elasticsearch.svg&quot; alt=&quot;Elasticsearch&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/facebook.svg&quot; alt=&quot;Facebook&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/github.svg&quot; alt=&quot;Github&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/gmail.svg&quot; alt=&quot;Gmail&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/google_calendar.svg&quot; alt=&quot;Google Calendar&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/google_drive.svg&quot; alt=&quot;Google Drive&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/hubspot.svg&quot; alt=&quot;Hubspot&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/intercom.svg&quot; alt=&quot;Intercom&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/jira.svg&quot; alt=&quot;Jira&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/linear.svg&quot; alt=&quot;Linear&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/linkedin.svg&quot; alt=&quot;Linkedin&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/mailchimp.svg&quot; alt=&quot;Mailchimp&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/monday.svg&quot; alt=&quot;Monday&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/mysql.svg&quot; alt=&quot;Mysql&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/notion.svg&quot; alt=&quot;Notion&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/onedrive.svg&quot; alt=&quot;Onedrive&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/oracle.svg&quot; alt=&quot;Oracle&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/outlook_calendar.svg&quot; alt=&quot;Outlook Calendar&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/outlook_mail.svg&quot; alt=&quot;Outlook Mail&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/perplexity.svg&quot; alt=&quot;Perplexity&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/postgresql.svg&quot; alt=&quot;Postgresql&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/salesforce.svg&quot; alt=&quot;Salesforce&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/slack.svg&quot; alt=&quot;Slack&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/sql_server.svg&quot; alt=&quot;Sql Server&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/sqlite.svg&quot; alt=&quot;Sqlite&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/stripe.svg&quot; alt=&quot;Stripe&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
    &lt;span style=&quot;width: 40px; display: inline-block; margin: 4px;&quot;&gt;&lt;/span&gt;&lt;span style=&quot;width: 40px; display: inline-block; margin: 4px;&quot;&gt;&lt;/span&gt;&lt;img src=&quot;frontend/src/components/icons/apps/todoist.svg&quot; alt=&quot;Todoist&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/trello.svg&quot; alt=&quot;Trello&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/whatsapp.svg&quot; alt=&quot;Whatsapp&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/zendesk.svg&quot; alt=&quot;Zendesk&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
  &lt;/div&gt;
&lt;/p&gt;

&lt;!-- END_APP_GRID --&gt;

## 💻 Usage

### Frontend
- Access the UI at `http://localhost:8080`
- Connect sources, configure syncs, and query data

### API
- Swagger docs: `http://localhost:8001/docs`
- Create connections, trigger syncs, and search data

## 📦 SDKs

### Python

```bash
pip install airweave-sdk
```

```python
from airweave import AirweaveClient

client = AirweaveClient(api_key=&quot;your-api-key&quot;)

# List all sources
sources = client.sources.list()

# Create a sync job
job = client.sync.create_sync(
  name=&quot;My first sync&quot;,
  source_connection_id=source_id,
  run_immediately=True
)
```

### TypeScript/JavaScript

```bash
npm install @airweave/sdk
# or
yarn add @airweave/sdk
```

```typescript
import { AirweaveClient } from &quot;@airweave/sdk&quot;;

const client = new AirweaveClient({
  apiKey: &quot;your-api-key&quot;,
});

// List sources
const sources = await client.sources.list();

// Create a sync job
const job = await client.sync.create_sync({
  name: &quot;My first sync&quot;,
  source_connection_id: sourceId,
  run_immediately: true,
});
```

## 🔑 Key Features

- **Data synchronization** from 25+ sources with minimal config
- **Entity extraction** and transformation pipeline
- **Multi-tenant** architecture with OAuth2
- **Incremental updates** using content hashing
- **Semantic search** for agent queries
- **Versioning** for data changes
- **White-labeling** support for SaaS builders

## 🔧 Technology Stack

- **Frontend**: React/TypeScript with ShadCN
- **Backend**: FastAPI (Python)
- **Databases**: PostgreSQL (metadata), Qdrant (vectors)
- **Deployment**: Docker Compose (dev), Kubernetes (prod)

## 🛣️ Roadmap

- Additional source integrations
- Redis worker queues for large-scale syncs
- Webhooks for event-driven syncs
- Kubernetes support via Helm charts

## 👥 Contributing

We welcome contributions! Please check [CONTRIBUTING.md](https://github.com/airweave-ai/airweave/blob/main/CONTRIBUTING.md) for details.

## 📄 License

Airweave is released under the [MIT](LICENSE) license.

## 🔗 Connect

- **[Discord](https://discord.com/invite/484HY9Ehxt)** - Get help and discuss features
- **[GitHub Issues](https://github.com/airweave-ai/airweave/issues)** - Report bugs or request features
- **[Twitter](https://x.com/airweave_ai)** - Follow for updates
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[reflex-dev/reflex]]></title>
            <link>https://github.com/reflex-dev/reflex</link>
            <guid>https://github.com/reflex-dev/reflex</guid>
            <pubDate>Sat, 17 May 2025 00:04:12 GMT</pubDate>
            <description><![CDATA[🕸️ Web apps in pure Python 🐍]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/reflex-dev/reflex">reflex-dev/reflex</a></h1>
            <p>🕸️ Web apps in pure Python 🐍</p>
            <p>Language: Python</p>
            <p>Stars: 22,773</p>
            <p>Forks: 1,341</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/reflex_dark.svg#gh-light-mode-only&quot; alt=&quot;Reflex Logo&quot; width=&quot;300px&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/reflex_light.svg#gh-dark-mode-only&quot; alt=&quot;Reflex Logo&quot; width=&quot;300px&quot;&gt;

&lt;hr&gt;

### **✨ Performant, customizable web apps in pure Python. Deploy in seconds. ✨**

[![PyPI version](https://badge.fury.io/py/reflex.svg)](https://badge.fury.io/py/reflex)
![versions](https://img.shields.io/pypi/pyversions/reflex.svg)
[![Documentation](https://img.shields.io/badge/Documentation%20-Introduction%20-%20%23007ec6)](https://reflex.dev/docs/getting-started/introduction)
[![PyPI Downloads](https://static.pepy.tech/badge/reflex)](https://pepy.tech/projects/reflex)
[![Discord](https://img.shields.io/discord/1029853095527727165?color=%237289da&amp;label=Discord)](https://discord.gg/T5WSbC2YtQ)

&lt;/div&gt;

---

[English](https://github.com/reflex-dev/reflex/blob/main/README.md) | [简体中文](https://github.com/reflex-dev/reflex/blob/main/docs/zh/zh_cn/README.md) | [繁體中文](https://github.com/reflex-dev/reflex/blob/main/docs/zh/zh_tw/README.md) | [Türkçe](https://github.com/reflex-dev/reflex/blob/main/docs/tr/README.md) | [हिंदी](https://github.com/reflex-dev/reflex/blob/main/docs/in/README.md) | [Português (Brasil)](https://github.com/reflex-dev/reflex/blob/main/docs/pt/pt_br/README.md) | [Italiano](https://github.com/reflex-dev/reflex/blob/main/docs/it/README.md) | [Español](https://github.com/reflex-dev/reflex/blob/main/docs/es/README.md) | [한국어](https://github.com/reflex-dev/reflex/blob/main/docs/kr/README.md) | [日本語](https://github.com/reflex-dev/reflex/blob/main/docs/ja/README.md) | [Deutsch](https://github.com/reflex-dev/reflex/blob/main/docs/de/README.md) | [Persian (پارسی)](https://github.com/reflex-dev/reflex/blob/main/docs/pe/README.md) | [Tiếng Việt](https://github.com/reflex-dev/reflex/blob/main/docs/vi/README.md)

---

# Reflex

Reflex is a library to build full-stack web apps in pure Python.

Key features:

- **Pure Python** - Write your app&#039;s frontend and backend all in Python, no need to learn Javascript.
- **Full Flexibility** - Reflex is easy to get started with, but can also scale to complex apps.
- **Deploy Instantly** - After building, deploy your app with a [single command](https://reflex.dev/docs/hosting/deploy-quick-start/) or host it on your own server.

See our [architecture page](https://reflex.dev/blog/2024-03-21-reflex-architecture/#the-reflex-architecture) to learn how Reflex works under the hood.

## ⚙️ Installation

Open a terminal and run (Requires Python 3.10+):

```bash
pip install reflex
```

## 🥳 Create your first app

Installing `reflex` also installs the `reflex` command line tool.

Test that the install was successful by creating a new project. (Replace `my_app_name` with your project name):

```bash
mkdir my_app_name
cd my_app_name
reflex init
```

This command initializes a template app in your new directory.

You can run this app in development mode:

```bash
reflex run
```

You should see your app running at http://localhost:3000.

Now you can modify the source code in `my_app_name/my_app_name.py`. Reflex has fast refreshes so you can see your changes instantly when you save your code.

## 🫧 Example App

Let&#039;s go over an example: creating an image generation UI around [DALL·E](https://platform.openai.com/docs/guides/images/image-generation?context=node). For simplicity, we just call the [OpenAI API](https://platform.openai.com/docs/api-reference/authentication), but you could replace this with an ML model run locally.

&amp;nbsp;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/dalle.gif&quot; alt=&quot;A frontend wrapper for DALL·E, shown in the process of generating an image.&quot; width=&quot;550&quot; /&gt;
&lt;/div&gt;

&amp;nbsp;

Here is the complete code to create this. This is all done in one Python file!

```python
import reflex as rx
import openai

openai_client = openai.OpenAI()


class State(rx.State):
    &quot;&quot;&quot;The app state.&quot;&quot;&quot;

    prompt = &quot;&quot;
    image_url = &quot;&quot;
    processing = False
    complete = False

    def get_image(self):
        &quot;&quot;&quot;Get the image from the prompt.&quot;&quot;&quot;
        if self.prompt == &quot;&quot;:
            return rx.window_alert(&quot;Prompt Empty&quot;)

        self.processing, self.complete = True, False
        yield
        response = openai_client.images.generate(
            prompt=self.prompt, n=1, size=&quot;1024x1024&quot;
        )
        self.image_url = response.data[0].url
        self.processing, self.complete = False, True


def index():
    return rx.center(
        rx.vstack(
            rx.heading(&quot;DALL-E&quot;, font_size=&quot;1.5em&quot;),
            rx.input(
                placeholder=&quot;Enter a prompt..&quot;,
                on_blur=State.set_prompt,
                width=&quot;25em&quot;,
            ),
            rx.button(
                &quot;Generate Image&quot;,
                on_click=State.get_image,
                width=&quot;25em&quot;,
                loading=State.processing
            ),
            rx.cond(
                State.complete,
                rx.image(src=State.image_url, width=&quot;20em&quot;),
            ),
            align=&quot;center&quot;,
        ),
        width=&quot;100%&quot;,
        height=&quot;100vh&quot;,
    )

# Add state and page to the app.
app = rx.App()
app.add_page(index, title=&quot;Reflex:DALL-E&quot;)
```

## Let&#039;s break this down.

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/dalle_colored_code_example.png&quot; alt=&quot;Explaining the differences between backend and frontend parts of the DALL-E app.&quot; width=&quot;900&quot; /&gt;
&lt;/div&gt;

### **Reflex UI**

Let&#039;s start with the UI.

```python
def index():
    return rx.center(
        ...
    )
```

This `index` function defines the frontend of the app.

We use different components such as `center`, `vstack`, `input`, and `button` to build the frontend. Components can be nested within each other
to create complex layouts. And you can use keyword args to style them with the full power of CSS.

Reflex comes with [60+ built-in components](https://reflex.dev/docs/library) to help you get started. We are actively adding more components, and it&#039;s easy to [create your own components](https://reflex.dev/docs/wrapping-react/overview/).

### **State**

Reflex represents your UI as a function of your state.

```python
class State(rx.State):
    &quot;&quot;&quot;The app state.&quot;&quot;&quot;
    prompt = &quot;&quot;
    image_url = &quot;&quot;
    processing = False
    complete = False

```

The state defines all the variables (called vars) in an app that can change and the functions that change them.

Here the state is comprised of a `prompt` and `image_url`. There are also the booleans `processing` and `complete` to indicate when to disable the button (during image generation) and when to show the resulting image.

### **Event Handlers**

```python
def get_image(self):
    &quot;&quot;&quot;Get the image from the prompt.&quot;&quot;&quot;
    if self.prompt == &quot;&quot;:
        return rx.window_alert(&quot;Prompt Empty&quot;)

    self.processing, self.complete = True, False
    yield
    response = openai_client.images.generate(
        prompt=self.prompt, n=1, size=&quot;1024x1024&quot;
    )
    self.image_url = response.data[0].url
    self.processing, self.complete = False, True
```

Within the state, we define functions called event handlers that change the state vars. Event handlers are the way that we can modify the state in Reflex. They can be called in response to user actions, such as clicking a button or typing in a text box. These actions are called events.

Our DALL·E. app has an event handler, `get_image` to which get this image from the OpenAI API. Using `yield` in the middle of an event handler will cause the UI to update. Otherwise the UI will update at the end of the event handler.

### **Routing**

Finally, we define our app.

```python
app = rx.App()
```

We add a page from the root of the app to the index component. We also add a title that will show up in the page preview/browser tab.

```python
app.add_page(index, title=&quot;DALL-E&quot;)
```

You can create a multi-page app by adding more pages.

## 📑 Resources

&lt;div align=&quot;center&quot;&gt;

📑 [Docs](https://reflex.dev/docs/getting-started/introduction) &amp;nbsp; | &amp;nbsp; 🗞️ [Blog](https://reflex.dev/blog) &amp;nbsp; | &amp;nbsp; 📱 [Component Library](https://reflex.dev/docs/library) &amp;nbsp; | &amp;nbsp; 🖼️ [Templates](https://reflex.dev/templates/) &amp;nbsp; | &amp;nbsp; 🛸 [Deployment](https://reflex.dev/docs/hosting/deploy-quick-start) &amp;nbsp;

&lt;/div&gt;

## ✅ Status

Reflex launched in December 2022 with the name Pynecone.

Beginning in 2025, [Reflex Cloud](https://cloud.reflex.dev) has launched to provide the best hosting experience for Reflex apps. We will continue to develop it and implement more features.

Reflex has new releases and features coming every week! Make sure to :star: star and :eyes: watch this repository to stay up to date.

## Contributing

We welcome contributions of any size! Below are some good ways to get started in the Reflex community.

- **Join Our Discord**: Our [Discord](https://discord.gg/T5WSbC2YtQ) is the best place to get help on your Reflex project and to discuss how you can contribute.
- **GitHub Discussions**: A great way to talk about features you want added or things that are confusing/need clarification.
- **GitHub Issues**: [Issues](https://github.com/reflex-dev/reflex/issues) are an excellent way to report bugs. Additionally, you can try and solve an existing issue and submit a PR.

We are actively looking for contributors, no matter your skill level or experience. To contribute check out [CONTRIBUTING.md](https://github.com/reflex-dev/reflex/blob/main/CONTRIBUTING.md)

## All Thanks To Our Contributors:

&lt;a href=&quot;https://github.com/reflex-dev/reflex/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=reflex-dev/reflex&quot; /&gt;
&lt;/a&gt;

## License

Reflex is open-source and licensed under the [Apache License 2.0](https://raw.githubusercontent.com/reflex-dev/reflex/main/LICENSE).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>