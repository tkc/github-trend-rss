<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Thu, 31 Jul 2025 00:04:37 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[9001/copyparty]]></title>
            <link>https://github.com/9001/copyparty</link>
            <guid>https://github.com/9001/copyparty</guid>
            <pubDate>Thu, 31 Jul 2025 00:04:37 GMT</pubDate>
            <description><![CDATA[Portable file server with accelerated resumable uploads, dedup, WebDAV, FTP, TFTP, zeroconf, media indexer, thumbnails++ all in one file, no deps]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/9001/copyparty">9001/copyparty</a></h1>
            <p>Portable file server with accelerated resumable uploads, dedup, WebDAV, FTP, TFTP, zeroconf, media indexer, thumbnails++ all in one file, no deps</p>
            <p>Language: Python</p>
            <p>Stars: 13,946</p>
            <p>Forks: 433</p>
            <p>Stars today: 3,579 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://github.com/9001/copyparty/raw/hovudstraum/docs/logo.svg&quot; width=&quot;250&quot; align=&quot;right&quot;/&gt;

### 💾🎉 copyparty

turn almost any device into a file server with resumable uploads/downloads using [*any*](#browser-support) web browser

* server only needs Python (2 or 3), all dependencies optional
* 🔌 protocols: [http](#the-browser) // [webdav](#webdav-server) // [ftp](#ftp-server) // [tftp](#tftp-server) // [smb/cifs](#smb-server)
* 📱 [android app](#android-app) // [iPhone shortcuts](#ios-shortcuts)

👉 **[Get started](#quickstart)!** or visit the **[read-only demo server](https://a.ocv.me/pub/demo/)** 👀 running on a nuc in my basement

📷 **screenshots:** [browser](#the-browser) // [upload](#uploading) // [unpost](#unpost) // [thumbnails](#thumbnails) // [search](#searching) // [fsearch](#file-search) // [zip-DL](#zip-downloads) // [md-viewer](#markdown-viewer)

🎬 **videos:** [upload](https://a.ocv.me/pub/demo/pics-vids/up2k.webm) // [cli-upload](https://a.ocv.me/pub/demo/pics-vids/u2cli.webm) // [race-the-beam](https://a.ocv.me/pub/g/nerd-stuff/cpp/2024-0418-race-the-beam.webm) // 👉 **[feature-showcase](https://a.ocv.me/pub/demo/showcase-hq.webm)** ([youtube](https://www.youtube.com/watch?v=15_-hgsX2V0))

made in Norway 🇳🇴


## readme toc

* top
    * [quickstart](#quickstart) - just run **[copyparty-sfx.py](https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py)** -- that&#039;s it! 🎉
        * [at home](#at-home) - make it accessible over the internet
        * [on servers](#on-servers) - you may also want these, especially on servers
    * [features](#features) - also see [comparison to similar software](./docs/versus.md)
    * [testimonials](#testimonials) - small collection of user feedback
* [motivations](#motivations) - project goals / philosophy
    * [notes](#notes) - general notes
* [bugs](#bugs) - roughly sorted by chance of encounter
    * [not my bugs](#not-my-bugs) - same order here too
* [breaking changes](#breaking-changes) - upgrade notes
* [FAQ](#FAQ) - &quot;frequently&quot; asked questions
* [accounts and volumes](#accounts-and-volumes) - per-folder, per-user permissions
    * [shadowing](#shadowing) - hiding specific subfolders
    * [dotfiles](#dotfiles) - unix-style hidden files/folders
* [the browser](#the-browser) - accessing a copyparty server using a web-browser
    * [tabs](#tabs) - the main tabs in the ui
    * [hotkeys](#hotkeys) - the browser has the following hotkeys
    * [navpane](#navpane) - switching between breadcrumbs or navpane
    * [thumbnails](#thumbnails) - press `g` or `田` to toggle grid-view instead of the file listing
    * [zip downloads](#zip-downloads) - download folders (or file selections) as `zip` or `tar` files
    * [uploading](#uploading) - drag files/folders into the web-browser to upload
        * [file-search](#file-search) - dropping files into the browser also lets you see if they exist on the server
        * [unpost](#unpost) - undo/delete accidental uploads
        * [self-destruct](#self-destruct) - uploads can be given a lifetime
        * [race the beam](#race-the-beam) - download files while they&#039;re still uploading ([demo video](http://a.ocv.me/pub/g/nerd-stuff/cpp/2024-0418-race-the-beam.webm))
        * [incoming files](#incoming-files) - the control-panel shows the ETA for all incoming files
    * [file manager](#file-manager) - cut/paste, rename, and delete files/folders (if you have permission)
    * [shares](#shares) - share a file or folder by creating a temporary link
    * [batch rename](#batch-rename) - select some files and press `F2` to bring up the rename UI
    * [rss feeds](#rss-feeds) - monitor a folder with your RSS reader
    * [recent uploads](#recent-uploads) - list all recent uploads
    * [media player](#media-player) - plays almost every audio format there is
        * [playlists](#playlists) - create and play [m3u8](https://en.wikipedia.org/wiki/M3U) playlists
        * [creating a playlist](#creating-a-playlist) - with a standalone mediaplayer or copyparty
        * [audio equalizer](#audio-equalizer) - and [dynamic range compressor](https://en.wikipedia.org/wiki/Dynamic_range_compression)
        * [fix unreliable playback on android](#fix-unreliable-playback-on-android) - due to phone / app settings
    * [textfile viewer](#textfile-viewer) - with realtime streaming of logfiles and such ([demo](https://a.ocv.me/pub/demo/logtail/))
    * [markdown viewer](#markdown-viewer) - and there are *two* editors
        * [markdown vars](#markdown-vars) - dynamic docs with serverside variable expansion
    * [other tricks](#other-tricks)
    * [searching](#searching) - search by size, date, path/name, mp3-tags, ...
* [server config](#server-config) - using arguments or config files, or a mix of both
    * [zeroconf](#zeroconf) - announce enabled services on the LAN ([pic](https://user-images.githubusercontent.com/241032/215344737-0eae8d98-9496-4256-9aa8-cd2f6971810d.png))
        * [mdns](#mdns) - LAN domain-name and feature announcer
        * [ssdp](#ssdp) - windows-explorer announcer
    * [qr-code](#qr-code) - print a qr-code [(screenshot)](https://user-images.githubusercontent.com/241032/194728533-6f00849b-c6ac-43c6-9359-83e454d11e00.png) for quick access
    * [ftp server](#ftp-server) - an FTP server can be started using `--ftp 3921`
    * [webdav server](#webdav-server) - with read-write support
        * [connecting to webdav from windows](#connecting-to-webdav-from-windows) - using the GUI
    * [tftp server](#tftp-server) - a TFTP server (read/write) can be started using `--tftp 3969`
    * [smb server](#smb-server) - unsafe, slow, not recommended for wan
    * [browser ux](#browser-ux) - tweaking the ui
    * [opengraph](#opengraph) - discord and social-media embeds
    * [file deduplication](#file-deduplication) - enable symlink-based upload deduplication
    * [file indexing](#file-indexing) - enable music search, upload-undo, and better dedup
        * [exclude-patterns](#exclude-patterns) - to save some time
        * [filesystem guards](#filesystem-guards) - avoid traversing into other filesystems
        * [periodic rescan](#periodic-rescan) - filesystem monitoring
    * [upload rules](#upload-rules) - set upload rules using volflags
    * [compress uploads](#compress-uploads) - files can be autocompressed on upload
    * [chmod and chown](#chmod-and-chown) - per-volume filesystem-permissions and ownership
    * [other flags](#other-flags)
    * [database location](#database-location) - in-volume (`.hist/up2k.db`, default) or somewhere else
    * [metadata from audio files](#metadata-from-audio-files) - set `-e2t` to index tags on upload
    * [file parser plugins](#file-parser-plugins) - provide custom parsers to index additional tags
    * [event hooks](#event-hooks) - trigger a program on uploads, renames etc ([examples](./bin/hooks/))
        * [zeromq](#zeromq) - event-hooks can send zeromq messages
        * [upload events](#upload-events) - the older, more powerful approach ([examples](./bin/mtag/))
    * [handlers](#handlers) - redefine behavior with plugins ([examples](./bin/handlers/))
    * [ip auth](#ip-auth) - autologin based on IP range (CIDR)
    * [identity providers](#identity-providers) - replace copyparty passwords with oauth and such
    * [user-changeable passwords](#user-changeable-passwords) - if permitted, users can change their own passwords
    * [using the cloud as storage](#using-the-cloud-as-storage) - connecting to an aws s3 bucket and similar
    * [hiding from google](#hiding-from-google) - tell search engines you don&#039;t wanna be indexed
    * [themes](#themes)
    * [complete examples](#complete-examples)
    * [listen on port 80 and 443](#listen-on-port-80-and-443) - become a *real* webserver
    * [reverse-proxy](#reverse-proxy) - running copyparty next to other websites
        * [real-ip](#real-ip) - teaching copyparty how to see client IPs
        * [reverse-proxy performance](#reverse-proxy-performance)
    * [permanent cloudflare tunnel](#permanent-cloudflare-tunnel) - if you have a domain and want to get your copyparty online real quick
    * [prometheus](#prometheus) - metrics/stats can be enabled
    * [other extremely specific features](#other-extremely-specific-features) - you&#039;ll never find a use for these
        * [custom mimetypes](#custom-mimetypes) - change the association of a file extension
        * [GDPR compliance](#GDPR-compliance) - imagine using copyparty professionally...
        * [feature chickenbits](#feature-chickenbits) - buggy feature? rip it out
        * [feature beefybits](#feature-beefybits) - force-enable features with known issues on your OS/env
* [packages](#packages) - the party might be closer than you think
    * [arch package](#arch-package) - `pacman -S copyparty` (in [arch linux extra](https://archlinux.org/packages/extra/any/copyparty/))
    * [fedora package](#fedora-package) - does not exist yet
    * [nix package](#nix-package) - `nix profile install github:9001/copyparty`
    * [nixos module](#nixos-module)
* [browser support](#browser-support) - TLDR: yes
* [client examples](#client-examples) - interact with copyparty using non-browser clients
    * [folder sync](#folder-sync) - sync folders to/from copyparty
    * [mount as drive](#mount-as-drive) - a remote copyparty server as a local filesystem
* [android app](#android-app) - upload to copyparty with one tap
* [iOS shortcuts](#iOS-shortcuts) - there is no iPhone app, but
* [performance](#performance) - defaults are usually fine - expect `8 GiB/s` download, `1 GiB/s` upload
    * [client-side](#client-side) - when uploading files
* [security](#security) - there is a [discord server](https://discord.gg/25J8CdTT6G)
    * [gotchas](#gotchas) - behavior that might be unexpected
    * [cors](#cors) - cross-site request config
    * [filekeys](#filekeys) - prevent filename bruteforcing
        * [dirkeys](#dirkeys) - share specific folders in a volume
    * [password hashing](#password-hashing) - you can hash passwords
    * [https](#https) - both HTTP and HTTPS are accepted
* [recovering from crashes](#recovering-from-crashes)
    * [client crashes](#client-crashes)
        * [firefox wsod](#firefox-wsod) - firefox 87 can crash during uploads
* [HTTP API](#HTTP-API) - see [devnotes](./docs/devnotes.md#http-api)
* [dependencies](#dependencies) - mandatory deps
    * [optional dependencies](#optional-dependencies) - install these to enable bonus features
        * [dependency chickenbits](#dependency-chickenbits) - prevent loading an optional dependency
    * [optional gpl stuff](#optional-gpl-stuff)
* [sfx](#sfx) - the self-contained &quot;binary&quot; (recommended!)
    * [copyparty.exe](#copypartyexe) - download [copyparty.exe](https://github.com/9001/copyparty/releases/latest/download/copyparty.exe) (win8+) or [copyparty32.exe](https://github.com/9001/copyparty/releases/latest/download/copyparty32.exe) (win7+)
    * [zipapp](#zipapp) - another emergency alternative, [copyparty.pyz](https://github.com/9001/copyparty/releases/latest/download/copyparty.pyz)
* [install on android](#install-on-android)
* [reporting bugs](#reporting-bugs) - ideas for context to include, and where to submit them
* [devnotes](#devnotes) - for build instructions etc, see [./docs/devnotes.md](./docs/devnotes.md)


## quickstart

just run **[copyparty-sfx.py](https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py)** -- that&#039;s it! 🎉

* or install through [pypi](https://pypi.org/project/copyparty/): `python3 -m pip install --user -U copyparty`
* or if you cannot install python, you can use [copyparty.exe](#copypartyexe) instead
* or install [on arch](#arch-package) ╱ [on NixOS](#nixos-module) ╱ [through nix](#nix-package)
* or if you are on android, [install copyparty in termux](#install-on-android)
* or maybe you have a [synology nas / dsm](./docs/synology-dsm.md)
* or if your computer is messed up and nothing else works, [try the pyz](#zipapp)
* or if your OS is dead, give the [bootable flashdrive / cd-rom](https://a.ocv.me/pub/stuff/edcd001/enterprise-edition/) a spin
* or if you don&#039;t trust copyparty yet and want to isolate it a little, then...
  * ...maybe [prisonparty](./bin/prisonparty.sh) to create a tiny [chroot](https://wiki.archlinux.org/title/Chroot) (very portable),
  * ...or [bubbleparty](./bin/bubbleparty.sh) to wrap it in [bubblewrap](https://github.com/containers/bubblewrap) (much better)
* or if you prefer to [use docker](./scripts/docker/) 🐋 you can do that too
  * docker has all deps built-in, so skip this step:

enable thumbnails (images/audio/video), media indexing, and audio transcoding by installing some recommended deps:

* **Alpine:** `apk add py3-pillow ffmpeg`
* **Debian:** `apt install --no-install-recommends python3-pil ffmpeg`
* **Fedora:** rpmfusion + `dnf install python3-pillow ffmpeg --allowerasing`
* **FreeBSD:** `pkg install py39-sqlite3 py39-pillow ffmpeg`
* **MacOS:** `port install py-Pillow ffmpeg`
* **MacOS** (alternative): `brew install pillow ffmpeg`
* **Windows:** `python -m pip install --user -U Pillow`
  * install [python](https://www.python.org/downloads/windows/) and [ffmpeg](#optional-dependencies) manually; do not use `winget` or `Microsoft Store` (it breaks $PATH)
  * copyparty.exe comes with `Pillow` and only needs [ffmpeg](#optional-dependencies) for mediatags/videothumbs
* see [optional dependencies](#optional-dependencies) to enable even more features

running copyparty without arguments (for example doubleclicking it on Windows) will give everyone read/write access to the current folder; you may want [accounts and volumes](#accounts-and-volumes)

or see [some usage examples](#complete-examples) for inspiration, or the [complete windows example](./docs/examples/windows.md)

some recommended options:
* `-e2dsa` enables general [file indexing](#file-indexing)
* `-e2ts` enables audio metadata indexing (needs either FFprobe or Mutagen)
* `-v /mnt/music:/music:r:rw,foo -a foo:bar` shares `/mnt/music` as `/music`, `r`eadable by anyone, and read-write for user `foo`, password `bar`
  * replace `:r:rw,foo` with `:r,foo` to only make the folder readable by `foo` and nobody else
  * see [accounts and volumes](#accounts-and-volumes) (or `--help-accounts`) for the syntax and other permissions


### at home

make it accessible over the internet  by starting a [cloudflare quicktunnel](https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/do-more-with-tunnels/trycloudflare/) like so:

first download [cloudflared](https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/downloads/) and then start the tunnel with `cloudflared tunnel --url http://127.0.0.1:3923`

as the tunnel starts, it will show a URL which you can share to let anyone browse your stash or upload files to you

but if you have a domain, then you probably want to skip the random autogenerated URL and instead make a [permanent cloudflare tunnel](#permanent-cloudflare-tunnel)

since people will be connecting through cloudflare, run copyparty with `--xff-hdr cf-connecting-ip` to detect client IPs correctly


### on servers

you may also want these, especially on servers:

* [contrib/systemd/copyparty.service](contrib/systemd/copyparty.service) to run copyparty as a systemd service (see guide inside)
* [contrib/systemd/prisonparty.service](contrib/systemd/prisonparty.service) to run it in a chroot (for extra security)
* [contrib/openrc/copyparty](contrib/openrc/copyparty) to run copyparty on Alpine / Gentoo
* [contrib/rc/copyparty](contrib/rc/copyparty) to run copyparty on FreeBSD
* [nixos module](#nixos-module) to run copyparty on NixOS hosts
* [contrib/nginx/copyparty.conf](contrib/nginx/copyparty.conf) to [reverse-proxy](#reverse-proxy) behind nginx (for better https)

and remember to open the ports you want; here&#039;s a complete example including every feature copyparty has to offer:
```
firewall-cmd --permanent --add-port={80,443,3921,3923,3945,3990}/tcp  # --zone=libvirt
firewall-cmd --permanent --add-port=12000-12099/tcp  # --zone=libvirt
firewall-cmd --permanent --add-port={69,1900,3969,5353}/udp  # --zone=libvirt
firewall-cmd --reload
```
(69:tftp, 1900:ssdp, 3921:ftp, 3923:http/https, 3945:smb, 3969:tftp, 3990:ftps, 5353:mdns, 12000:passive-ftp)


## features

also see [comparison to similar software](./docs/versus.md)

* backend stuff
  * ☑ IPv6 + unix-sockets
  * ☑ [multiprocessing](#performance) (actual multithreading)
  * ☑ volumes (mountpoints)
  * ☑ [accounts](#accounts-and-volumes)
  * ☑ [ftp server](#ftp-server)
  * ☑ [tftp server](#tftp-server)
  * ☑ [webdav server](#webdav-server)
  * ☑ [smb/cifs server](#smb-server)
  * ☑ [qr-code](#qr-code) for quick access
  * ☑ [upnp / zeroconf / mdns / ssdp](#zeroconf)
  * ☑ [event hooks](#event-hooks) / script runner
  * ☑ [reverse-proxy support](https://github.com/9001/copyparty#reverse-proxy)
  * ☑ cross-platform (Windows, Linux, Macos, Android, FreeBSD, arm32/arm64, ppc64le, s390x, risc-v/riscv64)
* upload
  * ☑ basic: plain multipart, ie6 support
  * ☑ [up2k](#uploading): js, resumable, multithreaded
    * **no filesize limit!** even on Cloudflare
  * ☑ stash: simple PUT filedropper
  * ☑ filename randomizer
  * ☑ write-only folders
  * ☑ [unpost](#unpost): undo/delete accidental uploads
  * ☑ [self-destruct](#self-destruct) (specified server-side or client-side)
  * ☑ [race the beam](#race-the-beam) (almost like peer-to-peer)
  * ☑ symlink/discard duplicates (content-matching)
* download
  * ☑ single files in browser
  * ☑ [folders as zip / tar files](#zip-downloads)
  * ☑ [FUSE client](https://github.com/9001/copyparty/tree/hovudstraum/bin#partyfusepy) (read-only)
* browser
  * ☑ [navpane](#navpane) (directory tree sidebar)
  * ☑ file manager (cut/paste, delete, [batch-rename](#batch-rename))
  * ☑ audio player (with [OS media controls](https://user-images.githubusercontent.com/241032/215347492-b4250797-6c90-4e09-9a4c-721edf2fb15c.png) and opus/mp3 transcoding)
    * ☑ play video files as audio (converted on server)
    * ☑ create and play [m3u8 playlists](#playlists)
  * ☑ image gallery with webm player
  * ☑ [textfile browser](#textfile-viewer) with syntax hilighting
    * ☑ realtime streaming of growing files (logfiles and such)
  * ☑ [thumbnails](#thumbnails)
    * ☑ ...of images using Pillow, pyvips, or FFmpeg
    * ☑ ...of videos using FFmpeg
    * ☑ ...of audio (spectrograms) using FFmpeg
    * ☑ cache eviction (max-age; maybe max-size eventually)
  * ☑ multilingual UI (english, norwegian, chinese, [add your own](./docs/rice/#translations)))
  * ☑ SPA (browse while uploading)
* server indexing
  * ☑ [locate files by contents](#file-search)
  * ☑ search by name/path/date/size
  * ☑ [search by ID3-tags etc.](#searching)
* client support
  * ☑ [folder sync](#folder-sync) (one-way only; full sync will never be supported)
  * ☑ [curl-friendly](https://user-images.githubusercontent.com/241032/215322619-ea5fd606-3654-40ad-94ee-2bc058647bb2.png)
  * ☑ [opengraph](#opengraph) (discord embeds)
* markdown
  * ☑ [viewer](#markdown-viewer)
  * ☑ editor (sure why not)
  * ☑ [variables](#markdown-vars)

PS: something missing? post any crazy ideas you&#039;ve got as a [feature request](https://github.com/9001/copyparty/issues/new?assignees=9001&amp;labels=enhancement&amp;template=feature_request.md) or [discussion](https://github.com/9001/copyparty/discussions/new?category=ideas) 🤙


## testimonials

small collection of user feedback

`good enough`, `surprisingly correct`, `certified good software`, `just works`, `why`, `wow this is better than nextcloud`

* UI просто ужасно. Если буду описывать детально не смогу удержаться в рамках приличий


# motivations

project goals / philosophy

* inverse linux philosophy -- do all the things, and do an *okay* job
  * quick drop-in service to get a lot of features in a pinch
  * some of [the alternatives](./docs/versus.md) might be a better fit for you


... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[roboflow/supervision]]></title>
            <link>https://github.com/roboflow/supervision</link>
            <guid>https://github.com/roboflow/supervision</guid>
            <pubDate>Thu, 31 Jul 2025 00:04:36 GMT</pubDate>
            <description><![CDATA[We write your reusable computer vision tools. 💜]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/roboflow/supervision">roboflow/supervision</a></h1>
            <p>We write your reusable computer vision tools. 💜</p>
            <p>Language: Python</p>
            <p>Stars: 31,999</p>
            <p>Forks: 2,550</p>
            <p>Stars today: 752 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;p&gt;
    &lt;a align=&quot;center&quot; href=&quot;&quot; target=&quot;https://supervision.roboflow.com&quot;&gt;
      &lt;img
        width=&quot;100%&quot;
        src=&quot;https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529&quot;
      &gt;
    &lt;/a&gt;
  &lt;/p&gt;

&lt;br&gt;

[notebooks](https://github.com/roboflow/notebooks) | [inference](https://github.com/roboflow/inference) | [autodistill](https://github.com/autodistill/autodistill) | [maestro](https://github.com/roboflow/multimodal-maestro)

&lt;br&gt;

[![version](https://badge.fury.io/py/supervision.svg)](https://badge.fury.io/py/supervision)
[![downloads](https://img.shields.io/pypi/dm/supervision)](https://pypistats.org/packages/supervision)
[![snyk](https://snyk.io/advisor/python/supervision/badge.svg)](https://snyk.io/advisor/python/supervision)
[![license](https://img.shields.io/pypi/l/supervision)](https://github.com/roboflow/supervision/blob/main/LICENSE.md)
[![python-version](https://img.shields.io/pypi/pyversions/supervision)](https://badge.fury.io/py/supervision)
[![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb)
[![gradio](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/Roboflow/Annotators)
[![discord](https://img.shields.io/discord/1159501506232451173?logo=discord&amp;label=discord&amp;labelColor=fff&amp;color=5865f2&amp;link=https%3A%2F%2Fdiscord.gg%2FGbfgXGJ8Bk)](https://discord.gg/GbfgXGJ8Bk)
[![built-with-material-for-mkdocs](https://img.shields.io/badge/Material_for_MkDocs-526CFE?logo=MaterialForMkDocs&amp;logoColor=white)](https://squidfunk.github.io/mkdocs-material/)

  &lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/124&quot;  target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/124&quot; alt=&quot;roboflow%2Fsupervision | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
  &lt;/div&gt;

&lt;/div&gt;

## 👋 hello

**We write your reusable computer vision tools.** Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! 🤝

## 💻 install

Pip install the supervision package in a
[**Python&gt;=3.9**](https://www.python.org/) environment.

```bash
pip install supervision
```

Read more about conda, mamba, and installing from source in our [guide](https://roboflow.github.io/supervision/).

## 🔥 quickstart

### models

Supervision was designed to be model agnostic. Just plug in any classification, detection, or segmentation model. For your convenience, we have created [connectors](https://supervision.roboflow.com/latest/detection/core/#detections) for the most popular libraries like Ultralytics, Transformers, or MMDetection.

```python
import cv2
import supervision as sv
from ultralytics import YOLO

image = cv2.imread(...)
model = YOLO(&quot;yolov8s.pt&quot;)
result = model(image)[0]
detections = sv.Detections.from_ultralytics(result)

len(detections)
# 5
```

&lt;details&gt;
&lt;summary&gt;👉 more model connectors&lt;/summary&gt;

- inference

  Running with [Inference](https://github.com/roboflow/inference) requires a [Roboflow API KEY](https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key).

  ```python
  import cv2
  import supervision as sv
  from inference import get_model

  image = cv2.imread(...)
  model = get_model(model_id=&quot;yolov8s-640&quot;, api_key=&lt;ROBOFLOW API KEY&gt;)
  result = model.infer(image)[0]
  detections = sv.Detections.from_inference(result)

  len(detections)
  # 5
  ```

&lt;/details&gt;

### annotators

Supervision offers a wide range of highly customizable [annotators](https://supervision.roboflow.com/latest/detection/annotators/), allowing you to compose the perfect visualization for your use case.

```python
import cv2
import supervision as sv

image = cv2.imread(...)
detections = sv.Detections(...)

box_annotator = sv.BoxAnnotator()
annotated_frame = box_annotator.annotate(
  scene=image.copy(),
  detections=detections)
```

https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce

### datasets

Supervision provides a set of [utils](https://supervision.roboflow.com/latest/datasets/core/) that allow you to load, split, merge, and save datasets in one of the supported formats.

```python
import supervision as sv
from roboflow import Roboflow

project = Roboflow().workspace(&lt;WORKSPACE_ID&gt;).project(&lt;PROJECT_ID&gt;)
dataset = project.version(&lt;PROJECT_VERSION&gt;).download(&quot;coco&quot;)

ds = sv.DetectionDataset.from_coco(
    images_directory_path=f&quot;{dataset.location}/train&quot;,
    annotations_path=f&quot;{dataset.location}/train/_annotations.coco.json&quot;,
)

path, image, annotation = ds[0]
    # loads image on demand

for path, image, annotation in ds:
    # loads image on demand
```

&lt;details close&gt;
&lt;summary&gt;👉 more dataset utils&lt;/summary&gt;

- load

  ```python
  dataset = sv.DetectionDataset.from_yolo(
      images_directory_path=...,
      annotations_directory_path=...,
      data_yaml_path=...
  )

  dataset = sv.DetectionDataset.from_pascal_voc(
      images_directory_path=...,
      annotations_directory_path=...
  )

  dataset = sv.DetectionDataset.from_coco(
      images_directory_path=...,
      annotations_path=...
  )
  ```

- split

  ```python
  train_dataset, test_dataset = dataset.split(split_ratio=0.7)
  test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)

  len(train_dataset), len(test_dataset), len(valid_dataset)
  # (700, 150, 150)
  ```

- merge

  ```python
  ds_1 = sv.DetectionDataset(...)
  len(ds_1)
  # 100
  ds_1.classes
  # [&#039;dog&#039;, &#039;person&#039;]

  ds_2 = sv.DetectionDataset(...)
  len(ds_2)
  # 200
  ds_2.classes
  # [&#039;cat&#039;]

  ds_merged = sv.DetectionDataset.merge([ds_1, ds_2])
  len(ds_merged)
  # 300
  ds_merged.classes
  # [&#039;cat&#039;, &#039;dog&#039;, &#039;person&#039;]
  ```

- save

  ```python
  dataset.as_yolo(
      images_directory_path=...,
      annotations_directory_path=...,
      data_yaml_path=...
  )

  dataset.as_pascal_voc(
      images_directory_path=...,
      annotations_directory_path=...
  )

  dataset.as_coco(
      images_directory_path=...,
      annotations_path=...
  )
  ```

- convert

  ```python
  sv.DetectionDataset.from_yolo(
      images_directory_path=...,
      annotations_directory_path=...,
      data_yaml_path=...
  ).as_pascal_voc(
      images_directory_path=...,
      annotations_directory_path=...
  )
  ```

&lt;/details&gt;

## 🎬 tutorials

Want to learn how to use Supervision? Explore our [how-to guides](https://supervision.roboflow.com/develop/how_to/detect_and_annotate/), [end-to-end examples](https://github.com/roboflow/supervision/tree/develop/examples), [cheatsheet](https://roboflow.github.io/cheatsheet-supervision/), and [cookbooks](https://supervision.roboflow.com/develop/cookbooks/)!

&lt;br/&gt;

&lt;p align=&quot;left&quot;&gt;
&lt;a href=&quot;https://youtu.be/hAWpsIuem10&quot; title=&quot;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&quot;&gt;&lt;img src=&quot;https://github.com/SkalskiP/SkalskiP/assets/26109316/a742823d-c158-407d-b30f-063a5d11b4e1&quot; alt=&quot;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&quot; width=&quot;300px&quot; align=&quot;left&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://youtu.be/hAWpsIuem10&quot; title=&quot;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&quot;&gt;&lt;strong&gt;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&lt;/strong&gt;&lt;/a&gt;
&lt;div&gt;&lt;strong&gt;Created: 5 Apr 2024&lt;/strong&gt;&lt;/div&gt;
&lt;br/&gt;Learn how to use computer vision to analyze wait times and optimize processes. This tutorial covers object detection, tracking, and calculating time spent in designated zones. Use these techniques to improve customer experience in retail, traffic management, or other scenarios.&lt;/p&gt;

&lt;br/&gt;

&lt;p align=&quot;left&quot;&gt;
&lt;a href=&quot;https://youtu.be/uWP6UjDeZvY&quot; title=&quot;Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source&quot;&gt;&lt;img src=&quot;https://github.com/SkalskiP/SkalskiP/assets/26109316/61a444c8-b135-48ce-b979-2a5ab47c5a91&quot; alt=&quot;Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source&quot; width=&quot;300px&quot; align=&quot;left&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://youtu.be/uWP6UjDeZvY&quot; title=&quot;Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source&quot;&gt;&lt;strong&gt;Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source&lt;/strong&gt;&lt;/a&gt;
&lt;div&gt;&lt;strong&gt;Created: 11 Jan 2024&lt;/strong&gt;&lt;/div&gt;
&lt;br/&gt;Learn how to track and estimate the speed of vehicles using YOLO, ByteTrack, and Roboflow Inference. This comprehensive tutorial covers object detection, multi-object tracking, filtering detections, perspective transformation, speed estimation, visualization improvements, and more.&lt;/p&gt;

## 💜 built with supervision

Did you build something cool using supervision? [Let us know!](https://github.com/roboflow/supervision/discussions/categories/built-with-supervision)

https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4

https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900

https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f

## 📚 documentation

Visit our [documentation](https://roboflow.github.io/supervision) page to learn how supervision can help you build computer vision applications faster and more reliably.

## 🏆 contribution

We love your input! Please see our [contributing guide](https://github.com/roboflow/supervision/blob/main/CONTRIBUTING.md) to get started. Thank you 🙏 to all our contributors!

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/roboflow/supervision/graphs/contributors&quot;&gt;
      &lt;img src=&quot;https://contrib.rocks/image?repo=roboflow/supervision&quot; /&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;br&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;div align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://youtube.com/roboflow&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/youtube.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949634652&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://roboflow.com&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/roboflow-app.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949746649&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://www.linkedin.com/company/roboflow-ai/&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/linkedin.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949633691&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://docs.roboflow.com&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/knowledge.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949634511&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://discuss.roboflow.com&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/forum.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949633584&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://blog.roboflow.com&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/blog.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949633605&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[mikf/gallery-dl]]></title>
            <link>https://github.com/mikf/gallery-dl</link>
            <guid>https://github.com/mikf/gallery-dl</guid>
            <pubDate>Thu, 31 Jul 2025 00:04:35 GMT</pubDate>
            <description><![CDATA[Command-line program to download image galleries and collections from several image hosting sites]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mikf/gallery-dl">mikf/gallery-dl</a></h1>
            <p>Command-line program to download image galleries and collections from several image hosting sites</p>
            <p>Language: Python</p>
            <p>Stars: 14,617</p>
            <p>Forks: 1,162</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[LMCache/LMCache]]></title>
            <link>https://github.com/LMCache/LMCache</link>
            <guid>https://github.com/LMCache/LMCache</guid>
            <pubDate>Thu, 31 Jul 2025 00:04:34 GMT</pubDate>
            <description><![CDATA[Supercharge Your LLM with the Fastest KV Cache Layer]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/LMCache/LMCache">LMCache/LMCache</a></h1>
            <p>Supercharge Your LLM with the Fastest KV Cache Layer</p>
            <p>Language: Python</p>
            <p>Stars: 3,619</p>
            <p>Forks: 410</p>
            <p>Stars today: 118 stars today</p>
            <h2>README</h2><pre># LMCache core library

## Installation

**Prerequisite:** Python &gt;= 3.10

```bash
pip install -e .
```

## Demos
Feel free to try our docker-based demos yourself! All the demos are available [in this repo](https://github.com/LMCache/demo).

## Quickstart: 

**Prerequisites**: To run the quickstart demo, your server should have 1 GPU and the [docker environment](https://docs.docker.com/engine/install/) installed.

**Step 1:** Pull docker images
```bash
docker pull apostacyh/vllm:lmcache-0.1.0
```

**Step 2:** Start vLLM + LMCache 
```bash
model=mistralai/Mistral-7B-Instruct-v0.2    # Replace with your model name
sudo docker run --runtime nvidia --gpus &#039;&quot;device=0&quot;&#039; \
    -v &lt;Huggingface cache dir on your local machine&gt;:/root/.cache/huggingface \
    -p 8000:8000 \
    --env &quot;HF_TOKEN=&lt;Your huggingface access token&gt;&quot; \
    --ipc=host \
    --network=host \
    apostacyh/vllm:lmcache-0.1.0 \
    --model $model --gpu-memory-utilization 0.6 --port 8000 \
    --lmcache-config-file /lmcache/LMCache/examples/example-local.yaml
```
Please fill `Huggingface cache dir on your local machine` and `Your huggingface access token` in the above command. 

You can also change the `model` variable to use different models.

The vLLM engine is ready after you see the logs like this:
```
INFO:     Started server process [865615]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

**Step 3:** Run demo application

You can now run the demo application in the LMCache repo. Please execute the following commands on the server
```bash
git clone https://github.com/LMCache/LMCache
cd LMCache/examples/

# Install openai client library
pip install openai

# Start the demo chat application
python openai_chat_completion_client.py 8000
```

This demo is a QA application based on a long context (`examples/f.txt`). The TTFT should be drastically reduced since the second round of QA.



## Use case 1: share prefix KV between different vLLM instance through LMCache
The following instructions help deploy LMCache backend + multile vLLM instance by docker containers. The architecture of the demo application looks like this:

&lt;img width=&quot;817&quot; alt=&quot;image&quot; src=&quot;https://github.com/LMCache/LMCache/assets/25103655/ab64f84d-26e1-46ce-a503-e7e917b618bc&quot;&gt;


**Prerequisites**: To run the quickstart demo, your server must have 2 GPUs and the [docker environment](https://docs.docker.com/engine/install/) installed.


**Step 1:** Pull docker images
```bash
docker pull apostacyh/lmcache-server:0.1.0
docker pull apostacyh/vllm:lmcache-0.1.0
```

**Step 2:** Start LMCache backend server 
```bash
docker run --name lmcache-server --network host -d apostacyh/lmcache-server:0.1.0 0.0.0.0 65432
```

**Step 3:** start 2 vLLM instances
```bash
# The first vLLM instance listens at port 8000
model=mistralai/Mistral-7B-Instruct-v0.2    # Replace with your model name
sudo docker run --runtime nvidia --gpus &#039;&quot;device=0&quot;&#039; \
    -v &lt;Huggingface cache dir on your local machine&gt;:/root/.cache/huggingface \
    -p 8000:8000 \
    --env &quot;HF_TOKEN=&lt;Your huggingface token&gt;&quot; \
    --ipc=host \
    --network=host \
    apostacyh/vllm:lmcache-0.1.0 \
    --model $model --gpu-memory-utilization 0.7 --port 8000 \
    --lmcache-config-file /lmcache/LMCache/examples/example.yaml
```

Now, open another terminal and start another vLLM instance
```bash
# The second vLLM instance listens at port 8001
model=mistralai/Mistral-7B-Instruct-v0.2    # Replace with your model name
sudo docker run --runtime nvidia --gpus &#039;&quot;device=1&quot;&#039; \
    -v &lt;Huggingface cache dir on your local machine&gt;:/root/.cache/huggingface \
    -p 8001:8001 \
    --env &quot;HF_TOKEN=&lt;Your huggingface token&gt;&quot; \
    --ipc=host \
    --network=host \
    apostacyh/vllm:lmcache-0.1.0 \
    --model $model --gpu-memory-utilization 0.7 --port 8001 \
    --lmcache-config-file /lmcache/LMCache/examples/example.yaml
```

Remember to replace the `Huggingface cache dir on your local machine` and `Your huggingface token` in the commandline.

The vLLM engines are ready after you see the logs like this:
```
INFO:     Started server process [865615]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

**Step 4:** Run demo application
You can run the demo application in the LMCache repo. Please execute the following commands on the server
```bash
git clone https://github.com/LMCache/LMCache
cd LMCache/examples/

# Install openai client library
pip install openai
```

In one terminal:
```
# Connect to the first vLLM engine
python openai_chat_completion_client.py 8000
```

In another terminal
```
# Connect to the second vLLM engine
python openai_chat_completion_client.py 8001
```

You should be able to see the second vLLM engine has much lower response delay.
This is because the KV cache of the long context can be shared across both vLLM engines by using LMCache.

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[sherlock-project/sherlock]]></title>
            <link>https://github.com/sherlock-project/sherlock</link>
            <guid>https://github.com/sherlock-project/sherlock</guid>
            <pubDate>Thu, 31 Jul 2025 00:04:33 GMT</pubDate>
            <description><![CDATA[Hunt down social media accounts by username across social networks]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sherlock-project/sherlock">sherlock-project/sherlock</a></h1>
            <p>Hunt down social media accounts by username across social networks</p>
            <p>Language: Python</p>
            <p>Stars: 67,618</p>
            <p>Forks: 7,761</p>
            <p>Stars today: 44 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[virattt/ai-hedge-fund]]></title>
            <link>https://github.com/virattt/ai-hedge-fund</link>
            <guid>https://github.com/virattt/ai-hedge-fund</guid>
            <pubDate>Thu, 31 Jul 2025 00:04:32 GMT</pubDate>
            <description><![CDATA[An AI Hedge Fund Team]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/virattt/ai-hedge-fund">virattt/ai-hedge-fund</a></h1>
            <p>An AI Hedge Fund Team</p>
            <p>Language: Python</p>
            <p>Stars: 38,865</p>
            <p>Forks: 6,831</p>
            <p>Stars today: 152 stars today</p>
            <h2>README</h2><pre># AI Hedge Fund

This is a proof of concept for an AI-powered hedge fund.  The goal of this project is to explore the use of AI to make trading decisions.  This project is for **educational** purposes only and is not intended for real trading or investment.

This system employs several agents working together:

1. Aswath Damodaran Agent - The Dean of Valuation, focuses on story, numbers, and disciplined valuation
2. Ben Graham Agent - The godfather of value investing, only buys hidden gems with a margin of safety
3. Bill Ackman Agent - An activist investor, takes bold positions and pushes for change
4. Cathie Wood Agent - The queen of growth investing, believes in the power of innovation and disruption
5. Charlie Munger Agent - Warren Buffett&#039;s partner, only buys wonderful businesses at fair prices
6. Michael Burry Agent - The Big Short contrarian who hunts for deep value
7. Peter Lynch Agent - Practical investor who seeks &quot;ten-baggers&quot; in everyday businesses
8. Phil Fisher Agent - Meticulous growth investor who uses deep &quot;scuttlebutt&quot; research 
9. Rakesh Jhunjhunwala Agent - The Big Bull of India
10. Stanley Druckenmiller Agent - Macro legend who hunts for asymmetric opportunities with growth potential
11. Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price
12. Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals
13. Sentiment Agent - Analyzes market sentiment and generates trading signals
14. Fundamentals Agent - Analyzes fundamental data and generates trading signals
15. Technicals Agent - Analyzes technical indicators and generates trading signals
16. Risk Manager - Calculates risk metrics and sets position limits
17. Portfolio Manager - Makes final trading decisions and generates orders

&lt;img width=&quot;1042&quot; alt=&quot;Screenshot 2025-03-22 at 6 19 07 PM&quot; src=&quot;https://github.com/user-attachments/assets/cbae3dcf-b571-490d-b0ad-3f0f035ac0d4&quot; /&gt;

Note: the system does not actually make any trades.

[![Twitter Follow](https://img.shields.io/twitter/follow/virattt?style=social)](https://twitter.com/virattt)

## Disclaimer

This project is for **educational and research purposes only**.

- Not intended for real trading or investment
- No investment advice or guarantees provided
- Creator assumes no liability for financial losses
- Consult a financial advisor for investment decisions
- Past performance does not indicate future results

By using this software, you agree to use it solely for learning purposes.

## Table of Contents
- [How to Install](#how-to-install)
- [How to Run](#how-to-run)
  - [⌨️ Command Line Interface](#️-command-line-interface)
  - [🖥️ Web Application (NEW!)](#️-web-application)
- [Contributing](#contributing)
- [Feature Requests](#feature-requests)
- [License](#license)

## How to Install

Before you can run the AI Hedge Fund, you&#039;ll need to install it and set up your API keys. These steps are common to both the full-stack web application and command line interface.

### 1. Clone the Repository

```bash
git clone https://github.com/virattt/ai-hedge-fund.git
cd ai-hedge-fund
```

### 2. Set Up Your API Keys

Create a `.env` file for your API keys:
```bash
# Create .env file for your API keys (in the root directory)
cp .env.example .env
```

Open and edit the `.env` file to add your API keys:
```bash
# For running LLMs hosted by openai (gpt-4o, gpt-4o-mini, etc.)
OPENAI_API_KEY=your-openai-api-key

# For running LLMs hosted by groq (deepseek, llama3, etc.)
GROQ_API_KEY=your-groq-api-key

# For getting financial data to power the hedge fund
FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key
```

**Important**: You must set at least one LLM API key (`OPENAI_API_KEY`, `GROQ_API_KEY`, `ANTHROPIC_API_KEY`, or `DEEPSEEK_API_KEY`) for the hedge fund to work. 

**Financial Data**: Data for AAPL, GOOGL, MSFT, NVDA, and TSLA is free and does not require an API key. For any other ticker, you will need to set the `FINANCIAL_DATASETS_API_KEY` in the .env file.

## How to Run

### ⌨️ Command Line Interface

For users who prefer working with command line tools, you can run the AI Hedge Fund directly via terminal. This approach offers more granular control and is useful for automation, scripting, and integration purposes.

&lt;img width=&quot;992&quot; alt=&quot;Screenshot 2025-01-06 at 5 50 17 PM&quot; src=&quot;https://github.com/user-attachments/assets/e8ca04bf-9989-4a7d-a8b4-34e04666663b&quot; /&gt;

Choose one of the following installation methods:

#### Using Poetry

1. Install Poetry (if not already installed):
```bash
curl -sSL https://install.python-poetry.org | python3 -
```

2. Install dependencies:
```bash
poetry install
```

#### Using Docker

1. Make sure you have Docker installed on your system. If not, you can download it from [Docker&#039;s official website](https://www.docker.com/get-started).

2. Navigate to the docker directory:
```bash
cd docker
```

3. Build the Docker image:
```bash
# On Linux/Mac:
./run.sh build

# On Windows:
run.bat build
```

#### Running the AI Hedge Fund (with Poetry)
```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA
```

#### Running the AI Hedge Fund (with Docker)
```bash
# Navigate to the docker directory first
cd docker

# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA main

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA main
```

You can also specify a `--ollama` flag to run the AI hedge fund using local LLMs.

```bash
# With Poetry:
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --ollama

# With Docker (from docker/ directory):
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA --ollama main

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA --ollama main
```

You can also specify a `--show-reasoning` flag to print the reasoning of each agent to the console.

```bash
# With Poetry:
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --show-reasoning

# With Docker (from docker/ directory):
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA --show-reasoning main

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA --show-reasoning main
```

You can optionally specify the start and end dates to make decisions for a specific time period.

```bash
# With Poetry:
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 

# With Docker (from docker/ directory):
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 main

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 main
```

#### Running the Backtester (with Poetry)
```bash
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA
```

#### Running the Backtester (with Docker)
```bash
# Navigate to the docker directory first
cd docker

# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA backtest

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA backtest
```

**Example Output:**
&lt;img width=&quot;941&quot; alt=&quot;Screenshot 2025-01-06 at 5 47 52 PM&quot; src=&quot;https://github.com/user-attachments/assets/00e794ea-8628-44e6-9a84-8f8a31ad3b47&quot; /&gt;


You can optionally specify the start and end dates to backtest over a specific time period.

```bash
# With Poetry:
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01

# With Docker (from docker/ directory):
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 backtest

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 backtest
```

You can also specify a `--ollama` flag to run the backtester using local LLMs.
```bash
# With Poetry:
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA --ollama

# With Docker (from docker/ directory):
# On Linux/Mac:
./run.sh --ticker AAPL,MSFT,NVDA --ollama backtest

# On Windows:
run.bat --ticker AAPL,MSFT,NVDA --ollama backtest
```

### 🖥️ Web Application

The new way to run the AI Hedge Fund is through our web application that provides a user-friendly interface. **This is recommended for most users, especially those who prefer visual interfaces over command line tools.**

&lt;img width=&quot;1721&quot; alt=&quot;Screenshot 2025-06-28 at 6 41 03 PM&quot; src=&quot;https://github.com/user-attachments/assets/b95ab696-c9f4-416c-9ad1-51feb1f5374b&quot; /&gt;

#### For Mac/Linux:
```bash
cd app &amp;&amp; ./run.sh
```

If you get a &quot;permission denied&quot; error, run this first:
```bash
cd app &amp;&amp; chmod +x run.sh &amp;&amp; ./run.sh
```

#### For Windows:
```bash
# Go to /app directory
cd app

# Run the app
\.run.bat
```

**That&#039;s it!** These scripts will:
1. Check for required dependencies (Node.js, Python, Poetry)
2. Install all dependencies automatically  
3. Start both frontend and backend services
4. **Automatically open your web browser** to the application


#### Detailed Setup Instructions

For detailed setup instructions, troubleshooting, and advanced configuration options, see:
- [Full-Stack App Documentation](./app/README.md)
- [Frontend Documentation](./app/frontend/README.md)  
- [Backend Documentation](./app/backend/README.md)


## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

**Important**: Please keep your pull requests small and focused.  This will make it easier to review and merge.

## Feature Requests

If you have a feature request, please open an [issue](https://github.com/virattt/ai-hedge-fund/issues) and make sure it is tagged with `enhancement`.

## License

This project is licensed under the MIT License - see the LICENSE file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[huggingface/smollm]]></title>
            <link>https://github.com/huggingface/smollm</link>
            <guid>https://github.com/huggingface/smollm</guid>
            <pubDate>Thu, 31 Jul 2025 00:04:31 GMT</pubDate>
            <description><![CDATA[Everything about the SmolLM and SmolVLM family of models]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/huggingface/smollm">huggingface/smollm</a></h1>
            <p>Everything about the SmolLM and SmolVLM family of models</p>
            <p>Language: Python</p>
            <p>Stars: 3,048</p>
            <p>Forks: 198</p>
            <p>Stars today: 49 stars today</p>
            <h2>README</h2><pre># Smol Models 🤏

Welcome to Smol Models, a family of efficient and lightweight AI models from Hugging Face. Our mission is to create fully open powerful yet compact models, for text and vision, that can run effectively on-device while maintaining strong performance.

## [NEW] SmolLM3 (Language Model)
![image](https://github.com/user-attachments/assets/2bf61ea2-8d2e-426b-ba40-0242d34325d2)

Our 3B model outperforms Llama 3.2 3B and Qwen2.5 3B while staying competitive with larger 4B alternatives (Qwen3 &amp; Gemma3). Beyond the performance numbers, we&#039;re sharing exactly how we built it using public datasets and training frameworks.

Ressources:
- [SmolLM3-Base](https://hf.co/HuggingFaceTB/SmolLM3-3B-Base)
- [SmolLM3](https://hf.co/HuggingFaceTB/SmolLM3-3B)
- [blog](https://hf.co/blog/smollm3)

Summary:
- **3B model** trained on 11T tokens, SoTA at the 3B scale and competitive with 4B models
- **Fully open model**, open weights + full training details including public data mixture and training configs
- **Instruct model** with **dual mode reasoning,** supporting think/no_think modes
- **Multilingual support** for 6 languages: English, French, Spanish, German, Italian, and Portuguese
- **Long context** up to 128k with NoPE and using YaRN

![image](https://github.com/user-attachments/assets/f1b76d3b-af2b-4218-91b3-4ce815bdf0a8)

## 👁️ SmolVLM (Vision Language Model)
[SmolVLM](https://huggingface.co/HuggingFaceTB/SmolVLM-Instruct) is our compact multimodal model that can:
- Process both images and text and perform tasks like visual QA, image description, and visual storytelling
- Handle multiple images in a single conversation
- Run efficiently on-device

## Repository Structure
```
smollm/
├── text/               # SmolLM3/2/1 related code and resources
├── vision/            # SmolVLM related code and resources
└── tools/             # Shared utilities and inference tools
    ├── smol_tools/    # Lightweight AI-powered tools
    ├── smollm_local_inference/
    └── smolvlm_local_inference/
```

## Getting Started

### SmolLM3
```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = &quot;HuggingFaceTB/SmolLM3-3B&quot;
device = &quot;cuda&quot;  # for GPU usage or &quot;cpu&quot; for CPU usage

# load the tokenizer and the model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
).to(device)

# prepare the model input
prompt = &quot;Give me a brief explanation of gravity in simple terms.&quot;
messages_think = [
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}
]

text = tokenizer.apply_chat_template(
    messages_think,
    tokenize=False,
    add_generation_prompt=True,
)
model_inputs = tokenizer([text], return_tensors=&quot;pt&quot;).to(model.device)

# Generate the output
generated_ids = model.generate(**model_inputs, max_new_tokens=32768)

# Get and decode the output
output_ids = generated_ids[0][len(model_inputs.input_ids[0]) :]
print(tokenizer.decode(output_ids, skip_special_tokens=True))
```

### SmolVLM
```python
from transformers import AutoProcessor, AutoModelForVision2Seq

processor = AutoProcessor.from_pretrained(&quot;HuggingFaceTB/SmolVLM-Instruct&quot;)
model = AutoModelForVision2Seq.from_pretrained(&quot;HuggingFaceTB/SmolVLM-Instruct&quot;)

messages = [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: [
            {&quot;type&quot;: &quot;image&quot;},
            {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;What&#039;s in this image?&quot;}
        ]
    }
]
```

## Ecosystem
&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/RvHjdlRT5gGQt5mJuhXH9.png&quot; width=&quot;700&quot;/&gt;
&lt;/div&gt;

## Resources

### Documentation
- [SmolLM3 Documentation](text/README.md)
- [SmolLM2 paper](https://arxiv.org/abs/2502.02737v1)
- [SmolVLM Documentation](vision/README.md)
- [Local Inference Guide](tools/README.md)

### Pretrained Models
- [SmolLM3 Models Collection](https://huggingface.co/collections/HuggingFaceTB/smollm3-686d33c1fdffe8e635317e23)
- [SmolLM2 Models Collection](https://huggingface.co/collections/HuggingFaceTB/smollm2-6723884218bcda64b34d7db9)
- [SmolVLM Model](https://huggingface.co/HuggingFaceTB/SmolVLM-Instruct)

### Datasets
- [SmolLM3 Pretraining dataset](https://huggingface.co/collections/HuggingFaceTB/smollm3-pretraining-datasets-685a7353fdc01aecde51b1d9)
- [SmolTalk](https://huggingface.co/datasets/HuggingFaceTB/smoltalk) - Our instruction-tuning dataset
- [FineMath](https://huggingface.co/datasets/HuggingFaceTB/finemath) - Mathematics pretraining dataset
- [FineWeb-Edu](https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu) - Educational content pretraining dataset
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[protectai/vulnhuntr]]></title>
            <link>https://github.com/protectai/vulnhuntr</link>
            <guid>https://github.com/protectai/vulnhuntr</guid>
            <pubDate>Thu, 31 Jul 2025 00:04:30 GMT</pubDate>
            <description><![CDATA[Zero shot vulnerability discovery using LLMs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/protectai/vulnhuntr">protectai/vulnhuntr</a></h1>
            <p>Zero shot vulnerability discovery using LLMs</p>
            <p>Language: Python</p>
            <p>Stars: 2,090</p>
            <p>Forks: 223</p>
            <p>Stars today: 62 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

  &lt;img width=&quot;250&quot; src=&quot;https://github.com/user-attachments/assets/d1153ab4-df29-4955-ad49-1be7fad18bb3&quot; alt=&quot;Vulnhuntr Logo&quot;&gt;

A tool to identify remotely exploitable vulnerabilities using LLMs and static code analysis.

**World&#039;s first autonomous AI-discovered 0day vulnerabilities**

&lt;/div&gt;

## Description
Vulnhuntr leverages the power of LLMs to automatically create and analyze entire code call chains starting from remote user input and ending at server output for detection of complex, multi-step, security-bypassing vulnerabilities that go far beyond what traditional static code analysis tools are capable of performing. See all the details including the Vulnhuntr output for all the 0-days here: [Protect AI Vulnhuntr Blog](https://protectai.com/threat-research/vulnhuntr-first-0-day-vulnerabilities)

## Vulnerabilities Found

&gt; [!TIP]
&gt; Found a vulnerability using Vulnhuntr? Submit a report to [huntr.com](https://huntr.com) to get $$ and submit a PR to add it to the list below!

&gt; [!NOTE]
&gt; This table is just a sample of the vulnerabilities found so far. We will unredact as responsible disclosure periods end.

| Repository | Stars | Vulnerabilities |
| - | - | - |
| [gpt_academic](https://github.com/binary-husky/gpt_academic) | 67k | [LFI](https://nvd.nist.gov/vuln/detail/CVE-2024-10100), [XSS](https://nvd.nist.gov/vuln/detail/CVE-2024-10101) |
| [ComfyUI](https://github.com/comfyanonymous/ComfyUI) | 66k | [XSS](https://nvd.nist.gov/vuln/detail/CVE-2024-10099) |
| [Langflow](https://github.com/langflow-ai/langflow) | 46k | RCE, IDOR |
| [FastChat](https://github.com/lm-sys/FastChat) | 37k | [SSRF](https://nvd.nist.gov/vuln/detail/CVE-2024-10044) | 
| [Ragflow](https://github.com/infiniflow/ragflow) | 31k | [RCE](https://nvd.nist.gov/vuln/detail/CVE-2024-10131) |
| [LLaVA](https://github.com/haotian-liu/LLaVA) | 21k | [SSRF](https://www.cve.org/CVERecord?id=CVE-2024-9309) |
| [gpt-researcher](https://github.com/assafelovic/gpt-researcher) | 17k | [AFO](https://github.com/assafelovic/gpt-researcher/pull/935) |
| [Letta](https://github.com/letta-ai/letta) | 14k | [AFO](https://github.com/letta-ai/letta/pull/2067) | 

## Limitations

- Only Python codebases are supported.
- Can only identify the following vulnerability classes:
  - Local file include (LFI)
  - Arbitrary file overwrite (AFO)
  - Remote code execution (RCE)
  - Cross site scripting (XSS)
  - SQL Injection (SQLI)
  - Server side request forgery (SSRF)
  - Insecure Direct Object Reference (IDOR)

## Installation

&gt; [!IMPORTANT]
&gt; Vulnhuntr strictly requires Python 3.10 because of a number of bugs in Jedi which it uses to parse Python code. It will not work reliably if installed with any other versions of Python.

We recommend using [pipx](https://github.com/pypa/pipx) or Docker to easily install and run Vulnhuntr.

Using Docker:
```bash
docker build -t vulnhuntr https://github.com/protectai/vulnhuntr.git#main
```

Using pipx:
```bash
pipx install git+https://github.com/protectai/vulnhuntr.git --python python3.10
```

Alternatively you can install directly from source using poetry:
```bash
git clone https://github.com/protectai/vulnhuntr
cd vulnhuntr &amp;&amp; poetry install
```

## Usage

This tool is designed to analyze a GitHub repository for potential remotely exploitable vulnerabilities. The tool requires an API key and the local path to a GitHub repository. You may also optionally specify a custom endpoint for the LLM service.

&gt; [!CAUTION]
&gt; Always set spending limits or closely monitor costs with the LLM provider you use. This tool has the potential to rack up hefty bills as it tries to fit as much code in the LLMs context window as possible. 

&gt; [!TIP]
&gt; We recommend using Claude for the LLM. Through testing we have had better results with it over GPT.

### Command Line Interface

```
usage: vulnhuntr [-h] -r ROOT [-a ANALYZE] [-l {claude,gpt,ollama}] [-v]

Analyze a GitHub project for vulnerabilities. Export your ANTHROPIC_API_KEY/OPENAI_API_KEY before running.

options:
  -h, --help            show this help message and exit
  -r ROOT, --root ROOT  Path to the root directory of the project
  -a ANALYZE, --analyze ANALYZE
                        Specific path or file within the project to analyze
  -l {claude,gpt,ollama}, --llm {claude,gpt,ollama}
                        LLM client to use (default: claude)
  -v, --verbosity       Increase output verbosity (-v for INFO, -vv for DEBUG)
```
### Examples
From a pipx install, analyze the entire repository using Claude:

```bash
export ANTHROPIC_API_KEY=&quot;sk-1234&quot;
vulnhuntr -r /path/to/target/repo/
```

&gt; [!TIP]
&gt; We recommend giving Vulnhuntr specific files that handle remote user input and scan them individually.

From a pipx install, analyze the `/path/to/target/repo/server.py` file using GPT-4o. Can also specify a subdirectory instead of a file:

```bash
export OPENAI_API_KEY=&quot;sk-1234&quot;
vulnhuntr -r /path/to/target/repo/ -a server.py -l gpt 
```

From a docker installation, run using Claude and a custom endpoint to analyze /local/path/to/target/repo/repo-subfolder/target-file.py:

```bash
docker run --rm -e ANTHROPIC_API_KEY=sk-1234 -e ANTHROPIC_BASE_URL=https://localhost:1234/api -v /local/path/to/target/repo:/repo vulnhuntr:latest -r /repo -a repo-subfolder/target-file.py
```

*Experimental*

Ollama is included as an option, however we haven&#039;t had success with the open source models structuring their output correctly.

```bash
export OLLAMA_BASE_URL=http://localhost:11434/api/generate
export OLLAMA_MODEL=llama3.2
vulnhuntr -r /path/to/target/repo/ -a server.py -l ollama
``` 

## Logic Flow
![VulnHuntr logic](https://github.com/user-attachments/assets/7757b053-36ff-425e-ab3d-ab0100c81d49)
- LLM summarizes the README and includes this in the system prompt
- LLM does initial analysis on an entire file and reports any potential vulnerabilities
- Vulnhuntr then gives the LLM a vulnerability-specific prompt for secondary analysis
- Each time the LLM analyzes the code, it requests additional context functions/classes/variables from other files in the project
- It continues doing this until the entire call chain from user input to server processing is complete then gives a final analysis
- The final analysis consists of it&#039;s reasoning, a proof of concept exploit, and a confidence score

&gt;[!TIP]
&gt; Generally confidence scores &lt; 7 mean there&#039;s unlikely a vulnerability. Confidence scores of 7 mean it should be investigated, and confidence scores of 8+ mean it is very likely to be a valid vulnerability.

## Output

The tool generates a detailed report of the vulnerabilities found in the analyzed files. The report includes:

- Initial assessment results for each file.
- Secondary assessment results with context functions and class references.
- Confidence scores for vulnerabilities found.
- Logs of the analysis process.
- PoC exploit

Below is an example of a Vulnhuntr report describing a 0-day remote code execution vulnerability in [Ragflow](https://github.com/infiniflow/ragflow) (now fixed):

```
scratchpad:
  1. Analyzing the add_llm function in llm_app.py. 2. Identified user input used as keys to access dictionaries: EmbeddingModel, ChatModel, RerankModel,
CvModel, and TTSModel. 3. These dictionaries contain class references, which are instantiated with user-supplied parameters. 4. The factory variable is 
directly used from user input (req[&#039;llm_factory&#039;]) without proper validation. 5. The llm_name is also derived from user input in most cases. 6. The 
instantiation of these classes occurs in try-except blocks, but exceptions are only used for error messages, not preventing execution. 7. The api_key 
and other sensitive information are passed directly to these instantiated classes. 8. There&#039;s no comprehensive input validation or sanitization for the 
factory or llm_name variables. 9. The vulnerability is in a route decorated with @login_required, indicating it&#039;s accessible to authenticated users. 10.
Reviewing the EmbeddingModel, ChatModel, RerankModel, CvModel, and TTSModel dictionaries to understand their contents and potential for exploitation.
----------------------------------------

analysis:
  The add_llm function in llm_app.py contains a critical Remote Code Execution (RCE) vulnerability. The function uses user-supplied input 
(req[&#039;llm_factory&#039;] and req[&#039;llm_name&#039;]) to dynamically instantiate classes from the EmbeddingModel, ChatModel, RerankModel, CvModel, and TTSModel 
dictionaries. This pattern of using user input as a key to access and instantiate classes is inherently dangerous, as it allows an attacker to 
potentially execute arbitrary code. The vulnerability is exacerbated by the lack of comprehensive input validation or sanitization on these 
user-supplied values. While there are some checks for specific factory types, they are not exhaustive and can be bypassed. An attacker could potentially
provide a malicious value for &#039;llm_factory&#039; that, when used as an index to these model dictionaries, results in the execution of arbitrary code. The 
vulnerability is particularly severe because it occurs in a route decorated with @login_required, suggesting it&#039;s accessible to authenticated users, 
which might give a false sense of security.
----------------------------------------

poc:
  POST /add_llm HTTP/1.1
  Host: target.com
  Content-Type: application/json
  Authorization: Bearer &lt;valid_token&gt;
  
  {
      &quot;llm_factory&quot;: &quot;__import__(&#039;os&#039;).system&quot;,
      &quot;llm_name&quot;: &quot;id&quot;,
      &quot;model_type&quot;: &quot;EMBEDDING&quot;,
      &quot;api_key&quot;: &quot;dummy_key&quot;
  }
  
  This payload attempts to exploit the vulnerability by setting &#039;llm_factory&#039; to a string that, when evaluated, imports the os module and calls system. 
The &#039;llm_name&#039; is set to &#039;id&#039;, which would be executed as a system command if the exploit is successful.
----------------------------------------

confidence_score:
  8
----------------------------------------

vulnerability_types:
  - RCE
----------------------------------------
```

## Logging

The tool logs the analysis process and results in a file named `vulhuntr.log`. This file contains detailed information about each step of the analysis, including the initial and secondary assessments.


## Authors

- Dan McInerney: dan@protectai.com, [@DanHMcinerney](https://x.com/DanHMcInerney)
- Marcello Salvati: marcello@protectai.com, [@byt3bl33d3r](https://x.com/byt3bl33d3r)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[denizsafak/abogen]]></title>
            <link>https://github.com/denizsafak/abogen</link>
            <guid>https://github.com/denizsafak/abogen</guid>
            <pubDate>Thu, 31 Jul 2025 00:04:29 GMT</pubDate>
            <description><![CDATA[Generate audiobooks from EPUBs, PDFs and text with synchronized captions.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/denizsafak/abogen">denizsafak/abogen</a></h1>
            <p>Generate audiobooks from EPUBs, PDFs and text with synchronized captions.</p>
            <p>Language: Python</p>
            <p>Stars: 740</p>
            <p>Forks: 54</p>
            <p>Stars today: 94 stars today</p>
            <h2>README</h2><pre># abogen &lt;img width=&quot;40px&quot; title=&quot;abogen icon&quot; src=&quot;https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/abogen/assets/icon.ico&quot; align=&quot;right&quot; style=&quot;padding-left: 10px; padding-top:5px;&quot;&gt;

[![Build Status](https://github.com/denizsafak/abogen/actions/workflows/test_pip.yml/badge.svg)](https://github.com/denizsafak/abogen/actions)
[![GitHub Release](https://img.shields.io/github/v/release/denizsafak/abogen)](https://github.com/denizsafak/abogen/releases/latest)
[![Abogen PyPi Python Versions](https://img.shields.io/pypi/pyversions/abogen)](https://pypi.org/project/abogen/)
[![Operating Systems](https://img.shields.io/badge/os-windows%20%7C%20linux%20%7C%20macos%20-blue)](https://github.com/denizsafak/abogen/releases/latest)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![License: MIT](https://img.shields.io/badge/License-MIT-maroon.svg)](https://opensource.org/licenses/MIT)

Abogen is a powerful text-to-speech conversion tool that makes it easy to turn ePub, PDF, or text files into high-quality audio with matching subtitles in seconds. Use it for audiobooks, voiceovers for Instagram, YouTube, TikTok, or any project that needs natural-sounding text-to-speech, using [Kokoro-82M](https://huggingface.co/hexgrad/Kokoro-82M).

&lt;img title=&quot;Abogen Main&quot; src=&#039;https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/abogen.png&#039; width=&quot;380&quot;&gt; &lt;img title=&quot;Abogen Processing&quot; src=&#039;https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/abogen2.png&#039; width=&quot;380&quot;&gt;

## Demo
https://github.com/user-attachments/assets/cb66512d-0a52-48c3-bda4-f1e6a03fb8d6

&gt; This demo was generated in just 5 seconds, producing ∼1 minute of audio with perfectly synced subtitles. To create a similar video, see [the demo guide](https://github.com/denizsafak/abogen/tree/main/demo).

## `How to install?` &lt;a href=&quot;https://pypi.org/project/abogen/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/pyversions/abogen&quot; alt=&quot;Abogen Compatible PyPi Python Versions&quot; align=&quot;right&quot; style=&quot;margin-top:6px;&quot;&gt;&lt;/a&gt;

### Windows
Go to [espeak-ng latest release](https://github.com/espeak-ng/espeak-ng/releases/latest) download and run the *.msi file.

#### OPTION 1: Install using script
1. [Download](https://github.com/denizsafak/abogen/archive/refs/heads/main.zip) the repository
2. Extract the ZIP file
3. Run `WINDOWS_INSTALL.bat` by double-clicking it

This method handles everything automatically - installing all dependencies including CUDA in a self-contained environment without requiring a separate Python installation. (You still need to install [espeak-ng](https://github.com/espeak-ng/espeak-ng/releases/latest).)

&gt; [!NOTE]
&gt; You don&#039;t need to install Python separately. The script will install Python automatically.

#### OPTION 2: Install using pip
```bash
# Create a virtual environment (optional)
mkdir abogen &amp;&amp; cd abogen
python -m venv venv
venv\Scripts\activate

# For NVIDIA GPUs:
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# For AMD GPUs:
# Not supported yet, because ROCm is not available on Windows. Use Linux if you have AMD GPU.

# Install abogen
pip install abogen
```

### Mac
```bash
# Install espeak-ng
brew install espeak-ng

# Create a virtual environment (recommended)
mkdir abogen &amp;&amp; cd abogen
python3 -m venv venv
source venv/bin/activate

# Install abogen
pip3 install abogen
```
### Linux
```bash
# Install espeak-ng
sudo apt install espeak-ng # Ubuntu/Debian
sudo pacman -S espeak-ng # Arch Linux
sudo dnf install espeak-ng # Fedora

# Create a virtual environment (recommended)
mkdir abogen &amp;&amp; cd abogen
python3 -m venv venv
source venv/bin/activate

# Install abogen
pip3 install abogen

# For NVIDIA GPUs:
# Already supported, no need to install CUDA separately.

# For AMD GPUs:
# After installing abogen, we need to uninstall the existing torch package
pip3 uninstall torch 
pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm6.4
```
&gt; [!TIP]
&gt; If you get `WARNING: The script abogen-cli is installed in &#039;/home/username/.local/bin&#039; which is not on PATH.` error, run the following command to add it to your PATH:
&gt;```bash
&gt;echo &quot;export PATH=\&quot;/home/$USER/.local/bin:\$PATH\&quot;&quot; &gt;&gt; ~/.bashrc &amp;&amp; source ~/.bashrc
&gt;```

&gt; [!TIP]
&gt; If you get &quot;No matching distribution found&quot; error, try installing it on supported Python (3.10 to 3.12). You can use [pyenv](https://github.com/pyenv/pyenv) to manage multiple Python versions easily in Linux. Watch this [video](https://www.youtube.com/watch?v=MVyb-nI4KyI) by NetworkChuck for a quick guide.

&gt; Special thanks to [@hg000125](https://github.com/hg000125) for his contribution in [#23](https://github.com/denizsafak/abogen/issues/23). AMD GPU support is possible thanks to his work.

## `How to run?`
If you installed using pip, you can simply run the following command to start Abogen:

```bash
abogen
```
&gt; [!TIP]
&gt; If you installed using the Windows installer `(WINDOWS_INSTALL.bat)`, It should have created a shortcut in the same folder, or your desktop. You can run it from there. If you lost the shortcut, Abogen is located in `python_embedded/Scripts/abogen.exe`. You can run it from there directly.

## `How to use?`
1) Drag and drop any ePub, PDF, or text file (or use the built-in text editor)
2) Configure the settings:
    - Set speech speed
    - Select a voice (or create a custom voice using voice mixer)
    - Select subtitle generation style (by sentence, word, etc.)
    - Select output format
    - Select where to save the output
3) Hit Start

## `In action`
&lt;img title=&quot;Abogen in action&quot; src=&#039;https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/abogen.gif&#039;&gt; 

Here’s Abogen in action: in this demo, it processes ∼3,000 characters of text in just 11 seconds and turns it into 3 minutes and 28 seconds of audio, and I have a low-end **RTX 2060 Mobile laptop GPU**. Your results may vary depending on your hardware.

## `Configuration`

| Options | Description |
|---------|-------------|
| **Input Box** | Drag and drop `ePub`, `PDF`, or `.TXT` files (or use built-in text editor) |
| **Queue options** | Add multiple files to a queue and process them in batch, with individual settings for each file. See [Queue mode](#queue-mode) for more details. |
| **Speed** | Adjust speech rate from `0.1x` to `2.0x` |
| **Select Voice** | First letter of the language code (e.g., `a` for American English, `b` for British English, etc.), second letter is for `m` for male and `f` for female. |
| **Voice mixer** | Create custom voices by mixing different voice models with a profile system. See [Voice Mixer](#voice-mixer) for more details. |
| **Voice preview** | Listen to the selected voice before processing. |
| **Generate subtitles** | `Disabled`, `Sentence`, `Sentence + Comma`, `1 word`, `2 words`, `3 words`, etc. (Represents the number of words in each subtitle entry) |
| **Output voice format** | `.WAV`, `.FLAC`, `.MP3`, `.OPUS (best compression)` and `M4B (with chapters)` (Special thanks to [@jborza](https://github.com/jborza) for chapter support in PR [#10](https://github.com/denizsafak/abogen/pull/10)) |
| **Output subtitle format** | Configures the subtitle format as `SRT (standard)`, `ASS (wide)`, `ASS (narrow)`, `ASS (centered wide)`, or `ASS (centered narrow)`. |
| **Replace single newlines with spaces** | Replaces single newlines with spaces in the text. This is useful for texts that have imaginary line breaks. |
| **Save location** | `Save next to input file`, `Save to desktop`, or `Choose output folder` |

| Book handler options | Description |
|---------|-------------|
| **Chapter Control** | Select specific `chapters` from ePUBs or `chapters + pages` from PDFs. |
| **Save each chapter separately** | Save each chapter in e-books as a separate audio file. |
| **Create a merged version** | Create a single audio file that combines all chapters. (If `Save each chapter separately` is disabled, this option will be the default behavior.) |
| **Save in a project folder with metadata** | Save the converted items in a project folder with available metadata files. |

| Menu options | Description |
|---------|-------------|
| **Theme** | Change the application&#039;s theme using `System`, `Light`, or `Dark` options. |
| **Configure max words per subtitle** | Configures the maximum number of words per subtitle entry. |
| **Configure max lines in log window** | Configures the maximum number of lines to display in the log window. |
| **Separate chapters audio format** | Configures the audio format for separate chapters as `wav`, `flac`, `mp3`, or `opus`. |
| **Create desktop shortcut** | Creates a shortcut on your desktop for easy access. |
| **Open config directory** | Opens the directory where the configuration file is stored. |
| **Open cache directory** | Opens the cache directory where converted text files are stored. |
| **Clear cache files** | Deletes cache files created during the conversion or preview. |
| **Check for updates at startup** | Automatically checks for updates when the program starts. |
| **Disable Kokoro&#039;s internet access** | Prevents Kokoro from downloading models or voices from HuggingFace Hub, useful for offline use. |
| **Reset to default settings** | Resets all settings to their default values. |

## `Voice Mixer`
&lt;img title=&quot;Abogen Voice Mixer&quot; src=&#039;https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/voice_mixer.png&#039;&gt;

With voice mixer, you can create custom voices by mixing different voice models. You can adjust the weight of each voice and save your custom voice as a profile for future use. The voice mixer allows you to create unique and personalized voices. (Huge thanks to [@jborza](https://github.com/jborza) for making this possible through his contributions in [#5](https://github.com/denizsafak/abogen/pull/5))

## `Queue Mode`
&lt;img title=&quot;Abogen queue mode&quot; src=&#039;https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/queue.png&#039;&gt;

Abogen supports **queue mode**, allowing you to add multiple files to a processing queue. This is useful if you want to convert several files in one batch.

- You can add text files (`.txt`) directly using the **Add files** button in the Queue Manager. To add PDF or EPUB files, use the input box in the main window and click the **Add to Queue** button.
- Each file in the queue keeps the configuration settings that were active when it was added. Changing the main window configuration afterward does **not** affect files already in the queue.
- You can view each file&#039;s configuration by hovering over them.

Abogen will process each item in the queue automatically, saving outputs as configured.
&gt; Special thanks to [@jborza](https://github.com/jborza) for adding queue mode in PR [#35](https://github.com/denizsafak/abogen/pull/35)

## `About Chapter Markers`
When you process ePUB or PDF files, Abogen converts them into text files stored in your cache directory. When you click &quot;Edit,&quot; you&#039;re actually modifying these converted text files. In these text files, you&#039;ll notice tags that look like this:

```
&lt;&lt;CHAPTER_MARKER:Chapter Title&gt;&gt;
```
These are chapter markers. They are automatically added when you process ePUB or PDF files, based on the chapters you select. They serve an important purpose:
-  Allow you to split the text into separate audio files for each chapter
-  Save time by letting you reprocess only specific chapters if errors occur, rather than the entire file

You can manually add these markers to plain text files for the same benefits. Simply include them in your text like this:

```
&lt;&lt;CHAPTER_MARKER:Introduction&gt;&gt;
This is the beginning of my text...  

&lt;&lt;CHAPTER_MARKER:Main Content&gt;&gt; 
Here&#039;s another part...  
```
When you process the text file, Abogen will detect these markers automatically and ask if you want to save each chapter separately and create a merged version.

![Abogen Chapter Marker](https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/chapter_marker.png)

## `About Metadata Tags`
Similar to chapter markers, it is possible to add metadata tags for `M4B` files. This is useful for audiobook players that support metadata, allowing you to add information like title, author, year, etc. Abogen automatically adds these tags when you process ePUB or PDF files, but you can also add them manually to your text files. Add metadata tags **at the beginning of your text file** like this:
```
&lt;&lt;METADATA_TITLE:Title&gt;&gt;
&lt;&lt;METADATA_ARTIST:Author&gt;&gt;
&lt;&lt;METADATA_ALBUM:Album Title&gt;&gt;
&lt;&lt;METADATA_YEAR:Year&gt;&gt;
&lt;&lt;METADATA_ALBUM_ARTIST:Album Artist&gt;&gt;
&lt;&lt;METADATA_COMPOSER:Narrator&gt;&gt;
&lt;&lt;METADATA_GENRE:Audiobook&gt;&gt;
```

## `Supported Languages`
```
# 🇺🇸 &#039;a&#039; =&gt; American English, 🇬🇧 &#039;b&#039; =&gt; British English
# 🇪🇸 &#039;e&#039; =&gt; Spanish es
# 🇫🇷 &#039;f&#039; =&gt; French fr-fr
# 🇮🇳 &#039;h&#039; =&gt; Hindi hi
# 🇮🇹 &#039;i&#039; =&gt; Italian it
# 🇯🇵 &#039;j&#039; =&gt; Japanese: pip install misaki[ja]
# 🇧🇷 &#039;p&#039; =&gt; Brazilian Portuguese pt-br
# 🇨🇳 &#039;z&#039; =&gt; Mandarin Chinese: pip install misaki[zh]
```
For a complete list of supported languages and voices, refer to Kokoro&#039;s [VOICES.md](https://huggingface.co/hexgrad/Kokoro-82M/blob/main/VOICES.md). To listen to sample audio outputs, see [SAMPLES.md](https://huggingface.co/hexgrad/Kokoro-82M/blob/main/SAMPLES.md).

## `MPV Config`
I highly recommend using [MPV](https://mpv.io/installation/) to play your audio files, as it supports displaying subtitles even without a video track. Here&#039;s my `mpv.conf`:
```
# --- MPV Settings ---
save-position-on-quit
keep-open=yes
# --- Subtitle ---
sub-ass-override=no
sub-margin-y=50
sub-margin-x=50
# --- Audio Quality ---
audio-spdif=ac3,dts,eac3,truehd,dts-hd
audio-channels=auto
audio-samplerate=48000
volume-max=200
```

## `Docker Guide`
If you want to run Abogen in a Docker container:
1) [Download the repository](https://github.com/denizsafak/abogen/archive/refs/heads/main.zip) and extract, or clone it using git.
2) Go to `abogen` folder. You should see `Dockerfile` there.
3) Open your termminal in that directory and run the following commands:

```bash
# Build the Docker image:
docker build --progress plain -t abogen .

# Note that building the image may take a while.
# After building is complete, run the Docker container:

# Windows
docker run --name abogen -v %cd%:/shared -p 5800:5800 -p 5900:5900 --gpus all abogen

# Linux
docker run --name abogen -v $(pwd):/shared -p 5800:5800 -p 5900:5900 --gpus all abogen

# MacOS
docker run --name abogen -v $(pwd):/shared -p 5800:5800 -p 5900:5900 abogen

# We expose port 5800 for use by a web browser, 5900 if you want to connect with a VNC client.
```

Abogen launches automatically inside the container. 
- You can access it via a web browser at [http://localhost:5800](http://localhost:5800) or connect to it using a VNC client at `localhost:5900`.
- You can use `/shared` directory to share files between your host and the container.
- For later use, start it with `docker start abogen` and stop it with `docker stop abogen`.

Known issues:
- Audio preview is not working inside container (ALSA error).
- `Open cache directory` and `Open configuration directory` options in settings not working. (Tried pcmanfm, did not work with Abogen).

(Special thanks to [@geo38](https://www.reddit.com/user/geo38/) from Reddit, who provided the Dockerfile and instructions in [this comment](https://www.reddit.com/r/selfhosted/comments/1k8x1yo/comment/mpe0bz8/).)

## `Similar Projects`
Abogen is a standalone project, but it is inspired by and shares some similarities with other projects. Here are a few:
- [audiblez](https://github.com/santinic/audiblez): Generate audiobooks from e-books. **(Has CLI and GUI support)**
- [autiobooks](https://github.com/plusuncold/autiobooks): Automatically convert epubs to audiobooks
- [pdf-narrator](https://github.com/mateogon/pdf-narrator): Convert your PDFs and EPUBs into audiobooks effortlessly.
- [epub_to_audiobook](https://github.com/p0n1/epub_to_audiobook): EPUB to audiobook converter, optimized for Audiobookshelf
- [ebook2audiobook](https://github.com/DrewThomasson/ebook2audiobook): Convert ebooks to audiobooks with chapters and metadata using dynamic AI models and voice cloning

## `Roadmap`
- [ ] Add OCR scan feature for PDF files using docling/teserract.
- [x] Add chapter metadata for .m4a files. (Issue [#9](https://github.com/denizsafak/abogen/issues/9), PR [#10](https://github.com/denizsafak/abogen/pull/10))
- [ ] Add support for different languages in GUI.
- [x] Add voice formula feature that enables mixing different voice models. (Issue [#1](https://github.com/denizsafak/abogen/issues/1), PR [#5](https://github.com/denizsafak/abogen/pull/5))
- [ ] Add support for kokoro-onnx (If it&#039;s necessary).
- [x] Add dark mode.

## `Troubleshooting`
If you encounter any issues while running Abogen, try launching it from the command line with:
```
abogen-cli
```
This will start Abogen in command-line mode and display detailed error messages. Please open a new issue on the [Issues](https://github.com/denizsafak/abogen/issues) page with the error message and a description of your problem.

## `Contributing`
I welcome contributions! If you have ideas for new features, improvements, or bug fixes, please fork the repository and submit a pull request.
### For developers and contributors
If you&#039;d like to modify the code and contribute to development, you can [download the repository](https://github.com/denizsafak/abogen/archive/refs/heads/main.zip), extract it and run the following commands to build **or** install the package:
```bash
# Go to the directory where you extracted the repository and run:
pip install -e .      # Installs the package in editable mode
pip install build     # Install the build package
python -m build       # Builds the package in dist folder (optional)
abogen                # Opens the GUI
```
Feel free to explore the code and make any changes you like.

## `Credits`
- Abogen uses [Kokoro](https://github.com/hexgrad/kokoro) for its high-quality, natural-sounding text-to-speech synthesis. Huge thanks to the Kokoro team for making this possible.
- Thanks to [@wojiushixiaobai](https://github.com/wojiushixiaobai) for [Embedded Python](https://github.com/wojiushixiaobai/Python-Embed-Win64) packages. These modified packages include pip pre-installed, enabling Abogen to function as a standalone application without requiring users to separately install Python in Windows.
- Thanks to creators of [EbookLib](https://github.com/aerkalov/ebooklib), a Python library for reading and writing ePub files, which is used for extracting text from ePub files.
- Special thanks to the [PyQt](https://www.riverbankcomputing.com/software/pyqt/) team for providing the cross-platform GUI toolkit that powers Abogen&#039;s interface.
- Icons: [US](https://icons8.com/icon/aRiu1GGi6Aoe/usa), [Great Britain](https://icons8.com/icon/t3NE3BsOAQwq/great-britain), [Spain](https://icons8.com/icon/ly7tzANRt33n/spain), [France](https://icons8.com/icon/3muzEmi4dpD5/france), [India](https://icons8.com/icon/esGVrxg9VCJ1/india), [Italy](https://icons8.com/icon/PW8KZnP7qXzO/italy), [Japan](https://icons8.com/icon/McQbrq9qaQye/japan), [Brazil](https://icons8.com/icon/zHmH8HpOmM90/brazil), [China](https://icons8.com/icon/Ej50Oe3crXwF/china), [Female](https://icons8.com/icon/uI49hxbpxTkp/female), [Male](https://icons8.com/icon/12351/male), [Adjust](https://icons8.com/icon/21698/adjust) and [Voice Id](https://icons8.com/icon/GskSeVoroQ7u/voice-id) icons by [Icons8](https://icons8.com/).

## `License`
This project is available under the MIT License - see the [LICENSE](https://github.com/denizsafak/abogen/blob/main/LICENSE) file for details.
[Kokoro](https://github.com/hexgrad/kokoro) is licensed under [Apache-2.0](https://github.com/hexgrad/kokoro/blob/main/LICENSE) which allows commercial use, modification, distribution, and private use.

&gt; [!IMPORTANT]
&gt; Subtitle generation currentl

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[searxng/searxng]]></title>
            <link>https://github.com/searxng/searxng</link>
            <guid>https://github.com/searxng/searxng</guid>
            <pubDate>Thu, 31 Jul 2025 00:04:28 GMT</pubDate>
            <description><![CDATA[SearXNG is a free internet metasearch engine which aggregates results from various search services and databases. Users are neither tracked nor profiled.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/searxng/searxng">searxng/searxng</a></h1>
            <p>SearXNG is a free internet metasearch engine which aggregates results from various search services and databases. Users are neither tracked nor profiled.</p>
            <p>Language: Python</p>
            <p>Stars: 20,774</p>
            <p>Forks: 2,112</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[kijai/ComfyUI-WanVideoWrapper]]></title>
            <link>https://github.com/kijai/ComfyUI-WanVideoWrapper</link>
            <guid>https://github.com/kijai/ComfyUI-WanVideoWrapper</guid>
            <pubDate>Thu, 31 Jul 2025 00:04:27 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kijai/ComfyUI-WanVideoWrapper">kijai/ComfyUI-WanVideoWrapper</a></h1>
            <p></p>
            <p>Language: Python</p>
            <p>Stars: 3,517</p>
            <p>Forks: 263</p>
            <p>Stars today: 32 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[dgtlmoon/changedetection.io]]></title>
            <link>https://github.com/dgtlmoon/changedetection.io</link>
            <guid>https://github.com/dgtlmoon/changedetection.io</guid>
            <pubDate>Thu, 31 Jul 2025 00:04:26 GMT</pubDate>
            <description><![CDATA[Best and simplest tool for website change detection, web page monitoring, and website change alerts. Perfect for tracking content changes, price drops, restock alerts, and website defacement monitoring—all for free or enjoy our SaaS plan!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dgtlmoon/changedetection.io">dgtlmoon/changedetection.io</a></h1>
            <p>Best and simplest tool for website change detection, web page monitoring, and website change alerts. Perfect for tracking content changes, price drops, restock alerts, and website defacement monitoring—all for free or enjoy our SaaS plan!</p>
            <p>Language: Python</p>
            <p>Stars: 25,737</p>
            <p>Forks: 1,415</p>
            <p>Stars today: 64 stars today</p>
            <h2>README</h2><pre># Detect Website Changes Automatically — Monitor Web Page Changes in Real Time

Monitor websites for updates — get notified via Discord, Email, Slack, Telegram, Webhook and many more.

**Detect web page content changes and get instant alerts.**  

Ideal for monitoring price changes, content edits, conditional changes and more.


[&lt;img src=&quot;https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/screenshot.png&quot; style=&quot;max-width:100%;&quot; alt=&quot;Web site page change monitoring&quot;  title=&quot;Web site page change monitoring&quot;  /&gt;](https://changedetection.io?src=github)

[![Release Version][release-shield]][release-link] [![Docker Pulls][docker-pulls]][docker-link] [![License][license-shield]](LICENSE.md)

![changedetection.io](https://github.com/dgtlmoon/changedetection.io/actions/workflows/test-only.yml/badge.svg?branch=master)

[**Get started with website page change monitoring straight away. Don&#039;t have time? Try our $8.99/month subscription, use our proxies and support!**](https://changedetection.io) , _half the price of other website change monitoring services!_


- Chrome browser included.
- Nothing to install, access via browser login after signup.
- Super fast, no registration needed setup.
- Get started watching and receiving website change notifications straight away.
- See our [tutorials and how-to page for more inspiration](https://changedetection.io/tutorials) 

### Target specific parts of the webpage using the Visual Selector tool.

Available when connected to a &lt;a href=&quot;https://github.com/dgtlmoon/changedetection.io/wiki/Playwright-content-fetcher&quot;&gt;playwright content fetcher&lt;/a&gt; (included as part of our subscription service)

[&lt;img src=&quot;https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/visualselector-anim.gif&quot; style=&quot;max-width:100%;&quot; alt=&quot;Select parts and elements of a web page to monitor for changes&quot;  title=&quot;Select parts and elements of a web page to monitor for changes&quot; /&gt;](https://changedetection.io?src=github)

### Easily see what changed, examine by word, line, or individual character.

[&lt;img src=&quot;https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/screenshot-diff.png&quot; style=&quot;max-width:100%;&quot; alt=&quot;Self-hosted web page change monitoring context difference &quot;  title=&quot;Self-hosted web page change monitoring context difference &quot; /&gt;](https://changedetection.io?src=github)


### Perform interactive browser steps

Fill in text boxes, click buttons and more, setup your changedetection scenario. 

Using the **Browser Steps** configuration, add basic steps before performing change detection, such as logging into websites, adding a product to a cart, accept cookie logins, entering dates and refining searches.

[&lt;img src=&quot;docs/browsersteps-anim.gif&quot; style=&quot;max-width:100%;&quot; alt=&quot;Website change detection with interactive browser steps, detect changes behind login and password, search queries and more&quot;  title=&quot;Website change detection with interactive browser steps, detect changes behind login and password, search queries and more&quot; /&gt;](https://changedetection.io?src=github)

After **Browser Steps** have been run, then visit the **Visual Selector** tab to refine the content you&#039;re interested in.
Requires Playwright to be enabled.

### Awesome restock and price change notifications

Enable the _&quot;Re-stock &amp; Price detection for single product pages&quot;_ option to activate the best way to monitor product pricing, this will extract any meta-data in the HTML page and give you many options to follow the pricing of the product.

Easily organise and monitor prices for products from the dashboard, get alerts and notifications when the price of a product changes or comes back in stock again!

[&lt;img src=&quot;docs/restock-overview.png&quot; style=&quot;max-width:100%;&quot; alt=&quot;Easily keep an eye on product price changes directly from the UI&quot;  title=&quot;Easily keep an eye on product price changes directly from the UI&quot; /&gt;](https://changedetection.io?src=github)

Set price change notification parameters, upper and lower price, price change percentage and more.
Always know when a product for sale drops in price.

[&lt;img src=&quot;docs/restock-settings.png&quot; style=&quot;max-width:100%;&quot; alt=&quot;Set upper lower and percentage price change notification values&quot;  title=&quot;Set upper lower and percentage price change notification values&quot; /&gt;](https://changedetection.io?src=github)



### Example use cases

- Products and services have a change in pricing
- _Out of stock notification_ and _Back In stock notification_
- Monitor and track PDF file changes, know when a PDF file has text changes.
- Governmental department updates (changes are often only on their websites)
- New software releases, security advisories when you&#039;re not on their mailing list.
- Festivals with changes
- Discogs restock alerts and monitoring
- Realestate listing changes
- Know when your favourite whiskey is on sale, or other special deals are announced before anyone else
- COVID related news from government websites
- University/organisation news from their website
- Detect and monitor changes in JSON API responses 
- JSON API monitoring and alerting
- Changes in legal and other documents
- Trigger API calls via notifications when text appears on a website
- Glue together APIs using the JSON filter and JSON notifications
- Create RSS feeds based on changes in web content
- Monitor HTML source code for unexpected changes, strengthen your PCI compliance
- You have a very sensitive list of URLs to watch and you do _not_ want to use the paid alternatives. (Remember, _you_ are the product)
- Get notified when certain keywords appear in Twitter search results
- Proactively search for jobs, get notified when companies update their careers page, search job portals for keywords.
- Get alerts when new job positions are open on Bamboo HR and other job platforms
- Website defacement monitoring
- Pokémon Card Restock Tracker / Pokémon TCG Tracker
- RegTech - stay ahead of regulatory changes, regulatory compliance

_Need an actual Chrome runner with Javascript support? We support fetching via WebDriver and Playwright!&lt;/a&gt;_

#### Key Features

- Lots of trigger filters, such as &quot;Trigger on text&quot;, &quot;Remove text by selector&quot;, &quot;Ignore text&quot;, &quot;Extract text&quot;, also using regular-expressions!
- Target elements with xPath 1 and xPath 2, CSS Selectors, Easily monitor complex JSON with JSONPath or jq
- Switch between fast non-JS and Chrome JS based &quot;fetchers&quot;
- Track changes in PDF files (Monitor text changed in the PDF, Also monitor PDF filesize and checksums)
- Easily specify how often a site should be checked
- Execute JS before extracting text (Good for logging in, see examples in the UI!)
- Override Request Headers, Specify `POST` or `GET` and other methods
- Use the &quot;Visual Selector&quot; to help target specific elements
- Configurable [proxy per watch](https://github.com/dgtlmoon/changedetection.io/wiki/Proxy-configuration)
- Send a screenshot with the notification when a change is detected in the web page

We [recommend and use Bright Data](https://brightdata.grsm.io/n0r16zf7eivq) global proxy services, Bright Data will match any first deposit up to $150 using our signup link.

Please :star: star :star: this project and help it grow! https://github.com/dgtlmoon/changedetection.io/

### Conditional web page changes

Easily [configure conditional actions](https://changedetection.io/tutorial/conditional-actions-web-page-changes), for example, only trigger when a price is above or below a preset amount, or [when a web page includes (or does not include) a keyword](https://changedetection.io/tutorial/how-monitor-keywords-any-website)

&lt;img src=&quot;./docs/web-page-change-conditions.png&quot; style=&quot;max-width:80%;&quot; alt=&quot;Conditional web page changes&quot;  title=&quot;Conditional web page changes&quot;  /&gt;

### Schedule web page watches in any timezone, limit by day of week and time.

Easily set a re-check schedule, for example you could limit the web page change detection to only operate during business hours.
Or perhaps based on a foreign timezone (for example, you want to check for the latest news-headlines in a foreign country at 0900 AM),

&lt;img src=&quot;./docs/scheduler.png&quot; style=&quot;max-width:80%;&quot; alt=&quot;How to monitor web page changes according to a schedule&quot;  title=&quot;How to monitor web page changes according to a schedule&quot;  /&gt;

Includes quick short-cut buttons to setup a schedule for **business hours only**, or **weekends**.

### We have a Chrome extension!

Easily add the current web page to your changedetection.io tool, simply install the extension and click &quot;Sync&quot; to connect it to your existing changedetection.io install.

[&lt;img src=&quot;./docs/chrome-extension-screenshot.png&quot; style=&quot;max-width:80%;&quot; alt=&quot;Chrome Extension to easily add the current web-page to detect a change.&quot;  title=&quot;Chrome Extension to easily add the current web-page to detect a change.&quot;  /&gt;](https://chromewebstore.google.com/detail/changedetectionio-website/kefcfmgmlhmankjmnbijimhofdjekbop)

[Goto the Chrome Webstore to download the extension.](https://chromewebstore.google.com/detail/changedetectionio-website/kefcfmgmlhmankjmnbijimhofdjekbop) ( Or check out the [GitHub repo](https://github.com/dgtlmoon/changedetection.io-browser-extension) ) 

## Installation

### Docker

With Docker composer, just clone this repository and..

```bash
$ docker compose up -d
```

Docker standalone
```bash
$ docker run -d --restart always -p &quot;127.0.0.1:5000:5000&quot; -v datastore-volume:/datastore --name changedetection.io dgtlmoon/changedetection.io
```

`:latest` tag is our latest stable release, `:dev` tag is our bleeding edge `master` branch.

Alternative docker repository over at ghcr - [ghcr.io/dgtlmoon/changedetection.io](https://ghcr.io/dgtlmoon/changedetection.io)

### Windows

See the install instructions at the wiki https://github.com/dgtlmoon/changedetection.io/wiki/Microsoft-Windows

### Python Pip

Check out our pypi page https://pypi.org/project/changedetection.io/

```bash
$ pip3 install changedetection.io
$ changedetection.io -d /path/to/empty/data/dir -p 5000
```

Then visit http://127.0.0.1:5000 , You should now be able to access the UI.

_Now with per-site configurable support for using a fast built in HTTP fetcher or use a Chrome based fetcher for monitoring of JavaScript websites!_

## Updating changedetection.io

### Docker
```
docker pull dgtlmoon/changedetection.io
docker kill $(docker ps -a -f name=changedetection.io -q)
docker rm $(docker ps -a -f name=changedetection.io -q)
docker run -d --restart always -p &quot;127.0.0.1:5000:5000&quot; -v datastore-volume:/datastore --name changedetection.io dgtlmoon/changedetection.io
```

### docker compose

```bash
docker compose pull &amp;&amp; docker compose up -d
```

See the wiki for more information https://github.com/dgtlmoon/changedetection.io/wiki


## Filters

XPath(1.0), JSONPath, jq, and CSS support comes baked in! You can be as specific as you need, use XPath exported from various XPath element query creation tools. 
(We support LXML `re:test`, `re:match` and `re:replace`.)

## Notifications

ChangeDetection.io supports a massive amount of notifications (including email, office365, custom APIs, etc) when a web-page has a change detected thanks to the &lt;a href=&quot;https://github.com/caronc/apprise&quot;&gt;apprise&lt;/a&gt; library.
Simply set one or more notification URL&#039;s in the _[edit]_ tab of that watch.

Just some examples

    discord://webhook_id/webhook_token
    flock://app_token/g:channel_id
    gitter://token/room
    gchat://workspace/key/token
    msteams://TokenA/TokenB/TokenC/
    o365://TenantID:AccountEmail/ClientID/ClientSecret/TargetEmail
    rocket://user:password@hostname/#Channel
    mailto://user:pass@example.com?to=receivingAddress@example.com
    json://someserver.com/custom-api
    syslog://
 
&lt;a href=&quot;https://github.com/caronc/apprise#popular-notification-services&quot;&gt;And everything else in this list!&lt;/a&gt;

&lt;img src=&quot;https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/screenshot-notifications.png&quot; style=&quot;max-width:100%;&quot; alt=&quot;Self-hosted web page change monitoring notifications&quot;  title=&quot;Self-hosted web page change monitoring notifications&quot;  /&gt;

Now you can also customise your notification content and use &lt;a target=&quot;_new&quot; href=&quot;https://jinja.palletsprojects.com/en/3.0.x/templates/&quot;&gt;Jinja2 templating&lt;/a&gt; for their title and body!

## JSON API Monitoring

Detect changes and monitor data in JSON API&#039;s by using either JSONPath or jq to filter, parse, and restructure JSON as needed.

![image](https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/json-filter-field-example.png)

This will re-parse the JSON and apply formatting to the text, making it super easy to monitor and detect changes in JSON API results

![image](https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/json-diff-example.png)

### JSONPath or jq?

For more complex parsing, filtering, and modifying of JSON data, jq is recommended due to the built-in operators and functions. Refer to the [documentation](https://stedolan.github.io/jq/manual/) for more specific information on jq.

One big advantage of `jq` is that you can use logic in your JSON filter, such as filters to only show items that have a value greater than/less than etc.

See the wiki https://github.com/dgtlmoon/changedetection.io/wiki/JSON-Selector-Filter-help for more information and examples

### Parse JSON embedded in HTML!

When you enable a `json:` or `jq:` filter, you can even automatically extract and parse embedded JSON inside a HTML page! Amazingly handy for sites that build content based on JSON, such as many e-commerce websites. 

```
&lt;html&gt;
...
&lt;script type=&quot;application/ld+json&quot;&gt;

{
   &quot;@context&quot;:&quot;http://schema.org/&quot;,
   &quot;@type&quot;:&quot;Product&quot;,
   &quot;offers&quot;:{
      &quot;@type&quot;:&quot;Offer&quot;,
      &quot;availability&quot;:&quot;http://schema.org/InStock&quot;,
      &quot;price&quot;:&quot;3949.99&quot;,
      &quot;priceCurrency&quot;:&quot;USD&quot;,
      &quot;url&quot;:&quot;https://www.newegg.com/p/3D5-000D-001T1&quot;
   },
   &quot;description&quot;:&quot;Cobratype King Cobra Hero Desktop Gaming PC&quot;,
   &quot;name&quot;:&quot;Cobratype King Cobra Hero Desktop Gaming PC&quot;,
   &quot;sku&quot;:&quot;3D5-000D-001T1&quot;,
   &quot;itemCondition&quot;:&quot;NewCondition&quot;
}
&lt;/script&gt;
```  

`json:$..price` or `jq:..price` would give `3949.99`, or you can extract the whole structure (use a JSONpath test website to validate with)

The application also supports notifying you that it can follow this information automatically


## Proxy Configuration

See the wiki https://github.com/dgtlmoon/changedetection.io/wiki/Proxy-configuration , we also support using [Bright Data proxy services where possible](https://github.com/dgtlmoon/changedetection.io/wiki/Proxy-configuration#brightdata-proxy-support) and [Oxylabs](https://oxylabs.go2cloud.org/SH2d) proxy services.

## Raspberry Pi support?

Raspberry Pi and linux/arm/v6 linux/arm/v7 arm64 devices are supported! See the wiki for [details](https://github.com/dgtlmoon/changedetection.io/wiki/Fetching-pages-with-WebDriver)

## Import support

Easily [import your list of websites to watch for changes in Excel .xslx file format](https://changedetection.io/tutorial/how-import-your-website-change-detection-lists-excel), or paste in lists of website URLs as plaintext. 

Excel import is recommended - that way you can better organise tags/groups of websites and other features.


## API Support

Supports managing the website watch list [via our API](https://changedetection.io/docs/api_v1/index.html)

## Support us

Do you use changedetection.io to make money? does it save you time or money? Does it make your life easier? less stressful? Remember, we write this software when we should be doing actual paid work, we have to buy food and pay rent just like you.


Consider taking out an officially supported [website change detection subscription](https://changedetection.io?src=github) , even if you don&#039;t use it, you still get the warm fuzzy feeling of helping out the project. (And who knows, you might just use it!)

## Commercial Support

I offer commercial support, this software is depended on by network security, aerospace , data-science and data-journalist professionals just to name a few, please reach out at dgtlmoon@gmail.com for any enquiries, I am more than glad to work with your organisation to further the possibilities of what can be done with changedetection.io


[release-shield]: https://img.shields.io:/github/v/release/dgtlmoon/changedetection.io?style=for-the-badge
[docker-pulls]: https://img.shields.io/docker/pulls/dgtlmoon/changedetection.io?style=for-the-badge
[test-shield]: https://github.com/dgtlmoon/changedetection.io/actions/workflows/test-only.yml/badge.svg?branch=master

[license-shield]: https://img.shields.io/github/license/dgtlmoon/changedetection.io.svg?style=for-the-badge
[release-link]: https://github.com/dgtlmoon/changedetection.io/releases
[docker-link]: https://hub.docker.com/r/dgtlmoon/changedetection.io

## Commercial Licencing

If you are reselling this software either in part or full as part of any commercial arrangement, you must abide by our COMMERCIAL_LICENCE.md found in our code repository, please contact dgtlmoon@gmail.com and contact@changedetection.io .

## Third-party licenses

changedetectionio.html_tools.elementpath_tostring: Copyright (c), 2018-2021, SISSA (Scuola Internazionale Superiore di Studi Avanzati), Licensed under [MIT license](https://github.com/sissaschool/elementpath/blob/master/LICENSE)

## Contributors

Recognition of fantastic contributors to the project

- Constantin Hong https://github.com/Constantin1489
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>