<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Sun, 09 Nov 2025 00:04:33 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[usestrix/strix]]></title>
            <link>https://github.com/usestrix/strix</link>
            <guid>https://github.com/usestrix/strix</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:33 GMT</pubDate>
            <description><![CDATA[âœ¨ Open-source AI hackers for your apps ğŸ‘¨ğŸ»â€ğŸ’»]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/usestrix/strix">usestrix/strix</a></h1>
            <p>âœ¨ Open-source AI hackers for your apps ğŸ‘¨ğŸ»â€ğŸ’»</p>
            <p>Language: Python</p>
            <p>Stars: 4,676</p>
            <p>Forks: 516</p>
            <p>Stars today: 593 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://usestrix.com/&quot;&gt;
    &lt;img src=&quot;.github/logo.png&quot; width=&quot;150&quot; alt=&quot;Strix Logo&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;
Strix
&lt;/h1&gt;

&lt;h2 align=&quot;center&quot;&gt;Open-source AI Hackers to secure your Apps&lt;/h2&gt;

&lt;div align=&quot;center&quot;&gt;

[![Python](https://img.shields.io/pypi/pyversions/strix-agent?color=3776AB)](https://pypi.org/project/strix-agent/)
[![PyPI](https://img.shields.io/pypi/v/strix-agent?color=10b981)](https://pypi.org/project/strix-agent/)
[![PyPI Downloads](https://static.pepy.tech/personalized-badge/strix-agent?period=total&amp;units=INTERNATIONAL_SYSTEM&amp;left_color=GREY&amp;right_color=RED&amp;left_text=Downloads)](https://pepy.tech/projects/strix-agent)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)

[![GitHub Stars](https://img.shields.io/github/stars/usestrix/strix)](https://github.com/usestrix/strix)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?&amp;logo=discord&amp;logoColor=white)](https://discord.gg/YjKFvEZSdZ)
[![Website](https://img.shields.io/badge/Website-usestrix.com-2d3748.svg)](https://usestrix.com)

&lt;a href=&quot;https://trendshift.io/repositories/15362&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15362&quot; alt=&quot;usestrix%2Fstrix | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

:star: _Love Strix? Give us a star to help other developers discover it!_

&lt;br /&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;.github/screenshot.png&quot; alt=&quot;Strix Demo&quot; width=&quot;800&quot; style=&quot;border-radius: 16px; box-shadow: 0 20px 40px rgba(0, 0, 0, 0.3), 0 0 0 1px rgba(255, 255, 255, 0.1), inset 0 1px 0 rgba(255, 255, 255, 0.2); transform: perspective(1000px) rotateX(2deg); transition: transform 0.3s ease;&quot;&gt;
&lt;/div&gt;

&gt; [!TIP]
&gt; **New!** Strix now integrates seamlessly with GitHub Actions and CI/CD pipelines. Automatically scan for vulnerabilities on every pull request and block insecure code before it reaches production!

---

## ğŸ¦‰ Strix Overview

Strix are autonomous AI agents that act just like real hackers - they run your code dynamically, find vulnerabilities, and validate them through actual proof-of-concepts. Built for developers and security teams who need fast, accurate security testing without the overhead of manual pentesting or the false positives of static analysis tools.

- **Full hacker toolkit** out of the box
- **Teams of agents** that collaborate and scale
- **Real validation** with PoCs, not false positives
- **Developerâ€‘first** CLI with actionable reports
- **Autoâ€‘fix &amp; reporting** to accelerate remediation

---

### ğŸ¯ Use Cases

- Detect and validate critical vulnerabilities in your applications.
- Get penetration tests done in hours, not weeks, with compliance reports.
- Automate bug bounty research and generate PoCs for faster reporting.
- Run tests in CI/CD to block vulnerabilities before reaching production.

---

### ğŸš€ Quick Start

Prerequisites:
- Docker (running)
- Python 3.12+
- An LLM provider key (or a local LLM)

```bash
# Install
pipx install strix-agent

# Configure AI provider
export STRIX_LLM=&quot;openai/gpt-5&quot;
export LLM_API_KEY=&quot;your-api-key&quot;

# Run security assessment
strix --target ./app-directory
```

First run pulls the sandbox Docker image. Results are saved under `agent_runs/&lt;run-name&gt;`.

### â˜ï¸ Cloud Hosted

Want to skip the setup? Try our cloud-hosted version: **[usestrix.com](https://usestrix.com)**

## âœ¨ Features

### ğŸ› ï¸ Agentic Security Tools

- **ğŸ”Œ Full HTTP Proxy** - Full request/response manipulation and analysis
- **ğŸŒ Browser Automation** - Multi-tab browser for testing of XSS, CSRF, auth flows
- **ğŸ’» Terminal Environments** - Interactive shells for command execution and testing
- **ğŸ Python Runtime** - Custom exploit development and validation
- **ğŸ” Reconnaissance** - Automated OSINT and attack surface mapping
- **ğŸ“ Code Analysis** - Static and dynamic analysis capabilities
- **ğŸ“ Knowledge Management** - Structured findings and attack documentation

### ğŸ¯ Comprehensive Vulnerability Detection

- **Access Control** - IDOR, privilege escalation, auth bypass
- **Injection Attacks** - SQL, NoSQL, command injection
- **Server-Side** - SSRF, XXE, deserialization flaws
- **Client-Side** - XSS, prototype pollution, DOM vulnerabilities
- **Business Logic** - Race conditions, workflow manipulation
- **Authentication** - JWT vulnerabilities, session management
- **Infrastructure** - Misconfigurations, exposed services

### ğŸ•¸ï¸ Graph of Agents

- **Distributed Workflows** - Specialized agents for different attacks and assets
- **Scalable Testing** - Parallel execution for fast comprehensive coverage
- **Dynamic Coordination** - Agents collaborate and share discoveries


## ğŸ’» Usage Examples

```bash
# Local codebase analysis
strix --target ./app-directory

# Repository security review
strix --target https://github.com/org/repo

# Web application assessment
strix --target https://your-app.com

# Multi-target white-box testing (source code + deployed app)
strix -t https://github.com/org/app -t https://your-app.com

# Test multiple environments simultaneously
strix -t https://dev.your-app.com -t https://staging.your-app.com -t https://prod.your-app.com

# Focused testing with instructions
strix --target api.your-app.com --instruction &quot;Prioritize authentication and authorization testing&quot;

# Testing with credentials
strix --target https://your-app.com --instruction &quot;Test with credentials: testuser/testpass. Focus on privilege escalation and access control bypasses.&quot;
```

### âš™ï¸ Configuration

```bash
export STRIX_LLM=&quot;openai/gpt-5&quot;
export LLM_API_KEY=&quot;your-api-key&quot;

# Optional
export LLM_API_BASE=&quot;your-api-base-url&quot;  # if using a local model, e.g. Ollama, LMStudio
export PERPLEXITY_API_KEY=&quot;your-api-key&quot;  # for search capabilities
```

[ğŸ“š View supported AI models](https://docs.litellm.ai/docs/providers)

### ğŸ¤– Headless Mode

Run Strix programmatically without interactive UI using the `-n/--non-interactive` flagâ€”perfect for servers and automated jobs. The CLI prints real-time vulnerability findings, and the final report before exiting. Exits with non-zero code when vulnerabilities are found.

```bash
strix -n --target https://your-app.com --instruction &quot;Focus on authentication and authorization vulnerabilities&quot;
```

### ğŸ”„ CI/CD (GitHub Actions)

Strix can be added to your pipeline to run a security test on pull requests with a lightweight GitHub Actions workflow:

```yaml
name: strix-penetration-test

on:
  pull_request:

jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Strix
        run: pipx install strix-agent

      - name: Run Strix
        env:
          STRIX_LLM: ${{ secrets.STRIX_LLM }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}

        run: strix -n -t ./
```

## ğŸ† Enterprise Platform

Our managed platform provides:

- **ğŸ“ˆ Executive Dashboards**
- **ğŸ§  Custom Fine-Tuned Models**
- **âš™ï¸ CI/CD Integration**
- **ğŸ” Large-Scale Scanning**
- **ğŸ”Œ Third-Party Integrations**
- **ğŸ¯ Enterprise Support**

[**Get Enterprise Demo â†’**](https://usestrix.com)

## ğŸ”’ Security Architecture

- **Container Isolation** - All testing in sandboxed Docker environments
- **Local Processing** - Testing runs locally, no data sent to external services

&gt; [!WARNING]
&gt; Only test systems you own or have permission to test. You are responsible for using Strix ethically and legally.

## ğŸ¤ Contributing

We welcome contributions from the community! There are several ways to contribute:

### Code Contributions
See our [Contributing Guide](CONTRIBUTING.md) for details on:
- Setting up your development environment
- Running tests and quality checks
- Submitting pull requests
- Code style guidelines

### Prompt Modules Collection
Help expand our collection of specialized prompt modules for AI agents:
- Advanced testing techniques for vulnerabilities, frameworks, and technologies
- See [Prompt Modules Documentation](strix/prompts/README.md) for guidelines
- Submit via [pull requests](https://github.com/usestrix/strix/pulls) or [issues](https://github.com/usestrix/strix/issues)

## ğŸŒŸ Support the Project

**Love Strix?** Give us a â­ on GitHub!

## ğŸ‘¥ Join Our Community

Have questions? Found a bug? Want to contribute? **[Join our Discord!](https://discord.gg/YjKFvEZSdZ)**

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[localstack/localstack]]></title>
            <link>https://github.com/localstack/localstack</link>
            <guid>https://github.com/localstack/localstack</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:32 GMT</pubDate>
            <description><![CDATA[ğŸ’» A fully functional local AWS cloud stack. Develop and test your cloud & Serverless apps offline]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/localstack/localstack">localstack/localstack</a></h1>
            <p>ğŸ’» A fully functional local AWS cloud stack. Develop and test your cloud & Serverless apps offline</p>
            <p>Language: Python</p>
            <p>Stars: 62,574</p>
            <p>Forks: 4,380</p>
            <p>Stars today: 139 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
:zap: We are thrilled to announce the release of &lt;a href=&quot;https://blog.localstack.cloud/localstack-for-aws-release-v-4-9-0/&quot;&gt;LocalStack 4.9&lt;/a&gt; :zap:
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;docs/localstack-readme-banner.svg&quot; alt=&quot;LocalStack - The Leading Platform for Local Cloud Development&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/localstack/localstack/actions/workflows/aws-main.yml?query=branch%3Amain&quot;&gt;&lt;img alt=&quot;GitHub Actions&quot; src=&quot;https://github.com/localstack/localstack/actions/workflows/aws-main.yml/badge.svg?branch=main&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://coveralls.io/github/localstack/localstack?branch=main&quot;&gt;&lt;img alt=&quot;Coverage Status&quot; src=&quot;https://coveralls.io/repos/github/localstack/localstack/badge.svg?branch=main&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://pypi.org/project/localstack/&quot;&gt;&lt;img alt=&quot;PyPI Version&quot; src=&quot;https://img.shields.io/pypi/v/localstack?color=blue&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://hub.docker.com/r/localstack/localstack&quot;&gt;&lt;img alt=&quot;Docker Pulls&quot; src=&quot;https://img.shields.io/docker/pulls/localstack/localstack&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://pypi.org/project/localstack&quot;&gt;&lt;img alt=&quot;PyPi downloads&quot; src=&quot;https://static.pepy.tech/badge/localstack&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;#backers&quot;&gt;&lt;img alt=&quot;Backers on Open Collective&quot; src=&quot;https://opencollective.com/localstack/backers/badge.svg&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;#sponsors&quot;&gt;&lt;img alt=&quot;Sponsors on Open Collective&quot; src=&quot;https://opencollective.com/localstack/sponsors/badge.svg&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://img.shields.io/pypi/l/localstack.svg&quot;&gt;&lt;img alt=&quot;PyPI License&quot; src=&quot;https://img.shields.io/pypi/l/localstack.svg&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/psf/black&quot;&gt;&lt;img alt=&quot;Code style: black&quot; src=&quot;https://img.shields.io/badge/code%20style-black-000000.svg&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/astral-sh/ruff&quot;&gt;&lt;img alt=&quot;Ruff&quot; src=&quot;https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://bsky.app/profile/localstack.cloud&quot;&gt;&lt;img alt=&quot;Bluesky&quot; src=&quot;https://img.shields.io/badge/bluesky-Follow-blue?logo=bluesky&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  LocalStack is a cloud software development framework to develop and test your AWS applications locally.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;#overview&quot;&gt;Overview&lt;/a&gt; â€¢
  &lt;a href=&quot;#install&quot;&gt;Install&lt;/a&gt; â€¢
  &lt;a href=&quot;#quickstart&quot;&gt;Quickstart&lt;/a&gt; â€¢
  &lt;a href=&quot;#running&quot;&gt;Run&lt;/a&gt; â€¢
  &lt;a href=&quot;#usage&quot;&gt;Usage&lt;/a&gt; â€¢
  &lt;a href=&quot;#releases&quot;&gt;Releases&lt;/a&gt; â€¢
  &lt;a href=&quot;#contributing&quot;&gt;Contributing&lt;/a&gt;
  &lt;br/&gt;
  &lt;a href=&quot;https://docs.localstack.cloud&quot; target=&quot;_blank&quot;&gt;ğŸ“– Docs&lt;/a&gt; â€¢
  &lt;a href=&quot;https://app.localstack.cloud&quot; target=&quot;_blank&quot;&gt;ğŸ’» Pro version&lt;/a&gt; â€¢
  &lt;a href=&quot;https://docs.localstack.cloud/references/coverage/&quot; target=&quot;_blank&quot;&gt;â˜‘ï¸ LocalStack coverage&lt;/a&gt;
&lt;/p&gt;

---

# Overview

[LocalStack](https://localstack.cloud) is a cloud service emulator that runs in a single container on your laptop or in your CI environment. With LocalStack, you can run your AWS applications or Lambdas entirely on your local machine without connecting to a remote cloud provider! Whether you are testing complex CDK applications or Terraform configurations, or just beginning to learn about AWS services, LocalStack helps speed up and simplify your testing and development workflow.

LocalStack supports a growing number of AWS services, like AWS Lambda, S3, DynamoDB, Kinesis, SQS, SNS, and many more! The [Pro version of LocalStack](https://localstack.cloud/pricing) supports additional APIs and advanced features. You can find a comprehensive list of supported APIs on our [â˜‘ï¸ Feature Coverage](https://docs.localstack.cloud/user-guide/aws/feature-coverage/) page.

LocalStack also provides additional features to make your life as a cloud developer easier! Check out LocalStack&#039;s [User Guides](https://docs.localstack.cloud/user-guide/) for more information.

## Install

The quickest way to get started with LocalStack is by using the LocalStack CLI. It enables you to start and manage the LocalStack Docker container directly through your command line. Ensure that your machine has a functional [`docker` environment](https://docs.docker.com/get-docker/) installed before proceeding.

### Brew (macOS or Linux with Homebrew)

Install the LocalStack CLI through our [official LocalStack Brew Tap](https://github.com/localstack/homebrew-tap):

```bash
brew install localstack/tap/localstack-cli
```

### Binary download (macOS, Linux, Windows)

If Brew is not installed on your machine, you can download the pre-built LocalStack CLI binary directly:

- Visit [localstack/localstack-cli](https://github.com/localstack/localstack-cli/releases/latest) and download the latest release for your platform.
- Extract the downloaded archive to a directory included in your `PATH` variable:
    -   For macOS/Linux, use the command: `sudo tar xvzf ~/Downloads/localstack-cli-*-darwin-*-onefile.tar.gz -C /usr/local/bin`

### PyPI (macOS, Linux, Windows)

LocalStack is developed using Python. To install the LocalStack CLI using `pip`, run the following command:

```bash
python3 -m pip install localstack
```

The `localstack-cli` installation enables you to run the Docker image containing the LocalStack runtime. To interact with the local AWS services, you need to install the `awslocal` CLI separately. For installation guidelines, refer to the [`awslocal` documentation](https://docs.localstack.cloud/user-guide/integrations/aws-cli/#localstack-aws-cli-awslocal).

&gt; **Important**: Do not use `sudo` or run as `root` user. LocalStack must be installed and started entirely under a local non-root user. If you have problems with permissions in macOS High Sierra, install with `pip install --user localstack`

## Quickstart

Start LocalStack inside a Docker container by running:

```bash
 % localstack start -d

     __                     _______ __             __
    / /   ____  _________ _/ / ___// /_____ ______/ /__
   / /   / __ \/ ___/ __ `/ /\__ \/ __/ __ `/ ___/ //_/
  / /___/ /_/ / /__/ /_/ / /___/ / /_/ /_/ / /__/ ,&lt;
 /_____/\____/\___/\__,_/_//____/\__/\__,_/\___/_/|_|

- LocalStack CLI: 4.9.0
- Profile: default
- App: https://app.localstack.cloud

[17:00:15] starting LocalStack in Docker mode ğŸ³               localstack.py:512
           preparing environment                               bootstrap.py:1322
           configuring container                               bootstrap.py:1330
           starting container                                  bootstrap.py:1340
[17:00:16] detaching                                           bootstrap.py:1344
```

You can query the status of respective services on LocalStack by running:

```bash
% localstack status services
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Service                  â”ƒ Status      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ acm                      â”‚ âœ” available â”‚
â”‚ apigateway               â”‚ âœ” available â”‚
â”‚ cloudformation           â”‚ âœ” available â”‚
â”‚ cloudwatch               â”‚ âœ” available â”‚
â”‚ config                   â”‚ âœ” available â”‚
â”‚ dynamodb                 â”‚ âœ” available â”‚
...
```

To use SQS, a fully managed distributed message queuing service, on LocalStack, run:

```shell
% awslocal sqs create-queue --queue-name sample-queue
{
    &quot;QueueUrl&quot;: &quot;http://sqs.us-east-1.localhost.localstack.cloud:4566/000000000000/sample-queue&quot;
}
```

Learn more about [LocalStack AWS services](https://docs.localstack.cloud/references/coverage/) and using them with LocalStack&#039;s `awslocal` CLI.

## Running

You can run LocalStack through the following options:

- [LocalStack CLI](https://docs.localstack.cloud/getting-started/installation/#localstack-cli)
- [Docker](https://docs.localstack.cloud/getting-started/installation/#docker)
- [Docker Compose](https://docs.localstack.cloud/getting-started/installation/#docker-compose)
- [Helm](https://docs.localstack.cloud/getting-started/installation/#helm)

## Usage

To start using LocalStack, check out our [documentation](https://docs.localstack.cloud).

- [LocalStack Configuration](https://docs.localstack.cloud/references/configuration/)
- [LocalStack in CI](https://docs.localstack.cloud/user-guide/ci/)
- [LocalStack Integrations](https://docs.localstack.cloud/user-guide/integrations/)
- [LocalStack Tools](https://docs.localstack.cloud/user-guide/tools/)
- [Understanding LocalStack](https://docs.localstack.cloud/references/)
- [Frequently Asked Questions](https://docs.localstack.cloud/getting-started/faq/)

To use LocalStack with a graphical user interface, you can use the following UI clients:

* [LocalStack Web Application](https://app.localstack.cloud)
* [LocalStack Desktop](https://docs.localstack.cloud/user-guide/tools/localstack-desktop/)
* [LocalStack Docker Extension](https://docs.localstack.cloud/user-guide/tools/localstack-docker-extension/)

## Releases

Please refer to [GitHub releases](https://github.com/localstack/localstack/releases) to see the complete list of changes for each release. For extended release notes, please refer to the [changelog](https://docs.localstack.cloud/references/changelog/).

## Contributing

If you are interested in contributing to LocalStack:

- Start by reading our [contributing guide](docs/CONTRIBUTING.md).
- Check out our [development environment setup guide](docs/development-environment-setup/README.md).
- Navigate our codebase and [open issues](https://github.com/localstack/localstack/issues).

We are thankful for all the contributions and feedback we receive.

## Get in touch

Get in touch with the LocalStack Team to
report ğŸ [issues](https://github.com/localstack/localstack/issues/new/choose),
upvote ğŸ‘ [feature requests](https://github.com/localstack/localstack/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+),
ğŸ™‹ğŸ½ ask [support questions](https://docs.localstack.cloud/getting-started/help-and-support/),
or ğŸ—£ï¸ discuss local cloud development:

- [LocalStack Slack Community](https://localstack.cloud/slack/)
- [LocalStack GitHub Issue tracker](https://github.com/localstack/localstack/issues)

### Contributors

We are thankful to all the people who have contributed to this project.

&lt;a href=&quot;https://github.com/localstack/localstack/graphs/contributors&quot;&gt;&lt;img src=&quot;https://opencollective.com/localstack/contributors.svg?width=890&quot; /&gt;&lt;/a&gt;

### Backers

We are also grateful to all our backers who have donated to the project. You can become a backer on [Open Collective](https://opencollective.com/localstack#backer).

&lt;a href=&quot;https://opencollective.com/localstack#backers&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/localstack/backers.svg?width=890&quot;&gt;&lt;/a&gt;

### Sponsors

You can also support this project by becoming a sponsor on [Open Collective](https://opencollective.com/localstack#sponsor). Your logo will show up here along with a link to your website.

&lt;a href=&quot;https://opencollective.com/localstack/sponsor/0/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/localstack/sponsor/0/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/localstack/sponsor/1/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/localstack/sponsor/1/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/localstack/sponsor/2/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/localstack/sponsor/2/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/localstack/sponsor/3/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/localstack/sponsor/3/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/localstack/sponsor/4/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/localstack/sponsor/4/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/localstack/sponsor/5/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/localstack/sponsor/5/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/localstack/sponsor/6/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/localstack/sponsor/6/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/localstack/sponsor/7/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/localstack/sponsor/7/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/localstack/sponsor/8/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/localstack/sponsor/8/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/localstack/sponsor/9/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/localstack/sponsor/9/avatar.svg&quot;&gt;&lt;/a&gt;

## License

Copyright (c) 2017-2025 LocalStack maintainers and contributors.

Copyright (c) 2016 Atlassian and others.

This version of LocalStack is released under the Apache License, Version 2.0 (see [LICENSE](LICENSE.txt)). By downloading and using this software you agree to the [End-User License Agreement (EULA)](docs/end_user_license_agreement).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Shubhamsaboo/awesome-llm-apps]]></title>
            <link>https://github.com/Shubhamsaboo/awesome-llm-apps</link>
            <guid>https://github.com/Shubhamsaboo/awesome-llm-apps</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:31 GMT</pubDate>
            <description><![CDATA[Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Shubhamsaboo/awesome-llm-apps">Shubhamsaboo/awesome-llm-apps</a></h1>
            <p>Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.</p>
            <p>Language: Python</p>
            <p>Stars: 75,765</p>
            <p>Forks: 9,974</p>
            <p>Stars today: 231 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;http://www.theunwindai.com&quot;&gt;
    &lt;img src=&quot;docs/banner/unwind_black.png&quot; width=&quot;900px&quot; alt=&quot;Unwind AI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.linkedin.com/in/shubhamsaboo/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-Follow%20Shubham%20Saboo-blue?logo=linkedin&amp;style=flat-square&quot; alt=&quot;LinkedIn&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/Saboo_Shubham_&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/twitter/follow/Shubham_Saboo&quot; alt=&quot;Twitter&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=de&quot;&gt;Deutsch&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=es&quot;&gt;EspaÃ±ol&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=fr&quot;&gt;franÃ§ais&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ja&quot;&gt;æ—¥æœ¬èª&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ko&quot;&gt;í•œêµ­ì–´&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=pt&quot;&gt;PortuguÃªs&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ru&quot;&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=zh&quot;&gt;ä¸­æ–‡&lt;/a&gt;
&lt;/p&gt;

&lt;hr/&gt;

# ğŸŒŸ Awesome LLM Apps

A curated collection of **Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.** This repository features LLM apps that use models from &lt;img src=&quot;https://cdn.simpleicons.org/openai&quot;  alt=&quot;openai logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**OpenAI** , &lt;img src=&quot;https://cdn.simpleicons.org/anthropic&quot;  alt=&quot;anthropic logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**Anthropic**, &lt;img src=&quot;https://cdn.simpleicons.org/googlegemini&quot;  alt=&quot;google logo&quot; width=&quot;25&quot; height=&quot;18&quot;&gt;**Google**, &lt;img src=&quot;https://cdn.simpleicons.org/x&quot;  alt=&quot;X logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**xAI** and open-source models like &lt;img src=&quot;https://cdn.simpleicons.org/alibabacloud&quot;  alt=&quot;alibaba logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**Qwen** or  &lt;img src=&quot;https://cdn.simpleicons.org/meta&quot;  alt=&quot;meta logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**Llama** that you can run locally on your computer.

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/9876&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/9876&quot; alt=&quot;Shubhamsaboo%2Fawesome-llm-apps | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## ğŸ¤” Why Awesome LLM Apps?

- ğŸ’¡ Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.
- ğŸ”¥ Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with AI Agents, Agent Teams, MCP &amp; RAG.
- ğŸ“ Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.

## ğŸ™ Thanks to our sponsors

&lt;table align=&quot;center&quot; cellpadding=&quot;16&quot; cellspacing=&quot;12&quot;&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://getunblocked.com/unblocked-mcp/?utm_source=oss&amp;utm_medium=sponsorship&amp;utm_campaign=awesome-llm-apps&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; title=&quot;Unblocked&quot;&gt;
        &lt;img src=&quot;docs/banner/sponsors/unblocked.png&quot; alt=&quot;Unblocked&quot; width=&quot;500&quot;&gt;
      &lt;/a&gt;
      &lt;br&gt;
      &lt;a href=&quot;https://getunblocked.com/unblocked-mcp/?utm_source=oss&amp;utm_medium=sponsorship&amp;utm_campaign=awesome-llm-apps&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; style=&quot;text-decoration: none; color: #333; font-weight: bold; font-size: 18px;&quot;&gt;
        Unblocked
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://okara.ai/?utm_source=oss&amp;utm_medium=sponsorship&amp;utm_campaign=awesome-llm-apps&quot; title=&quot;Okara&quot;&gt;
        &lt;img src=&quot;docs/banner/sponsors/okara.png&quot; alt=&quot;Okara&quot; width=&quot;500&quot;&gt;
      &lt;/a&gt;
      &lt;br&gt;
      &lt;a href=&quot;https://okara.ai/?utm_source=oss&amp;utm_medium=sponsorship&amp;utm_campaign=awesome-llm-apps&quot; style=&quot;text-decoration: none; color: #333; font-weight: bold; font-size: 18px;&quot;&gt;
        Okara AI
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://sponsorunwindai.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/_Sponsor_Us-FF69B4?style=for-the-badge&amp;logo=github-sponsors&amp;logoColor=white&quot; alt=&quot;Sponsor Us&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

## ğŸ“‚ Featured AI Projects

### AI Agents

### ğŸŒ± Starter AI Agents

*   [ğŸ™ï¸ AI Blog to Podcast Agent](starter_ai_agents/ai_blog_to_podcast_agent/)
*   [â¤ï¸â€ğŸ©¹ AI Breakup Recovery Agent](starter_ai_agents/ai_breakup_recovery_agent/)
*   [ğŸ“Š AI Data Analysis Agent](starter_ai_agents/ai_data_analysis_agent/)
*   [ğŸ©» AI Medical Imaging Agent](starter_ai_agents/ai_medical_imaging_agent/)
*   [ğŸ˜‚ AI Meme Generator Agent (Browser)](starter_ai_agents/ai_meme_generator_agent_browseruse/)
*   [ğŸµ AI Music Generator Agent](starter_ai_agents/ai_music_generator_agent/)
*   [ğŸ›« AI Travel Agent (Local &amp; Cloud)](starter_ai_agents/ai_travel_agent/)
*   [âœ¨ Gemini Multimodal Agent](starter_ai_agents/gemini_multimodal_agent_demo/)
*   [ğŸŒ Local News Agent (OpenAI Swarm)](starter_ai_agents/local_news_agent_openai_swarm/)
*   [ğŸ”„ Mixture of Agents](starter_ai_agents/mixture_of_agents/)
*   [ğŸ“Š xAI Finance Agent](starter_ai_agents/xai_finance_agent/)
*   [ğŸ” OpenAI Research Agent](starter_ai_agents/opeani_research_agent/)
*   [ğŸ•¸ï¸ Web Scrapping AI Agent (Local &amp; Cloud)](starter_ai_agents/web_scrapping_ai_agent/)

### ğŸš€ Advanced AI Agents
*   [ğŸšï¸ ğŸŒ AI Home Renovation Agent with Nano Banana](advanced_ai_agents/multi_agent_apps/ai_home_renovation_agent)
*   [ğŸ” AI Deep Research Agent](advanced_ai_agents/single_agent_apps/ai_deep_research_agent/)
*   [ğŸ¤ AI Consultant Agent](advanced_ai_agents/single_agent_apps/ai_consultant_agent)
*   [ğŸ—ï¸ AI System Architect Agent](advanced_ai_agents/single_agent_apps/ai_system_architect_r1/)
*   [ğŸ¯ AI Lead Generation Agent](advanced_ai_agents/single_agent_apps/ai_lead_generation_agent/)
*   [ğŸ’° AI Financial Coach Agent](advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/)
*   [ğŸ¬ AI Movie Production Agent](advanced_ai_agents/single_agent_apps/ai_movie_production_agent/)
*   [ğŸ“ˆ AI Investment Agent](advanced_ai_agents/single_agent_apps/ai_investment_agent/)
*   [ğŸ‹ï¸â€â™‚ï¸ AI Health &amp; Fitness Agent](advanced_ai_agents/single_agent_apps/ai_health_fitness_agent/)
*   [ğŸš€ AI Product Launch Intelligence Agent](advanced_ai_agents/multi_agent_apps/product_launch_intelligence_agent)
*   [ğŸ—ï¸ AI Journalist Agent](advanced_ai_agents/single_agent_apps/ai_journalist_agent/)
*   [ğŸ§  AI Mental Wellbeing Agent](advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/)
*   [ğŸ“‘ AI Meeting Agent](advanced_ai_agents/single_agent_apps/ai_meeting_agent/)
*   [ğŸ§¬ AI Self-Evolving Agent](advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/)
*   [ğŸ§ AI Social Media News and Podcast Agent](advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/)

### ğŸ® Autonomous Game Playing Agents

*   [ğŸ® AI 3D Pygame Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/)
*   [â™œ AI Chess Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/)
*   [ğŸ² AI Tic-Tac-Toe Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/)

### ğŸ¤ Multi-agent Teams

*   [ğŸ§² AI Competitor Intelligence Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/)
*   [ğŸ’² AI Finance Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/)
*   [ğŸ¨ AI Game Design Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/)
*   [ğŸ‘¨â€âš–ï¸ AI Legal Agent Team (Cloud &amp; Local)](advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/)
*   [ğŸ’¼ AI Recruitment Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/)
*   [ğŸ  AI Real Estate Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_real_estate_agent_team)
*   [ğŸ‘¨â€ğŸ’¼ AI Services Agency (CrewAI)](advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/)
*   [ğŸ‘¨â€ğŸ« AI Teaching Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/)
*   [ğŸ’» Multimodal Coding Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/)
*   [âœ¨ Multimodal Design Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/)
*   [ğŸ¨ ğŸŒ Multimodal UI/UX Feedback Agent Team with Nano Banana](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_uiux_feedback_agent_team/)
*   [ğŸŒ AI Travel Planner Agent Team](/advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/)

### ğŸ—£ï¸ Voice AI Agents

*   [ğŸ—£ï¸ AI Audio Tour Agent](voice_ai_agents/ai_audio_tour_agent/)
*   [ğŸ“ Customer Support Voice Agent](voice_ai_agents/customer_support_voice_agent/)
*   [ğŸ”Š Voice RAG Agent (OpenAI SDK)](voice_ai_agents/voice_rag_openaisdk/)


### &lt;img src=&quot;https://cdn.simpleicons.org/modelcontextprotocol&quot;  alt=&quot;mcp logo&quot; width=&quot;25&quot; height=&quot;20&quot;&gt; MCP AI Agents 

*   [â™¾ï¸ Browser MCP Agent](mcp_ai_agents/browser_mcp_agent/)
*   [ğŸ™ GitHub MCP Agent](mcp_ai_agents/github_mcp_agent/)
*   [ğŸ“‘ Notion MCP Agent](mcp_ai_agents/notion_mcp_agent) 
*   [ğŸŒ AI Travel Planner MCP Agent](mcp_ai_agents/ai_travel_planner_mcp_agent_team)

### ğŸ“€ RAG (Retrieval Augmented Generation)
*   [ğŸ”¥ Agentic RAG with Embedding Gemma](rag_tutorials/agentic_rag_embedding_gemma)
*   [ğŸ§ Agentic RAG with Reasoning](rag_tutorials/agentic_rag_with_reasoning/)
*   [ğŸ“° AI Blog Search (RAG)](rag_tutorials/ai_blog_search/)
*   [ğŸ” Autonomous RAG](rag_tutorials/autonomous_rag/)
*   [ğŸ”„ Contextual AI RAG Agent](rag_tutorials/contextualai_rag_agent/)
*   [ğŸ”„ Corrective RAG (CRAG)](rag_tutorials/corrective_rag/)
*   [ğŸ‹ Deepseek Local RAG Agent](rag_tutorials/deepseek_local_rag_agent/)
*   [ğŸ¤” Gemini Agentic RAG](rag_tutorials/gemini_agentic_rag/)
*   [ğŸ‘€ Hybrid Search RAG (Cloud)](rag_tutorials/hybrid_search_rag/)
*   [ğŸ”„ Llama 3.1 Local RAG](rag_tutorials/llama3.1_local_rag/)
*   [ğŸ–¥ï¸ Local Hybrid Search RAG](rag_tutorials/local_hybrid_search_rag/)
*   [ğŸ¦™ Local RAG Agent](rag_tutorials/local_rag_agent/)
*   [ğŸ§© RAG-as-a-Service](rag_tutorials/rag-as-a-service/)
*   [âœ¨ RAG Agent with Cohere](rag_tutorials/rag_agent_cohere/)
*   [â›“ï¸ Basic RAG Chain](rag_tutorials/rag_chain/)
*   [ğŸ“  RAG with Database Routing](rag_tutorials/rag_database_routing/)
*   [ğŸ–¼ï¸ Vision RAG](rag_tutorials/vision_rag/)

### ğŸ’¾ LLM Apps with Memory Tutorials

*   [ğŸ’¾ AI ArXiv Agent with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/ai_arxiv_agent_memory/)
*   [ğŸ›©ï¸ AI Travel Agent with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/ai_travel_agent_memory/)
*   [ğŸ’¬ Llama3 Stateful Chat](advanced_llm_apps/llm_apps_with_memory_tutorials/llama3_stateful_chat/)
*   [ğŸ“ LLM App with Personalized Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/llm_app_personalized_memory/)
*   [ğŸ—„ï¸ Local ChatGPT Clone with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/local_chatgpt_with_memory/)
*   [ğŸ§  Multi-LLM Application with Shared Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/multi_llm_memory/)


### ğŸ’¬ Chat with X Tutorials

*   [ğŸ’¬ Chat with GitHub (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_github/)
*   [ğŸ“¨ Chat with Gmail](advanced_llm_apps/chat_with_X_tutorials/chat_with_gmail/)
*   [ğŸ“„ Chat with PDF (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_pdf/)
*   [ğŸ“š Chat with Research Papers (ArXiv) (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_research_papers/)
*   [ğŸ“ Chat with Substack](advanced_llm_apps/chat_with_X_tutorials/chat_with_substack/)
*   [ğŸ“½ï¸ Chat with YouTube Videos](advanced_llm_apps/chat_with_X_tutorials/chat_with_youtube_videos/)

### ğŸ”§ LLM Fine-tuning Tutorials

* &lt;img src=&quot;https://cdn.simpleicons.org/google&quot;  alt=&quot;google logo&quot; width=&quot;20&quot; height=&quot;15&quot;&gt; [Gemma 3 Fine-tuning](advanced_llm_apps/llm_finetuning_tutorials/gemma3_finetuning/)
* &lt;img src=&quot;https://cdn.simpleicons.org/meta&quot;  alt=&quot;meta logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt; [Llama 3.2 Fine-tuning](advanced_llm_apps/llm_finetuning_tutorials/llama3.2_finetuning/)


### ğŸ§‘â€ğŸ« AI Agent Framework Crash Course

&lt;img src=&quot;https://cdn.simpleicons.org/google&quot;  alt=&quot;google logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt; [Google ADK Crash Course](ai_agent_framework_crash_course/google_adk_crash_course/)
  - Starter agent; modelâ€‘agnostic (OpenAI, Claude)
  - Structured outputs (Pydantic)
  - Tools: builtâ€‘in, function, thirdâ€‘party, MCP tools
  - Memory; callbacks; Plugins
  - Simple multiâ€‘agent; Multiâ€‘agent patterns

&lt;img src=&quot;https://cdn.simpleicons.org/openai&quot;  alt=&quot;openai logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt; [OpenAI Agents SDK Crash Course](ai_agent_framework_crash_course/openai_sdk_crash_course/)
  - Starter agent; function calling; structured outputs
  - Tools: builtâ€‘in, function, thirdâ€‘party integrations
  - Memory; callbacks; evaluation
  - Multiâ€‘agent patterns; agent handoffs
  - Swarm orchestration; routing logic

## ğŸš€ Getting Started

1. **Clone the repository** 

    ```bash 
    git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git 
    ```

2. **Navigate to the desired project directory**

    ```bash 
    cd awesome-llm-apps/starter_ai_agents/ai_travel_agent
    ```

3. **Install the required dependencies**

    ```bash
    pip install -r requirements.txt
    ```

4. **Follow the project-specific instructions** in each project&#039;s `README.md` file to set up and run the app.


### &lt;img src=&quot;https://cdn.simpleicons.org/github&quot;  alt=&quot;github logo&quot; width=&quot;25&quot; height=&quot;20&quot;&gt; Thank You, Community, for the Support! ğŸ™

[![Star History Chart](https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&amp;type=Date)](https://star-history.com/#Shubhamsaboo/awesome-llm-apps&amp;Date)

ğŸŒŸ **Donâ€™t miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.**
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[666ghj/BettaFish]]></title>
            <link>https://github.com/666ghj/BettaFish</link>
            <guid>https://github.com/666ghj/BettaFish</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:30 GMT</pubDate>
            <description><![CDATA[å¾®èˆ†ï¼šäººäººå¯ç”¨çš„å¤šAgentèˆ†æƒ…åˆ†æåŠ©æ‰‹ï¼Œæ‰“ç ´ä¿¡æ¯èŒ§æˆ¿ï¼Œè¿˜åŸèˆ†æƒ…åŸè²Œï¼Œé¢„æµ‹æœªæ¥èµ°å‘ï¼Œè¾…åŠ©å†³ç­–ï¼ä»0å®ç°ï¼Œä¸ä¾èµ–ä»»ä½•æ¡†æ¶ã€‚]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/666ghj/BettaFish">666ghj/BettaFish</a></h1>
            <p>å¾®èˆ†ï¼šäººäººå¯ç”¨çš„å¤šAgentèˆ†æƒ…åˆ†æåŠ©æ‰‹ï¼Œæ‰“ç ´ä¿¡æ¯èŒ§æˆ¿ï¼Œè¿˜åŸèˆ†æƒ…åŸè²Œï¼Œé¢„æµ‹æœªæ¥èµ°å‘ï¼Œè¾…åŠ©å†³ç­–ï¼ä»0å®ç°ï¼Œä¸ä¾èµ–ä»»ä½•æ¡†æ¶ã€‚</p>
            <p>Language: Python</p>
            <p>Stars: 23,021</p>
            <p>Forks: 4,415</p>
            <p>Stars today: 1,931 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;img src=&quot;static/image/logo_compressed.png&quot; alt=&quot;BettaFish Logo&quot; width=&quot;100%&quot;&gt;

&lt;a href=&quot;https://trendshift.io/repositories/15286&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15286&quot; alt=&quot;666ghj%2FBettaFish | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

&lt;a href=&quot;https://aihubmix.com/?aff=8Ds9&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./static/image/logo_aihubmix.png&quot; alt=&quot;666ghj%2FBettaFish | Trendshift&quot; height=&quot;40&quot;/&gt;&lt;/a&gt;&amp;ensp;
&lt;a href=&quot;https://lioncc.ai/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./static/image/logo_loincc.png&quot; alt=&quot;666ghj%2FBettaFish | Trendshift&quot; height=&quot;40&quot;/&gt;&lt;/a&gt;&amp;ensp;
&lt;a href=&quot;https://share.302.ai/P66Qe3&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./static/image/logo_302ai.png&quot; alt=&quot;666ghj%2FBettaFish | Trendshift&quot; height=&quot;40&quot;/&gt;&lt;/a&gt;

[![GitHub Stars](https://img.shields.io/github/stars/666ghj/BettaFish?style=flat-square)](https://github.com/666ghj/BettaFish/stargazers)
[![GitHub Watchers](https://img.shields.io/github/watchers/666ghj/BettaFish?style=flat-square)](https://github.com/666ghj/BettaFish/watchers)
[![GitHub Forks](https://img.shields.io/github/forks/666ghj/BettaFish?style=flat-square)](https://github.com/666ghj/BettaFish/network)
[![GitHub Issues](https://img.shields.io/github/issues/666ghj/BettaFish?style=flat-square)](https://github.com/666ghj/BettaFish/issues)
[![GitHub Pull Requests](https://img.shields.io/github/issues-pr/666ghj/BettaFish?style=flat-square)](https://github.com/666ghj/BettaFish/pulls)

[![GitHub License](https://img.shields.io/github/license/666ghj/BettaFish?style=flat-square)](https://github.com/666ghj/BettaFish/blob/main/LICENSE)
[![Version](https://img.shields.io/badge/version-v1.1.2-green.svg?style=flat-square)](https://github.com/666ghj/BettaFish)
[![Docker](https://img.shields.io/badge/Docker-Build-2496ED?style=flat-square&amp;logo=docker&amp;logoColor=white)](https://hub.docker.com/)



[English](./README-EN.md) | [ä¸­æ–‡æ–‡æ¡£](./README.md)

&lt;/div&gt;

## âš¡ é¡¹ç›®æ¦‚è¿°

â€œ**å¾®èˆ†**â€ æ˜¯ä¸€ä¸ªä»0å®ç°çš„åˆ›æ–°å‹ å¤šæ™ºèƒ½ä½“ èˆ†æƒ…åˆ†æç³»ç»Ÿï¼Œå¸®åŠ©å¤§å®¶ç ´é™¤ä¿¡æ¯èŒ§æˆ¿ï¼Œè¿˜åŸèˆ†æƒ…åŸè²Œï¼Œé¢„æµ‹æœªæ¥èµ°å‘ï¼Œè¾…åŠ©å†³ç­–ã€‚ç”¨æˆ·åªéœ€åƒèŠå¤©ä¸€æ ·æå‡ºåˆ†æéœ€æ±‚ï¼Œæ™ºèƒ½ä½“å¼€å§‹å…¨è‡ªåŠ¨åˆ†æ å›½å†…å¤–30+ä¸»æµç¤¾åª’ ä¸ æ•°ç™¾ä¸‡æ¡å¤§ä¼—è¯„è®ºã€‚

&gt; â€œå¾®èˆ†â€è°éŸ³â€œå¾®é±¼â€ï¼ŒBettaFishæ˜¯ä¸€ç§ä½“å‹å¾ˆå°ä½†éå¸¸å¥½æ–—ã€æ¼‚äº®çš„é±¼ï¼Œå®ƒè±¡å¾ç€â€œå°è€Œå¼ºå¤§ï¼Œä¸ç•æŒ‘æˆ˜â€

æŸ¥çœ‹ç³»ç»Ÿä»¥â€œæ­¦æ±‰å¤§å­¦èˆ†æƒ…â€ä¸ºä¾‹ï¼Œç”Ÿæˆçš„ç ”ç©¶æŠ¥å‘Šï¼š[æ­¦æ±‰å¤§å­¦å“ç‰Œå£°èª‰æ·±åº¦åˆ†ææŠ¥å‘Š](./final_reports/final_report__20250827_131630.html)

æŸ¥çœ‹ç³»ç»Ÿä»¥â€œæ­¦æ±‰å¤§å­¦èˆ†æƒ…â€ä¸ºä¾‹ï¼Œä¸€æ¬¡å®Œæ•´è¿è¡Œçš„è§†é¢‘ï¼š[è§†é¢‘-æ­¦æ±‰å¤§å­¦å“ç‰Œå£°èª‰æ·±åº¦åˆ†ææŠ¥å‘Š](https://www.bilibili.com/video/BV1TH1WBxEWN/?vd_source=da3512187e242ce17dceee4c537ec7a6#reply279744466833)

ä¸ä»…ä»…ä½“ç°åœ¨æŠ¥å‘Šè´¨é‡ä¸Šï¼Œç›¸æ¯”åŒç±»äº§å“ï¼Œæˆ‘ä»¬æ‹¥æœ‰ğŸš€å…­å¤§ä¼˜åŠ¿ï¼š

1. **AIé©±åŠ¨çš„å…¨åŸŸç›‘æ§**ï¼šAIçˆ¬è™«é›†ç¾¤7x24å°æ—¶ä¸é—´æ–­ä½œä¸šï¼Œå…¨é¢è¦†ç›–å¾®åšã€å°çº¢ä¹¦ã€æŠ–éŸ³ã€å¿«æ‰‹ç­‰10+å›½å†…å¤–å…³é”®ç¤¾åª’ã€‚ä¸ä»…å®æ—¶æ•è·çƒ­ç‚¹å†…å®¹ï¼Œæ›´èƒ½ä¸‹é’»è‡³æµ·é‡ç”¨æˆ·è¯„è®ºï¼Œè®©æ‚¨å¬åˆ°æœ€çœŸå®ã€æœ€å¹¿æ³›çš„å¤§ä¼—å£°éŸ³ã€‚

2. **è¶…è¶ŠLLMçš„å¤åˆåˆ†æå¼•æ“**ï¼šæˆ‘ä»¬ä¸ä»…ä¾èµ–è®¾è®¡çš„5ç±»ä¸“ä¸šAgentï¼Œæ›´èåˆäº†å¾®è°ƒæ¨¡å‹ã€ç»Ÿè®¡æ¨¡å‹ç­‰ä¸­é—´ä»¶ã€‚é€šè¿‡å¤šæ¨¡å‹ååŒå·¥ä½œï¼Œç¡®ä¿äº†åˆ†æç»“æœçš„æ·±åº¦ã€å‡†åº¦ä¸å¤šç»´è§†è§’ã€‚

3. **å¼ºå¤§çš„å¤šæ¨¡æ€èƒ½åŠ›**ï¼šçªç ´å›¾æ–‡é™åˆ¶ï¼Œèƒ½æ·±åº¦è§£ææŠ–éŸ³ã€å¿«æ‰‹ç­‰çŸ­è§†é¢‘å†…å®¹ï¼Œå¹¶ç²¾å‡†æå–ç°ä»£æœç´¢å¼•æ“ä¸­çš„å¤©æ°”ã€æ—¥å†ã€è‚¡ç¥¨ç­‰ç»“æ„åŒ–å¤šæ¨¡æ€ä¿¡æ¯å¡ç‰‡ï¼Œè®©æ‚¨å…¨é¢æŒæ¡èˆ†æƒ…åŠ¨æ€ã€‚

4. **Agentâ€œè®ºå›â€åä½œæœºåˆ¶**ï¼šä¸ºä¸åŒAgentèµ‹äºˆç‹¬ç‰¹çš„å·¥å…·é›†ä¸æ€ç»´æ¨¡å¼ï¼Œå¼•å…¥è¾©è®ºä¸»æŒäººæ¨¡å‹ï¼Œé€šè¿‡â€œè®ºå›â€æœºåˆ¶è¿›è¡Œé“¾å¼æ€ç»´ç¢°æ’ä¸è¾©è®ºã€‚è¿™ä¸ä»…é¿å…äº†å•ä¸€æ¨¡å‹çš„æ€ç»´å±€é™ä¸äº¤æµå¯¼è‡´çš„åŒè´¨åŒ–ï¼Œæ›´å‚¬ç”Ÿå‡ºæ›´é«˜è´¨é‡çš„é›†ä½“æ™ºèƒ½ä¸å†³ç­–æ”¯æŒã€‚

5. **å…¬ç§åŸŸæ•°æ®æ— ç¼èåˆ**ï¼šå¹³å°ä¸ä»…åˆ†æå…¬å¼€èˆ†æƒ…ï¼Œè¿˜æä¾›é«˜å®‰å…¨æ€§çš„æ¥å£ï¼Œæ”¯æŒæ‚¨å°†å†…éƒ¨ä¸šåŠ¡æ•°æ®åº“ä¸èˆ†æƒ…æ•°æ®æ— ç¼é›†æˆã€‚æ‰“é€šæ•°æ®å£å’ï¼Œä¸ºå‚ç›´ä¸šåŠ¡æä¾›â€œå¤–éƒ¨è¶‹åŠ¿+å†…éƒ¨æ´å¯Ÿâ€çš„å¼ºå¤§åˆ†æèƒ½åŠ›ã€‚

6. **è½»é‡åŒ–ä¸é«˜æ‰©å±•æ€§æ¡†æ¶**ï¼šåŸºäºçº¯Pythonæ¨¡å—åŒ–è®¾è®¡ï¼Œå®ç°è½»é‡åŒ–ã€ä¸€é”®å¼éƒ¨ç½²ã€‚ä»£ç ç»“æ„æ¸…æ™°ï¼Œå¼€å‘è€…å¯è½»æ¾é›†æˆè‡ªå®šä¹‰æ¨¡å‹ä¸ä¸šåŠ¡é€»è¾‘ï¼Œå®ç°å¹³å°çš„å¿«é€Ÿæ‰©å±•ä¸æ·±åº¦å®šåˆ¶ã€‚

**å§‹äºèˆ†æƒ…ï¼Œè€Œä¸æ­¢äºèˆ†æƒ…**ã€‚â€œå¾®èˆ†â€çš„ç›®æ ‡ï¼Œæ˜¯æˆä¸ºé©±åŠ¨ä¸€åˆ‡ä¸šåŠ¡åœºæ™¯çš„ç®€æ´é€šç”¨çš„æ•°æ®åˆ†æå¼•æ“ã€‚

&gt; ä¸¾ä¸ªä¾‹å­. ä½ åªéœ€ç®€å•ä¿®æ”¹Agentå·¥å…·é›†çš„apiå‚æ•°ä¸promptï¼Œå°±å¯ä»¥æŠŠä»–å˜æˆä¸€ä¸ªé‡‘èé¢†åŸŸçš„å¸‚åœºåˆ†æç³»ç»Ÿ
&gt;
&gt; é™„ä¸€ä¸ªæ¯”è¾ƒæ´»è·ƒçš„Lç«™é¡¹ç›®è®¨è®ºå¸–ï¼šhttps://linux.do/t/topic/1009280

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;static/image/system_schematic.png&quot; alt=&quot;banner&quot; width=&quot;800&quot;&gt;

å‘Šåˆ«ä¼ ç»Ÿçš„æ•°æ®çœ‹æ¿ï¼Œåœ¨â€œå¾®èˆ†â€ï¼Œä¸€åˆ‡ç”±ä¸€ä¸ªç®€å•çš„é—®é¢˜å¼€å§‹ï¼Œæ‚¨åªéœ€åƒå¯¹è¯ä¸€æ ·ï¼Œæå‡ºæ‚¨çš„åˆ†æéœ€æ±‚
&lt;/div&gt;

## ğŸª„ èµåŠ©å•†

LLMæ¨¡å‹APIèµåŠ©ï¼š&lt;a href=&quot;https://aihubmix.com/?aff=8Ds9&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./static/image/logo_aihubmix.png&quot; alt=&quot;666ghj%2FBettaFish | Trendshift&quot; height=&quot;40&quot;/&gt;&lt;/a&gt;

&lt;details&gt;
&lt;summary&gt;(ç‚¹å¼€â–¶æœ‰èµåŠ©LLMç®—åŠ›ç¦åˆ©)ç¼–ç¨‹æ‹¼è½¦codecodex.aiï¼›ç¼–ç¨‹ç®—åŠ›VibeCodingAPI.aiï¼š&lt;/a&gt;&lt;span style=&quot;margin-left: 10px&quot;&gt;&lt;a href=&quot;https://codecodex.ai/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./static/image/logo_loincc.png&quot; alt=&quot;666ghj%2FBettaFish | Trendshift&quot; height=&quot;40&quot;/&gt;&lt;/a&gt;&lt;/summary&gt;

1. æ‰€ç½—é—¨åšå®¢LionCC.aiå·²æ›´æ–°ã€ŠBettaFish å¾®èˆ†ç³»ç»Ÿ - LionCC API éƒ¨ç½²é…ç½®å®Œå…¨æŒ‡å—ã€‹æ­£åœ¨äºŒå¼€ä¼˜åŒ–ä¸€é”®éƒ¨ç½²å’Œäº‘æœåŠ¡å™¨è°ƒç”¨æ–¹æ¡ˆã€‚
2. VibeCodingapi.aiç‹®å­ç®—åŠ›å¹³å°å·²ç»é€‚é…ã€ŠBettaFish å¾®èˆ†ç³»ç»Ÿã€‹æ‰€æœ‰LLMæ¨¡å‹å«claude codeå’Œopenai codexå’Œgemini cliç¼–ç¨‹å¼€å‘ä¸‰å·¨å¤´ç®—åŠ›ã€‚é¢åº¦ä»·æ ¼ï¼Œåªè¦ä¸€æ¯”ä¸€ï¼ˆ100å…ƒç­‰äº100ç¾åˆ€é¢åº¦ï¼‰
3. Codecodex.aiç‹®å­ç¼–ç¨‹æ‹¼è½¦ç³»ç»Ÿï¼Œå·²å®ç°æ— IPé—¨æ§›ç»•è¿‡claude codeå’Œopenai codexå°é”ï¼ŒæŒ‰å®˜æ–¹éƒ¨ç½²æ•™ç¨‹ååˆ‡æ¢BASE_URLè°ƒç”¨åœ°å€å’ŒToken keyè°ƒç”¨å¯†é’¥å³å¯ä½¿ç”¨æœ€å¼ºç¼–ç¨‹æ¨¡å‹ã€‚

æ‰€ç½—é—¨LionCCèµåŠ©BettaFish å¾®èˆ†ç¦åˆ©ï¼šæ‰“å¼€codecodex.aiç‹®å­ç¼–ç¨‹é¢‘é“æ‰«ç åŠ å…¥å¾®ä¿¡ç¤¾ç¾¤ï¼Œæ³¨å†ŒVibeCodingapi.aiç‹®å­ç®—åŠ›ï¼Œç»Ÿä¸€é€20åˆ€APIé¢åº¦ï¼ˆä»…é™å‰ä¸€åƒåï¼‰
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;æŒ‰ç”¨é‡ä»˜è´¹çš„ä¼ä¸šçº§AIèµ„æºå¹³å°ï¼Œæä¾›å¸‚åœºä¸Šå…¨é¢çš„AIæ¨¡å‹å’ŒAPIï¼Œä»¥åŠå¤šç§åœ¨çº¿AIåº”ç”¨ï¼š&lt;/a&gt;&lt;span style=&quot;margin-left: 10px&quot;&gt;&lt;a href=&quot;https://share.302.ai/P66Qe3&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./static/image/logo_302ai.png&quot; alt=&quot;666ghj%2FBettaFish | Trendshift&quot; height=&quot;40&quot;/&gt;&lt;/a&gt;&lt;/summary&gt;
&lt;img src=&quot;static/image/banner_302ai_ch.jpg&quot; alt=&quot;banner&quot;&gt;302.AIæ˜¯ä¸€ä¸ªæŒ‰ç”¨é‡ä»˜è´¹çš„ä¼ä¸šçº§AIèµ„æºå¹³å°ï¼Œæä¾›å¸‚åœºä¸Šæœ€æ–°ã€æœ€å…¨é¢çš„AIæ¨¡å‹å’ŒAPIï¼Œä»¥åŠå¤šç§å¼€ç®±å³ç”¨çš„åœ¨çº¿AIåº”ç”¨ã€‚
&lt;/details&gt;

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ•´ä½“æ¶æ„å›¾

**Insight Agent** ç§æœ‰æ•°æ®åº“æŒ–æ˜ï¼šç§æœ‰èˆ†æƒ…æ•°æ®åº“æ·±åº¦åˆ†æAIä»£ç†

**Media Agent** å¤šæ¨¡æ€å†…å®¹åˆ†æï¼šå…·å¤‡å¼ºå¤§å¤šæ¨¡æ€èƒ½åŠ›çš„AIä»£ç†

**Query Agent** ç²¾å‡†ä¿¡æ¯æœç´¢ï¼šå…·å¤‡å›½å†…å¤–ç½‘é¡µæœç´¢èƒ½åŠ›çš„AIä»£ç†

**Report Agent** æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆï¼šå†…ç½®æ¨¡æ¿çš„å¤šè½®æŠ¥å‘Šç”ŸæˆAIä»£ç†

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;static/image/framework.png&quot; alt=&quot;banner&quot; width=&quot;800&quot;&gt;
&lt;/div&gt;

### ä¸€æ¬¡å®Œæ•´åˆ†ææµç¨‹

| æ­¥éª¤ | é˜¶æ®µåç§° | ä¸»è¦æ“ä½œ | å‚ä¸ç»„ä»¶ | å¾ªç¯ç‰¹æ€§ |
|------|----------|----------|----------|----------|
| 1 | ç”¨æˆ·æé—® | Flaskä¸»åº”ç”¨æ¥æ”¶æŸ¥è¯¢ | Flaskä¸»åº”ç”¨ | - |
| 2 | å¹¶è¡Œå¯åŠ¨ | ä¸‰ä¸ªAgentåŒæ—¶å¼€å§‹å·¥ä½œ | Query Agentã€Media Agentã€Insight Agent | - |
| 3 | åˆæ­¥åˆ†æ | å„Agentä½¿ç”¨ä¸“å±å·¥å…·è¿›è¡Œæ¦‚è§ˆæœç´¢ | å„Agent + ä¸“å±å·¥å…·é›† | - |
| 4 | ç­–ç•¥åˆ¶å®š | åŸºäºåˆæ­¥ç»“æœåˆ¶å®šåˆ†å—ç ”ç©¶ç­–ç•¥ | å„Agentå†…éƒ¨å†³ç­–æ¨¡å— | - |
| 5-N | **å¾ªç¯é˜¶æ®µ** | **è®ºå›åä½œ + æ·±åº¦ç ”ç©¶** | **ForumEngine + æ‰€æœ‰Agent** | **å¤šè½®å¾ªç¯** |
| 5.1 | æ·±åº¦ç ”ç©¶ | å„AgentåŸºäºè®ºå›ä¸»æŒäººå¼•å¯¼è¿›è¡Œä¸“é¡¹æœç´¢ | å„Agent + åæ€æœºåˆ¶ + è®ºå›å¼•å¯¼ | æ¯è½®å¾ªç¯ |
| 5.2 | è®ºå›åä½œ | ForumEngineç›‘æ§Agentå‘è¨€å¹¶ç”Ÿæˆä¸»æŒäººæ€»ç»“ | ForumEngine + LLMä¸»æŒäºº | æ¯è½®å¾ªç¯ |
| 5.3 | äº¤æµèåˆ | å„Agentæ ¹æ®è®¨è®ºè°ƒæ•´ç ”ç©¶æ–¹å‘ | å„Agent + forum_readerå·¥å…· | æ¯è½®å¾ªç¯ |
| N+1 | ç»“æœæ•´åˆ | Report Agentæ”¶é›†æ‰€æœ‰åˆ†æç»“æœå’Œè®ºå›å†…å®¹ | Report Agent | - |
| N+2 | æŠ¥å‘Šç”Ÿæˆ | åŠ¨æ€é€‰æ‹©æ¨¡æ¿å’Œæ ·å¼ï¼Œå¤šè½®ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š | Report Agent + æ¨¡æ¿å¼•æ“ | - |

### é¡¹ç›®ä»£ç ç»“æ„æ ‘

```
BettaFish/
â”œâ”€â”€ QueryEngine/                   # å›½å†…å¤–æ–°é—»å¹¿åº¦æœç´¢Agent
â”‚   â”œâ”€â”€ agent.py                   # Agentä¸»é€»è¾‘
â”‚   â”œâ”€â”€ llms/                      # LLMæ¥å£å°è£…
â”‚   â”œâ”€â”€ nodes/                     # å¤„ç†èŠ‚ç‚¹
â”‚   â”œâ”€â”€ tools/                     # æœç´¢å·¥å…·
â”‚   â”œâ”€â”€ utils/                     # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ ...                        # å…¶ä»–æ¨¡å—
â”œâ”€â”€ MediaEngine/                   # å¼ºå¤§çš„å¤šæ¨¡æ€ç†è§£Agent
â”‚   â”œâ”€â”€ agent.py                   # Agentä¸»é€»è¾‘
â”‚   â”œâ”€â”€ nodes/                     # å¤„ç†èŠ‚ç‚¹
â”‚   â”œâ”€â”€ llms/                      # LLMæ¥å£
â”‚   â”œâ”€â”€ tools/                     # æœç´¢å·¥å…·
â”‚   â”œâ”€â”€ utils/                     # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ ...                        # å…¶ä»–æ¨¡å—
â”œâ”€â”€ InsightEngine/                 # ç§æœ‰æ•°æ®åº“æŒ–æ˜Agent
â”‚   â”œâ”€â”€ agent.py                   # Agentä¸»é€»è¾‘
â”‚   â”œâ”€â”€ llms/                      # LLMæ¥å£å°è£…
â”‚   â”‚   â””â”€â”€ base.py                # ç»Ÿä¸€çš„ OpenAI å…¼å®¹å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ nodes/                     # å¤„ç†èŠ‚ç‚¹
â”‚   â”‚   â”œâ”€â”€ base_node.py           # åŸºç¡€èŠ‚ç‚¹ç±»
â”‚   â”‚   â”œâ”€â”€ formatting_node.py     # æ ¼å¼åŒ–èŠ‚ç‚¹
â”‚   â”‚   â”œâ”€â”€ report_structure_node.py # æŠ¥å‘Šç»“æ„èŠ‚ç‚¹
â”‚   â”‚   â”œâ”€â”€ search_node.py         # æœç´¢èŠ‚ç‚¹
â”‚   â”‚   â””â”€â”€ summary_node.py        # æ€»ç»“èŠ‚ç‚¹
â”‚   â”œâ”€â”€ tools/                     # æ•°æ®åº“æŸ¥è¯¢å’Œåˆ†æå·¥å…·
â”‚   â”‚   â”œâ”€â”€ keyword_optimizer.py   # Qwenå…³é”®è¯ä¼˜åŒ–ä¸­é—´ä»¶
â”‚   â”‚   â”œâ”€â”€ search.py              # æ•°æ®åº“æ“ä½œå·¥å…·é›†
â”‚   â”‚   â””â”€â”€ sentiment_analyzer.py  # æƒ…æ„Ÿåˆ†æé›†æˆå·¥å…·
â”‚   â”œâ”€â”€ state/                     # çŠ¶æ€ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ state.py               # AgentçŠ¶æ€å®šä¹‰
â”‚   â”œâ”€â”€ prompts/                   # æç¤ºè¯æ¨¡æ¿
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ prompts.py             # å„ç±»æç¤ºè¯
â”‚   â””â”€â”€ utils/                     # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py              # é…ç½®ç®¡ç†
â”‚       â””â”€â”€ text_processing.py     # æ–‡æœ¬å¤„ç†å·¥å…·
â”œâ”€â”€ ReportEngine/                  # å¤šè½®æŠ¥å‘Šç”ŸæˆAgent
â”‚   â”œâ”€â”€ agent.py                   # Agentä¸»é€»è¾‘
â”‚   â”œâ”€â”€ llms/                      # LLMæ¥å£
â”‚   â”œâ”€â”€ nodes/                     # æŠ¥å‘Šç”ŸæˆèŠ‚ç‚¹
â”‚   â”‚   â”œâ”€â”€ template_selection.py  # æ¨¡æ¿é€‰æ‹©èŠ‚ç‚¹
â”‚   â”‚   â””â”€â”€ html_generation.py     # HTMLç”ŸæˆèŠ‚ç‚¹
â”‚   â”œâ”€â”€ report_template/           # æŠ¥å‘Šæ¨¡æ¿åº“
â”‚   â”‚   â”œâ”€â”€ ç¤¾ä¼šå…¬å…±çƒ­ç‚¹äº‹ä»¶åˆ†æ.md
â”‚   â”‚   â”œâ”€â”€ å•†ä¸šå“ç‰Œèˆ†æƒ…ç›‘æµ‹.md
â”‚   â”‚   â””â”€â”€ ...                    # æ›´å¤šæ¨¡æ¿
â”‚   â””â”€â”€ flask_interface.py         # Flask APIæ¥å£
â”œâ”€â”€ ForumEngine/                   # è®ºå›å¼•æ“ç®€æ˜“å®ç°
â”‚   â”œâ”€â”€ monitor.py                 # æ—¥å¿—ç›‘æ§å’Œè®ºå›ç®¡ç†
â”‚   â””â”€â”€ llm_host.py                # è®ºå›ä¸»æŒäººLLMæ¨¡å—
â”œâ”€â”€ MindSpider/                    # å¾®åšçˆ¬è™«ç³»ç»Ÿ
â”‚   â”œâ”€â”€ main.py                    # çˆ¬è™«ä¸»ç¨‹åº
â”‚   â”œâ”€â”€ config.py                  # çˆ¬è™«é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ BroadTopicExtraction/      # è¯é¢˜æå–æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ database_manager.py    # æ•°æ®åº“ç®¡ç†å™¨
â”‚   â”‚   â”œâ”€â”€ get_today_news.py      # ä»Šæ—¥æ–°é—»è·å–
â”‚   â”‚   â”œâ”€â”€ main.py                # è¯é¢˜æå–ä¸»ç¨‹åº
â”‚   â”‚   â””â”€â”€ topic_extractor.py     # è¯é¢˜æå–å™¨
â”‚   â”œâ”€â”€ DeepSentimentCrawling/     # æ·±åº¦èˆ†æƒ…çˆ¬å–
â”‚   â”‚   â”œâ”€â”€ keyword_manager.py     # å…³é”®è¯ç®¡ç†å™¨
â”‚   â”‚   â”œâ”€â”€ main.py                # æ·±åº¦çˆ¬å–ä¸»ç¨‹åº
â”‚   â”‚   â”œâ”€â”€ MediaCrawler/          # åª’ä½“çˆ¬è™«æ ¸å¿ƒ
â”‚   â”‚   â””â”€â”€ platform_crawler.py    # å¹³å°çˆ¬è™«ç®¡ç†
â”‚   â””â”€â”€ schema/                    # æ•°æ®åº“ç»“æ„
â”‚       â”œâ”€â”€ db_manager.py          # æ•°æ®åº“ç®¡ç†å™¨
â”‚       â”œâ”€â”€ init_database.py       # æ•°æ®åº“åˆå§‹åŒ–
â”‚       â””â”€â”€ mindspider_tables.sql  # æ•°æ®åº“è¡¨ç»“æ„
â”œâ”€â”€ SentimentAnalysisModel/        # æƒ…æ„Ÿåˆ†ææ¨¡å‹é›†åˆ
â”‚   â”œâ”€â”€ WeiboSentiment_Finetuned/  # å¾®è°ƒBERT/GPT-2æ¨¡å‹
â”‚   â”œâ”€â”€ WeiboMultilingualSentiment/# å¤šè¯­è¨€æƒ…æ„Ÿåˆ†æï¼ˆæ¨èï¼‰
â”‚   â”œâ”€â”€ WeiboSentiment_SmallQwen/  # å°å‚æ•°Qwen3å¾®è°ƒ
â”‚   â””â”€â”€ WeiboSentiment_MachineLearning/ # ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•
â”œâ”€â”€ SingleEngineApp/               # å•ç‹¬Agentçš„Streamlitåº”ç”¨
â”‚   â”œâ”€â”€ query_engine_streamlit_app.py
â”‚   â”œâ”€â”€ media_engine_streamlit_app.py
â”‚   â””â”€â”€ insight_engine_streamlit_app.py
â”œâ”€â”€ templates/                     # Flaskæ¨¡æ¿
â”‚   â””â”€â”€ index.html                 # ä¸»ç•Œé¢å‰ç«¯
â”œâ”€â”€ static/                        # é™æ€èµ„æº
â”œâ”€â”€ logs/                          # è¿è¡Œæ—¥å¿—ç›®å½•
â”œâ”€â”€ final_reports/                 # æœ€ç»ˆç”Ÿæˆçš„HTMLæŠ¥å‘Šæ–‡ä»¶
â”œâ”€â”€ utils/                         # é€šç”¨å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ forum_reader.py            # Agenté—´è®ºå›é€šä¿¡
â”‚   â””â”€â”€ retry_helper.py            # ç½‘ç»œè¯·æ±‚é‡è¯•æœºåˆ¶å·¥å…·
â”œâ”€â”€ app.py                         # Flaskä¸»åº”ç”¨å…¥å£
â”œâ”€â”€ config.py                      # å…¨å±€é…ç½®æ–‡ä»¶
â””â”€â”€ requirements.txt               # Pythonä¾èµ–åŒ…æ¸…å•
```

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆDockerï¼‰

### 1. å¯åŠ¨é¡¹ç›®

**è¿è¡Œå‘½ä»¤ï¼š** æ‰§è¡Œä»¥ä¸‹å‘½ä»¤åœ¨**åå°**å¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼š

```bash
docker compose up -d
```

&gt; **æ³¨ï¼šé•œåƒæ‹‰å–é€Ÿåº¦æ…¢**ï¼Œåœ¨åŸ `docker-compose.yml` æ–‡ä»¶ä¸­ï¼Œæˆ‘ä»¬å·²ç»é€šè¿‡**æ³¨é‡Š**çš„æ–¹å¼æä¾›äº†å¤‡ç”¨é•œåƒåœ°å€ä¾›æ‚¨æ›¿æ¢

### 2. é…ç½®è¯´æ˜

#### æ•°æ®åº“é…ç½®ï¼ˆPostgreSQLï¼‰

è¯·æŒ‰ç…§ä»¥ä¸‹å‚æ•°é…ç½®æ•°æ®åº“è¿æ¥ä¿¡æ¯ï¼Œä¹Ÿæ”¯æŒMysqlå¯è‡ªè¡Œä¿®æ”¹ï¼š

| é…ç½®é¡¹ | å¡«å†™å€¼ | è¯´æ˜ |
| :--- | :--- | :--- |
| `DB_HOST` | `db` | æ•°æ®åº“æœåŠ¡åç§° (å¯¹åº” `docker-compose.yml` ä¸­çš„æœåŠ¡å) |
| `DB_PORT` | `5432` | é»˜è®¤ PostgreSQL ç«¯å£ |
| `DB_USER` | `bettafish` | æ•°æ®åº“ç”¨æˆ·å |
| `DB_PASSWORD` | `bettafish` | æ•°æ®åº“å¯†ç  |
| `DB_NAME` | `bettafish` | æ•°æ®åº“åç§° |
| **å…¶ä»–** | **ä¿æŒé»˜è®¤** | æ•°æ®åº“è¿æ¥æ± ç­‰å…¶ä»–å‚æ•°è¯·ä¿æŒé»˜è®¤è®¾ç½®ã€‚ |

#### å¤§æ¨¡å‹é…ç½®

&gt; æˆ‘ä»¬æ‰€æœ‰ LLM è°ƒç”¨ä½¿ç”¨ OpenAI çš„ API æ¥å£æ ‡å‡†

åœ¨å®Œæˆæ•°æ®åº“é…ç½®åï¼Œè¯·æ­£å¸¸é…ç½®**æ‰€æœ‰å¤§æ¨¡å‹ç›¸å…³çš„å‚æ•°**ï¼Œç¡®ä¿ç³»ç»Ÿèƒ½å¤Ÿè¿æ¥åˆ°æ‚¨é€‰æ‹©çš„å¤§æ¨¡å‹æœåŠ¡ã€‚

å®Œæˆä¸Šè¿°æ‰€æœ‰é…ç½®å¹¶ä¿å­˜åï¼Œç³»ç»Ÿå³å¯æ­£å¸¸è¿è¡Œã€‚

## ğŸ”§ æºç å¯åŠ¨æŒ‡å—

&gt; å¦‚æœä½ æ˜¯åˆæ¬¡å­¦ä¹ ä¸€ä¸ªAgentç³»ç»Ÿçš„æ­å»ºï¼Œå¯ä»¥ä»ä¸€ä¸ªéå¸¸ç®€å•çš„demoå¼€å§‹ï¼š[Deep Search Agent Demo](https://github.com/666ghj/DeepSearchAgent-Demo)

### ç¯å¢ƒè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Windowsã€Linuxã€MacOS
- **Pythonç‰ˆæœ¬**: 3.9+
- **Conda**: Anacondaæˆ–Miniconda
- **æ•°æ®åº“**: PostgreSQLï¼ˆæ¨èï¼‰æˆ–MySQL
- **å†…å­˜**: å»ºè®®2GBä»¥ä¸Š

### 1. åˆ›å»ºç¯å¢ƒ

#### å¦‚æœä½¿ç”¨Conda

```bash
# åˆ›å»ºcondaç¯å¢ƒ
conda create -n your_conda_name python=3.11
conda activate your_conda_name
```

#### å¦‚æœä½¿ç”¨uv

```bash
# åˆ›å»ºuvç¯å¢ƒ
uv venv --python 3.11 # åˆ›å»º3.11ç¯å¢ƒ
```

### 2. å®‰è£…ä¾èµ–åŒ…

```bash
# åŸºç¡€ä¾èµ–å®‰è£…
pip install -r requirements.txt

# uvç‰ˆæœ¬å‘½ä»¤ï¼ˆæ›´å¿«é€Ÿå®‰è£…ï¼‰
uv pip install -r requirements.txt
# å¦‚æœä¸æƒ³ä½¿ç”¨æœ¬åœ°æƒ…æ„Ÿåˆ†ææ¨¡å‹ï¼ˆç®—åŠ›éœ€æ±‚å¾ˆå°ï¼Œé»˜è®¤å®‰è£…cpuç‰ˆæœ¬ï¼‰ï¼Œå¯ä»¥å°†è¯¥æ–‡ä»¶ä¸­çš„â€œæœºå™¨å­¦ä¹ â€éƒ¨åˆ†æ³¨é‡Šæ‰å†æ‰§è¡ŒæŒ‡ä»¤
```

### 3. å®‰è£…Playwrightæµè§ˆå™¨é©±åŠ¨

```bash
# å®‰è£…æµè§ˆå™¨é©±åŠ¨ï¼ˆç”¨äºçˆ¬è™«åŠŸèƒ½ï¼‰
playwright install chromium
```

### 4. é…ç½®LLMä¸æ•°æ®åº“

å¤åˆ¶ä¸€ä»½é¡¹ç›®æ ¹ç›®å½• `.env.example` æ–‡ä»¶ï¼Œå‘½åä¸º `.env`

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œå¡«å…¥æ‚¨çš„APIå¯†é’¥ï¼ˆæ‚¨ä¹Ÿå¯ä»¥é€‰æ‹©è‡ªå·±çš„æ¨¡å‹ã€æœç´¢ä»£ç†ï¼Œè¯¦æƒ…è§æ ¹ç›®å½•.env.exampleæ–‡ä»¶å†…æˆ–æ ¹ç›®å½•config.pyä¸­çš„è¯´æ˜ï¼‰ï¼š

```yml
# ====================== æ•°æ®åº“é…ç½® ======================
# æ•°æ®åº“ä¸»æœºï¼Œä¾‹å¦‚localhost æˆ– 127.0.0.1
DB_HOST=your_db_host
# æ•°æ®åº“ç«¯å£å·ï¼Œé»˜è®¤ä¸º3306
DB_PORT=3306
# æ•°æ®åº“ç”¨æˆ·å
DB_USER=your_db_user
# æ•°æ®åº“å¯†ç 
DB_PASSWORD=your_db_password
# æ•°æ®åº“åç§°
DB_NAME=your_db_name
# æ•°æ®åº“å­—ç¬¦é›†ï¼Œæ¨èutf8mb4ï¼Œå…¼å®¹emoji
DB_CHARSET=utf8mb4
# æ•°æ®åº“ç±»å‹postgresqlæˆ–mysql
DB_DIALECT=postgresql
# æ•°æ®åº“ä¸éœ€è¦åˆå§‹åŒ–ï¼Œæ‰§è¡Œapp.pyæ—¶ä¼šè‡ªåŠ¨æ£€æµ‹

# ====================== LLMé…ç½® ======================
# æ‚¨å¯ä»¥æ›´æ”¹æ¯ä¸ªéƒ¨åˆ†LLMä½¿ç”¨çš„APIï¼Œåªè¦å…¼å®¹OpenAIè¯·æ±‚æ ¼å¼éƒ½å¯ä»¥

# Insight Agent
INSIGHT_ENGINE_API_KEY=
# Insight Agent LLMæ¥å£BaseUrlï¼Œå¯è‡ªå®šä¹‰å‚å•†API
INSIGHT_ENGINE_BASE_URL=
# Insight Agent LLMæ¨¡å‹åç§°ï¼Œå¦‚kimi-k2-0711-preview
INSIGHT_ENGINE_MODEL_NAME=

# Media Agent
...
```
æ¨èLLM APIä¾›åº”å•†ï¼š[æ¨ç†æ—¶ä»£](https://aihubmix.com/?aff=8Ds9)

### 5. å¯åŠ¨ç³»ç»Ÿ

#### 5.1 å®Œæ•´ç³»ç»Ÿå¯åŠ¨ï¼ˆæ¨èï¼‰

```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œæ¿€æ´»condaç¯å¢ƒ
conda activate your_conda_name

# å¯åŠ¨ä¸»åº”ç”¨å³å¯
python app.py
```

uv ç‰ˆæœ¬å¯åŠ¨å‘½ä»¤ 
```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œæ¿€æ´»uvç¯å¢ƒ
.venv\Scripts\activate

# å¯åŠ¨ä¸»åº”ç”¨å³å¯
python app.py
```

&gt; æ³¨1ï¼šä¸€æ¬¡è¿è¡Œç»ˆæ­¢åï¼Œstreamlit appå¯èƒ½ç»“æŸå¼‚å¸¸ä»ç„¶å ç”¨ç«¯å£ï¼Œæ­¤æ—¶æœç´¢å ç”¨ç«¯å£çš„è¿›ç¨‹killæ‰å³å¯

&gt; æ³¨2ï¼šæ•°æ®çˆ¬å–éœ€è¦å•ç‹¬æ“ä½œï¼Œè§5.3æŒ‡å¼•

&gt; æ³¨3ï¼šå¦‚æœæœåŠ¡å™¨è¿œç¨‹éƒ¨ç½²å‡ºç°é¡µé¢æ˜¾ç¤ºé—®é¢˜ï¼Œè§[PR#45](https://github.com/666ghj/BettaFish/pull/45)

è®¿é—® http://localhost:5000 å³å¯ä½¿ç”¨å®Œæ•´ç³»ç»Ÿ

#### 5.2 å•ç‹¬å¯åŠ¨æŸä¸ªAgent

```bash
# å¯åŠ¨QueryEngine
streamlit run SingleEngineApp/query_engine_streamlit_app.py --server.port 8503

# å¯åŠ¨MediaEngine  
streamlit run SingleEngineApp/media_engine_streamlit_app.py --server.port 8502

# å¯åŠ¨InsightEngine
streamlit run SingleEngineApp/insight_engine_streamlit_app.py --server.port 8501
```

#### 5.3 çˆ¬è™«ç³»ç»Ÿå•ç‹¬ä½¿ç”¨

è¿™éƒ¨åˆ†æœ‰è¯¦ç»†çš„é…ç½®æ–‡æ¡£ï¼š[MindSpiderä½¿ç”¨è¯´æ˜](./MindSpider/README.md)

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;MindSpider\img\example.png&quot; alt=&quot;banner&quot; width=&quot;600&quot;&gt;

MindSpider è¿è¡Œç¤ºä¾‹
&lt;/div&gt;

```bash
# è¿›å…¥çˆ¬è™«ç›®å½•
cd MindSpider

# é¡¹ç›®åˆå§‹åŒ–
python main.py --setup

# è¿è¡Œè¯é¢˜æå–ï¼ˆè·å–çƒ­ç‚¹æ–°é—»å’Œå…³é”®è¯ï¼‰
python main.py --broad-topic

# è¿è¡Œå®Œæ•´çˆ¬è™«æµç¨‹
python main.py --complete --date 2024-01-20

# ä»…è¿è¡Œè¯é¢˜æå–
python main.py --broad-topic --date 2024-01-20

# ä»…è¿è¡Œæ·±åº¦çˆ¬å–
python main.py --deep-sentiment --platforms xhs dy wb
```

## âš™ï¸ é«˜çº§é…ç½®ï¼ˆå·²è¿‡æ—¶ï¼Œå·²ç»ç»Ÿä¸€ä¸ºé¡¹ç›®æ ¹ç›®å½•.envæ–‡ä»¶ç®¡ç†ï¼Œå…¶ä»–å­agentè‡ªåŠ¨ç»§æ‰¿æ ¹ç›®å½•é…ç½®ï¼‰

### ä¿®æ”¹å…³é”®å‚æ•°

#### Agenté…ç½®å‚æ•°

æ¯ä¸ªAgentéƒ½æœ‰ä¸“é—¨çš„é…ç½®æ–‡ä»¶ï¼Œå¯æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼Œä¸‹é¢æ˜¯éƒ¨åˆ†ç¤ºä¾‹ï¼š

```python
# QueryEngine/utils/config.py
class Config:
    max_reflections = 2           # åæ€è½®æ¬¡
    max_search_results = 15       # æœ€å¤§æœç´¢ç»“æœæ•°
    max_content_length = 8000     # æœ€å¤§å†…å®¹é•¿åº¦
    
# MediaEngine/utils/config.py  
class Config:
    comprehensive_search_limit = 10  # ç»¼åˆæœç´¢é™åˆ¶
    web_search_limit = 15           # ç½‘é¡µæœç´¢é™åˆ¶
    
# InsightEngine/utils/config.py
class Config:
    default_search_topic_globally_limit = 200    # å…¨å±€æœç´¢é™åˆ¶
    default_get_comments_limit = 500             # è¯„è®ºè·å–é™åˆ¶
    max_search_results_for_llm = 50              # ä¼ ç»™LLMçš„æœ€å¤§ç»“æœæ•°
```

#### æƒ…æ„Ÿåˆ†ææ¨¡å‹é…ç½®

```python
# InsightEngine/tools/sentiment_analyzer.py
SENTIMENT_CONFIG = {
    &#039;model_type&#039;: &#039;multilingual&#039;,     # å¯é€‰: &#039;bert&#039;, &#039;multilingual&#039;, &#039;qwen&#039;ç­‰
    &#039;confidence_threshold&#039;: 0.8,      # ç½®ä¿¡åº¦é˜ˆå€¼
    &#039;batch_size&#039;: 32,                 # æ‰¹å¤„ç†å¤§å°
    &#039;max_sequence_length&#039;: 512,       # æœ€å¤§åºåˆ—é•¿åº¦
}
```

### æ¥å…¥ä¸åŒçš„LLMæ¨¡å‹

æ”¯æŒä»»æ„openAIè°ƒç”¨æ ¼å¼çš„LLMæä¾›å•†ï¼Œåªéœ€è¦åœ¨/config.pyä¸­å¡«å†™å¯¹åº”çš„KEYã€BASE_URLã€MODEL_NAMEå³å¯ã€‚

&gt; ä»€ä¹ˆæ˜¯openAIè°ƒç”¨æ ¼å¼ï¼Ÿä¸‹é¢æä¾›ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼š
&gt;```python
&gt;from openai import OpenAI
&gt;
&gt;client = OpenAI(api_key=&quot;your_api_key&quot;, 
&gt;                base_url=&quot;https://api.siliconflow.cn/v1&quot;)
&gt;
&gt;response = client.chat.completions.create(
&gt;    model=&quot;Qwen/Qwen2.5-72B-Instruct&quot;,
&gt;    messages=[
&gt;        {&#039;role&#039;: &#039;user&#039;, 
&gt;         &#039;content&#039;: &quot;æ¨ç†æ¨¡å‹ä¼šç»™å¸‚åœºå¸¦æ¥å“ªäº›æ–°çš„æœºä¼š&quot;}
&gt;    ],
&gt;)
&gt;
&gt;complete_response = response.choices[0].message.content
&gt;print(complete_response)
&gt;```

### æ›´æ”¹æƒ…æ„Ÿåˆ†ææ¨¡å‹

ç³»ç»Ÿé›†æˆäº†å¤šç§æƒ…æ„Ÿåˆ†ææ–¹æ³•ï¼Œå¯æ ¹æ®éœ€æ±‚é€‰æ‹©ï¼š

#### 1. å¤šè¯­è¨€æƒ…æ„Ÿåˆ†æ

```bash
cd SentimentAnalysisModel/WeiboMultilingualSentiment
python predict.py --text &quot;This product is amazing!&quot; --lang &quot;en&quot;
```

#### 2. å°å‚æ•°Qwen3å¾®è°ƒ

```bash
cd SentimentAnalysisModel/WeiboSentiment_SmallQwen
python predict_universal.py --text &quot;è¿™æ¬¡æ´»åŠ¨åŠå¾—å¾ˆæˆåŠŸ&quot;
```

#### 3. åŸºäºBERTçš„å¾®è°ƒæ¨¡å‹

```bash
# ä½¿ç”¨BERTä¸­æ–‡æ¨¡å‹
cd SentimentAnalysisModel/WeiboSentiment_Finetuned/BertChinese-Lora
python predict.py --text &quot;è¿™ä¸ªäº§å“çœŸçš„å¾ˆä¸é”™&quot;
```

#### 4. GPT-2 LoRAå¾®è°ƒæ¨¡å‹

```bash
cd SentimentAnalysisModel/WeiboSentiment_Finetuned/GPT2-Lora
python predict.py --text &quot;ä»Šå¤©å¿ƒæƒ…ä¸å¤ªå¥½&quot;
```

#### 5. ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•

```bash
cd SentimentAnalysisModel/WeiboSentiment_MachineLearning
python predict.py --model_type &quot;svm&quot; --text &quot;æœåŠ¡æ€åº¦éœ€è¦æ”¹è¿›&quot;
```

### æ¥å…¥è‡ªå®šä¹‰ä¸šåŠ¡æ•°æ®åº“

#### 1. ä¿®æ”¹æ•°æ®åº“è¿æ¥é…ç½®

```python
# config.py ä¸­æ·»åŠ æ‚¨çš„ä¸šåŠ¡æ•°æ®åº“é…ç½®
BUSINESS_DB_HOST = &quot;your_business_db_host&quot;
BUSINESS_DB_PORT = 3306
BUSINESS_DB_USER = &quot;your_business_user&quot;
BUSINESS_DB_PASSWORD = &quot;your_business_password&quot;
BUSINESS_DB_NAME = &quot;your_business_database&quot;
```

#### 2. åˆ›å»ºè‡ªå®šä¹‰æ•°æ®è®¿é—®å·¥å…·

```python
# InsightEngine/tools/custom_db_tool.py
class CustomBusinessDBTool:
    &quot;&quot;&quot;è‡ªå®šä¹‰ä¸šåŠ¡æ•°æ®åº“æŸ¥è¯¢å·¥å…·&quot;&quot;&quot;
    
    def __init__(self):
        self.connection_config = {
            &#039;host&#039;: config.BUSINESS_DB_HOST,
            &#039;port&#039;: config.BUSINESS_DB_PORT,
            &#039;user&#039;: config.BUSINESS_DB_USER,
            &#039;password&#039;: config.BUSINESS_DB_PASSWORD,
            &#039;database&#039;: config.BUSINESS_DB_NAME,
        }
    
    def search_business_data(self, query: str, table: str):
        &quot;&quot;&quot;æŸ¥è¯¢ä¸šåŠ¡æ•°æ®&quot;&quot;&quot;
        # å®ç°æ‚¨çš„ä¸šåŠ¡é€»è¾‘
        pass
    
    def get_customer_feedback(self, product_id: str):
        &quot;&quot;&quot;è·å–å®¢æˆ·åé¦ˆæ•°æ®&quot;&quot;&quot;
        # å®ç°å®¢æˆ·åé¦ˆæŸ¥è¯¢é€»è¾‘
        pass
```

#### 3. é›†æˆåˆ°InsightEngine

```python
# InsightEngine/agent.py ä¸­é›†æˆè‡ªå®šä¹‰å·¥å…·
from .tools.custom_db_tool import CustomBusinessDBTool

class DeepSearchAgent:
    def __init__(self, config=None):
        # ... å…¶ä»–åˆå§‹åŒ–ä»£ç 
        self.custom_db_tool = CustomBusinessDBTool()
    
    def execute_custom_search(self, query: str):
        &quot;&quot;&quot;æ‰§è¡Œè‡ªå®šä¹‰ä¸šåŠ¡æ•°æ®æœç´¢&quot;&quot;&quot;
        return self.custom_db_tool.search_business_data(query, &quot;your_table&quot;)
```

### è‡ªå®šä¹‰æŠ¥å‘Šæ¨¡æ¿

#### 1. åœ¨Webç•Œé¢ä¸­ä¸Šä¼ 

ç³»ç»Ÿæ”¯æŒä¸Šä¼ è‡ªå®šä¹‰æ¨¡æ¿æ–‡ä»¶ï¼ˆ.mdæˆ–.txtæ ¼å¼ï¼‰ï¼Œå¯åœ¨ç”ŸæˆæŠ¥å‘Šæ—¶é€‰æ‹©ä½¿ç”¨ã€‚

#### 2. åˆ›å»ºæ¨¡æ¿æ–‡ä»¶

åœ¨ `ReportEngine/report_template/` ç›®å½•ä¸‹åˆ›å»ºæ–°çš„æ¨¡æ¿ï¼Œæˆ‘ä»¬çš„Agentä¼šè‡ªè¡Œé€‰ç”¨æœ€åˆé€‚çš„æ¨¡æ¿ã€‚

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼

### å¦‚ä½•è´¡çŒ®

1. **Forké¡¹ç›®**åˆ°æ‚¨çš„GitHubè´¦å·
2. **åˆ›å»ºFeatureåˆ†æ”¯**ï¼š`git checkout -b feature/AmazingFeature`
3. **æäº¤æ›´æ”¹**ï¼š`git commit -m &#039;Add some AmazingFeature&#039;`
4. **æ¨é€åˆ°åˆ†æ”¯**ï¼š`git push origin feature/AmazingFeature`
5. **å¼€å¯Pull Request**

### å¼€å‘è§„èŒƒ

- ä»£ç éµå¾ªPEP8è§„èŒƒ
- æäº¤ä¿¡æ¯ä½¿ç”¨æ¸…æ™°çš„ä¸­è‹±æ–‡æè¿°
- æ–°åŠŸèƒ½éœ€è¦åŒ…å«ç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹
- æ›´æ–°ç›¸å…³æ–‡æ¡£

## ğŸ¦– ä¸‹ä¸€æ­¥å¼€å‘è®¡åˆ’

ç°åœ¨ç³»ç»Ÿåªå®Œæˆäº†&quot;ä¸‰æ¿æ–§&quot;ä¸­çš„å‰ä¸¤æ­¥ï¼Œå³ï¼šè¾“å…¥è¦æ±‚-&gt;è¯¦ç»†åˆ†æï¼Œè¿˜ç¼ºå°‘ä¸€æ­¥é¢„æµ‹ï¼Œç›´æ¥å°†ä»–ç»§ç»­äº¤ç»™LLMæ˜¯ä¸å…·æœ‰è¯´æœåŠ›çš„ã€‚

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;static/image/banner_compressed.png&quot; alt=&quot;banner&quot; width=&quot;800&quot;&gt;
&lt;/div&gt;

ç›®å‰æˆ‘ä»¬ç»è¿‡å¾ˆé•¿ä¸€æ®µæ—¶é—´çš„çˆ¬å–æ”¶é›†ï¼Œæ‹¥æœ‰äº†å¤§é‡å…¨ç½‘è¯é¢˜çƒ­åº¦éšæ—¶é—´ã€çˆ†ç‚¹ç­‰çš„å˜åŒ–è¶‹åŠ¿çƒ­åº¦æ•°æ®ï¼Œå·²ç»å…·å¤‡äº†å¯ä»¥å¼€å‘é¢„æµ‹æ¨¡å‹çš„æ¡ä»¶ã€‚æˆ‘ä»¬å›¢é˜Ÿå°†è¿ç”¨æ—¶åºæ¨¡å‹ã€å›¾ç¥ç»ç½‘ç»œã€å¤šæ¨¡æ€èåˆç­‰é¢„æµ‹æ¨¡å‹æŠ€æœ¯å‚¨å¤‡äºæ­¤ï¼Œå®ç°çœŸæ­£åŸºäºæ•°æ®é©±åŠ¨çš„èˆ†æƒ…é¢„æµ‹åŠŸèƒ½ã€‚

## âš ï¸ å…è´£å£°æ˜

**é‡è¦æé†’ï¼šæœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ ã€å­¦æœ¯ç ”ç©¶å’Œæ•™è‚²ç›®çš„ä½¿ç”¨**

1. **åˆè§„æ€§å£°æ˜**ï¼š
   - æœ¬é¡¹ç›®ä¸­çš„æ‰€æœ‰ä»£ç ã€å·¥å…·å’ŒåŠŸèƒ½å‡ä»…ä¾›å­¦ä¹ ã€å­¦æœ¯ç ”ç©¶å’Œæ•™è‚²ç›®çš„ä½¿ç”¨
   - ä¸¥ç¦å°†æœ¬é¡¹ç›®ç”¨äºä»»ä½•å•†ä¸šç”¨é€”æˆ–ç›ˆåˆ©æ€§æ´»åŠ¨
   - ä¸¥ç¦å°†æœ¬é¡¹ç›®ç”¨äºä»»ä½•è¿æ³•ã€è¿è§„æˆ–ä¾µçŠ¯ä»–äººæƒç›Šçš„è¡Œä¸º

2. **çˆ¬è™«åŠŸèƒ½å…è´£**ï¼š
   - é¡¹ç›®ä¸­çš„çˆ¬è™«åŠŸèƒ½ä»…ç”¨äºæŠ€æœ¯å­¦ä¹ å’Œç ”ç©¶ç›®çš„
   - ä½¿ç”¨è€…å¿…é¡»éµå®ˆç›®æ ‡ç½‘ç«™çš„robots.txtåè®®å’Œä½¿ç”¨æ¡æ¬¾
   - ä½¿ç”¨è€…å¿…é¡»éµå®ˆç›¸å…³æ³•å¾‹æ³•è§„ï¼Œä¸å¾—è¿›è¡Œæ¶æ„çˆ¬å–æˆ–æ•°æ®æ»¥ç”¨
   - å› ä½¿ç”¨çˆ¬è™«åŠŸèƒ½äº§ç”Ÿçš„ä»»ä½•æ³•å¾‹åæœç”±ä½¿ç”¨è€…è‡ªè¡Œæ‰¿æ‹…

3. **æ•°æ®ä½¿ç”¨å…è´£**ï¼š
   - é¡¹ç›®æ¶‰åŠçš„æ•°æ®åˆ†æåŠŸèƒ½ä»…ä¾›å­¦æœ¯ç ”ç©¶ä½¿ç”¨
   - ä¸¥ç¦å°†åˆ†æç»“æœç”¨äºå•†ä¸šå†³ç­–æˆ–ç›ˆåˆ©ç›®çš„
   - ä½¿ç”¨è€…åº”ç¡®ä¿æ‰€åˆ†ææ•°æ®çš„åˆæ³•æ€§å’Œåˆè§„æ€§

4. **æŠ€æœ¯å…è´£**ï¼š
   - æœ¬é¡¹ç›®æŒ‰&quot;ç°çŠ¶&quot;æä¾›ï¼Œä¸æä¾›ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„ä¿è¯
   - ä½œè€…ä¸å¯¹ä½¿ç”¨æœ¬é¡¹ç›®é€ æˆçš„ä»»ä½•ç›´æ¥æˆ–é—´æ¥æŸå¤±æ‰¿æ‹…è´£ä»»
   - ä½¿ç”¨è€…åº”è‡ªè¡Œè¯„ä¼°é¡¹ç›®çš„é€‚ç”¨æ€§å’Œé£é™©

5. **è´£ä»»é™åˆ¶**ï¼š
   - ä½¿ç”¨è€…åœ¨ä½¿ç”¨æœ¬é¡¹ç›®å‰åº”å……åˆ†äº†è§£ç›¸å…³æ³•å¾‹æ³•è§„
   - ä½¿ç”¨è€…åº”ç¡®ä¿å…¶ä½¿ç”¨è¡Œä¸ºç¬¦åˆå½“åœ°æ³•å¾‹æ³•è§„è¦æ±‚
   - å› è¿åæ³•å¾‹æ³•è§„ä½¿ç”¨æœ¬é¡¹ç›®è€Œäº§ç”Ÿçš„ä»»ä½•åæœç”±ä½¿ç”¨è€…è‡ªè¡Œæ‰¿æ‹…

**è¯·åœ¨ä½¿ç”¨æœ¬é¡¹ç›®å‰ä»”ç»†é˜…è¯»å¹¶ç†è§£ä¸Šè¿°å…è´£å£°æ˜ã€‚ä½¿ç”¨æœ¬é¡¹ç›®å³è¡¨ç¤ºæ‚¨å·²åŒæ„å¹¶æ¥å—ä¸Šè¿°æ‰€æœ‰æ¡æ¬¾ã€‚**

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [GPL-2.0è®¸å¯è¯](LICENSE)ã€‚è¯¦ç»†ä¿¡æ¯è¯·å‚é˜…LICENSEæ–‡ä»¶ã€‚

## ğŸ‰ æ”¯æŒä¸è”ç³»

### è·å–å¸®åŠ©

å¸¸è§é—®é¢˜è§£ç­”ï¼šhttps://github.com/666ghj/BettaFish/issues/185

- **é¡¹ç›®ä¸»é¡µ**ï¼š[GitHubä»“åº“](https://github.com/666ghj/BettaFish)
- **é—®é¢˜åé¦ˆ**ï¼š[Issuesé¡µé¢](https://github.com/666ghj/BettaFish/issues)
- **åŠŸèƒ½å»ºè®®**ï¼š[Discussionsé¡µé¢](https://github.com/666ghj/BettaFish/discussions)

### è”ç³»æ–¹å¼

- ğŸ“§ **é‚®ç®±**ï¼š670939375@qq.com

### å•†åŠ¡åˆä½œ

- **ä¼ä¸šå®šåˆ¶å¼€å‘**
- **å¤§æ•°æ®æœåŠ¡**
- **å­¦æœ¯åˆä½œ**
- **æŠ€æœ¯åŸ¹è®­**

## ğŸ‘¥ è´¡çŒ®è€…

æ„Ÿè°¢ä»¥ä¸‹ä¼˜ç§€çš„è´¡çŒ®è€…ä»¬ï¼š

[![Contributors](https://contrib.rocks/image?repo=666ghj/BettaFish)](https://github.com/666ghj/BettaFish/graphs/contributors)

## ğŸ“ˆ é¡¹ç›®ç»Ÿè®¡

&lt;a href=&quot;https://www.star-history.com/#666ghj/BettaFish&amp;type=date&amp;legend=top-left&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;type=date&amp;theme=dark&amp;legend=top-left&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;type=date&amp;legend=top-left&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;type=date&amp;legend=top-left&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

![Alt](https://repobeats.axiom.co/api/embed/e04e3eea4674edc39c148a7845c8d09c1b7b1922.svg &quot;Repobeats analytics image&quot;)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[airweave-ai/airweave]]></title>
            <link>https://github.com/airweave-ai/airweave</link>
            <guid>https://github.com/airweave-ai/airweave</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:29 GMT</pubDate>
            <description><![CDATA[Context retrieval for AI agents across apps and databases]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/airweave-ai/airweave">airweave-ai/airweave</a></h1>
            <p>Context retrieval for AI agents across apps and databases</p>
            <p>Language: Python</p>
            <p>Stars: 4,756</p>
            <p>Forks: 576</p>
            <p>Stars today: 119 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;frontend/public/logo-airweave-darkbg.svg&quot;/&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;frontend/public/logo-airweave-lightbg.svg&quot;/&gt;
  &lt;img width=&quot;837&quot; alt=&quot;airweave-lettermark&quot; style=&quot;padding-bottom: 12px;&quot; src=&quot;frontend/public/logo-airweave-darkbg.svg&quot;/&gt;
&lt;/picture&gt;

# Context Retrieval for AI Agents across Apps &amp; Databases

[![Ruff](https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml/badge.svg)](https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml)
[![ESLint](https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml/badge.svg)](https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml)
[![System Tests](https://github.com/airweave-ai/airweave/actions/workflows/test-public-api.yml/badge.svg)](https://github.com/airweave-ai/airweave/actions/workflows/test-public-api.yml)
[![PyPI Downloads](https://static.pepy.tech/personalized-badge/airweave-sdk?period=total&amp;units=INTERNATIONAL_SYSTEM&amp;left_color=GRAY&amp;right_color=BRIGHTGREEN&amp;left_text=downloads)](https://pepy.tech/projects/airweave-sdk)
[![Discord](https://img.shields.io/discord/1323415085011701870?label=Discord&amp;logo=discord&amp;logoColor=white&amp;style=flat-square)](https://discord.gg/gDuebsWGkn)
&lt;br&gt;
&lt;div style=&quot;padding-top: 16px;&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/13748&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13748&quot; alt=&quot;airweave-ai%2Fairweave | Trendshift&quot; style=&quot;width: 250px; height: 55px; margin-right: 24px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://www.ycombinator.com/launches/NX7-airweave-let-agents-search-any-app&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://www.ycombinator.com/launches/NX7-airweave-let-agents-search-any-app/upvote_embed.svg&quot; alt=&quot;Launch YC: Airweave - Let Agents Search Any App&quot; style=&quot;margin-left: 12px;&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;br&gt;

â­ **Help us reach more developers and grow the Airweave community. Star this repo!**

&lt;/div&gt;

## What is Airweave?

[Airweave](https://app.airweave.ai/) is a fully open-source context retrieval layer for AI agents across apps and databases. It connects to apps, productivity tools, databases, or document stores and transforms their contents into searchable knowledge bases, accessible through a standardized interface for agents.

The search interface is exposed via REST API or MCP. When using MCP, Airweave essentially builds a semantically searchable MCP server. The platform handles everything from auth and extraction to embedding and serving. You can find our documentation [here](https://docs.airweave.ai/welcome).

ğŸ“º Check out a quick demo of Airweave below:

&lt;video width=&quot;100%&quot; src=&quot;https://github.com/user-attachments/assets/995e4a36-3f88-4d8e-b401-6ca43db0c7bf&quot; controls&gt;&lt;/video&gt;

[**ğŸ”— Example notebooks**](https://github.com/airweave-ai/airweave/tree/main/examples)

## Table of Contents

- [Airweave](#airweave)
  - [Overview](#overview)
  - [Table of Contents](#table-of-contents)
  - [ğŸš€ Quick Start](#-quick-start)
  - [ğŸ”Œ Supported Integrations](#-supported-integrations)
  - [ğŸ’» Usage](#-usage)
    - [Frontend](#frontend)
    - [API](#api)
  - [ğŸ“¦ SDKs](#-sdks)
    - [Python](#python)
    - [TypeScript/JavaScript](#typescriptjavascript)
  - [ğŸ”‘ Key Features](#-key-features)
  - [ğŸ”§ Technology Stack](#-tech-stack)
  - [ğŸ‘¥ Contributing](#-contributing)
  - [ğŸ“„ License](#-license)
  - [ğŸ”— Connect](#-connect)

## ğŸš€ Quick Start

### Managed Service: [Airweave Cloud](https://app.airweave.ai/)

### Self-hosted:

Make sure docker and docker-compose are installed, then...

```bash
# 1. Clone the repository
git clone https://github.com/airweave-ai/airweave.git
cd airweave

# 2. Build and run
chmod +x start.sh
./start.sh
```

That&#039;s it! Access the dashboard at http://localhost:8080

## ğŸ”Œ Supported Integrations

&lt;!-- START_APP_GRID --&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/airtable.svg&quot; alt=&quot;Airtable&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/asana.svg&quot; alt=&quot;Asana&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/attio.svg&quot; alt=&quot;Attio&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/bitbucket.svg&quot; alt=&quot;Bitbucket&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/box.svg&quot; alt=&quot;Box&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/clickup.svg&quot; alt=&quot;ClickUp&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/confluence.svg&quot; alt=&quot;Confluence&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/ctti.svg&quot; alt=&quot;CTTI&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/dropbox.svg&quot; alt=&quot;Dropbox&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/excel.svg&quot; alt=&quot;Excel&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/github.svg&quot; alt=&quot;Github&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/gitlab.svg&quot; alt=&quot;Gitlab&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/gmail.svg&quot; alt=&quot;Gmail&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/google_calendar.svg&quot; alt=&quot;Google Calendar&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/google_docs.svg&quot; alt=&quot;Google Docs&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/google_drive.svg&quot; alt=&quot;Google Drive&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/google_slides.svg&quot; alt=&quot;Google Slides&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/hubspot.svg&quot; alt=&quot;Hubspot&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/jira.svg&quot; alt=&quot;Jira&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/linear.svg&quot; alt=&quot;Linear&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/monday.svg&quot; alt=&quot;Monday&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/notion.svg&quot; alt=&quot;Notion&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/onedrive.svg&quot; alt=&quot;Onedrive&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/onenote.svg&quot; alt=&quot;OneNote&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/outlook_calendar.svg&quot; alt=&quot;Outlook Calendar&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/outlook_mail.svg&quot; alt=&quot;Outlook Mail&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/postgresql.svg&quot; alt=&quot;Postgresql&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/salesforce.svg&quot; alt=&quot;Salesforce&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/sharepoint.svg&quot; alt=&quot;Sharepoint&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/slack.svg&quot; alt=&quot;Slack&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/stripe.svg&quot; alt=&quot;Stripe&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/teams.svg&quot; alt=&quot;Teams&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/todoist.svg&quot; alt=&quot;Todoist&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/trello.svg&quot; alt=&quot;Trello&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/word.svg&quot; alt=&quot;Word&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;img src=&quot;frontend/src/components/icons/apps/zendesk.svg&quot; alt=&quot;Zendesk&quot; width=&quot;50&quot; height=&quot;50&quot; style=&quot;margin: 8px;&quot; /&gt;
&lt;/p&gt;

&lt;!-- END_APP_GRID --&gt;

## ğŸ’» Usage

### Frontend
- Access the UI at `http://localhost:8080`
- Connect sources, configure syncs, and query data

### API
- Swagger docs: `http://localhost:8001/docs`
- Create connections, trigger syncs, and search data

## ğŸ“¦ SDKs

### Python

```bash
pip install airweave-sdk
```

```python
from airweave import AirweaveSDK

# Initialize client
client = AirweaveSDK(
    api_key=&quot;YOUR_API_KEY&quot;,
    base_url=&quot;http://localhost:8001&quot;
)

# Create a collection
collection = client.collections.create(name=&quot;My Collection&quot;)

# Add a source connection
source = client.source_connections.create(
    name=&quot;My Stripe Connection&quot;,
    short_name=&quot;stripe&quot;,
    readable_collection_id=collection.readable_id,
    authentication={
        &quot;credentials&quot;: {&quot;api_key&quot;: &quot;your_stripe_api_key&quot;}
    }
)

# Semantic search (default)
results = client.collections.search(
    readable_id=collection.readable_id,
    query=&quot;Find recent failed payments&quot;
)

# Hybrid search (semantic + keyword)
results = client.collections.search(
    readable_id=collection.readable_id,
    query=&quot;customer invoices Q4 2024&quot;,
    search_type=&quot;hybrid&quot;
)

# With query expansion and reranking
results = client.collections.search(
    readable_id=collection.readable_id,
    query=&quot;technical documentation&quot;,
    enable_query_expansion=True,
    enable_reranking=True,
    top_k=20
)

# Search with recency bias (prioritize recent results)
results = client.collections.search(
    readable_id=collection.readable_id,
    query=&quot;critical bugs&quot;,
    recency_bias=0.8,  # 0.0 to 1.0, higher = more recent
    limit=10
)

# Get AI-generated answer instead of raw results
answer = client.collections.search(
    readable_id=collection.readable_id,
    query=&quot;What are our customer refund policies?&quot;,
    response_type=&quot;completion&quot;,
    enable_reranking=True
)
```

### TypeScript/JavaScript
```bash
npm install @airweave/sdk
# or
yarn add @airweave/sdk
```

```typescript
import { AirweaveSDKClient, AirweaveSDKEnvironment } from &quot;@airweave/sdk&quot;;

// Initialize client
const client = new AirweaveSDKClient({
    apiKey: &quot;YOUR_API_KEY&quot;,
    environment: AirweaveSDKEnvironment.Local
});

// Create a collection
const collection = await client.collections.create({
    name: &quot;My Collection&quot;
});

// Add a source connection
const source = await client.sourceConnections.create({
    name: &quot;My Stripe Connection&quot;,
    shortName: &quot;stripe&quot;,
    readableCollectionId: collection.readableId,
    authentication: {
        credentials: { apiKey: &quot;your_stripe_api_key&quot; }
    }
});

// Semantic search (default)
const results = await client.collections.search(
    collection.readableId,
    { query: &quot;Find recent failed payments&quot; }
);

// Hybrid search (semantic + keyword)
const hybridResults = await client.collections.search(
    collection.readableId,
    {
        query: &quot;customer invoices Q4 2024&quot;,
        searchType: &quot;hybrid&quot;
    }
);

// With query expansion and reranking
const advancedResults = await client.collections.search(
    collection.readableId,
    {
        query: &quot;technical documentation&quot;,
        enableQueryExpansion: true,
        enableReranking: true,
        topK: 20
    }
);

// Search with recency bias (prioritize recent results)
const recentResults = await client.collections.search(
    collection.readableId,
    {
        query: &quot;critical bugs&quot;,
        recencyBias: 0.8,  // 0.0 to 1.0, higher = more recent
        limit: 10
    }
);

// Get AI-generated answer instead of raw results
const answer = await client.collections.search(
    collection.readableId,
    {
        query: &quot;What are our customer refund policies?&quot;,
        responseType: &quot;completion&quot;,
        enableReranking: true
    }
);
```

## ğŸ”‘ Key Features

- **Data synchronization** from 30+ sources with minimal config
- **Entity extraction** and transformation pipeline
- **Multi-tenant** architecture with OAuth2
- **Incremental updates** using content hashing
- **Semantic search** for agent queries
- **Versioning** for data changes

## ğŸ”§ Tech Stack

- **Frontend**: React/TypeScript with ShadCN
- **Backend**: FastAPI (Python)
- **Databases**: PostgreSQL (metadata), Qdrant (vectors)
- **Workers**: Temporal (workflow orchestration), Redis (pub/sub)
- **Deployment**: Docker Compose (dev), Kubernetes (prod)

## ğŸ‘¥ Contributing

We welcome contributions! Please check [CONTRIBUTING.md](https://github.com/airweave-ai/airweave/blob/main/CONTRIBUTING.md) for details.

## ğŸ“„ License

Airweave is released under the [MIT](LICENSE) license.

## ğŸ”— Connect

- **[Discord](https://discord.com/invite/484HY9Ehxt)** - Get help and discuss features
- **[GitHub Issues](https://github.com/airweave-ai/airweave/issues)** - Report bugs or request features
- **[Twitter](https://x.com/airweave_ai)** - Follow for updates
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[awslabs/mcp]]></title>
            <link>https://github.com/awslabs/mcp</link>
            <guid>https://github.com/awslabs/mcp</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:28 GMT</pubDate>
            <description><![CDATA[AWS MCP Servers â€” helping you get the most out of AWS, wherever you use MCP.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/awslabs/mcp">awslabs/mcp</a></h1>
            <p>AWS MCP Servers â€” helping you get the most out of AWS, wherever you use MCP.</p>
            <p>Language: Python</p>
            <p>Stars: 7,245</p>
            <p>Forks: 1,051</p>
            <p>Stars today: 198 stars today</p>
            <h2>README</h2><pre># AWS MCP Servers

A suite of specialized MCP servers that help you get the most out of AWS, wherever you use MCP.

[![GitHub](https://img.shields.io/badge/github-awslabs/mcp-blue.svg?style=flat&amp;logo=github)](https://github.com/awslabs/mcp)
[![License](https://img.shields.io/badge/license-Apache--2.0-brightgreen)](LICENSE)
[![Codecov](https://img.shields.io/codecov/c/github/awslabs/mcp)](https://app.codecov.io/gh/awslabs/mcp)
[![OSSF-Scorecard Score](https://img.shields.io/ossf-scorecard/github.com/awslabs/mcp)](https://scorecard.dev/viewer/?uri=github.com/awslabs/mcp)

## Table of Contents

- [AWS MCP Servers](#aws-mcp-servers)
  - [Table of Contents](#table-of-contents)
  - [What is the Model Context Protocol (MCP) and how does it work with AWS MCP Servers?](#what-is-the-model-context-protocol-mcp-and-how-does-it-work-with-aws-mcp-servers)
  - [AWS MCP Servers Transport Mechanisms](#aws-mcp-servers-transport-mechanisms)
    - [Supported transport mechanisms](#supported-transport-mechanisms)
    - [Server Sent Events Support Removal](#server-sent-events-support-removal)
  - [Why AWS MCP Servers?](#why-aws-mcp-servers)
  - [Available MCP Servers: Quick Installation](#available-mcp-servers-quick-installation)
    - [ğŸš€Getting Started with AWS](#-getting-started-with-aws)
    - [Browse by What You&#039;re Building](#browse-by-what-youre-building)
      - [ğŸ“š Real-time access to official AWS documentation](#-real-time-access-to-official-aws-documentation)
      - [ğŸ—ï¸ Infrastructure \&amp; Deployment](#ï¸-infrastructure--deployment)
        - [Infrastructure as Code](#infrastructure-as-code)
        - [Container Platforms](#container-platforms)
        - [Serverless \&amp; Functions](#serverless--functions)
        - [Support](#support)
      - [ğŸ¤– AI \&amp; Machine Learning](#-ai--machine-learning)
      - [ğŸ“Š Data \&amp; Analytics](#-data--analytics)
        - [SQL \&amp; NoSQL Databases](#sql--nosql-databases)
        - [Search \&amp; Analytics](#search--analytics)
        - [Caching \&amp; Performance](#caching--performance)
      - [ğŸ› ï¸ Developer Tools \&amp; Support](#ï¸-developer-tools--support)
      - [ğŸ“¡ Integration \&amp; Messaging](#-integration--messaging)
      - [ğŸ’° Cost \&amp; Operations](#-cost--operations)
      - [ğŸ§¬ Healthcare \&amp; Lifesciences](#-healthcare--lifesciences)
    - [Browse by How You&#039;re Working](#browse-by-how-youre-working)
      - [ğŸ‘¨â€ğŸ’» Vibe Coding \&amp; Development](#-vibe-coding--development)
        - [Core Development Workflow](#core-development-workflow)
        - [Infrastructure as Code](#infrastructure-as-code-1)
        - [Application Development](#application-development)
        - [Container \&amp; Serverless Development](#container--serverless-development)
        - [Testing \&amp; Data](#testing--data)
        - [Lifesciences Workflow Development](#lifesciences-workflow-development)
      - [ğŸ’¬ Conversational Assistants](#-conversational-assistants)
        - [Knowledge \&amp; Search](#knowledge--search)
        - [Content Processing \&amp; Generation](#content-processing--generation)
        - [Business Services](#business-services)
      - [ğŸ¤– Autonomous Background Agents](#-autonomous-background-agents)
        - [Data Operations \&amp; ETL](#data-operations--etl)
        - [Caching \&amp; Performance](#caching--performance-1)
        - [Workflow \&amp; Integration](#workflow--integration)
        - [Operations \&amp; Monitoring](#operations--monitoring)
  - [MCP AWS Lambda Handler Module](#mcp-aws-lambda-handler-module)
  - [When to use Local vs Remote MCP Servers?](#when-to-use-local-vs-remote-mcp-servers)
    - [Local MCP Servers](#local-mcp-servers)
    - [Remote MCP Servers](#remote-mcp-servers)
  - [Use Cases for the Servers](#use-cases-for-the-servers)
  - [Installation and Setup](#installation-and-setup)
    - [Running MCP servers in containers](#running-mcp-servers-in-containers)
    - [Getting Started with Amazon Q Developer CLI](#getting-started-with-amazon-q-developer-cli)
      - [`~/.aws/amazonq/mcp.json`](#awsamazonqmcpjson)
    - [Getting Started with Kiro](#getting-started-with-kiro)
      - [`kiro_mcp_settings.json`](#kiro_mcp_settingsjson)
    - [Getting Started with Cline and Amazon Bedrock](#getting-started-with-cline-and-amazon-bedrock)
      - [`cline_mcp_settings.json`](#cline_mcp_settingsjson)
    - [Getting Started with Cursor](#getting-started-with-cursor)
      - [`.cursor/mcp.json`](#cursormcpjson)
    - [Getting Started with Windsurf](#getting-started-with-windsurf)
      - [`~/.codeium/windsurf/mcp_config.json`](#codeiumwindsurfmcp_configjson)
    - [Getting Started with VS Code](#getting-started-with-vs-code)
      - [`.vscode/mcp.json`](#vscodemcpjson)
    - [Getting Started with Claude Code](#getting-started-with-claude-code)
      - [`.mcp.json`](#mcpjson)
  - [Samples](#samples)
  - [Vibe coding](#vibe-coding)
  - [Additional Resources](#additional-resources)
  - [Security](#security)
  - [Contributing](#contributing)
  - [Developer guide](#developer-guide)
  - [License](#license)
  - [Disclaimer](#disclaimer)

## What is the Model Context Protocol (MCP) and how does it work with AWS MCP Servers?

&gt; The Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools. Whether you&#039;re building an AI-powered IDE, enhancing a chat interface, or creating custom AI workflows, MCP provides a standardized way to connect LLMs with the context they need.
&gt;
&gt; &amp;mdash; [Model Context Protocol README](https://github.com/modelcontextprotocol#:~:text=The%20Model%20Context,context%20they%20need.)

An MCP Server is a lightweight program that exposes specific capabilities through the standardized Model Context Protocol. Host applications (such as chatbots, IDEs, and other AI tools) have MCP clients that maintain 1:1 connections with MCP servers. Common MCP clients include agentic AI coding assistants (like Q Developer, Cline, Cursor, Windsurf) as well as chatbot applications like Claude Desktop, with more clients coming soon. MCP servers can access local data sources and remote services to provide additional context that improves the generated outputs from the models.

AWS MCP Servers use this protocol to provide AI applications access to AWS documentation, contextual guidance, and best practices. Through the standardized MCP client-server architecture, AWS capabilities become an intelligent extension of your development environment or AI application.

AWS MCP servers enable enhanced cloud-native development, infrastructure management, and development workflowsâ€”making AI-assisted cloud computing more accessible and efficient.

The Model Context Protocol is an open source project run by Anthropic, PBC. and open to contributions from the entire community. For more information on MCP, you can find further documentation [here](https://modelcontextprotocol.io/introduction)

## AWS MCP Servers Transport Mechanisms

### Supported transport mechanisms

The MCP protocol currently defines two standard transport mechanisms for client-server communication:
- stdio, communication over standard in and standard out
- streamable HTTP

These AWS MCP Servers are designed to support stdio only.

You are responsible for ensuring that your use of these servers comply with the terms governing them, and any laws, rules, regulations, policies, or standards that apply to you.

### Server Sent Events Support Removal

**Important Notice:** On May 26th, 2025, Server Sent Events (SSE) support was removed from all MCP servers in their latest major versions. This change aligns with the Model Context Protocol specification&#039;s [backwards compatibility guidelines](https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#backwards-compatibility).

We are actively working towards supporting [Streamable HTTP](https://modelcontextprotocol.io/specification/draft/basic/transports#streamable-http), which will provide improved transport capabilities for future versions.

For applications still requiring SSE support, please use the previous major version of the respective MCP server until you can migrate to alternative transport methods.

### Why AWS MCP Servers?

MCP servers enhance the capabilities of foundation models (FMs) in several key ways:

- **Improved Output Quality**: By providing relevant information directly in the model&#039;s context, MCP servers significantly improve model responses for specialized domains like AWS services. This approach reduces hallucinations, provides more accurate technical details, enables more precise code generation, and ensures recommendations align with current AWS best practices and service capabilities.

- **Access to Latest Documentation**: FMs may not have knowledge of recent releases, APIs, or SDKs. MCP servers bridge this gap by pulling in up-to-date documentation, ensuring your AI assistant always works with the latest AWS capabilities.

- **Workflow Automation**: MCP servers convert common workflows into tools that foundation models can use directly. Whether it&#039;s CDK, Terraform, or other AWS-specific workflows, these tools enable AI assistants to perform complex tasks with greater accuracy and efficiency.

- **Specialized Domain Knowledge**: MCP servers provide deep, contextual knowledge about AWS services that might not be fully represented in foundation models&#039; training data, enabling more accurate and helpful responses for cloud development tasks.

## Available MCP Servers: Quick Installation

Get started quickly with one-click installation buttons for popular MCP clients. Click the buttons below to install servers directly in Cursor or VS Code:

### ğŸš€ Getting Started with AWS

For general AWS interactions and comprehensive API support, we recommend starting with:

| Server Name | Description | Install |
|-------------|-------------|---------|
| [AWS API MCP Server](src/aws-api-mcp-server) | Start here for general AWS interactions! Comprehensive AWS API support with command validation, security controls, and access to all AWS services. Perfect for managing infrastructure, exploring resources, and executing AWS operations through natural language. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&amp;logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-api-mcp-server&amp;config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWFwaS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D)&lt;br/&gt;[![Install VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20API%20MCP%20Server&amp;config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-api-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22type%22%3A%22stdio%22%7D) |
| [AWS Knowledge MCP Server](src/aws-knowledge-mcp-server) | A remote, fully-managed MCP server hosted by AWS that provides access to the latest AWS docs, API references, What&#039;s New Posts, Getting Started information, Builder Center, Blog posts, Architectural references, and Well-Architected guidance. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&amp;logo=cursor)](https://cursor.com/en/install-mcp?name=aws-knowledge-mcp&amp;config=eyJ1cmwiOiJodHRwczovL2tub3dsZWRnZS1tY3AuZ2xvYmFsLmFwaS5hd3MifQ==) &lt;br/&gt;[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://vscode.dev/redirect/mcp/install?name=aws-knowledge-mcp&amp;config=%7B%22type%22%3A%22http%22%2C%22url%22%3A%22https%3A%2F%2Fknowledge-mcp.global.api.aws%22%7D) |

### Browse by What You&#039;re Building

#### ğŸ“š Real-time access to official AWS documentation

| Server Name | Description | Install |
|-------------|-------------|---------|
| [AWS Knowledge MCP Server](src/aws-knowledge-mcp-server) | A remote, fully-managed MCP server hosted by AWS that provides access to the latest AWS docs, API references, What&#039;s New Posts, Getting Started information, Builder Center, Blog posts, Architectural references, and Well-Architected guidance. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&amp;logo=cursor)](https://cursor.com/en/install-mcp?name=aws-knowledge-mcp&amp;config=eyJ1cmwiOiJodHRwczovL2tub3dsZWRnZS1tY3AuZ2xvYmFsLmFwaS5hd3MifQ==) &lt;br/&gt;[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://vscode.dev/redirect/mcp/install?name=aws-knowledge-mcp&amp;config=%7B%22type%22%3A%22http%22%2C%22url%22%3A%22https%3A%2F%2Fknowledge-mcp.global.api.aws%22%7D) |
| [AWS Documentation MCP Server](src/aws-documentation-mcp-server) | Get latest AWS docs and API references | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&amp;logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-documentation-mcp-server&amp;config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWRvY3VtZW50YXRpb24tbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiIsIkFXU19ET0NVTUVOVEFUSU9OX1BBUlRJVElPTiI6ImF3cyJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) &lt;br/&gt;[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Documentation%20MCP%20Server&amp;config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-documentation-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_DOCUMENTATION_PARTITION%22%3A%22aws%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |


### ğŸ—ï¸ Infrastructure &amp; Deployment

Build, deploy, and manage cloud infrastructure with Infrastructure as Code best practices.

| Server Name | Description | Install |
|-------------|-------------|---------|
| [AWS Cloud Control API MCP Server](src/ccapi-mcp-server) | Direct AWS resource management with security scanning and best practices | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&amp;logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.ccapi-mcp-server&amp;config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2NhcGktbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) &lt;br/&gt;[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Cloud%20Control%20API%20MCP%20Server&amp;config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.ccapi-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |
| [AWS CDK MCP Server](src/cdk-mcp-server) | AWS CDK development with security compliance and best practices | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&amp;logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cdk-mcp-server&amp;config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2RrLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) &lt;br/&gt;[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CDK%20MCP%20Server&amp;config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cdk-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |
| [AWS Terraform MCP Server](src/terraform-mcp-server) | Terraform workflows with integrated security scanning | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&amp;logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.terraform-mcp-server&amp;config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMudGVycmFmb3JtLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) &lt;br/&gt;[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Terraform%20MCP%20Server&amp;config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.terraform-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |
| [AWS CloudFormation MCP Server](src/cfn-mcp-server) | Direct CloudFormation resource management via Cloud Control API | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&amp;logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cfn-mcp-server&amp;config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2ZuLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1uYW1lZC1wcm9maWxlIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) &lt;br/&gt;[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CloudFormation%20MCP%20Server&amp;config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cfn-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-named-profile%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |

#### Container Platforms

| Server Name | Description | Install |
|-------------|-------------|---------|
| [Amazon EKS MCP Server](src/eks-mcp-server) | Kubernetes cluster management and application deployment | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&amp;logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.eks-mcp-server&amp;config=eyJhdXRvQXBwcm92ZSI6W10sImRpc2FibGVkIjpmYWxzZSwiY29tbWFuZCI6InV2eCBhd3NsYWJzLmVrcy1tY3Atc2VydmVyQGxhdGVzdCAtLWFsbG93LXdyaXRlIC0tYWxsb3ctc2Vuc2l0aXZlLWRhdGEtYWNjZXNzIiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwidHJhbnNwb3J0VHlwZSI6InN0ZGlvIn0%3D) &lt;br/&gt;[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=EKS%20MCP%20Server&amp;config=%7B%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%2C%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.eks-mcp-server%40latest%22%2C%22--allow-write%22%2C%22--allow-sensitive-data-access%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22transportType%22%3A%22stdio%22%7D) |
| [Amazon ECS MCP Server](src/ecs-mcp-server) | Container orchestration and ECS application deployment | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&amp;logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.ecs-mcp-server&amp;config=eyJjb21tYW5kIjoidXZ4IC0tZnJvbSBhd3NsYWJzLWVjcy1tY3Atc2VydmVyIGVjcy1tY3Atc2VydmVyIiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ5b3VyLWF3cy1yZWdpb24iLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIiwiRkFTVE1DUF9MT0dfRklMRSI6Ii9wYXRoL3RvL2Vjcy1tY3Atc2VydmVyLmxvZyIsIkFMTE9XX1dSSVRFIjoiZmFsc2UiLCJBTExPV19TRU5TSVRJVkVfREFUQSI6ImZhbHNlIn19) &lt;br/&gt;[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=ECS%20MCP%20Server&amp;config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22--from%22%2C%22awslabs-ecs-mcp-server%22%2C%22ecs-mcp-server%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22your-aws-region%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22FASTMCP_LOG_FILE%22%3A%22%2Fpath%2Fto%2Fecs-mcp-server.log%22%2C%22ALLOW_WRITE%22%3A%22false%22%2C%22ALLOW_SENSITIVE_DAT

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[public-apis/public-apis]]></title>
            <link>https://github.com/public-apis/public-apis</link>
            <guid>https://github.com/public-apis/public-apis</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:27 GMT</pubDate>
            <description><![CDATA[A collective list of free APIs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/public-apis/public-apis">public-apis/public-apis</a></h1>
            <p>A collective list of free APIs</p>
            <p>Language: Python</p>
            <p>Stars: 377,038</p>
            <p>Forks: 39,915</p>
            <p>Stars today: 521 stars today</p>
            <h2>README</h2><pre># Try Public APIs for free
The Public APIs repository is manually curated by community members like you and folks working at [APILayer](https://apilayer.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo). It includes an extensive list of public APIs from many domains that you can use for your own products. Consider it a treasure trove of APIs well-managed by the community over the years.

&lt;br &gt;

&lt;p&gt;
    &lt;a href=&quot;https://apilayer.com&quot;&gt;
        &lt;div&gt;
            &lt;img src=&quot;.github/cs1586-APILayerLogoUpdate2022-LJ_v2-HighRes.png&quot; width=&quot;100%&quot; alt=&quot;APILayer Logo&quot; /&gt;
        &lt;/div&gt;
    &lt;/a&gt;
  &lt;/p&gt;

APILayer is the fastest way to integrate APIs into any product. Explore [APILayer APIs](https://apilayer.com/products/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo) here for your next project.

Join our [Discord server](https://discord.com/invite/hgjA78638n/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo) to get updates, ask questions, get answers, random community calls, and more.

&lt;br &gt;

## APILayer APIs
| API | Description | Call this API |
|:---|:---|:---|
| [IPstack](https://ipstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Locate and Identify Website Visitors by IP Address | [&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-55145132-244c-448c-8e6f-8780866e4862?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-55145132-244c-448c-8e6f-8780866e4862%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Marketstack](https://marketstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Free, easy-to-use REST API interface delivering worldwide stock market data in JSON format | [&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-9cbac391-3611-4f50-9bfd-d24ae41c97c1?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-9cbac391-3611-4f50-9bfd-d24ae41c97c1%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Weatherstack](https://weatherstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Retrieve instant, accurate weather information for any location in the world in lightweight JSON format | [&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-276c4312-f682-425d-b6b1-0f82c0a7f2b3?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-276c4312-f682-425d-b6b1-0f82c0a7f2b3%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Numverify](https://numverify.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers ) | Global Phone Number Validation &amp; Lookup JSON API |[&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-0760d25e-b802-412e-b0e4-26e5ca3b9ffa?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-0760d25e-b802-412e-b0e4-26e5ca3b9ffa%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Fixer](https://fixer.io/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Fixer is a simple and lightweight API for current and historical foreign exchange (forex) rates. |[&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-0d9c66b3-5f1a-42ed-a5ca-379217bd629d?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-0d9c66b3-5f1a-42ed-a5ca-379217bd629d%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Aviationstack](https://aviationstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Free, real-time flight status and global Aviation data API |[&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-72ee0d35-018e-4370-a2b6-a66d3ebd5b5a?action=collection/fork)|

&lt;br &gt;

## Learn more about Public APIs

&lt;strong&gt;Get Involved&lt;/strong&gt;

* [Contributing Guide](CONTRIBUTING.md)
* [API for this project](https://github.com/davemachado/public-api)
* [Issues](https://github.com/public-apis/public-apis/issues)
* [Pull Requests](https://github.com/public-apis/public-apis/pulls)
* [LICENSE](LICENSE) 

&lt;br /&gt;

## Index

* [Animals](#animals)
* [Anime](#anime)
* [Anti-Malware](#anti-malware)
* [Art &amp; Design](#art--design)
* [Authentication &amp; Authorization](#authentication--authorization)
* [Blockchain](#blockchain)
* [Books](#books)
* [Business](#business)
* [Calendar](#calendar)
* [Cloud Storage &amp; File Sharing](#cloud-storage--file-sharing)
* [Continuous Integration](#continuous-integration)
* [Cryptocurrency](#cryptocurrency)
* [Currency Exchange](#currency-exchange)
* [Data Validation](#data-validation)
* [Development](#development)
* [Dictionaries](#dictionaries)
* [Documents &amp; Productivity](#documents--productivity)
* [Email](#email)
* [Entertainment](#entertainment)
* [Environment](#environment)
* [Events](#events)
* [Finance](#finance)
* [Food &amp; Drink](#food--drink)
* [Games &amp; Comics](#games--comics)
* [Geocoding](#geocoding)
* [Government](#government)
* [Health](#health)
* [Jobs](#jobs)
* [Machine Learning](#machine-learning)
* [Music](#music)
* [News](#news)
* [Open Data](#open-data)
* [Open Source Projects](#open-source-projects)
* [Patent](#patent)
* [Personality](#personality)
* [Phone](#phone)
* [Photography](#photography)
* [Programming](#programming)
* [Science &amp; Math](#science--math)
* [Security](#security)
* [Shopping](#shopping)
* [Social](#social)
* [Sports &amp; Fitness](#sports--fitness)
* [Test Data](#test-data)
* [Text Analysis](#text-analysis)
* [Tracking](#tracking)
* [Transportation](#transportation)
* [URL Shorteners](#url-shorteners)
* [Vehicle](#vehicle)
* [Video](#video)
* [Weather](#weather)
&lt;br &gt;

### Animals
API | Description | Auth | HTTPS | CORS 
|:---|:---|:---|:---|:---|
| [AdoptAPet](https://www.adoptapet.com/public/apis/pet_list.html) | Resource to help get pets adopted | `apiKey` | Yes | Yes |
| [Axolotl](https://theaxolotlapi.netlify.app/) | Collection of axolotl pictures and facts | No | Yes | No |
| [Cat Facts](https://alexwohlbruck.github.io/cat-facts/) | Daily cat facts | No | Yes | No | |
| [Cataas](https://cataas.com/) | Cat as a service (cats pictures and gifs) | No | Yes | No |
| [Cats](https://docs.thecatapi.com/) | Pictures of cats from Tumblr | `apiKey` | Yes | No |
| [Dog Facts](https://dukengn.github.io/Dog-facts-API/) | Random dog facts | No | Yes | Yes |
| [Dog Facts](https://kinduff.github.io/dog-api/) | Random facts of Dogs | No | Yes | Yes |
| [Dogs](https://dog.ceo/dog-api/) | Based on the Stanford Dogs Dataset | No | Yes | Yes |
| [eBird](https://documenter.getpostman.com/view/664302/S1ENwy59) | Retrieve recent or notable birding observations within a region | `apiKey` | Yes | No |
| [FishWatch](https://www.fishwatch.gov/developers) | Information and pictures about individual fish species | No | Yes | Yes |
| [HTTP Cat](https://http.cat/) | Cat for every HTTP Status | No | Yes | Yes |
| [HTTP Dog](https://http.dog/) | Dogs for every HTTP response status code | No | Yes | Yes |
| [IUCN](http://apiv3.iucnredlist.org/api/v3/docs) | IUCN Red List of Threatened Species | `apiKey` | No | No |
| [MeowFacts](https://github.com/wh-iterabb-it/meowfacts) | Get random cat facts | No | Yes | No |
| [Movebank](https://github.com/movebank/movebank-api-doc) | Movement and Migration data of animals | No | Yes | Yes |
| [Petfinder](https://www.petfinder.com/developers/) | Petfinder is dedicated to helping pets find homes, another resource to get pets adopted | `apiKey` | Yes | Yes |
| [PlaceBear](https://placebear.com/) | Placeholder bear pictures | No | Yes | Yes |
| [PlaceDog](https://place.dog) | Placeholder Dog pictures | No | Yes | Yes |
| [PlaceKitten](https://placekitten.com/) | Placeholder Kitten pictures | No | Yes | Yes |
| [RandomDog](https://random.dog/woof.json) | Random pictures of dogs | No | Yes | Yes |
| [RandomDuck](https://random-d.uk/api) | Random pictures of ducks | No | Yes | No |
| [RandomFox](https://randomfox.ca/floof/) | Random pictures of foxes | No | Yes | No |
| [RescueGroups](https://userguide.rescuegroups.org/display/APIDG/API+Developers+Guide+Home) | Adoption | No | Yes | Unknown |
| [Shibe.Online](http://shibe.online/) | Random pictures of Shiba Inu, cats or birds | No | Yes | Yes |
| [The Dog](https://thedogapi.com/) | A public service all about Dogs, free to use when making your fancy new App, Website or Service | `apiKey` | Yes | No |
| [xeno-canto](https://xeno-canto.org/explore/api) | Bird recordings | No | Yes | Unknown |
| [Zoo Animals](https://zoo-animal-api.herokuapp.com/) | Facts and pictures of zoo animals | No | Yes | Yes |

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;

### Anime
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [AniAPI](https://aniapi.com/docs/) | Anime discovery, streaming &amp; syncing with trackers | `OAuth` | Yes | Yes |
| [AniDB](https://wiki.anidb.net/HTTP_API_Definition) | Anime Database | `apiKey` | No | Unknown |
| [AniList](https://github.com/AniList/ApiV2-GraphQL-Docs) | Anime discovery &amp; tracking | `OAuth` | Yes | Unknown |
| [AnimeChan](https://github.com/RocktimSaikia/anime-chan) | Anime quotes (over 10k+) | No | Yes | No |
| [AnimeFacts](https://chandan-02.github.io/anime-facts-rest-api/) | Anime Facts (over 100+) | No | Yes | Yes |
| [AnimeNewsNetwork](https://www.animenewsnetwork.com/encyclopedia/api.php) | Anime industry news | No | Yes | Yes |
| [Catboy](https://catboys.com/api) | Neko images, funny GIFs &amp; more | No | Yes | Yes |
| [Danbooru Anime](https://danbooru.donmai.us/wiki_pages/help:api) | Thousands of anime artist database to find good anime art | `apiKey` | Yes | Yes |
| [Jikan](https://jikan.moe) | Unofficial MyAnimeList API | No | Yes | Yes |
| [Kitsu](https://kitsu.docs.apiary.io/) | Anime discovery platform | `OAuth` | Yes | Yes |
| [MangaDex](https://api.mangadex.org/docs.html) | Manga Database and Community | `apiKey` | Yes | Unknown |
| [Mangapi](https://rapidapi.com/pierre.carcellermeunier/api/mangapi3/) | Translate manga pages from one language to another | `apiKey` | Yes | Unknown |
| [MyAnimeList](https://myanimelist.net/clubs.php?cid=13727) | Anime and Manga Database and Community | `OAuth` | Yes | Unknown |
| [NekosBest](https://docs.nekos.best) | Neko Images &amp; Anime roleplaying GIFs | No | Yes | Yes |
| [Shikimori](https://shikimori.one/api/doc) | Anime discovery, tracking, forum, rates | `OAuth` | Yes | Unknown |
| [Studio Ghibli](https://ghibliapi.herokuapp.com) | Resources from Studio Ghibli films | No | Yes | Yes |
| [Trace Moe](https://soruly.github.io/trace.moe-api/#/) | A useful tool to get the exact scene of an anime from a screenshot | No | Yes | No |
| [Waifu.im](https://waifu.im/docs) | Get waifu pictures from an archive of over 4000 images and multiple tags | No | Yes | Yes |
| [Waifu.pics](https://waifu.pics/docs) | Image sharing platform for anime images | No | Yes | No |

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;

### Anti-Malware
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [AbuseIPDB](https://docs.abuseipdb.com/) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |
| [AlienVault Open Threat Exchange (OTX)](https://otx.alienvault.com/api) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |
| [CAPEsandbox](https://capev2.readthedocs.io/en/latest/usage/api.html) | Malware execution and analysis | `apiKey` | Yes | Unknown |
| [Google Safe Browsing](https://developers.google.com/safe-browsing/) | Google Link/Domain Flagging | `apiKey` | Yes | Unknown |
| [MalDatabase](https://maldatabase.com/api-doc.html) | Provide malware datasets and threat intelligence feeds | `apiKey` | Yes | Unknown |
| [MalShare](https://malshare.com/doc.php) | Malware Archive / file sourcing | `apiKey` | Yes | No |
| [MalwareBazaar](https://bazaar.abuse.ch/api/) | Collect and share malware samples | `apiKey` | Yes | Unknown |
| [Metacert](https://metacert.com/) | Metacert Link Flagging | `apiKey` | Yes | Unknown |
| [NoPhishy](https://rapidapi.com/Amiichu/api/exerra-phishing-check/) | Check links to see if they&#039;re known phishing attempts | `apiKey` | Yes | Yes |
| [Phisherman](https://phisherman.gg/) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |
| [Scanii](https://docs.scanii.com/) | Simple REST API that can scan submitted documents/files for the presence of threats | `apiKey` | Yes | Yes |
| [URLhaus](https://urlhaus-api.abuse.ch/) | Bulk queries and Download Malware Samples | No | Yes | Yes |
| [URLScan.io](https://urlscan.io/about-api/) | Scan and Analyse URLs | `apiKey` | Yes | Unknown |
| [VirusTotal](https://www.virustotal.com/en/documentation/public-api/) | VirusTotal File/URL Analysis | `apiKey` | Yes | Unknown |
| [Web of Trust](https://support.mywot.com/hc/en-us/sections/360004477734-API-) | IP/domain/URL reputation | `apiKey` | Yes | Unknown | 

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Art &amp; Design
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [AmÃ©thyste](https://api.amethyste.moe/) | Generate images for Discord users | `apiKey` | Yes | Unknown |
| [Art Institute of Chicago](https://api.artic.edu/docs/) | Art | No | Yes | Yes |
| [Colormind](http://colormind.io/api-access/) | Color scheme generator | No | No | Unknown |
| [ColourLovers](http://www.colourlovers.com/api) | Get various patterns, palettes and images | No | No | Unknown |
| [Cooper Hewitt](https://collection.cooperhewitt.org/api) | Smithsonian Design Museum | `apiKey` | Yes | Unknown |
| [Dribbble](https://developer.dribbble.com) | Discover the worldâ€™s top designers &amp; creatives | `OAuth` | Yes | Unknown |
| [EmojiHub](https://github.com/cheatsnake/emojihub) | Get emojis by categories and groups | No | Yes | Yes |
| [Europeana](https://pro.europeana.eu/resources/apis/search) | European Museum and Galleries content | `apiKey` | Yes | Unknown |
| [Harvard Art Museums](https://github.com/harvardartmuseums/api-docs) | Art | `apiKey` | No | Unknown |
| [Icon Horse](https://icon.horse) | Favicons for any website, with fallbacks | No | Yes | Yes |
| [Iconfinder](https://developer.iconfinder.com) | Icons | `apiKey` | Yes | Unknown |
| [Icons8](https://img.icons8.com/) | Icons (find &quot;search icon&quot; hyperlink in page) | No | Yes | Unknown |
| [Lordicon](https://lordicon.com/) | Icons with predone Animations | No | Yes | Yes |
| [Metropolitan Museum of Art](https://metmuseum.github.io/) | Met Museum of Art | No | Yes | No |
| [Noun Project](http://api.thenounproject.com/index.html) | Icons | `OAuth` | No | Unknown |
| [PHP-Noise](https://php-noise.com/) | Noise Background Image Generator | No | Yes | Yes |
| [Pixel Encounter](https://pixelencounter.com/api) | SVG Icon Generator | No | Yes | No |
| [Rijksmuseum](https://data.rijksmuseum.nl/object-metadata/api/) | RijksMuseum Data | `apiKey` | Yes | Unknown |
| [Word Cloud](https://wordcloudapi.com/) | Easily create word clouds | `apiKey` | Yes | Unknown |
| [xColors](https://x-colors.herokuapp.com/) | Generate &amp; convert colors | No | Yes | Yes |

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Authentication &amp; Authorization
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [Auth0](https://auth0.com) | Easy to implement, adaptable authentication and authorization platform | `apiKey` | Yes | Yes |
| [GetOTP](https://otp.dev/en/docs/) | Implement OTP flow quickly | `apiKey` | Yes | No |
| [Micro User Service](https://m3o.com/user) | User management and authentication | `apiKey` | Yes | No |
| [MojoAuth](https://mojoauth.com) | Secure and modern passwordless authentication platform | `apiKey` | Yes | Yes |
| [SAWO Labs](https://sawolabs.com) | Simplify login and improve user experience by integrating passwordless authentication in your app | `apiKey` | Yes | Yes |
| [Stytch](https://stytch.com/) | User infrastructure for modern applications | `apiKey` | Yes | No |
| [Warrant](https://warrant.dev/) | APIs for authorization and access control | `apiKey` | Yes | Yes |

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Blockchain
| API | Description | Auth | HTTPS | CORS |
|---|:---|:---|:---|:---|
| [Bitquery](https://graphql.bitquery.io/ide) | Onchain GraphQL APIs &amp; DEX APIs | `apiKey` | Yes | Yes |
| [Chainlink](https://chain.link/developer-resources) | Build hybrid smart contracts with Chainlink | No | Yes | Unknown |
| [Chainpoint](https://tierion.com/chainpoint/) | Chainpoint is a global network for anchoring data to the Bitcoin blockchain | No | Yes | Unknown |
| [Covalent](https://www.covalenthq.com/docs/api/) | Multi-blockchain data aggregator platform | `apiKey` | Yes | Unknown |
| [Etherscan](https://etherscan.io/apis) | Ethereum explorer API | `apiKey` | Yes | Yes |
| [Helium](https://docs.helium.com/api/blockchain/introduction/) | Helium is a global, distributed network of Hotspots that create public, long-range wireless coverage | No | Yes | Unknown |
| [Nownodes](https://nownodes.io/) | Blockchain-as-a-service solution that provides high-quality connection via API | `apiKey` | Yes | Unknown |
| [Steem](https://developers.steem.io/) | Blockchain-based blogging and social media website | No | No | No |
| [The Graph](https://thegraph.com) | Indexing protocol for querying networks like Ethereum with GraphQL | `apiKey` | Yes | Unknown |
| [Walltime](https://walltime.info/api.html) | To retrieve Walltime&#039;s market info | No | Yes | Unknown |
| [Watchdata](https://docs.watchdata.io) | Provide simple and reliable API access to Ethereum blockchain | `apiKey` | Yes | Unknown |

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Books
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [A BÃ­blia Digital](https://www.abibliadigital.com.br/en) | Do not worry about managing the multiple versions of the Bible | `apiKey` | Yes | No |
| [Bhagavad Gita](https://docs.bhagavadgitaapi.in) | Open Source Shrimad Bhagavad Gita API including 21+ authors translation in Sanskrit/English/Hindi | `apiKey` | Yes | Yes |
| [Bhagavad Gita](https://bhagavadgita.io/api) | Bhagavad Gita text | `OAuth` | Yes | Yes |
| [Bhagavad Gita telugu](https://gita-api.vercel.app) | Bhagavad Gita API in telugu and odia languages | No | Yes | Yes |
| [Bible-api](https://bible-api.com/) | Free Bible API with multiple languages | No | Yes | Yes |
| [British National Bibliography](http://bnb.data.bl.uk/) | Books | No | No | Unknown |
| [Crossref Metadata Search](https://github.com/CrossRef/rest-api-doc) | Books &amp; Articles Metadata | No | Yes | Unknown |
| [Ganjoor](https://api.ganjoor.net) | Classic Persian poetry works including access to related manuscripts, recitations and music tracks | `OAuth` | Yes | Yes |
| [Google Books](https://developers.google.com/books/) | Books | `OAuth` | Yes | Unknown |
| [GurbaniNow](https://github.com/GurbaniNow/api) | Fast and Accurate Gurbani RESTful API | No | Yes | Unknown |
| [Gutendex](https://gutendex.com/) | Web-API for fetching data from Project Gutenberg Books Library | No | Yes | Unknown |
| [Open Library](https://openlibrary.org/developers/api) | Books, book covers and related data | No | Yes | No |
| [Penguin Publishing](http://www.penguinrandomhouse.biz/webservices/rest/) | Books, book covers and related data | No | Yes | Yes |
| [PoetryDB](https://github.com/thundercomb/poetrydb#readme) | Enables you to get instant data from our vast p

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[thinking-machines-lab/tinker-cookbook]]></title>
            <link>https://github.com/thinking-machines-lab/tinker-cookbook</link>
            <guid>https://github.com/thinking-machines-lab/tinker-cookbook</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:26 GMT</pubDate>
            <description><![CDATA[Post-training with Tinker]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/thinking-machines-lab/tinker-cookbook">thinking-machines-lab/tinker-cookbook</a></h1>
            <p>Post-training with Tinker</p>
            <p>Language: Python</p>
            <p>Stars: 1,532</p>
            <p>Forks: 120</p>
            <p>Stars today: 38 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;Tinker Cookbook&lt;/h1&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/tinker-cover.png&quot; width=&quot;60%&quot; /&gt;
&lt;/div&gt;

We provide two libraries for the broader community to customize their language models: `tinker` and `tinker-cookbook`.

- `tinker` is a training SDK for researchers and developers to fine-tune language models. You send API requests to us and we handle the complexities of distributed training.
- `tinker-cookbook` includes realistic examples of fine-tuning language models. It builds on the Tinker API and provides common abstractions to fine-tune language models.

## Installation

1. Sign up for Tinker through the [waitlist](https://thinkingmachines.ai/tinker).
2. Once you have access, create an API key from the [console](https://tinker-console.thinkingmachines.ai) and export it as environment variable `TINKER_API_KEY`.
3. Install tinker python client via `pip install tinker`
4. We recommend installing `tinker-cookbook` in a virtual env either with `conda` or `uv`. For running most examples, you can install via `pip install -e .`.

## Tinker

Refer to the [docs](https://tinker-docs.thinkingmachines.ai/training-sampling) to start from basics.
Here we introduce a few Tinker primitives - the basic components to fine-tune LLMs:

```python
service_client = tinker.ServiceClient()
training_client = service_client.create_lora_training_client(
  base_model=&quot;meta-llama/Llama-3.2-1B&quot;, rank=32,
)
training_client.forward_backward(...)
training_client.optim_step(...)
training_client.save_state(...)
training_client.load_state(...)

sampling_client = training_client.save_weights_and_get_sampling_client(name=&quot;my_model&quot;)
sampling_client.sample(...)
```

See [tinker_cookbook/recipes/sl_loop.py](tinker_cookbook/recipes/sl_loop.py) and [tinker_cookbook/recipes/rl_loop.py](tinker_cookbook/recipes/rl_loop.py) for minimal examples of using these primitives to fine-tune LLMs.

To download the weights of any model:
```python
rest_client = service_client.create_rest_client()
future = rest_client.download_checkpoint_archive_from_tinker_path(sampling_client.model_path)
with open(f&quot;model-checkpoint.tar.gz&quot;, &quot;wb&quot;) as f:
    f.write(future.result())
```

### Tinker Cookbook

Besides these primitives, we also offer **Tinker Cookbook** (a.k.a. this repo), a library of a wide range of abstractions to help you customize training environments.
[`tinker_cookbook/recipes/sl_basic.py`](tinker_cookbook/recipes/sl_basic.py) and [`tinker_cookbook/recipes/rl_basic.py`](tinker_cookbook/recipes/rl_basic.py) contain minimal examples to configure supervised learning and reinforcement learning.

We also include a wide range of more sophisticated examples in the [`tinker_cookbook/recipes/`](tinker_cookbook/recipes/) folder:
1. **[Chat supervised learning](tinker_cookbook/recipes/chat_sl/)**: supervised fine-tuning on conversational datasets like Tulu3.
2. **[Math reasoning](tinker_cookbook/recipes/math_rl/)**: improve LLM reasoning capability by rewarding it for answering math questions correctly.
3. **[Preference learning](tinker_cookbook/recipes/preference/)**: showcase a three-stage RLHF pipeline: 1) supervised fine-tuning, 2) learning a reward model, 3) RL against the reward model.
4. **[Tool use](tinker_cookbook/recipes/tool_use/)**: train LLMs to better use retrieval tools to answer questions more accurately.
5. **[Prompt distillation](tinker_cookbook/recipes/prompt_distillation/)**: internalize long and complex instructions into LLMs.
6. **[Multi-Agent](tinker_cookbook/recipes/multiplayer_rl/)**: optimize LLMs to play against another LLM or themselves.

These examples are located in each subfolder, and their `README.md` files will walk you through the key implementation details, the commands to run them, and the expected performance.

### Import our utilities

Tinker cookbook includes several utilities. Here&#039;s a quick overview:
- [`renderers`](tinker_cookbook/renderers.py) converts tokens from/to structured chat message objects
- [`hyperparam_utils`](tinker_cookbook/hyperparam_utils.py) helps calculate hyperparameters suitable for LoRAs
- [`evaluation`](tinker_cookbook/eval/evaluators.py) provides abstractions for evaluating Tinker models and [`inspect_evaluation`](tinker_cookbook/eval/inspect_evaluators.py) shows how to integrate with InspectAI to make evaluating on standard benchmarks easy.

## Contributing

This project is built in the spirit of open science and collaborative development. We believe that the best tools emerge through community involvement and shared learning.

We welcome PR contributions after our private beta is over. If you have any feedback, please email us at tinker@thinkingmachines.ai.

## Citation
If you use Tinker for your research, please cite it as:
```
Thinking Machines Lab, 2025. Tinker. https://thinkingmachines.ai/tinker/.
```

Or use this BibTeX citation:
```
@misc{tml2025tinker,
  author = {Thinking Machines Lab},
  title = {Tinker},
  year = {2025},
  url = {https://thinkingmachines.ai/tinker/},
}
```
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[jamwithai/arxiv-paper-curator]]></title>
            <link>https://github.com/jamwithai/arxiv-paper-curator</link>
            <guid>https://github.com/jamwithai/arxiv-paper-curator</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:25 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jamwithai/arxiv-paper-curator">jamwithai/arxiv-paper-curator</a></h1>
            <p></p>
            <p>Language: Python</p>
            <p>Stars: 1,342</p>
            <p>Forks: 424</p>
            <p>Stars today: 42 stars today</p>
            <h2>README</h2><pre># The Mother of AI Project
## Phase 1 RAG Systems: arXiv Paper Curator

&lt;div align=&quot;center&quot;&gt;
  &lt;h3&gt;A Learner-Focused Journey into Production RAG Systems&lt;/h3&gt;
  &lt;p&gt;Learn to build modern AI systems from the ground up through hands-on implementation&lt;/p&gt;
  &lt;p&gt;Master the most in-demand AI engineering skills: &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/Python-3.12+-blue.svg&quot; alt=&quot;Python Version&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/FastAPI-0.115+-green.svg&quot; alt=&quot;FastAPI&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/OpenSearch-2.19-orange.svg&quot; alt=&quot;OpenSearch&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/Docker-Compose-blue.svg&quot; alt=&quot;Docker&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/Status-Week%206%20Production%20Ready-brightgreen.svg&quot; alt=&quot;Status&quot;&gt;
&lt;/p&gt;

&lt;/br&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;#-about-this-course&quot;&gt;
    &lt;img src=&quot;static/mother_of_ai_project_rag_architecture.gif&quot; alt=&quot;RAG Architecture&quot; width=&quot;700&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

## ğŸ“– About This Course

This is a **learner-focused project** where you&#039;ll build a complete research assistant system that automatically fetches academic papers, understands their content, and answers your research questions using advanced RAG techniques.

**The arXiv Paper Curator** will teach you to build a **production-grade RAG system using industry best practices**. Unlike tutorials that jump straight to vector search, we follow the **professional path**: master keyword search foundations first, then enhance with vectors for hybrid retrieval.

&gt; **ğŸ¯ The Professional Difference:** We build RAG systems the way successful companies do - solid search foundations enhanced with AI, not AI-first approaches that ignore search fundamentals.

By the end of this course, you&#039;ll have your own AI research assistant and the deep technical skills to build production RAG systems for any domain.

### **ğŸ“ What You&#039;ll Build**

- **Week 1:** Complete infrastructure with Docker, FastAPI, PostgreSQL, OpenSearch, and Airflow
- **Week 2:** Automated data pipeline fetching and parsing academic papers from arXiv  
- **Week 3:** Production BM25 keyword search with filtering and relevance scoring
- **Week 4:** Intelligent chunking + hybrid search combining keywords with semantic understanding
- **Week 5:** **Complete RAG pipeline with local LLM, streaming responses, and Gradio interface**
- **Week 6:** **Production monitoring with Langfuse tracing and Redis caching for optimized performance**

---

## ğŸš€ Quick Start

### **ğŸ“‹ Prerequisites**
- **Docker Desktop** (with Docker Compose)  
- **Python 3.12+**
- **UV Package Manager** ([Install Guide](https://docs.astral.sh/uv/getting-started/installation/))
- **8GB+ RAM** and **20GB+ free disk space**

### **âš¡ Get Started**

```bash
# 1. Clone and setup
git clone &lt;repository-url&gt;
cd arxiv-paper-curator

# 2. Configure environment (IMPORTANT!)
cp .env.example .env
# The .env file contains all necessary configuration for OpenSearch, 
# arXiv API, and service connections. Defaults work out of the box.
# For Week 4: Add JINA_API_KEY=your_key_here for hybrid search

# 3. Install dependencies
uv sync

# 4. Start all services
docker compose up --build -d

# 5. Verify everything works
curl http://localhost:8000/health
```

### **ğŸ“š Weekly Learning Path**

| Week | Topic | Blog Post | Code Release |
|------|-------|-----------|--------------|
| **Week 0** | The Mother of AI project - 6 phases | [The Mother of AI project](https://jamwithai.substack.com/p/the-mother-of-ai-project) | - |
| **Week 1** | Infrastructure Foundation | [The Infrastructure That Powers RAG Systems](https://jamwithai.substack.com/p/the-infrastructure-that-powers-rag) | [week1.0](https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week1.0) |
| **Week 2** | Data Ingestion Pipeline | [Building Data Ingestion Pipelines for RAG](https://jamwithai.substack.com/p/bringing-your-rag-system-to-life) | [week2.0](https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week2.0) |
| **Week 3** | OpenSearch ingestion &amp; BM25 retrieval | [The Search Foundation Every RAG System Needs](https://jamwithai.substack.com/p/the-search-foundation-every-rag-system) | [week3.0](https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week3.0) |
| **Week 4** | **Chunking &amp; Hybrid Search** | [The Chunking Strategy That Makes Hybrid Search Work](https://jamwithai.substack.com/p/chunking-strategies-and-hybrid-rag) | [week4.0](https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week4.0) |
| **Week 5** | **Complete RAG system** | [The Complete RAG System](https://jamwithai.substack.com/p/the-complete-rag-system) | [week5.0](https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week5.0) |
| **Week 6** | **Production monitoring &amp; caching** | [Production-ready RAG: Monitoring &amp; Caching](https://jamwithai.substack.com/p/production-ready-rag-monitoring-and) | [week6.0](https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week6.0) |

**ğŸ“¥ Clone a specific week&#039;s release:**
```bash
# Clone a specific week&#039;s code
git clone --branch &lt;WEEK_TAG&gt; https://github.com/jamwithai/arxiv-paper-curator
cd arxiv-paper-curator
uv sync
docker compose down -v
docker compose up --build -d

# Replace &lt;WEEK_TAG&gt; with: week1.0, week2.0, etc.
```

### **ğŸ“Š Access Your Services**

| Service | URL | Purpose |
|---------|-----|---------|
| **API Documentation** | http://localhost:8000/docs | Interactive API testing |
| **Gradio RAG Interface** | http://localhost:7861 | User-friendly chat interface |
| **Langfuse Dashboard** | http://localhost:3000 | RAG pipeline monitoring &amp; tracing |
| **Airflow Dashboard** | http://localhost:8080 | Workflow management |
| **OpenSearch Dashboards** | http://localhost:5601 | Hybrid search engine UI |

#### **NOTE**: Check airflow/simple_auth_manager_passwords.json.generated for Airflow username and password
---

## ğŸ“š Week 1: Infrastructure Foundation âœ…

**Start here!** Master the infrastructure that powers modern RAG systems.

### **ğŸ¯ Learning Objectives**
- Complete infrastructure setup with Docker Compose
- FastAPI development with automatic documentation and health checks
- PostgreSQL database configuration and management
- OpenSearch hybrid search engine setup
- Ollama local LLM service configuration
- Service orchestration and health monitoring
- Professional development environment with code quality tools

### **ğŸ—ï¸ Architecture Overview**

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;static/week1_infra_setup.png&quot; alt=&quot;Week 1 Infrastructure Setup&quot; width=&quot;800&quot;&gt;
&lt;/p&gt;

**Infrastructure Components:**
- **FastAPI**: REST endpoints with async support (Port 8000)  
- **PostgreSQL 16**: Paper metadata storage (Port 5432)
- **OpenSearch 2.19**: Search engine with dashboards (Ports 9200, 5601)
- **Apache Airflow 3.0**: Workflow orchestration (Port 8080)
- **Ollama**: Local LLM server (Port 11434)

### **ğŸ““ Setup Guide**

```bash
# Launch the Week 1 notebook
uv run jupyter notebook notebooks/week1/week1_setup.ipynb
```

### **âœ… Success Criteria**
Complete when you can:
- [ ] Start all services with `docker compose up -d`
- [ ] Access API docs at http://localhost:8000/docs  
- [ ] Login to Airflow at http://localhost:8080
- [ ] Browse OpenSearch at http://localhost:5601
- [ ] All tests pass: `uv run pytest`

### **ğŸ“– Deep Dive**
**Blog Post:** [The Infrastructure That Powers RAG Systems](https://jamwithai.substack.com/p/the-infrastructure-that-powers-rag) - Detailed walkthrough and production insights

---

## ğŸ“š Week 2: Data Ingestion Pipeline âœ…

**Building on Week 1 infrastructure:** Learn to fetch, process, and store academic papers automatically.

### **ğŸ¯ Learning Objectives**
- arXiv API integration with rate limiting and retry logic
- Scientific PDF parsing using Docling
- Automated data ingestion pipelines with Apache Airflow
- Metadata extraction and storage workflows
- Complete paper processing from API to database

### **ğŸ—ï¸ Architecture Overview**

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;static/week2_data_ingestion_flow.png&quot; alt=&quot;Week 2 Data Ingestion Architecture&quot; width=&quot;800&quot;&gt;
&lt;/p&gt;

**Data Pipeline Components:**
- **MetadataFetcher**: ğŸ¯ Main orchestrator coordinating the entire pipeline
- **ArxivClient**: Rate-limited paper fetching with retry logic
- **PDFParserService**: Docling-powered scientific document processing  
- **Airflow DAGs**: Automated daily paper ingestion workflows
- **PostgreSQL Storage**: Structured paper metadata and content

### **ğŸ““ Implementation Guide**

```bash
# Launch the Week 2 notebook  
uv run jupyter notebook notebooks/week2/week2_arxiv_integration.ipynb
```

### **ğŸ’» Code Examples**

**arXiv API Integration:**
```python
# Example: Fetch papers with rate limiting
from src.services.arxiv.factory import make_arxiv_client

async def fetch_recent_papers():
    client = make_arxiv_client()
    papers = await client.search_papers(
        query=&quot;cat:cs.AI&quot;,
        max_results=10,
        from_date=&quot;20240801&quot;,
        to_date=&quot;20240807&quot;
    )
    return papers
```

**PDF Processing Pipeline:**
```python
# Example: Parse PDF with Docling
from src.services.pdf_parser.factory import make_pdf_parser_service

async def process_paper_pdf(pdf_url: str):
    parser = make_pdf_parser_service()
    parsed_content = await parser.parse_pdf_from_url(pdf_url)
    return parsed_content  # Structured content with text, tables, figures
```

**Complete Ingestion Workflow:**
```python
# Example: Full paper ingestion pipeline
from src.services.metadata_fetcher import make_metadata_fetcher

async def ingest_papers():
    fetcher = make_metadata_fetcher()
    results = await fetcher.fetch_and_store_papers(
        query=&quot;cat:cs.AI&quot;,
        max_results=5,
        from_date=&quot;20240807&quot;
    )
    return results  # Papers stored in database with full content
```

### **âœ… Success Criteria**
Complete when you can:
- [ ] Fetch papers from arXiv API: Test in Week 2 notebook
- [ ] Parse PDF content with Docling: View extracted structured content
- [ ] Run Airflow DAG: `arxiv_paper_ingestion` executes successfully
- [ ] Verify database storage: Papers appear in PostgreSQL with full content
- [ ] API endpoints work: `/papers` returns stored papers with metadata

### **ğŸ“– Deep Dive**
**Blog Post:** [Building Data Ingestion Pipelines for RAG](https://jamwithai.substack.com/p/bringing-your-rag-system-to-life) - arXiv API integration and PDF processing

---

## ğŸ“š Week 3: Keyword Search First - The Critical Foundation âš¡

&gt; **ğŸš¨ The 90% Problem:** Most RAG systems jump straight to vector search and miss the foundation that powers the best retrieval systems. We&#039;re doing it right!

**Building on Weeks 1-2 foundation:** Implement the keyword search foundation that professional RAG systems rely on.

### **ğŸ¯ Why Keyword Search First?**

**The Reality Check:** Vector search alone is not enough. The most effective RAG systems use **hybrid retrieval** - combining keyword search (BM25) with vector search. Here&#039;s why we start with keywords:

1. **ğŸ” Exact Match Power:** Keywords excel at finding specific terms, technical jargon, and precise phrases
2. **ğŸ“Š Interpretable Results:** You can understand exactly why a document was retrieved  
3. **âš¡ Speed &amp; Efficiency:** BM25 is computationally fast and doesn&#039;t require expensive embedding models
4. **ğŸ¯ Domain Knowledge:** Technical papers often require exact terminology matches that vector search might miss
5. **ğŸ“ˆ Production Reality:** Companies like Elasticsearch, Algolia, and enterprise search all use keyword search as their foundation

### **ğŸ—ï¸ Week 3 Architecture Overview**

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;static/week3_opensearch_flow.png&quot; alt=&quot;Week 3 OpenSearch Flow Architecture&quot; width=&quot;800&quot;&gt;
  &lt;br&gt;
  &lt;em&gt;Complete Week 3 architecture showing the OpenSearch integration flow&lt;/em&gt;
&lt;/p&gt;

**Search Infrastructure:** Master full-text search with OpenSearch before adding vector complexity.

#### **ğŸ¯ Learning Objectives**
- **Foundation First:** Why keyword search is essential for RAG systems
- **OpenSearch Mastery:** Index management, mappings, and search optimization
- **BM25 Algorithm:** Understanding the math behind effective keyword search
- **Query DSL:** Building complex search queries with filters and boosting
- **Search Analytics:** Measuring search relevance and performance
- **Production Patterns:** How real companies structure their search systems

#### **Key Components**
- `src/services/opensearch/`: Professional search service implementation
- `src/routers/search.py`: Search API endpoints with BM25 scoring
- `notebooks/week3/`: Complete OpenSearch integration guide  
- **Search Quality Metrics:** Precision, recall, and relevance scoring

#### **ğŸ’¡ The Pedagogical Approach**
```
Week 3: Master keyword search (BM25) â† YOU ARE HERE
Week 4: Add intelligent chunking strategies  
Week 5: Introduce vector embeddings for hybrid retrieval
Week 6: Optimize the complete hybrid system
```

**This progression mirrors how successful companies build search systems - solid foundation first, then enhance with advanced techniques.**

### **ğŸ““ Week 3 Implementation Guide**

```bash
# Launch the Week 3 notebook
uv run jupyter notebook notebooks/week3/week3_opensearch.ipynb
```

### **ğŸ’» Code Examples**

**BM25 Search Implementation:**
```python
# Example: Search papers with BM25 scoring
from src.services.opensearch.factory import make_opensearch_client

async def search_papers():
    client = make_opensearch_client()
    results = await client.search_papers(
        query=&quot;transformer attention mechanism&quot;,
        max_results=10,
        categories=[&quot;cs.AI&quot;, &quot;cs.LG&quot;]
    )
    return results  # Papers ranked by BM25 relevance
```

**Search API Usage:**
```python
# Example: Use the search endpoint
import httpx

async def query_papers():
    async with httpx.AsyncClient() as client:
        response = await client.post(&quot;http://localhost:8000/api/v1/search&quot;, json={
            &quot;query&quot;: &quot;neural networks optimization&quot;,
            &quot;max_results&quot;: 5,
            &quot;latest_papers&quot;: True
        })
        return response.json()
```

### **âœ… Success Criteria**
Complete when you can:
- [ ] Index papers in OpenSearch: Papers searchable via OpenSearch Dashboards
- [ ] Search via API: `/search` endpoint returns relevant papers with BM25 scoring
- [ ] Filter by categories: Search within specific arXiv categories (cs.AI, cs.LG, etc.)
- [ ] Sort by relevance or date: Toggle between BM25 scoring and latest papers
- [ ] View search analytics: Understanding why papers matched your query

### **ğŸ“– Deep Dive**
**Blog Post:** [The Search Foundation Every RAG System Needs](https://jamwithai.substack.com/p/the-search-foundation-every-rag-system) - Complete BM25 implementation with OpenSearch

---

## ğŸ“š Week 4: Chunking &amp; Hybrid Search - The Semantic Layer ğŸ”¥

&gt; **ğŸš€ The Intelligence Upgrade:** Now we enhance our solid BM25 foundation with semantic understanding through intelligent chunking and hybrid retrieval.

**Building on Week 3 foundation:** Add the semantic layer that makes search truly intelligent.

### **ğŸ¯ Why Chunking + Hybrid Search?**

**The Next Level:** With solid BM25 search proven, we can now intelligently add semantic capabilities:

1. **ğŸ§© Smart Chunking:** Break documents into coherent, searchable segments that preserve context
2. **ğŸ¤– Semantic Understanding:** Find relevant content even when users paraphrase or use synonyms  
3. **âš–ï¸ Hybrid Excellence:** Combine keyword precision with semantic recall using RRF fusion
4. **ğŸ“Š Best of Both Worlds:** Fast exact matching + deep semantic understanding
5. **ğŸ­ Production Reality:** How modern RAG systems actually work in practice

### **ğŸ—ï¸ Week 4 Architecture Overview**

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;static/week4_hybrid_opensearch.png&quot; alt=&quot;Week 4 Hybrid Search Architecture&quot; width=&quot;800&quot;&gt;
  &lt;br&gt;
  &lt;em&gt;Complete Week 4 hybrid search architecture with chunking, embeddings, and RRF fusion&lt;/em&gt;
&lt;/p&gt;

**Hybrid Search Infrastructure:** Production-grade chunking strategies with unified search supporting BM25, vector, and hybrid modes.

#### **ğŸ¯ Learning Objectives**
- **Section-Based Chunking:** Intelligent document segmentation that respects structure
- **Production Embeddings:** Jina AI integration with fallback strategies  
- **Hybrid Search Mastery:** RRF fusion combining keyword + semantic retrieval
- **Unified API Design:** Single endpoint supporting multiple search modes
- **Performance Analysis:** Understanding trade-offs between search approaches

#### **Key Components**
- `src/services/indexing/text_chunker.py`: Section-aware chunking with overlap strategies
- `src/services/embeddings/`: Production embedding pipeline with Jina AI
- `src/routers/hybrid_search.py`: Unified search API supporting all modes  
- `notebooks/week4/`: Complete hybrid search implementation guide

### **ğŸ““ Week 4 Implementation Guide**

```bash
# Launch the Week 4 notebook
uv run jupyter notebook notebooks/week4/week4_hybrid_search.ipynb
```

### **ğŸ’» Code Examples**

**Section-Based Chunking:**
```python
# Example: Intelligent document chunking
from src.services.indexing.text_chunker import TextChunker

chunker = TextChunker(chunk_size=600, overlap_size=100)
chunks = chunker.chunk_paper(
    title=&quot;Attention Mechanisms in Neural Networks&quot;,
    abstract=&quot;Recent advances in attention...&quot;,
    full_text=paper_content,
    sections=parsed_sections  # From Docling PDF parsing
)
# Result: Coherent chunks respecting document structure
```

**Hybrid Search Implementation:**
```python  
# Example: Unified search supporting multiple modes
async def search_papers(query: str, use_hybrid: bool = True):
    async with httpx.AsyncClient() as client:
        response = await client.post(&quot;http://localhost:8000/api/v1/hybrid-search/&quot;, json={
            &quot;query&quot;: query,
            &quot;use_hybrid&quot;: use_hybrid,  # Auto-generates embeddings
            &quot;size&quot;: 10,
            &quot;categories&quot;: [&quot;cs.AI&quot;]
        })
        return response.json()
        
# BM25 only: Fast keyword matching (~50ms)
bm25_results = await search_papers(&quot;transformer attention&quot;, use_hybrid=False)

# Hybrid search: Semantic + keyword understanding (~400ms)  
hybrid_results = await search_papers(&quot;how to make models more efficient&quot;, use_hybrid=True)
```

### **âœ… Success Criteria**
Complete when you can:
- [ ] Chunk documents intelligently: Papers broken into coherent 600-word segments
- [ ] Generate embeddings: Jina AI integration working with automatic query embedding
- [ ] Hybrid search working: RRF fusion combining BM25 + vector similarity
- [ ] Compare search modes: Understand when to use BM25 vs hybrid search
- [ ] Production API ready: `/hybrid-search` endpoint handling all search types

### **ğŸ“Š Performance Benchmarks**
| Search Mode | Speed | Precision@10 | Recall@10 | Use Case |
|-------------|-------|--------------|-----------|----------|
| **BM25 Only** | ~50ms | 0.67 | 0.71 | Exact keywords, author names |
| **Hybrid (RRF)** | ~400ms | 0.84 | 0.89 | Conceptual queries, synonyms |

### **ğŸ“– Deep Dive**  
**Blog Post:** [The Chunking Strategy That Makes Hybrid Search Work](link-to-week4-blog) - Production chunking and RRF fusion implementation

---

## ğŸ“š Week 5: Complete RAG Pipeline with LLM Integration ğŸš€

&gt; **ğŸ¯ The RAG Completion:** Transform search results into intelligent answers with local LLM integration and streaming responses.

**Building on Week 4 hybrid search:** Add the LLM layer that turns search into intelligent conversation.

### **ğŸ¯ Why Local LLM + Streaming?**

**The Production Advantage:** Complete the RAG pipeline with privacy-first, optimized generation:

1. **ğŸ  Local LLM Control:** Complete data privacy with Ollama - no external API calls
2. **âš¡ 6x Performance Boost:** Optimized from 120s â†’ 15-20s through prompt engineering
3. **ğŸ“¡ Real-time Streaming:** Server-Sent Events for immediate user feedback
4. **ğŸ›ï¸ User-Friendly Interface:** Gradio web UI for non-technical users
5. **ğŸ”§ Production Ready:** Clean API design 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Skyvern-AI/skyvern]]></title>
            <link>https://github.com/Skyvern-AI/skyvern</link>
            <guid>https://github.com/Skyvern-AI/skyvern</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:24 GMT</pubDate>
            <description><![CDATA[Automate browser based workflows with AI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Skyvern-AI/skyvern">Skyvern-AI/skyvern</a></h1>
            <p>Automate browser based workflows with AI</p>
            <p>Language: Python</p>
            <p>Stars: 17,180</p>
            <p>Forks: 1,453</p>
            <p>Stars today: 205 stars today</p>
            <h2>README</h2><pre>&lt;!-- DOCTOC SKIP --&gt;

&lt;h1 align=&quot;center&quot;&gt;
 &lt;a href=&quot;https://www.skyvern.com&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;fern/images/skyvern_logo.png&quot;/&gt;
    &lt;img height=&quot;120&quot; src=&quot;fern/images/skyvern_logo_blackbg.png&quot;/&gt;
  &lt;/picture&gt;
 &lt;/a&gt;
 &lt;br /&gt;
&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;
ğŸ‰ Automate Browser-based workflows using LLMs and Computer Vision ğŸ‰
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.skyvern.com/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Website-blue?logo=googlechrome&amp;logoColor=black&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.skyvern.com/docs/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Docs-yellow?logo=gitbook&amp;logoColor=black&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/fG2XXEuQX3&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1212486326352617534?logo=discord&amp;label=discord&quot;/&gt;&lt;/a&gt;
  &lt;!-- &lt;a href=&quot;https://pepy.tech/project/skyvern&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://static.pepy.tech/badge/skyvern&quot; alt=&quot;Total Downloads&quot;/&gt;&lt;/a&gt; --&gt;
  &lt;a href=&quot;https://github.com/skyvern-ai/skyvern&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/skyvern-ai/skyvern&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/Skyvern-AI/skyvern/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/skyvern-ai/skyvern&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/skyvernai&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/skyvernai?style=social&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.linkedin.com/company/95726232&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Follow%20 on%20LinkedIn-8A2BE2?logo=linkedin&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

[Skyvern](https://www.skyvern.com) automates browser-based workflows using LLMs and computer vision. It provides a simple API endpoint to fully automate manual workflows on a large number of websites, replacing brittle or unreliable automation solutions.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;fern/images/geico_shu_recording_cropped.gif&quot;/&gt;
&lt;/p&gt;

Traditional approaches to browser automations required writing custom scripts for websites, often relying on DOM parsing and XPath-based interactions which would break whenever the website layouts changed.

Instead of only relying on code-defined XPath interactions, Skyvern relies on Vision LLMs to learn and interact with the websites.

# How it works
Skyvern was inspired by the Task-Driven autonomous agent design popularized by [BabyAGI](https://github.com/yoheinakajima/babyagi) and [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT) -- with one major bonus: we give Skyvern the ability to interact with websites using browser automation libraries like [Playwright](https://playwright.dev/).

Skyvern uses a swarm of agents to comprehend a website, and plan and execute its actions:

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;fern/images/skyvern_2_0_system_diagram.png&quot; /&gt;
  &lt;img src=&quot;fern/images/skyvern_2_0_system_diagram.png&quot; /&gt;
&lt;/picture&gt;

This approach has a few advantages:

1. Skyvern can operate on websites it&#039;s never seen before, as it&#039;s able to map visual elements to actions necessary to complete a workflow, without any customized code
1. Skyvern is resistant to website layout changes, as there are no pre-determined XPaths or other selectors our system is looking for while trying to navigate
1. Skyvern is able to take a single workflow and apply it to a large number of websites, as it&#039;s able to reason through the interactions necessary to complete the workflow
1. Skyvern leverages LLMs to reason through interactions to ensure we can cover complex situations. Examples include:
    1. If you wanted to get an auto insurance quote from Geico, the answer to a common question &quot;Were you eligible to drive at 18?&quot; could be inferred from the driver receiving their license at age 16
    1. If you were doing competitor analysis, it&#039;s understanding that an Arnold Palmer 22 oz can at 7/11 is almost definitely the same product as a 23 oz can at Gopuff (even though the sizes are slightly different, which could be a rounding error!)

A detailed technical report can be found [here](https://www.skyvern.com/blog/skyvern-2-0-state-of-the-art-web-navigation-with-85-8-on-webvoyager-eval/).

# Demo
&lt;!-- Redo demo --&gt;
https://github.com/user-attachments/assets/5cab4668-e8e2-4982-8551-aab05ff73a7f

# Performance &amp; Evaluation

Skyvern has SOTA performance on the [WebBench benchmark](webbench.ai) with a 64.4% accuracy. The technical report + evaluation can be found [here](https://www.skyvern.com/blog/web-bench-a-new-way-to-compare-ai-browser-agents/)

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;fern/images/performance/webbench_overall.png&quot;/&gt;
&lt;/p&gt;

## Performance on WRITE tasks (eg filling out forms, logging in, downloading files, etc)

Skyvern is the best performing agent on WRITE tasks (eg filling out forms, logging in, downloading files, etc), which is primarily used for RPA (Robotic Process Automation) adjacent tasks.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;fern/images/performance/webbench_write.png&quot;/&gt;
&lt;/p&gt;

# Quickstart

## Skyvern Cloud
[Skyvern Cloud](https://app.skyvern.com) is a managed cloud version of Skyvern that allows you to run Skyvern without worrying about the infrastructure. It allows you to run multiple Skyvern instances in parallel and comes bundled with anti-bot detection mechanisms, proxy network, and CAPTCHA solvers.

If you&#039;d like to try it out, navigate to [app.skyvern.com](https://app.skyvern.com) and create an account.

## Install &amp; Run

Dependencies needed:
- [Python 3.11.x](https://www.python.org/downloads/), works with 3.12, not ready yet for 3.13
- [NodeJS &amp; NPM](https://nodejs.org/en/download/)

Additionally, for Windows:
- [Rust](https://rustup.rs/)
- VS Code with C++ dev tools and Windows SDK

### 1. Install Skyvern

```bash
pip install skyvern
```

### 2. Run Skyvern
This is most helpful for first time run (db setup, db migrations etc).

```bash
skyvern quickstart
```

### 3. Run task

#### UI (Recommended)

Start the Skyvern service and UI (when DB is up and running)

```bash
skyvern run all
```

Go to http://localhost:8080 and use the UI to run a task

#### Code

```python
from skyvern import Skyvern

skyvern = Skyvern()
task = await skyvern.run_task(prompt=&quot;Find the top post on hackernews today&quot;)
print(task)
```
Skyvern starts running the task in a browser that pops up and closes it when the task is done. You will be able to view the task from http://localhost:8080/history

You can also run a task on different targets:
```python
from skyvern import Skyvern

# Run on Skyvern Cloud
skyvern = Skyvern(api_key=&quot;SKYVERN API KEY&quot;)

# Local Skyvern service
skyvern = Skyvern(base_url=&quot;http://localhost:8000&quot;, api_key=&quot;LOCAL SKYVERN API KEY&quot;)

task = await skyvern.run_task(prompt=&quot;Find the top post on hackernews today&quot;)
print(task)
```

## Advanced Usage

### Control your own browser (Chrome)
&gt; âš ï¸ WARNING: Since [Chrome 136](https://developer.chrome.com/blog/remote-debugging-port), Chrome refuses any CDP connect to the browser using the default user_data_dir. In order to use your browser data, Skyvern copies your default user_data_dir to `./tmp/user_data_dir` the first time connecting to your local browser. âš ï¸

1. Just With Python Code
```python
from skyvern import Skyvern

# The path to your Chrome browser. This example path is for Mac.
browser_path = &quot;/Applications/Google Chrome.app/Contents/MacOS/Google Chrome&quot;
skyvern = Skyvern(
    base_url=&quot;http://localhost:8000&quot;,
    api_key=&quot;YOUR_API_KEY&quot;,
    browser_path=browser_path,
)
task = await skyvern.run_task(
    prompt=&quot;Find the top post on hackernews today&quot;,
)
```

2. With Skyvern Service

Add two variables to your .env file:
```bash
# The path to your Chrome browser. This example path is for Mac.
CHROME_EXECUTABLE_PATH=&quot;/Applications/Google Chrome.app/Contents/MacOS/Google Chrome&quot;
BROWSER_TYPE=cdp-connect
```

Restart Skyvern service `skyvern run all` and run the task through UI or code

### Run Skyvern with any remote browser
Grab the cdp connection url and pass it to Skyvern

```python
from skyvern import Skyvern

skyvern = Skyvern(cdp_url=&quot;your cdp connection url&quot;)
task = await skyvern.run_task(
    prompt=&quot;Find the top post on hackernews today&quot;,
)
```

### Get consistent output schema from your run
You can do this by adding the `data_extraction_schema` parameter:
```python
from skyvern import Skyvern

skyvern = Skyvern()
task = await skyvern.run_task(
    prompt=&quot;Find the top post on hackernews today&quot;,
    data_extraction_schema={
        &quot;type&quot;: &quot;object&quot;,
        &quot;properties&quot;: {
            &quot;title&quot;: {
                &quot;type&quot;: &quot;string&quot;,
                &quot;description&quot;: &quot;The title of the top post&quot;
            },
            &quot;url&quot;: {
                &quot;type&quot;: &quot;string&quot;,
                &quot;description&quot;: &quot;The URL of the top post&quot;
            },
            &quot;points&quot;: {
                &quot;type&quot;: &quot;integer&quot;,
                &quot;description&quot;: &quot;Number of points the post has received&quot;
            }
        }
    }
)
```

### Helpful commands to debug issues


```bash
# Launch the Skyvern Server Separately*
skyvern run server

# Launch the Skyvern UI
skyvern run ui

# Check status of the Skyvern service
skyvern status

# Stop the Skyvern service
skyvern stop all

# Stop the Skyvern UI
skyvern stop ui

# Stop the Skyvern Server Separately
skyvern stop server
```

## Docker Compose setup

1. Make sure you have [Docker Desktop](https://www.docker.com/products/docker-desktop/) installed and running on your machine
1. Make sure you don&#039;t have postgres running locally (Run `docker ps` to check)
1. Clone the repository and navigate to the root directory
1. Run `skyvern init llm` to generate a `.env` file. This will be copied into the Docker image.
1. Fill in the LLM provider key on the [docker-compose.yml](./docker-compose.yml). *If you want to run Skyvern on a remote server, make sure you set the correct server ip for the UI container in [docker-compose.yml](./docker-compose.yml).*
2. Run the following command via the commandline:
   ```bash
    docker compose up -d
   ```
3. Navigate to `http://localhost:8080` in your browser to start using the UI

&gt; **Important:** Only one Postgres container can run on port 5432 at a time. If you switch from the CLI-managed Postgres to Docker Compose, you must first remove the original container:
&gt; ```bash
&gt; docker rm -f postgresql-container
&gt; ```

If you encounter any database related errors while using Docker to run Skyvern, check which Postgres container is running with `docker ps`.



# Skyvern Features

## Skyvern Tasks
Tasks are the fundamental building block inside Skyvern. Each task is a single request to Skyvern, instructing it to navigate through a website and accomplish a specific goal.

Tasks require you to specify a `url`, `prompt`, and can optionally include a `data schema` (if you want the output to conform to a specific schema) and `error codes` (if you want Skyvern to stop running in specific situations).

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;fern/images/skyvern_2_0_screenshot.png&quot;/&gt;
&lt;/p&gt;


## Skyvern Workflows
Workflows are a way to chain multiple tasks together to form a cohesive unit of work.

For example, if you wanted to download all invoices newer than January 1st, you could create a workflow that first navigated to the invoices page, then filtered down to only show invoices newer than January 1st, extracted a list of all eligible invoices, and iterated through each invoice to download it.

Another example is if you wanted to automate purchasing products from an e-commerce store, you could create a workflow that first navigated to the desired product, then added it to a cart. Second, it would navigate to the cart and validate the cart state. Finally, it would go through the checkout process to purchase the items.

Supported workflow features include:
1. Browser Task
1. Browser Action
1. Data Extraction
1. Validation
1. For Loops
1. File parsing
1. Sending emails
1. Text Prompts
1. HTTP Request Block
1. Custom Code Block
1. Uploading files to block storage
1. (Coming soon) Conditionals

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;fern/images/block_example_v2.png&quot;/&gt;
&lt;/p&gt;

## Livestreaming
Skyvern allows you to livestream the viewport of the browser to your local machine so that you can see exactly what Skyvern is doing on the web. This is useful for debugging and understanding how Skyvern is interacting with a website, and intervening when necessary

## Form Filling
Skyvern is natively capable of filling out form inputs on websites. Passing in information via the `navigation_goal` will allow Skyvern to comprehend the information and fill out the form accordingly.

## Data Extraction
Skyvern is also capable of extracting data from a website.

You can also specify a `data_extraction_schema` directly within the main prompt to tell Skyvern exactly what data you&#039;d like to extract from the website, in jsonc format. Skyvern&#039;s output will be structured in accordance to the supplied schema.

## File Downloading
Skyvern is also capable of downloading files from a website. All downloaded files are automatically uploaded to block storage (if configured), and you can access them via the UI.

## Authentication
Skyvern supports a number of different authentication methods to make it easier to automate tasks behind a login. If you&#039;d like to try it out, please reach out to us [via email](mailto:founders@skyvern.com) or [discord](https://discord.gg/fG2XXEuQX3).

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;fern/images/secure_password_task_example.png&quot;/&gt;
&lt;/p&gt;


### ğŸ” 2FA Support (TOTP)
Skyvern supports a number of different 2FA methods to allow you to automate workflows that require 2FA.

Examples include:
1. QR-based 2FA (e.g. Google Authenticator, Authy)
1. Email based 2FA
1. SMS based 2FA

ğŸ” Learn more about 2FA support [here](https://www.skyvern.com/docs/credentials/totp).

### Password Manager Integrations
Skyvern currently supports the following password manager integrations:
- [x] Bitwarden
- [ ] 1Password
- [ ] LastPass


## Model Context Protocol (MCP)
Skyvern supports the Model Context Protocol (MCP) to allow you to use any LLM that supports MCP.

See the MCP documentation [here](https://github.com/Skyvern-AI/skyvern/blob/main/integrations/mcp/README.md)

## Zapier / Make.com / N8N Integration
Skyvern supports Zapier, Make.com, and N8N to allow you to connect your Skyvern workflows to other apps.

* [Zapier](https://www.skyvern.com/docs/integrations/zapier)
* [Make.com](https://www.skyvern.com/docs/integrations/make.com)
* [N8N](https://www.skyvern.com/docs/integrations/n8n)

ğŸ” Learn more about 2FA support [here](https://www.skyvern.com/docs/credentials/totp).


# Real-world examples of Skyvern
We love to see how Skyvern is being used in the wild. Here are some examples of how Skyvern is being used to automate workflows in the real world. Please open PRs to add your own examples!

## Invoice Downloading on many different websites
[Book a demo to see it live](https://meetings.hubspot.com/skyvern/demo)

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;fern/images/invoice_downloading.gif&quot;/&gt;
&lt;/p&gt;

## Automate the job application process
[ğŸ’¡ See it in action](https://app.skyvern.com/tasks/create/job_application)
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;fern/images/job_application_demo.gif&quot;/&gt;
&lt;/p&gt;

## Automate materials procurement for a manufacturing company
[ğŸ’¡ See it in action](https://app.skyvern.com/tasks/create/finditparts)
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;fern/images/finditparts_recording_crop.gif&quot;/&gt;
&lt;/p&gt;

## Navigating to government websites to register accounts or fill out forms
[ğŸ’¡ See it in action](https://app.skyvern.com/tasks/create/california_edd)
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;fern/images/edd_services.gif&quot;/&gt;
&lt;/p&gt;
&lt;!-- Add example of delaware entity lookups x2 --&gt;

## Filling out random contact us forms
[ğŸ’¡ See it in action](https://app.skyvern.com/tasks/create/contact_us_forms)
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;fern/images/contact_forms.gif&quot;/&gt;
&lt;/p&gt;


## Retrieving insurance quotes from insurance providers in any language
[ğŸ’¡ See it in action](https://app.skyvern.com/tasks/create/bci_seguros)
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;fern/images/bci_seguros_recording.gif&quot;/&gt;
&lt;/p&gt;

[ğŸ’¡ See it in action](https://app.skyvern.com/tasks/create/geico)

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;fern/images/geico_shu_recording_cropped.gif&quot;/&gt;
&lt;/p&gt;

# Contributor Setup
Make sure to have [uv](https://docs.astral.sh/uv/getting-started/installation/) installed.
1. Run this to create your virtual environment (`.venv`)
    ```bash
    uv sync --group dev
    ```
2. Perform initial server configuration
    ```bash
    uv run skyvern quickstart
    ```
3. Navigate to `http://localhost:8080` in your browser to start using the UI
   *The Skyvern CLI supports Windows, WSL, macOS, and Linux environments.*

# Documentation

More extensive documentation can be found on our [ğŸ“• docs page](https://www.skyvern.com/docs). Please let us know if something is unclear or missing by opening an issue or reaching out to us [via email](mailto:founders@skyvern.com) or [discord](https://discord.gg/fG2XXEuQX3).

# Supported LLMs
| Provider | Supported Models |
| -------- | ------- |
| OpenAI   | gpt4-turbo, gpt-4o, gpt-4o-mini |
| Anthropic | Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet) |
| Azure OpenAI | Any GPT models. Better performance with a multimodal llm (azure/gpt4-o) |
| AWS Bedrock | Anthropic Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet) |
| Gemini | Gemini 2.5 Pro and flash, Gemini 2.0 |
| Ollama | Run any locally hosted model via [Ollama](https://github.com/ollama/ollama) |
| OpenRouter | Access models through [OpenRouter](https://openrouter.ai) |
| OpenAI-compatible | Any custom API endpoint that follows OpenAI&#039;s API format (via [liteLLM](https://docs.litellm.ai/docs/providers/openai_compatible)) |

#### Environment Variables

##### OpenAI
| Variable | Description| Type | Sample Value|
| -------- | ------- | ------- | ------- |
| `ENABLE_OPENAI`| Register OpenAI models | Boolean | `true`, `false` |
| `OPENAI_API_KEY` | OpenAI API Key | String | `sk-1234567890` |
| `OPENAI_API_BASE` | OpenAI API Base, optional | String | `https://openai.api.base` |
| `OPENAI_ORGANIZATION` | OpenAI Organization ID, optional | String | `your-org-id` |

Recommended `LLM_KEY`: `OPENAI_GPT4O`, `OPENAI_GPT4O_MINI`, `OPENAI_GPT4_1`, `OPENAI_O4_MINI`, `OPENAI_O3`

##### Anthropic
| Variable | Description| Type | Sample Value|
| -------- | ------- | ------- | ------- |
| `ENABLE_ANTHROPIC` | Register Anthropic models| Boolean | `true`, `false` |
| `ANTHROPIC_API_KEY` | Anthropic API key| String | `sk-1234567890` |

Recommended`LLM_KEY`: `ANTHROPIC_CLAUDE3.5_SONNET`, `ANTHROPIC_CLAUDE3.7_SONNET`, `ANTHROPIC_CLAUDE4_OPUS`, `ANTHROPIC_CLAUDE4_SONNET`

##### Azure OpenAI
| Variable | Description| Type | Sample Value|
| -------- | ------- | ------- | ------- |
| `ENABLE_AZURE` | Register Azure OpenAI models | Boolean | `true`, `false` |
| `AZURE_API_KEY` | Azure deployment API key | String | `sk-1234567890` |
| `AZURE_DEPLOYMENT` | Azure OpenAI Deployment Name | String | `skyvern-deployment`|
| `AZURE_API_BASE` | Azure deployment api base url| String | `https://skyvern-deployment.openai.azure.com/`|
| `AZURE_API_VERSION` | Azure API Version| String | `2024-02-01`|

Recommended `LLM_KEY`: `AZURE_OPENAI`

##### AWS Bedrock
| Variable | Description| Type | Sample Value|
| -------- | ------- | ------- | ------- |
| `ENABLE_BEDROCK` | Register AWS Bedrock models. To use AWS Bedrock, you need to make sure your [AWS configurations](https://github.com/boto/boto3?tab=readme-ov-file#using-boto3) are set up correctly first. | Boolean | `true`, `false` |

Recommended `LLM_KEY`: `BEDROCK_ANTHROPIC_CLAUDE3.7_SONNET_INFERENCE_PROFILE`, `BEDROCK_ANTHROPIC_CLAUDE4_OPUS_INFERENCE_PROFILE`, `BEDROCK_ANTHROPIC_CLAUDE4_SONNET_INFERENCE_PROFILE`

##### Gemini
| Variable | Description| Type | Sample Value|
| -------- | ------- | ------- | ------- |
| `ENABLE_GEMINI` | Register Gemini models| Boolean | `true`, `false` |
| `GEMINI_API_KEY` | Gemini API Key| String | `your_google_gemini_api_key`|

Recommended `LLM_KEY`: `GEMINI_2.5_PRO_PREVIEW`, `GEMINI_2.5_FLASH_PREVIEW`

##### Ollama
| Variable

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[cheahjs/free-llm-api-resources]]></title>
            <link>https://github.com/cheahjs/free-llm-api-resources</link>
            <guid>https://github.com/cheahjs/free-llm-api-resources</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:23 GMT</pubDate>
            <description><![CDATA[A list of free LLM inference resources accessible via API.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cheahjs/free-llm-api-resources">cheahjs/free-llm-api-resources</a></h1>
            <p>A list of free LLM inference resources accessible via API.</p>
            <p>Language: Python</p>
            <p>Stars: 6,444</p>
            <p>Forks: 608</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre>&lt;!---
WARNING: DO NOT EDIT THIS FILE DIRECTLY. IT IS GENERATED BY src/pull_available_models.py
---&gt;
# Free LLM API resources

This lists various services that provide free access or credits towards API-based LLM usage.

&gt; [!NOTE]  
&gt; Please don&#039;t abuse these services, else we might lose them.

&gt; [!WARNING]  
&gt; This list explicitly excludes any services that are not legitimate (eg reverse engineers an existing chatbot)

- [Free Providers](#free-providers)
  - [OpenRouter](#openrouter)
  - [Google AI Studio](#google-ai-studio)
  - [NVIDIA NIM](#nvidia-nim)
  - [Mistral (La Plateforme)](#mistral-la-plateforme)
  - [Mistral (Codestral)](#mistral-codestral)
  - [HuggingFace Inference Providers](#huggingface-inference-providers)
  - [Vercel AI Gateway](#vercel-ai-gateway)
  - [Cerebras](#cerebras)
  - [Groq](#groq)
  - [Cohere](#cohere)
  - [GitHub Models](#github-models)
  - [Cloudflare Workers AI](#cloudflare-workers-ai)
  - [Google Cloud Vertex AI](#google-cloud-vertex-ai)
- [Providers with trial credits](#providers-with-trial-credits)
  - [Fireworks](#fireworks)
  - [Baseten](#baseten)
  - [Nebius](#nebius)
  - [Novita](#novita)
  - [AI21](#ai21)
  - [Upstage](#upstage)
  - [NLP Cloud](#nlp-cloud)
  - [Alibaba Cloud (International) Model Studio](#alibaba-cloud-international-model-studio)
  - [Modal](#modal)
  - [Inference.net](#inferencenet)
  - [Hyperbolic](#hyperbolic)
  - [SambaNova Cloud](#sambanova-cloud)
  - [Scaleway Generative APIs](#scaleway-generative-apis)

## Free Providers

### [OpenRouter](https://openrouter.ai)

**Limits:**

[20 requests/minute&lt;br&gt;50 requests/day&lt;br&gt;Up to 1000 requests/day with $10 lifetime topup](https://openrouter.ai/docs/api-reference/limits)

Models share a common quota.

- [DeepCoder 14B Preview](https://openrouter.ai/agentica-org/deepcoder-14b-preview:free)
- [DeepSeek R1](https://openrouter.ai/deepseek/deepseek-r1:free)
- [DeepSeek R1 Distill Llama 70B](https://openrouter.ai/deepseek/deepseek-r1-distill-llama-70b:free)
- [DeepSeek V3 0324](https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free)
- [Gemma 3 12B Instruct](https://openrouter.ai/google/gemma-3-12b-it:free)
- [Gemma 3 27B Instruct](https://openrouter.ai/google/gemma-3-27b-it:free)
- [Gemma 3 4B Instruct](https://openrouter.ai/google/gemma-3-4b-it:free)
- [Hermes 3 Llama 3.1 405B](https://openrouter.ai/nousresearch/hermes-3-llama-3.1-405b:free)
- [Llama 3.2 3B Instruct](https://openrouter.ai/meta-llama/llama-3.2-3b-instruct:free)
- [Llama 3.3 70B Instruct](https://openrouter.ai/meta-llama/llama-3.3-70b-instruct:free)
- [Llama 4 Maverick](https://openrouter.ai/meta-llama/llama-4-maverick:free)
- [Llama 4 Scout](https://openrouter.ai/meta-llama/llama-4-scout:free)
- [Mistral 7B Instruct](https://openrouter.ai/mistralai/mistral-7b-instruct:free)
- [Mistral Nemo](https://openrouter.ai/mistralai/mistral-nemo:free)
- [Mistral Small 24B Instruct 2501](https://openrouter.ai/mistralai/mistral-small-24b-instruct-2501:free)
- [Mistral Small 3.1 24B Instruct](https://openrouter.ai/mistralai/mistral-small-3.1-24b-instruct:free)
- [QwQ 32B ArliAI RpR v1](https://openrouter.ai/arliai/qwq-32b-arliai-rpr-v1:free)
- [Qwen 2.5 72B Instruct](https://openrouter.ai/qwen/qwen-2.5-72b-instruct:free)
- [Qwen 2.5 VL 32B Instruct](https://openrouter.ai/qwen/qwen2.5-vl-32b-instruct:free)
- [Qwen2.5 Coder 32B Instruct](https://openrouter.ai/qwen/qwen-2.5-coder-32b-instruct:free)
- [alibaba/tongyi-deepresearch-30b-a3b:free](https://openrouter.ai/alibaba/tongyi-deepresearch-30b-a3b:free)
- [cognitivecomputations/dolphin-mistral-24b-venice-edition:free](https://openrouter.ai/cognitivecomputations/dolphin-mistral-24b-venice-edition:free)
- [deepseek/deepseek-chat-v3.1:free](https://openrouter.ai/deepseek/deepseek-chat-v3.1:free)
- [deepseek/deepseek-r1-0528-qwen3-8b:free](https://openrouter.ai/deepseek/deepseek-r1-0528-qwen3-8b:free)
- [deepseek/deepseek-r1-0528:free](https://openrouter.ai/deepseek/deepseek-r1-0528:free)
- [google/gemma-3n-e2b-it:free](https://openrouter.ai/google/gemma-3n-e2b-it:free)
- [google/gemma-3n-e4b-it:free](https://openrouter.ai/google/gemma-3n-e4b-it:free)
- [meituan/longcat-flash-chat:free](https://openrouter.ai/meituan/longcat-flash-chat:free)
- [meta-llama/llama-3.3-8b-instruct:free](https://openrouter.ai/meta-llama/llama-3.3-8b-instruct:free)
- [microsoft/mai-ds-r1:free](https://openrouter.ai/microsoft/mai-ds-r1:free)
- [minimax/minimax-m2:free](https://openrouter.ai/minimax/minimax-m2:free)
- [mistralai/mistral-small-3.2-24b-instruct:free](https://openrouter.ai/mistralai/mistral-small-3.2-24b-instruct:free)
- [moonshotai/kimi-k2:free](https://openrouter.ai/moonshotai/kimi-k2:free)
- [nvidia/nemotron-nano-12b-v2-vl:free](https://openrouter.ai/nvidia/nemotron-nano-12b-v2-vl:free)
- [nvidia/nemotron-nano-9b-v2:free](https://openrouter.ai/nvidia/nemotron-nano-9b-v2:free)
- [openai/gpt-oss-20b:free](https://openrouter.ai/openai/gpt-oss-20b:free)
- [qwen/qwen3-14b:free](https://openrouter.ai/qwen/qwen3-14b:free)
- [qwen/qwen3-235b-a22b:free](https://openrouter.ai/qwen/qwen3-235b-a22b:free)
- [qwen/qwen3-30b-a3b:free](https://openrouter.ai/qwen/qwen3-30b-a3b:free)
- [qwen/qwen3-4b:free](https://openrouter.ai/qwen/qwen3-4b:free)
- [qwen/qwen3-coder:free](https://openrouter.ai/qwen/qwen3-coder:free)
- [tngtech/deepseek-r1t-chimera:free](https://openrouter.ai/tngtech/deepseek-r1t-chimera:free)
- [tngtech/deepseek-r1t2-chimera:free](https://openrouter.ai/tngtech/deepseek-r1t2-chimera:free)
- [z-ai/glm-4.5-air:free](https://openrouter.ai/z-ai/glm-4.5-air:free)

### [Google AI Studio](https://aistudio.google.com)

Data is used for training when used outside of the UK/CH/EEA/EU.

&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Model Name&lt;/th&gt;&lt;th&gt;Model Limits&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;Gemini 2.5 Pro&lt;/td&gt;&lt;td&gt;3,000,000 tokens/day&lt;br&gt;125,000 tokens/minute&lt;br&gt;50 requests/day&lt;br&gt;2 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemini 2.5 Flash&lt;/td&gt;&lt;td&gt;250,000 tokens/minute&lt;br&gt;250 requests/day&lt;br&gt;10 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemini 2.5 Flash-Lite&lt;/td&gt;&lt;td&gt;250,000 tokens/minute&lt;br&gt;1,000 requests/day&lt;br&gt;15 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemini 2.0 Flash&lt;/td&gt;&lt;td&gt;1,000,000 tokens/minute&lt;br&gt;200 requests/day&lt;br&gt;15 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemini 2.0 Flash-Lite&lt;/td&gt;&lt;td&gt;1,000,000 tokens/minute&lt;br&gt;200 requests/day&lt;br&gt;30 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemini 2.0 Flash (Experimental)&lt;/td&gt;&lt;td&gt;250,000 tokens/minute&lt;br&gt;50 requests/day&lt;br&gt;10 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;LearnLM 2.0 Flash (Experimental)&lt;/td&gt;&lt;td&gt;1,500 requests/day&lt;br&gt;15 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemma 3 27B Instruct&lt;/td&gt;&lt;td&gt;15,000 tokens/minute&lt;br&gt;14,400 requests/day&lt;br&gt;30 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemma 3 12B Instruct&lt;/td&gt;&lt;td&gt;15,000 tokens/minute&lt;br&gt;14,400 requests/day&lt;br&gt;30 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemma 3 4B Instruct&lt;/td&gt;&lt;td&gt;15,000 tokens/minute&lt;br&gt;14,400 requests/day&lt;br&gt;30 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Gemma 3 1B Instruct&lt;/td&gt;&lt;td&gt;15,000 tokens/minute&lt;br&gt;14,400 requests/day&lt;br&gt;30 requests/minute&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

### [NVIDIA NIM](https://build.nvidia.com/explore/discover)

Phone number verification required.
Models tend to be context window limited.

**Limits:** 40 requests/minute

- [Various open models](https://build.nvidia.com/models)

### [Mistral (La Plateforme)](https://console.mistral.ai/)

* Free tier (Experiment plan) requires opting into data training
* Requires phone number verification.

**Limits (per-model):** 1 request/second, 500,000 tokens/minute, 1,000,000,000 tokens/month

- [Open and Proprietary Mistral models](https://docs.mistral.ai/getting-started/models/models_overview/)

### [Mistral (Codestral)](https://codestral.mistral.ai/)

* Currently free to use
* Monthly subscription based
* Requires phone number verification

**Limits:** 30 requests/minute, 2,000 requests/day

- Codestral

### [HuggingFace Inference Providers](https://huggingface.co/docs/inference-providers/en/index)

HuggingFace Serverless Inference limited to models smaller than 10GB. Some popular models are supported even if they exceed 10GB.

**Limits:** [$0.10/month in credits](https://huggingface.co/docs/inference-providers/en/pricing)

- Various open models across supported providers

### [Vercel AI Gateway](https://vercel.com/docs/ai-gateway)

Routes to various supported providers.

**Limits:** [$5/month](https://vercel.com/docs/ai-gateway/pricing)


### [Cerebras](https://cloud.cerebras.ai/)

&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Model Name&lt;/th&gt;&lt;th&gt;Model Limits&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;gpt-oss-120b&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;60,000 tokens/minute&lt;br&gt;900 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;14,400 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Qwen 3 235B A22B Instruct&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;60,000 tokens/minute&lt;br&gt;900 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;14,400 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Qwen 3 235B A22B Thinking&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;60,000 tokens/minute&lt;br&gt;900 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;14,400 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Qwen 3 Coder 480B&lt;/td&gt;&lt;td&gt;10 requests/minute&lt;br&gt;150,000 tokens/minute&lt;br&gt;100 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;100 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Llama 3.3 70B&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;64,000 tokens/minute&lt;br&gt;900 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;14,400 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Qwen 3 32B&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;64,000 tokens/minute&lt;br&gt;900 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;14,400 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Llama 3.1 8B&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;60,000 tokens/minute&lt;br&gt;900 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;14,400 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Llama 4 Scout&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;60,000 tokens/minute&lt;br&gt;900 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;14,400 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Llama 4 Maverick&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;60,000 tokens/minute&lt;br&gt;900 requests/hour&lt;br&gt;1,000,000 tokens/hour&lt;br&gt;14,400 requests/day&lt;br&gt;1,000,000 tokens/day&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

### [Groq](https://console.groq.com)

&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Model Name&lt;/th&gt;&lt;th&gt;Model Limits&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;Allam 2 7B&lt;/td&gt;&lt;td&gt;7,000 requests/day&lt;br&gt;6,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Llama 3.1 8B&lt;/td&gt;&lt;td&gt;14,400 requests/day&lt;br&gt;6,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Llama 3.3 70B&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;12,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Llama 4 Maverick 17B 128E Instruct&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;6,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Llama 4 Scout Instruct&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;30,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Whisper Large v3&lt;/td&gt;&lt;td&gt;7,200 audio-seconds/minute&lt;br&gt;2,000 requests/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Whisper Large v3 Turbo&lt;/td&gt;&lt;td&gt;7,200 audio-seconds/minute&lt;br&gt;2,000 requests/day&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;groq/compound&lt;/td&gt;&lt;td&gt;250 requests/day&lt;br&gt;70,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;groq/compound-mini&lt;/td&gt;&lt;td&gt;250 requests/day&lt;br&gt;70,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;meta-llama/llama-guard-4-12b&lt;/td&gt;&lt;td&gt;14,400 requests/day&lt;br&gt;15,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;meta-llama/llama-prompt-guard-2-22m&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;meta-llama/llama-prompt-guard-2-86m&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;moonshotai/kimi-k2-instruct&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;10,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;moonshotai/kimi-k2-instruct-0905&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;10,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;openai/gpt-oss-120b&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;8,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;openai/gpt-oss-20b&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;8,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;openai/gpt-oss-safeguard-20b&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;8,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;qwen/qwen3-32b&lt;/td&gt;&lt;td&gt;1,000 requests/day&lt;br&gt;6,000 tokens/minute&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

### [Cohere](https://cohere.com)

**Limits:**

[20 requests/minute&lt;br&gt;1,000 requests/month](https://docs.cohere.com/docs/rate-limits)

Models share a common quota.

- c4ai-aya-expanse-32b
- c4ai-aya-expanse-8b
- c4ai-aya-vision-32b
- c4ai-aya-vision-8b
- command-a-03-2025
- command-a-reasoning-08-2025
- command-a-translate-08-2025
- command-a-vision-07-2025
- command-r-08-2024
- command-r-plus-08-2024
- command-r7b-12-2024
- command-r7b-arabic-02-2025

### [GitHub Models](https://github.com/marketplace/models)

Extremely restrictive input/output token limits.

**Limits:** [Dependent on Copilot subscription tier (Free/Pro/Pro+/Business/Enterprise)](https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits)

- AI21 Jamba 1.5 Large
- AI21 Jamba 1.5 Mini
- Codestral 25.01
- Cohere Command A
- Cohere Command R 08-2024
- Cohere Command R+ 08-2024
- Cohere Embed v3 English
- Cohere Embed v3 Multilingual
- DeepSeek-R1
- DeepSeek-R1-0528
- DeepSeek-V3-0324
- Grok 3
- Grok 3 Mini
- Llama 4 Maverick 17B 128E Instruct FP8
- Llama 4 Scout 17B 16E Instruct
- Llama-3.2-11B-Vision-Instruct
- Llama-3.2-90B-Vision-Instruct
- Llama-3.3-70B-Instruct
- MAI-DS-R1
- Meta-Llama-3.1-405B-Instruct
- Meta-Llama-3.1-8B-Instruct
- Ministral 3B
- Mistral Medium 3 (25.05)
- Mistral Small 3.1
- OpenAI GPT-4.1
- OpenAI GPT-4.1-mini
- OpenAI GPT-4.1-nano
- OpenAI GPT-4o
- OpenAI GPT-4o mini
- OpenAI Text Embedding 3 (large)
- OpenAI Text Embedding 3 (small)
- OpenAI gpt-5
- OpenAI gpt-5-chat (preview)
- OpenAI gpt-5-mini
- OpenAI gpt-5-nano
- OpenAI o1
- OpenAI o1-mini
- OpenAI o1-preview
- OpenAI o3
- OpenAI o3-mini
- OpenAI o4-mini
- Phi-4
- Phi-4-mini-instruct
- Phi-4-mini-reasoning
- Phi-4-multimodal-instruct
- Phi-4-reasoning

### [Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai)

**Limits:** [10,000 neurons/day](https://developers.cloudflare.com/workers-ai/platform/pricing/#free-allocation)

- @cf/aisingapore/gemma-sea-lion-v4-27b-it
- @cf/ibm-granite/granite-4.0-h-micro
- @cf/openai/gpt-oss-120b
- @cf/openai/gpt-oss-20b
- DeepSeek R1 Distill Qwen 32B
- Deepseek Coder 6.7B Base (AWQ)
- Deepseek Coder 6.7B Instruct (AWQ)
- Deepseek Math 7B Instruct
- Discolm German 7B v1 (AWQ)
- Falcom 7B Instruct
- Gemma 2B Instruct (LoRA)
- Gemma 3 12B Instruct
- Gemma 7B Instruct
- Gemma 7B Instruct (LoRA)
- Hermes 2 Pro Mistral 7B
- Llama 2 13B Chat (AWQ)
- Llama 2 7B Chat (FP16)
- Llama 2 7B Chat (INT8)
- Llama 2 7B Chat (LoRA)
- Llama 3 8B Instruct
- Llama 3 8B Instruct (AWQ)
- Llama 3.1 8B Instruct (AWQ)
- Llama 3.1 8B Instruct (FP8)
- Llama 3.2 11B Vision Instruct
- Llama 3.2 1B Instruct
- Llama 3.2 3B Instruct
- Llama 3.3 70B Instruct (FP8)
- Llama 4 Scout Instruct
- Llama Guard 3 8B
- LlamaGuard 7B (AWQ)
- Mistral 7B Instruct v0.1
- Mistral 7B Instruct v0.1 (AWQ)
- Mistral 7B Instruct v0.2
- Mistral 7B Instruct v0.2 (LoRA)
- Mistral Small 3.1 24B Instruct
- Neural Chat 7B v3.1 (AWQ)
- OpenChat 3.5 0106
- OpenHermes 2.5 Mistral 7B (AWQ)
- Phi-2
- Qwen 1.5 0.5B Chat
- Qwen 1.5 1.8B Chat
- Qwen 1.5 14B Chat (AWQ)
- Qwen 1.5 7B Chat (AWQ)
- Qwen 2.5 Coder 32B Instruct
- Qwen QwQ 32B
- SQLCoder 7B 2
- Starling LM 7B Beta
- TinyLlama 1.1B Chat v1.0
- Una Cybertron 7B v2 (BF16)
- Zephyr 7B Beta (AWQ)

### [Google Cloud Vertex AI](https://console.cloud.google.com/vertex-ai/model-garden)

Very stringent payment verification for Google Cloud.

&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Model Name&lt;/th&gt;&lt;th&gt;Model Limits&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3-2-90b-vision-instruct-maas&quot; target=&quot;_blank&quot;&gt;Llama 3.2 90B Vision Instruct&lt;/a&gt;&lt;/td&gt;&lt;td&gt;30 requests/minute&lt;br&gt;Free during preview&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3-1-405b-instruct-maas&quot; target=&quot;_blank&quot;&gt;Llama 3.1 70B Instruct&lt;/a&gt;&lt;/td&gt;&lt;td&gt;60 requests/minute&lt;br&gt;Free during preview&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3-1-405b-instruct-maas&quot; target=&quot;_blank&quot;&gt;Llama 3.1 8B Instruct&lt;/a&gt;&lt;/td&gt;&lt;td&gt;60 requests/minute&lt;br&gt;Free during preview&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;



## Providers with trial credits

### [Fireworks](https://fireworks.ai/)

**Credits:** $1

**Models:** [Various open models](https://fireworks.ai/models)

### [Baseten](https://app.baseten.co/)

**Credits:** $30

**Models:** [Any supported model - pay by compute time](https://www.baseten.co/library/)

### [Nebius](https://studio.nebius.com/)

**Credits:** $1

**Models:** [Various open models](https://studio.nebius.ai/models)

### [Novita](https://novita.ai/?ref=ytblmjc&amp;utm_source=affiliate)

**Credits:** $0.5 for 1 year

**Models:** [Various open models](https://novita.ai/models)

### [AI21](https://studio.ai21.com/)

**Credits:** $10 for 3 months

**Models:** Jamba family of models

### [Upstage](https://console.upstage.ai/)

**Credits:** $10 for 3 months

**Models:** Solar Pro/Mini

### [NLP Cloud](https://nlpcloud.com/home)

**Credits:** $15

**Requirements:** Phone number verification

**Models:** Various open models

### [Alibaba Cloud (International) Model Studio](https://bailian.console.alibabacloud.com/)

**Credits:** 1 million tokens/model

**Models:** [Various open and proprietary Qwen models](https://www.alibabacloud.com/en/product/modelstudio)

### [Modal](https://modal.com)

**Credits:** $5/month upon sign up, $30/month with payment method added

**Models:** Any supported model - pay by compute time

### [Inference.net](https://inference.net)

**Credits:** $1, $25 on responding to email survey

**Models:** Various open models

### [Hyperbolic](https://app.hyperbolic.xyz/)

**Credits:** $1

**Models:**
- DeepSeek V3
- DeepSeek V3 0324
- Hermes 3 Llama 3.1 70B
- Llama 3 70B Instruct
- Llama 3.1 405B Base
- Llama 3.1 405B Instruct
- Llama 3.1 70B Instruct
- Llama 3.1 8B Instruct
- Llama 3.2 3B Instruct
- Llama 3.3 70B Instruct
- Pixtral 12B (2409)
- Qwen QwQ 32B
- Qwen2.5 72B Instruct
- Qwen2.5 Coder 32B Instruct
- Qwen2.5 VL 72B Instruct
- Qwen2.5 VL 7B Instruct
- deepseek-ai/deepseek-r1-0528
- openai/gpt-oss-120b
- openai/gpt-oss-120b-turbo
- openai/gpt-oss-20b
- qwen/qwen3-235b-a22b
- qwen/qwen3-235b-a22b-instruct-2507
- qwen/qwen3-coder-480b-a35b-instruct
- qwen/qwen3-next-80b-a3b-instruct
- qwen/qwen3-next-80b-a3b-thinking

### [SambaNova Cloud](https://cloud.sambanova.ai/)

**Credits:** $5 for 3 months

**Models:**
- E5-Mistral-7B-Instruct
- Llama 3.1 8B
- Llama 3.3 70B
- Llama 3.3 70B
- Llama-4-Maverick-17B-128E-Instruct
- Qwen/Qwen3-32B
- Whisper-Large-v3
- deepseek-ai/DeepSeek-R1-0528
- deepseek-ai/DeepSeek-R1-Distill-Llama-70B
- deepseek-ai/DeepSeek-V3-0324
- deepseek-ai/DeepSeek-V3.1
- deepseek-ai/DeepSeek-V3.1-Terminus
- openai/gpt-oss-120b
- tbd

### [Scaleway Generative APIs](https://console.scaleway.com/generative-api/models)

**Credits:** 1,000,000 free tokens

**Models:**
- BGE-Multilingual-Gemma2
- DeepSeek R1 Distill Llama 70B
- Gemma 3 27B Instruct
- Llama 3.1 8B Instruct
- Llama 3.3 70B Instruct
- Mistral Nemo 2407
- Mistral Small 3.1 24B Instruct 2503
- Pixtral 12B (2409)
- Qwen2.5 Coder 32B Instruct
- Whisper Large v3
- devstral-small-2505
- gpt-oss-120b
- mistral-small-3.2-24b-instruct-2506
- qwen3-235b-a22b-instruct-2507
- qwen3-coder-30b-a3b-instruct
- voxtral-small-24b-2507


</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[google-deepmind/mujoco_menagerie]]></title>
            <link>https://github.com/google-deepmind/mujoco_menagerie</link>
            <guid>https://github.com/google-deepmind/mujoco_menagerie</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:22 GMT</pubDate>
            <description><![CDATA[A collection of high-quality models for the MuJoCo physics engine, curated by Google DeepMind.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google-deepmind/mujoco_menagerie">google-deepmind/mujoco_menagerie</a></h1>
            <p>A collection of high-quality models for the MuJoCo physics engine, curated by Google DeepMind.</p>
            <p>Language: Python</p>
            <p>Stars: 2,653</p>
            <p>Forks: 376</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;h1&gt;
  &lt;a href=&quot;#&quot;&gt;&lt;img alt=&quot;MuJoCo Menagerie&quot; src=&quot;assets/banner.png&quot; width=&quot;100%&quot;&gt;&lt;/a&gt;
&lt;/h1&gt;

&lt;p&gt;
  &lt;a href=&quot;https://github.com/google-deepmind/mujoco_menagerie/actions/workflows/build.yml?query=branch%3Amain&quot; alt=&quot;GitHub Actions&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/google-deepmind/mujoco_menagerie/build.yml?branch=main&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://mujoco.readthedocs.io/en/latest/models.html&quot; alt=&quot;Documentation&quot;&gt;
    &lt;img src=&quot;https://readthedocs.org/projects/mujoco/badge/?version=latest&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/google-deepmind/mujoco_menagerie/blob/main/CONTRIBUTING.md&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-green.svg&quot; alt=&quot;PRs&quot; height=&quot;20&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

**Menagerie** is a collection of high-quality models for the
[MuJoCo](https://github.com/google-deepmind/mujoco) physics engine, curated by
Google DeepMind.

A physics simulator is only as good as the model it is simulating, and in a
powerful simulator like MuJoCo with many modeling options, it is easy to create
&quot;bad&quot; models which do not behave as expected. The goal of this collection is to
provide the community with a curated library of well-designed models that work
well right out of the gate.

### Gallery

|&lt;img src=&quot;assets/franka_fr3-fr3.png&quot; width=100&gt;|&lt;img src=&quot;assets/kinova_gen3-gen3.png&quot; width=100&gt;|&lt;img src=&quot;assets/kuka_iiwa_14-iiwa14.png&quot; width=100&gt;|&lt;img src=&quot;assets/ufactory_lite6-lite6.png&quot; width=100&gt;|&lt;img src=&quot;assets/franka_emika_panda-panda.png&quot; width=100&gt;|
| :---: | :---: | :---: | :---: | :---: |
|&lt;img src=&quot;assets/agilex_piper-piper.png&quot; width=100&gt;|&lt;img src=&quot;assets/rethink_robotics_sawyer-sawyer.png&quot; width=100&gt;|&lt;img src=&quot;assets/universal_robots_ur10e-ur10e.png&quot; width=100&gt;|&lt;img src=&quot;assets/universal_robots_ur5e-ur5e.png&quot; width=100&gt;|&lt;img src=&quot;assets/trossen_vx300s-vx300s.png&quot; width=100&gt;|
|&lt;img src=&quot;assets/ufactory_xarm7-xarm7.png&quot; width=100&gt;|&lt;img src=&quot;assets/unitree_z1-z1.png&quot; width=100&gt;|&lt;img src=&quot;assets/aloha-aloha.png&quot; width=100&gt;|&lt;img src=&quot;assets/robotiq_2f85-2f85.png&quot; width=100&gt;|&lt;img src=&quot;assets/franka_emika_panda-hand.png&quot; width=100&gt;|
|&lt;img src=&quot;assets/ufactory_xarm7-hand.png&quot; width=100&gt;|&lt;img src=&quot;assets/wonik_allegro-left_hand.png&quot; width=100&gt;|&lt;img src=&quot;assets/shadow_hand-left_hand.png&quot; width=100&gt;|&lt;img src=&quot;assets/leap_hand-left_hand.png&quot; width=100&gt;|&lt;img src=&quot;assets/shadow_dexee-shadow_dexee.png&quot; width=100&gt;|
|&lt;img src=&quot;assets/google_robot-robot.png&quot; width=100&gt;|&lt;img src=&quot;assets/unitree_a1-a1.png&quot; width=100&gt;|&lt;img src=&quot;assets/anybotics_anymal_b-anymal_b.png&quot; width=100&gt;|&lt;img src=&quot;assets/anybotics_anymal_c-anymal_c.png&quot; width=100&gt;|&lt;img src=&quot;assets/google_barkour_v0-barkour_v0.png&quot; width=100&gt;|
|&lt;img src=&quot;assets/google_barkour_vb-barkour_vb.png&quot; width=100&gt;|&lt;img src=&quot;assets/unitree_go1-go1.png&quot; width=100&gt;|&lt;img src=&quot;assets/unitree_go2-go2.png&quot; width=100&gt;|&lt;img src=&quot;assets/boston_dynamics_spot-spot_arm.png&quot; width=100&gt;|&lt;img src=&quot;assets/agility_cassie-cassie.png&quot; width=100&gt;|
|&lt;img src=&quot;assets/unitree_g1-g1.png&quot; width=100&gt;|&lt;img src=&quot;assets/unitree_h1-h1.png&quot; width=100&gt;|&lt;img src=&quot;assets/robotis_op3-op3.png&quot; width=100&gt;|&lt;img src=&quot;assets/booster_t1-t1.png&quot; width=100&gt;|&lt;img src=&quot;assets/pal_talos-talos.png&quot; width=100&gt;|
|&lt;img src=&quot;assets/bitcraze_crazyflie_2-cf2.png&quot; width=100&gt;|&lt;img src=&quot;assets/skydio_x2-x2.png&quot; width=100&gt;|&lt;img src=&quot;assets/flybody-fruitfly.png&quot; width=100&gt;|&lt;img src=&quot;assets/realsense_d435i-d435i.png&quot; width=100&gt;||

- [Getting Started](#getting-started)
  - [Prerequisites](#prerequisites)
  - [Overview](#overview)
  - [Usage](#usage)
    - [Via `robot-descriptions`](#via-robot-descriptions)
    - [Via `git clone`](#via-git-clone)
- [Model Quality and Contributing](#model-quality-and-contributing)
- [Menagerie Models](#menagerie-models)
- [Citing Menagerie](#citing-menagerie)
- [Acknowledgments](#acknowledgments)
- [Changelog](#changelog)
- [License and Disclaimer](#license-and-disclaimer)

## Getting Started

### Prerequisites

The minimum required MuJoCo version for each model is specified in its
respective README. You can download prebuilt binaries for MuJoCo from the GitHub
[releases page](https://github.com/google-deepmind/mujoco/releases/), or if you
are working with Python, you can install the native bindings from
[PyPI](https://pypi.org/project/mujoco/) via `pip install mujoco`. For
alternative installation instructions, see
[here](https://github.com/google-deepmind/mujoco#installation).

### Overview

The structure of Menagerie is illustrated below. For brevity, we have only
included one model directory since all others follow the exact same pattern.

```bash
â”œâ”€â”€ unitree_go2
â”‚Â Â  â”œâ”€â”€ assets
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ base_0.obj
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ ...
â”‚Â Â  â”œâ”€â”€ go2.png
â”‚Â Â  â”œâ”€â”€ go2.xml
â”‚Â Â  â”œâ”€â”€ LICENSE
â”‚Â Â  â”œâ”€â”€ README.md
â”‚Â Â  â””â”€â”€ scene.xml
â”‚Â Â  â””â”€â”€ go2_mjx.xml
â”‚Â Â  â””â”€â”€ scene_mjx.xml
```

- `assets`: stores the 3D meshes (.stl or .obj) of the model used for visual and
  collision purposes
- `LICENSE`: describes the copyright and licensing terms of the model
- `README.md`: contains detailed steps describing how the model&#039;s MJCF XML file
  was generated
- `&lt;model&gt;.xml`: contains the MJCF definition of the model
- `scene.xml`: includes `&lt;model&gt;.xml` with a plane, a light source and
  potentially other objects
- `&lt;model&gt;.png`: a PNG image of `scene.xml`
- `&lt;model&gt;_mjx.xml`: contains an MJX-compatible version of the model. Not all
  models have an MJX variant (see [Menagerie Models](#menagerie-models) for more
  information).
- `scene_mjx.xml`: same as `scene.xml` but loads the MJX variant

Note that `&lt;model&gt;.xml` solely describes the model, i.e., no other entity is
defined in the kinematic tree. We leave additional body definitions for the
`scene.xml` file, as can be seen in the Shadow Hand
[`scene.xml`](shadow_hand/scene_right.xml).

### Usage

#### Via `robot-descriptions`

You can use the opensource
[`robot_descriptions`](https://github.com/robot-descriptions/robot_descriptions.py)
package to load any model in Menagerie. It is available on PyPI and can be
installed via `pip install robot_descriptions`.

Once installed, you can load a model of your choice as follows:

```python
import mujoco

# Loading a specific model description as an imported module.
from robot_descriptions import panda_mj_description
model = mujoco.MjModel.from_xml_path(panda_mj_description.MJCF_PATH)

# Directly loading an instance of MjModel.
from robot_descriptions.loaders.mujoco import load_robot_description
model = load_robot_description(&quot;panda_mj_description&quot;)

# Loading a variant of the model, e.g. panda without a gripper.
model = load_robot_description(&quot;panda_mj_description&quot;, variant=&quot;panda_nohand&quot;)
```

#### Via `git clone`

You can also directly clone this repository in the directory of your choice:

```bash
git clone https://github.com/google-deepmind/mujoco_menagerie.git
```

You can then interactively explore the model using the Python viewer:

```bash
python -m mujoco.viewer --mjcf mujoco_menagerie/unitree_go2/scene.xml
```

If you have further questions, please check out our [FAQ](FAQ.md).

## Model Quality and Contributing

Our goal is to eventually make all Menagerie models as faithful as possible to
the real system they are being modeled after. Improving model quality is an
ongoing effort, and the current state of many models is not necessarily
as good as it could be.

However, by releasing Menagerie in its current state, we hope to consolidate
and increase visibility for community contributions. To help Menagerie users
set proper expectations around the quality of each model, we introduce the
following grading system:

| Grade | Description                                                 |
|-------|-------------------------------------------------------------|
| A+    | Values are the product of proper system identification      |
| A     | Values are realistic, but have not been properly identified |
| B     | Stable, but some values are unrealistic                     |
| C     | Conditionally stable, can be significantly improved         |

The grading system will be applied to each model once a proper system
identification toolbox is created. We are currently planning to release
this toolbox later this year.

For more information regarding contributions, for example to add a new model to
Menagerie, see [CONTRIBUTING](CONTRIBUTING.md).

## Menagerie Models

**Arms.**

| Name | Maker | DoFs    | License | MJX |
|------|-------|---------|---------|-----|
| ARX L5 | ARX Robotics | 7 | [BSD-3-Clause](arx_l5/LICENSE) |âœ–ï¸|
| PiPER | AgileX | 7 | [MIT](agilex_piper/LICENSE) |âœ–ï¸|
| FR3 | Franka Robotics | 7 | [Apache-2.0](franka_fr3/LICENSE) |âœ–ï¸|
| iiwa14 | KUKA | 7 | [BSD-3-Clause](kuka_iiwa_14/LICENSE) |âœ–ï¸|
| Lite6 | UFACTORY | 6 | [BSD-3-Clause](ufactory_lite6/LICENSE) |âœ–ï¸|
| Panda | Franka Robotics | 7 | [BSD-3-Clause](franka_emika_panda/LICENSE) |âœ”ï¸|
| Sawyer | Rethink Robotics | 7 | [Apache-2.0](rethink_robotics_sawyer/LICENSE) |âœ–ï¸|
| Unitree Z1 | Unitree Robotics | 6 | [BSD-3-Clause](unitree_z1/LICENSE) |âœ–ï¸|
| UR5e | Universal Robots | 6 | [BSD-3-Clause](universal_robots_ur5e/LICENSE) |âœ–ï¸|
| UR10e | Universal Robots | 6 | [BSD-3-Clause](universal_robots_ur10e/LICENSE) |âœ–ï¸|
| ViperX 300 | Trossen Robotics | 8 | [BSD-3-Clause](trossen_vx300s/LICENSE) |âœ–ï¸|
| WidowX 250 | Trossen Robotics | 8 | [BSD-3-Clause](trossen_wx250s/LICENSE) |âœ–ï¸|
| xarm7 | UFACTORY | 7 | [BSD-3-Clause](ufactory_xarm7/LICENSE) |âœ–ï¸|
| Gen3 | Kinova Robotics | 7 | [BSD-3-Clause](kinova_gen3/LICENSE) |âœ–ï¸|
| SO-ARM100 | The Robot Studio | 5 | [Apache-2.0](trs_so_arm100/LICENSE) |âœ–ï¸|
| Koch v1.1 Low-Cost Robot | Hugging Face | 5 | [Apache-2.0](low_cost_robot_arm/LICENSE) |âœ–ï¸|
| YAM | I2RT Robotics | 7 | [MIT](i2rt_yam/LICENSE) |âœ–ï¸|

**Bipeds.**

| Name | Maker | DoFs    | License | MJX |
|------|-------|---------|---------|-----|
| Cassie | Agility Robotics | 28 | [BSD-3-Clause](agility_cassie/LICENSE) |âœ–ï¸|

**Dual Arms.**

| Name | Maker | DoFs    | License | MJX |
|------|-------|---------|---------|-----|
| ALOHA 2 | Trossen Robotics, Google DeepMind | 16 | [BSD-3-Clause](aloha/LICENSE) |âœ”ï¸|

**Drones.**

| Name | Maker | DoFs    | License | MJX |
|------|-------|---------|---------|-----|
| Crazyflie 2 | Bitcraze | 0 | [MIT](bitcraze_crazyflie_2/LICENSE) |âœ–ï¸|
| Skydio X2 | Skydio | 0 | [Apache-2.0](skydio_x2/LICENSE) |âœ–ï¸|

**End-effectors.**

| Name | Maker | DoFs    | License | MJX |
|------|-------|---------|---------|-----|
| Allegro Hand V3 | Wonik Robotics | 16 | [BSD-2-Clause](wonik_allegro/LICENSE) |âœ–ï¸|
| UMI Gripper | Stanford University | 1 | [MIT](umi_gripper/LICENSE) |âœ–ï¸|
| LEAP Hand | Carnegie Mellon University | 16 | [MIT](leap_hand/LICENSE) |âœ–ï¸|
| Robotiq 2F-85 | Robotiq | 8 | [BSD-2-Clause](robotiq_2f85/LICENSE) |âœ–ï¸|
| Shadow Hand EM35 | Shadow Robot Company | 24 | [Apache-2.0](shadow_hand/LICENSE) |âœ–ï¸|
| Shadow DEX-EE Hand | Shadow Robot Company | 12 | [Apache-2.0](shadow_dexee/LICENSE) |âœ–ï¸|

**Mobile Manipulators.**

| Name | Maker | DoFs    | License | MJX |
|------|-------|---------|---------|-----|
| Google Robot | Google DeepMind | 9 | [Apache-2.0](google_robot/LICENSE) |âœ–ï¸|
| Stanford TidyBot | Stanford University | 11 | [MIT](stanford_tidybot/LICENSE) |âœ–ï¸|
| Stretch 2 | Hello Robot | 17 | [Clear BSD](hello_robot_stretch/LICENSE) |âœ–ï¸|
| Stretch 3 | Hello Robot | 17 | [Apache-2.0](hello_robot_stretch_3/LICENSE) |âœ–ï¸|
| PAL Tiago | PAL Robotics | 12 | [Apache-2.0](pal_tiago/LICENSE) |âœ–ï¸|
| PAL Tiago Dual | PAL Robotics | 21 | [Apache-2.0](pal_tiago_dual/LICENSE) |âœ–ï¸|

**Mobile Bases.**

| Name | Maker | DoFs    | License | MJX |
|------|-------|---------|---------|-----|
| Omniwheel Soccer Robot | Robot Soccer Kit | 4 | [MIT](robot_soccer_kit/LICENSE) |âœ–ï¸|

**Humanoids.**

| Name | Maker | DoFs    | License | MJX |
|------|-------|---------|---------|-----|
| Adam Lite | PNDbotics | 25 | [MIT](pndbotics_adam_lite/LICENSE) |âœ–ï¸|
| Apptronik Apollo | Apptronik | 32 | [Apache-2.0](apptronik_apollo/LICENSE) |âœ”ï¸|
| Berkeley Humanoid | Hybrid Robotics | 12 | [BSD-3-Clause](berkeley_humanoid/LICENSE) |âœ–ï¸|
| Booster T1 | Booster Robotics | 23 | [Apache-2.0](booster_t1/LICENSE) |âœ–ï¸|
| Fourier N1 | Fourier Robotics | 30 | [Apache-2.0](fourier_n1/LICENSE) |âœ–ï¸|
| Robotis OP3 | Robotis | 20 | [Apache-2.0](robotis_op3/LICENSE) |âœ–ï¸|
| TALOS | PAL Robotics | 32 | [Apache-2.0](pal_talos/LICENSE) |âœ–ï¸|
| Unitree G1 | Unitree Robotics | 37 | [BSD-3-Clause](unitree_g1/LICENSE) |âœ”ï¸|
| Unitree H1 | Unitree Robotics | 19 | [BSD-3-Clause](unitree_h1/LICENSE) |âœ–ï¸|

**Quadrupeds.**

| Name | Maker | DoFs    | License | MJX |
|------|-------|---------|---------|-----|
| ANYmal B | ANYbotics | 12 | [BSD-3-Clause](anybotics_anymal_b/LICENSE) |âœ–ï¸|
| ANYmal C | ANYbotics | 12 | [BSD-3-Clause](anybotics_anymal_c/LICENSE) |âœ”ï¸|
| Spot | Boston Dynamics | 12 | [BSD-3-Clause](boston_dynamics_spot/LICENSE) |âœ–ï¸|
| Unitree A1 | Unitree Robotics | 12 | [BSD-3-Clause](unitree_a1/LICENSE) |âœ–ï¸|
| Unitree Go1 | Unitree Robotics | 12 | [BSD-3-Clause](unitree_go1/LICENSE) |âœ–ï¸|
| Unitree Go2 | Unitree Robotics | 12 | [BSD-3-Clause](unitree_go2/LICENSE) |âœ”ï¸|
| Google Barkour v0 | Google DeepMind | 12 | [Apache-2.0](google_barkour_v0/LICENSE) |âœ”ï¸|
| Google Barkour vB | Google DeepMind | 12 | [Apache-2.0](google_barkour_vb/LICENSE) |âœ”ï¸|

**Biomechanical.**

| Name | Maker | DoFs    | License | MJX |
|------|-------|---------|---------|-----|
| IIT Softfoot | IIT Softbots | 92 | [BSD-3-Clause](iit_softfoot/LICENSE) |âœ–ï¸|
| flybody | Google DeepMind, HHMI Janelia Research Campus | 102 | [Apache-2.0](flybody/LICENSE) |âœ–ï¸|

**Miscellaneous.**

| Name | Maker | DoFs    | License | MJX |
|------|-------|---------|---------|-----|
| D435i | Intel Realsense | 0 | [Apache-2.0](realsense_d435i/LICENSE) |âœ–ï¸|

## Citing Menagerie

If you use Menagerie in your work, please use the following citation:

```bibtex
@software{menagerie2022github,
  author = {Zakka, Kevin and Tassa, Yuval and {MuJoCo Menagerie Contributors}},
  title = {{MuJoCo Menagerie: A collection of high-quality simulation models for MuJoCo}},
  url = {http://github.com/google-deepmind/mujoco_menagerie},
  year = {2022},
}
```

## Acknowledgments

The models in this repository are based on third-party models designed by many talented people, and would not have been possible without their generous open-source contributions. We would like to acknowledge all the designers and engineers who made MuJoCo Menagerie possible.

We&#039;d like to thank Pedro Vergani for his help with visuals and design.

The main effort required to make this repository publicly available was undertaken by [Kevin Zakka](https://kzakka.com/), with help from the Robotics Simulation team at Google DeepMind.

This project has also benefited from contributions by members of the broader community â€” see the [CONTRIBUTORS.md](./CONTRIBUTORS.md) for a full list.

## Changelog

For a summary of key updates across the repository, see the [global CHANGELOG.md](./CHANGELOG.md).

Each individual model also includes its own `CHANGELOG.md` file with model-specific updates, linked directly from the corresponding README.

## License and Disclaimer

XML and asset files in each individual model directory of this repository are
subject to different license terms. Please consult the `LICENSE` files under
each specific model subdirectory for the relevant license and copyright
information.

All other content is Copyright 2022 DeepMind Technologies Limited and licensed
under the Apache License, Version 2.0. A copy of this license is provided in the
top-level LICENSE file in this repository.
You can also obtain it from https://www.apache.org/licenses/LICENSE-2.0.

This is not an officially supported Google product.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[TheAlgorithms/Python]]></title>
            <link>https://github.com/TheAlgorithms/Python</link>
            <guid>https://github.com/TheAlgorithms/Python</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:21 GMT</pubDate>
            <description><![CDATA[All Algorithms implemented in Python]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/TheAlgorithms/Python">TheAlgorithms/Python</a></h1>
            <p>All Algorithms implemented in Python</p>
            <p>Language: Python</p>
            <p>Stars: 212,797</p>
            <p>Forks: 49,201</p>
            <p>Stars today: 164 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;!-- Title: --&gt;
  &lt;a href=&quot;https://github.com/TheAlgorithms/&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/TheAlgorithms/website/1cd824df116b27029f17c2d1b42d81731f28a920/public/logo.svg&quot; height=&quot;100&quot;&gt;
  &lt;/a&gt;
  &lt;h1&gt;&lt;a href=&quot;https://github.com/TheAlgorithms/&quot;&gt;The Algorithms&lt;/a&gt; - Python&lt;/h1&gt;

&lt;!-- Labels: --&gt;
  &lt;!-- First row: --&gt;
  &lt;a href=&quot;https://gitpod.io/#https://github.com/TheAlgorithms/Python&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;Gitpod Ready-to-Code&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/static/v1.svg?label=Contributions&amp;message=Welcome&amp;color=0059b3&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;Contributions Welcome&quot;&gt;
  &lt;/a&gt;
  &lt;img src=&quot;https://img.shields.io/github/repo-size/TheAlgorithms/Python.svg?label=Repo%20size&amp;style=flat-square&quot; height=&quot;20&quot;&gt;
  &lt;a href=&quot;https://the-algorithms.com/discord&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/808045925556682782.svg?logo=discord&amp;colorB=7289DA&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;Discord chat&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://gitter.im/TheAlgorithms/community&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Chat-Gitter-ff69b4.svg?label=Chat&amp;logo=gitter&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;Gitter chat&quot;&gt;
  &lt;/a&gt;

  &lt;!-- Second row: --&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://github.com/TheAlgorithms/Python/actions&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/TheAlgorithms/Python/build.yml?branch=master&amp;label=CI&amp;logo=github&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;GitHub Workflow Status&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/pre-commit/pre-commit&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&amp;logoColor=white&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;pre-commit&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://docs.astral.sh/ruff/formatter/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/static/v1?label=code%20style&amp;message=ruff&amp;color=black&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;code style: black&quot;&gt;
  &lt;/a&gt;

&lt;!-- Short description: --&gt;
  &lt;h3&gt;All algorithms implemented in Python - for education ğŸ“š&lt;/h3&gt;
&lt;/div&gt;

Implementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.

## ğŸš€ Getting Started

ğŸ“‹ Read through our [Contribution Guidelines](CONTRIBUTING.md) before you contribute.

## ğŸŒ Community Channels

We are on [Discord](https://the-algorithms.com/discord) and [Gitter](https://gitter.im/TheAlgorithms/community)! Community channels are a great way for you to ask questions and get help. Please join us!

## ğŸ“œ List of Algorithms

See our [directory](DIRECTORY.md) for easier navigation and a better overview of the project.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[agno-agi/agno]]></title>
            <link>https://github.com/agno-agi/agno</link>
            <guid>https://github.com/agno-agi/agno</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:20 GMT</pubDate>
            <description><![CDATA[Multi-agent framework, runtime and control plane. Built for speed, privacy, and scale.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/agno-agi/agno">agno-agi/agno</a></h1>
            <p>Multi-agent framework, runtime and control plane. Built for speed, privacy, and scale.</p>
            <p>Language: Python</p>
            <p>Stars: 34,975</p>
            <p>Forks: 4,589</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; id=&quot;top&quot;&gt;
  &lt;a href=&quot;https://agno.com&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://agno-public.s3.us-east-1.amazonaws.com/assets/logo-dark.svg&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://agno-public.s3.us-east-1.amazonaws.com/assets/logo-light.svg&quot;&gt;
      &lt;img src=&quot;https://agno-public.s3.us-east-1.amazonaws.com/assets/logo-light.svg&quot; alt=&quot;Agno&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.agno.com&quot;&gt;Documentation&lt;/a&gt;
  &lt;span&gt;&amp;nbsp;&amp;nbsp;â€¢&amp;nbsp;&amp;nbsp;&lt;/span&gt;
  &lt;a href=&quot;https://docs.agno.com/examples/introduction&quot;&gt;Examples&lt;/a&gt;
  &lt;span&gt;&amp;nbsp;&amp;nbsp;â€¢&amp;nbsp;&amp;nbsp;&lt;/span&gt;
  &lt;a href=&quot;https://www.agno.com/?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=agno-github&quot;&gt;Website&lt;/a&gt;
  &lt;br /&gt;
&lt;/div&gt;

## What is Agno?

Agno is a multi-agent framework, runtime and control plane. Built for speed, privacy, and scale.

It provides a rich set of tools for building:

- **Agents** with memory, knowledge, session management, and advanced features like human-in-the-loop, guardrails, dynamic context management and best-in-class MCP support.
- **Multi-Agent Teams** that operate autonomously under a team leader that maintains shared state and context. Perfect for use cases where the scope exceeds beyond a single agent.
- **Step-based Workflows** for controlled, deterministic execution. Steps can be Agents, Teams, or regular python functions that run sequentially, in parallel, in loops, branches, or conditionally.

Agno also provides a ready-to-use FastAPI app (called the AgentOS) for serving your agents, teams and workflows in production. Stateless, horizontally scalable and designed for scale, the AgentOS gives you major head start in building your AI product.

## Getting started

If you&#039;re new to Agno, follow our [quickstart](https://docs.agno.com/introduction/quickstart) to build your first Agent and chat with it using the AgentOS UI.

After that, checkout the [examples gallery](https://docs.agno.com/examples/introduction) and build real-world applications with Agno.

## Documentation, Community &amp; More Examples

- Docs: &lt;a href=&quot;https://docs.agno.com&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs.agno.com&lt;/a&gt;
- Cookbook: &lt;a href=&quot;https://github.com/agno-agi/agno/tree/main/cookbook&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Cookbook&lt;/a&gt;
- Community forum: &lt;a href=&quot;https://community.agno.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;community.agno.com&lt;/a&gt;
- Discord: &lt;a href=&quot;https://discord.gg/4MtYHHrgA8&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;discord&lt;/a&gt;

## Example

Hereâ€™s an example of an Agent that connects to an MCP server, manages conversation state in a database, is served using a FastAPI application that you can chat with using the [AgentOS UI](https://os.agno.com).

```python agno_agent.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.anthropic import Claude
from agno.os import AgentOS
from agno.tools.mcp import MCPTools

# ************* Create Agent *************
agno_agent = Agent(
    name=&quot;Agno Agent&quot;,
    model=Claude(id=&quot;claude-sonnet-4-5&quot;),
    # Add a database to the Agent
    db=SqliteDb(db_file=&quot;agno.db&quot;),
    # Add the Agno MCP server to the Agent
    tools=[MCPTools(transport=&quot;streamable-http&quot;, url=&quot;https://docs.agno.com/mcp&quot;)],
    # Add the previous session history to the context
    add_history_to_context=True,
    markdown=True,
)


# ************* Create AgentOS *************
agent_os = AgentOS(agents=[agno_agent])
# Get the FastAPI app for the AgentOS
app = agent_os.get_app()

# ************* Run AgentOS *************
if __name__ == &quot;__main__&quot;:
    agent_os.serve(app=&quot;agno_agent:app&quot;, reload=True)
```

## AgentOS - Production Runtime for Multi-Agent Systems

Building Agents is easy, running them is hard, and that&#039;s where the AgentOS comes in. AgentOS is a high-performance runtime for serving multi-agent systems in production. Key features include:

1. **Pre-built FastAPI app**: AgentOS ships with a ready-to-use FastAPI app for orchestrating your agents, teams, and workflows. This gives you a major head start in building your AI product.

2. **Integrated Control Plane**: The [AgentOS UI](https://os.agno.com) connects directly to your runtime, letting you test, monitor, and manage your system in real time, giving you unmatched control over your system.

3. **Private by Design**: AgentOS runs entirely in your cloud, ensuring complete data privacy. No data ever leaves your system. This is ideal for security-conscious enterprises.

Here&#039;s what the [AgentOS UI](https://os.agno.com) looks like in action:

https://github.com/user-attachments/assets/feb23db8-15cc-4e88-be7c-01a21a03ebf6

## The Complete Agentic Solution

For companies building agents, Agno provides the complete agentic solution:

- The fastest framework for building agents, multi-agent teams and agentic workflows.
- A ready-to-use FastAPI app that gets you building AI products on day one.
- A control plane for testing, monitoring and managing your system.

Agno brings a novel architecture that no other framework provides, your AgentOS runs securely in your cloud, and the control plane connects directly to it from your browser. You don&#039;t need to send data to any external services or pay retention costs, you get complete privacy and control.

## Designed for Agent Engineering

Agno is an incredibly feature-rich framework, designed for Agent Engineering. Here are some key features:

| **Category** | **Feature** | **Description** |
|---------------|-------------|-----------------|
| **Core Intelligence** | **Model Agnostic** | Works with any model provider so you can use your favorite LLMs. |
|  | **Type Safe** | Enforce structured I/O through `input_schema` and `output_schema` for predictable, composable behavior. |
|  | **Dynamic Context Engineering** | Inject variables, state, and retrieved data on the fly into context. Perfect for dependency-driven agents. |
| **Memory, Knowledge, and Persistence** | **Persistent Storage** | Give your Agents, Teams, and Workflows a database to persist session history, state, and messages. |
|  | **User Memory** | Built-in memory system that allows Agents to recall user-specific context across sessions. |
|  | **Agentic RAG** | Connect to 20+ vector stores (called **Knowledge** in Agno) with hybrid search + reranking out of the box. |
|  | **Culture (Collective Memory)** | Shared knowledge that compounds across agents and time. |
| **Execution &amp; Control** | **Human-in-the-Loop** | Native support for confirmations, manual overrides, and external tool execution. |
|  | **Guardrails** | Built-in safeguards for validation, security, and prompt protection. |
|  | **Agent Lifecycle Hooks** | Pre- and post-hooks to validate or transform inputs and outputs. |
|  | **MCP Integration** | First-class support for the Model Context Protocol (MCP) to connect Agents with external systems. |
|  | **Toolkits** | 100+ built-in toolkits with thousands of tools, ready for use across data, code, web, and enterprise APIs. |
| **Runtime &amp; Evaluation** | **Runtime** | Pre-built FastAPI based runtime with SSE compatible endpoints, ready for production on day 1. |
|  | **Control Plane (UI)** | Integrated interface to visualize, monitor, and debug agent activity in real time. |
|  | **Natively Multimodal** | Agents can process and generate text, images, audio, video, and files. |
|  | **Evals** | Measure your Agents&#039; Accuracy, Performance, and Reliability. |
| **Security &amp; Privacy** | **Private by Design** | Runs entirely in your cloud. The UI connects directly to your AgentOS from your browser, no data is ever sent externally. |
|  | **Data Governance** | Your data lives securely in your Agent database, no external data sharing or vendor lock-in. |
|  | **Access Control** | Role-based access (RBAC) and per-agent permissions to protect sensitive contexts and tools. |

Every part of Agno is built for real-world deployment â€” where developer experience meets production performance.

## Setup Your Coding Agent to Use Agno

For LLMs and AI assistants to understand and navigate Agno&#039;s documentation, we provide an [llms.txt](https://docs.agno.com/llms.txt) or [llms-full.txt](https://docs.agno.com/llms-full.txt) file. This file is built for AI systems to efficiently parse and reference our documentation.

### IDE Integration

When building Agno agents, using Agno documentation as a source in your IDE is a great way to speed up your development. Here&#039;s how to integrate with Cursor:

1. In Cursor, go to the &quot;Cursor Settings&quot; menu.
2. Find the &quot;Indexing &amp; Docs&quot; section.
3. Add `https://docs.agno.com/llms-full.txt` to the list of documentation URLs.
4. Save the changes.

Now, Cursor will have access to the Agno documentation. You can do the same with other IDEs like VSCode, Windsurf etc.

## Performance

If you&#039;re building with Agno, you&#039;re guaranteed best-in-class performance by default. Our obsession with performance is necessary because even simple AI workflows can spawn hundreds of Agents and because many tasks are long-running -- stateless, horizontal scalability is key for success.

At Agno, we optimize performance across 3 dimensions:

1. **Agent performance:** We optimize static operations (instantiation, memory footprint) and runtime operations (tool calls, memory updates, history management).
2. **System performance:** The AgentOS API is async by default and has a minimal memory footprint. The system is stateless and horizontally scalable, with a focus on preventing memory leaks. It handles parallel and batch embedding generation during knowledge ingestion, metrics collection in background tasks, and other system-level optimizations.
3. **Agent reliability and accuracy:** Monitored through evals, which weâ€™ll explore later.

### Agent Performance

Let&#039;s measure the time it takes to instantiate an Agent and the memory footprint of an Agent. Here are the numbers (last measured in Oct 2025, on an Apple M4 MacBook Pro):

- **Agent instantiation:** ~3Î¼s on average
- **Memory footprint:** ~6.6Kib on average

We&#039;ll show below that Agno Agents instantiate **529Ã— faster than Langgraph**, **57Ã— faster than PydanticAI**, and **70Ã— faster than CrewAI**. Agno Agents also use **24Ã— lower memory than Langgraph**, **4Ã— lower than PydanticAI**, and **10Ã— lower than CrewAI**.

&gt; [!NOTE]
&gt; Run time performance is bottlenecked by inference and hard to benchmark accurately, so we focus on minimizing overhead, reducing memory usage, and parallelizing tool calls.

### Instantiation Time

Let&#039;s measure instantiation time for an Agent with 1 tool. We&#039;ll run the evaluation 1000 times to get a baseline measurement. We&#039;ll compare Agno to LangGraph, CrewAI and Pydantic AI.

&gt; [!NOTE]
&gt; The code for this benchmark is available [here](https://github.com/agno-agi/agno/tree/main/cookbook/evals/performance). You should run the evaluation yourself on your own machine, please, do not take these results at face value.

```shell
# Setup virtual environment
./scripts/perf_setup.sh
source .venvs/perfenv/bin/activate

# Agno
python cookbook/evals/performance/instantiate_agent_with_tool.py

# LangGraph
python cookbook/evals/performance/comparison/langgraph_instantiation.py
# CrewAI
python cookbook/evals/performance/comparison/crewai_instantiation.py
# Pydantic AI
python cookbook/evals/performance/comparison/pydantic_ai_instantiation.py
```

LangGraph is on the right, **let&#039;s start it first and give it a head start**. Then CrewAI and Pydantic AI follow, and finally Agno. Agno obviously finishes first, but let&#039;s see by how much.

https://github.com/user-attachments/assets/54b98576-1859-4880-9f2d-15e1a426719d

### Memory Usage

To measure memory usage, we use the `tracemalloc` library. We first calculate a baseline memory usage by running an empty function, then run the Agent 1000x times and calculate the difference. This gives a (reasonably) isolated measurement of the memory usage of the Agent.

We recommend running the evaluation yourself on your own machine, and digging into the code to see how it works. If we&#039;ve made a mistake, please let us know.

### Results

Taking Agno as the baseline, we can see that:

| Metric             | Agno | Langgraph   | PydanticAI | CrewAI     |
| ------------------ | ---- | ----------- | ---------- | ---------- |
| **Time (seconds)** | 1Ã—   | 529Ã— slower | 57Ã— slower | 70Ã— slower |
| **Memory (MiB)**   | 1Ã—   | 24Ã— higher  | 4Ã— higher  | 10Ã— higher |

Exact numbers from the benchmark:

| Metric             | Agno     | Langgraph | PydanticAI | CrewAI   |
| ------------------ | -------- | --------- | ---------- | -------- |
| **Time (seconds)** | 0.000003 | 0.001587  | 0.000170   | 0.000210 |
| **Memory (MiB)**   | 0.006642 | 0.161435  | 0.028712   | 0.065652 |

&gt; [!NOTE]
&gt; Agno agents are designed for performance and while we share benchmarks against other frameworks, we should be mindful that accuracy and reliability are more important than speed.

## Contributions

We welcome contributions, read our [contributing guide](https://github.com/agno-agi/agno/blob/v2.0/CONTRIBUTING.md) to get started.

## Telemetry

Agno logs which model an agent used so we can prioritize updates to the most popular providers. You can disable this by setting `AGNO_TELEMETRY=false` in your environment.

&lt;p align=&quot;left&quot;&gt;
  &lt;a href=&quot;#top&quot;&gt;â¬†ï¸ Back to Top&lt;/a&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[AI-Hypercomputer/maxtext]]></title>
            <link>https://github.com/AI-Hypercomputer/maxtext</link>
            <guid>https://github.com/AI-Hypercomputer/maxtext</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:19 GMT</pubDate>
            <description><![CDATA[A simple, performant and scalable Jax LLM!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/AI-Hypercomputer/maxtext">AI-Hypercomputer/maxtext</a></h1>
            <p>A simple, performant and scalable Jax LLM!</p>
            <p>Language: Python</p>
            <p>Stars: 1,970</p>
            <p>Forks: 420</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>&lt;!--
 # Copyright 2023â€“2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
 --&gt;

# MaxText

[![MaxText Package Tests](https://github.com/AI-Hypercomputer/maxtext/actions/workflows/RunTests.yml/badge.svg)](https://github.com/AI-Hypercomputer/maxtext/actions/workflows/build_and_test_maxtext.yml)

MaxText is a high performance, highly scalable, open-source LLM library and reference implementation written in pure Python/[JAX](https://docs.jax.dev/en/latest/jax-101.html) and targeting Google Cloud TPUs and GPUs for training. 

MaxText provides a library of high performance models to choose from, including Gemma, Llama, DeepSeek, Qwen, and Mistral. For each of these models, MaxText supports pre-training (up to tens of thousands of chips) and scalable post-training, with popular techniques like Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization (GRPO, a type of Reinforcement Learning). 

MaxText achieves high Model FLOPs Utilization (MFU) and tokens/second from single host to very large clusters while staying simple and largely &quot;optimization-free&quot; thanks to the power of JAX and the XLA compiler.

MaxText is the launching point for ambitious LLM projects both in research and production. We encourage you to start by experimenting with MaxText out of the box and then fork and modify MaxText to meet your needs.

Check out our [Read The Docs site](https://maxtext.readthedocs.io/en/latest/) or directly [Get Started](https://maxtext.readthedocs.io/en/latest/tutorials/first_run.html) with your first MaxText run. If youâ€™re interested in Diffusion models (Wan 2.1, Flux, etc), see the [MaxDiffusion](https://github.com/AI-Hypercomputer/maxdiffusion) repository in our AI Hypercomputer GitHub organization. 

## Installation

See our installation guide to [install MaxText with pip](https://maxtext.readthedocs.io/en/latest/guides/install_maxtext.html).

## ğŸ”¥ Latest news ğŸ”¥

* \[September 26, 2025\] Vocabulary tiling ([PR](https://github.com/AI-Hypercomputer/maxtext/pull/2242)) is now supported in MaxText! Adjust config `num_vocab_tiling` to unlock more efficient memory usage.
* \[September 24, 2025\] The GPT-OSS family of models (20B, 120B) is now supported.
* \[September 15, 2025\] MaxText is now available as a [PyPI package](https://pypi.org/project/maxtext). Users can now [install maxtext through pip](https://maxtext.readthedocs.io/en/latest/guides/install_maxtext.html).
* \[September 5, 2025\] MaxText has moved to an `src` layout as part of [RESTRUCTURE.md](RESTRUCTURE.md). For existing environments, please run `pip install -e .` from MaxText root.
* \[August 13, 2025\] The Qwen3 2507 MoE family of models is now supported: MoEs: 235B Thinking &amp; 280B Coder as well as existing dense models: 0.6B, 4B, 8B, 14B, and 32B.  
* \[July 27, 2025\] Updated TFLOPS/s calculation ([PR](https://github.com/AI-Hypercomputer/maxtext/pull/1988)) to account for causal attention, dividing the attention flops in half. Accounted for sliding window and chunked attention reduced attention flops in [PR](https://github.com/AI-Hypercomputer/maxtext/pull/2009) and [PR](https://github.com/AI-Hypercomputer/maxtext/pull/2030). Changes impact large sequence configs, as explained in this [doc](https://github.com/AI-Hypercomputer/maxtext/blob/main/docs/guides/performance_metrics.md)  
* \[July 16, 2025\] We will be restructuring the MaxText repository for improved organization and clarity. Please review the [proposed structure](https://github.com/AI-Hypercomputer/maxtext/blob/main/RESTRUCTURE.md) and provide feedback.  
* \[July 11, 2025\] Multi-Token Prediction (MTP) training support\! Adds an auxiliary loss based on predicting multiple future tokens, inspired by [DeepSeek-V3 paper](https://arxiv.org/html/2412.19437v1), to enhance training efficiency.  
* \[June 25, 2025\] DeepSeek R1-0528 variant is now supported.  
* \[April 24, 2025\] Llama 4 Maverick models are now supported.

## Use cases

MaxText provides a library of models and demonstrates how to perform pre-training or post-training with high performance and scale. 

MaxText leverages [JAX AI libraries](https://docs.jaxstack.ai/en/latest/getting_started.html) and presents a cohesive and comprehensive demonstration of training at scale by using [Flax](https://flax.readthedocs.io/en/latest/) (neural networks), [Tunix](https://github.com/google/tunix) (post-training), [Orbax](https://orbax.readthedocs.io/en/latest/) (checkpointing), [Optax](https://optax.readthedocs.io/en/latest/) (optimization), and [Grain](https://google-grain.readthedocs.io/en/latest/) (dataloading).

In addition to pure text-based LLMs, we also support multi-modal training with Gemma 3 and Llama 4 VLMs.

### Pre-training

If youâ€™re building models from scratch, MaxText can serve as a reference implementation for experimentation, ideation, and inspiration \- just fork and modify MaxText to train your model, whether itâ€™s a small dense model like Llama 8B, or a large MoE like DeepSeek-V3. Experiment with configs and model design to build the most efficient model on TPU or GPU. 

MaxText provides opinionated implementations for how to achieve optimal performance across a wide variety of dimensions like sharding, quantization, and checkpointing. 

### Post-training

If you are post-training a model, whether it is proprietary or open source, MaxText provides a scalable framework using Tunix. For RL (like GRPO), we leverage vLLM for sampling and Pathways (soon) for multi-host. 

Our goal is to provide a variety of models (dimension â€œaâ€) and techniques (dimension â€œbâ€), so you can easily explore (a) \* (b) combinations and efficiently train the perfect model for your use case.

Check out these getting started guides:

* [SFT](https://github.com/AI-Hypercomputer/maxtext/blob/main/end_to_end/tpu/llama3.1/8b/run_sft.sh) (Supervised Fine Tuning)  
* [GRPO](https://maxtext.readthedocs.io/en/latest/tutorials/grpo.html) (Group Relative Policy Optimization)

### Model library

MaxText aims to provide you with the best OSS models, whether as a reference implementation, or to post-train and then serve with vLLM. 

**Supported JAX models in MaxText**

* Google  
  * Gemma 3 (4B, 12B, 27B)  
  * Gemma 2 (2B, 9B, 27B)  
  * Gemma 1 (2B, 7B)  
* Alibaba  
  * Qwen 3 MoE 2507 (235B, 480B)  
  * Qwen 3 MoE (30B, 235B)  
  * Qwen 3 Dense (0.6B, 1.7B, 4B, 8B, 14B, 32B)  
* DeepSeek  
  * DeepSeek-V3 0324 (671B) &amp; DeepSeek-R1 0528 (671B)
  * DeepSeek-V2 (16B, 236B)  
* Meta  
  * Llama 4 Scout (109B) &amp; Maverick (400B)  
  * Llama 3.3 70B, 3.1 (8B, 70B, 405B), 3.0 (8B, 70B, 405B)  
  * Llama 2 (7B, 13B, 70B)  
* Open AI  
  * GPT-OSS (20B, 120B)
  * GPT3 (52K, 6B, 22B, 175B)  
* Mistral  
  * Mixtral (8x7B, 8x22B)  
  * Mistral (7B)  
* Diffusion Models  
  * See [MaxDiffusion](https://github.com/AI-Hypercomputer/maxdiffusion) (LTXV, Wan 2.1, Flux, SDXL, etc)

## Get involved

Please join our [Discord Channel](https://discord.com/invite/2H9PhvTcDU) and if you have feedback, you can file a feature request, documentation request, or bug report [here](https://github.com/AI-Hypercomputer/maxtext/issues/new/choose).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[hanxi/xiaomusic]]></title>
            <link>https://github.com/hanxi/xiaomusic</link>
            <guid>https://github.com/hanxi/xiaomusic</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:18 GMT</pubDate>
            <description><![CDATA[ä½¿ç”¨å°çˆ±éŸ³ç®±æ’­æ”¾éŸ³ä¹ï¼ŒéŸ³ä¹ä½¿ç”¨ yt-dlp ä¸‹è½½ã€‚]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hanxi/xiaomusic">hanxi/xiaomusic</a></h1>
            <p>ä½¿ç”¨å°çˆ±éŸ³ç®±æ’­æ”¾éŸ³ä¹ï¼ŒéŸ³ä¹ä½¿ç”¨ yt-dlp ä¸‹è½½ã€‚</p>
            <p>Language: Python</p>
            <p>Stars: 7,387</p>
            <p>Forks: 752</p>
            <p>Stars today: 402 stars today</p>
            <h2>README</h2><pre># XiaoMusic: æ— é™å¬æ­Œï¼Œè§£æ”¾å°çˆ±éŸ³ç®±

[![GitHub License](https://img.shields.io/github/license/hanxi/xiaomusic)](https://github.com/hanxi/xiaomusic)
[![Docker Image Version](https://img.shields.io/docker/v/hanxi/xiaomusic?sort=semver&amp;label=docker%20image)](https://hub.docker.com/r/hanxi/xiaomusic)
[![Docker Pulls](https://img.shields.io/docker/pulls/hanxi/xiaomusic)](https://hub.docker.com/r/hanxi/xiaomusic)
[![PyPI - Version](https://img.shields.io/pypi/v/xiaomusic)](https://pypi.org/project/xiaomusic/)
[![PyPI - Downloads](https://img.shields.io/pypi/dm/xiaomusic)](https://pypi.org/project/xiaomusic/)
[![Python Version from PEP 621 TOML](https://img.shields.io/python/required-version-toml?tomlFilePath=https%3A%2F%2Fraw.githubusercontent.com%2Fhanxi%2Fxiaomusic%2Fmain%2Fpyproject.toml)](https://pypi.org/project/xiaomusic/)
[![GitHub Release](https://img.shields.io/github/v/release/hanxi/xiaomusic)](https://github.com/hanxi/xiaomusic/releases)
[![Visitors](https://api.visitorbadge.io/api/daily?path=hanxi%2Fxiaomusic&amp;label=daily%20visitor&amp;countColor=%232ccce4&amp;style=flat)](https://visitorbadge.io/status?path=hanxi%2Fxiaomusic)
[![Visitors](https://api.visitorbadge.io/api/visitors?path=hanxi%2Fxiaomusic&amp;label=total%20visitor&amp;countColor=%232ccce4&amp;style=flat)](https://visitorbadge.io/status?path=hanxi%2Fxiaomusic)

ä½¿ç”¨å°çˆ±éŸ³ç®±æ’­æ”¾éŸ³ä¹ï¼ŒéŸ³ä¹ä½¿ç”¨ yt-dlp ä¸‹è½½ã€‚

&lt;https://github.com/hanxi/xiaomusic&gt;

æ–‡æ¡£: &lt;https://xdocs.hanxi.cc/&gt;

&gt; [!TIP]
&gt; åˆæ¬¡å®‰è£…é‡åˆ°é—®é¢˜è¯·æŸ¥é˜… [ğŸ’¬ FAQé—®é¢˜é›†åˆ](https://github.com/hanxi/xiaomusic/issues/99) ï¼Œä¸€èˆ¬é‡åˆ°çš„é—®é¢˜éƒ½å·²ç»æœ‰è§£å†³åŠæ³•ã€‚

## ğŸ‘‹ æœ€ç®€é…ç½®è¿è¡Œ

å·²ç»æ”¯æŒåœ¨ web é¡µé¢é…ç½®å…¶ä»–å‚æ•°ï¼Œdocker å¯åŠ¨å‘½ä»¤å¦‚ä¸‹:

```bash
docker run -p 58090:8090 -e XIAOMUSIC_PUBLIC_PORT=58090 -v /xiaomusic_music:/app/music -v /xiaomusic_conf:/app/conf hanxi/xiaomusic
```

ğŸ”¥ å›½å†…ï¼š

```bash
docker run -p 58090:8090 -e XIAOMUSIC_PUBLIC_PORT=58090 -v /xiaomusic_music:/app/music -v /xiaomusic_conf:/app/conf docker.hanxi.cc/hanxi/xiaomusic
```

å¯¹åº”çš„ docker compose é…ç½®å¦‚ä¸‹ï¼š

```yaml
services:
  xiaomusic:
    image: hanxi/xiaomusic
    container_name: xiaomusic
    restart: unless-stopped
    ports:
      - 58090:8090
    environment:
      XIAOMUSIC_PUBLIC_PORT: 58090
    volumes:
      - /xiaomusic_music:/app/music
      - /xiaomusic_conf:/app/conf
```

ğŸ”¥ å›½å†…ï¼š

```yaml
services:
  xiaomusic:
    image: docker.hanxi.cc/hanxi/xiaomusic
    container_name: xiaomusic
    restart: unless-stopped
    ports:
      - 58090:8090
    environment:
      XIAOMUSIC_PUBLIC_PORT: 58090
    volumes:
      - /xiaomusic_music:/app/music
      - /xiaomusic_conf:/app/conf
```

- å…¶ä¸­ conf ç›®å½•ä¸ºé…ç½®æ–‡ä»¶å­˜æ”¾ç›®å½•ï¼Œmusic ç›®å½•ä¸ºéŸ³ä¹å­˜æ”¾ç›®å½•ï¼Œå»ºè®®åˆ†å¼€é…ç½®ä¸ºä¸åŒçš„ç›®å½•ã€‚
- /xiaomusic_music å’Œ /xiaomusic_conf æ˜¯ docker æ‰€åœ¨çš„ä¸»æœºçš„ç›®å½•ï¼Œå¯ä»¥ä¿®æ”¹ä¸ºå…¶ä»–ç›®å½•ã€‚å¦‚æœæŠ¥é”™æ‰¾ä¸åˆ° /xiaomusic_music ç›®å½•ï¼Œå¯ä»¥å…ˆæ‰§è¡Œ `mkdir -p /xiaomusic_{music,conf}` å‘½ä»¤æ–°å»ºç›®å½•ã€‚
- /app/music å’Œ /app/conf æ˜¯ docker å®¹å™¨é‡Œçš„ç›®å½•ï¼Œä¸è¦å»ä¿®æ”¹ã€‚
- XIAOMUSIC_PUBLIC_PORT æ˜¯ç”¨æ¥é…ç½® NAS æœ¬åœ°ç«¯å£çš„ã€‚8090 æ˜¯å®¹å™¨ç«¯å£ï¼Œä¸è¦å»ä¿®æ”¹ã€‚
- åå°è®¿é—®åœ°å€ä¸ºï¼š http://NAS_IP:58090

&gt; [!NOTE]
&gt; docker å’Œ docker compose äºŒé€‰ä¸€å³å¯ï¼Œå¯åŠ¨æˆåŠŸåï¼Œåœ¨ web é¡µé¢å¯ä»¥é…ç½®å…¶ä»–å‚æ•°ï¼Œå¸¦æœ‰ `*` å·çš„é…ç½®æ˜¯å¿…é¡»è¦é…ç½®çš„ï¼Œå…¶ä»–çš„ç”¨ä¸ä¸Šæ—¶ä¸ç”¨ä¿®æ”¹ã€‚åˆæ¬¡é…ç½®æ—¶éœ€è¦åœ¨é¡µé¢ä¸Šè¾“å…¥å°ç±³è´¦å·å’Œå¯†ç ä¿å­˜åæ‰èƒ½è·å–åˆ°è®¾å¤‡åˆ—è¡¨ã€‚

&gt; [!TIP]
&gt; ç›®å‰å®‰è£…æ­¥éª¤å·²ç»æ˜¯æœ€ç®€åŒ–äº†ï¼Œå¦‚æœè¿˜æ˜¯å«Œå®‰è£…éº»çƒ¦ï¼Œå¯ä»¥å¾®ä¿¡æˆ–è€… QQ çº¦æˆ‘è¿œç¨‹å®‰è£…ï¼Œæˆ‘ä¸€èˆ¬å‘¨æœ«å’Œæ™šä¸Šæ‰æœ‰æ—¶é—´ï¼Œéœ€è¦èµåŠ©ä¸ªè¾›è‹¦è´¹ :moneybag: 50 å…ƒä¸€æ¬¡ã€‚

é‡åˆ°é—®é¢˜å¯ä»¥å» web è®¾ç½®é¡µé¢åº•éƒ¨ç‚¹å‡»ã€ä¸‹è½½æ—¥å¿—æ–‡ä»¶ã€‘æŒ‰é’®ï¼Œç„¶åæœç´¢ä¸€ä¸‹æ—¥å¿—æ–‡ä»¶å†…å®¹ç¡®ä¿é‡Œé¢æ²¡æœ‰è´¦å·å¯†ç ä¿¡æ¯å(æœ‰å°±åˆ é™¤è¿™äº›æ•æ„Ÿä¿¡æ¯)ï¼Œç„¶ååœ¨æ issues åé¦ˆé—®é¢˜æ—¶æŠŠä¸‹è½½çš„æ—¥å¿—æ–‡ä»¶å¸¦ä¸Šã€‚

&gt; [!TIP]
&gt; ä½œè€…çš„å¦ä¸€ä¸ªé€‚ç”¨äº NAS ä¸Šå®‰è£…çš„å¼€æºå·¥å…·ï¼š &lt;https://github.com/hanxi/tiny-nav&gt;

&gt; [!TIP]
&gt;
&gt; å–œæ¬¢å¬ä¹¦çš„å¯ä»¥é…åˆè¿™ä¸ªå·¥å…·ä½¿ç”¨ &lt;https://github.com/hanxi/epub2mp3&gt;

&gt; [!TIP]
&gt;
&gt; - ğŸ”¥ã€å¹¿å‘Š:å¯ç”¨äºå®‰è£… frp å®ç°å†…ç½‘ç©¿é€ã€‘
&gt; - ğŸ”¥ æµ·å¤– RackNerd VPS æœºå™¨æ¨èï¼Œå¯æ”¯ä»˜å®ä»˜æ¬¾ã€‚
&gt; - &lt;a href=&quot;https://my.racknerd.com/aff.php?aff=11177&quot;&gt;&lt;img src=&quot;https://racknerd.com/banners/320x50.gif&quot; alt=&quot;RackNerd Mobile Leaderboard Banner&quot; width=&quot;320&quot; height=&quot;50&quot;&gt;&lt;/a&gt;
&gt; - ä¸çŸ¥é“é€‰å“ªä¸ªå¥—é¤å¯ä»¥ç›´æ¥ä¹°è¿™ä¸ªæœ€ä¾¿å®œçš„ &lt;https://my.racknerd.com/aff.php?aff=11177&amp;pid=912&gt;
&gt; - ä¹Ÿå¯ä»¥ç”¨æ¥éƒ¨ç½²ä»£ç†ï¼Œdocker éƒ¨ç½²æ–¹æ³•è§ &lt;https://github.com/hanxi/blog/issues/96&gt;

&gt; [!TIP]
&gt;
&gt; - ğŸ”¥ã€å¹¿å‘Š: æ­å»ºæ‚¨çš„ä¸“å±å¤§æ¨¡å‹ä¸»é¡µ
å‘Šåˆ«ç¹çé…ç½®éš¾é¢˜ï¼Œä¸€é”®å³å¯ç•…äº«ç¨³å®šæµç•…çš„AIä½“éªŒï¼ã€‘&lt;https://university.aliyun.com/mobile?userCode=szqvatm6&gt;

&gt; [!TIP]
&gt; - å…è´¹ä¸»æœº
&gt; - &lt;a href=&quot;https://dartnode.com?aff=SnappyPigeon570&quot;&gt;&lt;img src=&quot;https://dartnode.com/branding/DN-Open-Source-sm.png&quot; alt=&quot;Powered by DartNode - Free VPS for Open Source&quot; width=&quot;320&quot;&gt;&lt;/a&gt;


### ğŸ¤ æ”¯æŒè¯­éŸ³å£ä»¤

- ã€æ’­æ”¾æ­Œæ›²ã€‘ï¼Œæ’­æ”¾æœ¬åœ°çš„æ­Œæ›²
- ã€æ’­æ”¾æ­Œæ›²+æ­Œåã€‘ï¼Œæ¯”å¦‚ï¼šæ’­æ”¾æ­Œæ›²å‘¨æ°ä¼¦æ™´å¤©
- ã€ä¸Šä¸€é¦–ã€‘
- ã€ä¸‹ä¸€é¦–ã€‘
- ã€å•æ›²å¾ªç¯ã€‘
- ã€å…¨éƒ¨å¾ªç¯ã€‘
- ã€éšæœºæ’­æ”¾ã€‘
- ã€å…³æœºã€‘ï¼Œã€åœæ­¢æ’­æ”¾ã€‘ï¼Œä¸¤ä¸ªæ•ˆæœæ˜¯ä¸€æ ·çš„ã€‚
- ã€åˆ·æ–°åˆ—è¡¨ã€‘ï¼Œå½“å¤åˆ¶äº†æ­Œæ›²è¿› music ç›®å½•åï¼Œå¯ä»¥ç”¨è¿™ä¸ªå£ä»¤åˆ·æ–°æ­Œå•ã€‚
- ã€æ’­æ”¾åˆ—è¡¨+åˆ—è¡¨åã€‘ï¼Œæ¯”å¦‚ï¼šæ’­æ”¾åˆ—è¡¨å…¶ä»–ã€‚
- ã€åŠ å…¥æ”¶è—ã€‘ï¼ŒæŠŠå½“å‰æ’­æ”¾çš„æ­Œæ›²åŠ å…¥æ”¶è—æ­Œå•ã€‚
- ã€å–æ¶ˆæ”¶è—ã€‘ï¼ŒæŠŠå½“å‰æ’­æ”¾çš„æ­Œæ›²ä»æ”¶è—æ­Œå•é‡Œç§»é™¤ã€‚
- ã€æ’­æ”¾åˆ—è¡¨æ”¶è—ã€‘ï¼Œè¿™ä¸ªç”¨äºæ’­æ”¾æ”¶è—æ­Œå•ã€‚
- ~ã€æ’­æ”¾æœ¬åœ°æ­Œæ›²+æ­Œåã€‘ï¼Œè¿™ä¸ªå£ä»¤å’Œæ’­æ”¾æ­Œæ›²çš„åŒºåˆ«æ˜¯æœ¬åœ°æ‰¾ä¸åˆ°ä¹Ÿä¸ä¼šå»ä¸‹è½½ã€‚~
- ã€æ’­æ”¾åˆ—è¡¨ç¬¬å‡ ä¸ª+åˆ—è¡¨åã€‘ï¼Œå…·ä½“è§ï¼š &lt;https://github.com/hanxi/xiaomusic/issues/158&gt;
- ã€æœç´¢æ’­æ”¾+å…³é”®è¯ã€‘ï¼Œä¼šæœç´¢å…³é”®è¯ä½œä¸ºä¸´æ—¶æœç´¢åˆ—è¡¨æ’­æ”¾ï¼Œæ¯”å¦‚è¯´ã€æœç´¢æ’­æ”¾æ—ä¿Šæ°ã€‘ï¼Œä¼šæ’­æ”¾æ‰€æœ‰æ—ä¿Šæ°çš„æ­Œã€‚
- ã€æœ¬åœ°æœç´¢æ’­æ”¾+å…³é”®è¯ã€‘ï¼Œè·Ÿæœç´¢æ’­æ”¾çš„åŒºåˆ«æ˜¯æœ¬åœ°æ‰¾ä¸åˆ°ä¹Ÿä¸ä¼šå»ä¸‹è½½ã€‚

&gt; [!TIP]
&gt; éšè—ç©æ³•: å¯¹å°çˆ±åŒå­¦è¯´æ’­æ”¾æ­Œæ›²å°çŒªä½©å¥‡çš„æ•…äº‹ï¼Œä¼šå…ˆä¸‹è½½å°çŒªä½©å¥‡çš„æ•…äº‹ï¼Œç„¶åå†æ’­æ”¾å°çŒªä½©å¥‡çš„æ•…äº‹ã€‚

## ğŸ› ï¸ pip æ–¹å¼å®‰è£…è¿è¡Œ

```shell
&gt; pip install -U xiaomusic
&gt; xiaomusic --help
 __  __  _                   __  __                 _
 \ \/ / (_)   __ _    ___   |  \/  |  _   _   ___  (_)   ___
  \  /  | |  / _` |  / _ \  | |\/| | | | | | / __| | |  / __|
  /  \  | | | (_| | | (_) | | |  | | | |_| | \__ \ | | | (__
 /_/\_\ |_|  \__,_|  \___/  |_|  |_|  \__,_| |___/ |_|  \___|
          XiaoMusic v0.3.69 by: github.com/hanxi

usage: xiaomusic [-h] [--port PORT] [--hardware HARDWARE] [--account ACCOUNT]
                 [--password PASSWORD] [--cookie COOKIE] [--verbose]
                 [--config CONFIG] [--ffmpeg_location FFMPEG_LOCATION]

options:
  -h, --help            show this help message and exit
  --port PORT           ç›‘å¬ç«¯å£
  --hardware HARDWARE   å°çˆ±éŸ³ç®±å‹å·
  --account ACCOUNT     xiaomi account
  --password PASSWORD   xiaomi password
  --cookie COOKIE       xiaomi cookie
  --verbose             show info
  --config CONFIG       config file path
  --ffmpeg_location FFMPEG_LOCATION
                        ffmpeg bin path
&gt; xiaomusic --config config.json
```

å…¶ä¸­ `config.json` æ–‡ä»¶å¯ä»¥å‚è€ƒ `config-example.json` æ–‡ä»¶é…ç½®ã€‚è§ &lt;https://github.com/hanxi/xiaomusic/issues/94&gt;

ä¸ä¿®æ”¹é»˜è®¤ç«¯å£ 8090 çš„æƒ…å†µä¸‹ï¼Œåªéœ€è¦æ‰§è¡Œ `xiaomusic` å³å¯å¯åŠ¨ã€‚

## ğŸ”© å¼€å‘ç¯å¢ƒè¿è¡Œ

- ä½¿ç”¨ install_dependencies.sh ä¸‹è½½ä¾èµ–
- ä½¿ç”¨ pdm å®‰è£…ç¯å¢ƒ
- é»˜è®¤ç›‘å¬äº†ç«¯å£ 8090 , ä½¿ç”¨å…¶ä»–ç«¯å£è‡ªè¡Œä¿®æ”¹ã€‚

```shell
pdm run xiaomusic.py
````

å¦‚æœæ˜¯å¼€å‘å‰ç«¯ç•Œé¢ï¼Œå¯ä»¥é€šè¿‡ &lt;http://localhost:8090/docs&gt;
æŸ¥çœ‹æœ‰ä»€ä¹ˆæ¥å£ã€‚ç›®å‰çš„ web æ§åˆ¶å°éå¸¸ç®€é™‹ï¼Œæ¬¢è¿æœ‰å…´è¶£çš„æœ‹å‹å¸®å¿™å®ç°ä¸€ä¸ªæ¼‚äº®çš„å‰ç«¯ï¼Œéœ€è¦ä»€ä¹ˆæ¥å£å¯ä»¥éšæ—¶æéœ€æ±‚ã€‚

### ğŸš¦ ä»£ç æäº¤è§„èŒƒ

æäº¤å‰è¯·æ‰§è¡Œ

```
pdm lintfmt
```

ç”¨äºæ£€æŸ¥ä»£ç å’Œæ ¼å¼åŒ–ä»£ç ã€‚

### æœ¬åœ°ç¼–è¯‘ Docker Image

```shell
docker build -t xiaomusic .
```

### æŠ€æœ¯æ ˆ

- åç«¯ä»£ç ä½¿ç”¨ Python è¯­è¨€ç¼–å†™ã€‚
- HTTP æœåŠ¡ä½¿ç”¨çš„æ˜¯ FastAPI æ¡†æ¶ï¼Œ~~æ—©æœŸç‰ˆæœ¬ä½¿ç”¨çš„æ˜¯ Flask~~ã€‚
- ä½¿ç”¨äº† Docker ï¼Œåœ¨ NAS ä¸Šå®‰è£…æ›´æ–¹ä¾¿ã€‚
- é»˜è®¤çš„å‰ç«¯ä¸»é¢˜ä½¿ç”¨äº† jQuery ã€‚

## å·²æµ‹è¯•æ”¯æŒçš„è®¾å¤‡

| å‹å·   | åç§°                                                                                             |
| ---- | ---------------------------------------------------------------------------------------------- |
| L06A | [å°çˆ±éŸ³ç®±](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.l06a)             |
| L07A | [Redmiå°çˆ±éŸ³ç®± Play](https://home.mi.com/webapp/content/baike/product/index.html?model=xiaomi.wifispeaker.l7a)                     |
| S12/S12A/MDZ-25-DA | [å°ç±³AIéŸ³ç®±](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.s12)            |
| LX5A | [å°çˆ±éŸ³ç®± ä¸‡èƒ½é¥æ§ç‰ˆ](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.lx5a)       |
| LX05 | [å°çˆ±éŸ³ç®±Playï¼ˆ2019æ¬¾ï¼‰](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.lx05)  |
| L15A | [å°ç±³AIéŸ³ç®±ï¼ˆç¬¬äºŒä»£ï¼‰](https://home.mi.com/webapp/content/baike/product/index.html?model=xiaomi.wifispeaker.l15a#/) |
| L16A | [Xiaomi Sound](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.l16a)     |
| L17A | [Xiaomi Sound Pro](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.l17a) |
| LX06 | [å°çˆ±éŸ³ç®±Pro](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.lx06)          |
| LX01 | [å°çˆ±éŸ³ç®±mini](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.lx01)         |
| L05B | [å°çˆ±éŸ³ç®±Play](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.l05b)         |
| L05C | [å°ç±³å°çˆ±éŸ³ç®±Play å¢å¼ºç‰ˆ](https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.l05c)   |
| L09A | [å°ç±³éŸ³ç®±Art](https://home.mi.com/webapp/content/baike/product/index.html?model=xiaomi.wifispeaker.l09a) |
| LX04 X10A X08A | å·²ç»æ”¯æŒçš„è§¦å±ç‰ˆ |
| X08C X08E X8F | å·²ç»ä¸éœ€è¦è®¾ç½®äº†. ~éœ€è¦è®¾ç½®ã€å‹å·å…¼å®¹æ¨¡å¼ã€‘é€‰é¡¹ä¸º true~ |
| M01/XMYX01JY | å°ç±³å°çˆ±éŸ³ç®±HD éœ€è¦è®¾ç½®ã€ç‰¹æ®Šå‹å·è·å–å¯¹è¯è®°å½•ã€‘é€‰é¡¹ä¸º true æ‰èƒ½è¯­éŸ³æ’­æ”¾|
| OH2P | XIAOMI æ™ºèƒ½éŸ³ç®± Pro |
| OH2 | XIAOMI æ™ºèƒ½éŸ³ç®± |

å‹å·ä¸äº§å“åç§°å¯¹ç…§å¯ä»¥åœ¨è¿™é‡ŒæŸ¥è¯¢ &lt;https://home.miot-spec.com/s/xiaomi.wifispeaker&gt;

&gt; [!NOTE]
&gt; å¦‚æœä½ çš„è®¾å¤‡æ”¯æŒæ’­æ”¾ï¼Œè¯·åé¦ˆç»™æˆ‘æ·»åŠ åˆ°æ”¯æŒåˆ—è¡¨é‡Œï¼Œè°¢è°¢ã€‚
&gt; ç›®å‰åº”è¯¥æ‰€æœ‰è®¾å¤‡ç±»å‹éƒ½å·²ç»æ”¯æŒæ’­æ”¾ï¼Œæœ‰é—®é¢˜éšæ—¶åé¦ˆã€‚
&gt; å…¶ä»–è§¦å±ç‰ˆä¸èƒ½æ’­æ”¾å¯ä»¥è®¾ç½®ã€å‹å·å…¼å®¹æ¨¡å¼ã€‘é€‰é¡¹ä¸º true è¯•è¯•ã€‚è§ &lt;https://github.com/hanxi/xiaomusic/issues/30&gt;

## ğŸµ æ”¯æŒéŸ³ä¹æ ¼å¼

- mp3
- flac
- wav
- ape
- ogg
- m4a

&gt; [!NOTE]
&gt; æœ¬åœ°éŸ³ä¹ä¼šæœç´¢ç›®å½•ä¸‹ä¸Šé¢æ ¼å¼çš„æ–‡ä»¶ï¼Œä¸‹è½½çš„æ­Œæ›²æ˜¯ mp3 æ ¼å¼çš„ã€‚
&gt; å·²çŸ¥ L05B L05C LX06 L16A ä¸æ”¯æŒ flac æ ¼å¼ã€‚
&gt; å¦‚æœæ ¼å¼ä¸èƒ½æ’­æ”¾å¯ä»¥æ‰“å¼€ã€è½¬æ¢ä¸ºMP3ã€‘å’Œã€å‹å·å…¼å®¹æ¨¡å¼ã€‘é€‰é¡¹ã€‚å…·ä½“è§ &lt;https://github.com/hanxi/xiaomusic/issues/153#issuecomment-2328168689&gt;

## ğŸŒ ç½‘ç»œæ­Œå•åŠŸèƒ½

å¯ä»¥é…ç½®ä¸€ä¸ª json æ ¼å¼çš„æ­Œå•ï¼Œæ”¯æŒç”µå°å’Œæ­Œæ›²ï¼Œä¹Ÿå¯ä»¥ç›´æ¥ç”¨åˆ«äººåˆ†äº«çš„é“¾æ¥ï¼ŒåŒæ—¶é…å¤‡äº† m3u æ–‡ä»¶æ ¼å¼è½¬æ¢å·¥å…·ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿çš„æŠŠ m3u ç”µå°æ–‡ä»¶è½¬æ¢æˆç½‘ç»œæ­Œå•æ ¼å¼çš„ json æ–‡ä»¶ï¼Œå…·ä½“ç”¨æ³•è§  &lt;https://github.com/hanxi/xiaomusic/issues/78&gt;

&gt; [!NOTE]
&gt; æ¬¢è¿æœ‰æƒ³æ³•çš„æœ‹å‹ä»¬åˆ¶ä½œæ›´å¤šçš„æ­Œå•è½¬æ¢å·¥å…·ã€‚

## ğŸº æ›´å¤šå…¶ä»–å¯é€‰é…ç½®

è§ &lt;https://github.com/hanxi/xiaomusic/issues/333&gt;

## âš ï¸ å®‰å…¨æé†’

&gt; [!IMPORTANT]
&gt;
&gt; 1. å¦‚æœé…ç½®äº†å…¬ç½‘è®¿é—® xiaomusic ï¼Œè¯·ä¸€å®šè¦å¼€å¯å¯†ç ç™»é™†ï¼Œå¹¶è®¾ç½®å¤æ‚çš„å¯†ç ã€‚ä¸”ä¸è¦åœ¨å…¬å…±åœºæ‰€çš„ WiFi ç¯å¢ƒä¸‹ä½¿ç”¨ï¼Œå¦åˆ™å¯èƒ½é€ æˆå°ç±³è´¦å·å¯†ç æ³„éœ²ã€‚
&gt; 2. å¼ºçƒˆä¸å»ºè®®å°†å°çˆ±éŸ³ç®±çš„å°ç±³è´¦å·ç»‘å®šæ‘„åƒå¤´ï¼Œä»£ç éš¾å…ä¼šæœ‰ bug ï¼Œä¸€æ—¦å°ç±³è´¦å·å¯†ç æ³„éœ²ï¼Œå¯èƒ½ç›‘æ§å½•åƒä¹Ÿä¼šæ³„éœ²ã€‚

## ğŸ¤” é«˜çº§ç¯‡

- è‡ªå®šä¹‰å£ä»¤åŠŸèƒ½ &lt;https://github.com/hanxi/xiaomusic/issues/105&gt;
- &lt;https://github.com/hanxi/xiaomusic/issues/312&gt;
- &lt;https://github.com/hanxi/xiaomusic/issues/269&gt;
- &lt;https://github.com/hanxi/xiaomusic/issues/159&gt;

## ğŸ“¢ è®¨è®ºåŒº

- [ç‚¹å‡»é“¾æ¥åŠ å…¥QQé¢‘é“ã€xiaomusicã€‘](https://pd.qq.com/s/e2jybz0ss)
- [ç‚¹å‡»é“¾æ¥åŠ å…¥ç¾¤èŠã€xiaomusicå®˜æ–¹äº¤æµç¾¤3ã€‘ 1072151477](https://qm.qq.com/q/lxIhquqbza)
- &lt;https://github.com/hanxi/xiaomusic/issues&gt;
- [å¾®ä¿¡ç¾¤äºŒç»´ç ](https://github.com/hanxi/xiaomusic/issues/86)

## â¤ï¸ æ„Ÿè°¢

- [xiaomi](https://www.mi.com/)
- [PDM](https://pdm.fming.dev/latest/)
- [xiaogpt](https://github.com/yihong0618/xiaogpt)
- [MiService](https://github.com/yihong0618/MiService)
- [å®ç°åŸç†](https://github.com/yihong0618/gitblog/issues/258)
- [yt-dlp](https://github.com/yt-dlp/yt-dlp)
- [awesome-xiaoai](https://github.com/zzz6519003/awesome-xiaoai)
- [å¾®ä¿¡å°ç¨‹åº: å¯å¯éŸ³ä¹](https://github.com/F-loat/xiaoplayer)
- [pure ä¸»é¢˜ xiaomusicUI](https://github.com/52fisher/xiaomusicUI)
- [ç§»åŠ¨ç«¯çš„æ’­æ”¾å™¨ä¸»é¢˜](https://github.com/52fisher/XMusicPlayer)
- [Tailwindä¸»é¢˜](https://github.com/clarencejh/xiaomusic)
- [SoundScapeä¸»é¢˜](https://github.com/jhao0413/SoundScape)
- [ä¸€ä¸ªç¬¬ä¸‰æ–¹çš„ä¸»é¢˜](https://github.com/DarrenWen/xiaomusicui)
- [Umami ç»Ÿè®¡](https://github.com/umami-software/umami)
- [Sentry æŠ¥é”™ç›‘æ§](https://github.com/getsentry/sentry)
- æ‰€æœ‰å¸®å¿™è°ƒè¯•å’Œæµ‹è¯•çš„æœ‹å‹
- æ‰€æœ‰åé¦ˆé—®é¢˜å’Œå»ºè®®çš„æœ‹å‹

### ğŸ‘‰ å…¶ä»–æ•™ç¨‹

æ›´å¤šåŠŸèƒ½è§ [ğŸ“ æ–‡æ¡£æ±‡æ€»](https://github.com/hanxi/xiaomusic/issues/211)

## ğŸš¨ å…è´£å£°æ˜

æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ç›®çš„ï¼Œä¸å¾—ç”¨äºä»»ä½•å•†ä¸šæ´»åŠ¨ã€‚ç”¨æˆ·åœ¨ä½¿ç”¨æœ¬é¡¹ç›®æ—¶åº”éµå®ˆæ‰€åœ¨åœ°åŒºçš„æ³•å¾‹æ³•è§„ï¼Œå¯¹äºè¿æ³•ä½¿ç”¨æ‰€å¯¼è‡´çš„åæœï¼Œæœ¬é¡¹ç›®åŠä½œè€…ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚
æœ¬é¡¹ç›®å¯èƒ½å­˜åœ¨æœªçŸ¥çš„ç¼ºé™·å’Œé£é™©ï¼ˆåŒ…æ‹¬ä½†ä¸é™äºè®¾å¤‡æŸåå’Œè´¦å·å°ç¦ç­‰ï¼‰ï¼Œä½¿ç”¨è€…åº”è‡ªè¡Œæ‰¿æ‹…ä½¿ç”¨æœ¬é¡¹ç›®æ‰€äº§ç”Ÿçš„æ‰€æœ‰é£é™©åŠè´£ä»»ã€‚
ä½œè€…ä¸ä¿è¯æœ¬é¡¹ç›®çš„å‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€åŠæ—¶æ€§ã€å¯é æ€§ï¼Œä¹Ÿä¸æ‰¿æ‹…ä»»ä½•å› ä½¿ç”¨æœ¬é¡¹ç›®è€Œäº§ç”Ÿçš„ä»»ä½•æŸå¤±æˆ–æŸå®³è´£ä»»ã€‚
ä½¿ç”¨æœ¬é¡¹ç›®å³è¡¨ç¤ºæ‚¨å·²é˜…è¯»å¹¶åŒæ„æœ¬å…è´£å£°æ˜çš„å…¨éƒ¨å†…å®¹ã€‚

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=hanxi/xiaomusic&amp;type=Date)](https://star-history.com/#hanxi/xiaomusic&amp;Date)

## èµèµ

- :moneybag: çˆ±å‘ç”µ &lt;https://afdian.com/a/imhanxi&gt;
- ç‚¹ä¸ª Star :star:
- è°¢è°¢ :heart:
- ![å–æ¯å¥¶èŒ¶](https://i.v2ex.co/7Q03axO5l.png)

## License

[MIT](https://github.com/hanxi/xiaomusic/blob/main/LICENSE) License Â© 2024 æ¶µæ›¦
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[QuentinFuxa/WhisperLiveKit]]></title>
            <link>https://github.com/QuentinFuxa/WhisperLiveKit</link>
            <guid>https://github.com/QuentinFuxa/WhisperLiveKit</guid>
            <pubDate>Sun, 09 Nov 2025 00:04:17 GMT</pubDate>
            <description><![CDATA[Simultaneous speech-to-text model]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/QuentinFuxa/WhisperLiveKit">QuentinFuxa/WhisperLiveKit</a></h1>
            <p>Simultaneous speech-to-text model</p>
            <p>Language: Python</p>
            <p>Stars: 8,314</p>
            <p>Forks: 780</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;WhisperLiveKit&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/QuentinFuxa/WhisperLiveKit/refs/heads/main/demo.png&quot; alt=&quot;WhisperLiveKit Demo&quot; width=&quot;730&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;b&gt;Real-time, Fully Local Speech-to-Text with Speaker Identification&lt;/b&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://pypi.org/project/whisperlivekit/&quot;&gt;&lt;img alt=&quot;PyPI Version&quot; src=&quot;https://img.shields.io/pypi/v/whisperlivekit?color=g&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://pepy.tech/project/whisperlivekit&quot;&gt;&lt;img alt=&quot;PyPI Downloads&quot; src=&quot;https://static.pepy.tech/personalized-badge/whisperlivekit?period=total&amp;units=international_system&amp;left_color=grey&amp;right_color=brightgreen&amp;left_text=installations&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://pypi.org/project/whisperlivekit/&quot;&gt;&lt;img alt=&quot;Python Versions&quot; src=&quot;https://img.shields.io/badge/python-3.9--3.15-dark_green&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/QuentinFuxa/WhisperLiveKit/blob/main/LICENSE&quot;&gt;&lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/badge/License-Apache 2.0-dark_green&quot;&gt;&lt;/a&gt;
&lt;/p&gt;


Real-time transcription directly to your browser, with a ready-to-use backend+server and a simple frontend.

#### Powered by Leading Research:

- Simul-[Whisper](https://github.com/backspacetg/simul_whisper)/[Streaming](https://github.com/ufal/SimulStreaming) (SOTA 2025) - Ultra-low latency transcription using [AlignAtt policy](https://arxiv.org/pdf/2305.11408)
- [NLLW](https://github.com/QuentinFuxa/NoLanguageLeftWaiting) (2025), based on [distilled](https://huggingface.co/entai2965/nllb-200-distilled-600M-ctranslate2) [NLLB](https://arxiv.org/abs/2207.04672) (2022, 2024) - Simulatenous translation from &amp; to 200 languages.
- [WhisperStreaming](https://github.com/ufal/whisper_streaming) (SOTA 2023) - Low latency transcription using [LocalAgreement policy](https://www.isca-archive.org/interspeech_2020/liu20s_interspeech.pdf)
- [Streaming Sortformer](https://arxiv.org/abs/2507.18446) (SOTA 2025) - Advanced real-time speaker diarization
- [Diart](https://github.com/juanmc2005/diart) (SOTA 2021) - Real-time speaker diarization
- [Silero VAD](https://github.com/snakers4/silero-vad) (2024) - Enterprise-grade Voice Activity Detection


&gt; **Why not just run a simple Whisper model on every audio batch?** Whisper is designed for complete utterances, not real-time chunks. Processing small segments loses context, cuts off words mid-syllable, and produces poor transcription. WhisperLiveKit uses state-of-the-art simultaneous speech research for intelligent buffering and incremental processing.


### Architecture

&lt;img alt=&quot;Architecture&quot; src=&quot;https://raw.githubusercontent.com/QuentinFuxa/WhisperLiveKit/refs/heads/main/architecture.png&quot; /&gt;

*The backend supports multiple concurrent users. Voice Activity Detection reduces overhead when no voice is detected.*

### Installation &amp; Quick Start

```bash
pip install whisperlivekit
```
&gt; You can also clone the repo and `pip install -e .` for the latest version.

#### Quick Start
1. **Start the transcription server:**
   ```bash
   whisperlivekit-server --model base --language en
   ```

2. **Open your browser** and navigate to `http://localhost:8000`. Start speaking and watch your words appear in real-time!


&gt; - See [tokenizer.py](https://github.com/QuentinFuxa/WhisperLiveKit/blob/main/whisperlivekit/simul_whisper/whisper/tokenizer.py) for the list of all available languages.
&gt; - For HTTPS requirements, see the **Parameters** section for SSL configuration options.

#### Use it to capture audio from web pages.

Go to `chrome-extension` for instructions.

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/QuentinFuxa/WhisperLiveKit/refs/heads/main/chrome-extension/demo-extension.png&quot; alt=&quot;WhisperLiveKit Demo&quot; width=&quot;600&quot;&gt;
&lt;/p&gt;



#### Optional Dependencies

| Optional | `pip install` |
|-----------|-------------|
| **Speaker diarization** | `git+https://github.com/NVIDIA/NeMo.git@main#egg=nemo_toolkit[asr]` |
| **Apple Silicon optimizations** | `mlx-whisper` |
| **Translation** | `nllw` |
| *[Not recommanded]*  Speaker diarization with Diart | `diart` |
| *[Not recommanded]*  Original Whisper backend | `whisper` |
| *[Not recommanded]*  Improved timestamps backend | `whisper-timestamped` |
| OpenAI API backend | `openai` |

See  **Parameters &amp; Configuration** below on how to use them.



### Usage Examples

**Command-line Interface**: Start the transcription server with various options:

```bash
# Large model and translate from french to danish
whisperlivekit-server --model large-v3 --language fr --target-language da

# Diarization and server listening on */80 
whisperlivekit-server --host 0.0.0.0 --port 80 --model medium --diarization --language fr
```


**Python API Integration**: Check [basic_server](https://github.com/QuentinFuxa/WhisperLiveKit/blob/main/whisperlivekit/basic_server.py) for a more complete example of how to use the functions and classes.

```python
from whisperlivekit import TranscriptionEngine, AudioProcessor, parse_args
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from contextlib import asynccontextmanager
import asyncio

transcription_engine = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    global transcription_engine
    transcription_engine = TranscriptionEngine(model=&quot;medium&quot;, diarization=True, lan=&quot;en&quot;)
    yield

app = FastAPI(lifespan=lifespan)

async def handle_websocket_results(websocket: WebSocket, results_generator):
    async for response in results_generator:
        await websocket.send_json(response)
    await websocket.send_json({&quot;type&quot;: &quot;ready_to_stop&quot;})

@app.websocket(&quot;/asr&quot;)
async def websocket_endpoint(websocket: WebSocket):
    global transcription_engine

    # Create a new AudioProcessor for each connection, passing the shared engine
    audio_processor = AudioProcessor(transcription_engine=transcription_engine)    
    results_generator = await audio_processor.create_tasks()
    results_task = asyncio.create_task(handle_websocket_results(websocket, results_generator))
    await websocket.accept()
    while True:
        message = await websocket.receive_bytes()
        await audio_processor.process_audio(message)        
```

**Frontend Implementation**: The package includes an HTML/JavaScript implementation [here](https://github.com/QuentinFuxa/WhisperLiveKit/blob/main/whisperlivekit/web/live_transcription.html). You can also import it using `from whisperlivekit import get_inline_ui_html` &amp; `page = get_inline_ui_html()`


## Parameters &amp; Configuration


| Parameter | Description | Default |
|-----------|-------------|---------|
| `--model` | Whisper model size. List and recommandations [here](https://github.com/QuentinFuxa/WhisperLiveKit/blob/main/docs/available_models.md) | `small` |
| `--model-path` | .pt file/directory containing whisper model. Overrides `--model`. Recommandations [here](https://github.com/QuentinFuxa/WhisperLiveKit/blob/main/docs/models_compatible_formats.md) | `None` |
| `--language` | List [here](https://github.com/QuentinFuxa/WhisperLiveKit/blob/main/whisperlivekit/simul_whisper/whisper/tokenizer.py). If you use `auto`, the model attempts to detect the language automatically, but it tends to bias towards English. | `auto` |
| `--target-language` | If sets, translate to using NLLB. Ex: `fr`. [200 languages available](https://github.com/QuentinFuxa/WhisperLiveKit/blob/main/docs/supported_languages.md). If you want to translate to english, you should rather use `--task translate`, since Whisper can do it directly. | `None` |
| `--task` | Set to `translate` to translate *only* to english, using Whisper translation. | `transcribe` |
| `--diarization` | Enable speaker identification | `False` |
| `--backend` | Processing backend. You can switch to `faster-whisper` if  `simulstreaming` does not work correctly | `simulstreaming` |
| `--no-vac` | Disable Voice Activity Controller | `False` |
| `--no-vad` | Disable Voice Activity Detection | `False` |
| `--warmup-file` | Audio file path for model warmup | `jfk.wav` |
| `--host` | Server host address | `localhost` |
| `--port` | Server port | `8000` |
| `--ssl-certfile` | Path to the SSL certificate file (for HTTPS support) | `None` |
| `--ssl-keyfile` | Path to the SSL private key file (for HTTPS support) | `None` |
| `--forwarded-allow-ips` | Ip or Ips allowed to reverse proxy the whisperlivekit-server. Supported types are  IP Addresses (e.g. 127.0.0.1), IP Networks (e.g. 10.100.0.0/16), or Literals (e.g. /path/to/socket.sock) | `None` |
| `--pcm-input` | raw PCM (s16le) data is expected as input and FFmpeg will be bypassed. Frontend will use AudioWorklet instead of MediaRecorder | `False` |

| Translation options | Description | Default |
|-----------|-------------|---------|
| `--nllb-backend` | `transformers` or `ctranslate2` | `ctranslate2` |
| `--nllb-size` | `600M` or `1.3B` | `600M` |

| Diarization options | Description | Default |
|-----------|-------------|---------|
| `--diarization-backend` |  `diart` or `sortformer` | `sortformer` |
| `--disable-punctuation-split` |  Disable punctuation based splits. See #214 | `False` |
| `--segmentation-model` | Hugging Face model ID for Diart segmentation model. [Available models](https://github.com/juanmc2005/diart/tree/main?tab=readme-ov-file#pre-trained-models) | `pyannote/segmentation-3.0` |
| `--embedding-model` | Hugging Face model ID for Diart embedding model. [Available models](https://github.com/juanmc2005/diart/tree/main?tab=readme-ov-file#pre-trained-models) | `speechbrain/spkrec-ecapa-voxceleb` |

| SimulStreaming backend options | Description | Default |
|-----------|-------------|---------|
| `--disable-fast-encoder` | Disable Faster Whisper or MLX Whisper backends for the encoder (if installed). Inference can be slower but helpful when GPU memory is limited | `False` |
| `--custom-alignment-heads` | Use your own alignment heads, useful when `--model-dir` is used | `None` |
| `--frame-threshold` | AlignAtt frame threshold (lower = faster, higher = more accurate) | `25` |
| `--beams` | Number of beams for beam search (1 = greedy decoding) | `1` |
| `--decoder` | Force decoder type (`beam` or `greedy`) | `auto` |
| `--audio-max-len` | Maximum audio buffer length (seconds) | `30.0` |
| `--audio-min-len` | Minimum audio length to process (seconds) | `0.0` |
| `--cif-ckpt-path` | Path to CIF model for word boundary detection | `None` |
| `--never-fire` | Never truncate incomplete words | `False` |
| `--init-prompt` | Initial prompt for the model | `None` |
| `--static-init-prompt` | Static prompt that doesn&#039;t scroll | `None` |
| `--max-context-tokens` | Maximum context tokens | `None` |
| `--preload-model-count` | Optional. Number of models to preload in memory to speed up loading (set up to the expected number of concurrent users) | `1` |



| WhisperStreaming backend options | Description | Default |
|-----------|-------------|---------|
| `--confidence-validation` | Use confidence scores for faster validation | `False` |
| `--buffer_trimming` | Buffer trimming strategy (`sentence` or `segment`) | `segment` |




&gt; For diarization using Diart, you need to accept user conditions [here](https://huggingface.co/pyannote/segmentation) for the `pyannote/segmentation` model, [here](https://huggingface.co/pyannote/segmentation-3.0) for the `pyannote/segmentation-3.0` model and [here](https://huggingface.co/pyannote/embedding) for the `pyannote/embedding` model. **Then**, login to HuggingFace: `huggingface-cli login`

### ğŸš€ Deployment Guide

To deploy WhisperLiveKit in production:
 
1. **Server Setup**: Install production ASGI server &amp; launch with multiple workers
   ```bash
   pip install uvicorn gunicorn
   gunicorn -k uvicorn.workers.UvicornWorker -w 4 your_app:app
   ```

2. **Frontend**: Host your customized version of the `html` example &amp; ensure WebSocket connection points correctly

3. **Nginx Configuration** (recommended for production):
    ```nginx    
   server {
       listen 80;
       server_name your-domain.com;
        location / {
            proxy_pass http://localhost:8000;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection &quot;upgrade&quot;;
            proxy_set_header Host $host;
    }}
    ```

4. **HTTPS Support**: For secure deployments, use &quot;wss://&quot; instead of &quot;ws://&quot; in WebSocket URL

## ğŸ‹ Docker

Deploy the application easily using Docker with GPU or CPU support.

### Prerequisites
- Docker installed on your system
- For GPU support: NVIDIA Docker runtime installed

### Quick Start

**With GPU acceleration (recommended):**
```bash
docker build -t wlk .
docker run --gpus all -p 8000:8000 --name wlk wlk
```

**CPU only:**
```bash
docker build -f Dockerfile.cpu -t wlk .
docker run -p 8000:8000 --name wlk wlk
```

### Advanced Usage

**Custom configuration:**
```bash
# Example with custom model and language
docker run --gpus all -p 8000:8000 --name wlk wlk --model large-v3 --language fr
```

### Memory Requirements
- **Large models**: Ensure your Docker runtime has sufficient memory allocated


#### Customization

- `--build-arg` Options:
  - `EXTRAS=&quot;whisper-timestamped&quot;` - Add extras to the image&#039;s installation (no spaces). Remember to set necessary container options!
  - `HF_PRECACHE_DIR=&quot;./.cache/&quot;` - Pre-load a model cache for faster first-time start
  - `HF_TKN_FILE=&quot;./token&quot;` - Add your Hugging Face Hub access token to download gated models

## ğŸ”® Use Cases
Capture discussions in real-time for meeting transcription, help hearing-impaired users follow conversations through accessibility tools, transcribe podcasts or videos automatically for content creation, transcribe support calls with speaker identification for customer service...
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>