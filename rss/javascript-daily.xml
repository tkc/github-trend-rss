<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for javascript - JavaScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for javascript.</description>
        <lastBuildDate>Thu, 05 Feb 2026 00:07:44 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[eyaltoledano/claude-task-master]]></title>
            <link>https://github.com/eyaltoledano/claude-task-master</link>
            <guid>https://github.com/eyaltoledano/claude-task-master</guid>
            <pubDate>Thu, 05 Feb 2026 00:07:44 GMT</pubDate>
            <description><![CDATA[An AI-powered task-management system you can drop into Cursor, Lovable, Windsurf, Roo, and others.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/eyaltoledano/claude-task-master">eyaltoledano/claude-task-master</a></h1>
            <p>An AI-powered task-management system you can drop into Cursor, Lovable, Windsurf, Roo, and others.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 25,300</p>
            <p>Forks: 2,415</p>
            <p>Stars today: 42 stars today</p>
            <h2>README</h2><pre>&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

&lt;div align=&#039;center&#039;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/13971&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13971&quot; alt=&quot;eyaltoledano%2Fclaude-task-master | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://task-master.dev&quot;&gt;&lt;img src=&quot;./images/logo.png?raw=true&quot; alt=&quot;Taskmaster logo&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;b&gt;Taskmaster&lt;/b&gt;: A task management system for AI-driven development, designed to work seamlessly with any AI chat.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.gg/taskmasterai&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://dcbadge.limes.pink/api/server/https://discord.gg/taskmasterai?style=flat&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt; |
  &lt;a href=&quot;https://docs.task-master.dev&quot; target=&quot;_blank&quot;&gt;Docs&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/eyaltoledano/claude-task-master/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://github.com/eyaltoledano/claude-task-master/actions/workflows/ci.yml/badge.svg&quot; alt=&quot;CI&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/eyaltoledano/claude-task-master/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/eyaltoledano/claude-task-master?style=social&quot; alt=&quot;GitHub stars&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://badge.fury.io/js/task-master-ai&quot;&gt;&lt;img src=&quot;https://badge.fury.io/js/task-master-ai.svg&quot; alt=&quot;npm version&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-MIT%20with%20Commons%20Clause-blue.svg&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/task-master-ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/d18m/task-master-ai?style=flat&quot; alt=&quot;NPM Downloads&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/task-master-ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dm/task-master-ai?style=flat&quot; alt=&quot;NPM Downloads&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/task-master-ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dw/task-master-ai?style=flat&quot; alt=&quot;NPM Downloads&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

## By [@eyaltoledano](https://x.com/eyaltoledano) &amp; [@RalphEcom](https://x.com/RalphEcom)

[![Twitter Follow](https://img.shields.io/twitter/follow/eyaltoledano)](https://x.com/eyaltoledano)
[![Twitter Follow](https://img.shields.io/twitter/follow/RalphEcom)](https://x.com/RalphEcom)

A task management system for AI-driven development with Claude, designed to work seamlessly with Cursor AI.

## Documentation

üìö **[View Full Documentation](https://docs.task-master.dev)**

For detailed guides, API references, and comprehensive examples, visit our documentation site.

### Quick Reference

The following documentation is also available in the `docs` directory:

- [Configuration Guide](docs/configuration.md) - Set up environment variables and customize Task Master
- [Tutorial](docs/tutorial.md) - Step-by-step guide to getting started with Task Master
- [Command Reference](docs/command-reference.md) - Complete list of all available commands
- [Task Structure](docs/task-structure.md) - Understanding the task format and features
- [Example Interactions](docs/examples.md) - Common Cursor AI interaction examples
- [Migration Guide](docs/migration-guide.md) - Guide to migrating to the new project structure

#### Quick Install for Cursor 1.0+ (One-Click)

[![Add task-master-ai MCP server to Cursor](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=task-master-ai&amp;config=eyJjb21tYW5kIjoibnB4IC15IC0tcGFja2FnZT10YXNrLW1hc3Rlci1haSB0YXNrLW1hc3Rlci1haSIsImVudiI6eyJBTlRIUk9QSUNfQVBJX0tFWSI6IllPVVJfQU5USFJPUElDX0FQSV9LRVlfSEVSRSIsIlBFUlBMRVhJVFlfQVBJX0tFWSI6IllPVVJfUEVSUExFWElUWV9BUElfS0VZX0hFUkUiLCJPUEVOQUlfQVBJX0tFWSI6IllPVVJfT1BFTkFJX0tFWV9IRVJFIiwiR09PR0xFX0FQSV9LRVkiOiJZT1VSX0dPT0dMRV9LRVlfSEVSRSIsIk1JU1RSQUxfQVBJX0tFWSI6IllPVVJfTUlTVFJBTF9LRVlfSEVSRSIsIkdST1FfQVBJX0tFWSI6IllPVVJfR1JPUV9LRVlfSEVSRSIsIk9QRU5ST1VURVJfQVBJX0tFWSI6IllPVVJfT1BFTlJPVVRFUl9LRVlfSEVSRSIsIlhBSV9BUElfS0VZIjoiWU9VUl9YQUlfS0VZX0hFUkUiLCJBWlVSRV9PUEVOQUlfQVBJX0tFWSI6IllPVVJfQVpVUkVfS0VZX0hFUkUiLCJPTExBTUFfQVBJX0tFWSI6IllPVVJfT0xMQU1BX0FQSV9LRVlfSEVSRSJ9fQ%3D%3D)

&gt; **Note:** After clicking the link, you&#039;ll still need to add your API keys to the configuration. The link installs the MCP server with placeholder keys that you&#039;ll need to replace with your actual API keys.

#### Claude Code Quick Install

For Claude Code users:

```bash
claude mcp add taskmaster-ai -- npx -y task-master-ai
```

Don&#039;t forget to add your API keys to the configuration:
- in the root .env of your Project
- in the &quot;env&quot; section of your mcp config for taskmaster-ai


## Requirements

Taskmaster utilizes AI across several commands, and those require a separate API key. You can use a variety of models from different AI providers provided you add your API keys. For example, if you want to use Claude 3.7, you&#039;ll need an Anthropic API key.

You can define 3 types of models to be used: the main model, the research model, and the fallback model (in case either the main or research fail). Whatever model you use, its provider API key must be present in either mcp.json or .env.

At least one (1) of the following is required:

- Anthropic API key (Claude API)
- OpenAI API key
- Google Gemini API key
- Perplexity API key (for research model)
- xAI API Key (for research or main model)
- OpenRouter API Key (for research or main model)
- Claude Code (no API key required - requires Claude Code CLI)
- Codex CLI (OAuth via ChatGPT subscription - requires Codex CLI)

Using the research model is optional but highly recommended. You will need at least ONE API key (unless using Claude Code or Codex CLI with OAuth). Adding all API keys enables you to seamlessly switch between model providers at will.

## Quick Start

### Option 1: MCP (Recommended)

MCP (Model Control Protocol) lets you run Task Master directly from your editor.

#### 1. Add your MCP config at the following path depending on your editor

| Editor       | Scope   | Linux/macOS Path                      | Windows Path                                      | Key          |
| ------------ | ------- | ------------------------------------- | ------------------------------------------------- | ------------ |
| **Cursor**   | Global  | `~/.cursor/mcp.json`                  | `%USERPROFILE%\.cursor\mcp.json`                  | `mcpServers` |
|              | Project | `&lt;project_folder&gt;/.cursor/mcp.json`   | `&lt;project_folder&gt;\.cursor\mcp.json`               | `mcpServers` |
| **Windsurf** | Global  | `~/.codeium/windsurf/mcp_config.json` | `%USERPROFILE%\.codeium\windsurf\mcp_config.json` | `mcpServers` |
| **VS Code**  | Project | `&lt;project_folder&gt;/.vscode/mcp.json`   | `&lt;project_folder&gt;\.vscode\mcp.json`               | `servers`    |
| **Q CLI**    | Global  | `~/.aws/amazonq/mcp.json`             |                                                   | `mcpServers` |

##### Manual Configuration

###### Cursor &amp; Windsurf &amp; Q Developer CLI (`mcpServers`)

```json
{
  &quot;mcpServers&quot;: {
    &quot;task-master-ai&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;task-master-ai&quot;],
      &quot;env&quot;: {
        // &quot;TASK_MASTER_TOOLS&quot;: &quot;all&quot;, // Options: &quot;all&quot;, &quot;standard&quot;, &quot;core&quot;, or comma-separated list of tools
        &quot;ANTHROPIC_API_KEY&quot;: &quot;YOUR_ANTHROPIC_API_KEY_HERE&quot;,
        &quot;PERPLEXITY_API_KEY&quot;: &quot;YOUR_PERPLEXITY_API_KEY_HERE&quot;,
        &quot;OPENAI_API_KEY&quot;: &quot;YOUR_OPENAI_KEY_HERE&quot;,
        &quot;GOOGLE_API_KEY&quot;: &quot;YOUR_GOOGLE_KEY_HERE&quot;,
        &quot;MISTRAL_API_KEY&quot;: &quot;YOUR_MISTRAL_KEY_HERE&quot;,
        &quot;GROQ_API_KEY&quot;: &quot;YOUR_GROQ_KEY_HERE&quot;,
        &quot;OPENROUTER_API_KEY&quot;: &quot;YOUR_OPENROUTER_KEY_HERE&quot;,
        &quot;XAI_API_KEY&quot;: &quot;YOUR_XAI_KEY_HERE&quot;,
        &quot;AZURE_OPENAI_API_KEY&quot;: &quot;YOUR_AZURE_KEY_HERE&quot;,
        &quot;OLLAMA_API_KEY&quot;: &quot;YOUR_OLLAMA_API_KEY_HERE&quot;
      }
    }
  }
}
```

&gt; üîë Replace `YOUR_‚Ä¶_KEY_HERE` with your real API keys. You can remove keys you don&#039;t use.

&gt; **Note**: If you see `0 tools enabled` in the MCP settings, restart your editor and check that your API keys are correctly configured.

###### VS‚ÄØCode (`servers` + `type`)

```json
{
  &quot;servers&quot;: {
    &quot;task-master-ai&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;task-master-ai&quot;],
      &quot;env&quot;: {
        // &quot;TASK_MASTER_TOOLS&quot;: &quot;all&quot;, // Options: &quot;all&quot;, &quot;standard&quot;, &quot;core&quot;, or comma-separated list of tools
        &quot;ANTHROPIC_API_KEY&quot;: &quot;YOUR_ANTHROPIC_API_KEY_HERE&quot;,
        &quot;PERPLEXITY_API_KEY&quot;: &quot;YOUR_PERPLEXITY_API_KEY_HERE&quot;,
        &quot;OPENAI_API_KEY&quot;: &quot;YOUR_OPENAI_KEY_HERE&quot;,
        &quot;GOOGLE_API_KEY&quot;: &quot;YOUR_GOOGLE_KEY_HERE&quot;,
        &quot;MISTRAL_API_KEY&quot;: &quot;YOUR_MISTRAL_KEY_HERE&quot;,
        &quot;GROQ_API_KEY&quot;: &quot;YOUR_GROQ_KEY_HERE&quot;,
        &quot;OPENROUTER_API_KEY&quot;: &quot;YOUR_OPENROUTER_KEY_HERE&quot;,
        &quot;XAI_API_KEY&quot;: &quot;YOUR_XAI_KEY_HERE&quot;,
        &quot;AZURE_OPENAI_API_KEY&quot;: &quot;YOUR_AZURE_KEY_HERE&quot;,
        &quot;OLLAMA_API_KEY&quot;: &quot;YOUR_OLLAMA_API_KEY_HERE&quot;
      },
      &quot;type&quot;: &quot;stdio&quot;
    }
  }
}
```

&gt; üîë Replace `YOUR_‚Ä¶_KEY_HERE` with your real API keys. You can remove keys you don&#039;t use.

#### 2. (Cursor-only) Enable Taskmaster MCP

Open Cursor Settings (Ctrl+Shift+J) ‚û° Click on MCP tab on the left ‚û° Enable task-master-ai with the toggle

#### 3. (Optional) Configure the models you want to use

In your editor&#039;s AI chat pane, say:

```txt
Change the main, research and fallback models to &lt;model_name&gt;, &lt;model_name&gt; and &lt;model_name&gt; respectively.
```

For example, to use Claude Code (no API key required):
```txt
Change the main model to claude-code/sonnet
```

[Table of available models](docs/models.md) | [Claude Code setup](docs/examples/claude-code-usage.md)

#### 4. Initialize Task Master

In your editor&#039;s AI chat pane, say:

```txt
Initialize taskmaster-ai in my project
```

#### 5. Make sure you have a PRD (Recommended)

For **new projects**: Create your PRD at `.taskmaster/docs/prd.txt`.
For **existing projects**: You can use `scripts/prd.txt` or migrate with `task-master migrate`

An example PRD template is available after initialization in `.taskmaster/templates/example_prd.txt`.

&gt; [!NOTE]
&gt; While a PRD is recommended for complex projects, you can always create individual tasks by asking &quot;Can you help me implement [description of what you want to do]?&quot; in chat.

**Always start with a detailed PRD.**

The more detailed your PRD, the better the generated tasks will be.

#### 6. Common Commands

Use your AI assistant to:

- Parse requirements: `Can you parse my PRD at scripts/prd.txt?`
- Plan next step: `What&#039;s the next task I should work on?`
- Implement a task: `Can you help me implement task 3?`
- View multiple tasks: `Can you show me tasks 1, 3, and 5?`
- Expand a task: `Can you help me expand task 4?`
- **Research fresh information**: `Research the latest best practices for implementing JWT authentication with Node.js`
- **Research with context**: `Research React Query v5 migration strategies for our current API implementation in src/api.js`

[More examples on how to use Task Master in chat](docs/examples.md)

### Option 2: Using Command Line

#### Installation

```bash
# Install globally
npm install -g task-master-ai

# OR install locally within your project
npm install task-master-ai
```

#### Initialize a new project

```bash
# If installed globally
task-master init

# If installed locally
npx task-master init

# Initialize project with specific rules
task-master init --rules cursor,windsurf,vscode
```

This will prompt you for project details and set up a new project with the necessary files and structure.

#### Common Commands

```bash
# Initialize a new project
task-master init

# Parse a PRD and generate tasks
task-master parse-prd your-prd.txt

# List all tasks
task-master list

# Show the next task to work on
task-master next

# Show specific task(s) - supports comma-separated IDs
task-master show 1,3,5

# Research fresh information with project context
task-master research &quot;What are the latest best practices for JWT authentication?&quot;

# Move tasks between tags (cross-tag movement)
task-master move --from=5 --from-tag=backlog --to-tag=in-progress
task-master move --from=5,6,7 --from-tag=backlog --to-tag=done --with-dependencies
task-master move --from=5 --from-tag=backlog --to-tag=in-progress --ignore-dependencies

# Add rules after initialization
task-master rules add windsurf,roo,vscode
```

## Tool Loading Configuration

### Optimizing MCP Tool Loading

Task Master&#039;s MCP server supports selective tool loading to reduce context window usage. By default, all 36 tools are loaded (~21,000 tokens) to maintain backward compatibility with existing installations.

You can optimize performance by configuring the `TASK_MASTER_TOOLS` environment variable:

### Available Modes

| Mode | Tools | Context Usage | Use Case |
|------|-------|--------------|----------|
| `all` (default) | 36 | ~21,000 tokens | Complete feature set - all tools available |
| `standard` | 15 | ~10,000 tokens | Common task management operations |
| `core` (or `lean`) | 7 | ~5,000 tokens | Essential daily development workflow |
| `custom` | Variable | Variable | Comma-separated list of specific tools |

### Configuration Methods

#### Method 1: Environment Variable in MCP Configuration

Add `TASK_MASTER_TOOLS` to your MCP configuration file&#039;s `env` section:

```jsonc
{
  &quot;mcpServers&quot;: {  // or &quot;servers&quot; for VS Code
    &quot;task-master-ai&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;task-master-ai&quot;],
      &quot;env&quot;: {
        &quot;TASK_MASTER_TOOLS&quot;: &quot;standard&quot;,  // Options: &quot;all&quot;, &quot;standard&quot;, &quot;core&quot;, &quot;lean&quot;, or comma-separated list
        &quot;ANTHROPIC_API_KEY&quot;: &quot;your-key-here&quot;,
        // ... other API keys
      }
    }
  }
}
```

#### Method 2: Claude Code CLI (One-Time Setup)

For Claude Code users, you can set the mode during installation:

```bash
# Core mode example (~70% token reduction)
claude mcp add task-master-ai --scope user \
  --env TASK_MASTER_TOOLS=&quot;core&quot; \
  -- npx -y task-master-ai@latest

# Custom tools example
claude mcp add task-master-ai --scope user \
  --env TASK_MASTER_TOOLS=&quot;get_tasks,next_task,set_task_status&quot; \
  -- npx -y task-master-ai@latest
```

### Tool Sets Details

**Core Tools (7):** `get_tasks`, `next_task`, `get_task`, `set_task_status`, `update_subtask`, `parse_prd`, `expand_task`

**Standard Tools (15):** All core tools plus `initialize_project`, `analyze_project_complexity`, `expand_all`, `add_subtask`, `remove_task`, `generate`, `add_task`, `complexity_report`

**All Tools (36):** Complete set including project setup, task management, analysis, dependencies, tags, research, and more

### Recommendations

- **New users**: Start with `&quot;standard&quot;` mode for a good balance
- **Large projects**: Use `&quot;core&quot;` mode to minimize token usage
- **Complex workflows**: Use `&quot;all&quot;` mode or custom selection
- **Backward compatibility**: If not specified, defaults to `&quot;all&quot;` mode

## Claude Code Support

Task Master now supports Claude models through the Claude Code CLI, which requires no API key:

- **Models**: `claude-code/opus` and `claude-code/sonnet`
- **Requirements**: Claude Code CLI installed
- **Benefits**: No API key needed, uses your local Claude instance

[Learn more about Claude Code setup](docs/examples/claude-code-usage.md)

## Troubleshooting

### If `task-master init` doesn&#039;t respond

Try running it with Node directly:

```bash
node node_modules/claude-task-master/scripts/init.js
```

Or clone the repository and run:

```bash
git clone https://github.com/eyaltoledano/claude-task-master.git
cd claude-task-master
node scripts/init.js
```

## Join Our Team

&lt;a href=&quot;https://tryhamster.com&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;./images/hamster-hiring.png&quot; alt=&quot;Join Hamster&#039;s founding team&quot; /&gt;
&lt;/a&gt;

## Contributors

&lt;a href=&quot;https://github.com/eyaltoledano/claude-task-master/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=eyaltoledano/claude-task-master&quot; alt=&quot;Task Master project contributors&quot; /&gt;
&lt;/a&gt;

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=eyaltoledano/claude-task-master&amp;type=Timeline)](https://www.star-history.com/#eyaltoledano/claude-task-master&amp;Timeline)

## Licensing

Task Master is licensed under the MIT License with Commons Clause. This means you can:

‚úÖ **Allowed**:

- Use Task Master for any purpose (personal, commercial, academic)
- Modify the code
- Distribute copies
- Create and sell products built using Task Master

‚ùå **Not Allowed**:

- Sell Task Master itself
- Offer Task Master as a hosted service
- Create competing products based on Task Master

See the [LICENSE](LICENSE) file for the complete license text and [licensing details](docs/licensing.md) for more information.
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[jaegertracing/jaeger-ui]]></title>
            <link>https://github.com/jaegertracing/jaeger-ui</link>
            <guid>https://github.com/jaegertracing/jaeger-ui</guid>
            <pubDate>Thu, 05 Feb 2026 00:07:43 GMT</pubDate>
            <description><![CDATA[Web UI for Jaeger]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jaegertracing/jaeger-ui">jaegertracing/jaeger-ui</a></h1>
            <p>Web UI for Jaeger</p>
            <p>Language: JavaScript</p>
            <p>Stars: 1,416</p>
            <p>Forks: 662</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>[![Build Status][ci-img]][ci] [![Coverage Status][cov-img]][cov] [![FOSSA Status][fossa-img]][fossa] [![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/jaegertracing/jaeger-ui/badge)](https://securityscorecards.dev/viewer/?uri=github.com/jaegertracing/jaeger-ui)

# Jaeger UI

Visualize distributed tracing with Jaeger.

|              Trace Search              |             Trace Details              |
| :------------------------------------: | :------------------------------------: |
| ![Trace Search](./media/ss_search.png) | ![Trace Details](./media/ss_trace.png) |

## Contributing

See [CONTRIBUTING](./CONTRIBUTING.md) for development setup, coding standards, and contribution guidelines.

Stuck somewhere or found a bug? See [Getting in Touch](https://www.jaegertracing.io/get-in-touch/) on how to ask for help.

## UI Configuration

See the [configuration guide](https://www.jaegertracing.io/docs/latest/frontend-ui/) for details on configuring Google Analytics tracking, menu customizations, and other aspects of UI behavior.

## License

[Apache 2.0 License](./LICENSE).

[ci-img]: https://github.com/jaegertracing/jaeger-ui/workflows/Unit%20Tests/badge.svg?branch=main
[ci]: https://github.com/jaegertracing/jaeger-ui/actions
[cov-img]: https://codecov.io/gh/jaegertracing/jaeger-ui/branch/main/graph/badge.svg
[cov]: https://codecov.io/gh/jaegertracing/jaeger-ui
[fossa-img]: https://app.fossa.io/api/projects/git%2Bgithub.com%2Fjaegertracing%2Fjaeger-ui.svg?type=shield
[fossa]: https://app.fossa.io/projects/git%2Bgithub.com%2Fjaegertracing%2Fjaeger-ui?ref=badge_shield
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[github/awesome-copilot]]></title>
            <link>https://github.com/github/awesome-copilot</link>
            <guid>https://github.com/github/awesome-copilot</guid>
            <pubDate>Thu, 05 Feb 2026 00:07:42 GMT</pubDate>
            <description><![CDATA[Community-contributed instructions, prompts, and configurations to help you make the most of GitHub Copilot.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/github/awesome-copilot">github/awesome-copilot</a></h1>
            <p>Community-contributed instructions, prompts, and configurations to help you make the most of GitHub Copilot.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 20,144</p>
            <p>Forks: 2,319</p>
            <p>Stars today: 140 stars today</p>
            <h2>README</h2><pre># ü§ñ Awesome GitHub Copilot
[![Powered by Awesome Copilot](https://img.shields.io/badge/Powered_by-Awesome_Copilot-blue?logo=githubcopilot)](https://aka.ms/awesome-github-copilot) [![GitHub contributors from allcontributors.org](https://img.shields.io/github/all-contributors/github/awesome-copilot?color=ee8449)](#contributors-)


A community created collection of custom agents, prompts, and instructions to supercharge your GitHub Copilot experience across different domains, languages, and use cases.

## üöÄ What is Awesome GitHub Copilot?

This repository provides a comprehensive toolkit for enhancing GitHub Copilot with specialized:

- **üëâ [Awesome Agents](docs/README.agents.md)** - Specialized GitHub Copilot agents that integrate with MCP servers to provide enhanced capabilities for specific workflows and tools
- **üëâ [Awesome Prompts](docs/README.prompts.md)** - Focused, task-specific prompts for generating code, documentation, and solving specific problems
- **üëâ [Awesome Instructions](docs/README.instructions.md)** - Comprehensive coding standards and best practices that apply to specific file patterns or entire projects
- **üëâ [Awesome Skills](docs/README.skills.md)** - Self-contained folders with instructions and bundled resources that enhance AI capabilities for specialized tasks
- **üëâ [Awesome Collections](docs/README.collections.md)** - Curated collections of related prompts, instructions, agents, and skills organized around specific themes and workflows
- **üëâ [Awesome Cookbook Recipes](cookbook/README.md)** - Practical, copy-paste-ready code snippets and real-world examples for working with GitHub Copilot tools and features

## üåü Featured Collections

Discover our curated collections of prompts, instructions, and agents organized around specific themes and workflows.

| Name | Description | Items | Tags |
| ---- | ----------- | ----- | ---- |
| [Awesome Copilot](collections/awesome-copilot.md) | Meta prompts that help you discover and generate curated GitHub Copilot agents, collections, instructions, prompts, and skills. | 5 items | github-copilot, discovery, meta, prompt-engineering, agents |
| [Copilot SDK](collections/copilot-sdk.md) | Build applications with the GitHub Copilot SDK across multiple programming languages. Includes comprehensive instructions for C#, Go, Node.js/TypeScript, and Python to help you create AI-powered applications. | 5 items | copilot-sdk, sdk, csharp, go, nodejs, typescript, python, ai, github-copilot |
| [Partners](collections/partners.md) | Custom agents that have been created by GitHub partners | 20 items | devops, security, database, cloud, infrastructure, observability, feature-flags, cicd, migration, performance |


## MCP Server

To make it easy to add these customizations to your editor, we have created a [MCP Server](https://developer.microsoft.com/blog/announcing-awesome-copilot-mcp-server) that provides a prompt for searching and installing prompts, instructions, agents, and skills directly from this repository. You&#039;ll need to have Docker installed and running to run the server.

[![Install in VS Code](https://img.shields.io/badge/VS_Code-Install-0098FF?logo=visualstudiocode&amp;logoColor=white)](https://aka.ms/awesome-copilot/mcp/vscode) [![Install in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install-24bfa5?logo=visualstudiocode&amp;logoColor=white)](https://aka.ms/awesome-copilot/mcp/vscode-insiders) [![Install in Visual Studio](https://img.shields.io/badge/Visual_Studio-Install-C16FDE?logo=visualstudio&amp;logoColor=white)](https://aka.ms/awesome-copilot/mcp/vs)

&lt;details&gt;
&lt;summary&gt;Show MCP Server JSON configuration&lt;/summary&gt;

```json
{
  &quot;servers&quot;: {
    &quot;awesome-copilot&quot;: {
      &quot;type&quot;: &quot;stdio&quot;,
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;-i&quot;,
        &quot;--rm&quot;,
        &quot;ghcr.io/microsoft/mcp-dotnet-samples/awesome-copilot:latest&quot;
      ]
    }
  }
}
```

&lt;/details&gt;

## üìÑ llms.txt

An [`llms.txt`](https://github.github.io/awesome-copilot/llms.txt) file following the [llmstxt.org](https://llmstxt.org/) specification is available on the GitHub Pages site. This machine-readable file makes it easy for Large Language Models to discover and understand all available agents, prompts, instructions, and skills, providing a structured overview of the repository&#039;s resources with names and descriptions.

## üîß How to Use

### ü§ñ Custom Agents

Custom agents can be used in Copilot coding agent (CCA), VS Code, and Copilot CLI (coming soon). For CCA, when assigning an issue to Copilot, select the custom agent from the provided list. In VS Code, you can activate the custom agent in the agents session, alongside built-in agents like Plan and Agent.

### üéØ Prompts

Use the `/` command in GitHub Copilot Chat to access prompts:

```plaintext
/awesome-copilot create-readme
```

### üìã Instructions

Instructions automatically apply to files based on their patterns and provide contextual guidance for coding standards, frameworks, and best practices.

## üéØ Why Use Awesome GitHub Copilot?

- **Productivity**: Pre-built agents, prompts and instructions save time and provide consistent results.
- **Best Practices**: Benefit from community-curated coding standards and patterns.
- **Specialized Assistance**: Access expert-level guidance through specialized custom agents.
- **Continuous Learning**: Stay updated with the latest patterns and practices across technologies.

## ü§ù Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details on how to:

- Add new prompts, instructions, agents, or skills
- Improve existing content
- Report issues or suggest enhancements

For AI coding agents working with this project, refer to [AGENTS.md](AGENTS.md) for detailed technical guidance on development workflows, setup commands, and contribution standards.

### Quick Contribution Guide

1. Follow our file naming conventions and frontmatter requirements
2. Test your contributions thoroughly
3. Update the appropriate README tables
4. Submit a pull request with a clear description

## üìñ Repository Structure

```plaintext
‚îú‚îÄ‚îÄ prompts/          # Task-specific prompts (.prompt.md)
‚îú‚îÄ‚îÄ instructions/     # Coding standards and best practices (.instructions.md)
‚îú‚îÄ‚îÄ agents/           # AI personas and specialized modes (.agent.md)
‚îú‚îÄ‚îÄ collections/      # Curated collections of related items (.collection.yml)
‚îú‚îÄ‚îÄ scripts/          # Utility scripts for maintenance
‚îî‚îÄ‚îÄ skills/           # AI capabilities for specialized tasks
```

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üõ°Ô∏è Security &amp; Support

- **Security Issues**: Please see our [Security Policy](SECURITY.md)
- **Support**: Check our [Support Guide](SUPPORT.md) for getting help
- **Code of Conduct**: We follow the [Contributor Covenant](CODE_OF_CONDUCT.md)

## ‚ÑπÔ∏è Disclaimer

The customizations in this repository are sourced from and created by third-party developers. GitHub does not verify, endorse, or guarantee the functionality or security of these agents. Please carefully inspect any agent and its documentation before installing to understand permissions it may require and actions it may perform.

---

**Ready to supercharge your coding experience?** Start exploring our [prompts](docs/README.prompts.md), [instructions](docs/README.instructions.md), and [custom agents](docs/README.agents.md)!

## Contributors ‚ú®

Thanks goes to these wonderful people ([emoji key](./CONTRIBUTING.md#contributors-recognition)):

&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt;
&lt;!-- prettier-ignore-start --&gt;
&lt;!-- markdownlint-disable --&gt;
&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.aaron-powell.com/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/434140?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Aaron Powell&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Aaron Powell&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#agents-aaronpowell&quot; title=&quot;Specialized agents for GitHub Copilot&quot;&gt;üé≠&lt;/a&gt; &lt;a href=&quot;https://github.com/github/awesome-copilot/commits?author=aaronpowell&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt; &lt;a href=&quot;#collections-aaronpowell&quot; title=&quot;Curated collections of related content&quot;&gt;üéÅ&lt;/a&gt; &lt;a href=&quot;https://github.com/github/awesome-copilot/commits?author=aaronpowell&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt; &lt;a href=&quot;#infra-aaronpowell&quot; title=&quot;Infrastructure (Hosting, Build-Tools, etc)&quot;&gt;üöá&lt;/a&gt; &lt;a href=&quot;#instructions-aaronpowell&quot; title=&quot;Custom instructions for GitHub Copilot&quot;&gt;üß≠&lt;/a&gt; &lt;a href=&quot;#maintenance-aaronpowell&quot; title=&quot;Maintenance&quot;&gt;üöß&lt;/a&gt; &lt;a href=&quot;#prompts-aaronpowell&quot; title=&quot;Reusable prompts for GitHub Copilot&quot;&gt;‚å®Ô∏è&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://codemilltech.com/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/2053639?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Matt Soucoup&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Matt Soucoup&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#infra-codemillmatt&quot; title=&quot;Infrastructure (Hosting, Build-Tools, etc)&quot;&gt;üöá&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.buymeacoffee.com/troystaylor&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/44444967?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Troy Simeon Taylor&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Troy Simeon Taylor&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#agents-troystaylor&quot; title=&quot;Specialized agents for GitHub Copilot&quot;&gt;üé≠&lt;/a&gt; &lt;a href=&quot;#collections-troystaylor&quot; title=&quot;Curated collections of related content&quot;&gt;üéÅ&lt;/a&gt; &lt;a href=&quot;#instructions-troystaylor&quot; title=&quot;Custom instructions for GitHub Copilot&quot;&gt;üß≠&lt;/a&gt; &lt;a href=&quot;#prompts-troystaylor&quot; title=&quot;Reusable prompts for GitHub Copilot&quot;&gt;‚å®Ô∏è&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/abbas133&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/7757139?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Abbas&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Abbas&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#agents-abbas133&quot; title=&quot;Specialized agents for GitHub Copilot&quot;&gt;üé≠&lt;/a&gt; &lt;a href=&quot;#instructions-abbas133&quot; title=&quot;Custom instructions for GitHub Copilot&quot;&gt;üß≠&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://calva.io/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/30010?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Peter Str√∂mberg&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Peter Str√∂mberg&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#agents-PEZ&quot; title=&quot;Specialized agents for GitHub Copilot&quot;&gt;üé≠&lt;/a&gt; &lt;a href=&quot;#collections-PEZ&quot; title=&quot;Curated collections of related content&quot;&gt;üéÅ&lt;/a&gt; &lt;a href=&quot;#instructions-PEZ&quot; title=&quot;Custom instructions for GitHub Copilot&quot;&gt;üß≠&lt;/a&gt; &lt;a href=&quot;#prompts-PEZ&quot; title=&quot;Reusable prompts for GitHub Copilot&quot;&gt;‚å®Ô∏è&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://danielscottraynsford.com/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/7589164?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Daniel Scott-Raynsford&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Daniel Scott-Raynsford&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#agents-PlagueHO&quot; title=&quot;Specialized agents for GitHub Copilot&quot;&gt;üé≠&lt;/a&gt; &lt;a href=&quot;#collections-PlagueHO&quot; title=&quot;Curated collections of related content&quot;&gt;üéÅ&lt;/a&gt; &lt;a href=&quot;#instructions-PlagueHO&quot; title=&quot;Custom instructions for GitHub Copilot&quot;&gt;üß≠&lt;/a&gt; &lt;a href=&quot;#prompts-PlagueHO&quot; title=&quot;Reusable prompts for GitHub Copilot&quot;&gt;‚å®Ô∏è&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/jhauga&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/10998676?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;John Haugabook&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;John Haugabook&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#instructions-jhauga&quot; title=&quot;Custom instructions for GitHub Copilot&quot;&gt;üß≠&lt;/a&gt; &lt;a href=&quot;#prompts-jhauga&quot; title=&quot;Reusable prompts for GitHub Copilot&quot;&gt;‚å®Ô∏è&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://witter.cz/@pavel&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/7853836?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Pavel Simsa&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Pavel Simsa&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/github/awesome-copilot/commits?author=psimsa&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://digitarald.de/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/8599?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Harald Kirschner&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Harald Kirschner&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/github/awesome-copilot/commits?author=digitarald&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt; &lt;a href=&quot;https://github.com/github/awesome-copilot/commits?author=digitarald&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt; &lt;a href=&quot;#maintenance-digitarald&quot; title=&quot;Maintenance&quot;&gt;üöß&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://mubaidr.js.org/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/2222702?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Muhammad Ubaid Raza&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Muhammad Ubaid Raza&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#agents-mubaidr&quot; title=&quot;Specialized agents for GitHub Copilot&quot;&gt;üé≠&lt;/a&gt; &lt;a href=&quot;#instructions-mubaidr&quot; title=&quot;Custom instructions for GitHub Copilot&quot;&gt;üß≠&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/tmeschter&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/10506730?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Tom Meschter&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Tom Meschter&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/github/awesome-copilot/commits?author=tmeschter&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.aungmyokyaw.com/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/9404824?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Aung Myo Kyaw&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Aung Myo Kyaw&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#agents-AungMyoKyaw&quot; title=&quot;Specialized agents for GitHub Copilot&quot;&gt;üé≠&lt;/a&gt; &lt;a href=&quot;#prompts-AungMyoKyaw&quot; title=&quot;Reusable prompts for GitHub Copilot&quot;&gt;‚å®Ô∏è&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/JasonYeMSFT&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/39359541?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;JasonYeMSFT&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;JasonYeMSFT&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/github/awesome-copilot/commits?author=JasonYeMSFT&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.linkedin.com/in/jrc356/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/37387479?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Jon Corbin&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jon Corbin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#agents-Jrc356&quot; title=&quot;Specialized agents for GitHub Copilot&quot;&gt;üé≠&lt;/a&gt; &lt;a href=&quot;#prompts-Jrc356&quot; title=&quot;Reusable prompts for GitHub Copilot&quot;&gt;‚å®Ô∏è&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/troytaylor-msft&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/248058374?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;troytaylor-msft&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;troytaylor-msft&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/github/awesome-copilot/commits?author=troytaylor-msft&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://delatorre.dev/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/38289677?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Emerson Delatorre&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Emerson Delatorre&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#instructions-fazedordecodigo&quot; title=&quot;Custom instructions for GitHub Copilot&quot;&gt;üß≠&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/burkeholland&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/686963?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Burke Holland&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Burke Holland&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#agents-burkeholland&quot; title=&quot;Specialized agents for GitHub Copilot&quot;&gt;üé≠&lt;/a&gt; &lt;a href=&quot;#infra-burkeholland&quot; title=&quot;Infrastructure (Hosting, Build-Tools, etc)&quot;&gt;üöá&lt;/a&gt; &lt;a href=&quot;#instructions-burkeholland&quot; title=&quot;Custom instructions for GitHub Copilot&quot;&gt;üß≠&lt;/a&gt; &lt;a href=&quot;#prompts-burkeholland&quot; title=&quot;Reusable prompts for GitHub Copilot&quot;&gt;‚å®Ô∏è&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://yaooqinn.github.io/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/8326978?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Kent Yao&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Kent Yao&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#instructions-yaooqinn&quot; title=&quot;Custom instructions for GitHub Copilot&quot;&gt;üß≠&lt;/a&gt; &lt;a href=&quot;#prompts-yaooqinn&quot; title=&quot;Reusable prompts for GitHub Copilot&quot;&gt;‚å®Ô∏è&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.devprodlogs.com/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/51440732?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Daniel Meppiel&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Daniel Meppiel&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#prompts-danielmeppiel&quot; title=&quot;Reusable prompts for GitHub Copilot&quot;&gt;‚å®Ô∏è&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/yeelam-gordon&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/73506701?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Gordon Lam&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Gordon Lam&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#instructions-yeelam-gordon&quot; title=&quot;Custom instructions for GitHub Copilot&quot;&gt;üß≠&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.madskristensen.net/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/1258877?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Mads Kristensen&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Mads Kristensen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#instructions-madskristensen&quot; title=&quot;Custom instructions for GitHub Copilot&quot;&gt;üß≠&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://ks6088ts.github.io/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/1254960?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Shinji Takenaka&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Shinji Takenaka&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/github/awesome-copilot/commits?author=ks6088ts&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/spectatora&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/1385755?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;spectatora&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;spectatora&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#agents-spectatora&quot; title=&quot;Specialized agents for GitHub Copilot&quot;&gt;üé≠&lt;/a&gt; &lt;a href=&quot;https://github.com/github/awesome-copilot/commits?author=spectatora&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt; &lt;a href=&quot;#maintenance-spectatora&quot; title=&quot;Maintenance&quot;&gt;üöß&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/sinedied&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/593151?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Yohan Lasorsa&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Yohan Lasorsa&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#instructions-sinedied&quot; title=&quot;Custom instructions for GitHub Copilot&quot;&gt;üß≠&lt;/a&gt; &lt;a href=&quot;#prompts-sinedied&quot; title=&quot;Reusable prompts for GitHub Copilot&quot;&gt;‚å®Ô∏è&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/VamshiVerma&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/21999324?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Vamshi Verma&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Vamshi Verma&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#instructions-VamshiVerma&quot; title=&quot;Custom instructions for GitHub Copilot&quot;&gt;üß≠&lt;/a&gt; &lt;a href=&quot;#prompts-VamshiVerma&quot; title=&quot;Reusable prompts for GitHub Copilot&quot;&gt;‚å®Ô∏è&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://montemagno.com/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/1676321?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;James Montemagno&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;James Montemagno&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#agents-jamesmontemagno&quot; title=&quot;Specialized agents for GitHub Copilot&quot;&gt;üé≠&lt;/a&gt; &lt;a href=&quot;https://github.com/github/awesome-copilot/commits?author=jamesmontemagno&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt; &lt;a href=&quot;#instructions-jamesmontemagno&quot; title=&quot;Custom instructions for GitHub Copilot&quot;&gt;üß≠&lt;/a&gt; &lt;a href=&quot;#prompts-jamesmontemagno&quot; title=&quot;Reusable prompts for GitHub Copilot&quot;&gt;‚å®Ô∏è&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://twitter.com/alefragnani&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/3781424?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Alessandro Fragnani&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Alessandro Fragnani&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/github/awesome-copilot/commits?author=alefragnani&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.linkedin.com/in/ambilykk/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/10282550?v=4?s=100&quot; width=&quot;

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[expressjs/express]]></title>
            <link>https://github.com/expressjs/express</link>
            <guid>https://github.com/expressjs/express</guid>
            <pubDate>Thu, 05 Feb 2026 00:07:41 GMT</pubDate>
            <description><![CDATA[Fast, unopinionated, minimalist web framework for node.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/expressjs/express">expressjs/express</a></h1>
            <p>Fast, unopinionated, minimalist web framework for node.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 68,658</p>
            <p>Forks: 22,390</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[maxandrews/Epstein-doc-explorer]]></title>
            <link>https://github.com/maxandrews/Epstein-doc-explorer</link>
            <guid>https://github.com/maxandrews/Epstein-doc-explorer</guid>
            <pubDate>Thu, 05 Feb 2026 00:07:40 GMT</pubDate>
            <description><![CDATA[a graph explorer of the Epstein emails]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/maxandrews/Epstein-doc-explorer">maxandrews/Epstein-doc-explorer</a></h1>
            <p>a graph explorer of the Epstein emails</p>
            <p>Language: JavaScript</p>
            <p>Stars: 381</p>
            <p>Forks: 75</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre># Epstein Document Network Explorer

&gt; **Note:** Additional documents are currently being processed and added to the network. The analysis pipeline is actively ingesting newly released documents from the House Oversight Committee.

An intelligent document analysis and network visualization system that processes legal documents to extract relationships, entities, and events, then visualizes them as an interactive knowledge graph.

## Project Overview

This project analyzes the Epstein document corpus to extract structured information about actors, actions, locations, and relationships. It uses Claude AI for intelligent extraction and presents findings through an interactive network visualization interface.

**Live Demo:** [Deployed on Render](https://epstein-doc-explorer-1.onrender.com/)

Source documents are available here: https://drive.google.com/drive/folders/1ldncvdqIf6miiskDp_EDuGSDAaI_fJx8
and here: https://huggingface.co/datasets/tensonaut/EPSTEIN_FILES_20K/tree/main
**special thanks to u/tensonaut for extracting the image files with tesseract!**

---

## Architecture Overview

The project has two main phases:

### 1. Analysis Pipeline
**Purpose:** Extract structured data from raw documents using AI
**Technology:** TypeScript, Claude AI (Anthropic), SQLite
**Location:** Root directory + `analysis_pipeline/`

### 2. Visualization Interface
**Purpose:** Interactive exploration of the extracted relationship network
**Technology:** React, TypeScript, Vite, D3.js/Force-Graph
**Location:** `network-ui/`

---

## Key Features

### Analysis Pipeline Features
- **AI-Powered Extraction:** Uses Claude to extract entities, relationships, and events from documents
- **Semantic Tagging:** Automatically tags triples with contextual metadata (legal, financial, travel, etc.)
- **Tag Clustering:** Groups 28,000+ tags into 30 semantic clusters using K-means for better filtering
- **Entity Deduplication:** Merges duplicate entities using LLM-based similarity detection
- **Incremental Processing:** Supports analyzing new documents without reprocessing everything
- **Top-3 Cluster Assignment:** Each relationship is assigned to its 3 most relevant tag clusters

### Visualization Features
- **Interactive Network Graph:** Force-directed graph with edge deduplication for performance
- **Actor-Centric Views:** Click any actor to see their specific relationships
- **Smart Filtering:** Filter by 30 content categories and hop distance from Jeffrey Epstein
- **Density-Based Pruning:** Displays highest-density network connections for clarity
- **Timeline View:** Chronological relationship browser with document links
- **Document Viewer:** Full-text document display with highlighting
- **Responsive Design:** Works on desktop and mobile devices
- **Performance Optimized:** Uses materialized database columns for fast filtering

---

## Project Structure

```
docnetwork/
‚îú‚îÄ‚îÄ analysis_pipeline/          # Document analysis scripts
‚îÇ   ‚îú‚îÄ‚îÄ extract_data.py        # Initial document extraction
‚îÇ   ‚îú‚îÄ‚îÄ analyze_documents.ts   # Main AI analysis pipeline
‚îÇ   ‚îú‚îÄ‚îÄ cluster_tags.ts        # K-means tag clustering
‚îÇ   ‚îú‚îÄ‚îÄ dedupe_with_llm.ts     # Entity deduplication
‚îÇ   ‚îî‚îÄ‚îÄ extracted/             # Raw extracted documents
‚îÇ
‚îú‚îÄ‚îÄ network-ui/                 # React visualization app
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/        # React components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.ts            # Backend API client
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ App.tsx           # Main application
‚îÇ   ‚îî‚îÄ‚îÄ dist/                  # Production build
‚îÇ
‚îú‚îÄ‚îÄ api_server.ts              # Express API server
‚îú‚îÄ‚îÄ document_analysis.db       # SQLite database (91MB)
‚îú‚îÄ‚îÄ tag_clusters.json          # 30 semantic tag clusters
‚îî‚îÄ‚îÄ analysis_pipeline/update_top_clusters.ts # Migration: materialize top clusters
```

---

## Core Components

### Analysis Pipeline

#### 1. Document Extraction (`analysis_pipeline/extract_data.py`)
**Purpose:** Extract raw text from PDF documents
**Input:** PDF files in `data/documents/`
**Output:** JSON files in `analysis_pipeline/extracted/`
**Key Features:**
- Preserves document metadata (ID, category, date)
- Handles various PDF formats
- Stores full text for AI analysis

#### 2. Document Analysis (`analysis_pipeline/analyze_documents.ts`)
**Purpose:** Main AI-powered extraction pipeline
**Input:** Extracted JSON documents
**Output:** SQLite database with entities and relationships
**Key Features:**
- Uses Claude to extract RDF-style triples (subject-action-object)
- Extracts temporal information (dates, timestamps)
- Tags relationships with contextual metadata
- Handles batch processing with rate limiting
- Stores document full text for search

**Database Schema:**
```sql
-- Documents table
CREATE TABLE documents (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  doc_id TEXT UNIQUE NOT NULL,
  file_path TEXT NOT NULL,
  one_sentence_summary TEXT NOT NULL,      -- AI-generated brief summary
  paragraph_summary TEXT NOT NULL,         -- AI-generated detailed summary
  date_range_earliest TEXT,                -- Earliest date mentioned in document
  date_range_latest TEXT,                  -- Latest date mentioned in document
  category TEXT NOT NULL,                  -- Document category
  content_tags TEXT NOT NULL,              -- JSON array of content tags
  analysis_timestamp TEXT NOT NULL,        -- When analysis was performed
  input_tokens INTEGER,                    -- Claude API usage metrics
  output_tokens INTEGER,
  cache_read_tokens INTEGER,
  cost_usd REAL,                          -- Estimated API cost
  error TEXT,                             -- Error message if analysis failed
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  full_text TEXT                          -- Complete document text for search
);
CREATE INDEX idx_documents_doc_id ON documents(doc_id);
CREATE INDEX idx_documents_category ON documents(category);

-- RDF triples (relationships)
CREATE TABLE rdf_triples (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  doc_id TEXT NOT NULL,
  timestamp TEXT,                         -- When the event occurred
  actor TEXT NOT NULL,                    -- Subject of the relationship
  action TEXT NOT NULL,                   -- Action/verb
  target TEXT NOT NULL,                   -- Object of the relationship
  location TEXT,                          -- Where the event occurred
  actor_likely_type TEXT,                 -- Type of actor (person, organization, etc.)
  triple_tags TEXT,                       -- JSON array of tags
  explicit_topic TEXT,                    -- Explicit subject matter
  implicit_topic TEXT,                    -- Inferred subject matter
  sequence_order INTEGER NOT NULL,        -- Order within document
  top_cluster_ids TEXT,                   -- JSON array of top 3 cluster IDs (materialized)
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (doc_id) REFERENCES documents(doc_id) ON DELETE CASCADE
);
CREATE INDEX idx_rdf_triples_doc_id ON rdf_triples(doc_id);
CREATE INDEX idx_rdf_triples_actor ON rdf_triples(actor);
CREATE INDEX idx_rdf_triples_timestamp ON rdf_triples(timestamp);
CREATE INDEX idx_top_cluster_ids ON rdf_triples(top_cluster_ids);

-- Entity aliases (deduplication)
CREATE TABLE entity_aliases (
  original_name TEXT PRIMARY KEY,
  canonical_name TEXT NOT NULL,
  reasoning TEXT,                         -- LLM explanation for the merge
  created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
  created_by TEXT DEFAULT &#039;llm_dedupe&#039;    -- Source of the alias
);
```

#### 3. Tag Clustering (`analysis_pipeline/cluster_tags.ts`)
**Purpose:** Group 28,000+ tags into semantic clusters
**Input:** All unique tags from database
**Output:** `tag_clusters.json` with 30 clusters
**Process:**
1. Collect all unique tags from triples
2. Generate or load cached embeddings using Qwen3-Embedding-0.6B-ONNX
3. Run K-means clustering with K-means++ initialization
4. Generate human-readable cluster names from exemplar tags
5. Save cluster assignments with full tag lists

**Technical Details:**
- **Algorithm:** K-means with cosine distance metric
- **Initialization:** K-means++ for better convergence
- **Convergence:** Typically ~85 iterations
- **Complexity:** O(n¬∑k¬∑i) - much faster than hierarchical methods
- **Output:** 30 clusters ranging from 500-1400 tags each

#### 4. Entity Deduplication (`analysis_pipeline/dedupe_with_llm.ts`)
**Purpose:** Merge duplicate entity mentions
**Input:** Entity names from database
**Output:** `entity_aliases` table mapping variants to canonical names
**Process:**
1. Identify potential duplicates using fuzzy matching
2. Use Claude to determine if entities are the same person
3. Create alias mappings (e.g., &quot;Jeff Epstein&quot; ‚Üí &quot;Jeffrey Epstein&quot;)
4. API server resolves aliases in real-time

#### 5. Migration Scripts
**`analysis_pipeline/update_top_clusters.ts`**
- Adds and populates `top_cluster_ids` column to `rdf_triples`
- Computes top 3 clusters for each triple based on tag matches
- Creates index for fast filtering
- Improves query performance by 10x+

---

### API Server (`api_server.ts`)

**Purpose:** Express.js backend serving data and frontend
**Port:** 3001 (configurable via `PORT` env var)
**Technology:** Express, better-sqlite3, CORS

#### Key Endpoints

**`GET /api/stats`**
- Returns database statistics (document count, triple count, actor count)
- Shows top document categories

**`GET /api/tag-clusters`**
- Returns all 30 tag clusters with metadata
- Includes cluster names, exemplar tags, and tag counts

**`GET /api/relationships?limit=9600&amp;clusters=0,1,2&amp;maxHops=3`**
- Returns relationship network filtered by clusters and hop distance
- Applies density-based pruning (highest-degree nodes prioritized)
- Edge deduplication before limiting (slider value = unique visual edges)
- Returns metadata: `{ relationships, totalBeforeLimit, totalBeforeFilter }`
- Uses materialized `top_cluster_ids` for fast filtering

**`GET /api/actor/:name/relationships?clusters=0,1,2`**
- Returns all relationships for a specific actor
- Handles entity aliases (resolves variants to canonical names)
- Filtered by selected tag clusters
- Returns: `{ relationships, totalBeforeFilter }`

**`GET /api/search?q=query`**
- Searches for actors by name
- Returns fuzzy matches with relationship counts

**`GET /api/document/:docId`**
- Returns document metadata
- Includes category, doc_id, file path

**`GET /api/document/:docId/text`**
- Returns full document text
- Used for document viewer modal

#### Performance Optimizations
- **Materialized Clusters:** Pre-computed top 3 clusters per triple
- **Indexed Columns:** Indexes on `top_cluster_ids`, `actor`, `target`
- **Database Limits:** 100k row limit to prevent memory exhaustion
- **Alias Resolution:** Efficient LEFT JOIN on entity_aliases
- **Rate Limiting:** 1000 requests per 15 minutes per IP

---

### Visualization Interface

#### Frontend Architecture (`network-ui/`)

**Technology Stack:**
- **React 18** with TypeScript
- **Vite** for build tooling
- **TailwindCSS** for styling
- **react-force-graph-2d** for network visualization
- **D3.js** for force simulation

#### Key Components

**`App.tsx`** - Main application container
- Manages global state (relationships, selected actor, filters)
- Loads tag clusters and enables all by default
- Coordinates data fetching and updates
- Handles desktop/mobile layout switching

**`NetworkGraph.tsx`** - Force-directed graph visualization
- Renders nodes (actors) and links (relationships)
- Node size based on connection count
- Click actors to select/deselect
- Zoom and pan controls
- Performance: Handles 15,000+ relationships smoothly

**`Sidebar.tsx`** - Desktop left sidebar
- Displays database statistics
- Actor search with autocomplete
- Relationship limit slider (100-25,000, default 9,600 desktop / 3,000 mobile)
- Hop distance filter (1-10 hops from Jeffrey Epstein, default 3)
- Tag cluster filter buttons
- Document category breakdown

**`RightSidebar.tsx`** - Desktop right sidebar (actor details)
- Shows when actor is selected
- Timeline view of actor&#039;s relationships
- &quot;Showing X of Y relationships&quot; indicator
- Document links with click-to-view

**`MobileBottomNav.tsx`** - Mobile navigation
- Tabbed interface: Search, Timeline, Filters
- Condensed version of desktop sidebars
- Touch-optimized controls

**`DocumentModal.tsx`** - Full-text document viewer
- Displays complete document text
- Highlights actor names in context
- Scrollable with close button
- Fetches text on demand

**`WelcomeModal.tsx`** - First-time visitor welcome
- Introduces users to the explorer
- Stored in localStorage (shown once)
- Dismissible

#### State Management

**Global State (in App.tsx):**
```typescript
const [stats, setStats] = useState&lt;Stats | null&gt;(null);
const [tagClusters, setTagClusters] = useState&lt;TagCluster[]&gt;([]);
const [relationships, setRelationships] = useState&lt;Relationship[]&gt;([]);
const [totalBeforeLimit, setTotalBeforeLimit] = useState&lt;number&gt;(0);
const [selectedActor, setSelectedActor] = useState&lt;string | null&gt;(null);
const [actorRelationships, setActorRelationships] = useState&lt;Relationship[]&gt;([]);
const [actorTotalBeforeFilter, setActorTotalBeforeFilter] = useState&lt;number&gt;(0);
const [limit, setLimit] = useState(isMobile ? 3000 : 9600);
const [maxHops, setMaxHops] = useState&lt;number | null&gt;(3);
const [minDensity, setMinDensity] = useState(50);
const [enabledClusterIds, setEnabledClusterIds] = useState&lt;Set&lt;number&gt;&gt;(new Set());
```

**Data Flow:**
1. Load tag clusters on mount ‚Üí enable all clusters
2. Fetch relationships when limit or clusters change
3. Fetch actor relationships when actor selected or clusters change
4. Update graph when relationships change

#### Responsive Design
- **Desktop (&gt;1024px):** Dual sidebar layout with main graph
- **Mobile (&lt;1024px):** Full-screen graph with bottom navigation
- **Adaptive Limits:** Mobile defaults to 3k relationships, desktop 9.6k

---

## Local Development

```bash
# Install dependencies
npm install
cd network-ui &amp;&amp; npm install &amp;&amp; cd ..

# Run API server
npx tsx api_server.ts

# Run frontend (separate terminal)
cd network-ui &amp;&amp; npm run dev

# Access:
# - API: http://localhost:3001
# - Frontend: http://localhost:5173
```

---

## Key Files Reference

### Analysis Scripts
| File | Purpose | When to Run |
|------|---------|-------------|
| `analysis_pipeline/analyze_documents.ts` | Main AI analysis | After impactful schema changes or adding new docs |
| `analysis_pipeline/cluster_tags.ts` | Create tag clusters with K-means | After major tag changes |
| `analysis_pipeline/dedupe_with_llm.ts` | Deduplicate entities | After analyzing new documents |
| `analysis_pipeline/update_top_clusters.ts` | Materialize cluster IDs | After running cluster_tags.ts |

---

## License

MIT License - See LICENSE file for details

## Contact

For questions or issues, please open a GitHub issue.

**Repository:** https://github.com/maxandrews/Epstein-doc-explorer
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[qeeqbox/social-analyzer]]></title>
            <link>https://github.com/qeeqbox/social-analyzer</link>
            <guid>https://github.com/qeeqbox/social-analyzer</guid>
            <pubDate>Thu, 05 Feb 2026 00:07:39 GMT</pubDate>
            <description><![CDATA[API, CLI, and Web App for analyzing and finding a person's profile in 1000 social media \ websites]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/qeeqbox/social-analyzer">qeeqbox/social-analyzer</a></h1>
            <p>API, CLI, and Web App for analyzing and finding a person's profile in 1000 social media \ websites</p>
            <p>Language: JavaScript</p>
            <p>Stars: 20,763</p>
            <p>Forks: 1,936</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/qeeqbox/social-analyzer/main/readme/socialanalyzerlogo_.png&quot;&gt;&lt;/p&gt;

Social Analyzer - API, CLI, and Web App for analyzing &amp; finding a person&#039;s profile across +1000 social media \ websites. It includes different analysis and detection modules, and you can choose which modules to use during the investigation process.

The detection modules utilize a rating mechanism based on different detection techniques, which produces a rate value that starts from 0 to 100 (No-Maybe-Yes). This module is intended to have fewer false positives.

The analysis and public extracted information from this OSINT tool could help investigate profiles related to suspicious or malicious activities such as cyberbullying, cyber grooming, cyberstalking, and spreading misinformation.

`This project is currently used by some law enforcement agencies in countries where resources are limited - The detection database is different than the one shared here..`

## So¬∑cial Me¬∑di¬∑a
Websites and applications that enable users to create and share content or to participate in social networking - Oxford Dictionary

## Structure
&lt;img src=&quot;https://raw.githubusercontent.com/qeeqbox/social-analyzer/main/readme/structure.png&quot;&gt;


## APP (Preferred!)
Standard localhost WEB APP url: http://0.0.0.0:9005/app.html

&lt;img src=&quot;https://raw.githubusercontent.com/qeeqbox/social-analyzer/main/readme/intro_fast.gif&quot; style=&quot;max-width:768px&quot;/&gt;

## CLI 
&lt;img src=&quot;https://raw.githubusercontent.com/qeeqbox/social-analyzer/main/readme/cli.gif&quot; style=&quot;max-width:768px&quot;/&gt;

## Features
- String &amp; name analysis (Permutations and Combinations)
- Find a profile using multiple techniques (HTTPS library &amp; Webdriver)
- Multi profile search (Used for correlation - any combination separated with &quot;,&quot; )
- Multilayers detections (OCR, normal, advanced &amp; special)
- Visualized profile information using Ixora (Metadata &amp; Patterns)
- Metadata &amp; Patterns extraction (Added from Qeeqbox OSINT project)
- Force-directed Graph for Metadata (Needs ExtractPatterns)
- Search by top ranking or by country (Alexa Ranking)
- Search by type (adult, music, etc.. - automated websites stats)
- Profiles stats and static info (Category country)
- Cross Metadata stats (Added from Qeeqbox OSINT project)
- Auto-flirtation to unnecessary output (Enable javascript etc..)
- Search engine lookup (Google API - optional)
- Custom search queries (Google API &amp; DuckDuckGo API - optional)
- Profile screenshot, title, info, and website description
- Find name origins, name similarity &amp; common words by language
- Find possible profile\person age (Limited analysis)
- Custom user-agent, proxy, timeout &amp; implicit wait
- Python CLI &amp; NodeJS CLI (limited to FindUserProfilesFast option)
- Screenshots of detected profile (The latest version of Chrome must be installed)
- Grid option for faster checking (limited to docker-compose)
- Dump logs to folder or terminal (prettified)
- Adjust finding\getting profile workers (default 15)
- Re-checking option for failed profiles
- Filter profiles by good, maybe, and bad
- Save the analysis as a JSON file
- Simplified web interface and CLI
- And, more!!

## Special Detections
- Facebook (Phone number, name, or profile name)
- Gmail (example@gmail.com)
- Google (example@example.com)

## Install &amp; Run
### Linux (As Node WebApp)
```bash
sudo apt-get update
#Depedning on your Linux distro, you may or may not need these 2 lines
sudo DEBIAN_FRONTEND=noninteractive apt-get install -y software-properties-common
sudo add-apt-repository ppa:mozillateam/ppa -y
sudo apt-get install -y firefox-esr tesseract-ocr git nodejs npm
git clone https://github.com/qeeqbox/social-analyzer.git
cd social-analyzer
npm update
npm install
npm start
```

### Linux (As Node CLI)
```bash
sudo apt-get update
#Depedning on your Linux distro, you may or may not need these 2 lines
sudo DEBIAN_FRONTEND=noninteractive apt-get install -y software-properties-common
sudo add-apt-repository ppa:mozillateam/ppa -y
sudo apt-get install -y firefox-esr tesseract-ocr git nodejs npm
git clone https://github.com/qeeqbox/social-analyzer.git
cd social-analyzer
npm install
nodejs app.js --username &quot;johndoe&quot;
#or
nodejs app.js --username &quot;johndoe,janedoe&quot; --metadata
#or
nodejs app.js --username &quot;johndoe,janedoe&quot; --metadata --top 100
#or
nodejs app.js --username &quot;johndoe&quot; --type &quot;adult&quot;
```

### Linux (As python package)
```bash
sudo apt-get update
sudo apt-get install python3 python3-pip
pip3 install social-analyzer
python3 -m social-analyzer --username &quot;johndoe&quot;
#or
python3 -m social-analyzer --username &quot;johndoe&quot; --metadata
#or
python3 -m social-analyzer --username &quot;johndoe&quot; --metadata --top 100
#or
python3 -m social-analyzer --username &quot;johndoe&quot; --type &quot;adult&quot;
#or
python3 -m social-analyzer --username &quot;johndoe&quot; --websites &quot;car&quot; --logs --screenshots
```

### Linux (As python script)
```bash
sudo apt-get update
sudo apt-get install git python3 python3-pip
git clone https://github.com/qeeqbox/social-analyzer
cd social-analyzer
pip3 install -r requirements.txt
python3 app.py --username &quot;janedoe&quot;
#or
python3 app.py --username &quot;johndoe&quot; --metadata
#or
python3 app.py --username &quot;johndoe&quot; --metadata --top 100
#or
python3 app.py --username &quot;johndoe&quot; --type &quot;adult&quot;
#or
python3 app.py --username &quot;johndoe&quot; --websites &quot;car&quot; --logs --screenshots
```

### Importing as object (python)
```python

#E.g. #1
from importlib import import_module
SocialAnalyzer = import_module(&quot;social-analyzer&quot;).SocialAnalyzer()
results = SocialAnalyzer.run_as_object(username=&quot;johndoe&quot;,silent=True)
print(results)

#E.g. #2
from importlib import import_module
SocialAnalyzer = import_module(&quot;social-analyzer&quot;).SocialAnalyzer()
results = SocialAnalyzer.run_as_object(username=&quot;johndoe,janedoe&quot;,silent=True,output=&quot;json&quot;,filter=&quot;good&quot;,metadata=False,timeout=10, profiles=&quot;detected&quot;)
print(results)
```

### Linux, Windows, MacOS, Raspberry pi..
- check this [wiki](https://github.com/qeeqbox/social-analyzer/wiki/install) for all possible installation methods
- check this [wiki](https://github.com/qeeqbox/social-analyzer/wiki/integration) for integrating social-analyzer with your OSINT tools, feeds, etc...

## social-analyzer --h
```
Required Arguments:
  --username   E.g. johndoe, john_doe or johndoe9999

Optional Arguments:
  --websites    A website or websites separated by space E.g. youtube, tiktokor tumblr
  --mode        Analysis mode E.g.fast -&gt; FindUserProfilesFast, slow -&gt; FindUserProfilesSlow or special -&gt; FindUserProfilesSpecial
  --output      Show the output in the following format: json -&gt; json outputfor integration or pretty -&gt; prettify the output
  --options     Show the following when a profile is found: link, rate, titleor text
  --method      find -&gt; show detected profiles, get -&gt; show all profiles regardless detected or not, all -&gt; combine find &amp; get
  --filter      Filter detected profiles by good, maybe or bad, you can do combine them with comma (good,bad) or use all
  --profiles    Filter profiles by detected, unknown or failed, you can do combine them with comma (detected,failed) or use all
  --countries   select websites by country or countries separated by space as: us br ru
  --type        Select websites by type (Adult, Music etc)
  --top         select top websites as 10, 50 etc...[--websites is not needed]
  --extract     Extract profiles, urls &amp; patterns if possible
  --metadata    Extract metadata if possible (pypi QeeqBox OSINT)
  --trim        Trim long strings
  --gui         Reserved for a gui (Not implemented)
  --cli         Reserved for a cli (Not needed)

Listing websites &amp; detections:
  --list        List all available websites

Setting:
  --headers     Headers as dict
  --logs_dir    Change logs directory
  --timeout     Change timeout between each request
  --silent      Disable output to screen
```

## Open Shell
[![Open in Cloud Shell](https://img.shields.io/static/v1?label=%3E_&amp;message=Open%20in%20Cloud%20Shell&amp;color=3267d6&amp;style=flat-square)](https://ssh.cloud.google.com/cloudshell/editor?cloudshell_git_repo=https://github.com/qeeqbox/social-analyzer&amp;tutorial=README.md) [![Open in repl.it Shell](https://img.shields.io/static/v1?label=%3E_&amp;message=Open%20in%20repl.it%20Shell&amp;color=606c74&amp;style=flat-square)](https://repl.it/github/qeeqbox/social-analyzer)

## Resources
- DuckDuckGo API, Google API, NodeJS, bootstrap, selectize, jQuery, Wikipedia, font-awesome, selenium-webdriver &amp; tesseract.js
- Let me know if I missed a reference or resource!

## Disclaimer\Notes
- Download this project from GitHub and treat it as a security project
- If you want your website to be excluded from this project list, please reach out to me
- This tool is meant to be used locally, not as a service (It does not have any Access Control)
- For issues related to modules that end with -private or under the private group ![](https://raw.githubusercontent.com/qeeqbox/social-analyzer/main/readme/modules.png), reach out directly to me (do not open an issue on GitHub)

## Other Projects
[![](https://github.com/qeeqbox/.github/blob/main/data/analyzer.png)](https://github.com/qeeqbox/analyzer) [![](https://github.com/qeeqbox/.github/blob/main/data/chameleon.png)](https://github.com/qeeqbox/chameleon) [![](https://github.com/qeeqbox/.github/blob/main/data/honeypots.png)](https://github.com/qeeqbox/honeypots) [![](https://github.com/qeeqbox/.github/blob/main/data/osint.png)](https://github.com/qeeqbox/osint) [![](https://github.com/qeeqbox/.github/blob/main/data/url-sandbox.png)](https://github.com/qeeqbox/url-sandbox) [![](https://github.com/qeeqbox/.github/blob/main/data/mitre-visualizer.png)](https://github.com/qeeqbox/mitre-visualizer) [![](https://github.com/qeeqbox/.github/blob/main/data/woodpecker.png)](https://github.com/qeeqbox/woodpecker) [![](https://github.com/qeeqbox/.github/blob/main/data/docker-images.png)](https://github.com/qeeqbox/docker-images) [![](https://github.com/qeeqbox/.github/blob/main/data/seahorse.png)](https://github.com/qeeqbox/seahorse) [![](https://github.com/qeeqbox/.github/blob/main/data/rhino.png)](https://github.com/qeeqbox/rhino) [![](https://github.com/qeeqbox/.github/blob/main/data/raven.png)](https://github.com/qeeqbox/raven) [![](https://github.com/qeeqbox/.github/blob/main/data/image-analyzer.png)](https://github.com/qeeqbox/image-analyzer)
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[mozilla/pdf.js]]></title>
            <link>https://github.com/mozilla/pdf.js</link>
            <guid>https://github.com/mozilla/pdf.js</guid>
            <pubDate>Thu, 05 Feb 2026 00:07:38 GMT</pubDate>
            <description><![CDATA[PDF Reader in JavaScript]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mozilla/pdf.js">mozilla/pdf.js</a></h1>
            <p>PDF Reader in JavaScript</p>
            <p>Language: JavaScript</p>
            <p>Stars: 52,775</p>
            <p>Forks: 10,576</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># PDF.js [![CI](https://github.com/mozilla/pdf.js/actions/workflows/ci.yml/badge.svg?query=branch%3Amaster)](https://github.com/mozilla/pdf.js/actions/workflows/ci.yml?query=branch%3Amaster)

[PDF.js](https://mozilla.github.io/pdf.js/) is a Portable Document Format (PDF) viewer that is built with HTML5.

PDF.js is community-driven and supported by Mozilla. Our goal is to
create a general-purpose, web standards-based platform for parsing and
rendering PDFs.

## Contributing

PDF.js is an open source project and always looking for more contributors. To
get involved, visit:

+ [Issue Reporting Guide](https://github.com/mozilla/pdf.js/blob/master/.github/CONTRIBUTING.md)
+ [Code Contribution Guide](https://github.com/mozilla/pdf.js/wiki/Contributing)
+ [Frequently Asked Questions](https://github.com/mozilla/pdf.js/wiki/Frequently-Asked-Questions)
+ [Good Beginner Bugs](https://github.com/mozilla/pdf.js/issues?q=is%3Aissue%20state%3Aopen%20label%3Agood-beginner-bug)
+ [Projects](https://github.com/mozilla/pdf.js/projects)

Feel free to stop by our [Matrix room](https://chat.mozilla.org/#/room/#pdfjs:mozilla.org) for questions or guidance.

## Getting Started

### Online demo

Please note that the &quot;Modern browsers&quot; version assumes native support for the
latest JavaScript features; please also see [this wiki page](https://github.com/mozilla/pdf.js/wiki/Frequently-Asked-Questions#faq-support).

+ Modern browsers: https://mozilla.github.io/pdf.js/web/viewer.html

+ Older browsers: https://mozilla.github.io/pdf.js/legacy/web/viewer.html

### Browser Extensions

#### Firefox

PDF.js is built into version 19+ of Firefox.

#### Chrome

+ The official extension for Chrome can be installed from the [Chrome Web Store](https://chrome.google.com/webstore/detail/pdf-viewer/oemmndcbldboiebfnladdacbdfmadadm).
*This extension is maintained by [@Rob--W](https://github.com/Rob--W).*
+ Build Your Own - Get the code as explained below and issue `npx gulp chromium`. Then open
Chrome, go to `Tools &gt; Extension` and load the (unpackaged) extension from the
directory `build/chromium`.

## Getting the Code

To get a local copy of the current code, clone it using git:

    $ git clone https://github.com/mozilla/pdf.js.git
    $ cd pdf.js

Next, install Node.js via the [official package](https://nodejs.org) or via
[nvm](https://github.com/creationix/nvm). If everything worked out, install
all dependencies for PDF.js:

    $ npm install

Finally, you need to start a local web server as some browsers do not allow opening
PDF files using a `file://` URL. Run:

    $ npx gulp server

and then you can open:

+ http://localhost:8888/web/viewer.html

Please keep in mind that this assumes the latest version of Mozilla Firefox; refer to [Building PDF.js](https://github.com/mozilla/pdf.js/blob/master/README.md#building-pdfjs) for non-development usage of the PDF.js library.

It is also possible to view all test PDF files on the right side by opening:

+ http://localhost:8888/test/pdfs/?frame

## Building PDF.js

In order to bundle all `src/` files into two production scripts and build the generic
viewer, run:

    $ npx gulp generic

If you need to support older browsers, run:

    $ npx gulp generic-legacy

This will generate `pdf.js` and `pdf.worker.js` in the `build/generic/build/` directory (respectively `build/generic-legacy/build/`).
Both scripts are needed but only `pdf.js` needs to be included since `pdf.worker.js` will
be loaded by `pdf.js`. The PDF.js files are large and should be minified for production.

## Using PDF.js in a web application

To use PDF.js in a web application you can choose to use a pre-built version of the library
or to build it from source. We supply pre-built versions for usage with NPM under
the `pdfjs-dist` name. For more information and examples please refer to the
[wiki page](https://github.com/mozilla/pdf.js/wiki/Setup-pdf.js-in-a-website) on this subject.

## Including via a CDN

PDF.js is hosted on several free CDNs:
 - https://www.jsdelivr.com/package/npm/pdfjs-dist
 - https://cdnjs.com/libraries/pdf.js
 - https://unpkg.com/pdfjs-dist/

## Learning

You can play with the PDF.js API directly from your browser using the live demos below:

+ [Interactive examples](https://mozilla.github.io/pdf.js/examples/index.html#interactive-examples)

More examples can be found in the [examples folder](https://github.com/mozilla/pdf.js/tree/master/examples/). Some of them are using the pdfjs-dist package, which can be built and installed in this repo directory via `npx gulp dist-install` command.

For an introduction to the PDF.js code, check out the presentation by our
contributor Julian Viereck:

+ https://www.youtube.com/watch?v=Iv15UY-4Fg8

More learning resources can be found at:

+ https://github.com/mozilla/pdf.js/wiki/Additional-Learning-Resources

The API documentation can be found at:

+ https://mozilla.github.io/pdf.js/api/

## Questions

Check out our FAQs and get answers to common questions:

+ https://github.com/mozilla/pdf.js/wiki/Frequently-Asked-Questions

Talk to us on Matrix:

+ https://chat.mozilla.org/#/room/#pdfjs:mozilla.org

File an issue:

+ https://github.com/mozilla/pdf.js/issues/new/choose
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[academind/react-complete-guide-course-resources]]></title>
            <link>https://github.com/academind/react-complete-guide-course-resources</link>
            <guid>https://github.com/academind/react-complete-guide-course-resources</guid>
            <pubDate>Thu, 05 Feb 2026 00:07:37 GMT</pubDate>
            <description><![CDATA[React - The Complete Guide Course Resources (Code, Attachments, Slides)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/academind/react-complete-guide-course-resources">academind/react-complete-guide-course-resources</a></h1>
            <p>React - The Complete Guide Course Resources (Code, Attachments, Slides)</p>
            <p>Language: JavaScript</p>
            <p>Stars: 3,773</p>
            <p>Forks: 2,878</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># React - The Complete Guide Course Resources

This repository provides access to code files, code snapshots, slides &amp; other resources that are used or provided by the [React - The Complete Guide](https://acad.link/reactjs) course.

If you&#039;re facing any issues with the code, please post in the course Q&amp;A section.

# Repository Content

- **Code Snapshots:** All code snapshots (starting snapshots, intermediate snapshots, finished snapshots) for the various course sections can be found in the [/code](/code/) folder.
- **Lecture Attachments:** Any standalone code files or other attachments that are mentioned in course lectures (and attached to those lectures) are stored in the [/attachments](/attachments/) folder.
- **Other Resources:** Other resources (like the course slides) can be found in the [/other](/other/) folder.

The **Code Snapshots** and **Lecture Attachments** folders contain one subfolder per course section - this allows you to easily access the resources for a specific course section.

# How To Use Code Snapshots

Code snapshots are primarily provided to allow you to compare your code to mine. The snapshots are taken directly from the course recordings and therefore reflect my code you see in the videos.

Of course, you can also try running those code snapshots on your machine. You&#039;ll need to run `npm install` in the individual snapshot folders, followed by `npm run dev` to start the development server - just as shown in the course.
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[harvard-edge/cs249r_book]]></title>
            <link>https://github.com/harvard-edge/cs249r_book</link>
            <guid>https://github.com/harvard-edge/cs249r_book</guid>
            <pubDate>Thu, 05 Feb 2026 00:07:36 GMT</pubDate>
            <description><![CDATA[Introduction to Machine Learning Systems]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/harvard-edge/cs249r_book">harvard-edge/cs249r_book</a></h1>
            <p>Introduction to Machine Learning Systems</p>
            <p>Language: JavaScript</p>
            <p>Stars: 17,806</p>
            <p>Forks: 2,054</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre># Machine Learning Systems
*Principles and Practices of Engineering Artificially Intelligent Systems*

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;README.md&quot;&gt;English&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;README/README_zh.md&quot;&gt;‰∏≠Êñá&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;README/README_ja.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;README/README_ko.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;p align=&quot;center&quot;&gt;

  [![Book](https://img.shields.io/github/actions/workflow/status/harvard-edge/cs249r_book/book-validate-dev.yml?branch=dev&amp;label=Book&amp;logo=githubactions&amp;cacheSeconds=300)](https://github.com/harvard-edge/cs249r_book/actions/workflows/book-validate-dev.yml)
  [![TinyTorch](https://img.shields.io/github/actions/workflow/status/harvard-edge/cs249r_book/tinytorch-validate-dev.yml?branch=dev&amp;label=TinyTorch&amp;logo=python&amp;cacheSeconds=300)](https://github.com/harvard-edge/cs249r_book/actions/workflows/tinytorch-validate-dev.yml)
  ![Updated](https://img.shields.io/github/last-commit/harvard-edge/cs249r_book/dev?label=Updated&amp;logo=git&amp;cacheSeconds=300)

  [![License](https://img.shields.io/badge/License-CC--BY--NC--ND%204.0-blue.svg)](https://github.com/harvard-edge/cs249r_book/blob/dev/LICENSE.md)
  [![Cite](https://img.shields.io/badge/Cite-IEEE%202024-blue?logo=ieee)](#-citation--license)
  [![Fund Us](https://img.shields.io/badge/Fund%20Us-Open%20Collective-blue.svg?logo=open-collective)](https://opencollective.com/mlsysbook)

&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;

  &lt;!-- Reader Navigation --&gt;
  **[üìñ Read Online](https://mlsysbook.ai)** ‚Ä¢
  **[Tinyüî•Torch](https://mlsysbook.ai/tinytorch)** ‚Ä¢
  **[üìÑ Download PDF](https://mlsysbook.ai/assets/downloads/Machine-Learning-Systems.pdf)** ‚Ä¢
  **[üìì Download EPUB](https://mlsysbook.ai/epub)** ‚Ä¢
  **[üåê Explore Ecosystem](https://mlsysbook.org)**

&lt;/p&gt;

üìö **Hardcopy edition coming 2026 with MIT Press.**

&lt;/div&gt;

---

## Mission

**The world is rushing to build AI systems. It is not engineering them.**

That gap is what we mean by AI engineering.

**AI engineering is the discipline of building efficient, reliable, safe, and robust intelligent systems that operate in the real world, not just models in isolation.**

**Our mission:** Establish AI engineering as a foundational discipline, alongside software engineering and computer engineering, by teaching how to design, build, and evaluate end to end intelligent systems. The long term impact of AI will be shaped by engineers who can turn ideas into working, dependable systems.

---

## What‚Äôs in this repo

This repository is the open learning stack for AI systems engineering.

It includes the textbook source, TinyTorch, hardware kits, and upcoming co-labs that connect principles to runnable code and real devices.

---

## Start Here

Choose a path based on your goal.

**READ** Start with the [textbook](https://mlsysbook.ai). Try [Chapter 1](https://www.mlsysbook.ai/book/contents/core/introduction/introduction.html) and the [Benchmarking chapter](https://mlsysbook.ai/book/contents/core/benchmarking/benchmarking.html).

**BUILD** Start TinyTorch with the [getting started guide](https://mlsysbook.ai/tinytorch/getting-started.html). Begin with Module 01 and work up from CNNs to transformers and the MLPerf benchmarks.

**DEPLOY** Pick a [hardware kit](https://mlsysbook.ai/kits) and run the labs on Arduino, Raspberry Pi, and other edge devices.

**CONNECT** Say hello in [Discussions](https://github.com/harvard-edge/cs249r_book/discussions). We will do our best to reply.

---

## The Learning Stack

The learning stack below shows how the textbook connects to hands on work and deployment. Read the textbook, then pick your path:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                               ‚îÇ
‚îÇ                           MACHINE LEARNING SYSTEMS                            ‚îÇ
‚îÇ                              Read the Textbook                                ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ                    Theory ‚Ä¢ Concepts ‚Ä¢ Best Practices                         ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                        ‚îÇ
                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                          ‚îÇ             ‚îÇ             ‚îÇ
                          ‚ñº             ‚ñº             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                            HANDS-ON ACTIVITIES                                ‚îÇ
‚îÇ                           (pick one or all)                                   ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ     ‚îÇ                 ‚îÇ      ‚îÇ                 ‚îÇ      ‚îÇ                 ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ    SOFTWARE     ‚îÇ      ‚îÇ    TINYTORCH    ‚îÇ      ‚îÇ    HARDWARE     ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ    CO-LABS      ‚îÇ      ‚îÇ    FRAMEWORK    ‚îÇ      ‚îÇ      LABS       ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ                 ‚îÇ      ‚îÇ                 ‚îÇ      ‚îÇ                 ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ EXPLORE         ‚îÇ      ‚îÇ BUILD           ‚îÇ      ‚îÇ DEPLOY          ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ                 ‚îÇ      ‚îÇ                 ‚îÇ      ‚îÇ                 ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ Run controlled  ‚îÇ      ‚îÇ Understand      ‚îÇ      ‚îÇ Engineer under  ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ experiments on  ‚îÇ      ‚îÇ frameworks by   ‚îÇ      ‚îÇ real constraints‚îÇ     ‚îÇ
‚îÇ     ‚îÇ latency, memory,‚îÇ      ‚îÇ implementing    ‚îÇ      ‚îÇ memory, power,  ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ energy, cost    ‚îÇ      ‚îÇ them            ‚îÇ      ‚îÇ timing, safety  ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ                 ‚îÇ      ‚îÇ                 ‚îÇ      ‚îÇ                 ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ (coming 2026)   ‚îÇ      ‚îÇ                 ‚îÇ      ‚îÇ Arduino, Pi     ‚îÇ     ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ           EXPLORE                  BUILD                   DEPLOY             ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                        ‚îÇ
                                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                               ‚îÇ
‚îÇ                                  AI OLYMPICS                                  ‚îÇ
‚îÇ                                 Prove Mastery                                 ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ       Compete across all tracks ‚Ä¢ University teams ‚Ä¢ Public leaderboards      ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ                                (coming 2026)                                  ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

| | Component | What You Do | Link |
|--|-----------|-------------|------|
| **READ** | [üìñ Textbook](https://mlsysbook.ai) | Understand ML systems concepts | [book/](book/README.md) |
| **EXPLORE** | üîÆ Software Co-Labs | Run controlled experiments on latency, memory, energy, cost | *Coming 2026* |
| **BUILD** | [üî• TinyTorch](https://mlsysbook.ai/tinytorch) | Understand frameworks by implementing them | [tinytorch/](tinytorch/README.md) |
| **DEPLOY** | [üîß Hardware Kits](https://mlsysbook.ai/kits) | Engineer under real constraints: memory, power, timing, safety | [kits/](kits/README.md) |
| **PROVE** | üèÜ AI Olympics | Compete and benchmark across all tracks | *Coming 2026* |

**What each path teaches:**
- **EXPLORE** teaches *why* ‚Äî Understand tradeoffs. Change batch sizes, precision, model architectures and see how latency, memory, and accuracy shift.
- **BUILD** teaches *how* ‚Äî Understand internals. Implement autograd, optimizers, and attention from scratch to see how TensorFlow and PyTorch actually work.
- **DEPLOY** teaches *where* ‚Äî Understand constraints. Face real memory limits, power budgets, and latency requirements on actual hardware.

---

## What You Will Learn

This textbook teaches you to think at the intersection of machine learning and systems engineering. Each chapter bridges algorithmic concepts with the infrastructure that makes them work in practice.

### The ML ‚Üî Systems Bridge

| ML Concept | Systems Concept | What You Learn |
|------------|-----------------|----------------|
| Model parameters | Memory constraints | How to fit large models on resource-limited devices |
| Inference latency | Hardware acceleration | How GPUs, TPUs, and accelerators execute neural networks |
| Training convergence | Compute efficiency | How mixed-precision and optimization techniques reduce cost |
| Model accuracy | Quantization and pruning | How to compress models while preserving performance |
| Data requirements | Pipeline infrastructure | How to build efficient data loading and preprocessing |
| Model deployment | MLOps practices | How to monitor, version, and update models in production |
| Privacy constraints | On-device learning | How to train and adapt models without sending data to the cloud |

### Book Structure

| Part | Focus | Chapters |
|------|-------|----------|
| **I. Foundations** | Core concepts | Introduction, ML Systems, DL Primer, Architectures |
| **II. Design** | Building blocks | Workflow, Data Engineering, Frameworks, Training |
| **III. Performance** | Making it fast | Efficient AI, Optimizations, HW Acceleration, Benchmarking |
| **IV. Deployment** | Making it work | MLOps, On-device Learning, Privacy, Robustness |
| **V. Trust** | Making it right | Responsible AI, Sustainable AI, AI for Good |
| **VI. Frontiers** | What&#039;s next | Emerging trends and future directions |

---

## What Makes This Different

This is a living textbook. We keep it updated as the field grows, with community input along the way.

AI may feel like it is moving at lightning speed, but the engineering building blocks that make it work do not change as quickly as the headlines. This project is built around those stable foundations.

Think of it like LEGO. New sets arrive all the time, but the bricks themselves stay the same. Once you learn how the bricks fit together, you can build anything. Here, those &quot;AI bricks&quot; are the solid systems principles that make AI work.

Whether you are reading a chapter, running a lab, or sharing feedback, you are helping make these ideas more accessible to the next learner.

### Research to Teaching Loop

We use the same loop for research and teaching: define the system problem, build a reference implementation, benchmark it, then turn it into curriculum and tooling so others can reproduce and extend it.

| Loop Step | Research Artifacts | Teaching Artifacts |
|-----------|-------------------|-------------------|
| **Measure** | Benchmarks, suites, metrics | Benchmarking chapter, assignments |
| **Build** | Reference systems, compilers, runtimes | TinyTorch modules, co-labs |
| **Deploy** | Hardware targets, constraints, reliability | Hardware labs, kits |

---

## Support This Work

We are working toward **1 million learners by 2030** so that AI engineering becomes a shared, teachable discipline, not a collection of isolated practices. Every star, share, and contribution helps move this effort forward.

### Why GitHub Stars Matter

&lt;div align=&quot;center&quot;&gt;

*What gets measured gets improved.*

Each star is a learner, educator, or supporter who believes AI systems should be engineered with rigor and real world constraints in mind.

[![Stars](https://img.shields.io/github/stars/harvard-edge/cs249r_book?style=for-the-badge&amp;logo=github&amp;color=gold)](https://github.com/harvard-edge/cs249r_book/stargazers)

[![Star History Chart](https://api.star-history.com/svg?repos=harvard-edge/cs249r_book&amp;type=Date)](https://star-history.com/#harvard-edge/cs249r_book&amp;Date)

1 learner ‚Üí 10 learners ‚Üí 100 learners ‚Üí 1,000 learners ‚Üí **10,000 learners** ‚Üí 100,000 learners ‚Üí **1M learners**

&lt;/div&gt;

Stars are not the goal. They are a signal.

A visible, growing community makes it easier for universities, foundations, and industry partners to adopt this material, donate hardware, and fund workshops. That momentum lowers the barrier for the next institution, the next classroom, and the next cohort of learners.

Support raised through this signal flows into [Open Collective](https://opencollective.com/mlsysbook) and funds concrete outcomes such as TinyML4D workshops, hardware kits for underserved classrooms, and the infrastructure required to keep this resource free and open.

One click can unlock the next classroom, the next contributor, and the next generation of AI engineers.

### Fund the Mission

&lt;div align=&quot;center&quot;&gt;

All contributions go to [Open Collective](https://opencollective.com/mlsysbook), a transparent fund that supports educational outreach.

[![Open Collective](https://img.shields.io/badge/üíù%20Support%20AI%20Education-Open%20Collective-blue.svg?style=for-the-badge)](https://opencollective.com/mlsysbook)

&lt;/div&gt;

---

## Community and Resources

| Resource | Description |
|---|---|
| [üìñ **Textbook**](https://mlsysbook.ai) | Interactive online textbook |
| [üî• **TinyTorch**](https://mlsysbook.ai/tinytorch) | Build ML frameworks from scratch |
| [üîß **Hardware Kits**](https://mlsysbook.ai/kits) | Deploy to Arduino, Raspberry Pi, edge devices |
| [üåê **Ecosystem**](https://mlsysbook.org) | Resources, workshops, and community |
| [üí¨ **Discussions**](https://github.com/harvard-edge/cs249r_book/discussions) | Questions and ideas |

---

## Contributing

We welcome contributions to the book, TinyTorch, and hardware kits!

| I want to... | Go here |
|--------------|---------|
| Fix a typo or improve a chapter | [book/docs/CONTRIBUTING.md](book/docs/CONTRIBUTING.md) |
| Add a TinyTorch module or fix a bug | [tinytorch/CONTRIBUTING.md](tinytorch/CONTRIBUTING.md) |
| Improve hardware labs | [kits/README.md](kits/README.md) |
| Report an issue | [GitHub Issues](https://github.com/harvard-edge/cs249r_book/issues) |
| Ask a question | [GitHub Discussions](https://github.com/harvard-edge/cs249r_book/discussions) |

---

## Citation &amp; License

### Citation
```bibtex
@inproceedings{reddi2024mlsysbook,
  title        = {MLSysBook.AI: Principles and Practices of Machine Learning Systems Engineering},
  author       = {Reddi, Vijay Janapa},
  booktitle    = {2024 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ ISSS)},
  pages        = {41--42},
  year         = {2024},
  organization = {IEEE},
  url          = {https://mlsysbook.org}
}
```

### License

This project uses a dual-license structure:

| Component | License | What It Means |
|-----------|---------|---------------|
| **Book content** | [CC BY-NC-ND 4.0](LICENSE.md) | Share freely with attribution; no commercial use; no derivatives |
| **TinyTorch code** | [Apache 2.0](tinytorch/LICENSE) | Use, modify, and distribute freely; includes patent protection |

The textbook content (chapters, figures, explanations) is educational material that should circulate with attribution and without commercial exploitation. The software framework is a tool designed to be easy for anyone to use, modify, or integrate into their own projects.

---

## Contributors

Thanks goes to these wonderful people who have contributed to making this resource better for everyone!

**Legend:** ü™≤ Bug Hunter ¬∑ üßë‚Äçüíª Code Contributor ¬∑ ‚úçÔ∏è Doc Wizard ¬∑ üé® Design Artist ¬∑ üß† Idea Spark ¬∑ üîé Code Reviewer ¬∑ üß™ Test Tinkerer ¬∑ üõ†Ô∏è Tool Builder

### üìñ Textbook Contributors

&lt;!-- BOOK-CONTRIBUTORS-START --&gt;
&lt;!-- prettier-ignore-start --&gt;
&lt;!-- markdownlint-disable --&gt;
&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/profvjreddi&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/profvjreddi?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Vijay Janapa Reddi&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Vijay Janapa Reddi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;ü™≤ üßë‚Äçüíª üé® ‚úçÔ∏è üß† üîé üß™ üõ†Ô∏è&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/Mjrovai&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/Mjrovai?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Marcelo Rovai&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Marcelo Rovai&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;üßë‚Äçüíª üé® üß™&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/GabrielAmazonas&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/GabrielAmazonas?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Gabriel Amazonas&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Gabriel Amazonas&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;ü™≤ ‚úçÔ∏è üß†&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/kai4avaya&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/kai4avaya?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Kai Kleinbard&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Kai Kleinbard&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;üßë‚Äçüíª üõ†Ô∏è&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/didier-durand&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/didier-durand?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Didier Durand&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Didier Durand&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;‚úçÔ∏è ü™≤&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/hzeljko&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/hzeljko?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Zeljko Hrcek&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Zeljko Hrcek&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;üßë‚Äçüíª&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/jasonjabbour&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/jasonjabbour?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Jason Jabbour&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jason Jabbour&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;‚úçÔ∏è&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/uchendui&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/uchendui?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Ikechukwu Uchendu&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ikechukwu Uchendu&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;‚úçÔ∏è&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/Naeemkh&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/Naeemkh?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Naeem Khoshnevis&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Naeem Khoshnevis&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;‚úçÔ∏è&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/Sara-Khosravi&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/Sara-Khosravi?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Sara Khosravi&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sara Khosravi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;‚úçÔ∏è&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/V0XNIHILI&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/V0XNIHILI?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Douwe den Blanken&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Douwe den Blanken&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;‚úçÔ∏è&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/18jeffreyma&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/18jeffreyma?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Jeffrey Ma&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jeffrey Ma&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;‚úçÔ∏è&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/shanzehbatool&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/shanzehbatool?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;shanzehbatool&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;shanzehbatool&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;‚úçÔ∏è&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/eliasab16&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/eliasab16?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Elias&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Elias&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;‚úçÔ∏è&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/JaredP94&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/JaredP94?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Jared Ping&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jared Ping&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;‚úçÔ∏è&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/ishapira1&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/ishapira1?

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[databricks-industry-solutions/pixels]]></title>
            <link>https://github.com/databricks-industry-solutions/pixels</link>
            <guid>https://github.com/databricks-industry-solutions/pixels</guid>
            <pubDate>Thu, 05 Feb 2026 00:07:35 GMT</pubDate>
            <description><![CDATA[Facilitates simple large scale processing of HLS Medical images, documents, zip files. OHIF Viewer, 2 segmentation models and interactive learning.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/databricks-industry-solutions/pixels">databricks-industry-solutions/pixels</a></h1>
            <p>Facilitates simple large scale processing of HLS Medical images, documents, zip files. OHIF Viewer, 2 segmentation models and interactive learning.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 318</p>
            <p>Forks: 103</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;div bgcolor=&quot;white&quot;&gt;
  &lt;img src=https://hls-eng-data-public.s3.amazonaws.com/img/Databricks_HLS.png width=&quot;380px&quot; align=&quot;right&quot;&gt;
&lt;/div&gt;

# `pixels` Solution Accelerator
‚úÖ  Ingest and index DICOM image metadata (.dcm and from zip archives)
&lt;/br&gt; ‚úÖ  Analyze DICOM image metadata with SQL and Machine Learning.
&lt;/br&gt; ‚úÖ  View, segment, label DICOM Images with OHIF viewer integrated into Lakehouse Apps and Databricks security model. 
&lt;/br&gt; ‚úÖ  One button push to launch model training from OHIF viewer.
&lt;/br&gt; ‚úÖ  NVIDIA&#039;s [MONAI](https://docs.nvidia.com/monai/index.html) Integration, AI to automatically segment medical images and train custom models.
&lt;/br&gt; ‚úÖ  Leverage Databricks&#039; [Model Serving](https://docs.databricks.com/en/machine-learning/model-serving/index.html) with serverless GPU enabled clusters for real-time segmentation.

---
## Secure Lakehouse integrated DICOM Viewer powered by OHIF
&lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/LHA_AUTOSEG.gif?raw=true&quot; alt=&quot;MONAI_AUTOSEG&quot;/&gt;&lt;/br&gt;

---
## Run SQL queries over DICOM metadata
![Analyze](https://github.com/databricks-industry-solutions/pixels/blob/main/images/DICOM-analyze-with-SQL.png?raw=true)

---
## Build Dashboards over DICOM metadata
add any features extracted too!
![Dashboard](images/pixels-dashboard.png)

---
## DICOM data ingestion is easy

```python
# import Pixels Catalog (indexer) and DICOM transformers &amp; utilities
from dbx.pixels import Catalog                              # 01
from dbx.pixels.dicom import *                              # 02

# catalog all your files
catalog = Catalog(spark)                                    # 03
catalog_df = catalog.catalog(&lt;path&gt;)                        # 04

# extract the DICOM metadata
meta_df = DicomMetaExtractor(catalog).transform(catalog_df) # 05

# save your work for SQL access
catalog.save(meta_df)                                       # 06
```
You&#039;ll find this example in [01-dcm-demo](https://github.com/databricks-industry-solutions/pixels/blob/main/01-dcm-demo.py) which does:

---
## Architecture
![image](https://github.com/user-attachments/assets/75decf47-3a37-446a-a672-d497d155f464)

The image depicts the **Pixels Reference Solution Architecture**, which outlines a data processing and analytics framework designed for healthcare or imaging applications. Here&#039;s a breakdown of its components:

### **Key Functional Areas**
1. **AI/BI Analytics**: Supports cohort building and natural language-based analysis.
   
2. **Lakehouse Apps**: Includes an OHIF Viewer for labeling and customer-specific applications.

3. **Deep Learning**: Facilitates active learning and customer model training.

4. **Realtime Inferencing**: Implements MONAI (Medical Open Network for AI) for segmentation integration with the OHIF viewer. Customer provided proprietary models can be easily plugged in.

### **Data Flow: Batch, Incremental, Streaming Lakeflow**
The architecture processes data in stages:
1. **Acquire**: from data in ADLS, S3, GCS cloud storage as governed by Unity Catalog (UC) Volumes.  Based on customer demand, due to the composible nature of the solution accelerator, sources VNA, PACS, CIFS, AWS HealthImaging can be added as needed.
   
2. **Ingest**:  Ultimately all the DICOM files are ingested. Ingesting and producing Nifti file formats are currently on the roadmap.

3. **Extract &amp; Index**: Unzips files, storing the extracted DICOM files into a UC volume. All of the DICOM metadata tags are extracted and stored in Databricks Data Intelligence Platform tables.

4. **Protect ‚Äì Metadata**: Applies PHI (Protected Health Information) redaction via format preserving encryption to all necessary tags.

5. **Protect ‚Äì Image**: Ensures PHI redaction for pixel-level data. This is under active integration based on work Databricks has done in previous solution accelerators.

6. **Inferencing**: Utilizes industry-standard models pre-trained MONAI open source models sponsored by NVIDIA. Similarly, customers can fine tune the MONAI models or bring their own segmentation or featurization models.

### **Supporting Layers**
- **Governance Layer**: Unity Catalog provides data access controls, automatic capture of data lineage (including models)
  
- **Customer‚Äôs Cloud Storage**: Stores object indexes, folders, and ML models in open formats in customer&#039;s account.
  
- **Open Access**: Provides APIs, SQL connections, Spark integration, and credential vending via Delta Sharing.

This architecture is designed to handle healthcare imaging data securely while enabling advanced analytics and AI-driven insights.


---
## Getting started

1. To run this accelerator, [clone](https://docs.databricks.com/aws/en/repos/git-operations-with-repos) this repo into a Databricks workspace. 

2. Attach a notebook to Serverless Compute or a cluster (&gt;=DBR 14.3 LTS)
3. Run [`config/setup.py`]($./config/setup) from the notebook. This will install the pixels package onto your workspace


## Run pipeline as a job
1. Attach the [`RUNME`]($./RUNME) notebook to Serverless Compute or a cluster (&gt;=DBR 14.3 LTS). 2. Execute the notebook via Run-All. You can configure the notebook tasks run by the job in `job_json`
A multi-step-job describing the accelerator pipeline will be created, and the link will be provided. The cost associated with running the accelerator is the user&#039;s responsibility.

## Incremental processing
Pixels allows you to ingest DICOM files in a streaming fashion using [autoloader](https://docs.databricks.com/en/ingestion/auto-loader/unity-catalog.html) capability.
To enable incremental processing you need to set `streaming` and `streamCheckpointBasePath` as follows:
```python
catalog_df = catalog.catalog(path, streaming=True, streamCheckpointBasePath=&lt;checkpointPath&gt;)
```

## Built-in unzip
Automatically extracts zip files in the defined volume path.
If extractZip is not enabled then zip files will be ignored.
To enable unzip capability you need to set `extractZip`. The parameter `extractZipBasePath` is optional and the default path will be volume + /unzipped/
```python
catalog_df = catalog.catalog(path, extractZip=True, extractZipBasePath=&lt;unzipPath&gt;)
```

## Metadata Anonymization
Pixels provides a feature to anonymize DICOM metadata to ensure patient privacy and compliance with regulations. This feature can be enabled during the cataloging process. An example can be explored in the [03-Metadata-DeIdentification](https://github.com/databricks-industry-solutions/pixels/blob/main/03-Metadata-DeIdentification.py) notebook.

To enable metadata anonymization, you can use the following extractor:
```python
metadata_df = DicomMetaAnonymizerExtractor(
   catalog,
   anonym_mode=&quot;METADATA&quot;,
   fp_key=&lt;fp_key&gt;, #ONLY HEX STRING ALLOWED - 128, 192 or 256 bits
   fp_tweak=&lt;fp_tweak&gt;,   #ONLY HEX STRING ALLOWED - 64 bits
   anonymization_base_path=&lt;anonym_path&gt;
).transform(catalog_df)
```
`fp_key` is the format preserving encryption key used to ensure that the anonymization process is consistent across different runs. This key is used to generate pseudonyms for sensitive data fields, ensuring that the same input value always maps to the same pseudonym. This is useful for maintaining the ability to link records across datasets without revealing the original sensitive information.

`fp_tweak` is an optional parameter that can be used to add an additional layer of randomness to the pseudonymization process. This can be useful for further enhancing privacy.

By setting the `anonym_mode` parameter to `&quot;METADATA&quot;`, the DICOM metadata will be anonymized during the ingestion process. This ensures that sensitive patient information is not stored in the catalog.
The default configuration will save the anonymized DICOM files under `anonymization_base_path` property&#039;s path.

---
## OHIF Viewer
Inside `dbx.pixels` resources folder, a pre-built version of [OHIF Viewer](https://github.com/OHIF/Viewers) with Databricks and [Unity Catalog Volumes](https://docs.databricks.com/en/sql/language-manual/sql-ref-volumes.html) extension is provided. 

All the catalog entries will be available in an easy to use study list.
![Catalog](https://github.com/databricks-industry-solutions/pixels/blob/main/images/ohif_catalog_view.png?raw=true)
Fast and multiple-layer visualization capability.
![CT_View](https://github.com/databricks-industry-solutions/pixels/blob/main/images/ohif_mr_view.png?raw=true)

To start the OHIF Viewer web app you need to:
 - Execute the [06-OHIF-Viewer](https://github.com/databricks-industry-solutions/pixels/blob/main/06-OHIF-Viewer.py) inside a Databricks workspace.
 - Set the `table` parameter to the full name of your Pixels catalog table. Ex: `main.pixels_solacc.object_catalog`
 - Set the `sqlWarehouseID`parameter to execute the queries required to collect the records. It&#039;s the final section of the `HTTP path` in the `Connection details` tab. Use [Serverless](https://docs.databricks.com/en/admin/sql/warehouse-types.html#sql-warehouse-types) for best performance.

    &lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/sqlWarehouseID.png?raw=true&quot; alt=&quot;sqlWarehouseID&quot;/&gt;

 - Use the link generated in the last notebook to access the OHIF viewer page.

## Save measurements and segmentations
The OHIF Viewer allows you to save back to Databricks the measurements and the segmentations created in the viewer.
The metadata will be stored in the object_catalog, and the generated dicom files in the volume under the path `/ohif/exports/`.

&lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/ohif_save_segm.png?raw=true&quot; alt=&quot;OHIF_SAVE_SEG&quot; height=&quot;300&quot;/&gt;
&lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/ohif_save_meas.png?raw=true&quot; alt=&quot;OHIF_SAVE_MEAS&quot; height=&quot;300&quot;/&gt;
&lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/ohif_save_result.png?raw=true&quot; alt=&quot;OHIF_SAVED&quot; height=&quot;300&quot;/&gt;


## MONAILabel Integration

[MONAILabel](https://monai.io/label.html) is an open-source tool designed for interactive medical image labeling. It supports various annotation tasks such as segmentation and classification, providing a seamless experience when integrated with viewers like OHIF that is already available in this solution accelerator.

![MONAI_BTN](https://github.com/databricks-industry-solutions/pixels/blob/main/images/monailabel_result.png?raw=true)
Once the server is running, you can use the OHIF Viewer to interact with your medical images. This integration allows you to leverage advanced annotation capabilities directly within your Databricks environment.

### Key Features
 - Interactive Annotation: Use AI-assisted tools for efficient labeling.
 - Seamless Integration: Work directly within Databricks using a web-based viewer.
 - Customizable Workflows: Tailor the annotation process to fit specific research needs.

### MONAILabel Setup Instructions
To execute the MONAILabel server it is mandatory to use a cluster with Databricks Runtime Version of `14.3 LTS ML`. For the best performance use a [GPU-Enabled compute](https://docs.databricks.com/en/compute/gpu.html#gpu-enabled-compute).
#### Start the MONAILabel server
 - Execute the [05-MONAILabel](https://github.com/databricks-industry-solutions/pixels/blob/main/05-MONAILabel.py) inside a Databricks workspace.
 - Set the `table` parameter to the full name of your Pixels catalog table. Ex: `main.pixels_solacc.object_catalog`
 - Set the `sqlWarehouseID`parameter to the DBSQL Warehouse ID, needed to run queries required to collect the records. Use [Serverless](https://docs.databricks.com/en/admin/sql/warehouse-types.html#sql-warehouse-types) for best performance.
    &lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/sqlWarehouseID.png?raw=true&quot; alt=&quot;sqlWarehouseID&quot;&gt;
#### Open the OHIF Viewer
 - Execute the notebook [06-OHIF-Viewer](https://github.com/databricks-industry-solutions/pixels/blob/main/06-OHIF-Viewer.py) to start the OHIF Viewer with the MONAILabel extension and open the generated link.
 - Select the preferred CT scan study and press the `MONAI Label` button.

    &lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/monailabel_btn.png?raw=true&quot; alt=&quot;MONAI_BTN&quot; height=&quot;250&quot;/&gt;&lt;/br&gt;
#### Connect, execute and save
 - Connect the MONAILabel server using the refresh button.

    &lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/monailabel_server.png?raw=true&quot; alt=&quot;MONAI_SERVER&quot; height=&quot;200&quot;/&gt;&lt;/br&gt;
 - Execute an auto-segmentation task using the Run button and wait for the results to be displayed.

    &lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/monailabel_autosegm.png?raw=true&quot; alt=&quot;MONAI_AUTOSEG&quot; height=&quot;650&quot;/&gt;&lt;/br&gt;
 - Save the final result metadata in the catalog and the generated dicom file in the volume under the path `/ohif/exports/` using the button `Export DICOM SEG`.

This setup enhances your medical image analysis workflow by combining Databricks&#039; computing power with MONAILabel&#039;s sophisticated annotation tools.

### Model Serving Instructions

To deploy the MONAILabel server in a Model Serving endpoint we prepared [ModelServing](https://github.com/databricks-industry-solutions/pixels/blob/main/monailabel_model/ModelServing.py), a Databricks notebook designed to initialize the Databricks customized version of the **MONAILabel server** that wraps the server in an **MLflow Python custom model** and registers it for use in a **serving endpoint**.

#### Key Features

- **Model Creation**: Utilizes the MONAILabel auto segmentation model on CT AXIAL images.
- **Unity Catalog Integration**: Adds the model to the Unity Catalog for organized management.
- **Serving Endpoint Deployment**: Deploys the model in a serving endpoint for real-time inference.

#### Auto Segmentation with Lakehouse App and Serving Endpoint

https://github.com/user-attachments/assets/8cf62378-ab39-4a89-86ad-c2f231b7a524

#### Active Learning

https://github.com/user-attachments/assets/17142752-d9b9-434b-b893-b6bc05080f54


## Working with Unity Catalog
Unity Catalog (UC) [volumes](https://docs.databricks.com/en/data-governance/unity-catalog/create-volumes.html) are the recommended approach for providing access to and governing non-tabular data assets in a cloud object storage locations, including DICOM files. Volumes are accessed by using the following format for the path that is passed to the pixels `Catalog` object - 
```
/Volumes/&lt;catalog&gt;/&lt;schema&gt;/&lt;volume&gt;/&lt;path-level-1&gt;/...
```
where `&lt;catalog&gt;`, `&lt;schema&gt;` and `&lt;volume&gt;` reflect the three-level namespace of Unity Catalog. The path field returned by the `Catalog` object reflects the volume file path listed above and subsequent metadata and thumbnail extraction operations will use volumes for accessing files.

DICOM file Ingestion works with Shared, Dedicated and Serverless Compute types.

---
## Contributors
- Douglas Moore @ Databricks
- Emanuele Rinaldi @ Databricks
- Nicole Jingting Lu @ Databricks
- Krishanu Nandy @ Databricks
- May Merkle-Tan @ Databricks
- Cal Reynolds @ Databricks
- Guanyu Chen @ Databricks
- Yen Low @ Databricks
- Ben Russoniello @ Prominence Advisors


## About `dbx.pixels`
Relibly turn millions of image files into SQL accessible metadata, thumbnails; Enable Deep Learning, AI/BI Dashboarding, Genie Spaces.

- tags: 
dicom, dcm, pre-processing, visualization, repos, sql, python, spark, pyspark, package, image catalog, mamograms, dcm file
---

## About DICOM
![DICOM Image processing](https://dicom.offis.uni-oldenburg.de/images/dicomlogo.gif)
[Per OFFIS computer science institute](https://dicom.offis.uni-oldenburg.de/en/general/dicom-introduction/) 

DICOM¬Æ ‚Äî Digital Imaging and Communications in Medicine ‚Äî is the international standard for medical images and related information. It defines the formats for medical images that can be exchanged with the data and quality necessary for clinical use.

DICOM¬Æ is implemented in almost every radiology, cardiology imaging, and radiotherapy device (X-ray, CT, MRI, ultrasound, etc.), and increasingly in devices in other medical domains such as ophthalmology and dentistry. With hundreds of thousands of medical imaging devices in use, DICOM¬Æ is one of the most widely deployed healthcare messaging Standards in the world. There are literally billions of DICOM¬Æ images currently in use for clinical care.

Since its first publication in 1993, DICOM¬Æ has revolutionized the practice of radiology, allowing the replacement of X-ray film with a fully digital workflow. Much as the Internet has become the platform for new consumer information applications, DICOM¬Æ has enabled advanced medical imaging applications that have ‚Äúchanged the face of clinical medicine‚Äù. From the emergency department, to cardiac stress testing, to breast cancer detection, DICOM¬Æ is the standard that makes medical imaging work ‚Äî for doctors and for patients.

DICOM¬Æ is recognized by the International Organization for Standardization as the ISO 12052 standard.

## Licensing

&amp;copy; 2024 Databricks, Inc. All rights reserved. The source in this notebook is provided subject to the Databricks License [https://databricks.com/db-license-source].  All included or referenced third party libraries are subject to the licenses set forth below.

| library              | purpose                             | license                       | source                                                  |
|----------------------|-------------------------------------|-------------------------------|---------------------------------------------------------|
| dbx.pixels           | Scale out image processing library  | Databricks                    | https://github.com/databricks-industry-solutions/pixels |
| pydicom              | Python api for DICOM files          | MIT                           | https://github.com/pydicom/pydicom                      |
| python-gdcm          | Install gdcm C++ libraries          | Apache Software License (BSD) | https://github.com/tfmoraes/python-gdcm                 |
| gdcm                 | Parse DICOM files                   | BSD                           | https://sourceforge.net/projects/gdcm                   |
| s3fs                 | Resolve s3:// paths                 | BSD 3-Clause                  | https://github.com/fsspec/s3fs                          |
| pandas               | Pandas UDFs                         | BSD License (BSD-3-Clause)    | https://github.com/pandas-dev/pandas                    |
| OHIF Viewer          | Medical image viewer                | MIT                           | https://github.com/OHIF/Viewers                         |
| MONAILabel           | Intelligent open source image labeling and learning tool | Apache-2.0 license  | https://github.com/Project-MONAI/MONAILabel |
| DICOGNITO            | A library and command line tool for anonymizing DICOM files | MIT  | https://github.com/blairconrad/dicognito |
| FF3                  | FPE - Format Preserving Encryption with FF3 in Python | Apache-2.0 license  | https://github.com/mysto/python-fpe |
| Vista3D              | MONAI Versatile Imaging SegmenTation and Annotation model | Apache-2.0 license (code) - NCLS v1 (model weight) | https://github.com/Project-MONAI/VISTA/tree/main/vista3d |


</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[mrdoob/three.js]]></title>
            <link>https://github.com/mrdoob/three.js</link>
            <guid>https://github.com/mrdoob/three.js</guid>
            <pubDate>Thu, 05 Feb 2026 00:07:34 GMT</pubDate>
            <description><![CDATA[JavaScript 3D Library.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mrdoob/three.js">mrdoob/three.js</a></h1>
            <p>JavaScript 3D Library.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 110,714</p>
            <p>Forks: 36,265</p>
            <p>Stars today: 24 stars today</p>
            <h2>README</h2><pre># three.js

[![NPM Package][npm]][npm-url]
[![Build Size][build-size]][build-size-url]
[![NPM Downloads][npm-downloads]][npmtrends-url]
[![jsDelivr Downloads][jsdelivr-downloads]][jsdelivr-url]
[![Discord][discord]][discord-url]

#### JavaScript 3D library

The aim of the project is to create an easy-to-use, lightweight, cross-browser, general-purpose 3D library. The current builds only include WebGL and WebGPU renderers but SVG and CSS3D renderers are also available as addons.

[Examples](https://threejs.org/examples/) &amp;mdash;
[Docs](https://threejs.org/docs/) &amp;mdash;
[Manual](https://threejs.org/manual/) &amp;mdash;
[Wiki](https://github.com/mrdoob/three.js/wiki) &amp;mdash;
[Migrating](https://github.com/mrdoob/three.js/wiki/Migration-Guide) &amp;mdash;
[Questions](https://stackoverflow.com/questions/tagged/three.js) &amp;mdash;
[Forum](https://discourse.threejs.org/) &amp;mdash;
[Discord](https://discord.gg/56GBJwAnUS)

### Usage

This code creates a scene, a camera, and a geometric cube, and it adds the cube to the scene. It then creates a `WebGL` renderer for the scene and camera, and it adds that viewport to the `document.body` element. Finally, it animates the cube within the scene for the camera.

```javascript
import * as THREE from &#039;three&#039;;

const width = window.innerWidth, height = window.innerHeight;

// init

const camera = new THREE.PerspectiveCamera( 70, width / height, 0.01, 10 );
camera.position.z = 1;

const scene = new THREE.Scene();

const geometry = new THREE.BoxGeometry( 0.2, 0.2, 0.2 );
const material = new THREE.MeshNormalMaterial();

const mesh = new THREE.Mesh( geometry, material );
scene.add( mesh );

const renderer = new THREE.WebGLRenderer( { antialias: true } );
renderer.setSize( width, height );
renderer.setAnimationLoop( animate );
document.body.appendChild( renderer.domElement );

// animation

function animate( time ) {

	mesh.rotation.x = time / 2000;
	mesh.rotation.y = time / 1000;

	renderer.render( scene, camera );

}
```

If everything goes well, you should see [this](https://jsfiddle.net/w43x5Lgh/).

### Cloning this repository

Cloning the repo with all its history results in a ~2 GB download. If you don&#039;t need the whole history you can use the `depth` parameter to significantly reduce download size.

```sh
git clone --depth=1 https://github.com/mrdoob/three.js.git
```

### Change log

[Releases](https://github.com/mrdoob/three.js/releases)


[npm]: https://img.shields.io/npm/v/three
[npm-url]: https://www.npmjs.com/package/three
[build-size]: https://badgen.net/bundlephobia/minzip/three
[build-size-url]: https://bundlephobia.com/result?p=three
[npm-downloads]: https://img.shields.io/npm/dw/three
[npmtrends-url]: https://www.npmtrends.com/three
[jsdelivr-downloads]: https://data.jsdelivr.com/v1/package/npm/three/badge?style=rounded
[jsdelivr-url]: https://www.jsdelivr.com/package/npm/three
[discord]: https://img.shields.io/discord/685241246557667386
[discord-url]: https://discord.gg/56GBJwAnUS
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[FortAwesome/Font-Awesome]]></title>
            <link>https://github.com/FortAwesome/Font-Awesome</link>
            <guid>https://github.com/FortAwesome/Font-Awesome</guid>
            <pubDate>Thu, 05 Feb 2026 00:07:33 GMT</pubDate>
            <description><![CDATA[The iconic SVG, font, and CSS toolkit]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/FortAwesome/Font-Awesome">FortAwesome/Font-Awesome</a></h1>
            <p>The iconic SVG, font, and CSS toolkit</p>
            <p>Language: JavaScript</p>
            <p>Stars: 76,289</p>
            <p>Forks: 12,249</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;h1&gt;&lt;img src=&quot;https://img.fortawesome.com/349cfdf6/fa-free-logo.svg&quot; alt=&quot;Font Awesome Free&quot; width=&quot;50%&quot;&gt;&lt;/h1&gt;

&gt; Version 5 ‚Äì the iconic SVG, font, and CSS framework

The internet&#039;s most popular icon toolkit has been redesigned and built from
scratch. On top of this, features like icon font ligatures, an SVG framework,
official NPM packages for popular frontend libraries like React, and access to
a new CDN.

Not familiar with Font Awesome 5? [Learn
more](https://www.kickstarter.com/projects/232193852/font-awesome-5) about our
successful Kickstarter and plan. You can also **[order Font Awesome
Pro](https://fontawesome.com/pro)** which includes tons more icons directly
from [fontawesome.com](https://fontawesome.com).

## Documentation

Learn how to get started with Font Awesome and then dive deeper into other and advanced topics:

### Using Font Awesome on the Web

* [With SVG with JavaScript](https://fontawesome.com/how-to-use/on-the-web/setup/getting-started?using=svg-with-js)
* [With web fonts with CSS](https://fontawesome.com/how-to-use/on-the-web/setup/getting-started?using=web-fonts-with-css)
* [Upgrading from version 4](https://fontawesome.com/how-to-use/on-the-web/setup/upgrading-from-version-4)
* [Installing Font Awesome with a package manager](https://fontawesome.com/how-to-use/on-the-web/setup/using-package-managers)
* [Downloading + hosting Font Awesome yourself](https://fontawesome.com/how-to-use/on-the-web/setup/hosting-font-awesome-yourself)
* [Performance and security](https://fontawesome.com/how-to-use/performance-and-security)
* [Accessibility](https://fontawesome.com/how-to-use/on-the-web/other-topics/accessibility)
* [Troubleshooting](https://fontawesome.com/how-to-use/on-the-web/other-topics/troubleshooting)

#### Advanced Options &amp; Techniques

* [Using CSS pseudo-elements](https://fontawesome.com/how-to-use/on-the-web/advanced/css-pseudo-elements)
* [SVG sprites](https://fontawesome.com/how-to-use/svg-sprites)
* [The Font Awesome API](https://fontawesome.com/how-to-use/font-awesome-api)
* [SVG symbols](https://fontawesome.com/how-to-use/on-the-web/advanced/svg-symbols)
* [SVG JavaScript Core](https://fontawesome.com/how-to-use/on-the-web/advanced/svg-javascript-core)
* [Server side rendering](https://fontawesome.com/how-to-use/server-side-rendering)

### Using Font Awesome on the Desktop

* [Getting started](https://fontawesome.com/how-to-use/on-the-desktop/setup/getting-started)
* [Upgrading from version 4](https://fontawesome.com/how-to-use/on-the-desktop/setup/upgrading-from-version-4)
* [Using ligatures](https://fontawesome.com/how-to-use/on-the-desktop/referencing-icons/using-ligatures)
* [Using glyphs](https://fontawesome.com/how-to-use/on-the-desktop/referencing-icons/using-glyphs)
* [Troubleshooting](https://fontawesome.com/how-to-use/on-the-desktop/other-topics/troubleshooting)

### Where did Font Awesome 4 (or 3) go?

Now that Font Awesome 5 has been released we are marking version 4 as
end-of-life. We don&#039;t plan on releasing any further versions of the 4.x or 3.x.

Documentation is still available but it&#039;s moved to
[https://fontawesome.com/v4.7.0](https://fontawesome.com/v4.7.0) and
[https://fontawesome.com/v3.2.1](https://fontawesome.com/v3.2.1).

The Git repository for
[v4.7.0](https://github.com/FortAwesome/Font-Awesome/releases/tag/v4.7.0) and
[v3.2.1](https://github.com/FortAwesome/Font-Awesome/releases/tag/v3.2.1) can
be found in our GitHub releases.

## Change log

We&#039;ll keep track of each release in the [CHANGELOG.md](./CHANGELOG.md)

Looking for older versions of Font Awesome? Check the [releases](https://github.com/FortAwesome/Font-Awesome/releases).

## Upgrading

From time-to-time we&#039;ll have special upgrading instructions from one version to the next.

Check out the [UPGRADING.md](./UPGRADING.md) guide when you upgrade your dependencies.

## Code of conduct

We will behave ourselves if you behave yourselves. For more details see our
[CODE_OF_CONDUCT.md](./CODE_OF_CONDUCT.md).

## Contributing

Please read through our [contributing guidelines](./CONTRIBUTING.md).  Included
are directions for opening issues.

## Versioning

Font Awesome will be maintained under the Semantic Versioning guidelines as much as possible. Releases will be numbered
with the following format:

`&lt;major&gt;.&lt;minor&gt;.&lt;patch&gt;`

For more information on SemVer, please visit http://semver.org.

**The major version &quot;5&quot; is part of an umbrella release.  It includes many different types of files and technologies. Therefore
we deviate from normal SemVer in the following ways:**

* Any release may update the design, look-and-feel, or branding of an existing
  icon
* We will never intentionally release a `patch` version update that breaks
  backward compatibility
* A `minor` release **may include backward-incompatible changes** but we will
  write clear upgrading instructions in UPGRADING.md
* A `minor` or `patch` release will never remove icons
* Bug fixes will be addressed as `patch` releases unless they include backward
  incompatibility then they will be `minor` releases

## License

Font Awesome Free is free, open source, and GPL friendly. You can use it for
commercial projects, open source projects, or really almost whatever you want.

- Icons ‚Äî CC BY 4.0 License
  - In the Font Awesome Free download, the CC BY 4.0 license applies to all icons packaged as .svg and .js files types.
- Fonts ‚Äî SIL OFL 1.1 License
  - In the Font Awesome Free download, the SIL OLF license applies to all icons packaged as web and desktop font files.
- Code ‚Äî MIT License
  - In the Font Awesome Free download, the MIT license applies to all non-font and non-icon files.

Attribution is required by MIT, SIL OLF, and CC BY licenses. Downloaded Font
Awesome Free files already contain embedded comments with sufficient
attribution, so you shouldn&#039;t need to do anything additional when using these
files normally.

We&#039;ve kept attribution comments terse, so we ask that you do not actively work
to remove them from files, especially code. They&#039;re a great way for folks to
learn about Font Awesome.

## Team
* [Dave Gandy](https://github.com/davegandy)
* [Travis Chase](https://github.com/supercodepoet)
* [Rob Madole](https://github.com/robmadole)
* [Brian Talbot](https://github.com/talbs)
* [Jory Raphael](https://github.com/sensibleworld)
* [Mike Wilkerson](https://github.com/mlwilkerson)
* [Frances Botsford](https://github.com/frrrances)
* [Trevor Chase](https://github.com/trevorchase)
* [Jason Lundien](https://github.com/jasonlundien)
* [Jason Otero](https://github.com/deathnfudge)
* [Edward Emanuel](https://github.com/ej2)
* [Kelsey Jackson](https://github.com/kelseythejackson)
* [Geremia Taglialatela](https://github.com/tagliala)
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[songquanpeng/one-api]]></title>
            <link>https://github.com/songquanpeng/one-api</link>
            <guid>https://github.com/songquanpeng/one-api</guid>
            <pubDate>Thu, 05 Feb 2026 00:07:32 GMT</pubDate>
            <description><![CDATA[LLM API ÁÆ°ÁêÜ & ÂàÜÂèëÁ≥ªÁªüÔºåÊîØÊåÅ OpenAI„ÄÅAzure„ÄÅAnthropic Claude„ÄÅGoogle Gemini„ÄÅDeepSeek„ÄÅÂ≠óËäÇË±ÜÂåÖ„ÄÅChatGLM„ÄÅÊñáÂøÉ‰∏ÄË®Ä„ÄÅËÆØÈ£ûÊòüÁÅ´„ÄÅÈÄö‰πâÂçÉÈóÆ„ÄÅ360 Êô∫ËÑë„ÄÅËÖæËÆØÊ∑∑ÂÖÉÁ≠â‰∏ªÊµÅÊ®°ÂûãÔºåÁªü‰∏Ä API ÈÄÇÈÖçÔºåÂèØÁî®‰∫é key ÁÆ°ÁêÜ‰∏é‰∫åÊ¨°ÂàÜÂèë„ÄÇÂçïÂèØÊâßË°åÊñá‰ª∂ÔºåÊèê‰æõ Docker ÈïúÂÉèÔºå‰∏ÄÈîÆÈÉ®ÁΩ≤ÔºåÂºÄÁÆ±Âç≥Áî®„ÄÇLLM API management & key redistribution system, unifying multiple providers under a single API. Single binary, Docker-ready, with an English UI.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/songquanpeng/one-api">songquanpeng/one-api</a></h1>
            <p>LLM API ÁÆ°ÁêÜ & ÂàÜÂèëÁ≥ªÁªüÔºåÊîØÊåÅ OpenAI„ÄÅAzure„ÄÅAnthropic Claude„ÄÅGoogle Gemini„ÄÅDeepSeek„ÄÅÂ≠óËäÇË±ÜÂåÖ„ÄÅChatGLM„ÄÅÊñáÂøÉ‰∏ÄË®Ä„ÄÅËÆØÈ£ûÊòüÁÅ´„ÄÅÈÄö‰πâÂçÉÈóÆ„ÄÅ360 Êô∫ËÑë„ÄÅËÖæËÆØÊ∑∑ÂÖÉÁ≠â‰∏ªÊµÅÊ®°ÂûãÔºåÁªü‰∏Ä API ÈÄÇÈÖçÔºåÂèØÁî®‰∫é key ÁÆ°ÁêÜ‰∏é‰∫åÊ¨°ÂàÜÂèë„ÄÇÂçïÂèØÊâßË°åÊñá‰ª∂ÔºåÊèê‰æõ Docker ÈïúÂÉèÔºå‰∏ÄÈîÆÈÉ®ÁΩ≤ÔºåÂºÄÁÆ±Âç≥Áî®„ÄÇLLM API management & key redistribution system, unifying multiple providers under a single API. Single binary, Docker-ready, with an English UI.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 29,515</p>
            <p>Forks: 5,706</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;right&quot;&gt;
   &lt;strong&gt;‰∏≠Êñá&lt;/strong&gt; | &lt;a href=&quot;./README.en.md&quot;&gt;English&lt;/a&gt; | &lt;a href=&quot;./README.ja.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;
&lt;/p&gt;


&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/songquanpeng/one-api&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/songquanpeng/one-api/main/web/default/public/logo.png&quot; width=&quot;150&quot; height=&quot;150&quot; alt=&quot;one-api logo&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

# One API

_‚ú® ÈÄöËøáÊ†áÂáÜÁöÑ OpenAI API Ê†ºÂºèËÆøÈóÆÊâÄÊúâÁöÑÂ§ßÊ®°ÂûãÔºåÂºÄÁÆ±Âç≥Áî® ‚ú®_

&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://raw.githubusercontent.com/songquanpeng/one-api/main/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/songquanpeng/one-api?color=brightgreen&quot; alt=&quot;license&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/songquanpeng/one-api/releases/latest&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/v/release/songquanpeng/one-api?color=brightgreen&amp;include_prereleases&quot; alt=&quot;release&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://hub.docker.com/repository/docker/justsong/one-api&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/docker/pulls/justsong/one-api?color=brightgreen&quot; alt=&quot;docker pull&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/songquanpeng/one-api/releases/latest&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/downloads/songquanpeng/one-api/total?color=brightgreen&amp;include_prereleases&quot; alt=&quot;release&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/songquanpeng/one-api&quot;&gt;
    &lt;img src=&quot;https://goreportcard.com/badge/github.com/songquanpeng/one-api&quot; alt=&quot;GoReportCard&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/songquanpeng/one-api#ÈÉ®ÁΩ≤&quot;&gt;ÈÉ®ÁΩ≤ÊïôÁ®ã&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://github.com/songquanpeng/one-api#‰ΩøÁî®ÊñπÊ≥ï&quot;&gt;‰ΩøÁî®ÊñπÊ≥ï&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://github.com/songquanpeng/one-api/issues&quot;&gt;ÊÑèËßÅÂèçÈ¶à&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://github.com/songquanpeng/one-api#Êà™ÂõæÂ±ïÁ§∫&quot;&gt;Êà™ÂõæÂ±ïÁ§∫&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://openai.justsong.cn/&quot;&gt;Âú®Á∫øÊºîÁ§∫&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://github.com/songquanpeng/one-api#Â∏∏ËßÅÈóÆÈ¢ò&quot;&gt;Â∏∏ËßÅÈóÆÈ¢ò&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://github.com/songquanpeng/one-api#Áõ∏ÂÖ≥È°πÁõÆ&quot;&gt;Áõ∏ÂÖ≥È°πÁõÆ&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://iamazing.cn/page/reward&quot;&gt;ËµûËµèÊîØÊåÅ&lt;/a&gt;
&lt;/p&gt;

&gt; [!NOTE]
&gt; Êú¨È°πÁõÆ‰∏∫ÂºÄÊ∫êÈ°πÁõÆÔºå‰ΩøÁî®ËÄÖÂøÖÈ°ªÂú®ÈÅµÂæ™ OpenAI ÁöÑ[‰ΩøÁî®Êù°Ê¨æ](https://openai.com/policies/terms-of-use)‰ª•Âèä**Ê≥ïÂæãÊ≥ïËßÑ**ÁöÑÊÉÖÂÜµ‰∏ã‰ΩøÁî®Ôºå‰∏çÂæóÁî®‰∫éÈùûÊ≥ïÁî®ÈÄî„ÄÇ
&gt;
&gt; Ê†πÊçÆ[„ÄäÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊúçÂä°ÁÆ°ÁêÜÊöÇË°åÂäûÊ≥ï„Äã](http://www.cac.gov.cn/2023-07/13/c_1690898327029107.htm)ÁöÑË¶ÅÊ±ÇÔºåËØ∑ÂãøÂØπ‰∏≠ÂõΩÂú∞Âå∫ÂÖ¨‰ºóÊèê‰æõ‰∏ÄÂàáÊú™ÁªèÂ§áÊ°àÁöÑÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊúçÂä°„ÄÇ

&gt; [!NOTE]
&gt; Á®≥ÂÆöÁâà / È¢ÑËßàÁâàÈïúÂÉèÂú∞ÂùÄÔºö[justsong/one-api](https://hub.docker.com/repository/docker/justsong/one-api)
&gt; ÊàñËÄÖ [ghcr.io/songquanpeng/one-api](https://github.com/songquanpeng/one-api/pkgs/container/one-api)
&gt;
&gt; alpha ÁâàÈïúÂÉèÂú∞ÂùÄÔºö[justsong/one-api-alpha](https://hub.docker.com/repository/docker/justsong/one-api-alpha)
&gt; ÊàñËÄÖ [ghcr.io/songquanpeng/one-api-alpha](https://github.com/songquanpeng/one-api/pkgs/container/one-api-alpha)

&gt; [!WARNING]
&gt; ‰ΩøÁî® root Áî®Êà∑ÂàùÊ¨°ÁôªÂΩïÁ≥ªÁªüÂêéÔºåÂä°ÂøÖ‰øÆÊîπÈªòËÆ§ÂØÜÁ†Å `123456`ÔºÅ

## ÂäüËÉΩ
1. ÊîØÊåÅÂ§öÁßçÂ§ßÊ®°ÂûãÔºö
   + [x] [OpenAI ChatGPT Á≥ªÂàóÊ®°Âûã](https://platform.openai.com/docs/guides/gpt/chat-completions-api)ÔºàÊîØÊåÅ [Azure OpenAI API](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference)Ôºâ
   + [x] [Anthropic Claude Á≥ªÂàóÊ®°Âûã](https://anthropic.com) (ÊîØÊåÅ AWS Claude)
   + [x] [Google PaLM2/Gemini Á≥ªÂàóÊ®°Âûã](https://developers.generativeai.google)
   + [x] [Mistral Á≥ªÂàóÊ®°Âûã](https://mistral.ai/)
   + [x] [Â≠óËäÇË∑≥Âä®Ë±ÜÂåÖÂ§ßÊ®°ÂûãÔºàÁÅ´Â±±ÂºïÊìéÔºâ](https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&amp;ac=DSASUQY5&amp;rc=2QXCA1VI)
   + [x] [ÁôæÂ∫¶ÊñáÂøÉ‰∏ÄË®ÄÁ≥ªÂàóÊ®°Âûã](https://cloud.baidu.com/doc/WENXINWORKSHOP/index.html)
   + [x] [ÈòøÈáåÈÄö‰πâÂçÉÈóÆÁ≥ªÂàóÊ®°Âûã](https://help.aliyun.com/document_detail/2400395.html)
   + [x] [ËÆØÈ£ûÊòüÁÅ´ËÆ§Áü•Â§ßÊ®°Âûã](https://www.xfyun.cn/doc/spark/Web.html)
   + [x] [Êô∫Ë∞± ChatGLM Á≥ªÂàóÊ®°Âûã](https://bigmodel.cn)
   + [x] [360 Êô∫ËÑë](https://ai.360.cn)
   + [x] [ËÖæËÆØÊ∑∑ÂÖÉÂ§ßÊ®°Âûã](https://cloud.tencent.com/document/product/1729)
   + [x] [Moonshot AI](https://platform.moonshot.cn/)
   + [x] [ÁôæÂ∑ùÂ§ßÊ®°Âûã](https://platform.baichuan-ai.com)
   + [x] [MINIMAX](https://api.minimax.chat/)
   + [x] [Groq](https://wow.groq.com/)
   + [x] [Ollama](https://github.com/ollama/ollama)
   + [x] [Èõ∂‰∏Ä‰∏áÁâ©](https://platform.lingyiwanwu.com/)
   + [x] [Èò∂Ë∑ÉÊòüËæ∞](https://platform.stepfun.com/)
   + [x] [Coze](https://www.coze.com/)
   + [x] [Cohere](https://cohere.com/)
   + [x] [DeepSeek](https://www.deepseek.com/)
   + [x] [Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai/)
   + [x] [DeepL](https://www.deepl.com/)
   + [x] [together.ai](https://www.together.ai/)
   + [x] [novita.ai](https://www.novita.ai/)
   + [x] [Á°ÖÂü∫ÊµÅÂä® SiliconCloud](https://cloud.siliconflow.cn/i/rKXmRobW)
   + [x] [xAI](https://x.ai/)
2. ÊîØÊåÅÈÖçÁΩÆÈïúÂÉè‰ª•Âèä‰ºóÂ§ö[Á¨¨‰∏âÊñπ‰ª£ÁêÜÊúçÂä°](https://iamazing.cn/page/openai-api-third-party-services)„ÄÇ
3. ÊîØÊåÅÈÄöËøá**Ë¥üËΩΩÂùáË°°**ÁöÑÊñπÂºèËÆøÈóÆÂ§ö‰∏™Ê∏†ÈÅì„ÄÇ
4. ÊîØÊåÅ **stream Ê®°Âºè**ÔºåÂèØ‰ª•ÈÄöËøáÊµÅÂºè‰º†ËæìÂÆûÁé∞ÊâìÂ≠óÊú∫ÊïàÊûú„ÄÇ
5. ÊîØÊåÅ**Â§öÊú∫ÈÉ®ÁΩ≤**Ôºå[ËØ¶ËßÅÊ≠§Â§Ñ](#Â§öÊú∫ÈÉ®ÁΩ≤)„ÄÇ
6. ÊîØÊåÅ**‰ª§ÁâåÁÆ°ÁêÜ**ÔºåËÆæÁΩÆ‰ª§ÁâåÁöÑËøáÊúüÊó∂Èó¥„ÄÅÈ¢ùÂ∫¶„ÄÅÂÖÅËÆ∏ÁöÑ IP ËåÉÂõ¥‰ª•ÂèäÂÖÅËÆ∏ÁöÑÊ®°ÂûãËÆøÈóÆ„ÄÇ
7. ÊîØÊåÅ**ÂÖëÊç¢Á†ÅÁÆ°ÁêÜ**ÔºåÊîØÊåÅÊâπÈáèÁîüÊàêÂíåÂØºÂá∫ÂÖëÊç¢Á†ÅÔºåÂèØ‰ΩøÁî®ÂÖëÊç¢Á†Å‰∏∫Ë¥¶Êà∑ËøõË°åÂÖÖÂÄº„ÄÇ
8. ÊîØÊåÅ**Ê∏†ÈÅìÁÆ°ÁêÜ**ÔºåÊâπÈáèÂàõÂª∫Ê∏†ÈÅì„ÄÇ
9. ÊîØÊåÅ**Áî®Êà∑ÂàÜÁªÑ**‰ª•Âèä**Ê∏†ÈÅìÂàÜÁªÑ**ÔºåÊîØÊåÅ‰∏∫‰∏çÂêåÂàÜÁªÑËÆæÁΩÆ‰∏çÂêåÁöÑÂÄçÁéá„ÄÇ
10. ÊîØÊåÅÊ∏†ÈÅì**ËÆæÁΩÆÊ®°ÂûãÂàóË°®**„ÄÇ
11. ÊîØÊåÅ**Êü•ÁúãÈ¢ùÂ∫¶ÊòéÁªÜ**„ÄÇ
12. ÊîØÊåÅ**Áî®Êà∑ÈÇÄËØ∑Â•ñÂä±**„ÄÇ
13. ÊîØÊåÅ‰ª•ÁæéÂÖÉ‰∏∫Âçï‰ΩçÊòæÁ§∫È¢ùÂ∫¶„ÄÇ
14. ÊîØÊåÅÂèëÂ∏ÉÂÖ¨ÂëäÔºåËÆæÁΩÆÂÖÖÂÄºÈìæÊé•ÔºåËÆæÁΩÆÊñ∞Áî®Êà∑ÂàùÂßãÈ¢ùÂ∫¶„ÄÇ
15. ÊîØÊåÅÊ®°ÂûãÊò†Â∞ÑÔºåÈáçÂÆöÂêëÁî®Êà∑ÁöÑËØ∑Ê±ÇÊ®°ÂûãÔºåÂ¶ÇÊó†ÂøÖË¶ÅËØ∑‰∏çË¶ÅËÆæÁΩÆÔºåËÆæÁΩÆ‰πãÂêé‰ºöÂØºËá¥ËØ∑Ê±Ç‰ΩìË¢´ÈáçÊñ∞ÊûÑÈÄ†ËÄåÈùûÁõ¥Êé•ÈÄè‰º†Ôºå‰ºöÂØºËá¥ÈÉ®ÂàÜËøòÊú™Ê≠£ÂºèÊîØÊåÅÁöÑÂ≠óÊÆµÊó†Ê≥ï‰º†ÈÄíÊàêÂäü„ÄÇ
16. ÊîØÊåÅÂ§±Ë¥•Ëá™Âä®ÈáçËØï„ÄÇ
17. ÊîØÊåÅÁªòÂõæÊé•Âè£„ÄÇ
18. ÊîØÊåÅ [Cloudflare AI Gateway](https://developers.cloudflare.com/ai-gateway/providers/openai/)ÔºåÊ∏†ÈÅìËÆæÁΩÆÁöÑ‰ª£ÁêÜÈÉ®ÂàÜÂ°´ÂÜô `https://gateway.ai.cloudflare.com/v1/ACCOUNT_TAG/GATEWAY/openai` Âç≥ÂèØ„ÄÇ
19. ÊîØÊåÅ‰∏∞ÂØåÁöÑ**Ëá™ÂÆö‰πâ**ËÆæÁΩÆÔºå
    1. ÊîØÊåÅËá™ÂÆö‰πâÁ≥ªÁªüÂêçÁß∞Ôºålogo ‰ª•ÂèäÈ°µËÑö„ÄÇ
    2. ÊîØÊåÅËá™ÂÆö‰πâÈ¶ñÈ°µÂíåÂÖ≥‰∫éÈ°µÈù¢ÔºåÂèØ‰ª•ÈÄâÊã©‰ΩøÁî® HTML &amp; Markdown ‰ª£Á†ÅËøõË°åËá™ÂÆö‰πâÔºåÊàñËÄÖ‰ΩøÁî®‰∏Ä‰∏™ÂçïÁã¨ÁöÑÁΩëÈ°µÈÄöËøá iframe ÂµåÂÖ•„ÄÇ
20. ÊîØÊåÅÈÄöËøáÁ≥ªÁªüËÆøÈóÆ‰ª§ÁâåË∞ÉÁî®ÁÆ°ÁêÜ APIÔºåËøõËÄå**Âú®Êó†ÈúÄ‰∫åÂºÄÁöÑÊÉÖÂÜµ‰∏ãÊâ©Â±ïÂíåËá™ÂÆö‰πâ** One API ÁöÑÂäüËÉΩÔºåËØ¶ÊÉÖËØ∑ÂèÇËÄÉÊ≠§Â§Ñ [API ÊñáÊ°£](./docs/API.md)„ÄÇ
21. ÊîØÊåÅ Cloudflare Turnstile Áî®Êà∑Ê†°È™å„ÄÇ
22. ÊîØÊåÅÁî®Êà∑ÁÆ°ÁêÜÔºåÊîØÊåÅ**Â§öÁßçÁî®Êà∑ÁôªÂΩïÊ≥®ÂÜåÊñπÂºè**Ôºö
    + ÈÇÆÁÆ±ÁôªÂΩïÊ≥®ÂÜåÔºàÊîØÊåÅÊ≥®ÂÜåÈÇÆÁÆ±ÁôΩÂêçÂçïÔºâ‰ª•ÂèäÈÄöËøáÈÇÆÁÆ±ËøõË°åÂØÜÁ†ÅÈáçÁΩÆ„ÄÇ
    + ÊîØÊåÅ[È£û‰π¶ÊéàÊùÉÁôªÂΩï](https://open.feishu.cn/document/uAjLw4CM/ukTMukTMukTM/reference/authen-v1/authorize/get)Ôºà[ËøôÈáåÊúâ One API ÁöÑÂÆûÁé∞ÁªÜËäÇÈòêËø∞‰æõÂèÇËÄÉ](https://iamazing.cn/page/feishu-oauth-login)Ôºâ„ÄÇ
    + ÊîØÊåÅ [GitHub ÊéàÊùÉÁôªÂΩï](https://github.com/settings/applications/new)„ÄÇ
    + ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÊéàÊùÉÔºàÈúÄË¶ÅÈ¢ùÂ§ñÈÉ®ÁΩ≤ [WeChat Server](https://github.com/songquanpeng/wechat-server)Ôºâ„ÄÇ
23. ÊîØÊåÅ‰∏ªÈ¢òÂàáÊç¢ÔºåËÆæÁΩÆÁéØÂ¢ÉÂèòÈáè `THEME` Âç≥ÂèØÔºåÈªòËÆ§‰∏∫ `default`ÔºåÊ¨¢Ëøé PR Êõ¥Â§ö‰∏ªÈ¢òÔºåÂÖ∑‰ΩìÂèÇËÄÉ[Ê≠§Â§Ñ](./web/README.md)„ÄÇ
24. ÈÖçÂêà [Message Pusher](https://github.com/songquanpeng/message-pusher) ÂèØÂ∞ÜÊä•Ë≠¶‰ø°ÊÅØÊé®ÈÄÅÂà∞Â§öÁßç App ‰∏ä„ÄÇ

## ÈÉ®ÁΩ≤
### Âü∫‰∫é Docker ËøõË°åÈÉ®ÁΩ≤
```shell
# ‰ΩøÁî® SQLite ÁöÑÈÉ®ÁΩ≤ÂëΩ‰ª§Ôºö
docker run --name one-api -d --restart always -p 3000:3000 -e TZ=Asia/Shanghai -v /home/ubuntu/data/one-api:/data justsong/one-api
# ‰ΩøÁî® MySQL ÁöÑÈÉ®ÁΩ≤ÂëΩ‰ª§ÔºåÂú®‰∏äÈù¢ÁöÑÂü∫Á°Ä‰∏äÊ∑ªÂä† `-e SQL_DSN=&quot;root:123456@tcp(localhost:3306)/oneapi&quot;`ÔºåËØ∑Ëá™Ë°å‰øÆÊîπÊï∞ÊçÆÂ∫ìËøûÊé•ÂèÇÊï∞Ôºå‰∏çÊ∏ÖÊ•öÂ¶Ç‰Ωï‰øÆÊîπËØ∑ÂèÇËßÅ‰∏ãÈù¢ÁéØÂ¢ÉÂèòÈáè‰∏ÄËäÇ„ÄÇ
# ‰æãÂ¶ÇÔºö
docker run --name one-api -d --restart always -p 3000:3000 -e SQL_DSN=&quot;root:123456@tcp(localhost:3306)/oneapi&quot; -e TZ=Asia/Shanghai -v /home/ubuntu/data/one-api:/data justsong/one-api
```

ÂÖ∂‰∏≠Ôºå`-p 3000:3000` ‰∏≠ÁöÑÁ¨¨‰∏Ä‰∏™ `3000` ÊòØÂÆø‰∏ªÊú∫ÁöÑÁ´ØÂè£ÔºåÂèØ‰ª•Ê†πÊçÆÈúÄË¶ÅËøõË°å‰øÆÊîπ„ÄÇ

Êï∞ÊçÆÂíåÊó•ÂøóÂ∞Ü‰ºö‰øùÂ≠òÂú®ÂÆø‰∏ªÊú∫ÁöÑ `/home/ubuntu/data/one-api` ÁõÆÂΩïÔºåËØ∑Á°Æ‰øùËØ•ÁõÆÂΩïÂ≠òÂú®‰∏îÂÖ∑ÊúâÂÜôÂÖ•ÊùÉÈôêÔºåÊàñËÄÖÊõ¥Êîπ‰∏∫ÂêàÈÄÇÁöÑÁõÆÂΩï„ÄÇ

Â¶ÇÊûúÂêØÂä®Â§±Ë¥•ÔºåËØ∑Ê∑ªÂä† `--privileged=true`ÔºåÂÖ∑‰ΩìÂèÇËÄÉ https://github.com/songquanpeng/one-api/issues/482 „ÄÇ

Â¶ÇÊûú‰∏äÈù¢ÁöÑÈïúÂÉèÊó†Ê≥ïÊãâÂèñÔºåÂèØ‰ª•Â∞ùËØï‰ΩøÁî® GitHub ÁöÑ Docker ÈïúÂÉèÔºåÂ∞Ü‰∏äÈù¢ÁöÑ `justsong/one-api` ÊõøÊç¢‰∏∫ `ghcr.io/songquanpeng/one-api` Âç≥ÂèØ„ÄÇ

Â¶ÇÊûú‰Ω†ÁöÑÂπ∂ÂèëÈáèËæÉÂ§ßÔºå**Âä°ÂøÖ**ËÆæÁΩÆ `SQL_DSN`ÔºåËØ¶ËßÅ‰∏ãÈù¢[ÁéØÂ¢ÉÂèòÈáè](#ÁéØÂ¢ÉÂèòÈáè)‰∏ÄËäÇ„ÄÇ

Êõ¥Êñ∞ÂëΩ‰ª§Ôºö`docker run --rm -v /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower -cR`

Nginx ÁöÑÂèÇËÄÉÈÖçÁΩÆÔºö
```
server{
   server_name openai.justsong.cn;  # ËØ∑Ê†πÊçÆÂÆûÈôÖÊÉÖÂÜµ‰øÆÊîπ‰Ω†ÁöÑÂüüÂêç

   location / {
          client_max_body_size  64m;
          proxy_http_version 1.1;
          proxy_pass http://localhost:3000;  # ËØ∑Ê†πÊçÆÂÆûÈôÖÊÉÖÂÜµ‰øÆÊîπ‰Ω†ÁöÑÁ´ØÂè£
          proxy_set_header Host $host;
          proxy_set_header X-Forwarded-For $remote_addr;
          proxy_cache_bypass $http_upgrade;
          proxy_set_header Accept-Encoding gzip;
          proxy_read_timeout 300s;  # GPT-4 ÈúÄË¶ÅËæÉÈïøÁöÑË∂ÖÊó∂Êó∂Èó¥ÔºåËØ∑Ëá™Ë°åË∞ÉÊï¥
   }
}
```

‰πãÂêé‰ΩøÁî® Let&#039;s Encrypt ÁöÑ certbot ÈÖçÁΩÆ HTTPSÔºö
```bash
# Ubuntu ÂÆâË£Ö certbotÔºö
sudo snap install --classic certbot
sudo ln -s /snap/bin/certbot /usr/bin/certbot
# ÁîüÊàêËØÅ‰π¶ &amp; ‰øÆÊîπ Nginx ÈÖçÁΩÆ
sudo certbot --nginx
# Ê†πÊçÆÊåáÁ§∫ËøõË°åÊìç‰Ωú
# ÈáçÂêØ Nginx
sudo service nginx restart
```

ÂàùÂßãË¥¶Âè∑Áî®Êà∑Âêç‰∏∫ `root`ÔºåÂØÜÁ†Å‰∏∫ `123456`„ÄÇ

### ÈÄöËøáÂÆùÂ°îÈù¢ÊùøËøõË°å‰∏ÄÈîÆÈÉ®ÁΩ≤
1. ÂÆâË£ÖÂÆùÂ°îÈù¢Êùø9.2.0Âèä‰ª•‰∏äÁâàÊú¨ÔºåÂâçÂæÄ [ÂÆùÂ°îÈù¢Êùø](https://www.bt.cn/new/download.html?r=dk_oneapi) ÂÆòÁΩëÔºåÈÄâÊã©Ê≠£ÂºèÁâàÁöÑËÑöÊú¨‰∏ãËΩΩÂÆâË£ÖÔºõ
2. ÂÆâË£ÖÂêéÁôªÂΩïÂÆùÂ°îÈù¢ÊùøÔºåÂú®Â∑¶‰æßËèúÂçïÊ†è‰∏≠ÁÇπÂáª `Docker`ÔºåÈ¶ñÊ¨°ËøõÂÖ•‰ºöÊèêÁ§∫ÂÆâË£Ö `Docker` ÊúçÂä°ÔºåÁÇπÂáªÁ´ãÂç≥ÂÆâË£ÖÔºåÊåâÊèêÁ§∫ÂÆåÊàêÂÆâË£ÖÔºõ
3. ÂÆâË£ÖÂÆåÊàêÂêéÂú®Â∫îÁî®ÂïÜÂ∫ó‰∏≠ÊêúÁ¥¢ `One-API`ÔºåÁÇπÂáªÂÆâË£ÖÔºåÈÖçÁΩÆÂüüÂêçÁ≠âÂü∫Êú¨‰ø°ÊÅØÂç≥ÂèØÂÆåÊàêÂÆâË£ÖÔºõ

### Âü∫‰∫é Docker Compose ËøõË°åÈÉ®ÁΩ≤

&gt; ‰ªÖÂêØÂä®ÊñπÂºè‰∏çÂêåÔºåÂèÇÊï∞ËÆæÁΩÆ‰∏çÂèòÔºåËØ∑ÂèÇËÄÉÂü∫‰∫é Docker ÈÉ®ÁΩ≤ÈÉ®ÂàÜ

```shell
# ÁõÆÂâçÊîØÊåÅ MySQL ÂêØÂä®ÔºåÊï∞ÊçÆÂ≠òÂÇ®Âú® ./data/mysql Êñá‰ª∂Â§πÂÜÖ
docker-compose up -d

# Êü•ÁúãÈÉ®ÁΩ≤Áä∂ÊÄÅ
docker-compose ps
```

### ÊâãÂä®ÈÉ®ÁΩ≤
1. ‰ªé [GitHub Releases](https://github.com/songquanpeng/one-api/releases/latest) ‰∏ãËΩΩÂèØÊâßË°åÊñá‰ª∂ÊàñËÄÖ‰ªéÊ∫êÁ†ÅÁºñËØëÔºö
   ```shell
   git clone https://github.com/songquanpeng/one-api.git

   # ÊûÑÂª∫ÂâçÁ´Ø
   cd one-api/web/default
   npm install
   npm run build

   # ÊûÑÂª∫ÂêéÁ´Ø
   cd ../..
   go mod download
   go build -ldflags &quot;-s -w&quot; -o one-api
   ````
2. ËøêË°åÔºö
   ```shell
   chmod u+x one-api
   ./one-api --port 3000 --log-dir ./logs
   ```
3. ËÆøÈóÆ [http://localhost:3000/](http://localhost:3000/) Âπ∂ÁôªÂΩï„ÄÇÂàùÂßãË¥¶Âè∑Áî®Êà∑Âêç‰∏∫ `root`ÔºåÂØÜÁ†Å‰∏∫ `123456`„ÄÇ

Êõ¥Âä†ËØ¶ÁªÜÁöÑÈÉ®ÁΩ≤ÊïôÁ®ã[ÂèÇËßÅÊ≠§Â§Ñ](https://iamazing.cn/page/how-to-deploy-a-website)„ÄÇ

### Â§öÊú∫ÈÉ®ÁΩ≤
1. ÊâÄÊúâÊúçÂä°Âô® `SESSION_SECRET` ËÆæÁΩÆ‰∏ÄÊ†∑ÁöÑÂÄº„ÄÇ
2. ÂøÖÈ°ªËÆæÁΩÆ `SQL_DSN`Ôºå‰ΩøÁî® MySQL Êï∞ÊçÆÂ∫ìËÄåÈùû SQLiteÔºåÊâÄÊúâÊúçÂä°Âô®ËøûÊé•Âêå‰∏Ä‰∏™Êï∞ÊçÆÂ∫ì„ÄÇ
3. ÊâÄÊúâ‰ªéÊúçÂä°Âô®ÂøÖÈ°ªËÆæÁΩÆ `NODE_TYPE` ‰∏∫ `slave`Ôºå‰∏çËÆæÁΩÆÂàôÈªòËÆ§‰∏∫‰∏ªÊúçÂä°Âô®„ÄÇ
4. ËÆæÁΩÆ `SYNC_FREQUENCY` ÂêéÊúçÂä°Âô®Â∞ÜÂÆöÊúü‰ªéÊï∞ÊçÆÂ∫ìÂêåÊ≠•ÈÖçÁΩÆÔºåÂú®‰ΩøÁî®ËøúÁ®ãÊï∞ÊçÆÂ∫ìÁöÑÊÉÖÂÜµ‰∏ãÔºåÊé®ËçêËÆæÁΩÆËØ•È°πÂπ∂ÂêØÁî® RedisÔºåÊó†ËÆ∫‰∏ª‰ªé„ÄÇ
5. ‰ªéÊúçÂä°Âô®ÂèØ‰ª•ÈÄâÊã©ËÆæÁΩÆ `FRONTEND_BASE_URL`Ôºå‰ª•ÈáçÂÆöÂêëÈ°µÈù¢ËØ∑Ê±ÇÂà∞‰∏ªÊúçÂä°Âô®„ÄÇ
6. ‰ªéÊúçÂä°Âô®‰∏ä**ÂàÜÂà´**Ë£ÖÂ•Ω RedisÔºåËÆæÁΩÆÂ•Ω `REDIS_CONN_STRING`ÔºåËøôÊ†∑ÂèØ‰ª•ÂÅöÂà∞Âú®ÁºìÂ≠òÊú™ËøáÊúüÁöÑÊÉÖÂÜµ‰∏ãÊï∞ÊçÆÂ∫ìÈõ∂ËÆøÈóÆÔºåÂèØ‰ª•ÂáèÂ∞ëÂª∂ËøüÔºàRedis ÈõÜÁæ§ÊàñËÄÖÂì®ÂÖµÊ®°ÂºèÁöÑÊîØÊåÅËØ∑ÂèÇËÄÉÁéØÂ¢ÉÂèòÈáèËØ¥ÊòéÔºâ„ÄÇ
7. Â¶ÇÊûú‰∏ªÊúçÂä°Âô®ËÆøÈóÆÊï∞ÊçÆÂ∫ìÂª∂Ëøü‰πüÊØîËæÉÈ´òÔºåÂàô‰πüÈúÄË¶ÅÂêØÁî® RedisÔºåÂπ∂ËÆæÁΩÆ `SYNC_FREQUENCY`Ôºå‰ª•ÂÆöÊúü‰ªéÊï∞ÊçÆÂ∫ìÂêåÊ≠•ÈÖçÁΩÆ„ÄÇ

ÁéØÂ¢ÉÂèòÈáèÁöÑÂÖ∑‰Ωì‰ΩøÁî®ÊñπÊ≥ïËØ¶ËßÅ[Ê≠§Â§Ñ](#ÁéØÂ¢ÉÂèòÈáè)„ÄÇ

### ÂÆùÂ°îÈÉ®ÁΩ≤ÊïôÁ®ã

ËØ¶ËßÅ [#175](https://github.com/songquanpeng/one-api/issues/175)„ÄÇ

Â¶ÇÊûúÈÉ®ÁΩ≤ÂêéËÆøÈóÆÂá∫Áé∞Á©∫ÁôΩÈ°µÈù¢ÔºåËØ¶ËßÅ [#97](https://github.com/songquanpeng/one-api/issues/97)„ÄÇ

### ÈÉ®ÁΩ≤Á¨¨‰∏âÊñπÊúçÂä°ÈÖçÂêà One API ‰ΩøÁî®
&gt; Ê¨¢Ëøé PR Ê∑ªÂä†Êõ¥Â§öÁ§∫‰æã„ÄÇ

#### ChatGPT Next Web
È°πÁõÆ‰∏ªÈ°µÔºöhttps://github.com/Yidadaa/ChatGPT-Next-Web

```bash
docker run --name chat-next-web -d -p 3001:3000 yidadaa/chatgpt-next-web
```

Ê≥®ÊÑè‰øÆÊîπÁ´ØÂè£Âè∑Ôºå‰πãÂêéÂú®È°µÈù¢‰∏äËÆæÁΩÆÊé•Âè£Âú∞ÂùÄÔºà‰æãÂ¶ÇÔºöhttps://openai.justsong.cn/ ÔºâÂíå API Key Âç≥ÂèØ„ÄÇ

#### ChatGPT Web
È°πÁõÆ‰∏ªÈ°µÔºöhttps://github.com/Chanzhaoyu/chatgpt-web

```bash
docker run --name chatgpt-web -d -p 3002:3002 -e OPENAI_API_BASE_URL=https://openai.justsong.cn -e OPENAI_API_KEY=sk-xxx chenzhaoyu94/chatgpt-web
```

Ê≥®ÊÑè‰øÆÊîπÁ´ØÂè£Âè∑„ÄÅ`OPENAI_API_BASE_URL` Âíå `OPENAI_API_KEY`„ÄÇ

#### QChatGPT - QQÊú∫Âô®‰∫∫
È°πÁõÆ‰∏ªÈ°µÔºöhttps://github.com/RockChinQ/QChatGPT

Ê†πÊçÆ[ÊñáÊ°£](https://qchatgpt.rockchin.top)ÂÆåÊàêÈÉ®ÁΩ≤ÂêéÔºåÂú® `data/provider.json`ËÆæÁΩÆ`requester.openai-chat-completions.base-url`‰∏∫ One API ÂÆû‰æãÂú∞ÂùÄÔºåÂπ∂Â°´ÂÜô API Key Âà∞ `keys.openai` ÁªÑ‰∏≠ÔºåËÆæÁΩÆ `model` ‰∏∫Ë¶Å‰ΩøÁî®ÁöÑÊ®°ÂûãÂêçÁß∞„ÄÇ

ËøêË°åÊúüÈó¥ÂèØ‰ª•ÈÄöËøá`!model`ÂëΩ‰ª§Êü•Áúã„ÄÅÂàáÊç¢ÂèØÁî®Ê®°Âûã„ÄÇ

### ÈÉ®ÁΩ≤Âà∞Á¨¨‰∏âÊñπÂπ≥Âè∞
&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ÈÉ®ÁΩ≤Âà∞ Sealos &lt;/strong&gt;&lt;/summary&gt;
&lt;div&gt;

&gt; Sealos ÁöÑÊúçÂä°Âô®Âú®ÂõΩÂ§ñÔºå‰∏çÈúÄË¶ÅÈ¢ùÂ§ñÂ§ÑÁêÜÁΩëÁªúÈóÆÈ¢òÔºåÊîØÊåÅÈ´òÂπ∂Âèë &amp; Âä®ÊÄÅ‰º∏Áº©„ÄÇ

ÁÇπÂáª‰ª•‰∏ãÊåâÈíÆ‰∏ÄÈîÆÈÉ®ÁΩ≤ÔºàÈÉ®ÁΩ≤ÂêéËÆøÈóÆÂá∫Áé∞ 404 ËØ∑Á≠âÂæÖ 3~5 ÂàÜÈíüÔºâÔºö

[![Deploy-on-Sealos.svg](https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg)](https://cloud.sealos.io/?openapp=system-fastdeploy?templateName=one-api)

&lt;/div&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ÈÉ®ÁΩ≤Âà∞ Zeabur&lt;/strong&gt;&lt;/summary&gt;
&lt;div&gt;

&gt; Zeabur ÁöÑÊúçÂä°Âô®Âú®ÂõΩÂ§ñÔºåËá™Âä®Ëß£ÂÜ≥‰∫ÜÁΩëÁªúÁöÑÈóÆÈ¢òÔºåÂêåÊó∂ÂÖçË¥πÁöÑÈ¢ùÂ∫¶‰πüË∂≥Â§ü‰∏™‰∫∫‰ΩøÁî®

[![Deploy on Zeabur](https://zeabur.com/button.svg)](https://zeabur.com/templates/7Q0KO3)

1. È¶ñÂÖà fork ‰∏Ä‰ªΩ‰ª£Á†Å„ÄÇ
2. ËøõÂÖ• [Zeabur](https://zeabur.com?referralCode=songquanpeng)ÔºåÁôªÂΩïÔºåËøõÂÖ•ÊéßÂà∂Âè∞„ÄÇ
3. Êñ∞Âª∫‰∏Ä‰∏™ ProjectÔºåÂú® Service -&gt; Add Service ÈÄâÊã© MarketplaceÔºåÈÄâÊã© MySQLÔºåÂπ∂ËÆ∞‰∏ãËøûÊé•ÂèÇÊï∞ÔºàÁî®Êà∑Âêç„ÄÅÂØÜÁ†Å„ÄÅÂú∞ÂùÄ„ÄÅÁ´ØÂè£Ôºâ„ÄÇ
4. Â§çÂà∂ÈìæÊé•ÂèÇÊï∞ÔºåËøêË°å ```create database `one-api` ``` ÂàõÂª∫Êï∞ÊçÆÂ∫ì„ÄÇ
5. ÁÑ∂ÂêéÂú® Service -&gt; Add ServiceÔºåÈÄâÊã© GitÔºàÁ¨¨‰∏ÄÊ¨°‰ΩøÁî®ÈúÄË¶ÅÂÖàÊéàÊùÉÔºâÔºåÈÄâÊã©‰Ω† fork ÁöÑ‰ªìÂ∫ì„ÄÇ
6. Deploy ‰ºöËá™Âä®ÂºÄÂßãÔºåÂÖàÂèñÊ∂à„ÄÇËøõÂÖ•‰∏ãÊñπ VariableÔºåÊ∑ªÂä†‰∏Ä‰∏™ `PORT`ÔºåÂÄº‰∏∫ `3000`ÔºåÂÜçÊ∑ªÂä†‰∏Ä‰∏™ `SQL_DSN`ÔºåÂÄº‰∏∫ `&lt;username&gt;:&lt;password&gt;@tcp(&lt;addr&gt;:&lt;port&gt;)/one-api` ÔºåÁÑ∂Âêé‰øùÂ≠ò„ÄÇ Ê≥®ÊÑèÂ¶ÇÊûú‰∏çÂ°´ÂÜô `SQL_DSN`ÔºåÊï∞ÊçÆÂ∞ÜÊó†Ê≥ïÊåÅ‰πÖÂåñÔºåÈáçÊñ∞ÈÉ®ÁΩ≤ÂêéÊï∞ÊçÆ‰ºö‰∏¢Â§±„ÄÇ
7. ÈÄâÊã© Redeploy„ÄÇ
8. ËøõÂÖ•‰∏ãÊñπ DomainsÔºåÈÄâÊã©‰∏Ä‰∏™ÂêàÈÄÇÁöÑÂüüÂêçÂâçÁºÄÔºåÂ¶Ç &quot;my-one-api&quot;ÔºåÊúÄÁªàÂüüÂêç‰∏∫ &quot;my-one-api.zeabur.app&quot;Ôºå‰πüÂèØ‰ª• CNAME Ëá™Â∑±ÁöÑÂüüÂêç„ÄÇ
9. Á≠âÂæÖÈÉ®ÁΩ≤ÂÆåÊàêÔºåÁÇπÂáªÁîüÊàêÁöÑÂüüÂêçËøõÂÖ• One API„ÄÇ

&lt;/div&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ÈÉ®ÁΩ≤Âà∞ Render&lt;/strong&gt;&lt;/summary&gt;
&lt;div&gt;

&gt; Render Êèê‰æõÂÖçË¥πÈ¢ùÂ∫¶ÔºåÁªëÂç°ÂêéÂèØ‰ª•Ëøõ‰∏ÄÊ≠•ÊèêÂçáÈ¢ùÂ∫¶

Render ÂèØ‰ª•Áõ¥Êé•ÈÉ®ÁΩ≤ docker ÈïúÂÉèÔºå‰∏çÈúÄË¶Å fork ‰ªìÂ∫ìÔºöhttps://dashboard.render.com

&lt;/div&gt;
&lt;/details&gt;

## ÈÖçÁΩÆ
Á≥ªÁªüÊú¨Ë∫´ÂºÄÁÆ±Âç≥Áî®„ÄÇ

‰Ω†ÂèØ‰ª•ÈÄöËøáËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÊàñËÄÖÂëΩ‰ª§Ë°åÂèÇÊï∞ËøõË°åÈÖçÁΩÆ„ÄÇ

Á≠âÂà∞Á≥ªÁªüÂêØÂä®ÂêéÔºå‰ΩøÁî® `root` Áî®Êà∑ÁôªÂΩïÁ≥ªÁªüÂπ∂ÂÅöËøõ‰∏ÄÊ≠•ÁöÑÈÖçÁΩÆ„ÄÇ

**Note**ÔºöÂ¶ÇÊûú‰Ω†‰∏çÁü•ÈÅìÊüê‰∏™ÈÖçÁΩÆÈ°πÁöÑÂê´‰πâÔºåÂèØ‰ª•‰∏¥Êó∂Âà†ÊéâÂÄº‰ª•ÁúãÂà∞Ëøõ‰∏ÄÊ≠•ÁöÑÊèêÁ§∫ÊñáÂ≠ó„ÄÇ

## ‰ΩøÁî®ÊñπÊ≥ï
Âú®`Ê∏†ÈÅì`È°µÈù¢‰∏≠Ê∑ªÂä†‰Ω†ÁöÑ API KeyÔºå‰πãÂêéÂú®`‰ª§Áâå`È°µÈù¢‰∏≠Êñ∞Â¢ûËÆøÈóÆ‰ª§Áâå„ÄÇ

‰πãÂêéÂ∞±ÂèØ‰ª•‰ΩøÁî®‰Ω†ÁöÑ‰ª§ÁâåËÆøÈóÆ One API ‰∫ÜÔºå‰ΩøÁî®ÊñπÂºè‰∏é [OpenAI API](https://platform.openai.com/docs/api-reference/introduction) ‰∏ÄËá¥„ÄÇ

‰Ω†ÈúÄË¶ÅÂú®ÂêÑÁßçÁî®Âà∞ OpenAI API ÁöÑÂú∞ÊñπËÆæÁΩÆ API Base ‰∏∫‰Ω†ÁöÑ One API ÁöÑÈÉ®ÁΩ≤Âú∞ÂùÄÔºå‰æãÂ¶ÇÔºö`https://openai.justsong.cn`ÔºåAPI Key Âàô‰∏∫‰Ω†Âú® One API ‰∏≠ÁîüÊàêÁöÑ‰ª§Áâå„ÄÇ

Ê≥®ÊÑèÔºåÂÖ∑‰ΩìÁöÑ API Base ÁöÑÊ†ºÂºèÂèñÂÜ≥‰∫é‰Ω†ÊâÄ‰ΩøÁî®ÁöÑÂÆ¢Êà∑Á´Ø„ÄÇ

‰æãÂ¶ÇÂØπ‰∫é OpenAI ÁöÑÂÆòÊñπÂ∫ìÔºö
```bash
OPENAI_API_KEY=&quot;sk-xxxxxx&quot;
OPENAI_API_BASE=&quot;https://&lt;HOST&gt;:&lt;PORT&gt;/v1&quot;
```

```mermaid
graph LR
    A(Áî®Êà∑)
    A ---&gt;|‰ΩøÁî® One API ÂàÜÂèëÁöÑ key ËøõË°åËØ∑Ê±Ç| B(One API)
    B --&gt;|‰∏≠ÁªßËØ∑Ê±Ç| C(OpenAI)
    B --&gt;|‰∏≠ÁªßËØ∑Ê±Ç| D(Azure)
    B --&gt;|‰∏≠ÁªßËØ∑Ê±Ç| E(ÂÖ∂‰ªñ OpenAI API Ê†ºÂºè‰∏ãÊ∏∏Ê∏†ÈÅì)
    B --&gt;|‰∏≠ÁªßÂπ∂‰øÆÊîπËØ∑Ê±Ç‰ΩìÂíåËøîÂõû‰Ωì| F(Èùû OpenAI API Ê†ºÂºè‰∏ãÊ∏∏Ê∏†ÈÅì)
```

ÂèØ‰ª•ÈÄöËøáÂú®‰ª§ÁâåÂêéÈù¢Ê∑ªÂä†Ê∏†ÈÅì ID ÁöÑÊñπÂºèÊåáÂÆö‰ΩøÁî®Âì™‰∏Ä‰∏™Ê∏†ÈÅìÂ§ÑÁêÜÊú¨Ê¨°ËØ∑Ê±ÇÔºå‰æãÂ¶ÇÔºö`Authorization: Bearer ONE_API_KEY-CHANNEL_ID`„ÄÇ
Ê≥®ÊÑèÔºåÈúÄË¶ÅÊòØÁÆ°ÁêÜÂëòÁî®Êà∑ÂàõÂª∫ÁöÑ‰ª§ÁâåÊâçËÉΩÊåáÂÆöÊ∏†ÈÅì ID„ÄÇ

‰∏çÂä†ÁöÑËØùÂ∞Ü‰ºö‰ΩøÁî®Ë¥üËΩΩÂùáË°°ÁöÑÊñπÂºè‰ΩøÁî®Â§ö‰∏™Ê∏†ÈÅì„ÄÇ

### ÁéØÂ¢ÉÂèòÈáè
&gt; One API ÊîØÊåÅ‰ªé `.env` Êñá‰ª∂‰∏≠ËØªÂèñÁéØÂ¢ÉÂèòÈáèÔºåËØ∑ÂèÇÁÖß `.env.example` Êñá‰ª∂Ôºå‰ΩøÁî®Êó∂ËØ∑Â∞ÜÂÖ∂ÈáçÂëΩÂêç‰∏∫ `.env`„ÄÇ
1. `REDIS_CONN_STRING`ÔºöËÆæÁΩÆ‰πãÂêéÂ∞Ü‰ΩøÁî® Redis ‰Ωú‰∏∫ÁºìÂ≠ò‰ΩøÁî®„ÄÇ
   + ‰æãÂ≠êÔºö`REDIS_CONN_STRING=redis://default:redispw@localhost:49153`
   + Â¶ÇÊûúÊï∞ÊçÆÂ∫ìËÆøÈóÆÂª∂ËøüÂæà‰ΩéÔºåÊ≤°ÊúâÂøÖË¶ÅÂêØÁî® RedisÔºåÂêØÁî®ÂêéÂèçËÄå‰ºöÂá∫Áé∞Êï∞ÊçÆÊªûÂêéÁöÑÈóÆÈ¢ò„ÄÇ
   + Â¶ÇÊûúÈúÄË¶Å‰ΩøÁî®Âì®ÂÖµÊàñËÄÖÈõÜÁæ§Ê®°ÂºèÔºö
     + ÂàôÈúÄË¶ÅÊääËØ•ÁéØÂ¢ÉÂèòÈáèËÆæÁΩÆ‰∏∫ËäÇÁÇπÂàóË°®Ôºå‰æãÂ¶ÇÔºö`localhost:49153,localhost:49154,localhost:49155`„ÄÇ
     + Èô§Ê≠§‰πãÂ§ñËøòÈúÄË¶ÅËÆæÁΩÆ‰ª•‰∏ãÁéØÂ¢ÉÂèòÈáèÔºö
       + `REDIS_PASSWORD`ÔºöRedis ÈõÜÁæ§ÊàñËÄÖÂì®ÂÖµÊ®°Âºè‰∏ãÁöÑÂØÜÁ†ÅËÆæÁΩÆ„ÄÇ
       + `REDIS_MASTER_NAME`ÔºöRedis Âì®ÂÖµÊ®°Âºè‰∏ã‰∏ªËäÇÁÇπÁöÑÂêçÁß∞„ÄÇ
2. `SESSION_SECRET`ÔºöËÆæÁΩÆ‰πãÂêéÂ∞Ü‰ΩøÁî®Âõ∫ÂÆöÁöÑ‰ºöËØùÂØÜÈí•ÔºåËøôÊ†∑Á≥ªÁªüÈáçÊñ∞ÂêØÂä®ÂêéÂ∑≤ÁôªÂΩïÁî®Êà∑ÁöÑ cookie Â∞Ü‰æùÊóßÊúâÊïà„ÄÇ
   + ‰æãÂ≠êÔºö`SESSION_SECRET=random_string`
3. `SQL_DSN`ÔºöËÆæÁΩÆ‰πãÂêéÂ∞Ü‰ΩøÁî®ÊåáÂÆöÊï∞ÊçÆÂ∫ìËÄåÈùû SQLiteÔºåËØ∑‰ΩøÁî® MySQL Êàñ PostgreSQL„ÄÇ
   + ‰æãÂ≠êÔºö
     + MySQLÔºö`SQL_DSN=root:123456@tcp(localhost:3306)/oneapi`
     + PostgreSQLÔºö`SQL_DSN=postgres://postgres:123456@localhost:5432/oneapi`ÔºàÈÄÇÈÖç‰∏≠ÔºåÊ¨¢ËøéÂèçÈ¶àÔºâ
   + Ê≥®ÊÑèÈúÄË¶ÅÊèêÂâçÂª∫Á´ãÊï∞ÊçÆÂ∫ì `oneapi`ÔºåÊó†ÈúÄÊâãÂä®Âª∫Ë°®ÔºåÁ®ãÂ∫èÂ∞ÜËá™Âä®Âª∫Ë°®„ÄÇ
   + Â¶ÇÊûú‰ΩøÁî®Êú¨Âú∞Êï∞ÊçÆÂ∫ìÔºöÈÉ®ÁΩ≤ÂëΩ‰ª§ÂèØÊ∑ªÂä† `--network=&quot;host&quot;` ‰ª•‰ΩøÂæóÂÆπÂô®ÂÜÖÁöÑÁ®ãÂ∫èÂèØ‰ª•ËÆøÈóÆÂà∞ÂÆø‰∏ªÊú∫‰∏äÁöÑ MySQL„ÄÇ
   + Â¶ÇÊûú‰ΩøÁî®‰∫ëÊï∞ÊçÆÂ∫ìÔºöÂ¶ÇÊûú‰∫ëÊúçÂä°Âô®ÈúÄË¶ÅÈ™åËØÅË∫´‰ªΩÔºåÈúÄË¶ÅÂú®ËøûÊé•ÂèÇÊï∞‰∏≠Ê∑ªÂä† `?tls=skip-verify`„ÄÇ
   + ËØ∑Ê†πÊçÆ‰Ω†ÁöÑÊï∞ÊçÆÂ∫ìÈÖçÁΩÆ‰øÆÊîπ‰∏ãÂàóÂèÇÊï∞ÔºàÊàñËÄÖ‰øùÊåÅÈªòËÆ§ÂÄºÔºâÔºö
     + `SQL_MAX_IDLE_CONNS`ÔºöÊúÄÂ§ßÁ©∫Èó≤ËøûÊé•Êï∞ÔºåÈªòËÆ§‰∏∫ `100`„ÄÇ
     + `SQL_MAX_OPEN_CONNS`ÔºöÊúÄÂ§ßÊâìÂºÄËøûÊé•Êï∞ÔºåÈªòËÆ§‰∏∫ `1000`„ÄÇ
       + Â¶ÇÊûúÊä•Èîô `Error 1040: Too many connections`ÔºåËØ∑ÈÄÇÂΩìÂáèÂ∞èËØ•ÂÄº„ÄÇ
     + `SQL_CONN_MAX_LIFETIME`ÔºöËøûÊé•ÁöÑÊúÄÂ§ßÁîüÂëΩÂë®ÊúüÔºåÈªòËÆ§‰∏∫ `60`ÔºåÂçï‰ΩçÂàÜÈíü„ÄÇ
4. `LOG_SQL_DSN`ÔºöËÆæÁΩÆ‰πãÂêéÂ∞Ü‰∏∫ `logs` Ë°®‰ΩøÁî®Áã¨Á´ãÁöÑÊï∞ÊçÆÂ∫ìÔºåËØ∑‰ΩøÁî® MySQL Êàñ PostgreSQL„ÄÇ
5. `FRONTEND_BASE_URL`ÔºöËÆæÁΩÆ‰πãÂêéÂ∞ÜÈáçÂÆöÂêëÈ°µÈù¢ËØ∑Ê±ÇÂà∞ÊåáÂÆöÁöÑÂú∞ÂùÄÔºå‰ªÖÈôê‰ªéÊúçÂä°Âô®ËÆæÁΩÆ„ÄÇ
   + ‰æãÂ≠êÔºö`FRONTEND_BASE_URL=https://openai.justsong.cn`
6. `MEMORY_CACHE_ENABLED`ÔºöÂêØÁî®ÂÜÖÂ≠òÁºìÂ≠òÔºå‰ºöÂØºËá¥Áî®Êà∑È¢ùÂ∫¶ÁöÑÊõ¥Êñ∞Â≠òÂú®‰∏ÄÂÆöÁöÑÂª∂ËøüÔºåÂèØÈÄâÂÄº‰∏∫ `true` Âíå `false`ÔºåÊú™ËÆæÁΩÆÂàôÈªòËÆ§‰∏∫ `false`„ÄÇ
   + ‰æãÂ≠êÔºö`MEMORY_CACHE_ENABLED=true`
7. `SYNC_FREQUENCY`ÔºöÂú®ÂêØÁî®ÁºìÂ≠òÁöÑÊÉÖÂÜµ‰∏ã‰∏éÊï∞ÊçÆÂ∫ìÂêåÊ≠•ÈÖçÁΩÆÁöÑÈ¢ëÁéáÔºåÂçï‰Ωç‰∏∫ÁßíÔºåÈªòËÆ§‰∏∫ `600` Áßí„ÄÇ
   + ‰æãÂ≠êÔºö`SYNC_FREQUENCY=60`
8. `NODE_TYPE`ÔºöËÆæÁΩÆ‰πãÂêéÂ∞ÜÊåáÂÆöËäÇÁÇπÁ±ªÂûãÔºåÂèØÈÄâÂÄº‰∏∫ `master` Âíå `slave`ÔºåÊú™ËÆæÁΩÆÂàôÈªòËÆ§‰∏∫ `master`„ÄÇ
   + ‰æãÂ≠êÔºö`NODE_TYPE=slave`
9. `CHANNEL_UPDATE_FREQUENCY`ÔºöËÆæÁΩÆ‰πãÂêéÂ∞ÜÂÆöÊúüÊõ¥Êñ∞Ê∏†ÈÅì‰ΩôÈ¢ùÔºåÂçï‰Ωç‰∏∫ÂàÜÈíüÔºåÊú™ËÆæÁΩÆÂàô‰∏çËøõË°åÊõ¥Êñ∞„ÄÇ
   + ‰æãÂ≠êÔºö`CHANNEL_UPDATE_FREQUENCY=1440`
10. `CHANNEL_TEST_FREQUENCY`ÔºöËÆæÁΩÆ‰πãÂêéÂ∞ÜÂÆöÊúüÊ£ÄÊü•Ê∏†ÈÅìÔºåÂçï‰Ωç‰∏∫ÂàÜÈíüÔºåÊú™ËÆæÁΩÆÂàô‰∏çËøõË°åÊ£ÄÊü•„ÄÇ 
   +‰æãÂ≠êÔºö`CHANNEL_TEST_FREQUENCY=1440`
11. `POLLING_INTERVAL`ÔºöÊâπÈáèÊõ¥Êñ∞Ê∏†ÈÅì‰ΩôÈ¢ù‰ª•ÂèäÊµãËØïÂèØÁî®ÊÄßÊó∂ÁöÑËØ∑Ê±ÇÈó¥ÈöîÔºåÂçï‰Ωç‰∏∫ÁßíÔºåÈªòËÆ§Êó†Èó¥Èöî„ÄÇ
    + ‰æãÂ≠êÔºö`POLLING_INTERVAL=5`
12. `BATCH_UPDATE_ENABLED`ÔºöÂêØÁî®Êï∞ÊçÆÂ∫ìÊâπÈáèÊõ¥Êñ∞ËÅöÂêàÔºå‰ºöÂØºËá¥Áî®Êà∑È¢ùÂ∫¶ÁöÑÊõ¥Êñ∞Â≠òÂú®‰∏ÄÂÆöÁöÑÂª∂ËøüÂèØÈÄâÂÄº‰∏∫ `true` Âíå `false`ÔºåÊú™ËÆæÁΩÆÂàôÈªòËÆ§‰∏∫ `false`„ÄÇ
    + ‰æãÂ≠êÔºö`BATCH_UPDATE_ENABLED=true`
    + Â¶ÇÊûú‰Ω†ÈÅáÂà∞‰∫ÜÊï∞ÊçÆÂ∫ìËøûÊé•Êï∞ËøáÂ§öÁöÑÈóÆÈ¢òÔºåÂèØ‰ª•Â∞ùËØïÂêØÁî®ËØ•ÈÄâÈ°π„ÄÇ
13. `BATCH_UPDATE_INTERVAL=5`ÔºöÊâπÈáèÊõ¥Êñ∞ËÅöÂêàÁöÑÊó∂Èó¥Èó¥ÈöîÔºåÂçï‰Ωç‰∏∫ÁßíÔºåÈªòËÆ§‰∏∫ `5`„ÄÇ
    + ‰æãÂ≠êÔºö`BATCH_UPDATE_INTERVAL=5`
14. ËØ∑Ê±ÇÈ¢ëÁéáÈôêÂà∂Ôºö
    + `GLOBAL_API_RATE_LIMIT`ÔºöÂÖ®Â±Ä API ÈÄüÁéáÈôêÂà∂ÔºàÈô§‰∏≠ÁªßËØ∑Ê±ÇÂ§ñÔºâÔºåÂçï ip ‰∏âÂàÜÈíüÂÜÖÁöÑÊúÄÂ§ßËØ∑Ê±ÇÊï∞ÔºåÈªòËÆ§‰∏∫ `180`„ÄÇ
    + `GLOBAL_WEB_RATE_LIMIT`ÔºöÂÖ®Â±Ä Web ÈÄüÁéáÈôêÂà∂ÔºåÂçï ip ‰∏âÂàÜÈíüÂÜÖÁöÑÊúÄÂ§ßËØ∑Ê±ÇÊï∞ÔºåÈªòËÆ§‰∏∫ `60`„ÄÇ
15. ÁºñÁ†ÅÂô®ÁºìÂ≠òËÆæÁΩÆÔºö
    + `TIKTOKEN_CACHE_DIR`ÔºöÈªòËÆ§Á®ãÂ∫èÂêØÂä®Êó∂‰ºöËÅîÁΩë‰∏ãËΩΩ‰∏Ä‰∫õÈÄöÁî®ÁöÑËØçÂÖÉÁöÑÁºñÁ†ÅÔºåÂ¶ÇÔºö`gpt-3.5-turbo`ÔºåÂú®‰∏Ä‰∫õÁΩëÁªúÁéØÂ¢É‰∏çÁ®≥ÂÆöÔºåÊàñËÄÖÁ¶ªÁ∫øÊÉÖÂÜµÔºåÂèØËÉΩ‰ºöÂØºËá¥ÂêØÂä®ÊúâÈóÆÈ¢òÔºåÂèØ‰ª•ÈÖçÁΩÆÊ≠§ÁõÆÂΩïÁºìÂ≠òÊï∞ÊçÆÔºåÂèØËøÅÁßªÂà∞Á¶ªÁ∫øÁéØÂ¢É„ÄÇ
    + `DATA_GYM_CACHE_DIR`ÔºöÁõÆÂâçËØ•ÈÖçÁΩÆ‰ΩúÁî®‰∏é `TIKTOKEN_CACHE_DIR` ‰∏ÄËá¥Ôºå‰ΩÜÊòØ‰ºòÂÖàÁ∫ßÊ≤°ÊúâÂÆÉÈ´ò„ÄÇ
16. `RELAY_TIMEOUT`Ôºö‰∏≠ÁªßË∂ÖÊó∂ËÆæÁΩÆÔºåÂçï‰Ωç‰∏∫ÁßíÔºåÈªòËÆ§‰∏çËÆæÁΩÆË∂ÖÊó∂Êó∂Èó¥„ÄÇ
17. `RELAY_PROXY`ÔºöËÆæÁΩÆÂêé‰ΩøÁî®ËØ•‰ª£ÁêÜÊù•ËØ∑Ê±Ç API„ÄÇ
18. `USER_CONTENT_REQUEST_TIMEOUT`ÔºöÁî®Êà∑‰∏ä‰º†ÂÜÖÂÆπ‰∏ãËΩΩË∂ÖÊó∂Êó∂Èó¥ÔºåÂçï‰Ωç‰∏∫Áßí„ÄÇ
19. `USER_CONTENT_REQUEST_PROXY`ÔºöËÆæÁΩÆÂêé‰ΩøÁî®ËØ•‰ª£ÁêÜÊù•ËØ∑Ê±ÇÁî®Êà∑‰∏ä‰º†ÁöÑÂÜÖÂÆπÔºå‰æãÂ¶ÇÂõæÁâá„ÄÇ
20. `SQLITE_BUSY_TIMEOUT`ÔºöSQLite ÈîÅÁ≠âÂæÖË∂ÖÊó∂ËÆæÁΩÆÔºåÂçï‰Ωç‰∏∫ÊØ´ÁßíÔºåÈªòËÆ§ `3000`„ÄÇ
21. `GEMINI_SAFETY_SETTING`ÔºöGemini ÁöÑÂÆâÂÖ®ËÆæÁΩÆÔºåÈªòËÆ§ `BLOCK_NONE`„ÄÇ
22. `GEMINI_VERSION`ÔºöOne API ÊâÄ‰ΩøÁî®ÁöÑ Gemini ÁâàÊú¨ÔºåÈªòËÆ§‰∏∫ `v1`„ÄÇ
23. `THEME`ÔºöÁ≥ªÁªüÁöÑ‰∏ªÈ¢òËÆæÁΩÆÔºåÈªòËÆ§‰∏∫ `default`ÔºåÂÖ∑‰ΩìÂèØÈÄâÂÄºÂèÇËÄÉ[Ê≠§Â§Ñ](./web/README.md)„ÄÇ
24. `ENABLE_METRIC`ÔºöÊòØÂê¶Ê†πÊçÆËØ∑Ê±ÇÊàêÂäüÁéáÁ¶ÅÁî®Ê∏†ÈÅìÔºåÈªòËÆ§‰∏çÂºÄÂêØÔºåÂèØÈÄâÂÄº‰∏∫ `true` Âíå `false`„ÄÇ
25. `METRIC_QUEUE_SIZE`ÔºöËØ∑Ê±ÇÊàêÂäüÁéáÁªüËÆ°ÈòüÂàóÂ§ßÂ∞èÔºåÈªòËÆ§‰∏∫ `10`„ÄÇ
26. `METRIC_SUCCESS_RATE_THRESHOLD`ÔºöËØ∑Ê±ÇÊàêÂäüÁéáÈòàÂÄºÔºåÈªòËÆ§‰∏∫ `0.8`„ÄÇ
27. `INITIAL_ROOT_TOKEN`ÔºöÂ¶ÇÊûúËÆæÁΩÆ‰∫ÜËØ•ÂÄºÔºåÂàôÂú®Á≥ªÁªüÈ¶ñÊ¨°ÂêØÂä®Êó∂‰ºöËá™Âä®ÂàõÂª∫‰∏Ä‰∏™ÂÄº‰∏∫ËØ•ÁéØÂ¢ÉÂèòÈáèÂÄºÁöÑ root Áî®Êà∑‰ª§Áâå„ÄÇ
28. `INITIAL_ROOT_ACCESS_TOKEN`ÔºöÂ¶ÇÊûúËÆæÁΩÆ‰∫ÜËØ•ÂÄºÔºåÂàôÂú®Á≥ªÁªüÈ¶ñÊ¨°ÂêØÂä®Êó∂‰ºöËá™Âä®ÂàõÂª∫‰∏Ä‰∏™ÂÄº‰∏∫ËØ•ÁéØÂ¢ÉÂèòÈáèÁöÑ root Áî®Êà∑ÂàõÂª∫Á≥ªÁªüÁÆ°ÁêÜ‰ª§Áâå„ÄÇ
29. `ENFORCE_INCLUDE_USAGE`ÔºöÊòØÂê¶Âº∫Âà∂Âú® stream Ê®°Âûã‰∏ãËøîÂõû usageÔºåÈªòËÆ§‰∏çÂºÄÂêØÔºåÂèØÈÄâÂÄº‰∏∫ `true` Âíå `false`„ÄÇ
30. `TEST_PROMPT`ÔºöÊµãËØïÊ®°ÂûãÊó∂ÁöÑÁî®Êà∑ promptÔºåÈªòËÆ§‰∏∫ `Print your model name exactly and do not output without any other text.`„ÄÇ

### ÂëΩ‰ª§Ë°åÂèÇÊï∞
1. `--port &lt;port_number&gt;`: ÊåáÂÆöÊúçÂä°Âô®ÁõëÂê¨ÁöÑÁ´ØÂè£Âè∑ÔºåÈªòËÆ§‰∏∫ `3000`„ÄÇ
   + ‰æãÂ≠êÔºö`--port 3000`
2. `--log-dir &lt;log_dir&gt;`: ÊåáÂÆöÊó•ÂøóÊñá‰ª∂Â§πÔºåÂ¶ÇÊûúÊ≤°ÊúâËÆæÁΩÆÔºåÈªòËÆ§‰øùÂ≠òËá≥Â∑•‰ΩúÁõÆÂΩïÁöÑ `logs` Êñá‰ª∂Â§π‰∏ã„ÄÇ
   + ‰æãÂ≠êÔºö`--log-dir ./logs`
3. `--version`: ÊâìÂç∞Á≥ªÁªüÁâàÊú¨Âè∑Âπ∂ÈÄÄÂá∫„ÄÇ
4. `--help`: Êü•ÁúãÂëΩ‰ª§ÁöÑ‰ΩøÁî®Â∏ÆÂä©ÂíåÂèÇÊï∞ËØ¥Êòé„ÄÇ

## ÊºîÁ§∫
### Âú®Á∫øÊºîÁ§∫
Ê≥®ÊÑèÔºåËØ•ÊºîÁ§∫Á´ô‰∏çÊèê‰æõÂØπÂ§ñÊúçÂä°Ôºö
https://openai.justsong.cn

### Êà™ÂõæÂ±ïÁ§∫
![channel](https://user-images.githubusercontent.com/39998050/233837954-ae6683aa-5c4f-429f-a949-6645a83c9490.png)
![token](https://user-images.githubusercontent.com/39998050/233837971-dab488b7-6d96-43af-b640-a168e8d1c9bf.png)

## Â∏∏ËßÅÈóÆÈ¢ò
1. È¢ùÂ∫¶ÊòØ‰ªÄ‰πàÔºüÊÄé‰πàËÆ°ÁÆóÁöÑÔºüOne API ÁöÑÈ¢ùÂ∫¶ËÆ°ÁÆóÊúâÈóÆÈ¢òÔºü
   + È¢ùÂ∫¶ = ÂàÜÁªÑÂÄçÁéá * Ê®°ÂûãÂÄçÁéá * ÔºàÊèêÁ§∫ token Êï∞ + Ë°•ÂÖ® token Êï∞ * Ë°•ÂÖ®ÂÄçÁéáÔºâ
   + ÂÖ∂‰∏≠Ë°•ÂÖ®ÂÄçÁéáÂØπ‰∫é GPT3.5 Âõ∫ÂÆö‰∏∫ 1.33ÔºåGPT4 ‰∏∫ 2Ôºå‰∏éÂÆòÊñπ‰øùÊåÅ‰∏ÄËá¥„ÄÇ
   + Â¶ÇÊûúÊòØÈùûÊµÅÊ®°ÂºèÔºåÂÆòÊñπÊé•Âè£‰ºöËøîÂõûÊ∂àËÄóÁöÑÊÄª tokenÔºå‰ΩÜÊòØ‰Ω†Ë¶ÅÊ≥®ÊÑèÊèêÁ§∫ÂíåË°•ÂÖ®ÁöÑÊ∂àËÄóÂÄçÁéá‰∏ç‰∏ÄÊ†∑„ÄÇ
   + Ê≥®ÊÑèÔºåOne API ÁöÑÈªòËÆ§ÂÄçÁéáÂ∞±ÊòØÂÆòÊñπÂÄçÁéáÔºåÊòØÂ∑≤ÁªèË∞ÉÊï¥ËøáÁöÑ„ÄÇ
2. Ë¥¶Êà∑È¢ùÂ∫¶Ë∂≥Â§ü‰∏∫‰ªÄ‰πàÊèêÁ§∫È¢ùÂ∫¶‰∏çË∂≥Ôºü
   + ËØ∑Ê£ÄÊü•‰Ω†ÁöÑ‰ª§ÁâåÈ¢ùÂ∫¶ÊòØÂê¶Ë∂≥Â§üÔºåËøô‰∏™ÂíåË¥¶Êà∑È¢ùÂ∫¶ÊòØÂàÜÂºÄÁöÑ„ÄÇ
   + ‰ª§ÁâåÈ¢ùÂ∫¶‰ªÖ‰æõÁî®Êà∑ËÆæÁΩÆÊúÄÂ§ß‰ΩøÁî®ÈáèÔºåÁî®Êà∑ÂèØËá™Áî±ËÆæÁΩÆ„ÄÇ
3. ÊèêÁ§∫Êó†ÂèØÁî®Ê∏†ÈÅìÔºü
   + ËØ∑Ê£ÄÊü•ÁöÑÁî®Êà∑ÂàÜÁªÑÂíåÊ∏†ÈÅìÂàÜÁªÑËÆæÁΩÆ„ÄÇ
   + ‰ª•ÂèäÊ∏†ÈÅìÁöÑÊ®°ÂûãËÆæÁΩÆ„ÄÇ
4. Ê∏†ÈÅìÊµãËØïÊä•ÈîôÔºö`invalid character &#039;&lt;&#039; looking for beginning of value`
   + ËøôÊòØÂõ†‰∏∫ËøîÂõûÂÄº‰∏çÊòØÂêàÊ≥ïÁöÑ JSONÔºåËÄåÊòØ‰∏Ä‰∏™ HTML È°µÈù¢„ÄÇ
   + Â§ßÊ¶ÇÁéáÊòØ‰Ω†ÁöÑÈÉ®ÁΩ≤Á´ôÁöÑ IP Êàñ‰ª£ÁêÜÁöÑËäÇÁÇπË¢´ CloudFlare Â∞ÅÁ¶Å‰∫Ü„ÄÇ
5. ChatGPT Next Web Êä•ÈîôÔºö`Failed to fetch`
   + ÈÉ®ÁΩ≤ÁöÑÊó∂ÂÄô‰∏çË¶ÅËÆæÁΩÆ `BASE_URL`„ÄÇ
   + Ê£ÄÊü•‰Ω†ÁöÑÊé•Âè£Âú∞ÂùÄÂíå API Key ÊúâÊ≤°ÊúâÂ°´ÂØπ„ÄÇ
   + Ê£ÄÊü•ÊòØÂê¶ÂêØÁî®‰∫Ü HTTPSÔºåÊµèËßàÂô®‰ºöÊã¶Êà™ HTTPS ÂüüÂêç‰∏ãÁöÑ HTTP ËØ∑Ê±Ç„ÄÇ
6. Êä•ÈîôÔºö`ÂΩìÂâçÂàÜÁªÑË¥üËΩΩÂ∑≤È•±ÂíåÔºåËØ∑Á®çÂêéÂÜçËØï`
   + ‰∏äÊ∏∏Ê∏†ÈÅì 429 ‰∫Ü„ÄÇ
7. ÂçáÁ∫ß‰πãÂêéÊàëÁöÑÊï∞ÊçÆ‰ºö‰∏¢Â§±ÂêóÔºü
   + Â¶ÇÊûú‰ΩøÁî® MySQLÔºå‰∏ç‰ºö„ÄÇ
   + Â¶ÇÊûú‰ΩøÁî® SQLiteÔºåÈúÄË¶ÅÊåâÁÖßÊàëÊâÄÁªôÁöÑÈÉ®ÁΩ≤ÂëΩ‰ª§ÊåÇËΩΩ volume ÊåÅ‰πÖÂåñ one-api.db Êï∞ÊçÆÂ∫ìÊñá‰ª∂ÔºåÂê¶ÂàôÂÆπÂô®ÈáçÂêØÂêéÊï∞ÊçÆ‰ºö‰∏¢Â§±„ÄÇ
8. ÂçáÁ∫ß‰πãÂâçÊï∞ÊçÆÂ∫ìÈúÄË¶ÅÂÅöÂèòÊõ¥ÂêóÔºü
   + ‰∏ÄËà¨ÊÉÖÂÜµ‰∏ã‰∏çÈúÄË¶ÅÔºåÁ≥ªÁªüÂ∞ÜÂú®ÂàùÂßãÂåñÁöÑÊó∂ÂÄôËá™Âä®Ë∞ÉÊï¥„ÄÇ
   + Â¶ÇÊûúÈúÄË¶ÅÁöÑËØùÔºåÊàë‰ºöÂú®Êõ¥Êñ∞Êó•Âøó‰∏≠ËØ¥ÊòéÔºåÂπ∂ÁªôÂá∫ËÑöÊú¨„ÄÇ
9. ÊâãÂä®‰øÆÊîπÊï∞ÊçÆÂ∫ìÂêéÊä•ÈîôÔºö`Êï∞ÊçÆÂ∫ì‰∏ÄËá¥ÊÄßÂ∑≤Ë¢´Á†¥ÂùèÔºåËØ∑ËÅîÁ≥ªÁÆ°ÁêÜÂëò`Ôºü
   + ËøôÊòØÊ£ÄÊµãÂà∞ ability Ë°®ÈáåÊúâ‰∫õËÆ∞ÂΩïÁöÑÊ∏†ÈÅì id ÊòØ‰∏çÂ≠òÂú®ÁöÑÔºåËøôÂ§ßÊ¶ÇÁéáÊòØÂõ†‰∏∫‰Ω†Âà†‰∫Ü channel Ë°®ÈáåÁöÑËÆ∞ÂΩï‰ΩÜÊòØÊ≤°ÊúâÂêåÊ≠•Âú® ability Ë°®ÈáåÊ∏ÖÁêÜÊó†ÊïàÁöÑÊ∏†ÈÅì„ÄÇ
   + ÂØπ‰∫éÊØè‰∏Ä‰∏™Ê∏†ÈÅìÔºåÂÖ∂ÊâÄÊîØÊåÅÁöÑÊ®°ÂûãÈÉΩÈúÄË¶ÅÊúâ‰∏Ä‰∏™‰∏ìÈó®ÁöÑ ability Ë°®ÁöÑËÆ∞ÂΩïÔºåË°®Á§∫ËØ•Ê∏†ÈÅìÊîØÊåÅËØ•Ê®°Âûã„ÄÇ

## Áõ∏ÂÖ≥È°πÁõÆ
* [FastGPT](https://github.com/labring/FastGPT): Âü∫‰∫é LLM Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÁü•ËØÜÂ∫ìÈóÆÁ≠îÁ≥ªÁªü
* [ChatGPT Next Web](https://github.com/Yidadaa/ChatGPT-Next-Web):  ‰∏ÄÈîÆÊã•Êúâ‰Ω†Ëá™Â∑±ÁöÑË∑®Âπ≥Âè∞ ChatGPT Â∫îÁî®
* [VChart](https://github.com/VisActor/VChart):  ‰∏çÂè™ÊòØÂºÄÁÆ±Âç≥Áî®ÁöÑÂ§öÁ´ØÂõæË°®Â∫ìÔºåÊõ¥ÊòØÁîüÂä®ÁÅµÊ¥ªÁöÑÊï∞ÊçÆÊïÖ‰∫ãËÆ≤Ëø∞ËÄÖ„ÄÇ
* [VMind](https://github.com/VisActor/VMind):  ‰∏ç‰ªÖËá™Âä®ÔºåËøòÂæàÊô∫ËÉΩ„ÄÇÂºÄÊ∫êÊô∫ËÉΩÂèØËßÜÂåñËß£ÂÜ≥ÊñπÊ°à„ÄÇ
* [CherryStudio](https://github.com/CherryHQ/cherry-studio):  ÂÖ®Âπ≥Âè∞ÊîØÊåÅÁöÑAIÂÆ¢Êà∑Á´Ø, Â§öÊúçÂä°ÂïÜÈõÜÊàêÁÆ°ÁêÜ„ÄÅÊú¨Âú∞Áü•ËØÜÂ∫ìÊîØÊåÅ„ÄÇ

## Ê≥®ÊÑè

Êú¨È°πÁõÆ‰ΩøÁî® MIT ÂçèËÆÆËøõË°åÂºÄÊ∫êÔºå**Âú®Ê≠§Âü∫Á°Ä‰∏ä**ÔºåÂøÖÈ°ªÂú®È°µÈù¢Â∫ïÈÉ®‰øùÁïôÁΩ≤Âêç‰ª•ÂèäÊåáÂêëÊú¨È°πÁõÆÁöÑÈìæÊé•„ÄÇÂ¶ÇÊûú‰∏çÊÉ≥‰øùÁïôÁΩ≤ÂêçÔºåÂøÖÈ°ªÈ¶ñÂÖàËé∑ÂæóÊéàÊùÉ„ÄÇ

ÂêåÊ†∑ÈÄÇÁî®‰∫éÂü∫‰∫éÊú¨È°πÁõÆÁöÑ‰∫åÂºÄÈ°πÁõÆ„ÄÇ

‰æùÊçÆ MIT ÂçèËÆÆÔºå‰ΩøÁî®ËÄÖÈúÄËá™Ë°åÊâøÊãÖ‰ΩøÁî®Êú¨È°πÁõÆÁöÑÈ£éÈô©‰∏éË¥£‰ªªÔºåÊú¨ÂºÄÊ∫êÈ°πÁõÆÂºÄÂèëËÄÖ‰∏éÊ≠§Êó†ÂÖ≥„ÄÇ
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[QuiteAFancyEmerald/Holy-Unblocker]]></title>
            <link>https://github.com/QuiteAFancyEmerald/Holy-Unblocker</link>
            <guid>https://github.com/QuiteAFancyEmerald/Holy-Unblocker</guid>
            <pubDate>Thu, 05 Feb 2026 00:07:31 GMT</pubDate>
            <description><![CDATA[Holy Unblocker LTS is a web proxy service that helps you access websites that may be blocked by your network, government or policy all within your browser with no download or setup. It does this securely and with additional privacy features. Browse Tor/Onion sites in any browser, hide browsing activity and bypass filters. (Star if you fork it!)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/QuiteAFancyEmerald/Holy-Unblocker">QuiteAFancyEmerald/Holy-Unblocker</a></h1>
            <p>Holy Unblocker LTS is a web proxy service that helps you access websites that may be blocked by your network, government or policy all within your browser with no download or setup. It does this securely and with additional privacy features. Browse Tor/Onion sites in any browser, hide browsing activity and bypass filters. (Star if you fork it!)</p>
            <p>Language: JavaScript</p>
            <p>Stars: 1,219</p>
            <p>Forks: 4,520</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>&lt;img align=&quot;center&quot; src=&quot;https://raw.githubusercontent.com/titaniumnetwork-dev/Holy-Unblocker/master/views/assets/img/github_banner.png&quot;&gt;&lt;/img&gt;

&lt;img align=&quot;left&quot; width=&quot;40px&quot; src=&quot;https://raw.githubusercontent.com/titaniumnetwork-dev/Holy-Unblocker/master/views/assets/img/logo_github.png&quot;&gt;&lt;/img&gt;

# Holy Unblocker LTS (v6.x.x)

![GitHub Actions Status](https://github.com/QuiteAFancyEmerald/Holy-Unblocker/workflows/CI-Production/badge.svg)
![GitHub Actions Status](https://github.com/QuiteAFancyEmerald/Holy-Unblocker/workflows/CI-Win/badge.svg)
[![Docker Image Version](https://img.shields.io/docker/v/quiteafancyemerald/holy-unblocker.svg)](https://hub.docker.com/r/quiteafancyemerald/holy-unblocker)
[![Docker Pulls](https://img.shields.io/docker/pulls/quiteafancyemerald/holy-unblocker.svg)](https://hub.docker.com/r/quiteafancyemerald/holy-unblocker)

Holy Unblocker LTS is an experimental web proxy service that can bypass web filters or &quot;blockers&quot; regardless of whether the method of censorship is client-side or network-based. This includes the ability to bypass content blockers from governments, chrome extensions, localized client firewalls, and network-related filters. The project even allows the ability to browse Tor/Onion sites in any browser (even Chromium) all through a website!

## You can support Holy Unblocker by starring the repository!

This project serves mostly as a proof of concept for the ideal clientless solution to bypassing censorship. A good use case of this project would be if you ever needed a clientless solution to use Tor or leave minimal traces of device activity. Simply host this project on any domain and have an alternative solution to a VPN without needing to download anything on said device. Being a secure web proxy service, it supports numerous sites while being updated frequently and concentrating on being easy to self-host. Holy Unblocker LTS works with a large number of sites, including YouTube, Discord, GeForce NOW and more!
Also has a good amount of locally hosted games featured on the site.

### Over 30M+ users since 2020. Thank you so much for the support I could have never imagined how massive the web proxy community has become.

#### Current Branch: Latest

&lt;details&gt;&lt;summary&gt;Branch Types&lt;/summary&gt;

- Latest (master; built for FOSS and SEO)
- Beta (pending changes; changes that may break things)
- Production (v4, v5, v6; stable version of Holy Unblocker LTS. Changes for self hosting in production settings; max filtering evasion and request handling)
&lt;/details&gt;

#### Considering switching branches for self-hosting to a production branch!

View the &lt;a href=&quot;#deploy-holy-unblocker&quot;&gt;self-deployment options&lt;/a&gt; if you wish to self host this project. Can&#039;t deploy using any of the free options? Check out Railway or look into cheap, paid VPS hosting solutions. If you don&#039;t wish to self-host join the discord for more official instance links that are restocked frequently.

**Be sure to join Titanium Network&#039;s Discord for more official site links:** &lt;a href=&quot;https://discord.gg/unblock&quot;&gt;https://discord.gg/unblock&lt;/a&gt;

&lt;br&gt;

&gt; [!CAUTION]
&gt; If you are going to self-host Holy Unblocker LTS please switch to the PRODUCTION branch for filter evasion features. The master branch is intended for development work and a highly readable source for developers. You can select a production branch (v6.x_production) via the branches dropdown.

&gt; [!TIP]
&gt; Holy Unblocker LTS is optimized for self-hosting to provide you with maximum privacy control! Fork this repository and consider starring. You can self-host using either free or paid deployment options, or set it up on a dedicated instance (VPS) for enhanced performance.

| **Supported Sites**        | **Features**                                                                                                                          |
| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- |
| Youtube                    | Built-in variety of open source web proxies with both a focus on speed and/or security                                                |
| Reddit                     | Features Source Randomization and DOM Masquerading to circumvent major filters effectively along with randomizations to proxy globals |
| Discord                    | Tab title + icon customization using the Settings Menu for improved browsing history stealth                                          |
| Instagram                  | Adblocking support across all websites while surfing and low latency DNS on official servers                                          |
| Reddit.com                 | SOCKS5 and Onion routing support with Tor within the Settings Menu. Use Tor/Onion sites in any browser!                               |
| GeForce NOW                | Game library with moderately decent titles and open-source emulation projects                                                         |
| Spotify                    | Bypass regional proxy blocks by swapping regions or enabling Tor                                                                      |
| And essentially all sites! | Built for intensive production loads and ease of setup                                                                                |

&lt;img src=&quot;https://raw.githubusercontent.com/titaniumnetwork-dev/Holy-Unblocker/master/views/assets/img/preview/hu-v6.4.3-preview.png&quot;&gt;&lt;/img&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/titaniumnetwork-dev/Holy-Unblocker/master/views/assets/img/preview/hu-v6.3.0-preview-settings.png&quot;&gt;&lt;/img&gt;

## Deploy Holy Unblocker

### Free Deployments

[![Deploy to Koyeb](https://binbashbanana.github.io/deploy-buttons/buttons/remade/koyeb.svg)](https://app.koyeb.com/deploy?name=holy-unblocker&amp;type=git&amp;repository=QuiteAFancyEmerald%2FHoly-Unblocker&amp;branch=v6.9.4_production&amp;builder=buildpack&amp;env%5B%5D=&amp;ports=8080%3Bhttp%3B%2F)
[![Deploy to Oracle Cloud](https://binbashbanana.github.io/deploy-buttons/buttons/remade/oraclecloud.svg)](https://cloud.oracle.com/resourcemanager/stacks/create?zipUrl=https://github.com/BinBashBanana/deploy-buttons/archive/refs/heads/main.zip)

&lt;details&gt;&lt;summary&gt;Alternative Free Sources&lt;/summary&gt;

[![Deploy to Cyclic](https://binbashbanana.github.io/deploy-buttons/buttons/remade/cyclic.svg)](https://app.cyclic.sh/api/app/deploy/shuttlenetwork/shuttle)
[![Deploy to Render](https://render.com/images/deploy-to-render-button.svg)](https://render.com/deploy?repo=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)
[![Deploy to Fly.io](https://img.shields.io/badge/Deploy%20to-Fly.io-blue?logo=fly.io)](https://fly.io/launch?repo=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)

&lt;/details&gt;

### Production Paid/Free Options (Requires Payment Info)

[![Deploy to Azure](https://raw.githubusercontent.com/BinBashBanana/deploy-buttons/master/buttons/remade/azure.svg)](https://deploy.azure.com/?repository=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)
[![Deploy to IBM Cloud](https://raw.githubusercontent.com/BinBashBanana/deploy-buttons/master/buttons/remade/ibmcloud.svg)](https://cloud.ibm.com/devops/setup/deploy?repository=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)
[![Deploy to Amplify Console](https://raw.githubusercontent.com/BinBashBanana/deploy-buttons/master/buttons/remade/amplifyconsole.svg)](https://console.aws.amazon.com/amplify/home#/deploy?repo=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)
[![Run on Google Cloud](https://raw.githubusercontent.com/BinBashBanana/deploy-buttons/master/buttons/remade/googlecloud.svg)](https://deploy.cloud.run/?git_repo=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)

#### What happened to Replit/Heroku Deployment?

Replit is no longer free and Heroku has a set policy against web proxies. Try GitHub Codespaces or Gitpod instead for development on the cloud OR Koyeb for free hosting.

### GitHub Codespaces

&lt;details&gt;&lt;summary&gt;Setup Instructions&lt;/summary&gt;

- Fork (and star!) this repository to your GitHub account
- Head to the official &lt;a href=&quot;https://github.com/codespaces&quot;&gt;Codespaces&lt;/a&gt; website (ensure you have a GitHub account already made)
- Select **New Codespaces** and look for _[USERNAME]/Holy-Unblocker_ on your account
- Ensure the branch is set to `master` and the dev container configuration is set to **Holy Unblocker LTS**
- Select **Create Codespace** and allow the container to setup
- Type `npm run fresh-install` and `npm start` in the terminal
- Click &quot;Make public&quot; on the application popup, then access the deployed website via the ports tab.

&lt;/details&gt;

## Table of contents:

- [Setup](#how-to-setup)
  - [Terminal](#terminal)
  - [Project Configuration](#configuration)
    - [Server Configuration](#server-configuration-setup)
    - [TOR Routing](#toronion-routing-setup)
    - [Proxy](#proxy-configuration)
    - [Client Navigation](#client-navigation-configuration)
    - [Games Management](#games-management)
  - [Structure](#structure)
    - [Structure Information](#structure-information)
    - [Static Files](#details-of-views)
    - [Scripts](#scripts-located-in-viewsassetsjs)
  - [Future Additions](#future-additions)
  - [Beginner&#039;s Explanation](#vauge-explanation-for-beginners-with-external-proxies-and-hosting)
    - [Hosting Providers](#list-of-some-good-hosting-options)
    - [Domain Setup](#freenomdomain-steps)
    - [Cloudflare Setup](#cloudflare-steps)
    - [Workspace Configurations](#workspace-configurations)
  - [Detailed FAQ](#detailed-faq)
  - [More Information](#more-information)

## How to Setup

#### It is highly recommended you switch branches via your IDE to a production released branch. Often the master branch contains unstable or WIP changes.|

#### Example: v6.x_production instead of master

### Terminal

Either use the button above to deploy to the deployment options above or type the commands below on a dedicated server

**THIS PROJECT REQUIRES NGINX NOT CADDY.** 

Please ensure you are using Node 20.x as well:

```bash
git clone https://github.com/QuiteAFancyEmerald/Holy-Unblocker.git

cd Holy-Unblocker

# Edit config.js and set production to true if you want to use pm2 (Allows for easier VPS hosting)
npm run fresh-install
npm start

# Or on subsequent uses...
npm restart

# For killing any production processes made with pm2
npm run kill

# For clearing respective Rammerhead cache
npm run clean

# If you encounter any build errors...
npm run build

# If you encounter any service errors...
npm run test
```

This website is hosted locally with Scramjet, Ultraviolet (Wisp, Bare-Mux, EpoxyTransport, CurlTransport) and Rammerhead built-in.

### For security reasons when hosting with a reverse proxy PLEASE use NGINX not Caddy. This is due to wisp-js using loopbacks.

#### Detailed Setup (Ubuntu Example)
You will need Node.js 20.x and Git installed; below is an example for Debian/Ubuntu setup.
&lt;details&gt;

For simplicity sake you can join the TN discord at discord.gg/unblock and request for mirror site links (that are restocked and unblocked).

### Hosting

If you wish to self-host however you will first need a VPS or hosting provider: 

- https://docs.titaniumnetwork.org/guides/vps-hosting/
- https://github.com/QuiteAFancyEmerald/Holy-Unblocker#deploy-holy-unblocker
- https://docs.titaniumnetwork.org/guides/dns-setup/

### Dependencies

You will then need to setup git, nginx (or caddy) and Node.js. Here is an example for Ubuntu LTS:
```
sudo apt update
sudo apt upgrade
sudo apt install curl git nginx

curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash

export NVM_DIR=&quot;$HOME/.nvm&quot;
[ -s &quot;$NVM_DIR/nvm.sh&quot; ] &amp;&amp; \. &quot;$NVM_DIR/nvm.sh&quot;

nvm install 20
nvm use 20
```
https://github.com/nvm-sh/nvm
https://docs.titaniumnetwork.org/guides/nginx/

### Tor Support (Optional)
https://github.com/QuiteAFancyEmerald/Holy-Unblocker#toronionsocks5-routing-setup

### Configurating Holy Unblocker
Most important options are production along with the obfuscation and DOM masquerading techniques. 

From there just configure as needed: https://github.com/QuiteAFancyEmerald/Holy-Unblocker#configuration

### Cloning and Running Holy Unblocker

Then run the respective process; if you have production set to true in the configuration pm2 will be automatically enabled with our own workers/cache system. 

```
git clone https://github.com/QuiteAFancyEmerald/Holy-Unblocker.git
cd Holy-Unblocker

npm run fresh-start
```

Then of course if you used NGINX or caddy please restart/reload it
```
sudo systemctl restart nginx
sudo systemctl restart tor
```

&lt;/details&gt;


Resources for self-hosting:

- https://github.com/nvm-sh/nvm
- https://docs.titaniumnetwork.org/guides/nginx/
- https://docs.titaniumnetwork.org/guides/vps-hosting/
- https://docs.titaniumnetwork.org/guides/dns-setup/

### Configuration

#### Server Configuration Setup

The default PORT for the proxy when started is `http://localhost:8080`. You can change the PORT and other production metrics if needed in `./ecosystem.config.js`. 

The default PORT for Rammerhead is `3000`. You can change this &lt;a href=&quot;https://github.com/QuiteAFancyEmerald/Holy-Unblocker/blob/8f6dcfedb71439a43a19cc0a015ee6ca7e29fd11/lib/rammerhead/holy-config.js#L9&quot;&gt;here&lt;/a&gt;.

Every other localized changes for source randomization, auto-minify, etc. are located in `./config.json`.

**config.json**
- `minifyScripts`: Automatically minify respective static assets upon starting the server.
- `randomizeIdentifiers`: Enable experimental proxy global randomization for Ultraviolet. This reduces the chances of UV being detected by any extension based filters.
- `production`: Utilize a pre-configured production setup for server hosting. Automatically has cache control, session jobs for Rammerhead and source rewrites setup.
- `disguiseFiles`: Enable DOM masquerading which obfuscates real the real content fetches for HU LTS. This is done through disguising requests, decompressing and then reconstructing the DOM tree.
- `usingSEO`: Enable Source Randomization which randomizes the source by swapping chunks of data specified in `./src/data.json`. Highly useful for masking keywords that will automatically flag or block Holy Unblocker LTS as well as preventing source blocks.

#### Tor/Onion/SOCKS5 Routing Setup

You need to setup Tor (no GUI need/GUI is alright. With GUI replace port 9050 with 9150) in order for the Onion Routing setting to work!

Simply host Tor using this guide: https://tb-manual.torproject.org/installation/

Alternative Guide (for CLI): https://community.torproject.org/onion-services/setup/install/

If you are hosting Holy Unblocker LTS on a VPS utilizing Ubuntu consider attaching Tor to systemctl for easier production management. Once Tor is up and running on either Linux or Windows it will work automatically with Holy Unblocker LTS when enabled by the user via the Settings menu.

If you wish to use a custom HTTP/HTTPS/SOCKS5 proxy to route all traffic through for Scramjet and Ultraviolet this is handled in `./views/assets/js/register-sw.js.` Modify `proxyUrl` with the respective protocol and address. This is done via the proxy option for Wisp. You can change the cases as needed.

```js
  proxyUrl = {
    tor: &#039;socks5h://localhost:9050&#039;,
    eu: &#039;socks5h://localhost:7000&#039;,
    jp: &#039;socks5h://localhost:7001&#039;,
  }
```

#### Proxy Configuration

The primary location for tweaking any web proxy related settings assigned via the Settings menu is `./views/assets/js/register-sw.js`. Here you can modify the provided transport options set locally via a cookie, swap out SOCKS5 proxies, change Onion routing ports, specify a blacklist, and more.

- `stockSW`: The default service worker configuration file for Ultraviolet. For Holy Unblocker however adblocking is automatically enabled so this is not used by default.
- `blacklistSW`: A modified version of Ultraviolet that allows for blacklisting domains and adblocking.
- `proxyUrl`: Specifies a SOCKS5/HTTPS/HTTP protocol URL defaulting to the default Tor proxy port. This can be swapped out with any valid port or SOCK5s proxy. This is done via the proxy option for both epoxy and libcurl.
- `transports`: Specifies any provided ports to be swapped via Bare-Mux and utilize Wisp.
- `wispUrl`: Modify the pathname or url handling for Wisp
- `defaultMode`: Specify the default transport used globally (can be swapped by the users still via the Settings menu)
- `ScramjetController`: This constructor allows you to swap out the prefix used for Scramjet dynamically and specify file locations. Note you may need to edit `./views/scram/scramjet.sw` when changing file names.

#### Client Navigation Configuration

The primary location for any client side navigation scripts is `./views/assets/js/common.js`. This file is primary used for Omnibox (Search Engine) functionality, swapping proxy options and linking games.

- `getDomain`: This constant is used for specifying any subdomains to remove when appending a URL into the omnibox.
- `goFrame`: This specifies the stealth frame used for Holy Unblocker LTS
- `sx`: This constant specifies the search engine you want to be proxied whenever a user types something in that isn&#039;t a URL
- `search/uvUrl/sjUrl`: These functions specify and parse the queries used for submitted URLs
- `RammerheadEncode:` This constant is a dependency for Rammerhead parsing and querying
- `urlHandler/asyncUrlHandler`: Used to set functions for the goProx object.
- `goProx`: This constant allows for the mapping of URL handling for specific proxies, games or links that need to fall under a web proxy.

```js
const goProx = Object.freeze({
  ultraviolet: urlHandler(uvUrl),

  scramjet: urlHandler(sjUrl),

  rammerhead: asyncUrlHandler(
    async (url) =&gt; location.origin + (await RammerheadEncode(search(url)))
  ),

  // `location.protocol + &quot;//&quot; + getDomain()` more like `location.origin`

  examplepath: urlHandler(location.protocol + `//c.${getDomain()}/example/`),

  examplesubdomain: urlHandler(location.protocol + &#039;//c.&#039; + getDomain()),

  example: urlHandler(sjUrl(&#039;https://example.com&#039;)),
});
```

- `prSet`: Attaches event listeners using goProx for any buttons or inputs needed

```js
// prSet function code here....

prSet(&#039;pr-uv&#039;, &#039;ultraviolet&#039;);
prSet(&#039;pr-sj&#039;, &#039;scramjet&#039;);
prSet(&#039;pr-rh&#039;, &#039;rammerhead&#039;);
prSet(&#039;pr-yt&#039;, &#039;youtube&#039;);
prSet(&#039;pr-example&#039;, &#039;example&#039;);
```

- `huLinks/navLists`: Automatically takes paths stated in `./views/assets/json` and appends them depending on the page and usage. This is used for hiding links that would lead to filter blocks and create an easier system for adding games.

#### Games Management

As stated above all game links that need to be appended to a page (including images and descriptions) are managed via the nav files in`./views/assets/json`. 

Download the latest release &lt;a href=&quot;https://github.com/QuiteAFancyEmerald/Holy-Unblocker/blob/master/views/GAMES.md&quot;&gt;here&lt;/a&gt; and extract it within a folder called `/views/archive`.

- `views/archive/g`: Contains any local or external HTML5/web games.
- `views/archive/gfiles/flash`: Contains Ruffle (an Adobe Flash emulator) and a collection of flash games linked to an external CDN.
- `views/archive/gfiles/rarch`: Contains webretro which is a project that ports RetroArch to WASM. Supports many systems like GBA, N64, etc; ROMS are NOT INCLUDED.

## Structure

&lt;details&gt;&lt;summary&gt;Web Pages&lt;/summary&gt;

### Structure Information

- `/views/`: The physical site base of Holy Unblocker goes here where static assets are served.
- `/src/`: For future implementation of obfuscation and keyword removing features.

#### Details of `/views/`

- `/dist/` is used for minfied files. Created on build.
- `/pages/` is used for the HTML for the site.
- `/assets/` is used for storing various CSS, JS, image, and JSON files.
- `/scram/` contains the respective local Scramjet implementation. Some files are overridden by the node module.
- `/uv/` contains 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
    </channel>
</rss>