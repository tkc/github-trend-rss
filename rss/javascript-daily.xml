<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for javascript - JavaScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for javascript.</description>
        <lastBuildDate>Wed, 04 Feb 2026 00:06:20 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[harvard-edge/cs249r_book]]></title>
            <link>https://github.com/harvard-edge/cs249r_book</link>
            <guid>https://github.com/harvard-edge/cs249r_book</guid>
            <pubDate>Wed, 04 Feb 2026 00:06:20 GMT</pubDate>
            <description><![CDATA[Introduction to Machine Learning Systems]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/harvard-edge/cs249r_book">harvard-edge/cs249r_book</a></h1>
            <p>Introduction to Machine Learning Systems</p>
            <p>Language: JavaScript</p>
            <p>Stars: 17,781</p>
            <p>Forks: 2,050</p>
            <p>Stars today: 86 stars today</p>
            <h2>README</h2><pre># Machine Learning Systems
*Principles and Practices of Engineering Artificially Intelligent Systems*

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;README.md&quot;&gt;English&lt;/a&gt; â€¢
  &lt;a href=&quot;README/README_zh.md&quot;&gt;ä¸­æ–‡&lt;/a&gt; â€¢
  &lt;a href=&quot;README/README_ja.md&quot;&gt;æ—¥æœ¬èª&lt;/a&gt; â€¢
  &lt;a href=&quot;README/README_ko.md&quot;&gt;í•œêµ­ì–´&lt;/a&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;p align=&quot;center&quot;&gt;

  [![Book](https://img.shields.io/github/actions/workflow/status/harvard-edge/cs249r_book/book-validate-dev.yml?branch=dev&amp;label=Book&amp;logo=githubactions&amp;cacheSeconds=300)](https://github.com/harvard-edge/cs249r_book/actions/workflows/book-validate-dev.yml)
  [![TinyTorch](https://img.shields.io/github/actions/workflow/status/harvard-edge/cs249r_book/tinytorch-validate-dev.yml?branch=dev&amp;label=TinyTorch&amp;logo=python&amp;cacheSeconds=300)](https://github.com/harvard-edge/cs249r_book/actions/workflows/tinytorch-validate-dev.yml)
  ![Updated](https://img.shields.io/github/last-commit/harvard-edge/cs249r_book/dev?label=Updated&amp;logo=git&amp;cacheSeconds=300)

  [![License](https://img.shields.io/badge/License-CC--BY--NC--ND%204.0-blue.svg)](https://github.com/harvard-edge/cs249r_book/blob/dev/LICENSE.md)
  [![Cite](https://img.shields.io/badge/Cite-IEEE%202024-blue?logo=ieee)](#-citation--license)
  [![Fund Us](https://img.shields.io/badge/Fund%20Us-Open%20Collective-blue.svg?logo=open-collective)](https://opencollective.com/mlsysbook)

&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;

  &lt;!-- Reader Navigation --&gt;
  **[ğŸ“– Read Online](https://mlsysbook.ai)** â€¢
  **[TinyğŸ”¥Torch](https://mlsysbook.ai/tinytorch)** â€¢
  **[ğŸ“„ Download PDF](https://mlsysbook.ai/assets/downloads/Machine-Learning-Systems.pdf)** â€¢
  **[ğŸ““ Download EPUB](https://mlsysbook.ai/epub)** â€¢
  **[ğŸŒ Explore Ecosystem](https://mlsysbook.org)**

&lt;/p&gt;

ğŸ“š **Hardcopy edition coming 2026 with MIT Press.**

&lt;/div&gt;

---

## Mission

**The world is rushing to build AI systems. It is not engineering them.**

That gap is what we mean by AI engineering.

**AI engineering is the discipline of building efficient, reliable, safe, and robust intelligent systems that operate in the real world, not just models in isolation.**

**Our mission:** Establish AI engineering as a foundational discipline, alongside software engineering and computer engineering, by teaching how to design, build, and evaluate end to end intelligent systems. The long term impact of AI will be shaped by engineers who can turn ideas into working, dependable systems.

---

## Whatâ€™s in this repo

This repository is the open learning stack for AI systems engineering.

It includes the textbook source, TinyTorch, hardware kits, and upcoming co-labs that connect principles to runnable code and real devices.

---

## Start Here

Choose a path based on your goal.

**READ** Start with the [textbook](https://mlsysbook.ai). Try [Chapter 1](https://www.mlsysbook.ai/book/contents/core/introduction/introduction.html) and the [Benchmarking chapter](https://mlsysbook.ai/book/contents/core/benchmarking/benchmarking.html).

**BUILD** Start TinyTorch with the [getting started guide](https://mlsysbook.ai/tinytorch/getting-started.html). Begin with Module 01 and work up from CNNs to transformers and the MLPerf benchmarks.

**DEPLOY** Pick a [hardware kit](https://mlsysbook.ai/kits) and run the labs on Arduino, Raspberry Pi, and other edge devices.

**CONNECT** Say hello in [Discussions](https://github.com/harvard-edge/cs249r_book/discussions). We will do our best to reply.

---

## The Learning Stack

The learning stack below shows how the textbook connects to hands on work and deployment. Read the textbook, then pick your path:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                               â”‚
â”‚                           MACHINE LEARNING SYSTEMS                            â”‚
â”‚                              Read the Textbook                                â”‚
â”‚                                                                               â”‚
â”‚                    Theory â€¢ Concepts â€¢ Best Practices                         â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚             â”‚             â”‚
                          â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            HANDS-ON ACTIVITIES                                â”‚
â”‚                           (pick one or all)                                   â”‚
â”‚                                                                               â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚     â”‚                 â”‚      â”‚                 â”‚      â”‚                 â”‚     â”‚
â”‚     â”‚    SOFTWARE     â”‚      â”‚    TINYTORCH    â”‚      â”‚    HARDWARE     â”‚     â”‚
â”‚     â”‚    CO-LABS      â”‚      â”‚    FRAMEWORK    â”‚      â”‚      LABS       â”‚     â”‚
â”‚     â”‚                 â”‚      â”‚                 â”‚      â”‚                 â”‚     â”‚
â”‚     â”‚ EXPLORE         â”‚      â”‚ BUILD           â”‚      â”‚ DEPLOY          â”‚     â”‚
â”‚     â”‚                 â”‚      â”‚                 â”‚      â”‚                 â”‚     â”‚
â”‚     â”‚ Run controlled  â”‚      â”‚ Understand      â”‚      â”‚ Engineer under  â”‚     â”‚
â”‚     â”‚ experiments on  â”‚      â”‚ frameworks by   â”‚      â”‚ real constraintsâ”‚     â”‚
â”‚     â”‚ latency, memory,â”‚      â”‚ implementing    â”‚      â”‚ memory, power,  â”‚     â”‚
â”‚     â”‚ energy, cost    â”‚      â”‚ them            â”‚      â”‚ timing, safety  â”‚     â”‚
â”‚     â”‚                 â”‚      â”‚                 â”‚      â”‚                 â”‚     â”‚
â”‚     â”‚ (coming 2026)   â”‚      â”‚                 â”‚      â”‚ Arduino, Pi     â”‚     â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                               â”‚
â”‚           EXPLORE                  BUILD                   DEPLOY             â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                               â”‚
â”‚                                  AI OLYMPICS                                  â”‚
â”‚                                 Prove Mastery                                 â”‚
â”‚                                                                               â”‚
â”‚       Compete across all tracks â€¢ University teams â€¢ Public leaderboards      â”‚
â”‚                                                                               â”‚
â”‚                                (coming 2026)                                  â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| | Component | What You Do | Link |
|--|-----------|-------------|------|
| **READ** | [ğŸ“– Textbook](https://mlsysbook.ai) | Understand ML systems concepts | [book/](book/README.md) |
| **EXPLORE** | ğŸ”® Software Co-Labs | Run controlled experiments on latency, memory, energy, cost | *Coming 2026* |
| **BUILD** | [ğŸ”¥ TinyTorch](https://mlsysbook.ai/tinytorch) | Understand frameworks by implementing them | [tinytorch/](tinytorch/README.md) |
| **DEPLOY** | [ğŸ”§ Hardware Kits](https://mlsysbook.ai/kits) | Engineer under real constraints: memory, power, timing, safety | [kits/](kits/README.md) |
| **PROVE** | ğŸ† AI Olympics | Compete and benchmark across all tracks | *Coming 2026* |

**What each path teaches:**
- **EXPLORE** teaches *why* â€” Understand tradeoffs. Change batch sizes, precision, model architectures and see how latency, memory, and accuracy shift.
- **BUILD** teaches *how* â€” Understand internals. Implement autograd, optimizers, and attention from scratch to see how TensorFlow and PyTorch actually work.
- **DEPLOY** teaches *where* â€” Understand constraints. Face real memory limits, power budgets, and latency requirements on actual hardware.

---

## What You Will Learn

This textbook teaches you to think at the intersection of machine learning and systems engineering. Each chapter bridges algorithmic concepts with the infrastructure that makes them work in practice.

### The ML â†” Systems Bridge

| ML Concept | Systems Concept | What You Learn |
|------------|-----------------|----------------|
| Model parameters | Memory constraints | How to fit large models on resource-limited devices |
| Inference latency | Hardware acceleration | How GPUs, TPUs, and accelerators execute neural networks |
| Training convergence | Compute efficiency | How mixed-precision and optimization techniques reduce cost |
| Model accuracy | Quantization and pruning | How to compress models while preserving performance |
| Data requirements | Pipeline infrastructure | How to build efficient data loading and preprocessing |
| Model deployment | MLOps practices | How to monitor, version, and update models in production |
| Privacy constraints | On-device learning | How to train and adapt models without sending data to the cloud |

### Book Structure

| Part | Focus | Chapters |
|------|-------|----------|
| **I. Foundations** | Core concepts | Introduction, ML Systems, DL Primer, Architectures |
| **II. Design** | Building blocks | Workflow, Data Engineering, Frameworks, Training |
| **III. Performance** | Making it fast | Efficient AI, Optimizations, HW Acceleration, Benchmarking |
| **IV. Deployment** | Making it work | MLOps, On-device Learning, Privacy, Robustness |
| **V. Trust** | Making it right | Responsible AI, Sustainable AI, AI for Good |
| **VI. Frontiers** | What&#039;s next | Emerging trends and future directions |

---

## What Makes This Different

This is a living textbook. We keep it updated as the field grows, with community input along the way.

AI may feel like it is moving at lightning speed, but the engineering building blocks that make it work do not change as quickly as the headlines. This project is built around those stable foundations.

Think of it like LEGO. New sets arrive all the time, but the bricks themselves stay the same. Once you learn how the bricks fit together, you can build anything. Here, those &quot;AI bricks&quot; are the solid systems principles that make AI work.

Whether you are reading a chapter, running a lab, or sharing feedback, you are helping make these ideas more accessible to the next learner.

### Research to Teaching Loop

We use the same loop for research and teaching: define the system problem, build a reference implementation, benchmark it, then turn it into curriculum and tooling so others can reproduce and extend it.

| Loop Step | Research Artifacts | Teaching Artifacts |
|-----------|-------------------|-------------------|
| **Measure** | Benchmarks, suites, metrics | Benchmarking chapter, assignments |
| **Build** | Reference systems, compilers, runtimes | TinyTorch modules, co-labs |
| **Deploy** | Hardware targets, constraints, reliability | Hardware labs, kits |

---

## Support This Work

We are working toward **1 million learners by 2030** so that AI engineering becomes a shared, teachable discipline, not a collection of isolated practices. Every star, share, and contribution helps move this effort forward.

### Why GitHub Stars Matter

&lt;div align=&quot;center&quot;&gt;

*What gets measured gets improved.*

Each star is a learner, educator, or supporter who believes AI systems should be engineered with rigor and real world constraints in mind.

[![Stars](https://img.shields.io/github/stars/harvard-edge/cs249r_book?style=for-the-badge&amp;logo=github&amp;color=gold)](https://github.com/harvard-edge/cs249r_book/stargazers)

[![Star History Chart](https://api.star-history.com/svg?repos=harvard-edge/cs249r_book&amp;type=Date)](https://star-history.com/#harvard-edge/cs249r_book&amp;Date)

1 learner â†’ 10 learners â†’ 100 learners â†’ 1,000 learners â†’ **10,000 learners** â†’ 100,000 learners â†’ **1M learners**

&lt;/div&gt;

Stars are not the goal. They are a signal.

A visible, growing community makes it easier for universities, foundations, and industry partners to adopt this material, donate hardware, and fund workshops. That momentum lowers the barrier for the next institution, the next classroom, and the next cohort of learners.

Support raised through this signal flows into [Open Collective](https://opencollective.com/mlsysbook) and funds concrete outcomes such as TinyML4D workshops, hardware kits for underserved classrooms, and the infrastructure required to keep this resource free and open.

One click can unlock the next classroom, the next contributor, and the next generation of AI engineers.

### Fund the Mission

&lt;div align=&quot;center&quot;&gt;

All contributions go to [Open Collective](https://opencollective.com/mlsysbook), a transparent fund that supports educational outreach.

[![Open Collective](https://img.shields.io/badge/ğŸ’%20Support%20AI%20Education-Open%20Collective-blue.svg?style=for-the-badge)](https://opencollective.com/mlsysbook)

&lt;/div&gt;

---

## Community and Resources

| Resource | Description |
|---|---|
| [ğŸ“– **Textbook**](https://mlsysbook.ai) | Interactive online textbook |
| [ğŸ”¥ **TinyTorch**](https://mlsysbook.ai/tinytorch) | Build ML frameworks from scratch |
| [ğŸ”§ **Hardware Kits**](https://mlsysbook.ai/kits) | Deploy to Arduino, Raspberry Pi, edge devices |
| [ğŸŒ **Ecosystem**](https://mlsysbook.org) | Resources, workshops, and community |
| [ğŸ’¬ **Discussions**](https://github.com/harvard-edge/cs249r_book/discussions) | Questions and ideas |

---

## Contributing

We welcome contributions to the book, TinyTorch, and hardware kits!

| I want to... | Go here |
|--------------|---------|
| Fix a typo or improve a chapter | [book/docs/CONTRIBUTING.md](book/docs/CONTRIBUTING.md) |
| Add a TinyTorch module or fix a bug | [tinytorch/CONTRIBUTING.md](tinytorch/CONTRIBUTING.md) |
| Improve hardware labs | [kits/README.md](kits/README.md) |
| Report an issue | [GitHub Issues](https://github.com/harvard-edge/cs249r_book/issues) |
| Ask a question | [GitHub Discussions](https://github.com/harvard-edge/cs249r_book/discussions) |

---

## Citation &amp; License

### Citation
```bibtex
@inproceedings{reddi2024mlsysbook,
  title        = {MLSysBook.AI: Principles and Practices of Machine Learning Systems Engineering},
  author       = {Reddi, Vijay Janapa},
  booktitle    = {2024 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ ISSS)},
  pages        = {41--42},
  year         = {2024},
  organization = {IEEE},
  url          = {https://mlsysbook.org}
}
```

### License

This project uses a dual-license structure:

| Component | License | What It Means |
|-----------|---------|---------------|
| **Book content** | [CC BY-NC-ND 4.0](LICENSE.md) | Share freely with attribution; no commercial use; no derivatives |
| **TinyTorch code** | [Apache 2.0](tinytorch/LICENSE) | Use, modify, and distribute freely; includes patent protection |

The textbook content (chapters, figures, explanations) is educational material that should circulate with attribution and without commercial exploitation. The software framework is a tool designed to be easy for anyone to use, modify, or integrate into their own projects.

---

## Contributors

Thanks goes to these wonderful people who have contributed to making this resource better for everyone!

**Legend:** ğŸª² Bug Hunter Â· ğŸ§‘â€ğŸ’» Code Contributor Â· âœï¸ Doc Wizard Â· ğŸ¨ Design Artist Â· ğŸ§  Idea Spark Â· ğŸ” Code Reviewer Â· ğŸ§ª Test Tinkerer Â· ğŸ› ï¸ Tool Builder

### ğŸ“– Textbook Contributors

&lt;!-- BOOK-CONTRIBUTORS-START --&gt;
&lt;!-- prettier-ignore-start --&gt;
&lt;!-- markdownlint-disable --&gt;
&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/profvjreddi&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/profvjreddi?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Vijay Janapa Reddi&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Vijay Janapa Reddi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;ğŸª² ğŸ§‘â€ğŸ’» ğŸ¨ âœï¸ ğŸ§  ğŸ” ğŸ§ª ğŸ› ï¸&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/Mjrovai&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/Mjrovai?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Marcelo Rovai&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Marcelo Rovai&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;ğŸ§‘â€ğŸ’» ğŸ¨ ğŸ§ª&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/GabrielAmazonas&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/GabrielAmazonas?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Gabriel Amazonas&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Gabriel Amazonas&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;ğŸª² âœï¸ ğŸ§ &lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/kai4avaya&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/kai4avaya?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Kai Kleinbard&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Kai Kleinbard&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;ğŸ§‘â€ğŸ’» ğŸ› ï¸&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/didier-durand&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/didier-durand?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Didier Durand&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Didier Durand&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;âœï¸ ğŸª²&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/hzeljko&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/hzeljko?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Zeljko Hrcek&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Zeljko Hrcek&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;ğŸ§‘â€ğŸ’»&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/jasonjabbour&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/jasonjabbour?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Jason Jabbour&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jason Jabbour&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;âœï¸&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/uchendui&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/uchendui?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Ikechukwu Uchendu&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ikechukwu Uchendu&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;âœï¸&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/Naeemkh&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/Naeemkh?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Naeem Khoshnevis&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Naeem Khoshnevis&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;âœï¸&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/Sara-Khosravi&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/Sara-Khosravi?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Sara Khosravi&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sara Khosravi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;âœï¸&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/V0XNIHILI&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/V0XNIHILI?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Douwe den Blanken&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Douwe den Blanken&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;âœï¸&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/18jeffreyma&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/18jeffreyma?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Jeffrey Ma&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jeffrey Ma&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;âœï¸&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/shanzehbatool&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/shanzehbatool?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;shanzehbatool&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;shanzehbatool&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;âœï¸&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/eliasab16&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/eliasab16?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Elias&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Elias&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;âœï¸&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/JaredP94&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/JaredP94?v=4?s=50&quot; width=&quot;50px;&quot; alt=&quot;Jared Ping&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jared Ping&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;âœï¸&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;11.11%&quot;&gt;&lt;a href=&quot;https://github.com/ishapira1&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/ishapira1?

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[eyaltoledano/claude-task-master]]></title>
            <link>https://github.com/eyaltoledano/claude-task-master</link>
            <guid>https://github.com/eyaltoledano/claude-task-master</guid>
            <pubDate>Wed, 04 Feb 2026 00:06:19 GMT</pubDate>
            <description><![CDATA[An AI-powered task-management system you can drop into Cursor, Lovable, Windsurf, Roo, and others.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/eyaltoledano/claude-task-master">eyaltoledano/claude-task-master</a></h1>
            <p>An AI-powered task-management system you can drop into Cursor, Lovable, Windsurf, Roo, and others.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 25,269</p>
            <p>Forks: 2,416</p>
            <p>Stars today: 44 stars today</p>
            <h2>README</h2><pre>&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

&lt;div align=&#039;center&#039;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/13971&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13971&quot; alt=&quot;eyaltoledano%2Fclaude-task-master | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://task-master.dev&quot;&gt;&lt;img src=&quot;./images/logo.png?raw=true&quot; alt=&quot;Taskmaster logo&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;b&gt;Taskmaster&lt;/b&gt;: A task management system for AI-driven development, designed to work seamlessly with any AI chat.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.gg/taskmasterai&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://dcbadge.limes.pink/api/server/https://discord.gg/taskmasterai?style=flat&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt; |
  &lt;a href=&quot;https://docs.task-master.dev&quot; target=&quot;_blank&quot;&gt;Docs&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/eyaltoledano/claude-task-master/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://github.com/eyaltoledano/claude-task-master/actions/workflows/ci.yml/badge.svg&quot; alt=&quot;CI&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/eyaltoledano/claude-task-master/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/eyaltoledano/claude-task-master?style=social&quot; alt=&quot;GitHub stars&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://badge.fury.io/js/task-master-ai&quot;&gt;&lt;img src=&quot;https://badge.fury.io/js/task-master-ai.svg&quot; alt=&quot;npm version&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-MIT%20with%20Commons%20Clause-blue.svg&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/task-master-ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/d18m/task-master-ai?style=flat&quot; alt=&quot;NPM Downloads&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/task-master-ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dm/task-master-ai?style=flat&quot; alt=&quot;NPM Downloads&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/task-master-ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dw/task-master-ai?style=flat&quot; alt=&quot;NPM Downloads&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

## By [@eyaltoledano](https://x.com/eyaltoledano) &amp; [@RalphEcom](https://x.com/RalphEcom)

[![Twitter Follow](https://img.shields.io/twitter/follow/eyaltoledano)](https://x.com/eyaltoledano)
[![Twitter Follow](https://img.shields.io/twitter/follow/RalphEcom)](https://x.com/RalphEcom)

A task management system for AI-driven development with Claude, designed to work seamlessly with Cursor AI.

## Documentation

ğŸ“š **[View Full Documentation](https://docs.task-master.dev)**

For detailed guides, API references, and comprehensive examples, visit our documentation site.

### Quick Reference

The following documentation is also available in the `docs` directory:

- [Configuration Guide](docs/configuration.md) - Set up environment variables and customize Task Master
- [Tutorial](docs/tutorial.md) - Step-by-step guide to getting started with Task Master
- [Command Reference](docs/command-reference.md) - Complete list of all available commands
- [Task Structure](docs/task-structure.md) - Understanding the task format and features
- [Example Interactions](docs/examples.md) - Common Cursor AI interaction examples
- [Migration Guide](docs/migration-guide.md) - Guide to migrating to the new project structure

#### Quick Install for Cursor 1.0+ (One-Click)

[![Add task-master-ai MCP server to Cursor](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=task-master-ai&amp;config=eyJjb21tYW5kIjoibnB4IC15IC0tcGFja2FnZT10YXNrLW1hc3Rlci1haSB0YXNrLW1hc3Rlci1haSIsImVudiI6eyJBTlRIUk9QSUNfQVBJX0tFWSI6IllPVVJfQU5USFJPUElDX0FQSV9LRVlfSEVSRSIsIlBFUlBMRVhJVFlfQVBJX0tFWSI6IllPVVJfUEVSUExFWElUWV9BUElfS0VZX0hFUkUiLCJPUEVOQUlfQVBJX0tFWSI6IllPVVJfT1BFTkFJX0tFWV9IRVJFIiwiR09PR0xFX0FQSV9LRVkiOiJZT1VSX0dPT0dMRV9LRVlfSEVSRSIsIk1JU1RSQUxfQVBJX0tFWSI6IllPVVJfTUlTVFJBTF9LRVlfSEVSRSIsIkdST1FfQVBJX0tFWSI6IllPVVJfR1JPUV9LRVlfSEVSRSIsIk9QRU5ST1VURVJfQVBJX0tFWSI6IllPVVJfT1BFTlJPVVRFUl9LRVlfSEVSRSIsIlhBSV9BUElfS0VZIjoiWU9VUl9YQUlfS0VZX0hFUkUiLCJBWlVSRV9PUEVOQUlfQVBJX0tFWSI6IllPVVJfQVpVUkVfS0VZX0hFUkUiLCJPTExBTUFfQVBJX0tFWSI6IllPVVJfT0xMQU1BX0FQSV9LRVlfSEVSRSJ9fQ%3D%3D)

&gt; **Note:** After clicking the link, you&#039;ll still need to add your API keys to the configuration. The link installs the MCP server with placeholder keys that you&#039;ll need to replace with your actual API keys.

#### Claude Code Quick Install

For Claude Code users:

```bash
claude mcp add taskmaster-ai -- npx -y task-master-ai
```

Don&#039;t forget to add your API keys to the configuration:
- in the root .env of your Project
- in the &quot;env&quot; section of your mcp config for taskmaster-ai


## Requirements

Taskmaster utilizes AI across several commands, and those require a separate API key. You can use a variety of models from different AI providers provided you add your API keys. For example, if you want to use Claude 3.7, you&#039;ll need an Anthropic API key.

You can define 3 types of models to be used: the main model, the research model, and the fallback model (in case either the main or research fail). Whatever model you use, its provider API key must be present in either mcp.json or .env.

At least one (1) of the following is required:

- Anthropic API key (Claude API)
- OpenAI API key
- Google Gemini API key
- Perplexity API key (for research model)
- xAI API Key (for research or main model)
- OpenRouter API Key (for research or main model)
- Claude Code (no API key required - requires Claude Code CLI)
- Codex CLI (OAuth via ChatGPT subscription - requires Codex CLI)

Using the research model is optional but highly recommended. You will need at least ONE API key (unless using Claude Code or Codex CLI with OAuth). Adding all API keys enables you to seamlessly switch between model providers at will.

## Quick Start

### Option 1: MCP (Recommended)

MCP (Model Control Protocol) lets you run Task Master directly from your editor.

#### 1. Add your MCP config at the following path depending on your editor

| Editor       | Scope   | Linux/macOS Path                      | Windows Path                                      | Key          |
| ------------ | ------- | ------------------------------------- | ------------------------------------------------- | ------------ |
| **Cursor**   | Global  | `~/.cursor/mcp.json`                  | `%USERPROFILE%\.cursor\mcp.json`                  | `mcpServers` |
|              | Project | `&lt;project_folder&gt;/.cursor/mcp.json`   | `&lt;project_folder&gt;\.cursor\mcp.json`               | `mcpServers` |
| **Windsurf** | Global  | `~/.codeium/windsurf/mcp_config.json` | `%USERPROFILE%\.codeium\windsurf\mcp_config.json` | `mcpServers` |
| **VS Code**  | Project | `&lt;project_folder&gt;/.vscode/mcp.json`   | `&lt;project_folder&gt;\.vscode\mcp.json`               | `servers`    |
| **Q CLI**    | Global  | `~/.aws/amazonq/mcp.json`             |                                                   | `mcpServers` |

##### Manual Configuration

###### Cursor &amp; Windsurf &amp; Q Developer CLI (`mcpServers`)

```json
{
  &quot;mcpServers&quot;: {
    &quot;task-master-ai&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;task-master-ai&quot;],
      &quot;env&quot;: {
        // &quot;TASK_MASTER_TOOLS&quot;: &quot;all&quot;, // Options: &quot;all&quot;, &quot;standard&quot;, &quot;core&quot;, or comma-separated list of tools
        &quot;ANTHROPIC_API_KEY&quot;: &quot;YOUR_ANTHROPIC_API_KEY_HERE&quot;,
        &quot;PERPLEXITY_API_KEY&quot;: &quot;YOUR_PERPLEXITY_API_KEY_HERE&quot;,
        &quot;OPENAI_API_KEY&quot;: &quot;YOUR_OPENAI_KEY_HERE&quot;,
        &quot;GOOGLE_API_KEY&quot;: &quot;YOUR_GOOGLE_KEY_HERE&quot;,
        &quot;MISTRAL_API_KEY&quot;: &quot;YOUR_MISTRAL_KEY_HERE&quot;,
        &quot;GROQ_API_KEY&quot;: &quot;YOUR_GROQ_KEY_HERE&quot;,
        &quot;OPENROUTER_API_KEY&quot;: &quot;YOUR_OPENROUTER_KEY_HERE&quot;,
        &quot;XAI_API_KEY&quot;: &quot;YOUR_XAI_KEY_HERE&quot;,
        &quot;AZURE_OPENAI_API_KEY&quot;: &quot;YOUR_AZURE_KEY_HERE&quot;,
        &quot;OLLAMA_API_KEY&quot;: &quot;YOUR_OLLAMA_API_KEY_HERE&quot;
      }
    }
  }
}
```

&gt; ğŸ”‘ Replace `YOUR_â€¦_KEY_HERE` with your real API keys. You can remove keys you don&#039;t use.

&gt; **Note**: If you see `0 tools enabled` in the MCP settings, restart your editor and check that your API keys are correctly configured.

###### VSâ€¯Code (`servers` + `type`)

```json
{
  &quot;servers&quot;: {
    &quot;task-master-ai&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;task-master-ai&quot;],
      &quot;env&quot;: {
        // &quot;TASK_MASTER_TOOLS&quot;: &quot;all&quot;, // Options: &quot;all&quot;, &quot;standard&quot;, &quot;core&quot;, or comma-separated list of tools
        &quot;ANTHROPIC_API_KEY&quot;: &quot;YOUR_ANTHROPIC_API_KEY_HERE&quot;,
        &quot;PERPLEXITY_API_KEY&quot;: &quot;YOUR_PERPLEXITY_API_KEY_HERE&quot;,
        &quot;OPENAI_API_KEY&quot;: &quot;YOUR_OPENAI_KEY_HERE&quot;,
        &quot;GOOGLE_API_KEY&quot;: &quot;YOUR_GOOGLE_KEY_HERE&quot;,
        &quot;MISTRAL_API_KEY&quot;: &quot;YOUR_MISTRAL_KEY_HERE&quot;,
        &quot;GROQ_API_KEY&quot;: &quot;YOUR_GROQ_KEY_HERE&quot;,
        &quot;OPENROUTER_API_KEY&quot;: &quot;YOUR_OPENROUTER_KEY_HERE&quot;,
        &quot;XAI_API_KEY&quot;: &quot;YOUR_XAI_KEY_HERE&quot;,
        &quot;AZURE_OPENAI_API_KEY&quot;: &quot;YOUR_AZURE_KEY_HERE&quot;,
        &quot;OLLAMA_API_KEY&quot;: &quot;YOUR_OLLAMA_API_KEY_HERE&quot;
      },
      &quot;type&quot;: &quot;stdio&quot;
    }
  }
}
```

&gt; ğŸ”‘ Replace `YOUR_â€¦_KEY_HERE` with your real API keys. You can remove keys you don&#039;t use.

#### 2. (Cursor-only) Enable Taskmaster MCP

Open Cursor Settings (Ctrl+Shift+J) â¡ Click on MCP tab on the left â¡ Enable task-master-ai with the toggle

#### 3. (Optional) Configure the models you want to use

In your editor&#039;s AI chat pane, say:

```txt
Change the main, research and fallback models to &lt;model_name&gt;, &lt;model_name&gt; and &lt;model_name&gt; respectively.
```

For example, to use Claude Code (no API key required):
```txt
Change the main model to claude-code/sonnet
```

[Table of available models](docs/models.md) | [Claude Code setup](docs/examples/claude-code-usage.md)

#### 4. Initialize Task Master

In your editor&#039;s AI chat pane, say:

```txt
Initialize taskmaster-ai in my project
```

#### 5. Make sure you have a PRD (Recommended)

For **new projects**: Create your PRD at `.taskmaster/docs/prd.txt`.
For **existing projects**: You can use `scripts/prd.txt` or migrate with `task-master migrate`

An example PRD template is available after initialization in `.taskmaster/templates/example_prd.txt`.

&gt; [!NOTE]
&gt; While a PRD is recommended for complex projects, you can always create individual tasks by asking &quot;Can you help me implement [description of what you want to do]?&quot; in chat.

**Always start with a detailed PRD.**

The more detailed your PRD, the better the generated tasks will be.

#### 6. Common Commands

Use your AI assistant to:

- Parse requirements: `Can you parse my PRD at scripts/prd.txt?`
- Plan next step: `What&#039;s the next task I should work on?`
- Implement a task: `Can you help me implement task 3?`
- View multiple tasks: `Can you show me tasks 1, 3, and 5?`
- Expand a task: `Can you help me expand task 4?`
- **Research fresh information**: `Research the latest best practices for implementing JWT authentication with Node.js`
- **Research with context**: `Research React Query v5 migration strategies for our current API implementation in src/api.js`

[More examples on how to use Task Master in chat](docs/examples.md)

### Option 2: Using Command Line

#### Installation

```bash
# Install globally
npm install -g task-master-ai

# OR install locally within your project
npm install task-master-ai
```

#### Initialize a new project

```bash
# If installed globally
task-master init

# If installed locally
npx task-master init

# Initialize project with specific rules
task-master init --rules cursor,windsurf,vscode
```

This will prompt you for project details and set up a new project with the necessary files and structure.

#### Common Commands

```bash
# Initialize a new project
task-master init

# Parse a PRD and generate tasks
task-master parse-prd your-prd.txt

# List all tasks
task-master list

# Show the next task to work on
task-master next

# Show specific task(s) - supports comma-separated IDs
task-master show 1,3,5

# Research fresh information with project context
task-master research &quot;What are the latest best practices for JWT authentication?&quot;

# Move tasks between tags (cross-tag movement)
task-master move --from=5 --from-tag=backlog --to-tag=in-progress
task-master move --from=5,6,7 --from-tag=backlog --to-tag=done --with-dependencies
task-master move --from=5 --from-tag=backlog --to-tag=in-progress --ignore-dependencies

# Add rules after initialization
task-master rules add windsurf,roo,vscode
```

## Tool Loading Configuration

### Optimizing MCP Tool Loading

Task Master&#039;s MCP server supports selective tool loading to reduce context window usage. By default, all 36 tools are loaded (~21,000 tokens) to maintain backward compatibility with existing installations.

You can optimize performance by configuring the `TASK_MASTER_TOOLS` environment variable:

### Available Modes

| Mode | Tools | Context Usage | Use Case |
|------|-------|--------------|----------|
| `all` (default) | 36 | ~21,000 tokens | Complete feature set - all tools available |
| `standard` | 15 | ~10,000 tokens | Common task management operations |
| `core` (or `lean`) | 7 | ~5,000 tokens | Essential daily development workflow |
| `custom` | Variable | Variable | Comma-separated list of specific tools |

### Configuration Methods

#### Method 1: Environment Variable in MCP Configuration

Add `TASK_MASTER_TOOLS` to your MCP configuration file&#039;s `env` section:

```jsonc
{
  &quot;mcpServers&quot;: {  // or &quot;servers&quot; for VS Code
    &quot;task-master-ai&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;task-master-ai&quot;],
      &quot;env&quot;: {
        &quot;TASK_MASTER_TOOLS&quot;: &quot;standard&quot;,  // Options: &quot;all&quot;, &quot;standard&quot;, &quot;core&quot;, &quot;lean&quot;, or comma-separated list
        &quot;ANTHROPIC_API_KEY&quot;: &quot;your-key-here&quot;,
        // ... other API keys
      }
    }
  }
}
```

#### Method 2: Claude Code CLI (One-Time Setup)

For Claude Code users, you can set the mode during installation:

```bash
# Core mode example (~70% token reduction)
claude mcp add task-master-ai --scope user \
  --env TASK_MASTER_TOOLS=&quot;core&quot; \
  -- npx -y task-master-ai@latest

# Custom tools example
claude mcp add task-master-ai --scope user \
  --env TASK_MASTER_TOOLS=&quot;get_tasks,next_task,set_task_status&quot; \
  -- npx -y task-master-ai@latest
```

### Tool Sets Details

**Core Tools (7):** `get_tasks`, `next_task`, `get_task`, `set_task_status`, `update_subtask`, `parse_prd`, `expand_task`

**Standard Tools (15):** All core tools plus `initialize_project`, `analyze_project_complexity`, `expand_all`, `add_subtask`, `remove_task`, `generate`, `add_task`, `complexity_report`

**All Tools (36):** Complete set including project setup, task management, analysis, dependencies, tags, research, and more

### Recommendations

- **New users**: Start with `&quot;standard&quot;` mode for a good balance
- **Large projects**: Use `&quot;core&quot;` mode to minimize token usage
- **Complex workflows**: Use `&quot;all&quot;` mode or custom selection
- **Backward compatibility**: If not specified, defaults to `&quot;all&quot;` mode

## Claude Code Support

Task Master now supports Claude models through the Claude Code CLI, which requires no API key:

- **Models**: `claude-code/opus` and `claude-code/sonnet`
- **Requirements**: Claude Code CLI installed
- **Benefits**: No API key needed, uses your local Claude instance

[Learn more about Claude Code setup](docs/examples/claude-code-usage.md)

## Troubleshooting

### If `task-master init` doesn&#039;t respond

Try running it with Node directly:

```bash
node node_modules/claude-task-master/scripts/init.js
```

Or clone the repository and run:

```bash
git clone https://github.com/eyaltoledano/claude-task-master.git
cd claude-task-master
node scripts/init.js
```

## Join Our Team

&lt;a href=&quot;https://tryhamster.com&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;./images/hamster-hiring.png&quot; alt=&quot;Join Hamster&#039;s founding team&quot; /&gt;
&lt;/a&gt;

## Contributors

&lt;a href=&quot;https://github.com/eyaltoledano/claude-task-master/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=eyaltoledano/claude-task-master&quot; alt=&quot;Task Master project contributors&quot; /&gt;
&lt;/a&gt;

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=eyaltoledano/claude-task-master&amp;type=Timeline)](https://www.star-history.com/#eyaltoledano/claude-task-master&amp;Timeline)

## Licensing

Task Master is licensed under the MIT License with Commons Clause. This means you can:

âœ… **Allowed**:

- Use Task Master for any purpose (personal, commercial, academic)
- Modify the code
- Distribute copies
- Create and sell products built using Task Master

âŒ **Not Allowed**:

- Sell Task Master itself
- Offer Task Master as a hosted service
- Create competing products based on Task Master

See the [LICENSE](LICENSE) file for the complete license text and [licensing details](docs/licensing.md) for more information.
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[usebruno/bruno]]></title>
            <link>https://github.com/usebruno/bruno</link>
            <guid>https://github.com/usebruno/bruno</guid>
            <pubDate>Wed, 04 Feb 2026 00:06:18 GMT</pubDate>
            <description><![CDATA[Opensource IDE For Exploring and Testing API's (lightweight alternative to Postman/Insomnia)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/usebruno/bruno">usebruno/bruno</a></h1>
            <p>Opensource IDE For Exploring and Testing API's (lightweight alternative to Postman/Insomnia)</p>
            <p>Language: JavaScript</p>
            <p>Stars: 40,499</p>
            <p>Forks: 2,089</p>
            <p>Stars today: 42 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[maxandrews/Epstein-doc-explorer]]></title>
            <link>https://github.com/maxandrews/Epstein-doc-explorer</link>
            <guid>https://github.com/maxandrews/Epstein-doc-explorer</guid>
            <pubDate>Wed, 04 Feb 2026 00:06:17 GMT</pubDate>
            <description><![CDATA[a graph explorer of the Epstein emails]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/maxandrews/Epstein-doc-explorer">maxandrews/Epstein-doc-explorer</a></h1>
            <p>a graph explorer of the Epstein emails</p>
            <p>Language: JavaScript</p>
            <p>Stars: 352</p>
            <p>Forks: 62</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre># Epstein Document Network Explorer

&gt; **Note:** Additional documents are currently being processed and added to the network. The analysis pipeline is actively ingesting newly released documents from the House Oversight Committee.

An intelligent document analysis and network visualization system that processes legal documents to extract relationships, entities, and events, then visualizes them as an interactive knowledge graph.

## Project Overview

This project analyzes the Epstein document corpus to extract structured information about actors, actions, locations, and relationships. It uses Claude AI for intelligent extraction and presents findings through an interactive network visualization interface.

**Live Demo:** [Deployed on Render](https://epstein-doc-explorer-1.onrender.com/)

Source documents are available here: https://drive.google.com/drive/folders/1ldncvdqIf6miiskDp_EDuGSDAaI_fJx8
and here: https://huggingface.co/datasets/tensonaut/EPSTEIN_FILES_20K/tree/main
**special thanks to u/tensonaut for extracting the image files with tesseract!**

---

## Architecture Overview

The project has two main phases:

### 1. Analysis Pipeline
**Purpose:** Extract structured data from raw documents using AI
**Technology:** TypeScript, Claude AI (Anthropic), SQLite
**Location:** Root directory + `analysis_pipeline/`

### 2. Visualization Interface
**Purpose:** Interactive exploration of the extracted relationship network
**Technology:** React, TypeScript, Vite, D3.js/Force-Graph
**Location:** `network-ui/`

---

## Key Features

### Analysis Pipeline Features
- **AI-Powered Extraction:** Uses Claude to extract entities, relationships, and events from documents
- **Semantic Tagging:** Automatically tags triples with contextual metadata (legal, financial, travel, etc.)
- **Tag Clustering:** Groups 28,000+ tags into 30 semantic clusters using K-means for better filtering
- **Entity Deduplication:** Merges duplicate entities using LLM-based similarity detection
- **Incremental Processing:** Supports analyzing new documents without reprocessing everything
- **Top-3 Cluster Assignment:** Each relationship is assigned to its 3 most relevant tag clusters

### Visualization Features
- **Interactive Network Graph:** Force-directed graph with edge deduplication for performance
- **Actor-Centric Views:** Click any actor to see their specific relationships
- **Smart Filtering:** Filter by 30 content categories and hop distance from Jeffrey Epstein
- **Density-Based Pruning:** Displays highest-density network connections for clarity
- **Timeline View:** Chronological relationship browser with document links
- **Document Viewer:** Full-text document display with highlighting
- **Responsive Design:** Works on desktop and mobile devices
- **Performance Optimized:** Uses materialized database columns for fast filtering

---

## Project Structure

```
docnetwork/
â”œâ”€â”€ analysis_pipeline/          # Document analysis scripts
â”‚   â”œâ”€â”€ extract_data.py        # Initial document extraction
â”‚   â”œâ”€â”€ analyze_documents.ts   # Main AI analysis pipeline
â”‚   â”œâ”€â”€ cluster_tags.ts        # K-means tag clustering
â”‚   â”œâ”€â”€ dedupe_with_llm.ts     # Entity deduplication
â”‚   â””â”€â”€ extracted/             # Raw extracted documents
â”‚
â”œâ”€â”€ network-ui/                 # React visualization app
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”œâ”€â”€ api.ts            # Backend API client
â”‚   â”‚   â””â”€â”€ App.tsx           # Main application
â”‚   â””â”€â”€ dist/                  # Production build
â”‚
â”œâ”€â”€ api_server.ts              # Express API server
â”œâ”€â”€ document_analysis.db       # SQLite database (91MB)
â”œâ”€â”€ tag_clusters.json          # 30 semantic tag clusters
â””â”€â”€ analysis_pipeline/update_top_clusters.ts # Migration: materialize top clusters
```

---

## Core Components

### Analysis Pipeline

#### 1. Document Extraction (`analysis_pipeline/extract_data.py`)
**Purpose:** Extract raw text from PDF documents
**Input:** PDF files in `data/documents/`
**Output:** JSON files in `analysis_pipeline/extracted/`
**Key Features:**
- Preserves document metadata (ID, category, date)
- Handles various PDF formats
- Stores full text for AI analysis

#### 2. Document Analysis (`analysis_pipeline/analyze_documents.ts`)
**Purpose:** Main AI-powered extraction pipeline
**Input:** Extracted JSON documents
**Output:** SQLite database with entities and relationships
**Key Features:**
- Uses Claude to extract RDF-style triples (subject-action-object)
- Extracts temporal information (dates, timestamps)
- Tags relationships with contextual metadata
- Handles batch processing with rate limiting
- Stores document full text for search

**Database Schema:**
```sql
-- Documents table
CREATE TABLE documents (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  doc_id TEXT UNIQUE NOT NULL,
  file_path TEXT NOT NULL,
  one_sentence_summary TEXT NOT NULL,      -- AI-generated brief summary
  paragraph_summary TEXT NOT NULL,         -- AI-generated detailed summary
  date_range_earliest TEXT,                -- Earliest date mentioned in document
  date_range_latest TEXT,                  -- Latest date mentioned in document
  category TEXT NOT NULL,                  -- Document category
  content_tags TEXT NOT NULL,              -- JSON array of content tags
  analysis_timestamp TEXT NOT NULL,        -- When analysis was performed
  input_tokens INTEGER,                    -- Claude API usage metrics
  output_tokens INTEGER,
  cache_read_tokens INTEGER,
  cost_usd REAL,                          -- Estimated API cost
  error TEXT,                             -- Error message if analysis failed
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  full_text TEXT                          -- Complete document text for search
);
CREATE INDEX idx_documents_doc_id ON documents(doc_id);
CREATE INDEX idx_documents_category ON documents(category);

-- RDF triples (relationships)
CREATE TABLE rdf_triples (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  doc_id TEXT NOT NULL,
  timestamp TEXT,                         -- When the event occurred
  actor TEXT NOT NULL,                    -- Subject of the relationship
  action TEXT NOT NULL,                   -- Action/verb
  target TEXT NOT NULL,                   -- Object of the relationship
  location TEXT,                          -- Where the event occurred
  actor_likely_type TEXT,                 -- Type of actor (person, organization, etc.)
  triple_tags TEXT,                       -- JSON array of tags
  explicit_topic TEXT,                    -- Explicit subject matter
  implicit_topic TEXT,                    -- Inferred subject matter
  sequence_order INTEGER NOT NULL,        -- Order within document
  top_cluster_ids TEXT,                   -- JSON array of top 3 cluster IDs (materialized)
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (doc_id) REFERENCES documents(doc_id) ON DELETE CASCADE
);
CREATE INDEX idx_rdf_triples_doc_id ON rdf_triples(doc_id);
CREATE INDEX idx_rdf_triples_actor ON rdf_triples(actor);
CREATE INDEX idx_rdf_triples_timestamp ON rdf_triples(timestamp);
CREATE INDEX idx_top_cluster_ids ON rdf_triples(top_cluster_ids);

-- Entity aliases (deduplication)
CREATE TABLE entity_aliases (
  original_name TEXT PRIMARY KEY,
  canonical_name TEXT NOT NULL,
  reasoning TEXT,                         -- LLM explanation for the merge
  created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
  created_by TEXT DEFAULT &#039;llm_dedupe&#039;    -- Source of the alias
);
```

#### 3. Tag Clustering (`analysis_pipeline/cluster_tags.ts`)
**Purpose:** Group 28,000+ tags into semantic clusters
**Input:** All unique tags from database
**Output:** `tag_clusters.json` with 30 clusters
**Process:**
1. Collect all unique tags from triples
2. Generate or load cached embeddings using Qwen3-Embedding-0.6B-ONNX
3. Run K-means clustering with K-means++ initialization
4. Generate human-readable cluster names from exemplar tags
5. Save cluster assignments with full tag lists

**Technical Details:**
- **Algorithm:** K-means with cosine distance metric
- **Initialization:** K-means++ for better convergence
- **Convergence:** Typically ~85 iterations
- **Complexity:** O(nÂ·kÂ·i) - much faster than hierarchical methods
- **Output:** 30 clusters ranging from 500-1400 tags each

#### 4. Entity Deduplication (`analysis_pipeline/dedupe_with_llm.ts`)
**Purpose:** Merge duplicate entity mentions
**Input:** Entity names from database
**Output:** `entity_aliases` table mapping variants to canonical names
**Process:**
1. Identify potential duplicates using fuzzy matching
2. Use Claude to determine if entities are the same person
3. Create alias mappings (e.g., &quot;Jeff Epstein&quot; â†’ &quot;Jeffrey Epstein&quot;)
4. API server resolves aliases in real-time

#### 5. Migration Scripts
**`analysis_pipeline/update_top_clusters.ts`**
- Adds and populates `top_cluster_ids` column to `rdf_triples`
- Computes top 3 clusters for each triple based on tag matches
- Creates index for fast filtering
- Improves query performance by 10x+

---

### API Server (`api_server.ts`)

**Purpose:** Express.js backend serving data and frontend
**Port:** 3001 (configurable via `PORT` env var)
**Technology:** Express, better-sqlite3, CORS

#### Key Endpoints

**`GET /api/stats`**
- Returns database statistics (document count, triple count, actor count)
- Shows top document categories

**`GET /api/tag-clusters`**
- Returns all 30 tag clusters with metadata
- Includes cluster names, exemplar tags, and tag counts

**`GET /api/relationships?limit=9600&amp;clusters=0,1,2&amp;maxHops=3`**
- Returns relationship network filtered by clusters and hop distance
- Applies density-based pruning (highest-degree nodes prioritized)
- Edge deduplication before limiting (slider value = unique visual edges)
- Returns metadata: `{ relationships, totalBeforeLimit, totalBeforeFilter }`
- Uses materialized `top_cluster_ids` for fast filtering

**`GET /api/actor/:name/relationships?clusters=0,1,2`**
- Returns all relationships for a specific actor
- Handles entity aliases (resolves variants to canonical names)
- Filtered by selected tag clusters
- Returns: `{ relationships, totalBeforeFilter }`

**`GET /api/search?q=query`**
- Searches for actors by name
- Returns fuzzy matches with relationship counts

**`GET /api/document/:docId`**
- Returns document metadata
- Includes category, doc_id, file path

**`GET /api/document/:docId/text`**
- Returns full document text
- Used for document viewer modal

#### Performance Optimizations
- **Materialized Clusters:** Pre-computed top 3 clusters per triple
- **Indexed Columns:** Indexes on `top_cluster_ids`, `actor`, `target`
- **Database Limits:** 100k row limit to prevent memory exhaustion
- **Alias Resolution:** Efficient LEFT JOIN on entity_aliases
- **Rate Limiting:** 1000 requests per 15 minutes per IP

---

### Visualization Interface

#### Frontend Architecture (`network-ui/`)

**Technology Stack:**
- **React 18** with TypeScript
- **Vite** for build tooling
- **TailwindCSS** for styling
- **react-force-graph-2d** for network visualization
- **D3.js** for force simulation

#### Key Components

**`App.tsx`** - Main application container
- Manages global state (relationships, selected actor, filters)
- Loads tag clusters and enables all by default
- Coordinates data fetching and updates
- Handles desktop/mobile layout switching

**`NetworkGraph.tsx`** - Force-directed graph visualization
- Renders nodes (actors) and links (relationships)
- Node size based on connection count
- Click actors to select/deselect
- Zoom and pan controls
- Performance: Handles 15,000+ relationships smoothly

**`Sidebar.tsx`** - Desktop left sidebar
- Displays database statistics
- Actor search with autocomplete
- Relationship limit slider (100-25,000, default 9,600 desktop / 3,000 mobile)
- Hop distance filter (1-10 hops from Jeffrey Epstein, default 3)
- Tag cluster filter buttons
- Document category breakdown

**`RightSidebar.tsx`** - Desktop right sidebar (actor details)
- Shows when actor is selected
- Timeline view of actor&#039;s relationships
- &quot;Showing X of Y relationships&quot; indicator
- Document links with click-to-view

**`MobileBottomNav.tsx`** - Mobile navigation
- Tabbed interface: Search, Timeline, Filters
- Condensed version of desktop sidebars
- Touch-optimized controls

**`DocumentModal.tsx`** - Full-text document viewer
- Displays complete document text
- Highlights actor names in context
- Scrollable with close button
- Fetches text on demand

**`WelcomeModal.tsx`** - First-time visitor welcome
- Introduces users to the explorer
- Stored in localStorage (shown once)
- Dismissible

#### State Management

**Global State (in App.tsx):**
```typescript
const [stats, setStats] = useState&lt;Stats | null&gt;(null);
const [tagClusters, setTagClusters] = useState&lt;TagCluster[]&gt;([]);
const [relationships, setRelationships] = useState&lt;Relationship[]&gt;([]);
const [totalBeforeLimit, setTotalBeforeLimit] = useState&lt;number&gt;(0);
const [selectedActor, setSelectedActor] = useState&lt;string | null&gt;(null);
const [actorRelationships, setActorRelationships] = useState&lt;Relationship[]&gt;([]);
const [actorTotalBeforeFilter, setActorTotalBeforeFilter] = useState&lt;number&gt;(0);
const [limit, setLimit] = useState(isMobile ? 3000 : 9600);
const [maxHops, setMaxHops] = useState&lt;number | null&gt;(3);
const [minDensity, setMinDensity] = useState(50);
const [enabledClusterIds, setEnabledClusterIds] = useState&lt;Set&lt;number&gt;&gt;(new Set());
```

**Data Flow:**
1. Load tag clusters on mount â†’ enable all clusters
2. Fetch relationships when limit or clusters change
3. Fetch actor relationships when actor selected or clusters change
4. Update graph when relationships change

#### Responsive Design
- **Desktop (&gt;1024px):** Dual sidebar layout with main graph
- **Mobile (&lt;1024px):** Full-screen graph with bottom navigation
- **Adaptive Limits:** Mobile defaults to 3k relationships, desktop 9.6k

---

## Local Development

```bash
# Install dependencies
npm install
cd network-ui &amp;&amp; npm install &amp;&amp; cd ..

# Run API server
npx tsx api_server.ts

# Run frontend (separate terminal)
cd network-ui &amp;&amp; npm run dev

# Access:
# - API: http://localhost:3001
# - Frontend: http://localhost:5173
```

---

## Key Files Reference

### Analysis Scripts
| File | Purpose | When to Run |
|------|---------|-------------|
| `analysis_pipeline/analyze_documents.ts` | Main AI analysis | After impactful schema changes or adding new docs |
| `analysis_pipeline/cluster_tags.ts` | Create tag clusters with K-means | After major tag changes |
| `analysis_pipeline/dedupe_with_llm.ts` | Deduplicate entities | After analyzing new documents |
| `analysis_pipeline/update_top_clusters.ts` | Materialize cluster IDs | After running cluster_tags.ts |

---

## License

MIT License - See LICENSE file for details

## Contact

For questions or issues, please open a GitHub issue.

**Repository:** https://github.com/maxandrews/Epstein-doc-explorer
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[pshenok/server-survival]]></title>
            <link>https://github.com/pshenok/server-survival</link>
            <guid>https://github.com/pshenok/server-survival</guid>
            <pubDate>Wed, 04 Feb 2026 00:06:16 GMT</pubDate>
            <description><![CDATA[Tower defense game that teaches cloud architecture. Build infrastructure, survive traffic, learn scaling.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pshenok/server-survival">pshenok/server-survival</a></h1>
            <p>Tower defense game that teaches cloud architecture. Build infrastructure, survive traffic, learn scaling.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 4,520</p>
            <p>Forks: 551</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre># Server Survival

![Gameplay Demo](assets/gameplay.gif)

**Server Survival** is an interactive 3D simulation game where you play as a **Cloud Architect**. Your mission is to build and scale a resilient cloud infrastructure to handle increasing traffic loads while fighting off DDoS attacks, managing your budget, and keeping your services healthy.

[![PLAY NOW](https://img.shields.io/badge/PLAY_NOW-Server_Survival-2ea44f?style=for-the-badge)](https://pshenok.github.io/server-survival/)

## How to Play

### Objective

Survive as long as possible! Manage your **Budget ($)**, **Reputation (%)**, and **Service Health**.

- **Earn Money** by successfully processing legitimate traffic requests.
- **Lose Reputation** if requests fail or if malicious traffic slips through.
- **Maintain Health** - Services degrade under load and need repairs.
- **Game Over** if Reputation hits 0% or you go bankrupt ($-1000).

### Traffic Types

| Traffic       | Color  | Destination | Reward | Description                            |
| :------------ | :----- | :---------- | :----- | :------------------------------------- |
| **STATIC**    | Green  | CDN / Storage | $0.50  | Static file requests (images, CSS, JS) |
| **READ**      | Blue   | SQL DB      | $0.80  | Database read operations               |

### Infrastructure &amp; Services

Build your architecture using the toolbar. Each service has a cost, capacity, and upkeep:

| Service      | Cost | Capacity  | Upkeep    | Function                                                           |
| :----------- | :--- | :-------- | :-------- | :----------------------------------------------------------------- |
| **Firewall** | $40  | 30        | Low       | **Security.** First line of defense. Blocks malicious traffic.     |
| **Queue**    | $40  | Queue:200 | Low       | **Buffer.** Buffers requests during spikes. Prevents drops.        |
| **Load Balancer**| $50  | 20        | Medium    | **Distribution.** Distributes traffic to multiple instances.      |
| **Compute**  | $60  | 4         | High      | **Processing.** Processes requests. **Upgradeable T1â†’T3.**         |
| **CDN**      | $60  | 50        | Low       | **Delivery.** Caches STATIC content at edge (95% hit rate).        |
| **Cache**    | $60  | 30        | Medium    | **Caching.** Caches responses to reduce DB load.                   |
| **SQL DB**   | $150 | 8         | Very High | **Database.** Destination for READ/WRITE/SEARCH. **Upgradeable T1â†’T3.** |
| **Storage**  | $25  | 25        | Low       | **File System.** Destination for STATIC/UPLOAD traffic.            |

### Scoring &amp; Economy

| Action         | Money  | Score | Reputation |
| :------------- | :----- | :---- | :--------- |
| Static Request | +$0.50 | +3    | +0.1       |
| DB Read        | +$0.80 | +5    | +0.1       |
| DB Write       | +$1.20 | +8    | +0.1       |
| File Upload    | +$1.50 | +10   | +0.1       |
| Search Query   | +$0.80 | +5    | +0.1       |
| Attack Blocked | +$0.50 | +10   | -          |
| Request Failed | -      | -half | -1         |
| Attack Leaked  | -      | -     | -5         |

### Upkeep &amp; Cost Scaling

- **Base Upkeep:** Each service has per-minute upkeep costs
- **Upkeep Scaling:** Costs increase 1x to 2x over 10 minutes
- **Repair Costs:** 15% of service cost to manually repair
- **Auto-Repair:** +10% upkeep overhead when enabled

### Game Modes

#### Survival Mode

The core experience - survive as long as possible against escalating traffic with constant intervention required:

**Dynamic Challenges:**

- **RPS Acceleration** - Traffic multiplies at time milestones (Ã—1.3 at 1min â†’ Ã—4.0 at 10min)
- **Random Events** - Cost spikes, capacity drops, traffic bursts every 15-45 seconds
- **Traffic Shifts** - Traffic patterns change every 40 seconds
- **DDoS Spikes** - 50% malicious traffic waves every 45 seconds
- **Service Degradation** - Services lose health under load, require repairs

**New UI Features:**

- **Health bars on all services**
- **Active event indicator bar at top**
- **Detailed finances panel (income/expenses breakdown)**
- **Service health panel with repair costs**
- **Auto-repair toggle**
- **Game over analysis with tips**

#### Sandbox Mode

A fully customizable testing environment for experimenting with any architecture:

| Control           | Description                                                       |
| :---------------- | :---------------------------------------------------------------- |
| **Budget**        | Set any starting budget (slider 0-10K, or type any amount)        |
| **RPS**           | Control traffic rate (0 = stopped, or type 100+ for stress tests) |
| **Traffic Mix**   | Adjust all 6 traffic type percentages independently               |
| **Burst**         | Spawn instant bursts of specific traffic types                    |
| **Upkeep Toggle** | Enable/disable service costs                                      |
| **Clear All**     | Reset all services and restore budget                             |

**No game over in Sandbox** - experiment freely!

### Recent Features (v2.1)

- **Constant Intervention Mechanics** - Game requires active management throughout
- **Service Health System** - Visual health bars, manual/auto repair options
- **RPS Milestones** - Traffic surge warnings with multiplier display
- **Active Event Bar** - Shows current random event with countdown timer
- **Detailed Finances** - Income by request type, expenses by service with counts
- **Game Over Analysis** - Failure reason, description, and contextual tips
- **Retry Same Setup** - Restart with same architecture after game over
- **Interactive Tutorial** - Guided walkthrough for new players

### Controls

- **Left Click:** Select tools, place services, and connect nodes.
- **Right Click + Drag:** Pan the camera.
- **Scroll:** Zoom in and out.
- **WASD / Arrows:** Move camera (pan) when zoomed in.
- **ESC:** Open main menu and pause game. Press again or click Resume to close menu (stays paused).
- **Camera Reset:** Press `R` to reset the camera position.
- **Birds-Eye View:** Press `T` to switch between isometric and top-down view.
- **Hide HUD:** Press `H` to toggle UI panels.
- **Connect Tool:** Click two nodes to create a connection (flow direction matters!).
  - _Valid Flows:_ Internet -&gt; (Firewall/CDN) -&gt; Load Balancer -&gt; Queue -&gt; Compute -&gt; Cache -&gt; (SQL DB/Storage)
- **Delete Tool:** Remove services to recover 50% of the cost.
- **Time Controls:** Pause, Play (1x), and Fast Forward (3x).

## Strategy Tips

1.  **Block Attacks First:** Always place a Firewall immediately connected to the Internet. Malicious leaks destroy reputation fast (-5 per leak).
2.  **Use CDN for Static Content:** Connect Internet -&gt; CDN -&gt; Storage. The CDN handles 95% of static traffic cheaply!
3.  **Watch Service Health:** Damaged services have reduced capacity. Click to repair or enable Auto-Repair.
4.  **Scale for Traffic Surges:** RPS multiplies at milestones - prepare before Ã—2.0 at 3 minutes!
5.  **Balance Income vs Upkeep:** Start lean, scale as income grows. Over-provisioning leads to bankruptcy.
6.  **Use Cache Wisely:** Reduces database load significantly for READ requests.
7.  **Buffer with Queue:** Queue helps survive traffic burst events without dropping requests.
8.  **React to Events:** Watch the event bar - cost spikes mean hold off on purchases, traffic bursts mean ensure capacity.

## Tech Stack

- **Core:** Vanilla JavaScript (ES6+)
- **Rendering:** [Three.js](https://threejs.org/) for 3D visualization.
- **Styling:** [Tailwind CSS](https://tailwindcss.com/) for the glassmorphism UI.
- **Build:** No build step required! Just standard HTML/CSS/JS.

## Getting Started

1.  Clone the repository.
2.  Open `index.html` in your modern web browser.
3.  Start building your cloud empire!

## Community

Join our Discord server to discuss strategies and share your high scores:
[Join Discord](https://discord.gg/f38NgHDwnK)

---

_Built with code and chaos._
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[databricks-industry-solutions/pixels]]></title>
            <link>https://github.com/databricks-industry-solutions/pixels</link>
            <guid>https://github.com/databricks-industry-solutions/pixels</guid>
            <pubDate>Wed, 04 Feb 2026 00:06:15 GMT</pubDate>
            <description><![CDATA[Facilitates simple large scale processing of HLS Medical images, documents, zip files. OHIF Viewer, 2 segmentation models and interactive learning.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/databricks-industry-solutions/pixels">databricks-industry-solutions/pixels</a></h1>
            <p>Facilitates simple large scale processing of HLS Medical images, documents, zip files. OHIF Viewer, 2 segmentation models and interactive learning.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 306</p>
            <p>Forks: 98</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre>&lt;div bgcolor=&quot;white&quot;&gt;
  &lt;img src=https://hls-eng-data-public.s3.amazonaws.com/img/Databricks_HLS.png width=&quot;380px&quot; align=&quot;right&quot;&gt;
&lt;/div&gt;

# `pixels` Solution Accelerator
âœ…  Ingest and index DICOM image metadata (.dcm and from zip archives)
&lt;/br&gt; âœ…  Analyze DICOM image metadata with SQL and Machine Learning.
&lt;/br&gt; âœ…  View, segment, label DICOM Images with OHIF viewer integrated into Lakehouse Apps and Databricks security model. 
&lt;/br&gt; âœ…  One button push to launch model training from OHIF viewer.
&lt;/br&gt; âœ…  NVIDIA&#039;s [MONAI](https://docs.nvidia.com/monai/index.html) Integration, AI to automatically segment medical images and train custom models.
&lt;/br&gt; âœ…  Leverage Databricks&#039; [Model Serving](https://docs.databricks.com/en/machine-learning/model-serving/index.html) with serverless GPU enabled clusters for real-time segmentation.

---
## Secure Lakehouse integrated DICOM Viewer powered by OHIF
&lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/LHA_AUTOSEG.gif?raw=true&quot; alt=&quot;MONAI_AUTOSEG&quot;/&gt;&lt;/br&gt;

---
## Run SQL queries over DICOM metadata
![Analyze](https://github.com/databricks-industry-solutions/pixels/blob/main/images/DICOM-analyze-with-SQL.png?raw=true)

---
## Build Dashboards over DICOM metadata
add any features extracted too!
![Dashboard](images/pixels-dashboard.png)

---
## DICOM data ingestion is easy

```python
# import Pixels Catalog (indexer) and DICOM transformers &amp; utilities
from dbx.pixels import Catalog                              # 01
from dbx.pixels.dicom import *                              # 02

# catalog all your files
catalog = Catalog(spark)                                    # 03
catalog_df = catalog.catalog(&lt;path&gt;)                        # 04

# extract the DICOM metadata
meta_df = DicomMetaExtractor(catalog).transform(catalog_df) # 05

# save your work for SQL access
catalog.save(meta_df)                                       # 06
```
You&#039;ll find this example in [01-dcm-demo](https://github.com/databricks-industry-solutions/pixels/blob/main/01-dcm-demo.py) which does:

---
## Architecture
![image](https://github.com/user-attachments/assets/75decf47-3a37-446a-a672-d497d155f464)

The image depicts the **Pixels Reference Solution Architecture**, which outlines a data processing and analytics framework designed for healthcare or imaging applications. Here&#039;s a breakdown of its components:

### **Key Functional Areas**
1. **AI/BI Analytics**: Supports cohort building and natural language-based analysis.
   
2. **Lakehouse Apps**: Includes an OHIF Viewer for labeling and customer-specific applications.

3. **Deep Learning**: Facilitates active learning and customer model training.

4. **Realtime Inferencing**: Implements MONAI (Medical Open Network for AI) for segmentation integration with the OHIF viewer. Customer provided proprietary models can be easily plugged in.

### **Data Flow: Batch, Incremental, Streaming Lakeflow**
The architecture processes data in stages:
1. **Acquire**: from data in ADLS, S3, GCS cloud storage as governed by Unity Catalog (UC) Volumes.  Based on customer demand, due to the composible nature of the solution accelerator, sources VNA, PACS, CIFS, AWS HealthImaging can be added as needed.
   
2. **Ingest**:  Ultimately all the DICOM files are ingested. Ingesting and producing Nifti file formats are currently on the roadmap.

3. **Extract &amp; Index**: Unzips files, storing the extracted DICOM files into a UC volume. All of the DICOM metadata tags are extracted and stored in Databricks Data Intelligence Platform tables.

4. **Protect â€“ Metadata**: Applies PHI (Protected Health Information) redaction via format preserving encryption to all necessary tags.

5. **Protect â€“ Image**: Ensures PHI redaction for pixel-level data. This is under active integration based on work Databricks has done in previous solution accelerators.

6. **Inferencing**: Utilizes industry-standard models pre-trained MONAI open source models sponsored by NVIDIA. Similarly, customers can fine tune the MONAI models or bring their own segmentation or featurization models.

### **Supporting Layers**
- **Governance Layer**: Unity Catalog provides data access controls, automatic capture of data lineage (including models)
  
- **Customerâ€™s Cloud Storage**: Stores object indexes, folders, and ML models in open formats in customer&#039;s account.
  
- **Open Access**: Provides APIs, SQL connections, Spark integration, and credential vending via Delta Sharing.

This architecture is designed to handle healthcare imaging data securely while enabling advanced analytics and AI-driven insights.


---
## Getting started

1. To run this accelerator, [clone](https://docs.databricks.com/aws/en/repos/git-operations-with-repos) this repo into a Databricks workspace. 

2. Attach a notebook to Serverless Compute or a cluster (&gt;=DBR 14.3 LTS)
3. Run [`config/setup.py`]($./config/setup) from the notebook. This will install the pixels package onto your workspace


## Run pipeline as a job
1. Attach the [`RUNME`]($./RUNME) notebook to Serverless Compute or a cluster (&gt;=DBR 14.3 LTS). 2. Execute the notebook via Run-All. You can configure the notebook tasks run by the job in `job_json`
A multi-step-job describing the accelerator pipeline will be created, and the link will be provided. The cost associated with running the accelerator is the user&#039;s responsibility.

## Incremental processing
Pixels allows you to ingest DICOM files in a streaming fashion using [autoloader](https://docs.databricks.com/en/ingestion/auto-loader/unity-catalog.html) capability.
To enable incremental processing you need to set `streaming` and `streamCheckpointBasePath` as follows:
```python
catalog_df = catalog.catalog(path, streaming=True, streamCheckpointBasePath=&lt;checkpointPath&gt;)
```

## Built-in unzip
Automatically extracts zip files in the defined volume path.
If extractZip is not enabled then zip files will be ignored.
To enable unzip capability you need to set `extractZip`. The parameter `extractZipBasePath` is optional and the default path will be volume + /unzipped/
```python
catalog_df = catalog.catalog(path, extractZip=True, extractZipBasePath=&lt;unzipPath&gt;)
```

## Metadata Anonymization
Pixels provides a feature to anonymize DICOM metadata to ensure patient privacy and compliance with regulations. This feature can be enabled during the cataloging process. An example can be explored in the [03-Metadata-DeIdentification](https://github.com/databricks-industry-solutions/pixels/blob/main/03-Metadata-DeIdentification.py) notebook.

To enable metadata anonymization, you can use the following extractor:
```python
metadata_df = DicomMetaAnonymizerExtractor(
   catalog,
   anonym_mode=&quot;METADATA&quot;,
   fp_key=&lt;fp_key&gt;, #ONLY HEX STRING ALLOWED - 128, 192 or 256 bits
   fp_tweak=&lt;fp_tweak&gt;,   #ONLY HEX STRING ALLOWED - 64 bits
   anonymization_base_path=&lt;anonym_path&gt;
).transform(catalog_df)
```
`fp_key` is the format preserving encryption key used to ensure that the anonymization process is consistent across different runs. This key is used to generate pseudonyms for sensitive data fields, ensuring that the same input value always maps to the same pseudonym. This is useful for maintaining the ability to link records across datasets without revealing the original sensitive information.

`fp_tweak` is an optional parameter that can be used to add an additional layer of randomness to the pseudonymization process. This can be useful for further enhancing privacy.

By setting the `anonym_mode` parameter to `&quot;METADATA&quot;`, the DICOM metadata will be anonymized during the ingestion process. This ensures that sensitive patient information is not stored in the catalog.
The default configuration will save the anonymized DICOM files under `anonymization_base_path` property&#039;s path.

---
## OHIF Viewer
Inside `dbx.pixels` resources folder, a pre-built version of [OHIF Viewer](https://github.com/OHIF/Viewers) with Databricks and [Unity Catalog Volumes](https://docs.databricks.com/en/sql/language-manual/sql-ref-volumes.html) extension is provided. 

All the catalog entries will be available in an easy to use study list.
![Catalog](https://github.com/databricks-industry-solutions/pixels/blob/main/images/ohif_catalog_view.png?raw=true)
Fast and multiple-layer visualization capability.
![CT_View](https://github.com/databricks-industry-solutions/pixels/blob/main/images/ohif_mr_view.png?raw=true)

To start the OHIF Viewer web app you need to:
 - Execute the [06-OHIF-Viewer](https://github.com/databricks-industry-solutions/pixels/blob/main/06-OHIF-Viewer.py) inside a Databricks workspace.
 - Set the `table` parameter to the full name of your Pixels catalog table. Ex: `main.pixels_solacc.object_catalog`
 - Set the `sqlWarehouseID`parameter to execute the queries required to collect the records. It&#039;s the final section of the `HTTP path` in the `Connection details` tab. Use [Serverless](https://docs.databricks.com/en/admin/sql/warehouse-types.html#sql-warehouse-types) for best performance.

    &lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/sqlWarehouseID.png?raw=true&quot; alt=&quot;sqlWarehouseID&quot;/&gt;

 - Use the link generated in the last notebook to access the OHIF viewer page.

## Save measurements and segmentations
The OHIF Viewer allows you to save back to Databricks the measurements and the segmentations created in the viewer.
The metadata will be stored in the object_catalog, and the generated dicom files in the volume under the path `/ohif/exports/`.

&lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/ohif_save_segm.png?raw=true&quot; alt=&quot;OHIF_SAVE_SEG&quot; height=&quot;300&quot;/&gt;
&lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/ohif_save_meas.png?raw=true&quot; alt=&quot;OHIF_SAVE_MEAS&quot; height=&quot;300&quot;/&gt;
&lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/ohif_save_result.png?raw=true&quot; alt=&quot;OHIF_SAVED&quot; height=&quot;300&quot;/&gt;


## MONAILabel Integration

[MONAILabel](https://monai.io/label.html) is an open-source tool designed for interactive medical image labeling. It supports various annotation tasks such as segmentation and classification, providing a seamless experience when integrated with viewers like OHIF that is already available in this solution accelerator.

![MONAI_BTN](https://github.com/databricks-industry-solutions/pixels/blob/main/images/monailabel_result.png?raw=true)
Once the server is running, you can use the OHIF Viewer to interact with your medical images. This integration allows you to leverage advanced annotation capabilities directly within your Databricks environment.

### Key Features
 - Interactive Annotation: Use AI-assisted tools for efficient labeling.
 - Seamless Integration: Work directly within Databricks using a web-based viewer.
 - Customizable Workflows: Tailor the annotation process to fit specific research needs.

### MONAILabel Setup Instructions
To execute the MONAILabel server it is mandatory to use a cluster with Databricks Runtime Version of `14.3 LTS ML`. For the best performance use a [GPU-Enabled compute](https://docs.databricks.com/en/compute/gpu.html#gpu-enabled-compute).
#### Start the MONAILabel server
 - Execute the [05-MONAILabel](https://github.com/databricks-industry-solutions/pixels/blob/main/05-MONAILabel.py) inside a Databricks workspace.
 - Set the `table` parameter to the full name of your Pixels catalog table. Ex: `main.pixels_solacc.object_catalog`
 - Set the `sqlWarehouseID`parameter to the DBSQL Warehouse ID, needed to run queries required to collect the records. Use [Serverless](https://docs.databricks.com/en/admin/sql/warehouse-types.html#sql-warehouse-types) for best performance.
    &lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/sqlWarehouseID.png?raw=true&quot; alt=&quot;sqlWarehouseID&quot;&gt;
#### Open the OHIF Viewer
 - Execute the notebook [06-OHIF-Viewer](https://github.com/databricks-industry-solutions/pixels/blob/main/06-OHIF-Viewer.py) to start the OHIF Viewer with the MONAILabel extension and open the generated link.
 - Select the preferred CT scan study and press the `MONAI Label` button.

    &lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/monailabel_btn.png?raw=true&quot; alt=&quot;MONAI_BTN&quot; height=&quot;250&quot;/&gt;&lt;/br&gt;
#### Connect, execute and save
 - Connect the MONAILabel server using the refresh button.

    &lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/monailabel_server.png?raw=true&quot; alt=&quot;MONAI_SERVER&quot; height=&quot;200&quot;/&gt;&lt;/br&gt;
 - Execute an auto-segmentation task using the Run button and wait for the results to be displayed.

    &lt;img src=&quot;https://github.com/databricks-industry-solutions/pixels/blob/main/images/monailabel_autosegm.png?raw=true&quot; alt=&quot;MONAI_AUTOSEG&quot; height=&quot;650&quot;/&gt;&lt;/br&gt;
 - Save the final result metadata in the catalog and the generated dicom file in the volume under the path `/ohif/exports/` using the button `Export DICOM SEG`.

This setup enhances your medical image analysis workflow by combining Databricks&#039; computing power with MONAILabel&#039;s sophisticated annotation tools.

### Model Serving Instructions

To deploy the MONAILabel server in a Model Serving endpoint we prepared [ModelServing](https://github.com/databricks-industry-solutions/pixels/blob/main/monailabel_model/ModelServing.py), a Databricks notebook designed to initialize the Databricks customized version of the **MONAILabel server** that wraps the server in an **MLflow Python custom model** and registers it for use in a **serving endpoint**.

#### Key Features

- **Model Creation**: Utilizes the MONAILabel auto segmentation model on CT AXIAL images.
- **Unity Catalog Integration**: Adds the model to the Unity Catalog for organized management.
- **Serving Endpoint Deployment**: Deploys the model in a serving endpoint for real-time inference.

#### Auto Segmentation with Lakehouse App and Serving Endpoint

https://github.com/user-attachments/assets/8cf62378-ab39-4a89-86ad-c2f231b7a524

#### Active Learning

https://github.com/user-attachments/assets/17142752-d9b9-434b-b893-b6bc05080f54


## Working with Unity Catalog
Unity Catalog (UC) [volumes](https://docs.databricks.com/en/data-governance/unity-catalog/create-volumes.html) are the recommended approach for providing access to and governing non-tabular data assets in a cloud object storage locations, including DICOM files. Volumes are accessed by using the following format for the path that is passed to the pixels `Catalog` object - 
```
/Volumes/&lt;catalog&gt;/&lt;schema&gt;/&lt;volume&gt;/&lt;path-level-1&gt;/...
```
where `&lt;catalog&gt;`, `&lt;schema&gt;` and `&lt;volume&gt;` reflect the three-level namespace of Unity Catalog. The path field returned by the `Catalog` object reflects the volume file path listed above and subsequent metadata and thumbnail extraction operations will use volumes for accessing files.

DICOM file Ingestion works with Shared, Dedicated and Serverless Compute types.

---
## Contributors
- Douglas Moore @ Databricks
- Emanuele Rinaldi @ Databricks
- Nicole Jingting Lu @ Databricks
- Krishanu Nandy @ Databricks
- May Merkle-Tan @ Databricks
- Cal Reynolds @ Databricks
- Guanyu Chen @ Databricks
- Yen Low @ Databricks
- Ben Russoniello @ Prominence Advisors


## About `dbx.pixels`
Relibly turn millions of image files into SQL accessible metadata, thumbnails; Enable Deep Learning, AI/BI Dashboarding, Genie Spaces.

- tags: 
dicom, dcm, pre-processing, visualization, repos, sql, python, spark, pyspark, package, image catalog, mamograms, dcm file
---

## About DICOM
![DICOM Image processing](https://dicom.offis.uni-oldenburg.de/images/dicomlogo.gif)
[Per OFFIS computer science institute](https://dicom.offis.uni-oldenburg.de/en/general/dicom-introduction/) 

DICOMÂ® â€” Digital Imaging and Communications in Medicine â€” is the international standard for medical images and related information. It defines the formats for medical images that can be exchanged with the data and quality necessary for clinical use.

DICOMÂ® is implemented in almost every radiology, cardiology imaging, and radiotherapy device (X-ray, CT, MRI, ultrasound, etc.), and increasingly in devices in other medical domains such as ophthalmology and dentistry. With hundreds of thousands of medical imaging devices in use, DICOMÂ® is one of the most widely deployed healthcare messaging Standards in the world. There are literally billions of DICOMÂ® images currently in use for clinical care.

Since its first publication in 1993, DICOMÂ® has revolutionized the practice of radiology, allowing the replacement of X-ray film with a fully digital workflow. Much as the Internet has become the platform for new consumer information applications, DICOMÂ® has enabled advanced medical imaging applications that have â€œchanged the face of clinical medicineâ€. From the emergency department, to cardiac stress testing, to breast cancer detection, DICOMÂ® is the standard that makes medical imaging work â€” for doctors and for patients.

DICOMÂ® is recognized by the International Organization for Standardization as the ISO 12052 standard.

## Licensing

&amp;copy; 2024 Databricks, Inc. All rights reserved. The source in this notebook is provided subject to the Databricks License [https://databricks.com/db-license-source].  All included or referenced third party libraries are subject to the licenses set forth below.

| library              | purpose                             | license                       | source                                                  |
|----------------------|-------------------------------------|-------------------------------|---------------------------------------------------------|
| dbx.pixels           | Scale out image processing library  | Databricks                    | https://github.com/databricks-industry-solutions/pixels |
| pydicom              | Python api for DICOM files          | MIT                           | https://github.com/pydicom/pydicom                      |
| python-gdcm          | Install gdcm C++ libraries          | Apache Software License (BSD) | https://github.com/tfmoraes/python-gdcm                 |
| gdcm                 | Parse DICOM files                   | BSD                           | https://sourceforge.net/projects/gdcm                   |
| s3fs                 | Resolve s3:// paths                 | BSD 3-Clause                  | https://github.com/fsspec/s3fs                          |
| pandas               | Pandas UDFs                         | BSD License (BSD-3-Clause)    | https://github.com/pandas-dev/pandas                    |
| OHIF Viewer          | Medical image viewer                | MIT                           | https://github.com/OHIF/Viewers                         |
| MONAILabel           | Intelligent open source image labeling and learning tool | Apache-2.0 license  | https://github.com/Project-MONAI/MONAILabel |
| DICOGNITO            | A library and command line tool for anonymizing DICOM files | MIT  | https://github.com/blairconrad/dicognito |
| FF3                  | FPE - Format Preserving Encryption with FF3 in Python | Apache-2.0 license  | https://github.com/mysto/python-fpe |
| Vista3D              | MONAI Versatile Imaging SegmenTation and Annotation model | Apache-2.0 license (code) - NCLS v1 (model weight) | https://github.com/Project-MONAI/VISTA/tree/main/vista3d |


</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[GitSquared/edex-ui]]></title>
            <link>https://github.com/GitSquared/edex-ui</link>
            <guid>https://github.com/GitSquared/edex-ui</guid>
            <pubDate>Wed, 04 Feb 2026 00:06:14 GMT</pubDate>
            <description><![CDATA[A cross-platform, customizable science fiction terminal emulator with advanced monitoring & touchscreen support.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GitSquared/edex-ui">GitSquared/edex-ui</a></h1>
            <p>A cross-platform, customizable science fiction terminal emulator with advanced monitoring & touchscreen support.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 44,054</p>
            <p>Forks: 2,968</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;img alt=&quot;Logo&quot; src=&quot;media/logo.png&quot;&gt;
  &lt;br&gt;&lt;br&gt;
  &lt;a href=&quot;https://lgtm.com/projects/g/GitSquared/edex-ui/context:javascript&quot;&gt;&lt;img alt=&quot;undefined&quot; src=&quot;https://img.shields.io/lgtm/grade/javascript/g/GitSquared/edex-ui.svg?logo=lgtm&amp;logoWidth=18&quot;/&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://github.com/GitSquared/edex-ui/releases/latest&quot;&gt;&lt;img alt=&quot;undefined&quot; src=&quot;https://img.shields.io/github/release/GitSquared/edex-ui.svg?style=popout&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;#featured-in&quot;&gt;&lt;img alt=&quot;undefined&quot; src=&quot;https://img.shields.io/github/downloads/GitSquared/edex-ui/total.svg?style=popout&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/GitSquared/edex-ui/blob/master/LICENSE&quot;&gt;&lt;img alt=&quot;undefined&quot; src=&quot;https://img.shields.io/github/license/GitSquared/edex-ui.svg?style=popout&quot;&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://github.com/GitSquared/edex-ui/releases/download/v2.2.8/eDEX-UI-Windows.exe&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;undefined&quot; src=&quot;https://badgen.net/badge/Download/Windows/?color=blue&amp;icon=windows&amp;label&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/GitSquared/edex-ui/releases/download/v2.2.8/eDEX-UI-macOS.dmg&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;undefined&quot; src=&quot;https://badgen.net/badge/Download/macOS/?color=grey&amp;icon=apple&amp;label&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/GitSquared/edex-ui/releases/download/v2.2.8/eDEX-UI-Linux-x86_64.AppImage&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;undefined&quot; src=&quot;https://badgen.net/badge/Download/Linux64/?color=orange&amp;icon=terminal&amp;label&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/GitSquared/edex-ui/releases/download/v2.2.8/eDEX-UI-Linux-arm64-AppImage&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;undefined&quot; src=&quot;https://badgen.net/badge/Download/LinuxArm64/?color=orange&amp;icon=terminal&amp;label&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://aur.archlinux.org/packages/edex-ui&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;undefined&quot; src=&quot;https://badgen.net/badge/AUR/Package/cyan&quot;&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://github.com/GitSquared/edex-ui/releases/tag/v2.2.8&quot;&gt;&lt;strong&gt;&lt;i&gt;(Project archived oct. 18th 2021)&lt;/i&gt;&lt;/strong&gt;&lt;/a&gt;
  &lt;br&gt;&lt;br&gt;&lt;br&gt;
&lt;/p&gt;

eDEX-UI is a fullscreen, cross-platform terminal emulator and system monitor that looks and feels like a sci-fi computer interface.

---

&lt;a href=&quot;https://youtu.be/BGeY1rK19zA&quot;&gt;
  &lt;img align=&quot;right&quot; width=&quot;400&quot; alt=&quot;Demo on YouTube&quot; src=&quot;media/youtube-demo-teaser.gif&quot;&gt;
&lt;/a&gt;

Heavily inspired from the [TRON Legacy movie effects](https://web.archive.org/web/20170511000410/http://jtnimoy.com/blogs/projects/14881671) (especially the [Board Room sequence](https://gmunk.com/TRON-Board-Room)), the eDEX-UI project was originally meant to be *&quot;[DEX-UI](https://github.com/seenaburns/dex-ui) with less Â« art Â» and more Â« distributable software Â»&quot;*.

While keeping a futuristic look and feel, it strives to maintain a certain level of functionality and to be usable in real-life scenarios, with the larger goal of bringing science-fiction UXs to the mainstream.

&lt;br&gt;

It might or might not be a joke taken too seriously.


---

&lt;p align=&quot;center&quot;&gt;
  &lt;em&gt;Jump to: &lt;br&gt;&lt;a href=&quot;#features&quot;&gt;Features&lt;/a&gt; â€” &lt;a href=&quot;#screenshots&quot;&gt;Screenshots&lt;/a&gt; â€” &lt;a href=&quot;#qa&quot;&gt;Questions &amp; Answers&lt;/a&gt; â€” &lt;strong&gt;&lt;a href=&quot;#how-do-i-get-it&quot;&gt;Download&lt;/a&gt;&lt;/strong&gt; â€” &lt;a href=&quot;#featured-in&quot;&gt;Featured In&lt;/a&gt; â€” &lt;a href=&quot;#useful-commands-for-the-nerds&quot;&gt;Contributor Instructions&lt;/a&gt; â€” &lt;a href=&quot;#credits&quot;&gt;Credits&lt;/a&gt;&lt;/em&gt;
&lt;/p&gt;

## Sponsor

**Want to help support my open-source experiments and learn some cool JavaScript tricks at the same time?**

Click the banner below and sign up to **Bytes**, the only newsletter cool enough to be recommended by eDEX-UI.

[![Bytes by UI.dev](media/sponsor-uidev-bytes.jpg)](https://ui.dev/bytes/?r=gabriel)

## Features
- Fully featured terminal emulator with tabs, colors, mouse events, and support for `curses` and `curses`-like applications.
- Real-time system (CPU, RAM, swap, processes) and network (GeoIP, active connections, transfer rates) monitoring.
- Full support for touch-enabled displays, including an on-screen keyboard.
- Directory viewer that follows the CWD (current working directory) of the terminal.
- Advanced customization using themes, on-screen keyboard layouts, CSS injections. See the [wiki](https://github.com/GitSquared/edex-ui/wiki) for more info.
- Optional sound effects made by a talented sound designer for maximum hollywood hacking vibe.

## Screenshots
![Default screenshot](media/screenshot_default.png)

_[neofetch](https://github.com/dylanaraps/neofetch) on eDEX-UI 2.2 with the default &quot;tron&quot; theme &amp; QWERTY keyboard_

![Blade screenshot](media/screenshot_blade.png)

_Checking out available themes in [eDEX&#039;s config dir](https://github.com/GitSquared/edex-ui/wiki/userData) with [`ranger`](https://github.com/ranger/ranger) on eDEX-UI 2.2 with the &quot;blade&quot; theme_

![Disrupted screenshot](media/screenshot_disrupted.png)

_[cmatrix](https://github.com/abishekvashok/cmatrix) on eDEX-UI 2.2 with the experimental &quot;tron-disrupted&quot; theme, and the user-contributed DVORAK keyboard_

![Horizon screenshot](media/screenshot_horizon.png)

_Editing eDEX-UI source code with `nvim` on eDEX-UI 2.2 with the custom [`horizon-full`](https://github.com/GitSquared/horizon-edex-theme) theme_

## Q&amp;A
#### How do I get it?
Click on the little badges under the eDEX logo at the top of this page, or go to the [Releases](https://github.com/GitSquared/edex-ui/releases) tab, or download it through [one of the available repositories](https://repology.org/project/edex-ui/versions) (Homebrew, AUR...).

Public release binaries are unsigned ([why](https://gaby.dev/posts/code-signing)). On Linux, you will need to `chmod +x` the AppImage file in order to run it.
#### I have a problem!
Search through the [Issues](https://github.com/GitSquared/edex-ui/issues) to see if yours has already been reported. If you&#039;re confident it hasn&#039;t been reported yet, feel free to open up a new one. If you see your issue and it&#039;s been closed, it probably means that the fix for it will ship in the next version, and you&#039;ll have to wait a bit.
#### Can you disable the keyboard/the filesystem display?
You can&#039;t disable them (yet) but you can hide them. See the `tron-notype` theme.
#### Why is the file browser saying that &quot;Tracking Failed&quot;? (Windows only)
On Linux and macOS, eDEX tracks where you&#039;re going in your terminal tab to display the content of the current folder on-screen.
Sadly, this is technically impossible to do on Windows right now, so the file browser reverts back to a &quot;detached&quot; mode. You can still use it to browse files &amp; directories and click on files to input their path in the terminal.
#### Can this run on a Raspberry Pi / ARM device?
We provide prebuilt arm64 builds. For other platforms, see [this issue comment](https://github.com/GitSquared/edex-ui/issues/313#issuecomment-443465345), and the thread on issue [#818](https://github.com/GitSquared/edex-ui/issues/818).
#### Is this repo actively maintained?
No, after a 3 years run, this project has been archived. See the [announcement](https://github.com/GitSquared/edex-ui/releases/tag/v2.2.8).
#### How did you make this?
Glad you&#039;re interested! See [#272](https://github.com/GitSquared/edex-ui/issues/272).
#### This is so cool.
Thanks! If you feel like it, you can [follow me on Twitter](https://gaby.dev/twitter) to hear about new stuff I&#039;m making.

&lt;img width=&quot;220&quot; src=&quot;https://78.media.tumblr.com/35d4ef4447e0112f776b629bffd99188/tumblr_mk4gf8zvyC1s567uwo1_500.gif&quot; /&gt;


## Featured in...
- [Linux Uprising Blog](https://www.linuxuprising.com/2018/11/edex-ui-fully-functioning-sci-fi.html)
- [My post on r/unixporn](https://www.reddit.com/r/unixporn/comments/9ysbx7/oc_a_little_project_that_ive_been_working_on/)
- [Korben article (in french)](https://korben.info/une-interface-futuriste-pour-vos-ecrans-tactiles.html)
- [Hacker News](https://news.ycombinator.com/item?id=18509828)
- [This tweet that made me smile](https://twitter.com/mikemaccana/status/1065615451940667396)
- [BoingBoing article](https://boingboing.net/2018/11/23/simulacrum-sf.html) - Apparently i&#039;m a &quot;French hacker&quot;
- [OReilly 4 short links](https://www.oreilly.com/ideas/four-short-links-23-november-2018)
- [Hackaday](https://hackaday.com/2018/11/23/look-like-a-movie-hacker/)
- [Developpez.com (another french link)](https://www.developpez.com/actu/234808/Une-application-de-bureau-ressemble-a-une-interface-d-ordinateur-de-science-fiction-inspiree-des-effets-du-film-TRON-Legacy/)
- [GitHub Blog&#039;s Release Radar November 2018](https://blog.github.com/2018-12-21-release-radar-november-2018/)
- [opensource.com Productive Tools for 2019](https://opensource.com/article/19/1/productivity-tool-edex-ui)
- [O&#039;Reilly 4 short links (again)](https://www.oreilly.com/radar/four-short-links-7-july-2020/)
- [LinuxLinks](https://www.linuxlinks.com/linux-candy-edex-ui-sci-fi-computer-terminal-emulator-system-monitor/)
- [Linux For Everyone (Youtube)](https://www.youtube.com/watch?v=gbzqCAjm--g)
- [BestOfJS Rising Stars 2020](https://risingstars.js.org/2020/en#edex-ui)
- [The Geek Freaks (Youtube/German)](https://youtu.be/TSjMIeLG0Sk)
- [JSNation Open Source Awards 2021](https://osawards.com/javascript/#nominees) (Nominee - Fun Side Project of the Year)


## Useful commands for the nerds

**IMPORTANT NOTE:** the following instructions are meant for running eDEX from the latest unoptimized, unreleased, development version. If you&#039;d like to get stable software instead, refer to [these](#how-do-i-get-it) instructions.

#### Starting from source:
on *nix systems (You&#039;ll need the Xcode command line tools on macOS):
- clone the repository
- `npm run install-linux`
- `npm run start`

on Windows:
- start cmd or powershell **as administrator**
- clone the repository
- `npm run install-windows`
- `npm run start`

#### Building
Note: Due to native modules, you can only build targets for the host OS you are using.

- `npm install` (NOT `install-linux` or `install-windows`)
- `npm run build-linux` or `build-windows` or `build-darwin`

The script will minify the source code, recompile native dependencies and create distributable assets in the `dist` folder.

#### Getting the bleeding edge
If you&#039;re interested in running the latest in-development version but don&#039;t want to compile source code yourself, you can can get pre-built nightly binaries on [GitHub Actions](https://github.com/GitSquared/edex-ui/actions): click the latest commits, and download the artifacts bundle for your OS.

## Credits
eDEX-UI&#039;s source code was primarily written by me, [Squared](https://github.com/GitSquared). If you want to get in touch with me or find other projects I&#039;m involved in, check out [my website](https://gaby.dev).

[PixelyIon](https://github.com/PixelyIon) helped me get started with Windows compatibility and offered some precious advice when I started to work on this project seriously.

[IceWolf](https://soundcloud.com/iamicewolf) composed the sound effects on v2.1.x and above. He makes really cool stuff, check out his music!

## Thanks
Of course, eDEX would never have existed if I hadn&#039;t stumbled upon the amazing work of [Seena](https://github.com/seenaburns) on [r/unixporn](https://reddit.com/r/unixporn).

This project uses a bunch of open-source libraries, frameworks and tools, see [the full dependency graph](https://github.com/GitSquared/edex-ui/network/dependencies).

I want to namely thank the developers behind [xterm.js](https://github.com/xtermjs/xterm.js), [systeminformation](https://github.com/sebhildebrandt/systeminformation) and [SmoothieCharts](https://github.com/joewalnes/smoothie).

Huge thanks to [Rob &quot;Arscan&quot; Scanlon](https://github.com/arscan) for making the fantastic [ENCOM Globe](https://github.com/arscan/encom-globe), also inspired by the TRON: Legacy movie, and distributing it freely. His work really puts the icing on the cake.

## Licensing

Licensed under the [GPLv3.0](https://github.com/GitSquared/edex-ui/blob/master/LICENSE).
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[rabbitmq/rabbitmq-server]]></title>
            <link>https://github.com/rabbitmq/rabbitmq-server</link>
            <guid>https://github.com/rabbitmq/rabbitmq-server</guid>
            <pubDate>Wed, 04 Feb 2026 00:06:13 GMT</pubDate>
            <description><![CDATA[Open source RabbitMQ: core server and tier 1 (built-in) plugins]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rabbitmq/rabbitmq-server">rabbitmq/rabbitmq-server</a></h1>
            <p>Open source RabbitMQ: core server and tier 1 (built-in) plugins</p>
            <p>Language: JavaScript</p>
            <p>Stars: 13,439</p>
            <p>Forks: 3,985</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># RabbitMQ Server

[![CI](https://github.com/rabbitmq/rabbitmq-server/actions/workflows/test-make.yaml/badge.svg)](https://github.com/rabbitmq/rabbitmq-server/actions/workflows/test-make.yaml)

[RabbitMQ](https://rabbitmq.com) is a [feature rich](https://www.rabbitmq.com/docs),
multi-protocol messaging and streaming broker. It supports:

 * AMQP 1.0
 * AMQP 0-9-1
 * [RabbitMQ Stream Protocol](https://www.rabbitmq.com/docs/streams)
 * MQTT 3.1, 3.1.1, and 5.0
 * STOMP 1.0 through 1.2
 * [MQTT over WebSocket](https://www.rabbitmq.com/docs/web-mqtt)
 * [STOMP over WebSocket](https://www.rabbitmq.com/docs/web-stomp)
 * AMQP 1.0 over WebSocket (supported in [VMware Tanzu RabbitMQ](https://www.vmware.com/products/app-platform/tanzu-rabbitmq))


## Installation

 * [Currently supported](https://www.rabbitmq.com/release-information) released series
 * [Installation guides](https://www.rabbitmq.com/docs/download) for various platforms
 * [Kubernetes Cluster Operator](https://www.rabbitmq.com/kubernetes/operator/operator-overview)
 * [Changelog](https://www.rabbitmq.com/release-information)
 * [Releases](https://github.com/rabbitmq/rabbitmq-server/releases) on GitHub
 * [Community Support Eligibility Policy](https://github.com/rabbitmq/rabbitmq-server/blob/main/COMMUNITY_SUPPORT.md)
 * [Supported Erlang versions](https://www.rabbitmq.com/docs/which-erlang)


## Tutorials and Documentation

 * [RabbitMQ tutorials](https://www.rabbitmq.com/tutorials) and their [executable versions on GitHub](https://github.com/rabbitmq/rabbitmq-tutorials)
 * [Documentation guides](https://rabbitmq.com/docs/)
 * [RabbitMQ blog](https://blog.rabbitmq.com/)

Some key doc guides include

 * [CLI tools guide](https://www.rabbitmq.com/docs/cli)
 * [Clustering](https://www.rabbitmq.com/docs/clustering) and [Cluster Formation](https://www.rabbitmq.com/docs/cluster-formation)
 * [Configuration guide](https://www.rabbitmq.com/docs/configure)
 * [Client libraries and tools](https://www.rabbitmq.com/client-libraries/devtools)
 * [Monitoring](https://www.rabbitmq.com/docs/monitoring) and [Prometheus/Grafana](https://www.rabbitmq.com/docs/prometheus)
 * [Upgrading](https://www.rabbitmq.com/docs/upgrade)
 * [Kubernetes Cluster Operator](https://www.rabbitmq.com/kubernetes/operator/operator-overview)
 * [Production checklist](https://www.rabbitmq.com/docs/production-checklist)
 * [Quorum queues](https://www.rabbitmq.com/docs/quorum-queues): a replicated, data safety- and consistency-oriented queue type
 * [Streams](https://www.rabbitmq.com/docs/streams): a persistent and replicated append-only log with non-destructive consumer semantics
 * [Runtime Parameters and Policies](https://www.rabbitmq.com/docs/parameters)
 * [Runnable tutorials](https://github.com/rabbitmq/rabbitmq-tutorials/)

RabbitMQ documentation is also [developed on GitHub](https://github.com/rabbitmq/rabbitmq-website/).

## Commercial Features and Support

 * [Commercial editions of RabbitMQ](https://tanzu.vmware.com/rabbitmq)
 * [Commercial edition for Kubernetes](https://docs.vmware.com/en/VMware-RabbitMQ-for-Kubernetes/1/rmq/installation.html)
 * [Commercial support](https://tanzu.vmware.com/rabbitmq/oss) from [Broadcom](https://vmware.com) for open source RabbitMQ

## Getting Help from the Community

Please read the [Community Support Eligibility Policy](https://github.com/rabbitmq/rabbitmq-server/blob/main/COMMUNITY_SUPPORT.md) document
first.

The recommended community forums are

 * [GitHub Discussions](https://github.com/rabbitmq/rabbitmq-server/discussions/)
 * [Community Discord server](https://rabbitmq.com/discord/)
 * `#rabbitmq` on [Libera Chat](https://libera.chat/)


## Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md) and our [development process overview](https://www.rabbitmq.com/github).

Questions about contributing, internals and so on are very welcome in [GitHub Discussions](https://github.com/rabbitmq/rabbitmq-server/discussions)
or [community Discord server](https://www.rabbitmq.com/discord/) in the `contributors` channel.


## Licensing

RabbitMQ server is [licensed under the MPL 2.0](LICENSE-MPL-RabbitMQ).

[Community Support Eligibility Policy](https://github.com/rabbitmq/rabbitmq-server/blob/main/COMMUNITY_SUPPORT.md)
document explains the open source RabbitMQ support policy adopted by the RabbitMQ Core Team.


## AI Agent Instructions

See `AGENTS.md`.


## Building From Source and Packaging

 * [Contributor resources](https://github.com/rabbitmq/contribute)
 * [Building RabbitMQ from Source](https://www.rabbitmq.com/docs/build-server)
 * [Building RabbitMQ Distribution Packages](https://www.rabbitmq.com/docs/build-server)


## Copyright

(c) 2007-2026 Broadcom. All Rights Reserved. The term â€œBroadcomâ€ refers to Broadcom Inc. and/or its subsidiaries.
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
    </channel>
</rss>