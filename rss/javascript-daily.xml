<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for javascript - JavaScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for javascript.</description>
        <lastBuildDate>Mon, 15 Sep 2025 00:05:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[trueadm/ripple]]></title>
            <link>https://github.com/trueadm/ripple</link>
            <guid>https://github.com/trueadm/ripple</guid>
            <pubDate>Mon, 15 Sep 2025 00:05:05 GMT</pubDate>
            <description><![CDATA[the elegant TypeScript UI framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/trueadm/ripple">trueadm/ripple</a></h1>
            <p>the elegant TypeScript UI framework</p>
            <p>Language: JavaScript</p>
            <p>Stars: 4,487</p>
            <p>Forks: 160</p>
            <p>Stars today: 304 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://ripplejs.com&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/ripple-dark.png&quot;&gt;
    &lt;img src=&quot;assets/ripple-light.png&quot; alt=&quot;Ripple - the elegant TypeScript UI framework&quot; /&gt;
  &lt;/picture&gt;
&lt;/a&gt;

[![CI](https://github.com/trueadm/ripple/actions/workflows/ci.yml/badge.svg)](https://github.com/trueadm/ripple/actions/workflows/ci.yml)
[![Discord](https://img.shields.io/badge/Discord-Join%20Server-7289da?logo=discord&amp;logoColor=white)](https://discord.gg/JBF2ySrh2W)
[![Open in StackBlitz](https://developer.stackblitz.com/img/open_in_stackblitz_small.svg)](https://stackblitz.com/github/trueadm/ripple/tree/main/templates/basic)

# What is Ripple?

&gt; Currently, this project is still in early development, and should not be used in production.

Ripple is a TypeScript UI framework that takes the best parts of React, Solid and Svelte and combines them into one package.

I wrote Ripple as a love letter for frontend web – and this is largely a project that I built in less than a week, so it&#039;s very raw.

Personally, I ([@trueadm](https://github.com/trueadm)) have been involved in some truly amazing frontend frameworks along their journeys – from [Inferno](https://github.com/infernojs/inferno), where it all began, to [React](https://github.com/facebook/react) and the journey of React Hooks, to creating [Lexical](https://github.com/facebook/lexical), to [Svelte 5](https://github.com/sveltejs/svelte) and its new compiler and signal-based reactivity runtime. Along that journey, I collected ideas, and intriguing thoughts that may or may not pay off. Given my time between roles, I decided it was the best opportunity to try them out, and for open source to see what I was cooking.

Ripple was designed to be a JS/TS-first framework, rather than HTML-first. Ripple modules have their own `.ripple` extension, and these modules
fully support TypeScript. By introducing a new extension, it allows Ripple to invent its own superset language, which plays really nicely with
TypeScript and JSX, but with a few interesting touches. In my experience, this has led to better DX not only for humans, but also for LLMs.

Right now, there will be plenty of bugs, things just won&#039;t work either and you&#039;ll find TODOs everywhere. At this stage, Ripple is more of an early alpha version of something that _might_ be, rather than something you should try and adopt. If anything, maybe some of the ideas can be shared and incubated back into other frameworks. There&#039;s also a lot of similarities with Svelte 5, and that&#039;s not by accident; that&#039;s because of my recent time working on Svelte 5.

If you&#039;d like to know more, join the [Ripple Discord](https://discord.gg/JBF2ySrh2W).

## Features

- **Reactive State Management**: Built-in reactivity with `$` prefixed variables and object properties
- **Component-Based Architecture**: Clean, reusable components with props and children
- **JSX-like Syntax**: Familiar templating with Ripple-specific enhancements
- **Performance**: Fine-grain rendering, with industry-leading performance and memory usage
- **TypeScript Support**: Full TypeScript integration with type checking
- **VSCode Integration**: Rich editor support with diagnostics, syntax highlighting, and IntelliSense
- **Prettier Support**: Full Prettier formatting support for `.ripple` modules

## Missing Features

- **SSR**: Ripple is currently an SPA only, this is because I haven&#039;t gotten around to it
- **Types**: The codebase is very raw with limited types; we&#039;re getting around to it

## Getting Started

### Try Ripple

&gt; We&#039;re working hard on getting an online playground available. Watch this space!

You can try Ripple now by using our basic Vite template either via [StackBlitz](https://stackblitz.com/github/trueadm/ripple/tree/main/templates/basic), or by running these commands in your terminal:

```bash
npx degit trueadm/ripple/templates/basic my-app
cd my-app
npm i # or yarn or pnpm
npm run dev # or yarn or pnpm
```

## VSCode Extension

The [Ripple VSCode extension](https://marketplace.visualstudio.com/items?itemName=ripplejs.ripple-vscode-plugin) provides:

- **Syntax Highlighting** for `.ripple` files
- **Real-time Diagnostics** for compilation errors
- **TypeScript Integration** for type checking
- **IntelliSense** for autocompletion

You can find the extension on the VS Code Marketplace as [`Ripple for VS Code`](https://marketplace.visualstudio.com/items?itemName=ripplejs.ripple-vscode-plugin).

You can also [manually install the extension](https://github.com/trueadm/ripple/raw/refs/heads/main/packages/ripple-vscode-plugin/published/ripple-vscode-plugin.vsix) `.vsix` that have been manually packaged.

### Mounting your app

You can use the `mount` API from the `ripple` package to render your Ripple component, using the `target`
option to specify what DOM element you want to render the component.

```ts
// index.ts
import { mount } from &#039;ripple&#039;;
import { App } from &#039;/App.ripple&#039;;

mount(App, {
  props: {
    title: &#039;Hello world!&#039;,
  },
  target: document.getElementById(&#039;root&#039;),
});
```

## Key Concepts

### Components

Define reusable components with the `component` keyword. These are similar to functions in that they have `props`, but crucially,
they allow for a JSX-like syntax to be defined alongside standard TypeScript. That means you do not _return JSX_ like in other frameworks,
but you instead use it like a JavaScript statement, as shown:

```jsx
component Button(props: { text: string, onClick: () =&gt; void }) {
  &lt;button onClick={props.onClick}&gt;
    {props.text}
  &lt;/button&gt;
}

// Usage
export component App() {
  &lt;Button text=&quot;Click me&quot; onClick={() =&gt; console.log(&quot;Clicked!&quot;)} /&gt;
}
```

Ripple&#039;s templating language also supports shorthands and object spreads too:

```svelte
// you can do a normal prop
&lt;div onClick={onClick}&gt;{text}&lt;/div&gt;

// or using the shorthand prop
&lt;div {onClick}&gt;{text}&lt;/div&gt;

// and you can spread props
&lt;div {...properties}&gt;{text}&lt;/div&gt;
```

### Reactive Variables

Variables prefixed with `$` are automatically reactive:

```ts
let $name = &#039;World&#039;;
let $count = 0;

// Updates automatically trigger re-renders
$count++;
```

Object properties prefixed with `$` are also automatically reactive:

```ts
let counter = { $current: 0 };

// Updates automatically trigger re-renders
counter.$current++;
```

Derived values are simply `$` variables that combined different parts of state:

```ts
let $count = 0;
let $double = $count * 2;
let $quadruple = $double * 2;
```

That means `$count` itself might be derived if it were to reference another reactive property. For example:

```jsx
component Counter({ $startingCount }) {
  let $count = $startingCount;
  let $double = $count * 2;
  let $quadruple = $double * 2;
}
```

Now given `$startingCount` is reactive, it would mean that `$count` might reset each time an incoming change to `$startingCount` occurs. That might not be desirable, so Ripple provides a way to `untrack` reactivity in those cases:

```jsx
import { untrack } from &#039;ripple&#039;;

component Counter({ $startingCount }) {
  let $count = untrack(() =&gt; $startingCount);
  let $double = $count * 2;
  let $quadruple = $double * 2;
}
```

Now `$count` will only reactively create its value on initialization.

&gt; Note: you cannot define reactive variables in module/global scope, they have to be created on access from an active component

#### Transporting Reactivity

Ripple doesn&#039;t constrain reactivity to components only. Reactivity can be used inside other functions (and classes in the future) and be composed in a way to improve expressivity and co-location.

Ripple provides a very nice way to transport reactivity between boundaries so that it&#039;s persisted – using objects and arrays. Here&#039;s an example using arrays to transport reactivity:

```jsx
import { effect } from &#039;ripple&#039;;

function createDouble([ $count ]) {
  const $double = $count * 2;

  effect(() =&gt; {
    console.log(&#039;Count:&#039;, $count)
  });

  return [ $double ];
}

export component App() {
  let $count = 0;

  const [ $double ] = createDouble([ $count ]);

  &lt;div&gt;{&#039;Double: &#039; + $double}&lt;/div&gt;
  &lt;button onClick={() =&gt; { $count++; }}&gt;{&#039;Increment&#039;}&lt;/button&gt;
}
```

You can do the same with objects too:

```jsx
import { effect } from &#039;ripple&#039;;

function createDouble({ $count }) {
  const $double = $count * 2;

  effect(() =&gt; {
    console.log(&#039;Count:&#039;, $count)
  });

  return { $double };
}

export component App() {
  let $count = 0;
  const { $double } = createDouble({ $count });

  &lt;div&gt;{&#039;Double: &#039; + $double}&lt;/div&gt;
  &lt;button onClick={() =&gt; { $count++; }}&gt;{&#039;Increment&#039;}&lt;/button&gt;
}
```

Just remember, reactive state must be connected to a component and it can&#039;t be global or created within the top-level of a module – because then Ripple won&#039;t be able to link it to your component tree.

#### Reactive Arrays

Just like, objects, you can use the `$` prefix in an array literal to specify that the field is reactive.

```js
let $first = 0;
let $second = 0;
const arr = [$first, $second];

const $total = arr.reduce((a, b) =&gt; a + b, 0);
```

Like shown in the above example, you can compose normal arrays with reactivity and pass them through props or boundaries.

However, if you need the entire array to be fully reactive, including when
new elements get added, you should use the reactive array that Ripple provides.

You&#039;ll need to import the `RippleArray` class from Ripple. It extends the standard JS `Array` class, and supports all of its methods and properties.

```js
import { RippleArray } from &#039;ripple&#039;;

// using the new constructor
const arr = new RippleArray(1, 2, 3);

// using static from method
const arr = RippleArray.from([1, 2, 3]);

// using static of method
const arr = RippleArray.of(1, 2, 3);
```

The `RippleArray` is a reactive array, and that means you can access properties normally using numeric index. However,
accessing the `length` property of a `RippleArray` will be not be reactive, instead you should use `$length`.

#### Reactive Set

The `RippleSet` extends the standard JS `Set` class, and supports all of its methods and properties. However,
accessing the `size` property of a `RippleSet` will be not be reactive, instead you should use `$size`.

```js
import { RippleSet } from &#039;ripple&#039;;

const set = new RippleSet([1, 2, 3]);
```

RippleSet&#039;s reactive methods or properties can be used directly or assigned to reactive variables.

```jsx
import { RippleSet } from &#039;ripple&#039;;

export component App() {
  const set = new RippleSet([1, 2, 3]);

  // direct usage
  &lt;p&gt;{&quot;Direct usage: set contains 2: &quot;}{set.has(2)}&lt;/p&gt;

  // reactive assignment with prefixed `$`
  let $has = set.has(2);
  &lt;p&gt;{&quot;Assigned usage: set contains 2: &quot;}{$has}&lt;/p&gt;

  &lt;button onClick={() =&gt; set.delete(2)}&gt;{&quot;Delete 2&quot;}&lt;/button&gt;
  &lt;button onClick={() =&gt; set.add(2)}&gt;{&quot;Add 2&quot;}&lt;/button&gt;
}
```

#### Reactive Map

The `RippleMap` extends the standard JS `Map` class, and supports all of its methods and properties. However,
accessing the `size` property of a `RippleMap` will be not be reactive, instead you should use `$size`.

```js
import { RippleMap } from &#039;ripple&#039;;

const map = new RippleMap([[1,1], [2,2], [3,3], [4,4]]);
```

RippleMap&#039;s reactive methods or properties can be used directly or assigned to reactive variables.

```jsx
import { RippleMap } from &#039;ripple&#039;;

export component App() {
  const map = new RippleMap([[1,1], [2,2], [3,3], [4,4]]);

  // direct usage
  &lt;p&gt;{&quot;Direct usage: map has an item with key 2: &quot;}{map.has(2)}&lt;/p&gt;

  // reactive assignment with prefixed `$`
  let $has = map.has(2);
  &lt;p&gt;{&quot;Assigned usage: map has an item with key 2: &quot;}{$has}&lt;/p&gt;

  &lt;button onClick={() =&gt; map.delete(2)}&gt;{&quot;Delete item with key 2&quot;}&lt;/button&gt;
  &lt;button onClick={() =&gt; map.set(2, 2)}&gt;{&quot;Add key 2 with value 2&quot;}&lt;/button&gt;
}
```

### Effects

When dealing with reactive state, you might want to be able to create side-effects based upon changes that happen upon updates.
To do this, you can use `effect`:

```jsx
import { effect } from &#039;ripple&#039;;

export component App() {
  let $count = 0;

  effect(() =&gt; {
    console.log($count);
  });

  &lt;button onClick={() =&gt; $count++}&gt;{&#039;Increment&#039;}&lt;/button&gt;
}
```

### Control flow

The JSX-like syntax might take some time to get used to if you&#039;re coming from another framework. For one, templating in Ripple
can only occur _inside_ a `component` body – you can&#039;t create JSX inside functions, or assign it to variables as an expression.

```jsx
&lt;div&gt;
  // you can create variables inside the template!
  const str = &quot;hello world&quot;;

  console.log(str); // and function calls too!

  debugger; // you can put breakpoints anywhere to help debugging!

  {str}
&lt;/div&gt;
```

Note that strings inside the template need to be inside `{&quot;string&quot;}`, you can&#039;t do `&lt;div&gt;hello&lt;/div&gt;` as Ripple
has no idea if `hello` is a string or maybe some JavaScript code that needs evaluating, so just ensure you wrap them
in curly braces. This shouldn&#039;t be an issue in the real-world anyway, as you&#039;ll likely use an i18n library that means
using JavaScript expressions regardless.

### If statements

If blocks work seamlessly with Ripple&#039;s templating language, you can put them inside the JSX-like
statements, making control-flow far easier to read and reason with.

```jsx
component Truthy({ x }) {
  &lt;div&gt;
    if (x) {
      &lt;span&gt;{&#039;x is truthy&#039;}&lt;/span&gt;
    } else {
      &lt;span&gt;{&#039;x is falsy&#039;}&lt;/span&gt;
    }
  &lt;/div&gt;
}
```

### For statements

You can render collections using a `for...of` block, and you don&#039;t need to specify a `key` prop like
other frameworks.

```jsx
component ListView({ title, items }) {
  &lt;h2&gt;{title}&lt;/h2&gt;
  &lt;ul&gt;
    for (const item of items) {
      &lt;li&gt;{item.text}&lt;/li&gt;
    }
  &lt;/ul&gt;
}
```

You can use Ripple&#039;s reactive arrays to easily compose contents of an array.

```jsx
import { RippleArray } from &#039;ripple&#039;;

component Numbers() {
  const items = new RippleArray(1, 2, 3);

  for (const item of items) {
    &lt;div&gt;{item}&lt;/div&gt;
  }

  &lt;button onClick={() =&gt; items.push(`Item ${items.$length + 1}`)}&gt;{&quot;Add Item&quot;}&lt;/button&gt;
}
```

Clicking the `&lt;button&gt;` will create a new item, note that `items` is not `$` prefixed, because it&#039;s not
reactive, but rather its properties are instead.

### Try statements

Try blocks work to build the foundation for **error boundaries**, when the runtime encounters
an error in the `try` block, you can easily render a fallback in the `catch` block.

```jsx
import { reportError } from &#039;some-library&#039;;

component ErrorBoundary() {
  &lt;div&gt;
    try {
      &lt;ComponentThatFails /&gt;
    } catch (e) {
      reportError(e);

      &lt;div&gt;{&#039;An error occurred! &#039; + e.message}&lt;/div&gt;
    }
  &lt;/div&gt;
}
```

### Props

If you want a prop to be reactive, you should also give it a `$` prefix.

```jsx
component Button(props: { $text: string, onClick: () =&gt; void }) {
  &lt;button onClick={props.onClick}&gt;
    {props.$text}
  &lt;/button&gt;
}

// Usage
&lt;Button $text={some_text} onClick={() =&gt; console.log(&quot;Clicked!&quot;)} /&gt;
```

This also applies to DOM elements, if you want an attribute or property to be reactive, it needs to have a `$` prefix.

```tsx
&lt;div $class={props.$someClass} $id={$someId}&gt;
  {$someText}
&lt;/div&gt;
```

Otherwise changes to the attribute or property will not be reactively updated.

### Children

Use `$children` prop and then use it in the form of `&lt;$children /&gt;` for component composition.

When you pass in children to a component, it gets implicitly passed as the `$children` prop, in the form of a component.

```jsx
import type { Component } from &#039;ripple&#039;;

component Card(props: { $children: Component }) {
  &lt;div class=&quot;card&quot;&gt;
    &lt;props.$children /&gt;
  &lt;/div&gt;
}

// Usage
&lt;Card&gt;
  &lt;p&gt;{&quot;Card content here&quot;}&lt;/p&gt;
&lt;/Card&gt;
```

You could also explicitly write the same code as shown:

```jsx
import type { Component } from &#039;ripple&#039;;

component Card(props: { $children: Component }) {
  &lt;div class=&quot;card&quot;&gt;
    &lt;props.$children /&gt;
  &lt;/div&gt;
}

// Usage with explicit component
&lt;Card&gt;
  component $children() {
    &lt;p&gt;{&quot;Card content here&quot;}&lt;/p&gt;
  }
&lt;/Card&gt;
```

### Accessor Props

When working with props on composite components (`&lt;Foo&gt;` rather than `&lt;div&gt;`), it can sometimes be difficult to debug why a certain value is a certain way. JavaScript gives us a way to do this on objects using the `get` syntax:

```js
let name = &#039;Bob&#039;;

const object = {
  get name() {
    // I can easily debug when this property gets
    // access and track it easily
    console.log(name);
    return name;
  }
}
```

So Ripple provides similar capabilities when working with composite components in a template, specifically using `$prop:={}` rather than the typical `$prop={}`.

In fact, when you use an accessor, you must pass a function, and the prop must be `$` prefixed, as Ripple considers accessor props as reactive:

```jsx
let $name = &#039;Bob&#039;;

const getName = () =&gt; {
  // I can easily debug when this property gets
  // access and track it easily
  console.log(name);
  return $name;
};

&lt;Person $name:={getName} /&gt;
```

You can also inline the function too:

```jsx
let $name = &#039;Bob&#039;;

&lt;Person $name:={() =&gt; {
  // I can easily debug when this property gets
  // access and track it easily
  console.log(name);
  return $name;
}} /&gt;
```

Furthermore, just like property accessors in JavaScript, Ripple provides a way of capturing the `set` too, enabling two-way data-flow on composite component props. You just need to provide a second function after the first, separated using a comma:

```jsx
let $name = &#039;Bob&#039;;

const getName = () =&gt; {
  return $name;
}

const setName = (newName) =&gt; {
  $name = newName;
}

&lt;Person $name:={getName, setName} /&gt;
```

Or an inlined version:

```jsx
let $name = &#039;Bob&#039;;

&lt;Person $name:={() =&gt; $name, (newName) =&gt; $name = $newName} /&gt;
```

Now changes in the `Person` to its `props` will propagate to its parent component:

```jsx
component Person(props) {
  const updateName = (newName) =&gt; {
    props.$name = newName;
  }

  &lt;NameInput onChange={updateName}&gt;
}
```

### Decorators

Ripple provides a consistent way to capture the underlying DOM element – decorators. Specifically, using
the syntax `{@use fn}` where `fn` is a function that captures the DOM element. If you&#039;re familiar with other frameworks, then
this is identical to `{@attach fn}` in Svelte 5 and somewhat similar to `ref` in React. The hook function will receive
the reference to the underlying DOM element.

```jsx
export component App() {
  let $node;

  const ref = (node) =&gt; {
    $node = node;
    console.log(&quot;mounted&quot;, node);

    return () =&gt; {
      $node = undefined;
      console.log(&quot;unmounted&quot;, node);
    };
  };

  &lt;div {@use ref}&gt;{&quot;Hello world&quot;}&lt;/div&gt;
}
```

You can also create `{@use}` functions inline.

```jsx
export component App() {
  let $node;

  &lt;div {@use (node) =&gt; {
    $node = node;
    return () =&gt; $node = null;
  }}&gt;{&quot;Hello world&quot;}&lt;/div&gt;
}
```

You can also use function factories to define properties, these are functions that return functions that do the same
thing. However, you can use this pattern to pass reactive properties.

```jsx
import { fadeIn } from &#039;some-library&#039;;

export component App({ $ms }) {
  &lt;div {@use fadeIn({ $ms })}&gt;{&quot;Hello world&quot;}&lt;/div&gt;
}
```

Lastly, you can use decorators on composite components.

```jsx
&lt;Image {@use (node) =&gt; console.log(node)} {...props} /&gt;
```

When passing decorators to composite components (rather than HTML elements) as shown above, they will be passed a `Symbol` property, as they are not named. This still means that it can be spread to HTML template elements later on and still work.

### Event Props

Like React, events are props that start with `on` and then continue with an uppercase character, such as:

- `onClick`
- `onPointerMove`
- `onPointerDown`
- `onKeyDown`

For `capture` phase events, just add `Capture` to the end of the prop name:

- `onClickCapture`
- `onPointerMoveCapture`
- `onPointerDownCapture`
- `onKeyDownCapture`

&gt; Note: Some events are automatically delegated where possible by Ripple to improve runtime performance.

### Styling

Ripple supports native CSS styling that is

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[SkyworkAI/DeepResearchAgent]]></title>
            <link>https://github.com/SkyworkAI/DeepResearchAgent</link>
            <guid>https://github.com/SkyworkAI/DeepResearchAgent</guid>
            <pubDate>Mon, 15 Sep 2025 00:05:04 GMT</pubDate>
            <description><![CDATA[DeepResearchAgent is a hierarchical multi-agent system designed not only for deep research tasks but also for general-purpose task solving. The framework leverages a top-level planning agent to coordinate multiple specialized lower-level agents, enabling automated task decomposition and efficient execution across diverse and complex domains.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/SkyworkAI/DeepResearchAgent">SkyworkAI/DeepResearchAgent</a></h1>
            <p>DeepResearchAgent is a hierarchical multi-agent system designed not only for deep research tasks but also for general-purpose task solving. The framework leverages a top-level planning agent to coordinate multiple specialized lower-level agents, enabling automated task decomposition and efficient execution across diverse and complex domains.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 1,845</p>
            <p>Forks: 282</p>
            <p>Stars today: 51 stars today</p>
            <h2>README</h2><pre># DeepResearchAgent

[![Website](https://img.shields.io/badge/🌐-Website-blue?style=for-the-badge&amp;logo=github)](https://skyworkai.github.io/DeepResearchAgent/)
[![Paper](https://img.shields.io/badge/📄-arXiv%20Paper-red?style=for-the-badge&amp;logo=arxiv)](https://arxiv.org/abs/2506.12508)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)

English | [简体中文](README_CN.md) | [🌐 **Website**](https://skyworkai.github.io/DeepResearchAgent/)

## Introduction
image.png
DeepResearchAgent is a hierarchical multi-agent system designed not only for deep research tasks but also for general-purpose task solving. The framework leverages a top-level planning agent to coordinate multiple specialized lower-level agents, enabling automated task decomposition and efficient execution across diverse and complex domains.

&gt; 🌐 **Check out our interactive website**: [https://skyworkai.github.io/DeepResearchAgent/](https://skyworkai.github.io/DeepResearchAgent/) - Explore the architecture, view experiments, and learn more about our research!

## Architecture

&lt;p align=&quot;center&quot;&gt;

  &lt;img src=&quot;./docs/assets/architecture.png&quot; alt=&quot;Architecture&quot; width=&quot;700&quot;/&gt;

&lt;/p&gt;

The system adopts a two-layer structure:

### 1. Top-Level Planning Agent

* Responsible for understanding, decomposing, and planning the overall workflow for a given task.
* Breaks down tasks into manageable sub-tasks and assigns them to appropriate lower-level agents.
* Dynamically coordinates the collaboration among agents to ensure smooth task completion.

### 2. Specialized Lower-Level Agents

* **Deep Analyzer**

  * Performs in-depth analysis of input information, extracting key insights and potential requirements.
  * Supports analysis of various data types, including text and structured data.
* **Deep Researcher**

  * Conducts thorough research on specified topics or questions, retrieving and synthesizing high-quality information.
  * Capable of generating research reports or knowledge summaries automatically.
* **Browser Use**

  * Automates browser operations, supporting web search, information extraction, and data collection tasks.
  * Assists the Deep Researcher in acquiring up-to-date information from the internet.
  
* **MCP Manager Agent**
  * Manages and orchestrates Model Context Protocol (MCP) tools and services.
  * Enables dynamic tool discovery, registration, and execution through MCP standards.
  * Supports both local and remote MCP tool integration for enhanced agent capabilities.

* **General Tool Calling Agent**
  * Provides a general-purpose interface for invoking various tools and APIs.
  * Supports function calling, allowing the agent to execute specific tasks or retrieve information from external services.

## Features

- Hierarchical agent collaboration for complex and dynamic task scenarios
- Extensible agent system, allowing easy integration of additional specialized agents
- Automated information analysis, research, and web interaction capabilities
- Secure Python code execution environment for tools, featuring configurable import controls, restricted built-ins, attribute access limitations, and resource limits. (See [PythonInterpreterTool Sandboxing](./docs/python_interpreter_sandbox.md) for details).
- Support for asynchronous operations, enabling efficient handling of multiple tasks and agents
- Support for local and remote model inference, including OpenAI, Anthropic, Google LLMs, and local Qwen models via vLLM
- Support for image and video generation tools based on the Imagen and Veo3 models, respectively

Image and Video Examples:
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/assets/cat_yarn_playful_reference.png&quot; alt=&quot;Image Example&quot; width=&quot;300&quot;/&gt;
    &lt;img src=&quot;./docs/assets/cat_playing_with_yarn_video.gif&quot; alt=&quot;Video Example&quot; width=&quot;600&quot;/&gt;
&lt;/p&gt;

## Updates
* **2025.08.04**: Add the support for loading mcp tools from the local json file.
* **2025.07.08**: Add the video generator tool, which can generate a video based on the input text and/or image. The video generator tool is based on the Veo3 model.
* **2025.07.08**: Add the image generator tool, which can generate images based on the input text. The image generator tool is based on the Imagen model.
* **2025.07.07**: Due to the limited flexibility of TOML configuration files, we have switched to using the config format supported by mmengine.
* **2025.06.20**: Add the support for the mcp (Both the local mcp and remote mcp).
* **2025.06.17**: Update technical report https://arxiv.org/pdf/2506.12508.
* **2025.06.01**: Update the browser-use to 0.1.48.
* **2025.05.30**: Convert the sub agent to a function call. Planning agent can now be gpt-4.1 or gemini-2.5-pro.
* **2025.05.27**: Support OpenAI, Anthropic, Google LLMs, and local Qwen models (via vLLM, see details in [Usage](#usage)).

## TODO List

* [x] Asynchronous feature completed
* [x] Image Generator Tool completed
* [x] Video Generator Tool completed
* [x] MCP in progress
* [x] Load local MCP tools from JSON file completed
* [ ] AI4Research Agent to be developed
* [ ] Novel Writing Agent to be developed

## Installation

### Prepare Environment

```bash
# poetry install environment
conda create -n dra python=3.11
conda activate dra
make install

# (Optional) You can also use requirements.txt
conda create -n dra python=3.11
conda activate dra
make install-requirements

# playwright install if needed
pip install playwright
playwright install chromium --with-deps --no-shell
```

### Set Up `.env`

Please refer to the `.env.template` file and create a `.env` file in the root directory of the project. This file is used to configure API keys and other environment variables.

Refer to the following instructions to obtain the necessary google gemini-2.5-pro API key and set it in the `.env` file:

* [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)
* [https://cloud.google.com/docs/authentication/application-default-credentials?hl=zh-cn](https://cloud.google.com/docs/authentication/application-default-credentials?hl=zh-cn)

```bash
brew install --cask google-cloud-sdk
gcloud init
gcloud auth application-default login
```

## Usage

### Main Example
A simple example to demonstrate the usage of the DeepResearchAgent framework.
```bash
python main.py
```

### Run Single Agent Example
A simple example to demonstrate the usage of a single agent, such as a general tool calling agent.
```bash
python examples/run_general.py
```

### RUN GAIA Evaluation Example

```bash
# Download GAIA
mkdir data &amp;&amp; cd data
git clone https://huggingface.co/datasets/gaia-benchmark/GAIA

# Run
python examples/run_gaia.py
```

## Experiments

We evaluated our agent on both GAIA validation and test sets, achieving state-of-the-art performance. Our system demonstrates superior performance across all difficulty levels.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/assets/gaia_test.png&quot; alt=&quot;GAIA Test Results&quot; width=&quot;300&quot;/&gt;
  &lt;img src=&quot;./docs/assets/gaia_validation.png&quot; alt=&quot;GAIA Validation Results&quot; width=&quot;300&quot;/&gt;
&lt;/p&gt;

With the integration of the Computer Use and MCP Manager Agent, which now enables pixel-level control of the browser, our system demonstrates remarkable evolutionary capabilities. The agents can dynamically acquire and enhance their abilities through learning and adaptation, leading to significantly improved performance. The latest results show:
- **Test Set**: 83.39 (average), with 93.55 on Level 1, 83.02 on Level 2, and 65.31 on Level 3
- **Validation Set**: 82.4 (average), with 92.5 on Level 1, 83.7 on Level 2, and 57.7 on Level 3

## Questions

### 1. About Qwen Models

Our framework now supports:

* qwen2.5-7b-instruct
* qwen2.5-14b-instruct
* qwen2.5-32b-instruct

Update your config:

```toml
model_id = &quot;qwen2.5-7b-instruct&quot;
```

### 2. Browser Use

If problems occur, reinstall:

```bash
pip install &quot;browser-use[memory]&quot;==0.1.48
pip install playwright
playwright install chromium --with-deps --no-shell
```

### 3. Sub-Agent Calling

Function-calling is now supported natively by GPT-4.1 / Gemini 2.5 Pro. Claude-3.7-Sonnet is also recommended.

### 4. Use vllm for local models
We provide huggingface as a shortcut to the local model. Also provide vllm as a way to start services so that parallel acceleration can be provided.

#### Step 1: Launch the vLLM Inference Service

```bash
nohup bash -c &#039;CUDA_VISIBLE_DEVICES=0,1 python -m vllm.entrypoints.openai.api_server \
  --model /input0/Qwen3-32B \
  --served-model-name Qwen \
  --host 0.0.0.0 \
  --port 8000 \
  --max-num-seqs 16 \
  --enable-auto-tool-choice \
  --tool-call-parser hermes \
  --tensor_parallel_size 2&#039; &gt; vllm_qwen.log 2&gt;&amp;1 &amp;
```

Update `.env`:

```bash
QWEN_API_BASE=http://localhost:8000/v1
QWEN_API_KEY=&quot;abc&quot;
```

#### Step 2: Launch the Agent Service

```bash
python main.py
```

Example command:

```bash
Use deep_researcher_agent to search the latest papers on the topic of &#039;AI Agent&#039; and then summarize it.
```

## Acknowledgement

DeepResearchAgent is primarily inspired by the architecture of smolagents. The following improvements have been made:
- The codebase of smolagents has been modularized for better structure and organization.
- The original synchronous framework has been refactored into an asynchronous one.
- The multi-agent setup process has been optimized to make it more user-friendly and efficient.

We would like to express our gratitude to the following open source projects, which have greatly contributed to the development of this work:
- [smolagents](https://github.com/huggingface/smolagents) - A lightweight agent framework.
- [OpenManus](https://github.com/mannaandpoem/OpenManus) - An asynchronous agent framework.
- [browser-use](https://github.com/browser-use/browser-use) - An AI-powered browser automation tool.
- [crawl4ai](https://github.com/unclecode/crawl4ai) - A web crawling library for AI applications.
- [markitdown](https://github.com/microsoft/markitdown) - A tool for converting files to Markdown format.

We sincerely appreciate the efforts of all contributors and maintainers of these projects for their commitment to advancing AI technologies and making them available to the wider community.

## Contribution

Contributions and suggestions are welcome! Feel free to open issues or submit pull requests.

## Cite

```bibtex
@misc{zhang2025agentorchestrahierarchicalmultiagentframework,
      title={AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving}, 
      author={Wentao Zhang, Liang Zeng, Yuzhen Xiao, Yongcong Li, Ce Cui, Yilei Zhao, Rui Hu, Yang Liu, Yahui Zhou, Bo An},
      year={2025},
      eprint={2506.12508},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2506.12508}, 
}
```

---

### 🇨🇳 中文版说明文档

如果你更习惯阅读中文说明文档，请查阅 [README_CN.md](./README_CN.md)。
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[marktext/marktext]]></title>
            <link>https://github.com/marktext/marktext</link>
            <guid>https://github.com/marktext/marktext</guid>
            <pubDate>Mon, 15 Sep 2025 00:05:03 GMT</pubDate>
            <description><![CDATA[📝A simple and elegant markdown editor, available for Linux, macOS and Windows.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/marktext/marktext">marktext/marktext</a></h1>
            <p>📝A simple and elegant markdown editor, available for Linux, macOS and Windows.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 51,458</p>
            <p>Forks: 3,778</p>
            <p>Stars today: 72 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;static/logo-small.png&quot; alt=&quot;MarkText&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;MarkText&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://twitter.com/intent/tweet?via=marktextme&amp;url=https://github.com/marktext/marktext/&amp;text=What%20do%20you%20want%20to%20say%20to%20app?&amp;hashtags=happyMarkText&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/twitter/url/https/github.com/marktext/marktext.svg?style=for-the-badge&quot; alt=&quot;twitter&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;strong&gt;:high_brightness: Next generation markdown editor :crescent_moon:&lt;/strong&gt;&lt;br&gt;
  A simple and elegant open-source markdown editor that focused on speed and usability.&lt;br&gt;
  &lt;sub&gt;Available for Linux, macOS and Windows.&lt;/sub&gt;
&lt;/div&gt;

&lt;br&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;!-- License --&gt;
  &lt;a href=&quot;LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/marktext/marktext.svg&quot; alt=&quot;LICENSE&quot;&gt;
  &lt;/a&gt;
  &lt;!-- Build Status --&gt;
  &lt;a href=&quot;https://travis-ci.org/marktext/marktext/&quot;&gt;
    &lt;img src=&quot;https://travis-ci.org/marktext/marktext.svg?branch=master&quot; alt=&quot;build&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://ci.appveyor.com/project/marktext/marktext/branch/master&quot;&gt;
    &lt;img src=&quot;https://ci.appveyor.com/api/projects/status/l4gxgydj0i95hmxg/branch/master?svg=true&quot; alt=&quot;build&quot;&gt;
  &lt;/a&gt;
  &lt;!-- Downloads total --&gt;
  &lt;a href=&quot;https://github.com/marktext/marktext/releases&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/downloads/marktext/marktext/total.svg&quot; alt=&quot;total download&quot;&gt;
  &lt;/a&gt;
  &lt;!-- Downloads latest release --&gt;
  &lt;a href=&quot;https://github.com/marktext/marktext/releases/latest&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/downloads/marktext/marktext/v0.17.1/total.svg&quot; alt=&quot;latest download&quot;&gt;
  &lt;/a&gt;
  &lt;!-- sponsors --&gt;
  &lt;a href=&quot;https://opencollective.com/marktext&quot;&gt;
    &lt;img src=&quot;https://opencollective.com/marktext/tiers/silver-sponsors/badge.svg?label=SilverSponsors&amp;color=brightgreen&quot; alt=&quot;sponsors&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;h3&gt;
    &lt;a href=&quot;https://github.com/marktext/marktext&quot;&gt;
      Website
    &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/marktext/marktext#features&quot;&gt;
      Features
    &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/marktext/marktext#download-and-installation&quot;&gt;
      Downloads
    &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/marktext/marktext#development&quot;&gt;
      Development
    &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/marktext/marktext#contribution&quot;&gt;
      Contribution
    &lt;/a&gt;
  &lt;/h3&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;sub&gt;Translations:&lt;/sub&gt;
  &lt;a href=&quot;docs/i18n/zh_cn.md#readme&quot;&gt;
    &lt;span&gt;:cn:&lt;/span&gt;
  &lt;/a&gt;
  &lt;a href=&quot;docs/i18n/zh_tw.md#readme&quot;&gt;
    &lt;span&gt;:taiwan:&lt;/span&gt;
  &lt;/a&gt;
  &lt;a href=&quot;docs/i18n/pl.md#readme&quot;&gt;
    &lt;span&gt;:poland:&lt;/span&gt;
  &lt;/a&gt;
  &lt;a href=&quot;docs/i18n/ja.md#readme&quot;&gt;
    &lt;span&gt;:jp:&lt;/span&gt;
  &lt;/a&gt;
  &lt;a href=&quot;docs/i18n/french.md#readme&quot;&gt;
    &lt;span&gt;:fr:&lt;/span&gt;
  &lt;/a&gt;
  &lt;a href=&quot;docs/i18n/tr.md#readme&quot;&gt;
    &lt;span&gt;:tr:&lt;/span&gt;
  &lt;/a&gt;
  &lt;a href=&quot;docs/i18n/spanish.md#readme&quot;&gt;
    &lt;span&gt;:es:&lt;/span&gt;
  &lt;/a&gt;
  &lt;a href=&quot;docs/i18n/pt.md#readme&quot;&gt;
    &lt;span&gt;:portugal:&lt;/span&gt;
  &lt;/a&gt;
  &lt;a href=&quot;docs/i18n/ko.md#readme&quot;&gt;
    &lt;span&gt;:kr:&lt;/span&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;sub&gt;This Markdown editor that could. Built with ❤︎ by
    &lt;a href=&quot;https://github.com/Jocs&quot;&gt;Jocs&lt;/a&gt; and
    &lt;a href=&quot;https://github.com/marktext/marktext/graphs/contributors&quot;&gt;
      contributors
    &lt;/a&gt;
    .
  &lt;/sub&gt;
&lt;/div&gt;

&lt;br /&gt;

&lt;h2 align=&quot;center&quot;&gt;Supporting MarkText&lt;/h2&gt;

MarkText is an MIT licensed open source project, and the latest version will always be downloadable for free from the GitHub release page. MarkText is still in development, and its development is inseparable from all sponsors. I hope you join them:

- [Become a backer or sponsor on Patreon](https://www.patreon.com/ranluo) or [One time donation](https://github.com/Jocs/sponsor.me)
- [Become a backer or sponsor on Open Collective](https://opencollective.com/marktext)

##### What&#039;s the difference between Patreon and Open Collective?

Patreon: Funds will be directly sponsored to Luo Ran (@jocs) who created MarkText and continues to maintain it.
Open Collective: All expenses are transparent. The funds will be used for the development and maintenance of MarkText, funding online and offline activities, and acquiring other necessary resources.
Names and company logos of all sponsors (from both Patreon and Open Collective) will appear on the official website for MarkText and in its README.md file.

**Special Sponsors**

&lt;a href=&quot;https://www.dogedoge.com/&quot;&gt;
 &lt;img src=&quot;https://www.dogedoge.com/assets/new_logo.min.png&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;
&lt;/a&gt;

**Platinum Sponsors**

&lt;a href=&quot;https://opencollective.com/marktext#platinum-sponsors&quot;&gt;
 &lt;img src=&quot;https://opencollective.com/marktext/tiers/platinum-sponsors.svg?avatarHeight=36&amp;width=600&quot;&gt;
&lt;/a&gt;

**Gold Sponsors**

&lt;a href=&quot;https://opencollective.com/marktext#platinum-sponsors&quot;&gt;
  &lt;img src=&quot;https://opencollective.com/marktext/tiers/gold-sponsors.svg?avatarHeight=36&amp;width=600&quot;&gt;
&lt;/a&gt;

**Silver Sponsors**

&lt;a href=&quot;https://opencollective.com/marktext#platinum-sponsors&quot;&gt;
  &lt;img src=&quot;https://opencollective.com/marktext/tiers/silver-sponsors.svg?avatarHeight=36&amp;width=600&quot;&gt;
&lt;/a&gt;

**Bronze Sponsors**

&lt;a href=&quot;https://opencollective.com/marktext#platinum-sponsors&quot;&gt;
  &lt;img src=&quot;https://opencollective.com/marktext/tiers/bronze-sponsors.svg?avatarHeight=36&amp;width=600&quot;&gt;
&lt;/a&gt;

**Backers**

&lt;a href=&quot;https://opencollective.com/marktext#backers&quot;&gt;
  &lt;img src=&quot;https://opencollective.com/marktext/tiers/backer.svg?avatarHeight=36&amp;width=600&quot;&gt;
&lt;/a&gt;

## Screenshot

![](docs/marktext.png?raw=true)

## Features

- Realtime preview (WYSIWYG) and a clean and simple interface to get a distraction-free writing experience.
- Support [CommonMark Spec](https://spec.commonmark.org/0.29/), [GitHub Flavored Markdown Spec](https://github.github.com/gfm/) and selective support [Pandoc markdown](https://pandoc.org/MANUAL.html#pandocs-markdown).
- Markdown extensions such as math expressions (KaTeX), front matter and emojis.
- Support paragraphs and inline style shortcuts to improve your writing efficiency.
- Output **HTML** and **PDF** files.
- Various themes: **Cadmium Light**, **Material Dark** etc.
- Various editing modes: **Source Code mode**, **Typewriter mode**, **Focus mode**.
- Paste images directly from clipboard.

&lt;h4 align=&quot;center&quot;&gt;:crescent_moon:themes:high_brightness:&lt;/h4&gt;

| Cadmium Light                                     | Dark                                            |
|:-------------------------------------------------:|:-----------------------------------------------:|
| ![](docs/themeImages/cadmium-light.png?raw=true)  | ![](docs/themeImages/dark.png?raw=true)         |
| Graphite Light                                    | Material Dark                                   |
| ![](docs/themeImages/graphite-light.png?raw=true) | ![](docs/themeImages/materal-dark.png?raw=true) |
| Ulysses Light                                     | One Dark                                        |
| ![](docs/themeImages/ulysses-light.png?raw=true)  | ![](docs/themeImages/one-dark.png?raw=true)     |

&lt;h4 align=&quot;center&quot;&gt;:smile_cat:Edit modes:dog:&lt;/h4&gt;

| Source Code          | Typewriter               | Focus               |
|:--------------------:|:------------------------:|:-------------------:|
| ![](docs/source.gif) | ![](docs/typewriter.gif) | ![](docs/focus.gif) |

## Why make another editor?

1. I love writing. I have used a lot of markdown editors, yet there is still not an editor that can fully meet my needs. I don&#039;t like to be disturbed when I write by some unbearable bug. **MarkText** uses virtual DOM to render pages which has the added benefits of being highly efficient and being open source. That way anyone who loves markdown and writing can use MarkText.
2. As mentioned above, **MarkText** is completely free and open source and will be open source forever. We hope that all markdown lovers will contribute their own code and help develop **MarkText** into a popular markdown editor.
3. There are many markdown editors and all have their own merits, some have features which others don&#039;t. It&#039;s difficult to satisfy each markdown users&#039; needs but we hope **MarkText** will be able to satisfy each markdown user as much as possible. Although the latest **MarkText** is still not perfect, we will try to make it as best as we possibly can.

## Download and Installation

![platform](https://img.shields.io/static/v1.svg?label=Platform&amp;message=Linux-64%20|%20macOS-64%20|%20Win-32%20|%20Win-64&amp;style=for-the-badge)

| ![](https://raw.githubusercontent.com/wiki/ryanoasis/nerd-fonts/screenshots/v1.0.x/mac-pass-sm.png)                                                                                                  | ![](https://raw.githubusercontent.com/wiki/ryanoasis/nerd-fonts/screenshots/v1.0.x/windows-pass-sm.png)                                                                                                          | ![](https://raw.githubusercontent.com/wiki/ryanoasis/nerd-fonts/screenshots/v1.0.x/linux-pass-sm.png)                                                                                                                        |
|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
| [![latest version](https://img.shields.io/github/downloads/marktext/marktext/latest/marktext-x64.dmg.svg)](https://github.com/marktext/marktext/releases/download/v0.17.1/marktext-x64.dmg) | [![latest version](https://img.shields.io/github/downloads/marktext/marktext/latest/marktext-setup.exe.svg)](https://github.com/marktext/marktext/releases/download/v0.17.1/marktext-setup.exe) | [![latest version](https://img.shields.io/github/downloads/marktext/marktext/latest/marktext-x86_64.AppImage.svg)](https://github.com/marktext/marktext/releases/download/v0.17.1/marktext-x86_64.AppImage) |

Want to see new features of the latest version? Please refer to [CHANGELOG](.github/CHANGELOG.md).

#### macOS

You can either download the latest `marktext-%version%.dmg` from the [release page](https://github.com/marktext/marktext/releases/latest) or install MarkText using [**homebrew cask**](https://github.com/caskroom/homebrew-cask). To use Homebrew-Cask you just need to have [Homebrew](https://brew.sh/) installed.

```bash
brew install --cask mark-text
```

#### Windows

Simply download and install MarkText via setup wizard (`marktext-setup-%version%.exe`) and choose whether to install per-user or machine wide. Alternatively, install MarkText using a package manager such as [Chocolatey](https://chocolatey.org/) or [Winget](https://docs.microsoft.com/en-us/windows/package-manager/winget/).

To use Chocolatey, you need to have [Chocolatey](https://chocolatey.org/install) installed:

```bash
choco install marktext
```

To use Winget, you need to have [Winget](https://docs.microsoft.com/en-us/windows/package-manager/winget/#install-winget) installed:

```bash
winget install marktext
```

#### Linux

Please follow the [Linux installation instructions](docs/LINUX.md).

#### Other

All binaries for Linux, macOS and Windows can be downloaded from the [release page](https://github.com/marktext/marktext/releases/latest). If a version is unavailable for your system, then please open an [issue](https://github.com/marktext/marktext/issues).

## Development

If you wish to build MarkText yourself, please check out our [build instructions](docs/dev/BUILD.md).

- [User documentation](docs/README.md)
- [Developer documentation](docs/dev/README.md)

If you have any questions regarding MarkText, you are welcome to write an issue. When doing so please use the default format found when opening an issue. Of course, if you submit a PR directly, it will be greatly appreciated.

## Integrations

- [Alfred Workflow](http://www.packal.org/workflow/mark-text): A Workflow for the macOS app Alfred: Use &quot;mt&quot; to open files/folder with MarkText.

## Contribution

MarkText is in development, please make sure to read the [Contributing Guide](CONTRIBUTING.md) before making a pull request. Want to add some features to MarkText? Refer to our [roadmap](https://github.com/marktext/marktext/projects) and open issues.


## Contributors

Thank you to all the people who have already contributed to MarkText[[contributors](https://github.com/marktext/marktext/graphs/contributors)].

Special thanks to @[Yasujizr](https://github.com/Yasujizr) who designed the MarkText logo.

&lt;a href=&quot;https://github.com/marktext/marktext/graphs/contributors&quot;&gt;&lt;img src=&quot;https://opencollective.com/marktext/contributors.svg?width=890&quot; /&gt;&lt;/a&gt;

## License

[**MIT**](LICENSE).

[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Fmarktext%2Fmarktext.svg?type=large)](https://app.fossa.io/projects/git%2Bgithub.com%2Fmarktext%2Fmarktext?ref=badge_large)
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[met4citizen/TalkingHead]]></title>
            <link>https://github.com/met4citizen/TalkingHead</link>
            <guid>https://github.com/met4citizen/TalkingHead</guid>
            <pubDate>Mon, 15 Sep 2025 00:05:02 GMT</pubDate>
            <description><![CDATA[Talking Head (3D): A JavaScript class for real-time lip-sync using Ready Player Me full-body 3D avatars.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/met4citizen/TalkingHead">met4citizen/TalkingHead</a></h1>
            <p>Talking Head (3D): A JavaScript class for real-time lip-sync using Ready Player Me full-body 3D avatars.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 815</p>
            <p>Forks: 221</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre># Talking Head (3D)

### Demo Videos

*All the demo videos are real-time screen captures from a Chrome browser running
the TalkingHead test web app without any post-processing.*

Video | Description
--- | ---
&lt;span style=&quot;display: block; min-width:400px&quot;&gt;[&lt;img src=&quot;images/dynamicbones.jpg&quot; width=&quot;400&quot;/&gt;](https://youtu.be/YUbDIWkskuw)&lt;br&gt;[&lt;img src=&quot;images/dynamicbones2.jpg&quot; width=&quot;400&quot;/&gt;](https://youtu.be/4Y9NFnENH5s)&lt;/span&gt; | Having a good hair day! – A two-part introduction to the TalkingHead&#039;s dynamic bones feature 🦴🦴 and built-in physics engine. Using custom models with rigged hair and two different hairstyles. See Appendix E for more details.
[&lt;img src=&quot;images/screenshot4.jpg&quot; width=&quot;400&quot;/&gt;](https://youtu.be/OA6LBZjkzJI) | I chat with Jenny and Harri. The close-up view allows you to evaluate the accuracy of lip-sync in both English and Finnish. Using GPT-3.5 and Microsoft text-to-speech.
[&lt;img src=&quot;images/screenshot5.jpg&quot; width=&quot;400&quot;/&gt;](https://youtu.be/fJrYGaGCAGo) | A short demo of how AI can control the avatar&#039;s movements. Using OpenAI&#039;s function calling and Google TTS with the TalkingHead&#039;s built-in viseme generation.
[&lt;img src=&quot;images/screenshot6.jpg&quot; width=&quot;400&quot;/&gt;](https://youtu.be/6XRxALY1Iwg) | Michael lip-syncs to two MP3 audio tracks using OpenAI&#039;s Whisper and TalkingHead&#039;s `speakAudio` method. He kicks things off with some casual talk, but then goes all out by trying to tackle an old Meat Loaf classic. 🤘 Keep rockin&#039;, Michael! 🎤😂
[&lt;img src=&quot;images/screenshot3.jpg&quot; width=&quot;400&quot;/&gt;](https://youtu.be/SfnqRnWKT40) | Julia and I showcase some of the features of the TalkingHead class and the test app including the settings, some poses and animations.

---

### Use Case Examples

*Some videos, apps, and projects using the TalkingHead class:*

Video/App | Use Case
--- | ---
&lt;span style=&quot;display: block; min-width:400px&quot;&gt;[&lt;img src=&quot;images/olivia.jpg&quot; width=&quot;400&quot;/&gt;](https://youtu.be/9GeXwjuslnQ)&lt;/span&gt; | **Video conferencing**. A video conferencing solution with real-time transcription, contextual AI responses, and voice lip-sync. The app and demo, featuring Olivia, by [namnm](https://github.com/namnm) 👍
[&lt;img src=&quot;images/edgespeaker.png&quot; width=&quot;400&quot;/&gt;](https://www.edgespeaker.com/) | **Fully in-browser AI you can talk to**. Uses TalkingHead, [HeadTTS (with Kokoro)](https://github.com/met4citizen/HeadTTS), [whisper-web](https://github.com/xenova/whisper-web), and [WebLLM (with Llama 3.2)](https://github.com/mlc-ai/web-llm). No APIs, no accounts. For more details, see [#115](https://github.com/met4citizen/TalkingHead/issues/115). — For best performance and WebGPU support, use a desktop version of Chrome or Edge: 👉 [EdgeSpeaker.com](https://www.edgespeaker.com/)
[&lt;img src=&quot;images/geminicompetition.jpg&quot; width=&quot;400&quot;/&gt;](https://www.youtube.com/watch?v=Dl2o9kRvbLQ) | **Recycling Advisor 3D**. Snap a photo and get local recycling advice from a talking avatar. My entry for the [Gemini API Developer Competition](https://ai.google.dev/competition/projects/recycling-advisor-3d).
[&lt;img src=&quot;images/evertrail.jpg&quot; width=&quot;400&quot;/&gt;](https://www.youtube.com/watch?v=OG1vwOit_Yk) | **Live Twitch adventure**. [Evertrail](https://evertrail.app) is an infinite, real-time generated world where all of your choices shape the outcome. Video clip and the app by [JPhilipp](https://github.com/JPhilipp) 👏👏&lt;br&gt;**NEWS**: Featured at the AI Film Awards during the 2025 Cannes Film Festival!
[&lt;img src=&quot;images/cliquevm.jpg&quot; width=&quot;400&quot;/&gt;](https://www.youtube.com/watch?v=vNJ9Ifv-as8) | **Quantum physics using a blackboard**. David introduces us to the CHSH game and explores the mystery of quantum entanglement. For more information about the research project, see [CliqueVM](https://github.com/met4citizen/CliqueVM).
[&lt;img src=&quot;images/interactiveportfolio.jpg&quot; width=&quot;400&quot;/&gt;](https://akshatrastogi.in/) | **Interactive Portfolio**. Click the image to open the app, where you can interview the virtual persona of its developer, [AkshatRastogi-1nC0re](https://github.com/AkshatRastogi-1nC0re) 👋
[&lt;img src=&quot;images/datingprofile.jpg&quot; width=&quot;400&quot;/&gt;](https://www.youtube.com/watch?v=Hv-ItCZ0qc4) | **Interactive Dating Profiles**. ❤️ Researchers from the MIT Media Lab and Harvard used the TalkingHead class and data-driven AI to create digital twins that potential dating partners could interact with. Their paper (Baradari et al., 2025) was presented at [CHI 2025](https://programs.sigchi.org/chi/2025/program/content/194739) in Japan. 


---

### Introduction

Talking Head (3D) is a browser JavaScript class featuring a 3D avatar that can
speak and lip-sync in real-time. The class supports
[Ready Player Me](https://readyplayer.me/) / [PlayerZero](https://playerzero.me/)
full-body 3D avatars (GLB) and
[Mixamo](https://www.mixamo.com) animations (FBX).
It also knows a set of emojis and can convert them into facial expressions.

You can create your own 3D avatar for free using the Ready Player Me or PlayerZero
service. Alternatively, you can create a custom 3D avatar by making it compatible with
RPM models. See Appendix A for more details.

By default, the class uses
[Google Cloud TTS](https://cloud.google.com/text-to-speech) for text-to-speech
and has a built-in lip-sync support for English, German, French, Finnish, and Lithuanian.
New lip-sync languages can be added by creating new lip-sync language modules.

It is also possible to integrate the TalkingHead class with any external
TTS service that can provide word-level timestamps, such as the
[ElevenLabs WebSocket API](https://elevenlabs.io).
Note that a lip-sync language module is not required if your TTS engine
can output viseme IDs or blend shape data directly. For example, by using the
[Microsoft Azure Speech SDK](https://github.com/microsoft/cognitive-services-speech-sdk-js),
you can extend TalkingHead&#039;s lip-sync support to 100+ languages.

The class uses [ThreeJS](https://github.com/mrdoob/three.js/) / WebGL for 3D
rendering.

&gt; [!TIP]
&gt; If you&#039;re looking for a free English TTS that can output timestamps and viseme IDs, check out [HeadTTS](https://github.com/met4citizen/HeadTTS). It offers Kokoro neural voices, phoneme-level timestamps, and can run locally or even entirely in a browser using WebGPU. And best of all, it&#039;s fully compatible with the TalkingHead class.

---

### Talking Head class

You can download the TalkingHead modules from
[releases](https://github.com/met4citizen/TalkingHead/releases)
(without dependencies). Alternatively, you can install them from
[NPM](https://www.npmjs.com/package/@met4citizen/talkinghead),
or import all the needed modules from a CDN:

```javascript
&lt;script type=&quot;importmap&quot;&gt;
{ &quot;imports&quot;:
  {
    &quot;three&quot;: &quot;https://cdn.jsdelivr.net/npm/three@0.180.0/build/three.module.js/+esm&quot;,
    &quot;three/addons/&quot;: &quot;https://cdn.jsdelivr.net/npm/three@0.180.0/examples/jsm/&quot;,
    &quot;talkinghead&quot;: &quot;https://cdn.jsdelivr.net/gh/met4citizen/TalkingHead@1.5/modules/talkinghead.mjs&quot;
  }
}
&lt;/script&gt;
```

&gt; [!TIP]
&gt; **FOR HOBBYISTS:** If you&#039;re just looking to experiment on your personal
laptop without dealing with proxies, JSON Web Tokens, or Single Sign-On,
take a look at the [minimal code example](https://github.com/met4citizen/TalkingHead/blob/main/examples/minimal.html).
Simply download the file, add your Google TTS API key, and you&#039;ll
have a basic web app template with a talking head.

If you want to use the built-in Google TTS and lip-sync using
Single Sign-On (SSO) functionality, give the class your TTS proxy endpoint and
a function from which to obtain the JSON Web Token needed to use that proxy.
Refer to Appendix B for one way to implement JWT SSO.

```javascript
import { TalkingHead } from &quot;talkinghead&quot;;

// Create the talking head avatar
const nodeAvatar = document.getElementById(&#039;avatar&#039;);
const head = new TalkingHead( nodeAvatar, {
  ttsEndpoint: &quot;/gtts/&quot;,
  jwtGet: jwtGet,
  lipsyncModules: [&quot;en&quot;, &quot;fi&quot;],
  mixerGainSpeech: 3
});
```

&lt;details&gt;
  &lt;summary&gt;CLICK HERE to see all the available OPTIONS.&lt;/summary&gt;

Option | Description | Default
--- | --- | ---
`jwsGet` | Function to get the JSON Web Token (JWT). See Appendix B for more information. | `null`
`ttsEndpoint` | Text-to-speech backend/endpoint/proxy implementing the Google Text-to-Speech API. | `null`
`ttsApikey` | If you don&#039;t want to use a proxy or JWT, you can use Google TTS endpoint directly and provide your API key here. **NOTE: I recommend that you don&#039;t use this in production and never put your API key in any client-side code.** | `null`
`ttsLang` | Google text-to-speech language. | `&quot;fi-FI&quot;`
`ttsVoice` | Google text-to-speech voice. The used voice must support SSML and \&lt;mark&gt; tags that are needed to get word-level timestamps. Currently, Google supports SSML and \&lt;mark&gt; tags when using Standard, Wavenet, Neural2, News, or Casual voice types. | `&quot;fi-FI-Standard-A&quot;`
`ttsRate` | Google text-to-speech rate in the range [0.25, 4.0]. | `1.0`
`ttsPitch` | Google text-to-speech pitch in the range [-20.0, 20.0]. | `0`
`ttsVolume` | Google text-to-speech volume gain (in dB) in the range [-96.0, 16.0]. | `0`
`ttsTrimStart` | Trim the viseme sequence start relative to the beginning of the audio (shift in milliseconds). | `0`
`ttsTrimEnd` | Trim the viseme sequence end relative to the end of the audio (shift in milliseconds). | `400`
`mixerGainSpeech` | The amount of gain for speech. See Web Audio API / GainNode for more information. | `null`
`mixerGainBackground` | The amount of gain for background audio. See Web Audio API / GainNode for more information. | `null`
`lipsyncModules`| Lip-sync modules to load dynamically at start-up. Limiting the number of language modules improves the loading time and memory usage. | `[&quot;en&quot;, &quot;fi&quot;, &quot;lt&quot;]`
`lipsyncLang`| Lip-sync language. | `&quot;fi&quot;`
`pcmSampleRate` | PCM (signed 16bit little endian) sample rate used in `speakAudio` in Hz. | `22050`
`modelRoot` | The root name of the armature. | `Armature`
`modelPixelRatio` | Sets the device&#039;s pixel ratio. | `1`
`modelFPS` | Frames per second. Note that actual frame rate will be a bit lower than the set value. | `30`
`modelMovementFactor` | A factor in the range [0,1] limiting the avatar&#039;s upper body movement when standing. | `1`
`dracoEnabled` | If `true`, use Draco geometry compression. [&amp;#8805;`v1.5`] | `false`
`dracoDecoderPath` | Draco decoder library path. [&amp;#8805;`v1.5`] | `&quot;https://www.gstatic.com/`&lt;br&gt;`draco/v1/decoders/&quot;`
`cameraView` | Initial view. Supported views are `&quot;full&quot;`, `&quot;mid&quot;`, `&quot;upper&quot;`  and `&quot;head&quot;`. | `&quot;full&quot;`
`cameraDistance` | Camera distance offset for initial view in meters. | `0`
`cameraX` | Camera position offset in X direction in meters. | `0`
`cameraY` | Camera position offset in Y direction in meters. | `0`
`cameraRotateX` | Camera rotation offset in X direction in radians. | `0`
`cameraRotateY` | Camera rotation offset in Y direction in radians. | `0`
`cameraRotateEnable` | If true, the user is allowed to rotate the 3D model. | `true`
`cameraPanEnable` | If true, the user is allowed to pan the 3D model. | `false`
`cameraZoomEnable` | If true, the user is allowed to zoom the 3D model. | `false`
`lightAmbientColor` | Ambient light color. The value can be a hexadecimal color or CSS-style string. | `0xffffff`
`lightAmbientIntensity` | Ambient light intensity. | `2`
`lightDirectColor` | Direction light color. The value can be a hexadecimal color or CSS-style string. | `0x8888aa`
`lightDirectIntensity` | Direction light intensity. | `30`
`lightDirectPhi` | Direction light phi angle. | `0.1`
`lightDirectTheta` | Direction light theta angle. | `2`
`lightSpotColor` | Spot light color. The value can be a hexadecimal color or CSS-style string. | `0x3388ff`
`lightSpotIntensity` | Spot light intensity. | `0`
`lightSpotPhi` | Spot light phi angle. | `0.1`
`lightSpotTheta` | Spot light theta angle. | `4`
`lightSpotDispersion` | Spot light dispersion. | `1`
`avatarMood` | The mood of the avatar. Supported moods: `&quot;neutral&quot;`, `&quot;happy&quot;`, `&quot;angry&quot;`, `&quot;sad&quot;`, `&quot;fear&quot;`, `&quot;disgust&quot;`, `&quot;love&quot;`, `&quot;sleep&quot;`. | `&quot;neutral&quot;`
`avatarMute`| Mute the avatar. This can be helpful option if you want to output subtitles without audio and lip-sync. | `false`
`avatarIdle`&lt;br&gt;`EyeContact` | The average proportion of eye contact while idle in the range [0,1]. | `0.2`
`avatarIdle`&lt;br&gt;`HeadMove` | The average proportion of head movement while idle in the range [0,1]. | `0.5`
`avatarSpeaking`&lt;br&gt;`EyeContact` | The average proportion of eye contact while speaking in the range [0,1]. | `0.5`
`avatarSpeaking`&lt;br&gt;`HeadMove` | The average proportion of head movement while speaking in the range [0,1]. | `0.5`
`avatarIgnoreCamera` | If set to `true`, makes the avatar to ignore the camera and speak to whatever it is facing. | `false`
`listeningSilence`&lt;br&gt;`ThresholdLevel` |  Silence detection threshold in the range of [0,100]. If the volume stays below the level for the set duration, a `&quot;stop&quot;` event is triggered. | `40`
`listeningSilence`&lt;br&gt;`ThresholdMs` | Silence detection duration in milliseconds. If the volume stays below the level for the set duration, a `&quot;stop&quot;` event is triggered. | `2000`
`listeningSilence`&lt;br&gt;`DurationMax` | Maximum silence in milliseconds before `&quot;maxsilence&quot;` event is triggered. | `10000`
`listeningActive`&lt;br&gt;`ThresholdLevel` | Activity detection threshold in the range of [0,100]. If the volume stays above the set level for the set duration, a `&quot;start&quot;` event is triggered. | `90`
`listeningActive`&lt;br&gt;`ThresholdMs` | Activity detection duration in milliseconds. If the volume stays above the set level for the set duration, a `&quot;start&quot;` event is triggered. | `400`
`listeningActive`&lt;br&gt;`DurationMax` | Maximum activity in milliseconds before `&quot;maxactive&quot;` event is triggered. | `240000`
`avatarOnly` | If `true`, creates an avatar armature object instead of a standalone instance with a 3D scene, lights, and renderer. Read Appendix H for more details about the `avatarOnly` mode. (EXPERIMENTAL) | `false`
`avatarOnlyCamera` | In `avatarOnly` mode, sets the camera to which the avatar is linked. | `null`
`avatarOnlyScene` | If set in `avatarOnly` mode, the armature object is automatically added to the specified scene. | `null`
`update` | Custom callback function inside the `requestAnimationFrame` animation loop. Enables the app to do custom processing before rendering the 3D scene. If `null`, disabled. | `null`
`statsNode` | Parent DOM element for the three.js stats display. If `null`, don&#039;t use. | `null`
`statsStyle` | CSS style for the stats element. If `null`, use the three.js default style. | `null`

&lt;/details&gt;

Once the instance has been created, you can load and display your avatar.
Refer to Appendix A for how to make your avatar:

```javascript
// Load and show the avatar
try {
  await head.showAvatar( {
    url: &#039;./avatars/brunette.glb&#039;,
    body: &#039;F&#039;,
    avatarMood: &#039;neutral&#039;,
    ttsLang: &quot;en-GB&quot;,
    ttsVoice: &quot;en-GB-Standard-A&quot;,
    lipsyncLang: &#039;en&#039;
  });
} catch (error) {
  console.log(error);
}
```

An example of how to make the avatar speak the text on input `text` when
the button `speak` is clicked:

```javascript
// Speak &#039;text&#039; when the button &#039;speak&#039; is clicked
const nodeSpeak = document.getElementById(&#039;speak&#039;);
nodeSpeak.addEventListener(&#039;click&#039;, function () {
  try {
    const text = document.getElementById(&#039;text&#039;).value;
    if ( text ) {
      head.speakText( text );
    }
  } catch (error) {
    console.log(error);
  }
});
```

&lt;details&gt;
  &lt;summary&gt;CLICK HERE to see the key METHODS.&lt;/summary&gt;

Method | Description
--- | ---
`showAvatar(avatar, [onprogress=null])` | Load and show the specified avatar. The `avatar` object must include the `url` for GLB file. Optional properties are `body` for either male `M` or female `F` body form, `lipsyncLang`, `lipsyncHeadMovement`, `baseline` object for blend shape baseline, `modelDynamicBones` for dynamic bones (see Appendix E), `ttsLang`, `ttsVoice`, `ttsRate`, `ttsPitch`, `ttsVolume`, `avatarMood`, `avatarMute`, `avatarIdleEyeContact`, `avatarSpeakingEyeContact`, `avatarListeningEyeContact`, and `avatarIgnoreCamera`.
`setView(view, [opt])` | Set view. Supported views are `&quot;full&quot;`, `&quot;mid&quot;`, `&quot;upper&quot;`  and `&quot;head&quot;`. The `opt` object can be used to set `cameraDistance`, `cameraX`, `cameraY`, `cameraRotateX`, `cameraRotateY`.
`setLighting(opt)` | Change lighting settings. The `opt` object can be used to set `lightAmbientColor`, `lightAmbientIntensity`, `lightDirectColor`, `lightDirectIntensity`, `lightDirectPhi`, `lightDirectTheta`, `lightSpotColor`, `lightSpotIntensity`, `lightSpotPhi`, `lightSpotTheta`, `lightSpotDispersion`.
`speakText(text, [opt={}], [onsubtitles=null], [excludes=[]])` | Add the `text` string to the speech queue. The text can contain face emojis. Options `opt` can be used to set text-specific `lipsyncLang`, `ttsLang`, `ttsVoice`, `ttsRate`, `ttsPitch`, `ttsVolume`, `avatarMood`, `avatarMute`. Optional callback function `onsubtitles` is called whenever a new subtitle is to be written with the parameter of the added string. The optional `excludes` is an array of [start,end] indices to be excluded from audio but to be included in the subtitles.
`speakAudio(audio, [opt={}], [onsubtitles=null])` | Add a new `audio` object to the speech queue. In audio object, property `audio` is either `AudioBuffer` or an array of PCM 16bit LE audio chunks. Property `words` is an array of words, `wtimes` is an array of corresponding starting times in milliseconds, and `wdurations` an array of durations in milliseconds. If the Oculus viseme IDs are known, they can be given in optional `visemes`, `vtimes` and `vdurations` arrays. The object also supports optional timed callbacks using `markers` and `mtimes`. In addition, you can provide an optional `anim` as an animation template object that can drive your own blendshape or morph target data in sync with audio playback. See Appendix F for more details. The `opt` object can be used to set text-specific `lipsyncLang`.
`streamStart(opt={},  onAudioStart = null, onAudioEnd = null, onSubtitles = null, onMetrics = null)` | Sets the talking head in streaming mode. See Appendix G for streaming instructions.
`streamAudio(audio)` | Starts feeding audio chunks to talkinghead in the streaming mode. See Appendix G for streaming instructions.
`streamNotifyEnd()` | Signals the end of streaming audio chunks to the talkinghead. See Appendix G for streaming instructions.
`streamInterrupt()` | Interrupts ongoing audio and lip-sync in streaming mode without ending the session. See Appendix G for streaming instructions.
`streamStop()` | Exits the streaming mode and ends the session. See Appendix G for streaming instructions.
`speakEmoji(e)` | Add an emoji `e` to the speech queue.
`speakBreak(t)` | Add a break of `t` milliseconds to the speech queue.
`speakMarker(onmarker)` | Add a marker to the speech queue. The callback function `onmarker` is called when the queue processes the marker.
`lookAt(x,y,t)` | Make the avatar&#039;s head turn to look at the screen position (`x`,`y`) for `t` milliseconds.
`lookAhead(t)` | Make avatar look ahead for `t` milliseconds.
`lookAtCamera(t)` | Make the avatar&#039;s head turn to look at the camera for `t` milliseconds. If `avatarIgnoreCamera` is set to `true`, looks ahead for `t` milliseconds.
`makeEyeContact(t)` | Make the avatar maintain eye contact with the person in front of it for (at least) `t` milliseconds.
`setMood(mood)` | Set avatar mood.
`playBackgroundAudio(url)` | Play background audio such as ambient sounds/music in a loop.
`stopBackgroundAudio()` | Stop playing the background audio.
`setMixerGain(speech, [background=null], [fadeSecs=0])` | The amount of gain for speech and background audio (see Web Audio API / GainNode for more information). Value `null` means no change. Optional `fadeSecs` parameter sets exponential fade in/out time in seconds.
`playAnimation(url, [onprogress=null], [dur=10], [ndx=0], [scale=0.01])` | Play Mixamo animation file for `dur` seconds, but full rounds and at least once. If the FBX file includes sev

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[bgstaal/multipleWindow3dScene]]></title>
            <link>https://github.com/bgstaal/multipleWindow3dScene</link>
            <guid>https://github.com/bgstaal/multipleWindow3dScene</guid>
            <pubDate>Mon, 15 Sep 2025 00:05:01 GMT</pubDate>
            <description><![CDATA[A quick example of how one can "synchronize" a 3d scene across multiple windows using three.js and localStorage]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bgstaal/multipleWindow3dScene">bgstaal/multipleWindow3dScene</a></h1>
            <p>A quick example of how one can "synchronize" a 3d scene across multiple windows using three.js and localStorage</p>
            <p>Language: JavaScript</p>
            <p>Stars: 18,760</p>
            <p>Forks: 2,913</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre># Multiple Window 3D Scene using Three.js

## Introduction
This project demonstrates a unique approach to creating and managing a 3D scene across multiple browser windows using Three.js and localStorage. It&#039;s designed for developers interested in advanced web graphics and window management techniques.

## Features
- 3D scene creation and rendering with Three.js.
- Synchronization of 3D scenes across multiple browser windows.
- Dynamic window management and state synchronization using localStorage.

## Installation
Clone the repository and open `index.html` in your browser to start exploring the 3D scene.

```
git clone https://github.com/bgstaal/multipleWindow3dScene
```
## Usage
The main application logic is contained within `main.js` and `WindowManager.js`. The 3D scene is rendered in `index.html`, which serves as the entry point of the application.

## Structure and Components
- `index.html`: Entry point that sets up the HTML structure and includes the Three.js library and the main script.
- `WindowManager.js`: Core class managing window creation, synchronization, and state management across multiple windows.
- `main.js`: Contains the logic for initializing the 3D scene, handling window events, and rendering the scene.
- `three.r124.min.js`: Minified version of the Three.js library used for 3D graphics rendering.

## Detailed Functionality
- `WindowManager.js` handles the lifecycle of multiple browser windows, including creation, synchronization, and removal. It uses localStorage to maintain state across windows.
- `main.js` initializes the 3D scene using Three.js, manages the window&#039;s resize events, and updates the scene based on window interactions.

## Contributing
Contributions to enhance or expand the project are welcome. Feel free to fork the repository, make changes, and submit pull requests.

## License
This project is open-sourced under the MIT License.

## Acknowledgments
- The Three.js team for their comprehensive 3D library.
- x.com/didntdrinkwater for this readme.

## Contact
For more information and updates, follow [@_nonfigurativ_](https://twitter.com/_nonfigurativ_) on Twitter.
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[drawdb-io/drawdb]]></title>
            <link>https://github.com/drawdb-io/drawdb</link>
            <guid>https://github.com/drawdb-io/drawdb</guid>
            <pubDate>Mon, 15 Sep 2025 00:05:00 GMT</pubDate>
            <description><![CDATA[Free, simple, and intuitive online database diagram editor and SQL generator.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/drawdb-io/drawdb">drawdb-io/drawdb</a></h1>
            <p>Free, simple, and intuitive online database diagram editor and SQL generator.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 32,669</p>
            <p>Forks: 2,424</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;sup&gt;Special thanks to:&lt;/sup&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://www.warp.dev/drawdb/&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Warp sponsorship&quot; width=&quot;280&quot; src=&quot;https://github.com/user-attachments/assets/c7f141e7-9751-407d-bb0e-d6f2c487b34f&quot;&gt;
    &lt;br&gt;
    &lt;b&gt;Next-gen AI-powered intelligent terminal for all platforms&lt;/b&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;br/&gt;
&lt;br/&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;img width=&quot;64&quot; alt=&quot;drawdb logo&quot; src=&quot;./src/assets/icon-dark.png&quot;&gt;
    &lt;h1&gt;drawDB&lt;/h1&gt;
&lt;/div&gt;

&lt;h3 align=&quot;center&quot;&gt;Free, simple, and intuitive database schema editor and SQL generator.&lt;/h3&gt;

&lt;div align=&quot;center&quot; style=&quot;margin-bottom:12px;&quot;&gt;
    &lt;a href=&quot;https://drawdb.app/&quot; style=&quot;display: flex; align-items: center;&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/Start%20building-grey&quot; alt=&quot;drawDB&quot;/&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/BrjZgNrmR6&quot; style=&quot;display: flex; align-items: center;&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1196658537208758412.svg?label=Join%20the%20Discord&amp;logo=discord&quot; alt=&quot;Discord&quot;/&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://x.com/drawDB_&quot; style=&quot;display: flex; align-items: center;&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/Follow%20us%20on%20X-blue?logo=X&quot; alt=&quot;Follow us on X&quot;/&gt;
    &lt;/a&gt;
&lt;/div&gt;

&lt;h3 align=&quot;center&quot;&gt;&lt;img width=&quot;700&quot; style=&quot;border-radius:5px;&quot; alt=&quot;demo&quot; src=&quot;drawdb.png&quot;&gt;&lt;/h3&gt;

DrawDB is a robust and user-friendly database entity relationship (DBER) editor right in your browser. Build diagrams with a few clicks, export sql scripts, customize your editor, and more without creating an account. See the full set of features [here](https://drawdb.app/).

## Getting Started

### Local Development

```bash
git clone https://github.com/drawdb-io/drawdb
cd drawdb
npm install
npm run dev
```

### Build

```bash
git clone https://github.com/drawdb-io/drawdb
cd drawdb
npm install
npm run build
```

### Docker Build

```bash
docker build -t drawdb .
docker run -p 3000:80 drawdb
```

If you wish to work with sharing, set up [server](https://github.com/drawdb-io/drawdb-server) and environment variables according to `.env.sample`. This is not required unless you want to share files.
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[brave/brave-browser]]></title>
            <link>https://github.com/brave/brave-browser</link>
            <guid>https://github.com/brave/brave-browser</guid>
            <pubDate>Mon, 15 Sep 2025 00:04:59 GMT</pubDate>
            <description><![CDATA[Brave browser for Android, iOS, Linux, macOS, Windows.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/brave/brave-browser">brave/brave-browser</a></h1>
            <p>Brave browser for Android, iOS, Linux, macOS, Windows.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 20,170</p>
            <p>Forks: 2,738</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>![Brave Browser](./docs/source/_static/Brave.svg)

## Overview

This repository holds the build tools needed to build the Brave desktop browser for macOS, Windows, and Linux.  In particular, it fetches and syncs code from the projects defined in `package.json` and `src/brave/DEPS`:

  - [Chromium](https://chromium.googlesource.com/chromium/src.git)
    - Fetches code via `depot_tools`.
    - Sets the branch for Chromium (ex: 65.0.3325.181).
  - [brave-core](https://github.com/brave/brave-core)
    - Mounted at `src/brave`.
    - Maintains patches for 3rd party Chromium code.
  - [adblock-rust](https://github.com/brave/adblock-rust)
    - Implements Brave&#039;s ad-block engine.
    - Linked through [brave/adblock-rust-ffi](https://github.com/brave/brave-core/tree/master/components/adblock_rust_ffi).

## Downloads

You can [visit our website](https://brave.com/download) to get the latest stable release.

## Contributing

Please see the [contributing guidelines](./CONTRIBUTING.md).

Our [Wiki](https://github.com/brave/brave-browser/wiki) also has some useful technical information.

## Community

[Join the Q&amp;A community](https://community.brave.app/) if you&#039;d like to get more involved with Brave. You can [ask for help](https://community.brave.app/c/support-and-troubleshooting),
[discuss features you&#039;d like to see](https://community.brave.app/c/brave-feature-requests), and a lot more. We&#039;d love to have your help so that we can continue improving Brave.

Help us translate Brave to your language by submitting translations at https://explore.transifex.com/brave/brave_en/.

Follow [@brave](https://x.com/brave) on X for important news and announcements.

## Install prerequisites

Follow the instructions for your platform:

- [macOS](https://github.com/brave/brave-browser/wiki/macOS-Development-Environment)
- [iOS](https://github.com/brave/brave-browser/wiki/iOS-Development-Environment)
- [Windows](https://github.com/brave/brave-browser/wiki/Windows-Development-Environment)
- [Linux](https://github.com/brave/brave-browser/wiki/Linux-Development-Environment)
- [Android](https://github.com/brave/brave-browser/wiki/Android-Development-Environment)

## Clone and initialize the repo

Once you have the prerequisites installed, you can get the code and initialize the build environment.

```bash
git clone git@github.com:brave/brave-core.git path-to-your-project-folder/src/brave
cd path-to-your-project-folder/src/brave
npm install

# the Chromium source is downloaded, which has a large history (gigabytes of data)
# this might take really long to finish depending on internet speed

npm run init
```
brave-core based android builds should use `npm run init -- --target_os=android --target_arch=arm` (or whichever CPU type you want to build for)
brave-core based iOS builds should use `npm run init -- --target_os=ios`

You can also set the target_os and target_arch for init and build using:

```
npm config set target_os android
npm config set target_arch arm
```

Additional parameters needed to build are documented at https://github.com/brave/brave-browser/wiki/Build-configuration

Internal developers can find more information at https://github.com/brave/devops/wiki/%60.env%60-config-for-Brave-Developers

## Build Brave
The default build type is component.

```
# start the component build compile
npm run build
```

To do a release build:

```
# start the release compile
npm run build Release
```

brave-core based android builds should use `npm run build -- --target_os=android --target_arch=arm` or set the npm config variables as specified above for `init`

brave-core based iOS builds should use the Xcode project found in `ios/brave-ios/App`. You can open this project directly or run `npm run ios_bootstrap -- --open_xcodeproj` to have it opened in Xcode. See the [iOS Developer Environment](https://github.com/brave/brave-browser/wiki/iOS-Development-Environment#Building) for more information on iOS builds.

### Build Configurations

Running a release build with `npm run build Release` can be very slow and use a lot of RAM, especially on Linux with the Gold LLVM plugin.

To run a statically linked build (takes longer to build, but starts faster):

```bash
npm run build -- Static
```

To run a debug build (Component build with is_debug=true):

```bash
npm run build -- Debug
```
NOTE: the build will take a while to complete. Depending on your processor and memory, it could potentially take a few hours.

## Run Brave
To start the build:

`npm start [Release|Component|Static|Debug]`

# Update Brave

`npm run sync -- [--force] [--init] [--create] [brave_core_ref]`

**This will attempt to stash your local changes in brave-core, but it&#039;s safer to commit local changes before running this**

`npm run sync` will (depending on the below flags):

1. 📥 Update sub-projects (chromium, brave-core) to latest commit of a git ref (e.g. tag or branch)
2. 🤕 Apply patches
3. 🔄 Update gclient DEPS dependencies
4. ⏩ Run hooks (e.g. to perform `npm install` on child projects)

| flag | Description |
|---|---|
|`[no flags]`|updates chromium if needed and re-applies patches. If the chromium version did not change, it will only re-apply patches that have changed. Will update child dependencies **only if any project needed updating during this script run**. &lt;br&gt; **Use this if you want the script to manage keeping you up to date instead of pulling or switching branches manually. **|
|`--force`|updates both _Chromium_ and _brave-core_ to the latest remote commit for the current brave-core branch and the _Chromium_ ref specified in brave-browser/package.json (e.g. `master` or `74.0.0.103`). Will re-apply all patches. Will force update all child dependencies. &lt;br&gt; **Use this if you&#039;re having trouble and want to force the branches back to a known state. **|
|`--init`|force update both _Chromium_ and _brave-core_ to the versions specified in brave-browser/package.json and force updates all dependent repos - same as `npm run init`|
|`--sync_chromium (true/false)`|Will force or skip the chromium version update when applicable. Useful if you want to avoid a minor update when not ready for the larger build time a chromium update may result in. A warning will be output about the current code state expecting a different chromium version. Your build may fail as a result.|
|`-D, --delete_unused_deps`|Will delete from the working copy any dependencies that have been removed since the last sync. Mimics `gclient sync -D`.|

Run `npm run sync brave_core_ref` to checkout the specified _brave-core_ ref and update all dependent repos including chromium if needed.

## Scenarios

#### Create a new branch:
```bash
brave-browser&gt; cd src/brave
brave-browser/src/brave&gt; git checkout -b branch_name
```

#### Checkout an existing branch or tag:
```bash
brave-browser/src/brave&gt; git fetch origin
brave-browser/src/brave&gt; git checkout [-b] branch_name
brave-browser/src/brave&gt; npm run sync
...Updating 2 patches...
...Updating child dependencies...
...Running hooks...
```

#### Update the current branch to the latest remote:
```bash
brave-browser/src/brave&gt; git pull
brave-browser/src/brave&gt; npm run sync
...Updating 2 patches...
...Updating child dependencies...
...Running hooks...
```

#### Reset to latest brave-browser master and brave-core master (via `init`, will always result in a longer build and will remove any pending changes in your brave-core working directory):
```bash
brave-browser&gt; git checkout master
brave-browser&gt; git pull
brave-browser&gt; npm run sync -- --init
```

#### When you know that DEPS didn&#039;t change, but .patch files did (quickest attempt to perform a mini-sync before a build):
```bash
brave-browser/src/brave&gt; git checkout featureB
brave-browser/src/brave&gt; git pull
brave-browser/src/brave&gt; cd ../..
brave-browser&gt; npm run apply_patches
...Applying 2 patches...
```

# Enabling third-party APIs:

1. **Google Safe Browsing**: Get an API key with SafeBrowsing API enabled from https://console.developers.google.com/. Update the `GOOGLE_API_KEY` environment variable with your key as per https://www.chromium.org/developers/how-tos/api-keys to enable Google SafeBrowsing.

# Development

- [Security rules from Chromium](https://chromium.googlesource.com/chromium/src/+/refs/heads/main/docs/security/rules.md)
- [IPC review guidelines](https://chromium.googlesource.com/chromium/src/+/HEAD/docs/security/ipc-reviews.md) (in particular [this reference](https://docs.google.com/document/d/1Kw4aTuISF7csHnjOpDJGc7JYIjlvOAKRprCTBVWw_E4/edit#heading=h.84bpc1e9z1bg))
- [Brave&#039;s internal security guidelines](https://github.com/brave/internal/wiki/Pull-request-security-audit-checklist) (for employees only)
- [Rust usage](https://github.com/brave/brave-core/blob/master/docs/rust.md)

# Troubleshooting

See [Troubleshooting](https://github.com/brave/brave-browser/wiki/Troubleshooting) for solutions to common problems.
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[4ian/GDevelop]]></title>
            <link>https://github.com/4ian/GDevelop</link>
            <guid>https://github.com/4ian/GDevelop</guid>
            <pubDate>Mon, 15 Sep 2025 00:04:58 GMT</pubDate>
            <description><![CDATA[🎮 Open-source, cross-platform 2D/3D/multiplayer game engine designed for everyone.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/4ian/GDevelop">4ian/GDevelop</a></h1>
            <p>🎮 Open-source, cross-platform 2D/3D/multiplayer game engine designed for everyone.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 16,417</p>
            <p>Forks: 1,075</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre>![GDevelop logo](https://raw.githubusercontent.com/4ian/GDevelop/master/newIDE/GDevelop%20banner.png &quot;GDevelop logo&quot;)

GDevelop is a **full-featured, no-code, open-source** game development software. You can build **2D, 3D and multiplayer games** for mobile (iOS, Android), desktop and the web. GDevelop is fast and easy to use: the game logic is built up using an intuitive and powerful event-based system and reusable behaviors.

![The GDevelop editor when editing a game level](https://raw.githubusercontent.com/4ian/GDevelop/master/newIDE/GDevelop%20screenshot.png &quot;The GDevelop editor when editing a game level&quot;)

## Getting started

| ❔ I want to...                                   | 🚀 What to do                                                                                                                                                     |
| ------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 🎮 Use GDevelop to make games                     | Go to [GDevelop homepage](https://gdevelop.io) to download the app!                                                                                               |
| ⚙️ Create/improve an extension                    | Read about [creating an extension](https://wiki.gdevelop.io/gdevelop5/extensions/create), with no-code or code.                                                   |
| 🧑‍💻 Contribute to the editor or game engine        | Follow this [README](newIDE/README.md).                                                                                                                           |
| 👾 Create or sell a game template                 | Submit a [free example or a paid template on the Asset Store](https://wiki.gdevelop.io/gdevelop5/community/guide-for-submitting-an-example/).                     |
| 🎨 Share or sell an asset pack                    | Submit a [free or paid asset pack on the Asset Store](https://wiki.gdevelop.io/gdevelop5/community/sell-asset-pack-store).                                        |
| 🌐 Help translate GDevelop                        | Go on the [GDevelop project on Crowdin](https://crowdin.com/project/gdevelop) or translate [in-app tutorials](https://github.com/GDevelopApp/GDevelop-tutorials). |
| 👥 Get online game services or commercial support | See offers for [professionals, teams or individual creators](https://gdevelop.io/pricing).                                                                        |

&gt; Are you interested in contributing to GDevelop for the first time? Take a look at the list of **[good first issues](https://github.com/4ian/GDevelop/issues?q=is%3Aissue+is%3Aopen+label%3A%22%F0%9F%91%8Cgood+first+issue%22)**, **[good first contributions](https://github.com/4ian/GDevelop/discussions/categories/good-first-contribution)** or the **[&quot;🏐 not too hard&quot; cards](https://trello.com/b/qf0lM7k8/gdevelop-roadmap?menu=filter&amp;filter=label:Not%20too%20hard%20%E2%9A%BD%EF%B8%8F)** on the Roadmap.

## Games made with GDevelop

- Find GDevelop games on [gd.games](https://gd.games), the gaming platform for games powered by GDevelop.
- See the [showcase of games](https://gdevelop.io/games) created with GDevelop and published on Steam, iOS (App Store), Android (Google Play), Itch.io, Newgrounds, CrazyGames, Poki...
  - Suggest your game to be [added to the showcase here](https://docs.google.com/forms/d/e/1FAIpQLSfjiOnkbODuPifSGuzxYY61vB5kyMWdTZSSqkJsv3H6ePRTQA/viewform).

[![Some games made with GDevelop](https://raw.githubusercontent.com/4ian/GDevelop/master/newIDE/GDevelop%20games.png &quot;Some games made with GDevelop&quot;)](https://gdevelop.io/games)

## Technical architecture

GDevelop is composed of an **editor**, a **game engine**, an **ecosystem** of extensions as well as **online services** and commercial support.

| Directory     | ℹ️ Description                                                                                                                                                                                                                                                                                           |
| ------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `Core`        | Core classes, describing the structure of a game and tools to implement the IDE and work with GDevelop games.                                                                                                                                                                                            |
| `GDJS`        | The game engine, written in TypeScript, using PixiJS and Three.js for 2D and 3D rendering (WebGL), powering all GDevelop games.                                                                                                                                                                          |
| `GDevelop.js` | Bindings of `Core`, `GDJS` and `Extensions` to JavaScript (with WebAssembly), used by the IDE.                                                                                                                                                                                                           |
| `newIDE`      | The game editor, written in JavaScript with React, Electron, PixiJS and Three.js.js.                                                                                                                                                                                                                     |
| `Extensions`  | Built-in extensions for the game engine, providing objects, behaviors and new features. For example, this includes the physics engines running in WebAssembly (Box2D or Jolt Physics for 3D). All the [community extensions are on this repository](https://github.com/GDevelopApp/GDevelop-extensions). |

To learn more about GDevelop Architecture, read the [architecture overview here](Core/GDevelop-Architecture-Overview.md).

Pre-generated documentation of the game engine is [available here](https://docs.gdevelop.io).

Status of the tests and builds: [![macOS and Linux build status](https://circleci.com/gh/4ian/GDevelop.svg?style=shield)](https://app.circleci.com/pipelines/github/4ian/GDevelop) [![Fast tests status](https://gdevelop.semaphoreci.com/badges/GDevelop/branches/master.svg?style=shields)](https://gdevelop.semaphoreci.com/projects/GDevelop) [![Windows Build status](https://ci.appveyor.com/api/projects/status/84uhtdox47xp422x/branch/master?svg=true)](https://ci.appveyor.com/project/4ian/gdevelop/branch/master) [![https://good-labs.github.io/greater-good-affirmation/assets/images/badge.svg](https://good-labs.github.io/greater-good-affirmation/assets/images/badge.svg)](https://good-labs.github.io/greater-good-affirmation)

## Links

### Community

- [GDevelop forums](https://forum.gdevelop.io) and [Discord chat](https://discord.gg/gdevelop).
- [GDevelop homepage](https://gdevelop.io).
- [GDevelop wiki (documentation)](https://wiki.gdevelop.io/gdevelop5/start).
- Help translate GDevelop in your language: [GDevelop project on Crowdin](https://crowdin.com/project/gdevelop).
- Open-source [extensions](https://github.com/GDevelopApp/GDevelop-extensions), [examples](https://github.com/GDevelopApp/GDevelop-examples), [tutorials](https://github.com/GDevelopApp/GDevelop-tutorials) are on GitHub.

### Development Roadmap

- [GDevelop Roadmap on Trello.com](https://trello.com/b/qf0lM7k8/gdevelop-roadmap), for a global view of the features that could be added. Please vote and comment here for new features/requests.
- [GitHub issue page](https://github.com/4ian/GDevelop/issues), for technical issues and bugs.
- [Github discussions](https://github.com/4ian/GDevelop/discussions) to talk about new features and ideas.

## License

- The Core library, the native and HTML5 game engines, the IDE, and all extensions (respectively `Core`, `GDJS`, `newIDE` and `Extensions` folders) are under the **MIT license**.
- The name, GDevelop, and its logo are the exclusive property of Florian Rival.

Games exported with GDevelop are based on the GDevelop game engine (see `Core` and `GDJS` folders): this engine is distributed under the MIT license so that you can **distribute, sell or do anything** with the games you created with GDevelop. In particular, you are not forced to make your game open-source.

[node.js]: https://nodejs.org

## Star History

Help us spread the word about GDevelop by starring the repository on GitHub!

[![Star History Chart](https://api.star-history.com/svg?repos=4ian/gdevelop&amp;type=Date)](https://star-history.com/#4ian/gdevelop&amp;Date)
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[juliangarnier/anime]]></title>
            <link>https://github.com/juliangarnier/anime</link>
            <guid>https://github.com/juliangarnier/anime</guid>
            <pubDate>Mon, 15 Sep 2025 00:04:57 GMT</pubDate>
            <description><![CDATA[JavaScript animation engine]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/juliangarnier/anime">juliangarnier/anime</a></h1>
            <p>JavaScript animation engine</p>
            <p>Language: JavaScript</p>
            <p>Stars: 63,839</p>
            <p>Forks: 4,262</p>
            <p>Stars today: 87 stars today</p>
            <h2>README</h2><pre># Anime.js

&lt;p align=&quot;center&quot;&gt;
  &lt;picture align=&quot;center&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./assets/images/animejs-v4-logo-animation-dark.gif&quot;&gt;
    &lt;img align=&quot;center&quot; alt=&quot;Anime.js V4 logo animation&quot; src=&quot;./assets/images/animejs-v4-logo-animation.gif&quot; width=&quot;560&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
  &lt;em&gt;Anime.js&lt;/em&gt; is a fast, multipurpose and lightweight JavaScript animation library with a simple, yet powerful API.&lt;br&gt;
  It works with CSS properties, SVG, DOM attributes and JavaScript Objects.
  &lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;NPM Downloads&quot; src=&quot;https://img.shields.io/npm/dm/animejs?style=flat-square&amp;logo=npm&quot;&gt;
  &lt;img alt=&quot;jsDelivr hits (npm)&quot; src=&quot;https://img.shields.io/jsdelivr/npm/hm/animejs?style=flat-square&amp;logo=jsdeliver&quot;&gt;
  &lt;img alt=&quot;GitHub Sponsors&quot; src=&quot;https://img.shields.io/github/sponsors/juliangarnier?style=flat-square&amp;logo=github&quot;&gt;
&lt;/p&gt;

## Sponsors

Anime.js is 100% free and is only made possible with the help of our sponsors.
Help the project become sustainable by sponsoring us on &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/sponsors/juliangarnier&quot;&gt;GitHub Sponsors&lt;/a&gt;.

### Platinum sponsors

&lt;p&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://ice.io/?ref=animejs&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./assets/sponsors/ice-open-network-logomark.png&quot;&gt;
    &lt;img align=&quot;center&quot; src=&quot;./assets/sponsors/ice-open-network-logomark-dark.png&quot; width=&quot;250&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/p&gt;

### Silver sponsors

&lt;p&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://www.lambdatest.com?utm_source=animeJS&amp;utm_medium=organic&amp;utm_campaign=july_08&amp;utm_term=sk&amp;utm_content=opensource&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./assets/sponsors/lambdatest-logomark.png&quot;&gt;
    &lt;img align=&quot;center&quot; src=&quot;./assets/sponsors/lambdatest-logomark-dark.png&quot; width=&quot;150&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://inspatialapp.com/?ref=animejs&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./assets/sponsors/inspatial-logomark.png&quot;&gt;
    &lt;img align=&quot;center&quot; src=&quot;./assets/sponsors/inspatial-logomark-dark.png&quot; width=&quot;150&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/p&gt;

## Usage

Anime.js V4 works by importing ES modules like so:

&lt;table&gt;
&lt;tr&gt;
  &lt;td&gt;

```javascript
import {
  animate,
  stagger,
} from &#039;animejs&#039;;

animate(&#039;.square&#039;, {
  x: 320,
  rotate: { from: -180 },
  duration: 1250,
  delay: stagger(65, { from: &#039;center&#039; }),
  ease: &#039;inOutQuint&#039;,
  loop: true,
  alternate: true
});
```

  &lt;/td&gt;
  &lt;td&gt;
    &lt;img align=&quot;center&quot; alt=&quot;Anime.js code example&quot; src=&quot;./assets/images/usage-example-result.gif&quot;&gt;
  &lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

## V4 Documentation

The full documentation is available [here](https://animejs.com/documentation).

## V3 Migration guide

You can find the v3 to v4 migration guide [here](https://github.com/juliangarnier/anime/wiki/Migrating-from-v3-to-v4).

## NPM development scripts

First, run `npm i` to install all the necessary packages.
Then, execute the following scripts with `npm run &lt;script&gt;`.

| script | action |
| ------ | ------ |
| `dev` | Watch any changes in `src/` and compiles the esm version to `lib/anime.esm.js` |
| `dev-types` | Same as `dev`, but also run TypeScript and generate the `types/index.d.ts` file |
| `build` | Generate types definition and compiles ESM / UMD / IIFE versions to `lib/` |
| `test-browser` | Start a local server and start all browser related tests |
| `test-node` | Start all Node related tests |
| `open-examples` | Start a local server to browse the examples locally |

© [Julian Garnier](http://juliangarnier.com) | [MIT License](LICENSE.md)</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[automatisch/automatisch]]></title>
            <link>https://github.com/automatisch/automatisch</link>
            <guid>https://github.com/automatisch/automatisch</guid>
            <pubDate>Mon, 15 Sep 2025 00:04:56 GMT</pubDate>
            <description><![CDATA[The open source Zapier alternative. Build workflow automation without spending time and money.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/automatisch/automatisch">automatisch/automatisch</a></h1>
            <p>The open source Zapier alternative. Build workflow automation without spending time and money.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 13,131</p>
            <p>Forks: 989</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre># Automatisch - Open Source Zapier Alternative

![Automatisch - Screenshot](https://user-images.githubusercontent.com/2501931/191562539-e42f6c34-03c7-4dc4-bcf9-7f9473a9c64f.png)

🧐 Automatisch is a business automation tool that lets you connect different services like Twitter, Slack, and more to automate your business processes.

💸 Automating your workflows doesn&#039;t have to be a difficult or expensive process. You also don&#039;t need any programming knowledge to use Automatisch.

## Advantages

There are other existing solutions in the market, like Zapier and Integromat, so you might be wondering why you should use Automatisch.

✅ One of the main benefits of using Automatisch is that it allows you to store your data on your own servers, which is essential for businesses that handle sensitive user information and cannot risk sharing it with external cloud services. This is especially relevant for industries such as healthcare and finance, as well as for European companies that must adhere to the General Data Protection Regulation (GDPR).

🤓 Your contributions are vital to the development of Automatisch. As an open-source software, anyone can have an impact on how it is being developed.

💙 No vendor lock-in. If you ever decide that Automatisch is no longer helpful for your business, you can switch to any other provider, which will be easier than switching from the one cloud provider to another since you have all data and flexibility.

## Documentation

The official documentation can be found here: [https://automatisch.io/docs](https://automatisch.io/docs)

## Installation

```bash
# Clone the repository
git clone https://github.com/automatisch/automatisch.git

# Go to the repository folder
cd automatisch

# Start
docker compose up
```

You can use `user@automatisch.io` email address and `sample` password to login to Automatisch. Please do not forget to change your email and password from the settings page.

For other installation types, you can check the [installation](https://automatisch.io/docs/guide/installation) guide.

## Community Links

- [Discord](https://discord.gg/dJSah9CVrC)
- [Twitter](https://twitter.com/automatischio)

## Support

If you have any questions or problems, please visit our GitHub issues page, and we&#039;ll try to help you as soon as possible.

[https://github.com/automatisch/automatisch/issues](https://github.com/automatisch/automatisch/issues)

## License

Automatisch Community Edition (Automatisch CE) is an open-source software with the [AGPL-3.0 license](LICENSE.agpl).

Automatisch Enterprise Edition (Automatisch EE) is a commercial offering with the [Enterprise license](LICENSE.enterprise).

The Automatisch repository contains both AGPL-licensed and Enterprise-licensed files. We maintain a single repository to make development easier.

All files that contain &quot;.ee.&quot; in their name fall under the [Enterprise license](LICENSE.enterprise). All other files fall under the [AGPL-3.0 license](LICENSE.agpl).

See the [LICENSE](LICENSE) file for more information.
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[Mintplex-Labs/anything-llm]]></title>
            <link>https://github.com/Mintplex-Labs/anything-llm</link>
            <guid>https://github.com/Mintplex-Labs/anything-llm</guid>
            <pubDate>Mon, 15 Sep 2025 00:04:55 GMT</pubDate>
            <description><![CDATA[The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, No-code agent builder, MCP compatibility, and more.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Mintplex-Labs/anything-llm">Mintplex-Labs/anything-llm</a></h1>
            <p>The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, No-code agent builder, MCP compatibility, and more.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 49,024</p>
            <p>Forks: 5,073</p>
            <p>Stars today: 37 stars today</p>
            <h2>README</h2><pre>&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://anythingllm.com&quot;&gt;&lt;img src=&quot;https://github.com/Mintplex-Labs/anything-llm/blob/master/images/wordmark.png?raw=true&quot; alt=&quot;AnythingLLM logo&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;div align=&#039;center&#039;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/2415&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/2415&quot; alt=&quot;Mintplex-Labs%2Fanything-llm | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;b&gt;AnythingLLM:&lt;/b&gt; The all-in-one AI app you were looking for.&lt;br /&gt;
    Chat with your docs, use AI Agents, hyper-configurable, multi-user, &amp; no frustrating setup required.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.gg/6UyHPeGZAC&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/chat-mintplex_labs-blue.svg?style=flat&amp;logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAMAAABEpIrGAAAAIGNIUk0AAHomAACAhAAA+gAAAIDoAAB1MAAA6mAAADqYAAAXcJy6UTwAAAH1UExURQAAAP////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////r6+ubn5+7u7/3+/v39/enq6urq6/v7+97f39rb26eoqT1BQ0pOT4+Rkuzs7cnKykZKS0NHSHl8fdzd3ejo6UxPUUBDRdzc3RwgIh8jJSAkJm5xcvHx8aanqB4iJFBTVezt7V5hYlJVVuLj43p9fiImKCMnKZKUlaaoqSElJ21wcfT09O3u7uvr6zE0Nr6/wCUpK5qcnf7+/nh7fEdKTHx+f0tPUOTl5aipqiouMGtubz5CRDQ4OsTGxufn515hY7a3uH1/gXBydIOFhlVYWvX29qaoqCQoKs7Pz/Pz87/AwUtOUNfY2dHR0mhrbOvr7E5RUy8zNXR2d/f39+Xl5UZJSx0hIzQ3Odra2/z8/GlsbaGjpERHSezs7L/BwScrLTQ4Odna2zM3Obm7u3x/gKSmp9jZ2T1AQu/v71pdXkVISr2+vygsLiInKTg7PaOlpisvMcXGxzk8PldaXPLy8u7u7rm6u7S1tsDBwvj4+MPExbe4ueXm5s/Q0Kyf7ewAAAAodFJOUwAABClsrNjx/QM2l9/7lhmI6jTB/kA1GgKJN+nea6vy/MLZQYeVKK3rVA5tAAAAAWJLR0QB/wIt3gAAAAd0SU1FB+cKBAAmMZBHjXIAAAISSURBVDjLY2CAAkYmZhZWNnYODnY2VhZmJkYGVMDIycXNw6sBBbw8fFycyEoYGfkFBDVQgKAAPyMjQl5IWEQDDYgIC8FUMDKKsmlgAWyiEBWMjGJY5YEqxMAqGMWFNXAAYXGgAkYJSQ2cQFKCkYFRShq3AmkpRgYJbghbU0tbB0Tr6ukbgGhDI10gySfBwCwDUWBsYmpmDqQtLK2sbTQ0bO3sHYA8GWYGWWj4WTs6Obu4ami4OTm7exhqeHp5+4DCVJZBDmqdr7ufn3+ArkZgkJ+fU3CIRmgYWFiOARYGvo5OQUHhEUAFTkF+kVHRsLBgkIeyYmLjwoOc4hMSk5JTnINS06DC8gwcEEZ6RqZGlpOfc3ZObl5+gZ+TR2ERWFyBQQFMF5eklmqUpQb5+ReU61ZUOvkFVVXXQBSAraitq29o1GiKcfLzc29u0mjxBzq0tQ0kww5xZHtHUGeXhkZhdxBYgZ4d0LI6c4gjwd7siQQraOp1AivQ6CuAKZCDBBRQQQNQgUb/BGf3cqCCiZOcnCe3QQIKHNRTpk6bDgpZjRkzg3pBQTBrdtCcuZCgluAD0vPmL1gIdvSixUuWgqNs2YJ+DUhkEYxuggkGmOQUcckrioPTJCOXEnZ5JS5YslbGnuyVERlDDFvGEUPOWvwqaH6RVkHKeuDMK6SKnHlVhTgx8jeTmqy6Eij7K6nLqiGyPwChsa1MUrnq1wAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMy0xMC0wNFQwMDozODo0OSswMDowMB9V0a8AAAAldEVYdGRhdGU6bW9kaWZ5ADIwMjMtMTAtMDRUMDA6Mzg6NDkrMDA6MDBuCGkTAAAAKHRFWHRkYXRlOnRpbWVzdGFtcAAyMDIzLTEwLTA0VDAwOjM4OjQ5KzAwOjAwOR1IzAAAAABJRU5ErkJggg==&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt; |
  &lt;a href=&quot;https://github.com/Mintplex-Labs/anything-llm/blob/master/LICENSE&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/static/v1?label=license&amp;message=MIT&amp;color=white&quot; alt=&quot;License&quot;&gt;
  &lt;/a&gt; |
  &lt;a href=&quot;https://docs.anythingllm.com&quot; target=&quot;_blank&quot;&gt;
    Docs
  &lt;/a&gt; |
   &lt;a href=&quot;https://my.mintplexlabs.com/aio-checkout?product=anythingllm&quot; target=&quot;_blank&quot;&gt;
    Hosted Instance
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;English&lt;/b&gt; · &lt;a href=&#039;./locales/README.zh-CN.md&#039;&gt;简体中文&lt;/a&gt; · &lt;a href=&#039;./locales/README.ja-JP.md&#039;&gt;日本語&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
👉 AnythingLLM for desktop (Mac, Windows, &amp; Linux)! &lt;a href=&quot;https://anythingllm.com/download&quot; target=&quot;_blank&quot;&gt; Download Now&lt;/a&gt;
&lt;/p&gt;

A full-stack application that enables you to turn any document, resource, or piece of content into context that any LLM can use as a reference during chatting. This application allows you to pick and choose which LLM or Vector Database you want to use as well as supporting multi-user management and permissions.

![Chatting](https://github.com/Mintplex-Labs/anything-llm/assets/16845892/cfc5f47c-bd91-4067-986c-f3f49621a859)

&lt;details&gt;
&lt;summary&gt;&lt;kbd&gt;Watch the demo!&lt;/kbd&gt;&lt;/summary&gt;

[![Watch the video](/images/youtube.png)](https://youtu.be/f95rGD9trL0)

&lt;/details&gt;

### Product Overview

AnythingLLM is a full-stack application where you can use commercial off-the-shelf LLMs or popular open source LLMs and vectorDB solutions to build a private ChatGPT with no compromises that you can run locally as well as host remotely and be able to chat intelligently with any documents you provide it.

AnythingLLM divides your documents into objects called `workspaces`. A Workspace functions a lot like a thread, but with the addition of containerization of your documents. Workspaces can share documents, but they do not talk to each other so you can keep your context for each workspace clean.

## Cool features of AnythingLLM

- 🆕 [**Full MCP-compatibility**](https://docs.anythingllm.com/mcp-compatibility/overview)
- 🆕 [**No-code AI Agent builder**](https://docs.anythingllm.com/agent-flows/overview)
- 🖼️ **Multi-modal support (both closed and open-source LLMs!)**
- [**Custom AI Agents**](https://docs.anythingllm.com/agent/custom/introduction)
- 👤 Multi-user instance support and permissioning _Docker version only_
- 🦾 Agents inside your workspace (browse the web, etc)
- 💬 [Custom Embeddable Chat widget for your website](https://github.com/Mintplex-Labs/anythingllm-embed/blob/main/README.md) _Docker version only_
- 📖 Multiple document type support (PDF, TXT, DOCX, etc)
- Simple chat UI with Drag-n-Drop functionality and clear citations.
- 100% Cloud deployment ready.
- Works with all popular [closed and open-source LLM providers](#supported-llms-embedder-models-speech-models-and-vector-databases).
- Built-in cost &amp; time-saving measures for managing very large documents compared to any other chat UI.
- Full Developer API for custom integrations!
- Much more...install and find out!

### Supported LLMs, Embedder Models, Speech models, and Vector Databases

**Large Language Models (LLMs):**

- [Any open-source llama.cpp compatible model](/server/storage/models/README.md#text-generation-llm-selection)
- [OpenAI](https://openai.com)
- [OpenAI (Generic)](https://openai.com)
- [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)
- [AWS Bedrock](https://aws.amazon.com/bedrock/)
- [Anthropic](https://www.anthropic.com/)
- [NVIDIA NIM (chat models)](https://build.nvidia.com/explore/discover)
- [Google Gemini Pro](https://ai.google.dev/)
- [Hugging Face (chat models)](https://huggingface.co/)
- [Ollama (chat models)](https://ollama.ai/)
- [LM Studio (all models)](https://lmstudio.ai)
- [LocalAI (all models)](https://localai.io/)
- [Together AI (chat models)](https://www.together.ai/)
- [Fireworks AI  (chat models)](https://fireworks.ai/)
- [Perplexity (chat models)](https://www.perplexity.ai/)
- [OpenRouter (chat models)](https://openrouter.ai/)
- [DeepSeek (chat models)](https://deepseek.com/)
- [Mistral](https://mistral.ai/)
- [Groq](https://groq.com/)
- [Cohere](https://cohere.com/)
- [KoboldCPP](https://github.com/LostRuins/koboldcpp)
- [LiteLLM](https://github.com/BerriAI/litellm)
- [Text Generation Web UI](https://github.com/oobabooga/text-generation-webui)
- [Apipie](https://apipie.ai/)
- [xAI](https://x.ai/)
- [Novita AI (chat models)](https://novita.ai/model-api/product/llm-api?utm_source=github_anything-llm&amp;utm_medium=github_readme&amp;utm_campaign=link)
- [PPIO](https://ppinfra.com?utm_source=github_anything-llm)
- [Moonshot AI](https://www.moonshot.ai/)

**Embedder models:**

- [AnythingLLM Native Embedder](/server/storage/models/README.md) (default)
- [OpenAI](https://openai.com)
- [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)
- [LocalAI (all)](https://localai.io/)
- [Ollama (all)](https://ollama.ai/)
- [LM Studio (all)](https://lmstudio.ai)
- [Cohere](https://cohere.com/)

**Audio Transcription models:**

- [AnythingLLM Built-in](https://github.com/Mintplex-Labs/anything-llm/tree/master/server/storage/models#audiovideo-transcription) (default)
- [OpenAI](https://openai.com/)

**TTS (text-to-speech) support:**

- Native Browser Built-in (default)
- [PiperTTSLocal - runs in browser](https://github.com/rhasspy/piper)
- [OpenAI TTS](https://platform.openai.com/docs/guides/text-to-speech/voice-options)
- [ElevenLabs](https://elevenlabs.io/)
- Any OpenAI Compatible TTS service.

**STT (speech-to-text) support:**

- Native Browser Built-in (default)

**Vector Databases:**

- [LanceDB](https://github.com/lancedb/lancedb) (default)
- [PGVector](https://github.com/pgvector/pgvector)
- [Astra DB](https://www.datastax.com/products/datastax-astra)
- [Pinecone](https://pinecone.io)
- [Chroma &amp; ChromaCloud](https://trychroma.com)
- [Weaviate](https://weaviate.io)
- [Qdrant](https://qdrant.tech)
- [Milvus](https://milvus.io)
- [Zilliz](https://zilliz.com)

### Technical Overview

This monorepo consists of six main sections:

- `frontend`: A viteJS + React frontend that you can run to easily create and manage all your content the LLM can use.
- `server`: A NodeJS express server to handle all the interactions and do all the vectorDB management and LLM interactions.
- `collector`: NodeJS express server that processes and parses documents from the UI.
- `docker`: Docker instructions and build process + information for building from source.
- `embed`: Submodule for generation &amp; creation of the [web embed widget](https://github.com/Mintplex-Labs/anythingllm-embed).
- `browser-extension`: Submodule for the [chrome browser extension](https://github.com/Mintplex-Labs/anythingllm-extension).

## 🛳 Self-Hosting

Mintplex Labs &amp; the community maintain a number of deployment methods, scripts, and templates that you can use to run AnythingLLM locally. Refer to the table below to read how to deploy on your preferred environment or to automatically deploy.
| Docker | AWS | GCP | Digital Ocean | Render.com |
|----------------------------------------|----|-----|---------------|------------|
| [![Deploy on Docker][docker-btn]][docker-deploy] | [![Deploy on AWS][aws-btn]][aws-deploy] | [![Deploy on GCP][gcp-btn]][gcp-deploy] | [![Deploy on DigitalOcean][do-btn]][do-deploy] | [![Deploy on Render.com][render-btn]][render-deploy] |

| Railway  |  RepoCloud | Elestio |
| --- | --- | --- |
| [![Deploy on Railway][railway-btn]][railway-deploy] | [![Deploy on RepoCloud][repocloud-btn]][repocloud-deploy] | [![Deploy on Elestio][elestio-btn]][elestio-deploy] |

[or set up a production AnythingLLM instance without Docker →](./BARE_METAL.md)

## How to setup for development

- `yarn setup` To fill in the required `.env` files you&#039;ll need in each of the application sections (from root of repo).
  - Go fill those out before proceeding. Ensure `server/.env.development` is filled or else things won&#039;t work right.
- `yarn dev:server` To boot the server locally (from root of repo).
- `yarn dev:frontend` To boot the frontend locally (from root of repo).
- `yarn dev:collector` To then run the document collector (from root of repo).

[Learn about documents](./server/storage/documents/DOCUMENTS.md)

[Learn about vector caching](./server/storage/vector-cache/VECTOR_CACHE.md)

## External Apps &amp; Integrations

_These are apps that are not maintained by Mintplex Labs, but are compatible with AnythingLLM. A listing here is not an endorsement._

- [Midori AI Subsystem Manager](https://io.midori-ai.xyz/subsystem/anythingllm/) - A streamlined and efficient way to deploy AI systems using Docker container technology.
- [Coolify](https://coolify.io/docs/services/anythingllm/) - Deploy AnythingLLM with a single click.
- [GPTLocalhost for Microsoft Word](https://gptlocalhost.com/demo/) - A local Word Add-in for you to use AnythingLLM in Microsoft Word.

## Telemetry &amp; Privacy

AnythingLLM by Mintplex Labs Inc contains a telemetry feature that collects anonymous usage information.

&lt;details&gt;
&lt;summary&gt;&lt;kbd&gt;More about Telemetry &amp; Privacy for AnythingLLM&lt;/kbd&gt;&lt;/summary&gt;

### Why?

We use this information to help us understand how AnythingLLM is used, to help us prioritize work on new features and bug fixes, and to help us improve AnythingLLM&#039;s performance and stability.

### Opting out

Set `DISABLE_TELEMETRY` in your server or docker .env settings to &quot;true&quot; to opt out of telemetry. You can also do this in-app by going to the sidebar &gt; `Privacy` and disabling telemetry.

### What do you explicitly track?

We will only track usage details that help us make product and roadmap decisions, specifically:

- Type of your installation (Docker or Desktop)

- When a document is added or removed. No information _about_ the document. Just that the event occurred. This gives us an idea of use.

- Type of vector database in use. This helps us prioritize changes when updates arrive for that provider.

- Type of LLM provider &amp; model tag in use. This helps us prioritize changes when updates arrive for that provider or model, or combination thereof. eg: reasoning vs regular, multi-modal models, etc.

- When a chat is sent. This is the most regular &quot;event&quot; and gives us an idea of the daily-activity of this project across all installations. Again, only the **event** is sent - we have no information on the nature or content of the chat itself.

You can verify these claims by finding all locations `Telemetry.sendTelemetry` is called. Additionally these events are written to the output log so you can also see the specific data which was sent - if enabled. **No IP or other identifying information is collected**. The Telemetry provider is [PostHog](https://posthog.com/) - an open-source telemetry collection service.

We take privacy very seriously, and we hope you understand that we want to learn how our tool is used, without using annoying popup surveys, so we can build something worth using. The anonymous data is _never_ shared with third parties, ever.

[View all telemetry events in source code](https://github.com/search?q=repo%3AMintplex-Labs%2Fanything-llm%20.sendTelemetry\(&amp;type=code)

&lt;/details&gt;

## 👋 Contributing

- [Contributing to AnythingLLM](./CONTRIBUTING.md) - How to contribute to AnythingLLM.

## 💖 Sponsors

### Premium Sponsors

&lt;!-- premium-sponsors (reserved for $100/mth sponsors who request to be called out here and/or are non-private sponsors) --&gt;
&lt;a href=&quot;https://www.dcsdigital.co.uk&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://a8cforagenciesportfolio.wordpress.com/wp-content/uploads/2024/08/logo-image-232621379.png&quot; height=&quot;100px&quot; alt=&quot;User avatar: DCS DIGITAL&quot; /&gt;
&lt;/a&gt;
&lt;!-- premium-sponsors --&gt;

### All Sponsors

&lt;!-- all-sponsors --&gt;&lt;a href=&quot;https://github.com/jaschadub&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;jaschadub.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Jascha&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/KickingAss2024&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;KickingAss2024.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: KickAss&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ShadowArcanist&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;ShadowArcanist.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: ShadowArcanist&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/AtlasVIA&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;AtlasVIA.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Atlas&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/cope&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;cope.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Predrag Stojadinović&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/DiegoSpinola&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;DiegoSpinola.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Diego Spinola&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/PortlandKyGuy&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;PortlandKyGuy.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Kyle&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/peperunas&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;peperunas.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Giulio De Pasquale&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/jasoncdavis0&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;jasoncdavis0.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: &quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/macstadium&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;macstadium.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: MacStadium&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/armlynobinguar&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;armlynobinguar.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: &quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/MikeHago&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;MikeHago.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: &quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/maaisde&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;maaisde.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: &quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/mhollier117&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;mhollier117.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: &quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/pleabargain&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;pleabargain.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Dennis&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/broichan&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;broichan.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Michael Hamilton, Ph.D.&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/azim-charaniya&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;azim-charaniya.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: &quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/gabriellemon&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;gabriellemon.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: TernaryLabs&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/CelaDaniel&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;CelaDaniel.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Daniel Cela&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/altrsadmin&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;altrsadmin.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Alesso&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/bitjungle&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;bitjungle.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Rune Mathisen&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/pcrossleyAC&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;pcrossleyAC.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: &quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/saroj-pattnaik&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;saroj-pattnaik.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: &quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/techmedic5&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;techmedic5.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Alan&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ddocta&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;ddocta.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Damien Peters&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/dcsdigital&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;dcsdigital.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: DCS Digital&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/pm7y&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;pm7y.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Paul Mcilreavy&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/tilwolf&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;tilwolf.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Til Wolf&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ozzyoss77&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;ozzyoss77.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Leopoldo Crhistian Riverin Gomez&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/AlphaEcho11&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;AlphaEcho11.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: AJEsau&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/svanomm&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;svanomm.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Steven VanOmmeren&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/socketbox&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;socketbox.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Casey Boettcher&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/zebbern&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;zebbern.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: &quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/avineetbespin&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;avineetbespin.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Avineet&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/invictus-1&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;invictus-1.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Chris&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/mirbyte&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;mirbyte.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: mirko&quot; /&gt;&lt;/a&gt;&lt;!-- all-sponsors --&gt;

## 🌟 Contributors

[![anythingllm contributors](https://contrib.rocks/image?repo=mintplex-labs/anything-llm)](https://github.com/mintplex-labs/anything-llm/graphs/contributors)

[![Star History Chart](https://api.star-his

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[anuraghazra/github-readme-stats]]></title>
            <link>https://github.com/anuraghazra/github-readme-stats</link>
            <guid>https://github.com/anuraghazra/github-readme-stats</guid>
            <pubDate>Mon, 15 Sep 2025 00:04:54 GMT</pubDate>
            <description><![CDATA[⚡ Dynamically generated stats for your github readmes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/anuraghazra/github-readme-stats">anuraghazra/github-readme-stats</a></h1>
            <p>⚡ Dynamically generated stats for your github readmes</p>
            <p>Language: JavaScript</p>
            <p>Stars: 75,894</p>
            <p>Forks: 25,948</p>
            <p>Stars today: 24 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[home-sweet-gnome/dash-to-panel]]></title>
            <link>https://github.com/home-sweet-gnome/dash-to-panel</link>
            <guid>https://github.com/home-sweet-gnome/dash-to-panel</guid>
            <pubDate>Mon, 15 Sep 2025 00:04:53 GMT</pubDate>
            <description><![CDATA[An icon taskbar for the Gnome Shell. This extension moves the dash into the gnome main panel so that the application launchers and system tray are combined into a single panel, similar to that found in KDE Plasma and Windows 7+. A separate dock is no longer needed for easy access to running and favorited applications.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/home-sweet-gnome/dash-to-panel">home-sweet-gnome/dash-to-panel</a></h1>
            <p>An icon taskbar for the Gnome Shell. This extension moves the dash into the gnome main panel so that the application launchers and system tray are combined into a single panel, similar to that found in KDE Plasma and Windows 7+. A separate dock is no longer needed for easy access to running and favorited applications.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 4,120</p>
            <p>Forks: 302</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;left&quot;&gt;
  &lt;img src=&quot;/media/design/svg/D2P_logo.svg&quot; width=&quot;620&quot;/&gt;
&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;
    &lt;img src=&quot;/media/design/svg/GitHub_logo.svg&quot; width=&quot;120&quot;/&gt;&amp;nbsp;
    &lt;a href=&quot;https://extensions.gnome.org/extension/1160/dash-to-panel/&quot; style=&quot;margin-left: 20px&quot;&gt;
        &lt;img src=&quot;/media/design/svg/Gnome_logo.svg&quot; width=&quot;120px&quot;/&gt;
    &lt;/a&gt;&amp;nbsp;
    &lt;a href=&quot;https://www.paypal.com/donate/?hosted_button_id=5DCVELP7BSAVQ&quot;&gt;
        &lt;img src=&quot;https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif&quot; /&gt;
    &lt;/a&gt;
&lt;/p&gt;

![](media/design/png/dtp-main-p2.png)

### Introduction

Dash to Panel is an icon taskbar for Gnome Shell. This extension moves the dash into the gnome main panel so that the application launchers and system tray are combined into a single panel, similar to that found in KDE Plasma and Windows 7+. A separate dock is no longer needed for easy access to running and favorited applications. 

Beyond that, just about every aspect of the panel is fully customizable. From positioning and scaling panel elements to running indicators to multi-monitor display, to window previews and even intellihide, Dash to Panel has everything you need to make your workspace feel like home.

### Features

|Customizable appearance|
|:-----:|
|![screenshot](media/design/gif/customizable.gif)|
|Hide &amp; show panel elements and set their positions, sizes &amp; colors|

##

&lt;table&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th colspan=2&gt;Customizable running indicators&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td align=&quot;center&quot;&gt;Metro&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;Ciliora/Dashes&lt;/td&gt;
        &lt;/tr&gt; 
        &lt;tr&gt;
            &lt;td align=&quot;center&quot;&gt;&lt;img src=&quot;media/design/png/metro.png&quot;/&gt;&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;&lt;img src=&quot;media/design/png/ciliora-dashes.png&quot;/&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&quot;center&quot;&gt;Ciliora&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;Squares/Segmented&lt;/td&gt;
        &lt;/tr&gt; 
        &lt;tr&gt;
            &lt;td align=&quot;center&quot;&gt;&lt;img src=&quot;media/design/png/ciliora.png&quot;/&gt;&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;&lt;img src=&quot;media/design/png/squares-segments.png&quot;/&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&quot;center&quot;&gt;Dashes&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;Dots/Solid&lt;/td&gt;
        &lt;/tr&gt; 
        &lt;tr&gt;
            &lt;td align=&quot;center&quot;&gt;&lt;img src=&quot;media/design/png/dashes.png&quot;/&gt;&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;&lt;img src=&quot;media/design/png/dots-solid.png&quot;/&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan=2 align=&quot;center&quot;&gt;Set position, style, weight &amp; color of running indicators to easily and quickly identify focused and unfocused applications&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

##

|Live Previews on Hover|
|:-----:|
|![screenshot](media/design/gif/previews.gif)|
|Hover over the launcher icon for an open application to get a live window preview|

##
|Launch by Number|
|:-----:|
|![](media/design/png/indicators-num.png.png)|
|Optionally launch your favorite applications via keyboard|

##

|Panel Intellihide|
|:-----:|
|![Intellihide](media/design/gif/Intellihide.gif)|
|Hide and reveal the panel according to your set preferences|

##
|Additional Features|Feature Implemented|
|:-----|:-----:|
|Add &quot;Show Desktop&quot; button to panel|![](media/design/png/done.png)|
|Isolate running apps by workspaces and/or monitors|![](media/design/png/done.png)|
|Custom click behaviors (launch new window, cycle open windows, minimize, etc)|![](media/design/png/done.png)|
|Integrate native Gnome appMenu into right-click secondary menu|![](media/design/png/done.png)|
|Multi-monitor support|![](media/design/png/done.png)|
|Dynamic transparency|![](media/design/png/done.png)|
|Ungroup application windows|![](media/design/png/done.png)|
|Export and import settings|![](media/design/png/done.png)|
##

### Installation

**To install the most recent official release:
[Visit Dash-to-Panel at GNOME Extensions](https://extensions.gnome.org/extension/1160/dash-to-panel/)**

To install a development version from source, please see the [Installation wiki page](https://github.com/home-sweet-gnome/dash-to-panel/wiki/Installation).

## 
### FAQ

How do I customize the panel? [See the Wiki](https://github.com/home-sweet-gnome/dash-to-panel/wiki/Enable-and-Customize#customize-it)

How do I embed my bottom left notification drawer into the panel like a system tray? [Top Icons Plus](https://extensions.gnome.org/extension/2311/topicons-plus) or [(K)StatusNotifierItem/AppIndicator Support](https://extensions.gnome.org/extension/615/appindicator-support)

How do I add a traditional start menu? [Arc Menu](https://extensions.gnome.org/extension/3628/arcmenu/)

How do I disable the hot corner? [No Topleft Hot Corner](https://extensions.gnome.org/extension/118/no-topleft-hot-corner)

How do I move the notifications to somewhere other than the top center? [Notification Banner Reloaded](https://extensions.gnome.org/extension/4651/notification-banner-reloaded/)

How do I display Minimize &amp; Maximize buttons? In the Tweak Tool application, turn on `Windows &gt; Titlebar Buttons &gt; Minimize &amp; Maximize`.

How do I reset the extension to its default settings? `dconf reset -f /org/gnome/shell/extensions/dash-to-panel/`.

## 
### Themes
While this extension works well with most popular Gnome Shell themes, the following themes are known to have explicitly added custom styles for this extension:
- [Ciliora Tertia](https://github.com/zagortenay333/ciliora-tertia-shell) / [Ciliora Secunda](https://github.com/zagortenay333/ciliora-secunda-shell)
- [Plano](https://github.com/lassekongo83/plano-theme)


## 
### Compatibility

This extension has been tested with Gnome 3.18+.

This extension manipulates the Gnome Main Panel, aka Top Bar. So, most other extensions which operate on the top bar should be compatible.

##
### Volunteers needed!

This extension could be even better with your help! Any items in the issue tracker labelled `help wanted` or `good first issue` are up for grabs. For more info, see the [Contributing wiki page](https://github.com/home-sweet-gnome/dash-to-panel/wiki/Contributing).

## 
### Credits

This extension is developed and maintained by [@jderose9](https://github.com/jderose9) and [@charlesg99](https://github.com/charlesg99).

Significant portions of code in this extension were derived from [Dash-to-Dock](https://micheleg.github.io/dash-to-dock/index.html).

Additional credits: This extension leverages the work for [ZorinOS Taskbar](https://github.com/ZorinOS/zorin-taskbar) (used in [ZorinOS](https://zorinos.com/)) to show window previews and allow the dash from [Dash-to-Dock](https://micheleg.github.io/dash-to-dock/index.html) to be embedded in the Gnome main panel.
Code to set anchor position taken from [Thoma5/gnome-shell-extension-bottompanel](https://github.com/Thoma5/gnome-shell-extension-bottompanel).
Pattern for moving panel contents based on [Frippery Move Clock](http://frippery.org/extensions/) by R M Yorston.
Ideas for recursing child actors and assigning inline styles are based on code from the extension [StatusAreaHorizontalSpacing](https://bitbucket.org/mathematicalcoffee/status-area-horizontal-spacing-gnome-shell-extension).
##

#### Thanks to the following people for contributing via pull requests:

- @franglais125 for launching apps by number (w/ overlay), bug fixes, and issue support
- @LinxGem33 and @sbarrett322 for artwork, logos, screenshots and design effort
- @dziku1337 for peek mode in window previews
- @robrobinbin for configuring appMenu on/off in the panel
- @MartinPL for toggling favorites on/off in panel
- @jackwickham for thumbnail middle and right click actions
- @abakkk for centering the taskbar icons in the panel, and animated taskbar hovering
- @quasoft for changing of font weight of ungrouped application titles
- @jordanribera for using icon&#039;s dominant color as running indicator color
- @tper0700 for dynamically building context menu based on system capabilities
- @levacic for configurable minimized application title font color
- @l3nn4rt for toggling workspace switch popup
- @hlechner for adjustable show desktop line color and window preview icon size
- @ArtyomZorin for animated urgent icons
- @jvpessoa10 for additional click window cycle options
- @marksvc for assigning percent of display for panel length
- @philippun1 for GNOME 40 support :rocket:
- @HaselLoyance for toggle for notification counter badge
- @rastersoft for Desktop Icons NG integration
- @max-dw-i for symbolic icons
- @Hirnmoder for Beautify DTP and panel border
- @JimBroad for grayscale icons

#### Bug Fixes: 
@imrvelj, @Teslator, @bil-elmoussaoui, @brandon-schumann, @sw9, @rockon999 , @lexruee, @3v1n0, @freeroot, @moqmar, @ArtyomZorin, @lkc0987, @saibotk, @vanillajonathan, @Zkdc, @leebickmtu, @l3nn4rt, @Melix19, @Aikatsui, @melix99, @kyrillzorin, @oneshadab, @CorvetteCole, @vantu5z, @spectreseven1138, @aperezdc, @smedir, @lucaxvi, @andyholmes, @vowstar, @T99Rots, @City-busz, @guoqiyi, @gcrabbe, @Anduin2017, @xalt7x, @Survolog, @TorosFanny

#### Documentation Improvements:
@BoQsc, @zakkak, @dandv, @elliotwutingfeng

#### Translations: 
@frnogueira / @victorwpbastos / @vagkaefer (pt_BR), @zeten30 / @Amereyeu (cs), @franglais125 / @calotam / @oeramirez / @jhonatanseminario / @oscfdezdz (es), @LaurentTreguier / @SolarLiner / @DelphinPETER (fr), @elsieholmes / @xalt7x (uk), @hosiet / @zhmars (zh\_CN), @jonnius / @linuxr01 / @Etamuk / @daPhipz (de), @urbalazs / @pappfer (hu), @crayxt (kk), @pkomur / @MartinPL / @alex4401 / @konradmb / @alewicki95 / @0rzech (pl), @AlexGluck / @GoodNike / @rjapolov / @vantu5z / @Keleth / @code-ascend (ru), @sicklylife-jp / @ryonakano / @nexryai / @Umoxfo (ja), @oltulu / @TeknoMobil / @daenney / @osmancoskun (tr), @sbadux / @kowalski7cc / @l3nn4rt / @albanobattistella (it), @OriginCode / @pan93412 (zh\_TW), @ojn (sv), @frandieguez (gl), @kuroehanako / @MarongHappy (ko), @jose1711 / @dodog (sk), @eshagh79 (fa)


## 
### License &amp; Terms ![](media/design/png/copyleft-16.png)

Dash to Panel is available under the terms of the GPL-v2 or later license See [`COPYING`](https://github.com/home-sweet-gnome/dash-to-panel/blob/master/COPYING) for details.

![](https://img.shields.io/badge/Language-JavaScript-yellow.svg) ![](https://img.shields.io/badge/Licence-GPL--2.0-blue.svg)
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[pixeltris/TwitchAdSolutions]]></title>
            <link>https://github.com/pixeltris/TwitchAdSolutions</link>
            <guid>https://github.com/pixeltris/TwitchAdSolutions</guid>
            <pubDate>Mon, 15 Sep 2025 00:04:52 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pixeltris/TwitchAdSolutions">pixeltris/TwitchAdSolutions</a></h1>
            <p></p>
            <p>Language: JavaScript</p>
            <p>Stars: 9,936</p>
            <p>Forks: 556</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># TwitchAdSolutions

This repo aims to provide multiple solutions for blocking Twitch ads.

**Don&#039;t combine Twitch specific ad blockers.**

## Recommendations

Proxies are the most reliable way of avoiding ads ([buffering / downtime info](full-list.md#proxy-issues)).

- `TTV LOL PRO` - [chrome](https://chrome.google.com/webstore/detail/ttv-lol-pro/bpaoeijjlplfjbagceilcgbkcdjbomjd) / [firefox](https://addons.mozilla.org/addon/ttv-lol-pro/) / [code](https://github.com/younesaassila/ttv-lol-pro)

Alternatively:

- `Alternate Player for Twitch.tv` - [chrome](https://chrome.google.com/webstore/detail/alternate-player-for-twit/bhplkbgoehhhddaoolmakpocnenplmhf) / [firefox](https://addons.mozilla.org/en-US/firefox/addon/twitch_5/)
- `Purple AdBlock` - [chrome](https://chrome.google.com/webstore/detail/purple-adblock/lkgcfobnmghhbhgekffaadadhmeoindg) / [firefox](https://addons.mozilla.org/en-US/firefox/addon/purpleadblock/) / [code](https://github.com/arthurbolsoni/Purple-adblock/)
- `AdGuard Extra` - [chrome](https://chrome.google.com/webstore/detail/adguard-extra-beta/mglpocjcjbekdckiahfhagndealpkpbj) / [firefox](https://github.com/AdguardTeam/AdGuardExtra/#firefox) / [userscript](https://userscripts.adtidy.org/release/adguard-extra/1.0/adguard-extra.user.js)
- `video-swap-new` - see below

[Read this for a full list and descriptions.](full-list.md)

[Also see this list maintained by @zGato.](https://github.com/zGato/ScrewTwitchAds)

## Scripts

**There are better / easier to use methods in the above recommendations.**

- video-swap-new - [userscript](https://github.com/pixeltris/TwitchAdSolutions/raw/master/video-swap-new/video-swap-new.user.js) / [ublock](https://raw.githubusercontent.com/pixeltris/TwitchAdSolutions/master/video-swap-new/video-swap-new-ublock-origin.js) / [ublock (permalink)](https://raw.githubusercontent.com/pixeltris/TwitchAdSolutions/6eefa4d2fa02a51a34b61a5dea45f6b42d637060/video-swap-new/video-swap-new-ublock-origin.js)
  - Uses a lower resolution stream during ads.
- vaft - [userscript](https://github.com/pixeltris/TwitchAdSolutions/raw/master/vaft/vaft.user.js) / [ublock](https://raw.githubusercontent.com/pixeltris/TwitchAdSolutions/master/vaft/vaft-ublock-origin.js) / [ublock (permalink)](https://raw.githubusercontent.com/pixeltris/TwitchAdSolutions/6eefa4d2fa02a51a34b61a5dea45f6b42d637060/vaft/vaft-ublock-origin.js)
  - The same as `video-swap-new` but attempts to get a clean stream faster (may suffer from more freezing / playback issues).

## Applying a script (uBlock Origin)

- Navigate to the uBlock Origin Dashboard (the extension options)
- Under the `My filters` tab add `twitch.tv##+js(twitch-videoad)`.
- Under the `Settings` tab, enable `I am an advanced user`, then click the cog that appears. Modify the value of `userResourcesLocation` from `unset` to the full url of the solution you wish to use (if a url is already in use, add a space after the existing url). e.g. `userResourcesLocation https://raw.githubusercontent.com/pixeltris/TwitchAdSolutions/master/video-swap-new/video-swap-new-ublock-origin.js` 
- To ensure uBlock Origin loads the script I recommend that you disable/enable the uBlock Origin extension (or restart your browser).

To stop using a script remove the filter and make the url `unset`.

*For the sake of security it&#039;s recommended to use a permalink when using uBlock Origin (permalinks do not auto update).*

*The scripts __may randomly stop being applied by uBlock Origin__ for unknown reasons ([#200](https://github.com/pixeltris/TwitchAdSolutions/issues/200)). It&#039;s recommended to use the userscript versions instead.*

**Brave currently doesn&#039;t work with the uBlock Origin scripts, use the userscript instead.**

## Applying a script (userscript)

- Viewing one of the userscript files should prompt the given script to be added (assuming you have a userscript manager).
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[danielmiessler/Fabric]]></title>
            <link>https://github.com/danielmiessler/Fabric</link>
            <guid>https://github.com/danielmiessler/Fabric</guid>
            <pubDate>Mon, 15 Sep 2025 00:04:51 GMT</pubDate>
            <description><![CDATA[Fabric is an open-source framework for augmenting humans using AI. It provides a modular system for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/danielmiessler/Fabric">danielmiessler/Fabric</a></h1>
            <p>Fabric is an open-source framework for augmenting humans using AI. It provides a modular system for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 33,454</p>
            <p>Forks: 3,420</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://go.warp.dev/fabric&quot; target=&quot;_blank&quot;&gt;
        &lt;sup&gt;Special thanks to:&lt;/sup&gt;
        &lt;br&gt;
        &lt;img alt=&quot;Warp sponsorship&quot; width=&quot;400&quot; src=&quot;https://raw.githubusercontent.com/warpdotdev/brand-assets/refs/heads/main/Github/Sponsor/Warp-Github-LG-02.png&quot;&gt;
        &lt;br&gt;
        &lt;h&gt;Warp, built for coding with multiple AI agents&lt;/b&gt;
        &lt;br&gt;
        &lt;sup&gt;Available for macOS, Linux and Windows&lt;/sup&gt;
    &lt;/a&gt;
&lt;/div&gt;

&lt;br&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;img src=&quot;./docs/images/fabric-logo-gif.gif&quot; alt=&quot;fabriclogo&quot; width=&quot;400&quot; height=&quot;400&quot;/&gt;

# `fabric`

![Static Badge](https://img.shields.io/badge/mission-human_flourishing_via_AI_augmentation-purple)
&lt;br /&gt;
![GitHub top language](https://img.shields.io/github/languages/top/danielmiessler/fabric)
![GitHub last commit](https://img.shields.io/github/last-commit/danielmiessler/fabric)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/danielmiessler/fabric)

&lt;div align=&quot;center&quot;&gt;
&lt;h4&gt;&lt;code&gt;fabric&lt;/code&gt; is an open-source framework for augmenting humans using AI.&lt;/h4&gt;
&lt;/div&gt;

![Screenshot of fabric](./docs/images/fabric-summarize.png)

&lt;/div&gt;

[Updates](#updates) •
[What and Why](#what-and-why) •
[Philosophy](#philosophy) •
[Installation](#installation) •
[Usage](#usage) •
[Examples](#examples) •
[Just Use the Patterns](#just-use-the-patterns) •
[Custom Patterns](#custom-patterns) •
[Helper Apps](#helper-apps) •
[Meta](#meta)

![Screenshot of fabric](./docs/images/fabric-summarize.png)

&lt;/div&gt;

## What and why

Since the start of modern AI in late 2022 we&#039;ve seen an **_extraordinary_** number of AI applications for accomplishing tasks. There are thousands of websites, chat-bots, mobile apps, and other interfaces for using all the different AI out there.

It&#039;s all really exciting and powerful, but _it&#039;s not easy to integrate this functionality into our lives._

&lt;div class=&quot;align center&quot;&gt;
&lt;h4&gt;In other words, AI doesn&#039;t have a capabilities problem—it has an &lt;em&gt;integration&lt;/em&gt; problem.&lt;/h4&gt;
&lt;/div&gt;

**Fabric was created to address this by creating and organizing the fundamental units of AI—the prompts themselves!**

Fabric organizes prompts by real-world task, allowing people to create, collect, and organize their most important AI solutions in a single place for use in their favorite tools. And if you&#039;re command-line focused, you can use Fabric itself as the interface!

## Updates

Dear Users,

We&#039;ve been doing so many exciting things here at Fabric, I wanted to give a quick summary here to give you a sense of our development velocity!

Below are the **new features and capabilities** we&#039;ve added (newest first):

### Recent Major Features

- [v1.4.311](https://github.com/danielmiessler/fabric/releases/tag/v1.4.311) (Sep 13, 2025) — **More internationalization support**: Adds de (German), fa (Persian / Farsi), fr (French), it (Italian),
  ja (Japanese), pt (Portuguese), zh (Chinese)
- [v1.4.309](https://github.com/danielmiessler/fabric/releases/tag/v1.4.309) (Sep 9, 2025) — **Comprehensive internationalization support**: Includes English and Spanish locale files.
- [v1.4.303](https://github.com/danielmiessler/fabric/releases/tag/v1.4.303) (Aug 29, 2025) — **New Binary Releases**: Linux ARM and Windows ARM targets. You can run Fabric on the Raspberry PI and on your Windows Surface!
- [v1.4.294](https://github.com/danielmiessler/fabric/releases/tag/v1.4.294) (Aug 20, 2025) — **Venice AI Support**: Added the Venice AI provider. Venice is a Privacy-First, Open-Source AI provider. See their [&quot;About Venice&quot;](https://docs.venice.ai/overview/about-venice) page for details.
- [v1.4.291](https://github.com/danielmiessler/fabric/releases/tag/v1.4.291) (Aug 18, 2025) — **Speech To Text**: Add OpenAI speech-to-text support with `--transcribe-file`, `--transcribe-model`, and `--split-media-file` flags.
- [v1.4.287](https://github.com/danielmiessler/fabric/releases/tag/v1.4.287) (Aug 16, 2025) — **AI Reasoning**: Add Thinking to Gemini models and introduce `readme_updates` python script
- [v1.4.286](https://github.com/danielmiessler/fabric/releases/tag/v1.4.286) (Aug 14, 2025) — **AI Reasoning**: Introduce Thinking Config Across Anthropic and OpenAI Providers
- [v1.4.285](https://github.com/danielmiessler/fabric/releases/tag/v1.4.285) (Aug 13, 2025) — **Extended Context**: Enable One Million Token Context Beta Feature for Sonnet-4
- [v1.4.284](https://github.com/danielmiessler/fabric/releases/tag/v1.4.284) (Aug 12, 2025) — **Easy Shell Completions Setup**: Introduce One-Liner Curl Install for Completions
- [v1.4.283](https://github.com/danielmiessler/fabric/releases/tag/v1.4.283) (Aug 12, 2025) — **Model Management**: Add Vendor Selection Support for Models
- [v1.4.282](https://github.com/danielmiessler/fabric/releases/tag/v1.4.282) (Aug 11, 2025) — **Enhanced Shell Completions**: Enhanced Shell Completions for Fabric CLI Binaries
- [v1.4.281](https://github.com/danielmiessler/fabric/releases/tag/v1.4.281) (Aug 11, 2025) — **Gemini Search Tool**: Add Web Search Tool Support for Gemini Models
- [v1.4.278](https://github.com/danielmiessler/fabric/releases/tag/v1.4.278) (Aug 9, 2025) — **Enhance YouTube Transcripts**: Enhance YouTube Support with Custom yt-dlp Arguments
- [v1.4.277](https://github.com/danielmiessler/fabric/releases/tag/v1.4.277) (Aug 8, 2025) — **Desktop Notifications**: Add cross-platform desktop notifications to Fabric CLI
- [v1.4.274](https://github.com/danielmiessler/fabric/releases/tag/v1.4.274) (Aug 7, 2025) — **Claude 4.1 Added**: Add Support for Claude Opus 4.1 Model
- [v1.4.271](https://github.com/danielmiessler/fabric/releases/tag/v1.4.271) (Jul 28, 2025) — **AI Summarized Release Notes**: Enable AI summary updates for GitHub releases
- [v1.4.268](https://github.com/danielmiessler/fabric/releases/tag/v1.4.268) (Jul 26, 2025) — **Gemini TTS Voice Selection**: add Gemini TTS voice selection and listing functionality
- [v1.4.267](https://github.com/danielmiessler/fabric/releases/tag/v1.4.267) (Jul 26, 2025) — **Text-to-Speech**: Update Gemini Plugin to New SDK with TTS Support
- [v1.4.258](https://github.com/danielmiessler/fabric/releases/tag/v1.4.258) (Jul 17, 2025) — **Onboarding Improved**: Add startup check to initialize config and .env file automatically
- [v1.4.257](https://github.com/danielmiessler/fabric/releases/tag/v1.4.257) (Jul 17, 2025) — **OpenAI Routing Control**: Introduce CLI Flag to Disable OpenAI Responses API
- [v1.4.252](https://github.com/danielmiessler/fabric/releases/tag/v1.4.252) (Jul 16, 2025) — **Hide Thinking Block**: Optional Hiding of Model Thinking Process with Configurable Tags
- [v1.4.246](https://github.com/danielmiessler/fabric/releases/tag/v1.4.246) (Jul 14, 2025) — **Automatic ChangeLog Updates**: Add AI-powered changelog generation with high-performance Go tool and comprehensive caching
- [v1.4.245](https://github.com/danielmiessler/fabric/releases/tag/v1.4.245) (Jul 11, 2025) — **Together AI**: Together AI Support with OpenAI Fallback Mechanism Added
- [v1.4.232](https://github.com/danielmiessler/fabric/releases/tag/v1.4.232) (Jul 6, 2025) — **Add Custom**: Add Custom Patterns Directory Support
- [v1.4.231](https://github.com/danielmiessler/fabric/releases/tag/v1.4.231) (Jul 5, 2025) — **OAuth Auto-Auth**: OAuth Authentication Support for Anthropic (Use your Max Subscription)
- [v1.4.230](https://github.com/danielmiessler/fabric/releases/tag/v1.4.230) (Jul 5, 2025) — **Model Management**: Add advanced image generation parameters for OpenAI models with four new CLI flags
- [v1.4.227](https://github.com/danielmiessler/fabric/releases/tag/v1.4.227) (Jul 4, 2025) — **Add Image**: Add Image Generation Support to Fabric
- [v1.4.226](https://github.com/danielmiessler/fabric/releases/tag/v1.4.226) (Jul 4, 2025) — **Web Search**: OpenAI Plugin Now Supports Web Search Functionality
- [v1.4.225](https://github.com/danielmiessler/fabric/releases/tag/v1.4.225) (Jul 4, 2025) — **Web Search**: Runtime Web Search Control via Command-Line `--search` Flag
- [v1.4.224](https://github.com/danielmiessler/fabric/releases/tag/v1.4.224) (Jul 1, 2025) — **Add code_review**: Add code_review pattern and updates in Pattern_Descriptions
- [v1.4.222](https://github.com/danielmiessler/fabric/releases/tag/v1.4.222) (Jul 1, 2025) — **OpenAI Plugin**: OpenAI Plugin Migrates to New Responses API
- [v1.4.218](https://github.com/danielmiessler/fabric/releases/tag/v1.4.218) (Jun 27, 2025) — **Model Management**: Add Support for OpenAI Search and Research Model Variants
- [v1.4.217](https://github.com/danielmiessler/fabric/releases/tag/v1.4.217) (Jun 26, 2025) — **New YouTube**: New YouTube Transcript Endpoint Added to REST API
- [v1.4.212](https://github.com/danielmiessler/fabric/releases/tag/v1.4.212) (Jun 23, 2025) — **Add Langdock**: Add Langdock AI and enhance generic OpenAI compatible support
- [v1.4.211](https://github.com/danielmiessler/fabric/releases/tag/v1.4.211) (Jun 19, 2025) — **REST API**: REST API and Web UI Now Support Dynamic Pattern Variables
- [v1.4.210](https://github.com/danielmiessler/fabric/releases/tag/v1.4.210) (Jun 18, 2025) — **Add Citations**: Add Citation Support to Perplexity Response
- [v1.4.208](https://github.com/danielmiessler/fabric/releases/tag/v1.4.208) (Jun 17, 2025) — **Add Perplexity**: Add Perplexity AI Provider with Token Limits Support
- [v1.4.203](https://github.com/danielmiessler/fabric/releases/tag/v1.4.203) (Jun 14, 2025) — **Add Amazon Bedrock**: Add support for Amazon Bedrock

These features represent our commitment to making Fabric the most powerful and flexible AI augmentation framework available!

## Intro videos

Keep in mind that many of these were recorded when Fabric was Python-based, so remember to use the current [install instructions](#installation) below.

- [Network Chuck](https://www.youtube.com/watch?v=UbDyjIIGaxQ)
- [David Bombal](https://www.youtube.com/watch?v=vF-MQmVxnCs)
- [My Own Intro to the Tool](https://www.youtube.com/watch?v=wPEyyigh10g)
- [More Fabric YouTube Videos](https://www.youtube.com/results?search_query=fabric+ai)

## Navigation

- [`fabric`](#fabric)
  - [What and why](#what-and-why)
  - [Updates](#updates)
    - [Recent Major Features](#recent-major-features)
  - [Intro videos](#intro-videos)
  - [Navigation](#navigation)
  - [Changelog](#changelog)
  - [Philosophy](#philosophy)
    - [Breaking problems into components](#breaking-problems-into-components)
    - [Too many prompts](#too-many-prompts)
  - [Installation](#installation)
    - [One-Line Install (Recommended)](#one-line-install-recommended)
    - [Manual Binary Downloads](#manual-binary-downloads)
    - [Using package managers](#using-package-managers)
      - [macOS (Homebrew)](#macos-homebrew)
      - [Arch Linux (AUR)](#arch-linux-aur)
      - [Windows](#windows)
    - [From Source](#from-source)
    - [Docker](#docker)
    - [Environment Variables](#environment-variables)
    - [Setup](#setup)
    - [Per-Pattern Model Mapping](#per-pattern-model-mapping)
    - [Add aliases for all patterns](#add-aliases-for-all-patterns)
      - [Save your files in markdown using aliases](#save-your-files-in-markdown-using-aliases)
    - [Migration](#migration)
    - [Upgrading](#upgrading)
    - [Shell Completions](#shell-completions)
      - [Quick install (no clone required)](#quick-install-no-clone-required)
      - [Zsh Completion](#zsh-completion)
      - [Bash Completion](#bash-completion)
      - [Fish Completion](#fish-completion)
  - [Usage](#usage)
    - [Debug Levels](#debug-levels)
  - [Our approach to prompting](#our-approach-to-prompting)
  - [Examples](#examples)
  - [Just use the Patterns](#just-use-the-patterns)
    - [Prompt Strategies](#prompt-strategies)
  - [Custom Patterns](#custom-patterns)
    - [Setting Up Custom Patterns](#setting-up-custom-patterns)
    - [Using Custom Patterns](#using-custom-patterns)
    - [How It Works](#how-it-works)
  - [Helper Apps](#helper-apps)
    - [`to_pdf`](#to_pdf)
    - [`to_pdf` Installation](#to_pdf-installation)
    - [`code_helper`](#code_helper)
  - [pbpaste](#pbpaste)
  - [Web Interface](#web-interface)
    - [Installing](#installing)
    - [Streamlit UI](#streamlit-ui)
      - [Clipboard Support](#clipboard-support)
  - [Meta](#meta)
    - [Primary contributors](#primary-contributors)
    - [Contributors](#contributors)

&lt;br /&gt;

## Changelog

Fabric is evolving rapidly.

Stay current with the latest features by reviewing the [CHANGELOG](./CHANGELOG.md) for all recent changes.

## Philosophy

&gt; AI isn&#039;t a thing; it&#039;s a _magnifier_ of a thing. And that thing is **human creativity**.

We believe the purpose of technology is to help humans flourish, so when we talk about AI we start with the **human** problems we want to solve.

### Breaking problems into components

Our approach is to break problems into individual pieces (see below) and then apply AI to them one at a time. See below for some examples.

&lt;img width=&quot;2078&quot; alt=&quot;augmented_challenges&quot; src=&quot;https://github.com/danielmiessler/fabric/assets/50654/31997394-85a9-40c2-879b-b347e4701f06&quot;&gt;

### Too many prompts

Prompts are good for this, but the biggest challenge I faced in 2023——which still exists today—is **the sheer number of AI prompts out there**. We all have prompts that are useful, but it&#039;s hard to discover new ones, know if they are good or not, _and manage different versions of the ones we like_.

One of `fabric`&#039;s primary features is helping people collect and integrate prompts, which we call _Patterns_, into various parts of their lives.

Fabric has Patterns for all sorts of life and work activities, including:

- Extracting the most interesting parts of YouTube videos and podcasts
- Writing an essay in your own voice with just an idea as an input
- Summarizing opaque academic papers
- Creating perfectly matched AI art prompts for a piece of writing
- Rating the quality of content to see if you want to read/watch the whole thing
- Getting summaries of long, boring content
- Explaining code to you
- Turning bad documentation into usable documentation
- Creating social media posts from any content input
- And a million more…

## Installation

### One-Line Install (Recommended)

**Unix/Linux/macOS:**

```bash
curl -fsSL https://raw.githubusercontent.com/danielmiessler/fabric/main/scripts/installer/install.sh | bash
```

**Windows PowerShell:**

```powershell
iwr -useb https://raw.githubusercontent.com/danielmiessler/fabric/main/scripts/installer/install.ps1 | iex
```

&gt; See [scripts/installer/README.md](./scripts/installer/README.md) for custom installation options and troubleshooting.

### Manual Binary Downloads

The latest release binary archives and their expected SHA256 hashes can be found at &lt;https://github.com/danielmiessler/fabric/releases/latest&gt;

### Using package managers

**NOTE:** using Homebrew or the Arch Linux package managers makes `fabric` available as `fabric-ai`, so add
the following alias to your shell startup files to account for this:

```bash
alias fabric=&#039;fabric-ai&#039;
```

#### macOS (Homebrew)

`brew install fabric-ai`

#### Arch Linux (AUR)

`yay -S fabric-ai`

#### Windows

Use the official Microsoft supported `Winget` tool:

`winget install danielmiessler.Fabric`

### From Source

To install Fabric, [make sure Go is installed](https://go.dev/doc/install), and then run the following command.

```bash
# Install Fabric directly from the repo
go install github.com/danielmiessler/fabric/cmd/fabric@latest
```

### Docker

Run Fabric using pre-built Docker images:

```bash
# Use latest image from Docker Hub
docker run --rm -it kayvan/fabric:latest --version

# Use specific version from GHCR
docker run --rm -it ghcr.io/ksylvan/fabric:v1.4.305 --version

# Run setup (first time)
mkdir -p $HOME/.fabric-config
docker run --rm -it -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest --setup

# Use Fabric with your patterns
docker run --rm -it -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest -p summarize

# Run the REST API server
docker run --rm -it -p 8080:8080 -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest --serve
```

**Images available at:**

- Docker Hub: [kayvan/fabric](https://hub.docker.com/repository/docker/kayvan/fabric/general)
- GHCR: [ksylvan/fabric](https://github.com/ksylvan/fabric/pkgs/container/fabric)

See [scripts/docker/README.md](./scripts/docker/README.md) for building custom images and advanced configuration.

### Environment Variables

You may need to set some environment variables in your `~/.bashrc` on linux or `~/.zshrc` file on mac to be able to run the `fabric` command. Here is an example of what you can add:

For Intel based macs or linux

```bash
# Golang environment variables
export GOROOT=/usr/local/go
export GOPATH=$HOME/go

# Update PATH to include GOPATH and GOROOT binaries
export PATH=$GOPATH/bin:$GOROOT/bin:$HOME/.local/bin:$PATH
```

for Apple Silicon based macs

```bash
# Golang environment variables
export GOROOT=$(brew --prefix go)/libexec
export GOPATH=$HOME/go
export PATH=$GOPATH/bin:$GOROOT/bin:$HOME/.local/bin:$PATH
```

### Setup

Now run the following command

```bash
# Run the setup to set up your directories and keys
fabric --setup
```

If everything works you are good to go.

### Per-Pattern Model Mapping

 You can configure specific models for individual patterns using environment variables
 like `FABRIC_MODEL_PATTERN_NAME=vendor|model`

 This makes it easy to maintain these per-pattern model mappings in your shell startup files.

### Add aliases for all patterns

In order to add aliases for all your patterns and use them directly as commands, for example, `summarize` instead of `fabric --pattern summarize`
You can add the following to your `.zshrc` or `.bashrc` file. You
can also optionally set the `FABRIC_ALIAS_PREFIX` environment variable
before, if you&#039;d prefer all the fabric aliases to start with the same prefix.

```bash
# Loop through all files in the ~/.config/fabric/patterns directory
for pattern_file in $HOME/.config/fabric/patterns/*; do
    # Get the base name of the file (i.e., remove the directory path)
    pattern_name=&quot;$(basename &quot;$pattern_file&quot;)&quot;
    alias_name=&quot;${FABRIC_ALIAS_PREFIX:-}${pattern_name}&quot;

    # Create an alias in the form: alias pattern_name=&quot;fabric --pattern pattern_name&quot;
    alias_command=&quot;alias $alias_name=&#039;fabric --pattern $pattern_name&#039;&quot;

    # Evaluate the alias command to add it to the current shell
    eval &quot;$alias_command&quot;
done

yt() {
    if [ &quot;$#&quot; -eq 0 ] || [ &quot;$#&quot; -gt 2 ]; then
        echo &quot;Usage: yt [-t | --timestamps] youtube-link&quot;
        echo &quot;Use the &#039;-t&#039; flag to get the transcript with timestamps.&quot;
        return 1
    fi

    transcript_flag=&quot;--transcript&quot;
    if [ &quot;$1&quot; = &quot;-t&quot; ] || [ &quot;$1&quot; = &quot;--timestamps&quot; ]; then
        transcript_flag=&quot;--transcript-with-timestamps&quot;
        shift
    fi
    local video_link=&quot;$1&quot;
    fabric -y &quot;$video_link&quot; $transcript_flag
}
```

You can add the below code for the equivalent aliases inside PowerShell by running `notepad $PROFILE` inside a PowerShell window:

```powershell
# Path to the patterns directory
$patternsPath = Join-Path $HOME &quot;.config/fabric/patterns&quot;
foreach ($patternDir in Get-ChildItem -Path $patternsPath -Directory) {
    # Prepend FABRIC_ALIAS_PREFIX if set; otherwise use empty string
    $prefix = $env:FABRIC_ALIAS_PREFIX ?? &#039;&#039;
    $patternName = &quot;$($patternDir.Name)&quot;
    $aliasName = &quot;$prefix$patternName&quot;
    # Dynamically define a function for each pattern
    $functionDefinition = @&quot;
function $aliasName {
    [CmdletBinding()]
    param(
        [Parameter(ValueFromPipeline = `$true)]
        [string] `$InputObject,

        [Parameter(ValueFromRemainingArguments = `$true)]
        [String[]] `$patternArgs
    )

    begin {
        # Initialize an array to collect pipeline input
        `$collector = @()
    }

    process {
        # Coll

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[academind/react-complete-guide-course-resources]]></title>
            <link>https://github.com/academind/react-complete-guide-course-resources</link>
            <guid>https://github.com/academind/react-complete-guide-course-resources</guid>
            <pubDate>Mon, 15 Sep 2025 00:04:50 GMT</pubDate>
            <description><![CDATA[React - The Complete Guide Course Resources (Code, Attachments, Slides)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/academind/react-complete-guide-course-resources">academind/react-complete-guide-course-resources</a></h1>
            <p>React - The Complete Guide Course Resources (Code, Attachments, Slides)</p>
            <p>Language: JavaScript</p>
            <p>Stars: 3,431</p>
            <p>Forks: 2,671</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># React - The Complete Guide Course Resources

This repository provides access to code files, code snapshots, slides &amp; other resources that are used or provided by the [React - The Complete Guide](https://acad.link/reactjs) course.

If you&#039;re facing any issues with the code, please post in the course Q&amp;A section.

# Repository Content

- **Code Snapshots:** All code snapshots (starting snapshots, intermediate snapshots, finished snapshots) for the various course sections can be found in the [/code](/code/) folder.
- **Lecture Attachments:** Any standalone code files or other attachments that are mentioned in course lectures (and attached to those lectures) are stored in the [/attachments](/attachments/) folder.
- **Other Resources:** Other resources (like the course slides) can be found in the [/other](/other/) folder.

The **Code Snapshots** and **Lecture Attachments** folders contain one subfolder per course section - this allows you to easily access the resources for a specific course section.

# How To Use Code Snapshots

Code snapshots are primarily provided to allow you to compare your code to mine. The snapshots are taken directly from the course recordings and therefore reflect my code you see in the videos.

Of course, you can also try running those code snapshots on your machine. You&#039;ll need to run `npm install` in the individual snapshot folders, followed by `npm run dev` to start the development server - just as shown in the course.
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[mindcraft-bots/mindcraft]]></title>
            <link>https://github.com/mindcraft-bots/mindcraft</link>
            <guid>https://github.com/mindcraft-bots/mindcraft</guid>
            <pubDate>Mon, 15 Sep 2025 00:04:49 GMT</pubDate>
            <description><![CDATA[Minecraft AI with LLMs+Mineflayer]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mindcraft-bots/mindcraft">mindcraft-bots/mindcraft</a></h1>
            <p>Minecraft AI with LLMs+Mineflayer</p>
            <p>Language: JavaScript</p>
            <p>Stars: 3,804</p>
            <p>Forks: 541</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># Mindcraft 🧠⛏️

Crafting minds for Minecraft with LLMs and [Mineflayer!](https://prismarinejs.github.io/mineflayer/#/)

[FAQ](https://github.com/kolbytn/mindcraft/blob/main/FAQ.md) | [Discord Support](https://discord.gg/mp73p35dzC) | [Video Tutorial](https://www.youtube.com/watch?v=gRotoL8P8D8) | [Blog Post](https://kolbynottingham.com/mindcraft/) | [Contributor TODO](https://github.com/users/kolbytn/projects/1) | [Paper Website](https://mindcraft-minecollab.github.io/index.html) | [MineCollab](https://github.com/kolbytn/mindcraft/blob/main/minecollab.md) 


&gt; [!Caution]
Do not connect this bot to public servers with coding enabled. This project allows an LLM to write/execute code on your computer. The code is sandboxed, but still vulnerable to injection attacks. Code writing is disabled by default, you can enable it by setting `allow_insecure_coding` to `true` in `settings.js`. Ye be warned.

## Requirements

- [Minecraft Java Edition](https://www.minecraft.net/en-us/store/minecraft-java-bedrock-edition-pc) (up to v1.21.6, recommend v1.21.1)
- [Node.js Installed](https://nodejs.org/) (at least v18)
- One of these: [OpenAI API Key](https://openai.com/blog/openai-api) | [Gemini API Key](https://aistudio.google.com/app/apikey) | [Anthropic API Key](https://docs.anthropic.com/claude/docs/getting-access-to-claude) | [Replicate API Key](https://replicate.com/) | [Hugging Face API Key](https://huggingface.co/) | [Groq API Key](https://console.groq.com/keys) | [Ollama Installed](https://ollama.com/download). | [Mistral API Key](https://docs.mistral.ai/getting-started/models/models_overview/) | [Qwen API Key [Intl.]](https://www.alibabacloud.com/help/en/model-studio/developer-reference/get-api-key)/[[cn]](https://help.aliyun.com/zh/model-studio/getting-started/first-api-call-to-qwen?) | [Novita AI API Key](https://novita.ai/settings?utm_source=github_mindcraft&amp;utm_medium=github_readme&amp;utm_campaign=link#key-management) | [Cerebras API Key](https://cloud.cerebras.ai) | [Mercury API](https://platform.inceptionlabs.ai/docs)

## Install and Run

1. Make sure you have the requirements above.

2. Clone or download this repository (big green button) &#039;git clone https://github.com/kolbytn/mindcraft.git&#039;

3. Rename `keys.example.json` to `keys.json` and fill in your API keys (you only need one). The desired model is set in `andy.json` or other profiles. For other models refer to the table below.

4. In terminal/command prompt, run `npm install` from the installed directory

5. Start a minecraft world and open it to LAN on localhost port `55916`

6. Run `node main.js` from the installed directory

If you encounter issues, check the [FAQ](https://github.com/kolbytn/mindcraft/blob/main/FAQ.md) or find support on [discord](https://discord.gg/mp73p35dzC). We are currently not very responsive to github issues. To run tasks please refer to [Minecollab Instructions](minecollab.md#installation)

## Tasks

Bot performance can be roughly evaluated with Tasks. Tasks automatically intialize bots with a goal to aquire specific items or construct predefined buildings, and remove the bot once the goal is achieved.

To run tasks, you need python, pip, and optionally conda. You can then install dependencies with `pip install -r requirements.txt`. 

Tasks are defined in json files in the `tasks` folder, and can be run with: `python tasks/run_task_file.py --task_path=tasks/example_tasks.json`

For full evaluations, you will need to [download and install the task suite. Full instructions.](minecollab.md#installation)

## Model Customization

You can configure project details in `settings.js`. [See file.](settings.js)

You can configure the agent&#039;s name, model, and prompts in their profile like `andy.json` with the `model` field. For comprehensive details, see [Model Specifications](#model-specifications).

| API | Config Variable | Example Model name | Docs |
|------|------|------|------|
| `openai` | `OPENAI_API_KEY` | `gpt-4o-mini` | [docs](https://platform.openai.com/docs/models) |
| `google` | `GEMINI_API_KEY` | `gemini-2.0-flash` | [docs](https://ai.google.dev/gemini-api/docs/models/gemini) |
| `anthropic` | `ANTHROPIC_API_KEY` | `claude-3-haiku-20240307` | [docs](https://docs.anthropic.com/claude/docs/models-overview) |
| `xai` | `XAI_API_KEY` | `grok-2-1212` | [docs](https://docs.x.ai/docs) |
| `deepseek` | `DEEPSEEK_API_KEY` | `deepseek-chat` | [docs](https://api-docs.deepseek.com/) |
| `ollama` (local) | n/a | `ollama/sweaterdog/andy-4:micro-q8_0` | [docs](https://ollama.com/library) |
| `qwen` | `QWEN_API_KEY` | `qwen-max` | [Intl.](https://www.alibabacloud.com/help/en/model-studio/developer-reference/use-qwen-by-calling-api)/[cn](https://help.aliyun.com/zh/model-studio/getting-started/models) |
| `mistral` | `MISTRAL_API_KEY` | `mistral-large-latest` | [docs](https://docs.mistral.ai/getting-started/models/models_overview/) |
| `replicate` | `REPLICATE_API_KEY` | `replicate/meta/meta-llama-3-70b-instruct` | [docs](https://replicate.com/collections/language-models) |
| `groq` (not grok) | `GROQCLOUD_API_KEY` | `groq/mixtral-8x7b-32768` | [docs](https://console.groq.com/docs/models) |
| `huggingface` | `HUGGINGFACE_API_KEY` | `huggingface/mistralai/Mistral-Nemo-Instruct-2407` | [docs](https://huggingface.co/models) |
| `novita` | `NOVITA_API_KEY` | `novita/deepseek/deepseek-r1` | [docs](https://novita.ai/model-api/product/llm-api?utm_source=github_mindcraft&amp;utm_medium=github_readme&amp;utm_campaign=link) |
| `openrouter` | `OPENROUTER_API_KEY` | `openrouter/anthropic/claude-3.5-sonnet` | [docs](https://openrouter.ai/models) |
| `glhf.chat` | `GHLF_API_KEY` | `glhf/hf:meta-llama/Llama-3.1-405B-Instruct` | [docs](https://glhf.chat/user-settings/api) |
| `hyperbolic` | `HYPERBOLIC_API_KEY` | `hyperbolic/deepseek-ai/DeepSeek-V3` | [docs](https://docs.hyperbolic.xyz/docs/getting-started) |
| `vllm` | n/a | `vllm/llama3` | n/a |
| `cerebras` | `CEREBRAS_API_KEY` | `cerebras/llama-3.3-70b` | [docs](https://inference-docs.cerebras.ai/introduction) |
| `mercury` | `MERCURY_API_KEY` | `mercury-coder-small` | [docs](https://www.inceptionlabs.ai/) |

If you use Ollama, to install the models used by default (generation and embedding), execute the following terminal command:
`ollama pull sweaterdog/andy-4:micro-q8_0 &amp;&amp; ollama pull embeddinggemma`

To use Azure, you can reuse the `OPENAI_API_KEY` environment variable. You can get the key from the Azure portal. See [azure.json](profiles/azure.json) for an example.

### Online Servers
To connect to online servers your bot will need an official Microsoft/Minecraft account. You can use your own personal one, but will need another account if you want to connect too and play with it. To connect, change these lines in `settings.js`:
```javascript
&quot;host&quot;: &quot;111.222.333.444&quot;,
&quot;port&quot;: 55920,
&quot;auth&quot;: &quot;microsoft&quot;,

// rest is same...
```
&gt; [!Important]
&gt; The bot&#039;s name in the profile.json must exactly match the Minecraft profile name! Otherwise the bot will spam talk to itself.

To use different accounts, Mindcraft will connect with the account that the Minecraft launcher is currently using. You can switch accounts in the launcer, then run `node main.js`, then switch to your main account after the bot has connected.

### Docker Container

If you intend to `allow_insecure_coding`, it is a good idea to run the app in a docker container to reduce risks of running unknown code. This is strongly recommended before connecting to remote servers.

```bash
docker run -i -t --rm -v $(pwd):/app -w /app -p 3000-3003:3000-3003 node:latest node main.js
```
or simply
```bash
docker-compose up
```

When running in docker, if you want the bot to join your local minecraft server, you have to use a special host address `host.docker.internal` to call your localhost from inside your docker container. Put this into your [settings.js](settings.js):

```javascript
&quot;host&quot;: &quot;host.docker.internal&quot;, // instead of &quot;localhost&quot;, to join your local minecraft from inside the docker container
```

To connect to an unsupported minecraft version, you can try to use [viaproxy](services/viaproxy/README.md)

# Bot Profiles

Bot profiles are json files (such as `andy.json`) that define:

1. Bot backend LLMs to use for talking, coding, and embedding.
2. Prompts used to influence the bot&#039;s behavior.
3. Examples help the bot perform tasks.

## Model Specifications

LLM models can be specified simply as `&quot;model&quot;: &quot;gpt-4o&quot;`. However, you can use different models for chat, coding, and embeddings. 
You can pass a string or an object for these fields. A model object must specify an `api`, and optionally a `model`, `url`, and additional `params`.

```json
&quot;model&quot;: {
  &quot;api&quot;: &quot;openai&quot;,
  &quot;model&quot;: &quot;gpt-4o&quot;,
  &quot;url&quot;: &quot;https://api.openai.com/v1/&quot;,
  &quot;params&quot;: {
    &quot;max_tokens&quot;: 1000,
    &quot;temperature&quot;: 1
  }
},
&quot;code_model&quot;: {
  &quot;api&quot;: &quot;openai&quot;,
  &quot;model&quot;: &quot;gpt-4&quot;,
  &quot;url&quot;: &quot;https://api.openai.com/v1/&quot;
},
&quot;vision_model&quot;: {
  &quot;api&quot;: &quot;openai&quot;,
  &quot;model&quot;: &quot;gpt-4o&quot;,
  &quot;url&quot;: &quot;https://api.openai.com/v1/&quot;
},
&quot;embedding&quot;: {
  &quot;api&quot;: &quot;openai&quot;,
  &quot;url&quot;: &quot;https://api.openai.com/v1/&quot;,
  &quot;model&quot;: &quot;text-embedding-ada-002&quot;
},
&quot;speak_model&quot;: {
  &quot;api&quot;: &quot;openai&quot;,
  &quot;url&quot;: &quot;https://api.openai.com/v1/&quot;,
  &quot;model&quot;: &quot;tts-1&quot;,
  &quot;voice&quot;: &quot;echo&quot;
}

```

`model` is used for chat, `code_model` is used for newAction coding, `vision_model` is used for image interpretation, and `embedding` is used to embed text for example selection. If `code_model` or `vision_model` is not specified, `model` will be used by default. Not all APIs support embeddings or vision.

All apis have default models and urls, so those fields are optional. The `params` field is optional and can be used to specify additional parameters for the model. It accepts any key-value pairs supported by the api. Is not supported for embedding models.

## Embedding Models

Embedding models are used to embed and efficiently select relevant examples for conversation and coding.

Supported Embedding APIs: `openai`, `google`, `replicate`, `huggingface`, `novita`

If you try to use an unsupported model, then it will default to a simple word-overlap method. Expect reduced performance, recommend mixing APIs to ensure embedding support.

## Specifying Profiles via Command Line

By default, the program will use the profiles specified in `settings.js`. You can specify one or more agent profiles using the `--profiles` argument: `node main.js --profiles ./profiles/andy.json ./profiles/jill.json`

## Patches

Some of the node modules that we depend on have bugs in them. To add a patch, change your local node module file and run `npx patch-package [package-name]`

## Citation:

```
@article{mindcraft2025,
  title = {Collaborating Action by Action: A Multi-agent LLM Framework for Embodied Reasoning},
  author = {White*, Isadora and Nottingham*, Kolby and Maniar, Ayush and Robinson, Max and Lillemark, Hansen and Maheshwari, Mehul and Qin, Lianhui and Ammanabrolu, Prithviraj},
  journal = {arXiv preprint arXiv:2504.17950},
  year = {2025},
  url = {https://arxiv.org/abs/2504.17950},
}
```


</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
    </channel>
</rss>