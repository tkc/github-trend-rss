<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for javascript - JavaScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for javascript.</description>
        <lastBuildDate>Sun, 13 Apr 2025 00:28:44 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[chartjs/Chart.js]]></title>
            <link>https://github.com/chartjs/Chart.js</link>
            <guid>https://github.com/chartjs/Chart.js</guid>
            <pubDate>Sun, 13 Apr 2025 00:28:44 GMT</pubDate>
            <description><![CDATA[Simple HTML5 Charts using the <canvas> tag]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/chartjs/Chart.js">chartjs/Chart.js</a></h1>
            <p>Simple HTML5 Charts using the <canvas> tag</p>
            <p>Language: JavaScript</p>
            <p>Stars: 65,691</p>
            <p>Forks: 11,941</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.chartjs.org/&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://www.chartjs.org/media/logo-title.svg&quot; alt=&quot;https://www.chartjs.org/&quot;&gt;&lt;br/&gt;
  &lt;/a&gt;
    Simple yet flexible JavaScript charting for designers &amp; developers
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.chartjs.org/docs/latest/getting-started/installation.html&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/chartjs/Chart.js.svg?style=flat-square&amp;maxAge=600&quot; alt=&quot;Downloads&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/chartjs/Chart.js/actions?query=workflow%3ACI+branch%3Amaster&quot;&gt;&lt;img alt=&quot;GitHub Workflow Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/chartjs/Chart.js/ci.yml?branch=master&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://coveralls.io/github/chartjs/Chart.js?branch=master&quot;&gt;&lt;img src=&quot;https://img.shields.io/coveralls/chartjs/Chart.js.svg?style=flat-square&amp;maxAge=600&quot; alt=&quot;Coverage&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/chartjs/awesome&quot;&gt;&lt;img src=&quot;https://awesome.re/badge-flat2.svg&quot; alt=&quot;Awesome&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/HxEguTK6av&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/discord-chartjs-blue?style=flat-square&amp;maxAge=3600&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

## Documentation

All the links point to the new version 4 of the lib.

* [Introduction](https://www.chartjs.org/docs/latest/)
* [Getting Started](https://www.chartjs.org/docs/latest/getting-started/index)
* [General](https://www.chartjs.org/docs/latest/general/data-structures)
* [Configuration](https://www.chartjs.org/docs/latest/configuration/index)
* [Charts](https://www.chartjs.org/docs/latest/charts/line)
* [Axes](https://www.chartjs.org/docs/latest/axes/index)
* [Developers](https://www.chartjs.org/docs/latest/developers/index)
* [Popular Extensions](https://github.com/chartjs/awesome)
* [Samples](https://www.chartjs.org/samples/)

In case you are looking for an older version of the docs, you will have to specify the specific version in the url like this: [https://www.chartjs.org/docs/2.9.4/](https://www.chartjs.org/docs/2.9.4/)

## Contributing

Instructions on building and testing Chart.js can be found in [the documentation](https://www.chartjs.org/docs/master/developers/contributing.html#building-and-testing). Before submitting an issue or a pull request, please take a moment to look over the [contributing guidelines](https://www.chartjs.org/docs/master/developers/contributing) first. For support, please post questions on [Stack Overflow](https://stackoverflow.com/questions/tagged/chart.js) with the `chart.js` tag.

## License

Chart.js is available under the [MIT license](LICENSE.md).
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[wekan/wekan]]></title>
            <link>https://github.com/wekan/wekan</link>
            <guid>https://github.com/wekan/wekan</guid>
            <pubDate>Sun, 13 Apr 2025 00:28:43 GMT</pubDate>
            <description><![CDATA[The Open Source kanban (built with Meteor). Keep variable/table/field names camelCase. For translations, only add Pull Request changes to wekan/i18n/en.i18n.json , other translations are done at https://app.transifex.com/wekan/wekan only.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wekan/wekan">wekan/wekan</a></h1>
            <p>The Open Source kanban (built with Meteor). Keep variable/table/field names camelCase. For translations, only add Pull Request changes to wekan/i18n/en.i18n.json , other translations are done at https://app.transifex.com/wekan/wekan only.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 20,005</p>
            <p>Forks: 2,885</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>[Gitpod Ready-to-Code](https://gitpod.io/#https://github.com/wekan/wekan)

# WeKan ® - Open Source kanban

## Downloads

https://wekan.github.io / Install WeKan ® Server

## Docker Containers

- [GitHub](https://github.com/wekan/wekan/pkgs/container/wekan)
- [Quay](https://quay.io/repository/wekan/wekan)
- [Docker Hub](https://hub.docker.com/r/wekanteam/wekan)

docker-compose.yml at https://github.com/wekan/wekan/blob/main/docker-compose.yml

## Standards

- [WeKan and Standard for Public Code](https://wekan.github.io/standard-for-public-code/) assessment was made at 2023-11.
  Currently Wekan meets 8 out of 16 criteria out of the box.
  Some others could be met with small changes.

## Code stats

- [CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/4619)
- [Code Climate](https://codeclimate.com/github/wekan/wekan)
- [Open Hub](https://www.openhub.net/p/wekan)
- [OSS Insight](https://ossinsight.io/analyze/wekan/wekan)

## [Translate WeKan ® at Transifex](https://app.transifex.com/wekan/)

Translations to non-English languages are accepted only at [Transifex](https://app.transifex.com/wekan/wekan) using webbrowser.
New English strings of new features can be added as PRs to master branch file wekan/imports/i18n/data/en.i18n.json .

## [WeKan ® feature requests and bugs](https://github.com/wekan/wekan/issues)

Please add most of your questions as GitHub issue: [WeKan ® Feature Requests and Bugs](https://github.com/wekan/wekan/issues).
It&#039;s better than at chat where details get lost when chat scrolls up.

## Chat

[Discussions][discussions] - WeKan Community GitHub Discussions, that are not [Feature Requests and Bugs](https://github.com/wekan/wekan/issues).

[WeKan IRC FAQ](https://github.com/wekan/wekan/wiki/IRC-FAQ)

## Docker: Latest tag has newest release

You can use latest tag to get newest release tag.
See bottom of https://github.com/wekan/wekan/issues/3874

## FAQ

**NOTE**:
- Please read the [FAQ](https://github.com/wekan/wekan/wiki/FAQ) first
- Please don&#039;t feed the [trolls](https://github.com/wekan/wekan/wiki/FAQ#why-am-i-called-a-troll) and [spammers](https://github.com/wekan/wekan/wiki/FAQ#why-am-i-called-a-spammer) that are mentioned in the FAQ :)

## About WeKan ®

WeKan ® is an completely [Open Source][open_source] and [Free software][free_software]
collaborative kanban board application with MIT license.

Whether you’re maintaining a personal todo list, planning your holidays with some friends,
or working in a team on your next revolutionary idea, Kanban boards are an unbeatable tool
to keep your things organized. They give you a visual overview of the current state of your project,
and make you productive by allowing you to focus on the few items that matter the most.

Since WeKan ® is a free software, you don’t have to trust us with your data and can
install Wekan on your own computer or server. In fact we encourage you to do
that by providing one-click installation on various platforms.

- WeKan ® is used in [most countries of the world](https://snapcraft.io/wekan).
- WeKan ® largest user has 30k users using WeKan ® in their company.
- WeKan ® has been [translated](https://app.transifex.com/wekan/) to about 105 languages.
- [Features][features]: WeKan ® has real-time user interface.
- [Platforms][platforms]: WeKan ® supports many platforms.
  WeKan ® is critical part of new platforms Wekan is currently being integrated to.

## Requirements

- 64bit: Linux [Snap](https://github.com/wekan/wekan-snap/wiki/Install) or [Sandstorm](https://sandstorm.io) /
  [Mac](https://github.com/wekan/wekan/wiki/Mac) / [Windows](https://github.com/wekan/wekan/wiki/Install-Wekan-from-source-on-Windows).
  [More Platforms](https://github.com/wekan/wekan/wiki/Platforms), bundle for RasPi3 ARM and other CPUs where Node.js and MongoDB exists.
- 1 GB RAM minimum free for WeKan ®. Production server should have minimum total 4 GB RAM.
  For thousands of users, for example with [Docker](https://github.com/wekan/wekan/blob/main/docker-compose.yml): 3 frontend servers,
  each having 2 CPU and 2 wekan-app containers. One backend wekan-db server with many CPUs.
- Enough disk space and alerts about low disk space. If you run out disk space, MongoDB database gets corrupted.
- SECURITY: Updating to newest WeKan ® version very often. Please check you do not have automatic updates of Sandstorm or Snap turned off.
  Old versions have security issues because of old versions Node.js etc. Only newest WeKan ® is supported.
  WeKan ® on Sandstorm is not usually affected by any Standalone WeKan ® (Snap/Docker/Source) security issues.
- [Reporting all new bugs immediately](https://github.com/wekan/wekan/issues).
  New features and fixes are added to WeKan ® [many times a day](https://github.com/wekan/wekan/blob/main/CHANGELOG.md).
- [Backups](https://github.com/wekan/wekan/wiki/Backup) of WeKan ® database once a day miminum.
  Bugs, updates, users deleting list or card, harddrive full, harddrive crash etc can eat your data. There is no undo yet.
  Some bug can cause WeKan ® board to not load at all, requiring manual fixing of database content.

## Roadmap and Demo

[Roadmap][roadmap_wekan] - Public read-only board at WeKan ® demo.

[Developer Documentation][dev_docs]

- There is many companies and individuals contributing code to WeKan ®, to add features and bugfixes
  [many times a day](https://github.com/wekan/wekan/blob/main/CHANGELOG.md).
- [Please add Add new Feature Requests and Bug Reports immediately](https://github.com/wekan/wekan/issues).
- [Commercial Support](https://wekan.team/commercial-support/).

We also welcome sponsors for features and bugfixes.
By working directly with WeKan ® you get the benefit of active maintenance and new features added by growing WeKan ® developer community.

## Getting Started with Development

The default branch uses [Meteor 2 with Node.js 14](https://wekan.github.io/install/).

To contribute, [create a fork](https://github.com/wekan/wekan/wiki/Emoji#2-create-fork-of-httpsgithubcomwekanwekan-at-github-web-page) and run `./rebuild-wekan.sh` (or `./rebuild-wekan.bat` on Windows) as detailed [here](https://github.com/wekan/wekan/wiki/Emoji#3-select-option-1-to-install-dependencies-and-then-enter). Once you&#039;re ready, please test your code and [submit a pull request (PR)](https://github.com/wekan/wekan/wiki/Emoji#7-test).

Please refer to the [developer documentation](https://github.com/wekan/wekan/wiki/Developer-Documentation) for more information.

## Screenshot

[More screenshots at Features page](https://github.com/wekan/wekan/wiki/Features)

[![Screenshot of WeKan ®][screenshot_wekan]][roadmap_wekan]

## License

WeKan ® is released under the very permissive [MIT license](LICENSE), and made
with [Meteor](https://www.meteor.com).

[platforms]: https://github.com/wekan/wekan/wiki/Platforms
[dev_docs]: https://github.com/wekan/wekan/wiki/Developer-Documentation
[screenshot_wekan]: https://wekan.github.io/wekan-dark-mode.png
[features]: https://github.com/wekan/wekan/wiki/Features
[roadmap_wekan]: https://boards.wekan.team/b/D2SzJKZDS4Z48yeQH/wekan-open-source-kanban-board-with-mit-license
[wekan_issues]: https://github.com/wekan/wekan/issues
[wekan_issues]: https://github.com/wekan/wekan/issues
[docker_image]: https://hub.docker.com/r/wekanteam/wekan/
[wekan_wiki]: https://github.com/wekan/wekan/wiki
[translate_wekan]: https://app.transifex.com/wekan/
[open_source]: https://en.wikipedia.org/wiki/Open-source_software
[free_software]: https://en.wikipedia.org/wiki/Free_software
[discussions]: https://github.com/wekan/wekan/discussions
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[UseInterstellar/Interstellar]]></title>
            <link>https://github.com/UseInterstellar/Interstellar</link>
            <guid>https://github.com/UseInterstellar/Interstellar</guid>
            <pubDate>Sun, 13 Apr 2025 00:28:42 GMT</pubDate>
            <description><![CDATA[One of the most popular modern web proxies with blazing fast speeds and a variety of games.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/UseInterstellar/Interstellar">UseInterstellar/Interstellar</a></h1>
            <p>One of the most popular modern web proxies with blazing fast speeds and a variety of games.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 1,440</p>
            <p>Forks: 17,623</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/UseInterstellar/Interstellar/main/.github/branding/in.png&quot;&gt;
    &lt;p&gt;Serving over 8+ million users since 2023.&lt;p&gt;
    &lt;p&gt;Interstellar is a web proxy with a Clean and Sleek UI and easy to use menus. Our goal is to provide the best user experience to everyone.&lt;/p&gt;
&lt;/div&gt;

![inpreview](https://github.com/UseInterstellar/Interstellar/assets/89202835/2669efed-5186-4932-83c4-725acae60bd2)

&gt; [!IMPORTANT]
&gt; If you fork this project, consider giving it a star in the original repository!

**Join Our [Discord Community](https://discord.gg/interstellar) for support, more links, and an active community!**

## Features

- About:Blank Cloaking
- Tab Cloaking
- Wide collection of apps &amp; games
- Clean, Easy to use UI
- Inspect Element
- Various Themes
- Password Protection (Optional)
- Built-in Tab System
- Now.gg Support
- Fast Speeds
- Geforce NOW Support

## Deployment

&gt; [!IMPORTANT]
&gt; You **cannot** deploy to static web hosts, including Netlify, Cloudflare Pages, and GitHub Pages.

### Password Protection

1. Go to the `config.js` file and set `challenge` to **true**. Then, set the environment variable as follows:
2. For PNPM: Run either `config=true pnpm start` or `$env:config=true; pnpm start`, depending on your server.
3. For Bun: Run either `config=true bun start` or `$env:config=true; bun start` if you prefer Bun.
4. For NPM: Run either `config=true npm start` or `$env:config=true; npm start` if you prefer NPM.


### Server Deployment

You must run these commands on your server:

```bash
git clone https://github.com/UseInterstellar/Interstellar
cd Interstellar
```

#### Ad-Free Deployment

```bash
git clone --branch Ad-Free https://github.com/UseInterstellar/Interstellar
cd Interstellar
```

Next depending on your package manager, run one of the following commands:

#### Bun

If you are using Bun, run the following commands:

```bash
bun i
bun start
```

#### pnpm

If you are using pnpm, run the following commands:

```bash
pnpm i
pnpm start
```

#### npm

If you are using npm, run the following commands:

```bash
npm i
npm run start
```

### Updating

```bash
cd Interstellar
git pull --force --allow-unrelated-histories # This may overwrite your local changes
```

&lt;a target=&quot;_blank&quot; href=&quot;https://heroku.com/deploy/?template=https://github.com/UseInterstellar/Interstellar&quot;&gt;&lt;img alt=&quot;Deploy to Heroku&quot; src=&quot;https://binbashbanana.github.io/deploy-buttons/buttons/remade/heroku.svg&quot;&gt;&lt;/a&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://app.koyeb.com/deploy?type=git&amp;repository=github.com/UseInterstellar/Interstellar&quot;&gt;&lt;img alt=&quot;Deploy to Koyeb&quot; src=&quot;https://binbashbanana.github.io/deploy-buttons/buttons/remade/koyeb.svg&quot;&gt;&lt;/a&gt;

### Deployment Alternatives

For more deployment options, join our [Discord Server](https://discord.gg/interstellar) for various ways to deploy Interstellar.
This includes methods of deploying to Render/OnRender.

#### What happened to Replit Deployment?

As of January 1st, 2024, Replit is [no longer free](https://blog.replit.com/hosting-changes). Try GitHub Codespaces instead.

### GitHub Codespaces

&gt; [!NOTE]
&gt; If you&#039;re setting the port below 1023, then you must run `sudo PORT=1023`

1. Create a GitHub account if you haven&#039;t already.
2. Click &quot;Code&quot; (green button) and then &quot;Create Codespace on main.&quot;
3. In the terminal at the bottom, paste `pnpm i &amp;&amp; pnpm start`.
4. Respond to the application popup by clicking &quot;Make public.&quot;
&gt; [!IMPORTANT]
&gt; Make sure you click the &quot;Make public.&quot; button, or the proxy won&#039;t function properly.&lt;br&gt;
&gt; If you get a Range Error, go back and make sure you clicked Make public!
5. Access the deployed website from the ports tab.
6. For subsequent uses in the same codespace, just run `pnpm start`

### Solution for if there is no popup.

1. Run `pnpm i`, and before `pnpm start`, prepend `PORT=8080`, replacing 8080 with another port. For example, `PORT=6969 pnpm start`.
2. If this does not work then you can prepend `$env:PORT=8080;`, replacing 8080 with another port. For example, `$env:PORT=6969; pnpm start`
3. Go to the ports tab, Click Forward A Port, And type the port number.
4. Right-click Visibility and set Port Visibility to Public.

&gt; [!NOTE]
&gt; We are committed to making Interstellar easy and personalized however, as of now we need your support in making it ad-free. Consider keeping ads so Interstellar can run freely or contribute by being a supporter.

## Report Issues

If you encounter problems, open an issue on GitHub, and we&#039;ll address it promptly.

&gt; [!TIP]
&gt; If you&#039;re having trouble, don&#039;t hesitate to reach out to us on [Discord](https://discord.gg/interstellar) for personalized support.

# Credits

A huge thanks goes out to all of the people who have contributed to Interstellar.

[![Contributors](https://contrib.rocks/image?repo=UseInterstellar/Interstellar)](https://github.com/UseInterstellar/Interstellar/graphs/contributors)
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[HeyPuter/puter]]></title>
            <link>https://github.com/HeyPuter/puter</link>
            <guid>https://github.com/HeyPuter/puter</guid>
            <pubDate>Sun, 13 Apr 2025 00:28:41 GMT</pubDate>
            <description><![CDATA[🌐 The Internet OS! Free, Open-Source, and Self-Hostable.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/HeyPuter/puter">HeyPuter/puter</a></h1>
            <p>🌐 The Internet OS! Free, Open-Source, and Self-Hostable.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 30,143</p>
            <p>Forks: 2,233</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>&lt;h3 align=&quot;center&quot;&gt;&lt;img width=&quot;80&quot; alt=&quot;Puter.com, The Personal Cloud Computer: All your files, apps, and games in one place accessible from anywhere at any time.&quot; src=&quot;https://assets.puter.site/puter-logo.png&quot;&gt;&lt;/h3&gt;

&lt;h3 align=&quot;center&quot;&gt;The Internet OS! Free, Open-Source, and Self-Hostable.&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://puter.com/?ref=github.com&quot;&gt;&lt;strong&gt;« LIVE DEMO »&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://puter.com/?ref=github.com&quot;&gt;Puter.com&lt;/a&gt;
    ·
    &lt;a href=&quot;https://puter.com/app/app-center&quot;&gt;App Store&lt;/a&gt;
    ·
    &lt;a href=&quot;https://developer.puter.com&quot; target=&quot;_blank&quot;&gt;Developers&lt;/a&gt;
    ·
    &lt;a href=&quot;https://github.com/heyputer/puter-cli&quot; target=&quot;_blank&quot;&gt;CLI&lt;/a&gt;
    ·
    &lt;a href=&quot;https://discord.com/invite/PQcx7Teh8u&quot;&gt;Discord&lt;/a&gt;
    ·
    &lt;a href=&quot;https://reddit.com/r/puter&quot;&gt;Reddit&lt;/a&gt;
    ·
    &lt;a href=&quot;https://twitter.com/HeyPuter&quot;&gt;X&lt;/a&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;&lt;img width=&quot;800&quot; style=&quot;border-radius:5px;&quot; alt=&quot;screenshot&quot; src=&quot;https://assets.puter.site/puter.com-screenshot-3.webp&quot;&gt;&lt;/h3&gt;

&lt;br/&gt;

## Puter

Puter is an advanced, open-source internet operating system designed to be feature-rich, exceptionally fast, and highly extensible. Puter can be used as:

- A privacy-first personal cloud to keep all your files, apps, and games in one secure place, accessible from anywhere at any time.
- A platform for building and publishing websites, web apps, and games.
- An alternative to Dropbox, Google Drive, OneDrive, etc. with a fresh interface and powerful features.
- A remote desktop environment for servers and workstations.
- A friendly, open-source project and community to learn about web development, cloud computing, distributed systems, and much more!

&lt;br/&gt;

## Getting Started

### 💻 Local Development

```bash
git clone https://github.com/HeyPuter/puter
cd puter
npm install
npm start
```
✨ This should launch Puter at 
&lt;font color=&quot;red&quot;&gt; http://puter.localhost:4100 (or the next available port). &lt;/font&gt;



If this does not work, see [First Run Issues](./doc/self-hosters/first-run-issues.md) for
troubleshooting steps.

&lt;br/&gt;

### 🐳 Docker

```bash
mkdir puter &amp;&amp; cd puter &amp;&amp; mkdir -p puter/config puter/data &amp;&amp; sudo chown -R 1000:1000 puter &amp;&amp; docker run --rm -p 4100:4100 -v `pwd`/puter/config:/etc/puter -v `pwd`/puter/data:/var/puter  ghcr.io/heyputer/puter
```
✨ This should launch Puter at 
&lt;font color=&quot;red&quot;&gt; http://puter.localhost:4100 (or the next available port). &lt;/font&gt;

&lt;br/&gt;

### 🐙 Docker Compose

#### Linux/macOS

```bash
mkdir -p puter/config puter/data
sudo chown -R 1000:1000 puter
wget https://raw.githubusercontent.com/HeyPuter/puter/main/docker-compose.yml
docker compose up
```
✨ This should be available at 
&lt;font color=&quot;red&quot;&gt; http://puter.localhost:4100 (or the next available port). &lt;/font&gt;

&lt;br/&gt;

#### Windows

```powershell
mkdir -p puter
cd puter
New-Item -Path &quot;puter\config&quot; -ItemType Directory -Force
New-Item -Path &quot;puter\data&quot; -ItemType Directory -Force
Invoke-WebRequest -Uri &quot;https://raw.githubusercontent.com/HeyPuter/puter/main/docker-compose.yml&quot; -OutFile &quot;docker-compose.yml&quot;
docker compose up
```
✨ This should launch Puter at 
&lt;font color=&quot;red&quot;&gt; http://puter.localhost:4100 (or the next available port). &lt;/font&gt;

&lt;br/&gt;

### 🚀 Self-Hosting

For detailed guides on self-hosting Puter, including configuration options and best practices, see our [Self-Hosting Documentation](https://github.com/HeyPuter/puter/blob/main/doc/self-hosters/instructions.md).

&lt;br/&gt;

### ☁️ Puter.com

Puter is available as a hosted service at [**puter.com**](https://puter.com).

&lt;br/&gt;

## System Requirements

- **Operating Systems:** Linux, macOS, Windows
- **RAM:** 2GB minimum (4GB recommended)
- **Disk Space:** 1GB free space
- **Node.js:** Version 16+ (Version 23+ recommended)
- **npm:** Latest stable version

&lt;br/&gt;

## Support

Connect with the maintainers and community through these channels:

- Bug report or feature request? Please [open an issue](https://github.com/HeyPuter/puter/issues/new/choose).
- Discord: [discord.com/invite/PQcx7Teh8u](https://discord.com/invite/PQcx7Teh8u)
- X (Twitter): [x.com/HeyPuter](https://x.com/HeyPuter)
- Reddit: [reddit.com/r/puter/](https://www.reddit.com/r/puter/)
- Mastodon: [mastodon.social/@puter](https://mastodon.social/@puter)
- Security issues? [security@puter.com](mailto:security@puter.com)
- Email maintainers at [hi@puter.com](mailto:hi@puter.com)

We are always happy to help you with any questions you may have. Don&#039;t hesitate to ask!

&lt;br/&gt;

## License

This repository, including all its contents, sub-projects, modules, and components, is licensed under [AGPL-3.0](https://github.com/HeyPuter/puter/blob/main/LICENSE.txt) unless explicitly stated otherwise. Third-party libraries included in this repository may be subject to their own licenses.

&lt;br/&gt;

## Translations

- [Arabic / العربية](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.ar.md)
- [Armenian / Հայերեն](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.hy.md)
- [Bengali / বাংলা](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.bn.md)
- [Chinese / 中文](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.zh.md)
- [Danish / Dansk](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.da.md)
- [English](https://github.com/HeyPuter/puter/blob/main/README.md)
- [Farsi / فارسی](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.fa.md)
- [Finnish / Suomi](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.fi.md)
- [French / Français](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.fr.md)
- [German/ Deutsch](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.de.md)
- [Hebrew/ עברית](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.he.md)
- [Hindi / हिंदी](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.hi.md)
- [Hungarian / Magyar](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.hu.md)
- [Indonesian / Bahasa Indonesia](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.id.md)
- [Italian / Italiano](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.it.md)
- [Japanese / 日本語](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.jp.md)
- [Korean / 한국어](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.ko.md)
- [Malayalam / മലയാളം](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.ml.md)
- [Polish / Polski](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.pl.md)
- [Portuguese / Português](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.pt.md)
- [Romanian / Română](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.ro.md)
- [Russian / Русский](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.ru.md)
- [Spanish / Español](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.es.md)
- [Swedish / Svenska](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.sv.md)
- [Tamil / தமிழ்](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.ta.md)
- [Telugu / తెలుగు](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.te.md)
- [Thai / ไทย](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.th.md)
- [Turkish / Türkçe](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.tr.md)
- [Ukrainian / Українська](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.ua.md)
- [Urdu / اردو](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.ur.md)
- [Vietnamese / Tiếng Việt](https://github.com/HeyPuter/puter/blob/main/doc/i18n/README.vi.md)
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[open-webui/open-webui]]></title>
            <link>https://github.com/open-webui/open-webui</link>
            <guid>https://github.com/open-webui/open-webui</guid>
            <pubDate>Sun, 13 Apr 2025 00:28:40 GMT</pubDate>
            <description><![CDATA[User-friendly AI Interface (Supports Ollama, OpenAI API, ...)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-webui/open-webui">open-webui/open-webui</a></h1>
            <p>User-friendly AI Interface (Supports Ollama, OpenAI API, ...)</p>
            <p>Language: JavaScript</p>
            <p>Stars: 89,104</p>
            <p>Forks: 11,143</p>
            <p>Stars today: 176 stars today</p>
            <h2>README</h2><pre># Open WebUI 👋

![GitHub stars](https://img.shields.io/github/stars/open-webui/open-webui?style=social)
![GitHub forks](https://img.shields.io/github/forks/open-webui/open-webui?style=social)
![GitHub watchers](https://img.shields.io/github/watchers/open-webui/open-webui?style=social)
![GitHub repo size](https://img.shields.io/github/repo-size/open-webui/open-webui)
![GitHub language count](https://img.shields.io/github/languages/count/open-webui/open-webui)
![GitHub top language](https://img.shields.io/github/languages/top/open-webui/open-webui)
![GitHub last commit](https://img.shields.io/github/last-commit/open-webui/open-webui?color=red)
![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2Follama-webui%2Follama-wbui&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=hits&amp;edge_flat=false)
[![Discord](https://img.shields.io/badge/Discord-Open_WebUI-blue?logo=discord&amp;logoColor=white)](https://discord.gg/5rJgQTnV4s)
[![](https://img.shields.io/static/v1?label=Sponsor&amp;message=%E2%9D%A4&amp;logo=GitHub&amp;color=%23fe8e86)](https://github.com/sponsors/tjbck)

**Open WebUI is an [extensible](https://docs.openwebui.com/features/plugin/), feature-rich, and user-friendly self-hosted AI platform designed to operate entirely offline.** It supports various LLM runners like **Ollama** and **OpenAI-compatible APIs**, with **built-in inference engine** for RAG, making it a **powerful AI deployment solution**.

![Open WebUI Demo](./demo.gif)

&gt; [!TIP]  
&gt; **Looking for an [Enterprise Plan](https://docs.openwebui.com/enterprise)?** – **[Speak with Our Sales Team Today!](mailto:sales@openwebui.com)**
&gt;
&gt; Get **enhanced capabilities**, including **custom theming and branding**, **Service Level Agreement (SLA) support**, **Long-Term Support (LTS) versions**, and **more!**

For more information, be sure to check out our [Open WebUI Documentation](https://docs.openwebui.com/).

## Key Features of Open WebUI ⭐

- 🚀 **Effortless Setup**: Install seamlessly using Docker or Kubernetes (kubectl, kustomize or helm) for a hassle-free experience with support for both `:ollama` and `:cuda` tagged images.

- 🤝 **Ollama/OpenAI API Integration**: Effortlessly integrate OpenAI-compatible APIs for versatile conversations alongside Ollama models. Customize the OpenAI API URL to link with **LMStudio, GroqCloud, Mistral, OpenRouter, and more**.

- 🛡️ **Granular Permissions and User Groups**: By allowing administrators to create detailed user roles and permissions, we ensure a secure user environment. This granularity not only enhances security but also allows for customized user experiences, fostering a sense of ownership and responsibility amongst users.

- 📱 **Responsive Design**: Enjoy a seamless experience across Desktop PC, Laptop, and Mobile devices.

- 📱 **Progressive Web App (PWA) for Mobile**: Enjoy a native app-like experience on your mobile device with our PWA, providing offline access on localhost and a seamless user interface.

- ✒️🔢 **Full Markdown and LaTeX Support**: Elevate your LLM experience with comprehensive Markdown and LaTeX capabilities for enriched interaction.

- 🎤📹 **Hands-Free Voice/Video Call**: Experience seamless communication with integrated hands-free voice and video call features, allowing for a more dynamic and interactive chat environment.

- 🛠️ **Model Builder**: Easily create Ollama models via the Web UI. Create and add custom characters/agents, customize chat elements, and import models effortlessly through [Open WebUI Community](https://openwebui.com/) integration.

- 🐍 **Native Python Function Calling Tool**: Enhance your LLMs with built-in code editor support in the tools workspace. Bring Your Own Function (BYOF) by simply adding your pure Python functions, enabling seamless integration with LLMs.

- 📚 **Local RAG Integration**: Dive into the future of chat interactions with groundbreaking Retrieval Augmented Generation (RAG) support. This feature seamlessly integrates document interactions into your chat experience. You can load documents directly into the chat or add files to your document library, effortlessly accessing them using the `#` command before a query.

- 🔍 **Web Search for RAG**: Perform web searches using providers like `SearXNG`, `Google PSE`, `Brave Search`, `serpstack`, `serper`, `Serply`, `DuckDuckGo`, `TavilySearch`, `SearchApi` and `Bing` and inject the results directly into your chat experience.

- 🌐 **Web Browsing Capability**: Seamlessly integrate websites into your chat experience using the `#` command followed by a URL. This feature allows you to incorporate web content directly into your conversations, enhancing the richness and depth of your interactions.

- 🎨 **Image Generation Integration**: Seamlessly incorporate image generation capabilities using options such as AUTOMATIC1111 API or ComfyUI (local), and OpenAI&#039;s DALL-E (external), enriching your chat experience with dynamic visual content.

- ⚙️ **Many Models Conversations**: Effortlessly engage with various models simultaneously, harnessing their unique strengths for optimal responses. Enhance your experience by leveraging a diverse set of models in parallel.

- 🔐 **Role-Based Access Control (RBAC)**: Ensure secure access with restricted permissions; only authorized individuals can access your Ollama, and exclusive model creation/pulling rights are reserved for administrators.

- 🌐🌍 **Multilingual Support**: Experience Open WebUI in your preferred language with our internationalization (i18n) support. Join us in expanding our supported languages! We&#039;re actively seeking contributors!

- 🧩 **Pipelines, Open WebUI Plugin Support**: Seamlessly integrate custom logic and Python libraries into Open WebUI using [Pipelines Plugin Framework](https://github.com/open-webui/pipelines). Launch your Pipelines instance, set the OpenAI URL to the Pipelines URL, and explore endless possibilities. [Examples](https://github.com/open-webui/pipelines/tree/main/examples) include **Function Calling**, User **Rate Limiting** to control access, **Usage Monitoring** with tools like Langfuse, **Live Translation with LibreTranslate** for multilingual support, **Toxic Message Filtering** and much more.

- 🌟 **Continuous Updates**: We are committed to improving Open WebUI with regular updates, fixes, and new features.

Want to learn more about Open WebUI&#039;s features? Check out our [Open WebUI documentation](https://docs.openwebui.com/features) for a comprehensive overview!

## 🔗 Also Check Out Open WebUI Community!

Don&#039;t forget to explore our sibling project, [Open WebUI Community](https://openwebui.com/), where you can discover, download, and explore customized Modelfiles. Open WebUI Community offers a wide range of exciting possibilities for enhancing your chat interactions with Open WebUI! 🚀

## How to Install 🚀

### Installation via Python pip 🐍

Open WebUI can be installed using pip, the Python package installer. Before proceeding, ensure you&#039;re using **Python 3.11** to avoid compatibility issues.

1. **Install Open WebUI**:
   Open your terminal and run the following command to install Open WebUI:

   ```bash
   pip install open-webui
   ```

2. **Running Open WebUI**:
   After installation, you can start Open WebUI by executing:

   ```bash
   open-webui serve
   ```

This will start the Open WebUI server, which you can access at [http://localhost:8080](http://localhost:8080)

### Quick Start with Docker 🐳

&gt; [!NOTE]  
&gt; Please note that for certain Docker environments, additional configurations might be needed. If you encounter any connection issues, our detailed guide on [Open WebUI Documentation](https://docs.openwebui.com/) is ready to assist you.

&gt; [!WARNING]
&gt; When using Docker to install Open WebUI, make sure to include the `-v open-webui:/app/backend/data` in your Docker command. This step is crucial as it ensures your database is properly mounted and prevents any loss of data.

&gt; [!TIP]  
&gt; If you wish to utilize Open WebUI with Ollama included or CUDA acceleration, we recommend utilizing our official images tagged with either `:cuda` or `:ollama`. To enable CUDA, you must install the [Nvidia CUDA container toolkit](https://docs.nvidia.com/dgx/nvidia-container-runtime-upgrade/) on your Linux/WSL system.

### Installation with Default Configuration

- **If Ollama is on your computer**, use this command:

  ```bash
  docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
  ```

- **If Ollama is on a Different Server**, use this command:

  To connect to Ollama on another server, change the `OLLAMA_BASE_URL` to the server&#039;s URL:

  ```bash
  docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://example.com -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
  ```

- **To run Open WebUI with Nvidia GPU support**, use this command:

  ```bash
  docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda
  ```

### Installation for OpenAI API Usage Only

- **If you&#039;re only using OpenAI API**, use this command:

  ```bash
  docker run -d -p 3000:8080 -e OPENAI_API_KEY=your_secret_key -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
  ```

### Installing Open WebUI with Bundled Ollama Support

This installation method uses a single container image that bundles Open WebUI with Ollama, allowing for a streamlined setup via a single command. Choose the appropriate command based on your hardware setup:

- **With GPU Support**:
  Utilize GPU resources by running the following command:

  ```bash
  docker run -d -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
  ```

- **For CPU Only**:
  If you&#039;re not using a GPU, use this command instead:

  ```bash
  docker run -d -p 3000:8080 -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
  ```

Both commands facilitate a built-in, hassle-free installation of both Open WebUI and Ollama, ensuring that you can get everything up and running swiftly.

After installation, you can access Open WebUI at [http://localhost:3000](http://localhost:3000). Enjoy! 😄

### Other Installation Methods

We offer various installation alternatives, including non-Docker native installation methods, Docker Compose, Kustomize, and Helm. Visit our [Open WebUI Documentation](https://docs.openwebui.com/getting-started/) or join our [Discord community](https://discord.gg/5rJgQTnV4s) for comprehensive guidance.

### Troubleshooting

Encountering connection issues? Our [Open WebUI Documentation](https://docs.openwebui.com/troubleshooting/) has got you covered. For further assistance and to join our vibrant community, visit the [Open WebUI Discord](https://discord.gg/5rJgQTnV4s).

#### Open WebUI: Server Connection Error

If you&#039;re experiencing connection issues, it’s often due to the WebUI docker container not being able to reach the Ollama server at 127.0.0.1:11434 (host.docker.internal:11434) inside the container . Use the `--network=host` flag in your docker command to resolve this. Note that the port changes from 3000 to 8080, resulting in the link: `http://localhost:8080`.

**Example Docker Command**:

```bash
docker run -d --network=host -v open-webui:/app/backend/data -e OLLAMA_BASE_URL=http://127.0.0.1:11434 --name open-webui --restart always ghcr.io/open-webui/open-webui:main
```

### Keeping Your Docker Installation Up-to-Date

In case you want to update your local Docker installation to the latest version, you can do it with [Watchtower](https://containrrr.dev/watchtower/):

```bash
docker run --rm --volume /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --run-once open-webui
```

In the last part of the command, replace `open-webui` with your container name if it is different.

Check our Updating Guide available in our [Open WebUI Documentation](https://docs.openwebui.com/getting-started/updating).

### Using the Dev Branch 🌙

&gt; [!WARNING]
&gt; The `:dev` branch contains the latest unstable features and changes. Use it at your own risk as it may have bugs or incomplete features.

If you want to try out the latest bleeding-edge features and are okay with occasional instability, you can use the `:dev` tag like this:

```bash
docker run -d -p 3000:8080 -v open-webui:/app/backend/data --name open-webui --add-host=host.docker.internal:host-gateway --restart always ghcr.io/open-webui/open-webui:dev
```

### Offline Mode

If you are running Open WebUI in an offline environment, you can set the `HF_HUB_OFFLINE` environment variable to `1` to prevent attempts to download models from the internet.

```bash
export HF_HUB_OFFLINE=1
```

## What&#039;s Next? 🌟

Discover upcoming features on our roadmap in the [Open WebUI Documentation](https://docs.openwebui.com/roadmap/).

## License 📜

This project is licensed under the [BSD-3-Clause License](LICENSE) - see the [LICENSE](LICENSE) file for details. 📄

## Support 💬

If you have any questions, suggestions, or need assistance, please open an issue or join our
[Open WebUI Discord community](https://discord.gg/5rJgQTnV4s) to connect with us! 🤝

## Star History

&lt;a href=&quot;https://star-history.com/#open-webui/open-webui&amp;Date&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=open-webui/open-webui&amp;type=Date&amp;theme=dark&quot; /&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=open-webui/open-webui&amp;type=Date&quot; /&gt;
    &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=open-webui/open-webui&amp;type=Date&quot; /&gt;
  &lt;/picture&gt;
&lt;/a&gt;

---

Created by [Timothy Jaeryang Baek](https://github.com/tjbck) - Let&#039;s make Open WebUI even more amazing together! 💪
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[HumanSignal/label-studio]]></title>
            <link>https://github.com/HumanSignal/label-studio</link>
            <guid>https://github.com/HumanSignal/label-studio</guid>
            <pubDate>Sun, 13 Apr 2025 00:28:39 GMT</pubDate>
            <description><![CDATA[Label Studio is a multi-type data labeling and annotation tool with standardized output format]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/HumanSignal/label-studio">HumanSignal/label-studio</a></h1>
            <p>Label Studio is a multi-type data labeling and annotation tool with standardized output format</p>
            <p>Language: JavaScript</p>
            <p>Stars: 21,562</p>
            <p>Forks: 2,667</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://raw.githubusercontent.com/heartexlabs/label-studio/master/images/ls_github_header.png&quot;/&gt;

![GitHub](https://img.shields.io/github/license/heartexlabs/label-studio?logo=heartex) ![label-studio:build](https://github.com/heartexlabs/label-studio/workflows/label-studio:build/badge.svg) ![GitHub release](https://img.shields.io/github/v/release/heartexlabs/label-studio?include_prereleases)

[Website](https://labelstud.io/) • [Docs](https://labelstud.io/guide/) • [Twitter](https://twitter.com/heartexlabs) • [Join Slack Community &lt;img src=&quot;https://app.heartex.ai/docs/images/slack-mini.png&quot; width=&quot;18px&quot;/&gt;](https://slack.labelstudio.heartex.com/?source=github-1)


## What is Label Studio?

&lt;!-- &lt;a href=&quot;https://labelstud.io/blog/release-130.html&quot;&gt;&lt;img src=&quot;https://github.com/heartexlabs/label-studio/raw/master/docs/themes/htx/source/images/release-130/LS-Hits-v1.3.png&quot; align=&quot;right&quot; /&gt;&lt;/a&gt; --&gt;

Label Studio is an open source data labeling tool. It lets you label data types like audio, text, images, videos, and time series with a simple and straightforward UI and export to various model formats. It can be used to prepare raw data or improve existing training data to get more accurate ML models.

- [Try out Label Studio](#try-out-label-studio)
- [What you get from Label Studio](#what-you-get-from-label-studio)
- [Included templates for labeling data in Label Studio](#included-templates-for-labeling-data-in-label-studio)
- [Set up machine learning models with Label Studio](#set-up-machine-learning-models-with-Label-Studio)
- [Integrate Label Studio with your existing tools](#integrate-label-studio-with-your-existing-tools)

![Gif of Label Studio annotating different types of data](https://raw.githubusercontent.com/heartexlabs/label-studio/master/images/annotation_examples.gif)

Have a custom dataset? You can customize Label Studio to fit your needs. Read an [introductory blog post](https://towardsdatascience.com/introducing-label-studio-a-swiss-army-knife-of-data-labeling-140c1be92881) to learn more. 

## Try out Label Studio

Install Label Studio locally, or deploy it in a cloud instance. Also you can try [Label Studio Teams](https://app.heartex.com).

- [Install locally with Docker](#install-locally-with-docker)
- [Run with Docker Compose (Label Studio + Nginx + PostgreSQL)](#run-with-docker-compose)
- [Install locally with pip](#install-locally-with-pip)
- [Install locally with Anaconda](#install-locally-with-anaconda)
- [Install for local development](#install-for-local-development)
- [Deploy in a cloud instance](#deploy-in-a-cloud-instance)

### Install locally with Docker
Official Label Studio docker image is [here](https://hub.docker.com/r/heartexlabs/label-studio) and it can be downloaded with `docker pull`. 
Run Label Studio in a Docker container and access it at `http://localhost:8080`.


```bash
docker pull heartexlabs/label-studio:latest
docker run -it -p 8080:8080 -v `pwd`/mydata:/label-studio/data heartexlabs/label-studio:latest
```
You can find all the generated assets, including SQLite3 database storage `label_studio.sqlite3` and uploaded files, in the `./mydata` directory.

#### Override default Docker install
You can override the default launch command by appending the new arguments:
```bash
docker run -it -p 8080:8080 -v `pwd`/mydata:/label-studio/data heartexlabs/label-studio:latest label-studio --log-level DEBUG
```

#### Build a local image with Docker
If you want to build a local image, run:
```bash
docker build -t heartexlabs/label-studio:latest .
```

### Run with Docker Compose
Docker Compose script provides production-ready stack consisting of the following components:

- Label Studio
- [Nginx](https://www.nginx.com/) - proxy web server used to load various static data, including uploaded audio, images, etc.
- [PostgreSQL](https://www.postgresql.org/) - production-ready database that replaces less performant SQLite3.

To start using the app from `http://localhost` run this command:
```bash
docker-compose up
```

### Install locally with pip

```bash
# Requires Python &gt;=3.7 &lt;=3.9
pip install label-studio

# Start the server at http://localhost:8080
label-studio
```

### Install locally with Anaconda

```bash
conda create --name label-studio
conda activate label-studio
pip install label-studio
```

### Install for local development

You can run the latest Label Studio version locally without installing the package with pip. 

```bash
# Install all package dependencies
pip install -e .
# Run database migrations
python label_studio/manage.py migrate
# Start the server in development mode at http://localhost:8080
python label_studio/manage.py runserver
```

### Deploy in a cloud instance

You can deploy Label Studio with one click in Heroku, Microsoft Azure, or Google Cloud Platform: 

[&lt;img src=&quot;https://www.herokucdn.com/deploy/button.svg&quot; height=&quot;30px&quot;&gt;](https://heroku.com/deploy?template=https://github.com/heartexlabs/label-studio/tree/heroku-persistent-pg)
[&lt;img src=&quot;https://aka.ms/deploytoazurebutton&quot; height=&quot;30px&quot;&gt;](https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fheartexlabs%2Flabel-studio%2Fmaster%2Fazuredeploy.json)
[&lt;img src=&quot;https://deploy.cloud.run/button.svg&quot; height=&quot;30px&quot;&gt;](https://deploy.cloud.run)


#### Apply frontend changes

The frontend part of Label Studio app lies in the `frontend/` folder and written in React JSX. In case you&#039;ve made some changes there, the following commands should be run before building / starting the instance:

```
cd label_studio/frontend/
npm ci
npx webpack
cd ../..
python label_studio/manage.py collectstatic --no-input
```

### Troubleshoot installation
If you see any errors during installation, try to rerun the installation

```bash
pip install --ignore-installed label-studio
```

#### Install dependencies on Windows 
To run Label Studio on Windows, download and install the following wheel packages from [Gohlke builds](https://www.lfd.uci.edu/~gohlke/pythonlibs) to ensure you&#039;re using the correct version of Python:
- [lxml](https://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml)

```bash
# Upgrade pip 
pip install -U pip

# If you&#039;re running Win64 with Python 3.8, install the packages downloaded from Gohlke:
pip install lxml‑4.5.0‑cp38‑cp38‑win_amd64.whl

# Install label studio
pip install label-studio
```

#### Run test suite
```bash
pip install -r deploy/requirements-test.txt
cd label_studio

# postgres (assumes default postgres user,db,pass)
DJANGO_DB=default DJANGO_SETTINGS_MODULE=core.settings.label_studio python -m pytest -vv -n auto

# sqlite3
DJANGO_DB=sqlite DJANGO_SETTINGS_MODULE=core.settings.label_studio python -m pytest -vv -n auto
```


## What you get from Label Studio

![Screenshot of Label Studio data manager grid view with images](https://raw.githubusercontent.com/heartexlabs/label-studio/master/images/labelstudio-ui.gif)

- **Multi-user labeling** sign up and login, when you create an annotation it&#039;s tied to your account.
- **Multiple projects** to work on all your datasets in one instance.
- **Streamlined design** helps you focus on your task, not how to use the software.
- **Configurable label formats** let you customize the visual interface to meet your specific labeling needs.
- **Support for multiple data types** including images, audio, text, HTML, time-series, and video. 
- **Import from files or from cloud storage** in Amazon AWS S3, Google Cloud Storage, or JSON, CSV, TSV, RAR, and ZIP archives. 
- **Integration with machine learning models** so that you can visualize and compare predictions from different models and perform pre-labeling.
- **Embed it in your data pipeline** REST API makes it easy to make it a part of your pipeline

## Included templates for labeling data in Label Studio 

Label Studio includes a variety of templates to help you label your data, or you can create your own using specifically designed configuration language. The most common templates and use cases for labeling include the following cases:

&lt;img src=&quot;https://raw.githubusercontent.com/heartexlabs/label-studio/master/images/templates-categories.jpg&quot; /&gt;

## Set up machine learning models with Label Studio

Connect your favorite machine learning model using the Label Studio Machine Learning SDK. Follow these steps:

1. Start your own machine learning backend server. See [more detailed instructions](https://github.com/heartexlabs/label-studio-ml-backend).
2. Connect Label Studio to the server on the model page found in project settings.

This lets you:

- **Pre-label** your data using model predictions. 
- Do **online learning** and retrain your model while new annotations are being created. 
- Do **active learning** by labeling only the most complex examples in your data.

## Integrate Label Studio with your existing tools

You can use Label Studio as an independent part of your machine learning workflow or integrate the frontend or backend into your existing tools.  

* Use the [Label Studio Frontend](https://github.com/heartexlabs/label-studio-frontend) as a separate React library. See more in the [Frontend Library documentation](https://labelstud.io/guide/frontend.html). 

## Ecosystem

| Project | Description |
|-|-|
| label-studio | Server, distributed as a pip package |
| [label-studio-frontend](https://github.com/heartexlabs/label-studio-frontend) | React and JavaScript frontend and can run standalone in a web browser or be embedded into your application. |  
| [data-manager](https://github.com/heartexlabs/dm2) | React and JavaScript frontend for managing data. Includes the Label Studio Frontend. Relies on the label-studio server or a custom backend with the expected API methods. | 
| [label-studio-converter](https://github.com/heartexlabs/label-studio-converter) | Encode labels in the format of your favorite machine learning library | 
| [label-studio-transformers](https://github.com/heartexlabs/label-studio-transformers) | Transformers library connected and configured for use with Label Studio |


## Roadmap

Want to use **The Coolest Feature X** but Label Studio doesn&#039;t support it? Check out [our public roadmap](roadmap.md)!

## Citation

```tex
@misc{Label Studio,
  title={{Label Studio}: Data labeling software},
  url={https://github.com/heartexlabs/label-studio},
  note={Open source software available from https://github.com/heartexlabs/label-studio},
  author={
    Maxim Tkachenko and
    Mikhail Malyuk and
    Andrey Holmanyuk and
    Nikolai Liubimov},
  year={2020-2022},
}
```

## License

This software is licensed under the [Apache 2.0 LICENSE](/LICENSE) © [Heartex](https://www.heartex.ai/). 2020-2021

&lt;img src=&quot;https://github.com/heartexlabs/label-studio/blob/master/images/opossum_looking.png?raw=true&quot; title=&quot;Hey everyone!&quot; height=&quot;140&quot; width=&quot;140&quot; /&gt;
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[swagger-api/swagger-ui]]></title>
            <link>https://github.com/swagger-api/swagger-ui</link>
            <guid>https://github.com/swagger-api/swagger-ui</guid>
            <pubDate>Sun, 13 Apr 2025 00:28:38 GMT</pubDate>
            <description><![CDATA[Swagger UI is a collection of HTML, JavaScript, and CSS assets that dynamically generate beautiful documentation from a Swagger-compliant API.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/swagger-api/swagger-ui">swagger-api/swagger-ui</a></h1>
            <p>Swagger UI is a collection of HTML, JavaScript, and CSS assets that dynamically generate beautiful documentation from a Swagger-compliant API.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 27,203</p>
            <p>Forks: 9,059</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;https://raw.githubusercontent.com/swagger-api/swagger.io/wordpress/images/assets/SWU-logo-clr.png&quot; width=&quot;300&quot;&gt;

[![NPM version](https://badge.fury.io/js/swagger-ui.svg)](http://badge.fury.io/js/swagger-ui)
[![Build Status](https://jenkins.swagger.io/view/OSS%20-%20JavaScript/job/oss-swagger-ui-master/badge/icon?subject=jenkins%20build)](https://jenkins.swagger.io/view/OSS%20-%20JavaScript/job/oss-swagger-ui-master/)
[![npm audit](https://jenkins.swagger.io/buildStatus/icon?job=oss-swagger-ui-security-audit&amp;subject=npm%20audit)](https://jenkins.swagger.io/job/oss-swagger-ui-security-audit/lastBuild/console)
![total GitHub contributors](https://img.shields.io/github/contributors-anon/swagger-api/swagger-ui.svg)

![monthly npm installs](https://img.shields.io/npm/dm/swagger-ui.svg?label=npm%20downloads)
![docker registry](https://img.shields.io/badge/docker-docker.swagger.io%2Fswaggerapi%2Fswagger--ui-blue)
![monthly packagist installs](https://img.shields.io/packagist/dm/swagger-api/swagger-ui.svg?label=packagist%20installs)
![gzip size](https://img.shields.io/bundlephobia/minzip/swagger-ui.svg?label=gzip%20size)

## Introduction
[Swagger UI](https://swagger.io/tools/swagger-ui/) allows anyone — be it your development team or your end consumers — to visualize and interact with the API’s resources without having any of the implementation logic in place. It’s automatically generated from your OpenAPI (formerly known as Swagger) Specification, with the visual documentation making it easy for back end implementation and client side consumption.

## General
**👉🏼 Want to score an easy open-source contribution?** Check out our [Good first issue](https://github.com/swagger-api/swagger-ui/issues?q=is%3Aissue+is%3Aopen+label%3A%22Good+first+issue%22) label.

**🕰️ Looking for the older version of Swagger UI?** Refer to the [*2.x* branch](https://github.com/swagger-api/swagger-ui/tree/2.x).


This repository publishes three different NPM modules:

* [swagger-ui](https://www.npmjs.com/package/swagger-ui) is a traditional npm module intended for use in single-page applications that are capable of resolving dependencies (via Webpack, Browserify, etc.).
* [swagger-ui-dist](https://www.npmjs.com/package/swagger-ui-dist) is a dependency-free module that includes everything you need to serve Swagger UI in a server-side project, or a single-page application that can&#039;t resolve npm module dependencies.
* [swagger-ui-react](https://www.npmjs.com/package/swagger-ui-react) is Swagger UI packaged as a React component for use in React applications.

We strongly suggest that you use `swagger-ui` instead of `swagger-ui-dist` if you&#039;re building a single-page application, since `swagger-ui-dist` is significantly larger.

If you are looking for plain ol&#039; HTML/JS/CSS, [download the latest release](https://github.com/swagger-api/swagger-ui/releases/latest) and copy the contents of the `/dist` folder to your server.


## Compatibility
The OpenAPI Specification has undergone 5 revisions since initial creation in 2010.  Compatibility between Swagger UI and the OpenAPI Specification is as follows:

| Swagger UI Version | Release Date | OpenAPI Spec compatibility                           | Notes                                                                 |
|--------------------|--------------|------------------------------------------------------|-----------------------------------------------------------------------|
| 5.19.0             | 2025-02-17   | 2.0, 3.0.0, 3.0.1, 3.0.2, 3.0.3, 3.0.4, 3.1.0, 3.1.1 | [tag v5.19.0](https://github.com/swagger-api/swagger-ui/tree/v5.19.0) |
| 5.0.0              | 2023-06-12   | 2.0, 3.0.0, 3.0.1, 3.0.2, 3.0.3, 3.1.0               | [tag v5.0.0](https://github.com/swagger-api/swagger-ui/tree/v5.0.0)   |
| 4.0.0              | 2021-11-03   | 2.0, 3.0.0, 3.0.1, 3.0.2, 3.0.3                      | [tag v4.0.0](https://github.com/swagger-api/swagger-ui/tree/v4.0.0)   |
| 3.18.3             | 2018-08-03   | 2.0, 3.0.0, 3.0.1, 3.0.2, 3.0.3                      | [tag v3.18.3](https://github.com/swagger-api/swagger-ui/tree/v3.18.3) |
| 3.0.21             | 2017-07-26   | 2.0                                                  | [tag v3.0.21](https://github.com/swagger-api/swagger-ui/tree/v3.0.21) |
| 2.2.10             | 2017-01-04   | 1.1, 1.2, 2.0                                        | [tag v2.2.10](https://github.com/swagger-api/swagger-ui/tree/v2.2.10) |
| 2.1.5              | 2016-07-20   | 1.1, 1.2, 2.0                                        | [tag v2.1.5](https://github.com/swagger-api/swagger-ui/tree/v2.1.5)   |
| 2.0.24             | 2014-09-12   | 1.1, 1.2                                             | [tag v2.0.24](https://github.com/swagger-api/swagger-ui/tree/v2.0.24) |
| 1.0.13             | 2013-03-08   | 1.1, 1.2                                             | [tag v1.0.13](https://github.com/swagger-api/swagger-ui/tree/v1.0.13) |
| 1.0.1              | 2011-10-11   | 1.0, 1.1                                             | [tag v1.0.1](https://github.com/swagger-api/swagger-ui/tree/v1.0.1)   |

## Anonymized analytics

SwaggerUI uses [Scarf](https://scarf.sh/) to collect [anonymized installation analytics](https://github.com/scarf-sh/scarf-js?tab=readme-ov-file#as-a-user-of-a-package-using-scarf-js-what-information-does-scarf-js-send-about-me). These analytics help support the maintainers of this library and ONLY run during installation. To [opt out](https://github.com/scarf-sh/scarf-js?tab=readme-ov-file#as-a-user-of-a-package-using-scarf-js-how-can-i-opt-out-of-analytics), you can set the `scarfSettings.enabled` field to `false` in your project&#039;s `package.json`:

```
// package.json
{
  // ...
  &quot;scarfSettings&quot;: {
    &quot;enabled&quot;: false
  }
  // ...
}
```

Alternatively, you can set the environment variable `SCARF_ANALYTICS` to `false` as part of the environment that installs your npm packages, e.g., `SCARF_ANALYTICS=false npm install`.

## Documentation

#### Usage
- [Installation](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/usage/installation.md)
- [Configuration](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/usage/configuration.md)
- [CORS](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/usage/cors.md)
- [OAuth2](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/usage/oauth2.md)
- [Deep Linking](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/usage/deep-linking.md)
- [Limitations](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/usage/limitations.md)
- [Version detection](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/usage/version-detection.md)

#### Customization
- [Overview](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/customization/overview.md)
- [Plugin API](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/customization/plugin-api.md)
- [Custom layout](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/customization/custom-layout.md)

#### Development
- [Setting up](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/development/setting-up.md)
- [Scripts](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/development/scripts.md)

#### Contributing
- [Contributing](https://github.com/swagger-api/.github/blob/HEAD/CONTRIBUTING.md)

##### Integration Tests

You will need JDK of version 7 or higher as instructed here
https://nightwatchjs.org/guide/getting-started/installation.html#install-selenium-server

Integration tests can be run locally with `npm run e2e` - be sure you aren&#039;t running a dev server when testing!

### Browser support
Swagger UI works in the latest versions of Chrome, Safari, Firefox, and Edge.

### Known Issues

To help with the migration, here are the currently known issues with 3.X. This list will update regularly, and will not include features that were not implemented in previous versions.

- Only part of the parameters previously supported are available.
- The JSON Form Editor is not implemented.
- Support for `collectionFormat` is partial.
- l10n (translations) is not implemented.
- Relative path support for external files is not implemented.

## Security contact

Please disclose any security-related issues or vulnerabilities by emailing [security@swagger.io](mailto:security@swagger.io), instead of using the public issue tracker.

## License

SwaggerUI is licensed under [Apache 2.0 license](https://github.com/swagger-api/swagger-ui/blob/master/LICENSE).
SwaggerUI comes with an explicit [NOTICE](https://github.com/swagger-api/swagger-ui/blob/master/NOTICE) file
containing additional legal notices and information.
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[pollinations/pollinations]]></title>
            <link>https://github.com/pollinations/pollinations</link>
            <guid>https://github.com/pollinations/pollinations</guid>
            <pubDate>Sun, 13 Apr 2025 00:28:37 GMT</pubDate>
            <description><![CDATA[Free Open-Source Image and Text Generation]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pollinations/pollinations">pollinations/pollinations</a></h1>
            <p>Free Open-Source Image and Text Generation</p>
            <p>Language: JavaScript</p>
            <p>Stars: 1,578</p>
            <p>Forks: 173</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre># [Pollinations.AI](https://pollinations.ai)

---

## 🆕 Latest News

- **🔍 Special Bee** - New &quot;Special Bee&quot; issue template! Projects can now request referrer verification by submitting a [Domain Verification Request](https://github.com/pollinations/pollinations/issues/new?template=special-bee-request.yml)[More info](https://github.com/pollinations/pollinations/blob/master/APIDOCS.md#special-bee-)
- **📚 API Documentation** - Major API documentation improvements! We&#039;ve completely revamped our API docs with better examples, clearer explanations, and interactive code snippets. [Check it out](https://github.com/pollinations/pollinations/blob/master/APIDOCS.md).
- **🤖 MCP Server** - New Model Context Protocol (MCP) server for AI assistants like Claude to generate images directly! [Learn more](./model-context-protocol/README.md).  
  [![MCP Server Interface](https://github.com/user-attachments/assets/7311a7df-6b6a-4da5-94f8-7d57baca0ba3)](./model-context-protocol/README.md)
- **💲 Support Us** - You can now support us with our new **Tip Us** button. Optionally connect your Discord account to **Ko-Fi** to get premium Discord roles!
- **🎵 Audio Generation** - New text-to-speech and speech-to-text capabilities are now available! Try the `openai-audio` model - see our [API documentation](APIDOCS.md#audio-generation-api) for details.
- **🤖 AI Code Assistant** - We&#039;re excited to announce MentatBot, the autonomous AI coding assistant that implements new features directly from GitHub issues! Simply [create an issue](https://github.com/pollinations/pollinations/issues/new) describing what you&#039;d like to see, and MentatBot will analyze and implement it. [Learn more](https://mentat.ai/).

---

[![Pollinations.AI Logo](https://pollinations.ai/p/3D_wireframe_blueprint_of_the_conceptual_isometric_world_of_Pollinations_AI_a_surreal_hyperrealistic_digital_garden_Elements_emerge_partially_from_all_sides?width=3000&amp;height=1000&amp;seed=-1)](https://pollinations.ai/p/3D_wireframe_blueprint_of_the_conceptual_isometric_world_of_Pollinations_AI_a_surreal_hyperrealistic_digital_garden_Elements_emerge_partially_from_all_sides?width=3000&amp;height=1000&amp;seed=-1)

## 🌟 Introduction

[Pollinations.AI](https://pollinations.ai) is an open-source gen AI startup based in Berlin, providing the most easy-to-use, free text and image generation API available. No signups or API keys required. We prioritize your privacy with zero data storage and completely anonymous usage.

## 🚀 Key Features

- 🔓 **100% Open Source**
- 🆓 **_Free to use_**
- 🔒 **Simplicity and privacy:** No logins, no keys, no data stored
- 🖼️ **Embed like any normal image or text**
- 🎵 **Audio generation:** Text-to-speech and speech-to-text capabilities
- 🌍 Over **50,000 active users** and &gt; **_20 million images generated per month_**
- 🤝 Used by various **open-source LLMs**, **bots**, and **communities**
- 🎣 **_Easy-to-use React hooks_** ([React Hooks Examples](https://react-hooks.pollinations.ai/))
- 🤖 **Autonomous Development:** Features implemented by our MentatBot coding assistant through GitHub issues

&lt;a href=&quot;https://star-history.com/#pollinations/pollinations&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=pollinations/pollinations&amp;type=Date&amp;theme=dark&quot; width=&quot;600&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=pollinations/pollinations&amp;type=Date&quot; width=&quot;600&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=pollinations/pollinations&amp;type=Date&quot; width=&quot;600&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

## 🚀 Getting Started

### Image Generation

1. Visit [https://pollinations.ai](https://pollinations.ai)
2. Type your description in the text box
3. Click &quot;Generate&quot; and watch the magic happen!

### Text Generation

1. Visit [https://text.pollinations.ai](https://text.pollinations.ai)
2. Start chatting with the AI

### Audio Generation

1. Use the `openai-audio` model with our API ([explore voices at OpenAI.fm](https://www.openai.fm/))
2. Generate speech from text or transcribe audio to text

### MCP Server for AI Assistants

Our MCP (Model Context Protocol) server enables AI assistants like Claude to generate images and audio directly. [Learn more](./model-context-protocol/README.md)

```bash
# Run with npx (no installation required)
npx @pollinations/model-context-protocol
```

AI assistants can:
- Generate images from text descriptions
- Create text-to-speech audio with various voice options
- Play audio responses through the system speakers
- Access all Pollinations.AI models and services seamlessly
- List available models, voices, and capabilities

For more advanced usage, check out our [API documentation](APIDOCS.md).

## 🖥️ How to Use

### Web Interface

Our web interface is user-friendly and doesn&#039;t require any technical knowledge. Simply visit [https://pollinations.ai](https://pollinations.ai) and start creating!

### API

Use our API directly in your browser or applications:

    https://pollinations.ai/p/conceptual_isometric_world_of_pollinations_ai_surreal_hyperrealistic_digital_garden

Replace the description with your own, and you&#039;ll get a unique image based on your words!

## 🎨 Examples

### Image Generation

Here&#039;s an example of a generated image:

[![Conceptual Isometric World](https://pollinations.ai/p/3d_wireframe_blueprint_for_the_prompt_conceptual%20isometric%20world%20of%20pollinations%20ai%20surreal%20hyperrealistic%20digital%20garden?width=2000&amp;height=500&amp;nologo=true&amp;seed=-1)](https://pollinations.ai/p/3d_wireframe_blueprint_for_the_prompt_conceptual%20isometric%20world%20of%20pollinations%20ai%20surreal%20hyperrealistic%20digital%20garden?width=2000&amp;height=500&amp;nologo=true&amp;seed=-1)

Python code to download the generated image:

    import requests

    def download_image(prompt):
        url = f&quot;https://pollinations.ai/p/{prompt}&quot;
        response = requests.get(url)
        with open(&#039;generated_image.jpg&#039;, &#039;wb&#039;) as file:
            file.write(response.content)
        print(&#039;Image downloaded!&#039;)

    download_image(&quot;conceptual_isometric_world_of_pollinations_ai_surreal_hyperrealistic_digital_garden&quot;)

### Text Generation

To generate text, use this URL:

    https://text.pollinations.ai/What%20is%20artificial%20intelligence?

### Audio Generation

To generate audio from text, use this URL:

    https://text.pollinations.ai/Welcome%20to%20Pollinations?model=openai-audio&amp;voice=nova

## 🛠️ Integration

### React Hooks

We offer React hooks for easy integration. Example usage:

    import React from &#039;react&#039;;
    import { usePollinationsImage, usePollinationsText } from &#039;@pollinations/react&#039;;
    import ReactMarkdown from &#039;react-markdown&#039;;

    const AIGeneratedContent = () =&gt; {
      const imageUrl = usePollinationsImage(&quot;Beautiful landscape of Paris with Eiffel Tower&quot;, { width: 800, height: 600, seed: 42 });
      const markdown = usePollinationsText(&quot;Write a brief travel guide for Paris, including top attractions and local cuisine in markdown&quot;, { seed: 42 });

      return (
        &lt;div&gt;
          &lt;h2&gt;AI-Generated Travel Guide&lt;/h2&gt;
          &lt;img src={imageUrl} alt=&quot;AI Generated&quot; /&gt;
          {markdown ? (
            &lt;ReactMarkdown&gt;{markdown}&lt;/ReactMarkdown&gt;
          ) : (
            &lt;p&gt;Loading markdown content...&lt;/p&gt;
          )}
        &lt;/div&gt;
      );
    };

    export default AIGeneratedContent;

Check out our [Pollinations React Hooks](./pollinations-react/README.md) for more details.

## Architecture
```mermaid
graph LR
    Q[Bots - Discord, Telegram, WhatsApp] --&gt; L1
    
    N[30+ Mobile and Web Apps] --&gt; L1
    N --&gt; L2
    
    A[pollinations.ai Web Frontend] --&gt; L1
    A --&gt; L2
    
    R[AI Agents - Qwen, Sillytavern, ...] --&gt; L1
    
    AI[AI Assistants - Claude] --&gt; MCP[MCP Server]
    MCP --&gt; L1
    
    L1[Image CDN] --&gt; CF[Cloudflare Worker with R2 Cache]
    L2[Text CDN] --&gt; C
    
    CF --&gt; B
    
    B[image-origin.pollinations.ai - AWS EC2 CPU] --&gt; F[Azure OpenAI - Prompt Enhancing]
    B --&gt; S[LlamaGuard - Safety Checker]
    F --&gt; E[Translation Service - 1 GPU VM]
    E --&gt; D[FLUX image generation model - 2-6 GPU VMs on AWS]
    
    C[text.pollinations.ai - AWS EC2 CPU] --&gt; P[karma.yt - Realtime News]
    C --&gt; SC[Scaleway API]
    C --&gt; DS[Deepseek API]
    C --&gt; G[Azure-hosted Serverless LLMs]
    C --&gt; CFM[Cloudflare AI]
    SC --&gt; MI[Mistral Models]
    SC --&gt; QW[Qwen Models]
    SC --&gt; LL[Llama Models]
    DS --&gt; DM[Deepseek Models]
    G --&gt; H[OpenAI]
    G --&gt; K[Claude]
    CFM --&gt; CFL[Llama &amp; Deepseek Models]
```

## Projects Using Pollinations.AI

Pollinations.AI is used in various projects, including:

### LLM Integrations

| Project | Description | Creator | Links |
|---------|-------------|---------|-------|
| 🆕 Goalani | Voice-enabled AI fitness coach that helps with fitness tracking, nutrition logging, and personalized coaching using voice commands | goalani.app@gmail.com | [Website](https://goalani.com) |
| 🆕 IMyself AI 🇨🇳 | 我们提供高质量的AI生成服务，包括图像生成、文本生成、音频生成和语音转文本服务， 让您轻松创建各种创意内容。 (We provide high-quality AI generation services, including image generation, text generation, audio generation, and speech to text services, allowing you to easily create various creative content.) | Shadownc | [Website](https://openai.lmyself.top/) |
| 🆕 AI Chat Assistant | A comprehensive AI Chat Assistant designed to provide users with an interactive chat interface that supports both text and image generation. Features multiple AI models (GPT-4o, Claude, Qwen-Coder, Llama, Mistral, etc.), image generation from text prompts, image-to-image processing, and a responsive UI with desktop and mobile support | @_dr_misterio_ | [Website](https://seed-ashy.vercel.app/) |
| 🆕 FreeAI 🇨🇳 | An AI application platform based on Pollinations.AI API, providing free and unlimited AI chat assistant, image generation, and voice synthesis services | @Azad-sl | [Website](https://freeai.aihub.ren/), [GitHub](https://github.com/Azad-sl/FreeAI) |
| 🆕 AI Unlimited Customizable Feature Module 🇨🇳 | This project provides a free API interface supporting various text and image generation models, including OpenAI&#039;s GPT-4, Gemini 2.0, etc. Users can access these models without an API key to perform text generation, image generation, translation, text polishing, and more | [S_S](https://linux.do/u/s_s/summary) | [Website](https://getquicker.net/Sharedaction?code=9ac738ed-a4b2-4ded-933c-08dd5f710a8b&amp;fromMyShare=true) |
| 🆕 PrivatePollenAI | A privacy-focused chat assistant app that securely stores data locally, integrates with PollinationAI for text and image generation, features a minimalistic UI, and allows users to choose models and write their own system instructions | [tenacious_humming_bird](https://discordapp.com/users/tenacious_humming_bird) | [Website](https://mmojocoder.github.io/PrivatePollenAI/chat.html), [GitHub](https://github.com/MMojoCoder/PrivatePollenAI) |
| 🆕 Zelos AI image generator | It uses Pollinations for both prompt enhancing and image generation, it was a easy to make project due to pollinations services being easy to use | [Roblox Profile](https://www.roblox.com/users/4361935306/profile) | [Website](https://websim.ai/@ISWEARIAMNOTADDICTEDTOPILLOW/ai-image-prompt-generator) |
| 🆕 MiReXa AI | A state-of-the-art chatbot integrating multiple LLMs with advanced features including audio generation, image generation, mathematical proficiency, and real-time web search | withthatway | [Website](https://mirexa.vercel.app) |
| Pollinations Chat | Pollinations&#039; integrated AI for text and images, totally free and unlimited | @adrianoprogramer | [Website](https://websim.ai/@AdrianoDev1/pollinations-ai-assistant/4), [Instagram](https://www.instagram.com/adrianop_761?igshid=MmxwNnRsajVnZmMy) |
| LobeChat | An open-source, modern-design ChatGPT/LLMs UI/Framework with speech-synthesis, multi-modal, and extensible plugin system | - | [Website](https://lobehub.com/plugins/pollinations-drawing), [GitHub](https://github.com/lobehub/lobe-chat) |
| Qwen-Agent | A framework for developing agentic LLM applications | - | [GitHub](https://github.com/QwenLM/Qwen-Agent) |
| SillyTavern | An LLM frontend for power users. Pollinations permits it to generate images | - | [Docs](https://docs.sillytavern.app/extensions/stable-diffusion/), [GitHub](https://github.com/SillyTavern/SillyTavern) |
| FlowGPT | Generate images on-demand with ChatGPT | - | [Website](https://flowgpt.com/p/instant-image-generation-with-chatgpt-and-pollinationsai) |
| gpt4free | The official gpt4free repository - various collection of powerful language models | xtekky | [GitHub](https://github.com/xtekky/gpt4free) |
| Unity AI Lab | A specialized uncensored LLM model built on Mistral Large, focused on unrestricted conversations | - | [Website](https://blog.unityailab.com/unity.html) |
| DynaSpark AI | A versatile AI assistant with advanced image and text generation capabilities | Th3-C0der | [Website](https://dynaspark.onrender.com), [GitHub](https://github.com/Th3-C0der) |


### Creative &amp; Interactive Applications

| App | Description | Creator | Links |
|-----|-------------|---------|-------|
| 🆕 Podcast #1500 | Podcast project featuring dialogues among LLMs, with first episode featuring 3o-mini and DeepSeek R1 70B discussing Vibe Coding | @brain.diver | [Spotify](https://open.spotify.com/show/1wu4ngb1dclyTwoNN4cZzK) |
| 🆕 LAHGen | An advanced AI-driven text-to-image generation platform designed to provide users with high-quality and realistic AI-generated images based on textual prompts | working7816@gmail.com | [Website](https://image.aixboost.com/) |
| 🆕 Elixpo Art | A Web interface to create thematic images from prompts, with multiple aspect ratios and also image reference inputs | Ayushman Bhattacharya | [Website](https://elixpoart.vercel.app), [GitHub](https://github.com/Circuit-Overtime/elixpo_ai_chapter) |
| 🆕 Riffle | A powerful tool designed to make reading English books more enjoyable and effective while helping you build your vocabulary naturally. Using Pollinations AI to create content that incorporates your own vocabulary words allows you to learn them in a vivid, engaging context. | gsx123@gmail.com | [Website](https://riffle.ink) |
| 🆕 VibeCoder | A web app for coding with vibes, created using Pollinations.AI Open Source API without coding syntax. | @Aashir__Shaikh | [Website](https://vibecoderbyaashir.netlify.app/), [Twitter](https://x.com/Aashir__Shaikh) |
| 🆕 AI 文本转音频 🇨🇳 | 输入文本，选择语音风格，一键将文字转换为自然流畅的语音。 支持多种声音特征，帮您创建专业水准的音频内容。 (Input text, select voice style, and instantly convert text to natural, fluid speech. Supports various voice characteristics to help you create professional-grade audio content.) | https://github.com/Azad-sl | [Website](https://tts-gules-theta.vercel.app/), [GitHub](https://github.com/Azad-sl/tts) |
| 🆕 Case Me 🇧🇷 | O projeto consiste em uma vending machine que criará capinhas para celular personalizadas com fotos ou outras imagens e cores de escolha do cliente final. (A vending machine that creates customized phone cases with photos or other images and colors chosen by the end customer.) | anaboxmania@gmail.com | - |
| 🆕 PixPax | A user-friendly chatbot that lets you analyze images, remix existing images or create new images, all through simple chat. | @andreas_11 | [Website](https://pixpal.chat) |
| 🆕 Watch TV with neko (Roblox) | Roblox game where you can talk with AI catgirls 🐾 or just have fun, talking with other players in cozy rooms ⭐️ | @mangofoxplay | [Roblox](https://www.roblox.com/games/15087497266/UPD-Watch-TV-with-neko-AI) |
| 🆕 Jenny AI | An AI chatbot and character creation platform with tts and sst it also has image generation and vision ability which are powered by pollinations. | HiiiiiPritam | [Website](https://jenny-two.vercel.app/) |
| 🆕 CalcuBite AI | A smart tool that analyzes food from images to provide calorie and nutrient details. Just take a photo, and it quickly gives you an estimate of your meal&#039;s nutritional value. It uses AI for accurate analysis, and if you run out of free scans, you can watch an ad to get more! | @sugamdeol | [Website](https://calcubite.vercel.app/) |
| 🆕 RoastMaster AI | An AI-powered roast generator that allows users to upload selfies for savage AI-generated roasts, enter text for brutal critiques, or engage in roast battles. Images are processed securely on the device, protecting user privacy | @sugamdeol | [Website](https://roastmaster-ai.vercel.app/) |
| 🆕 roastmyselfie.app | AI Personality Analyzer - Get roasted and psychoanalyzed.. just from one selfie! Dare to try? | @andres_11 | [Website](https://roastmyselfie.app) |
| 🆕 StoryMagic: Interactive Kids Stories | An interactive web application designed to create engaging and customizable stories for children. Features AI-powered story generation, customizable themes, interactive elements, visual customization, web search integration, and a user-friendly interface | @_dr_misterio_ | [Website](https://storyai-wizard.vercel.app) |
| 🆕 PromptPix (Android) | An AI-powered image generation platform for Android designed to create stunning visuals from text prompts. Features dynamic image generation as users scroll, save to gallery, favorites, and a user-friendly interface | @taylorsnupe | [Expo](https://expo.dev/accounts/aminmusah/projects/image-generator/builds/ed32c5d0-83c0-416b-889f-e36b997dd706), [GitHub](https://github.com/AminMusah/ai-image-generator) |
| 🆕 AI儿童故事 🇨🇳 | 基于此项目 构建有趣的孩子故事书应用演示 (Based on this project, build an interesting children&#039;s storybook application demo) | MZ | [Website](https://kidss.netlify.app/) |
| 🆕 Herramientas IA | Tools designed with Pollinations.AI and the DescartesJS editor, including tools from other Pollinations.AI community members | @juanrivera126 | [Website](https://proyectodescartes.org/descartescms/herramientas-ia) |
| 🆕 AvatarStudio | A system for creating custom characters that uses the Pollinations API for totally free and unlimited image generation | @nic-wq | [Website](https://astudio-dcae4.web.app) |
| 🆕 Musify - AI Enhanced Music Streaming | Musify is your AI-powered music buddy, making your jam sessions smarter and more fun. It is powered by pollinations api, it offers a slick and intuitive music experience with features like AI Music Assistant, Voice Commands, AI Playlist Creator, and Responsive Design. | @Sugamdeol | [Website](https://musify-sd.vercel.app/) |
| 🆕 image1gen | Website to easily create images via pollinations.ai API | @oopshnik | [Website](https://image1gen.streamlit.app/), [GitHub](https://github.com/oopshnik/image1gen), [HuggingFace](https://huggingface.co/spaces/oopshnik/image_gen) |
| 🆕 AI Image Generator | A web-based AI image generator powered by Pollinations.ai, featuring multi-model support, customizable parameters, and real-time preview | @hrisjeui | [Website](https://fvai.infinityfreeapp.com/my-apps/pollicb09.html), [GitHub](https://github.com/hrisjeui/Multi-text-image-model-pollinations) |
| 🆕 🎵 PolliSonic Generator | An AI-driven tool that transforms text prompts using MidiJourney into MIDI-based melodies through browser oscillators | @brain.diver | [Website](https://interzone.art.br/pollisonic_generator/), [GitHub](https://github.com/rafabez/pollisonic_generator) |
| 🆕 Abyss Ascending | A web-based generative interactive fiction (text adventure) set in a sci-fi underwater world | @brain.diver | [Website](https://interzone.art.br/abyss_ascending/), [GitHub](https://github.com/rafabez/abyss_ascending) |
| 🆕 🎮 Deep Saga | A text based RPG with AI-generated scene images | @jr_7_77 | [Play Store](https://play.google.com/store/apps/details?id=com.cestrian.deepsaga.android&amp;pcampaignid=pollinations) |
| [AI] Character RP (Roblox) | A popular Roblox game for AI character roleplay | @renewed | [Roblox](https://www.roblox.com/games/108463136689847/) |
| MIDIjourney | An AI-powered plugin for Ableton Live that turns text descr

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[sveltejs/svelte]]></title>
            <link>https://github.com/sveltejs/svelte</link>
            <guid>https://github.com/sveltejs/svelte</guid>
            <pubDate>Sun, 13 Apr 2025 00:28:36 GMT</pubDate>
            <description><![CDATA[web development for the rest of us]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sveltejs/svelte">sveltejs/svelte</a></h1>
            <p>web development for the rest of us</p>
            <p>Language: JavaScript</p>
            <p>Stars: 82,217</p>
            <p>Forks: 4,472</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://svelte.dev&quot;&gt;
	&lt;picture&gt;
		&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/banner_dark.png&quot;&gt;
		&lt;img src=&quot;assets/banner.png&quot; alt=&quot;Svelte - web development for the rest of us&quot; /&gt;
	&lt;/picture&gt;
&lt;/a&gt;

[![License](https://img.shields.io/npm/l/svelte.svg)](LICENSE.md) [![Chat](https://img.shields.io/discord/457912077277855764?label=chat&amp;logo=discord)](https://svelte.dev/chat)

## What is Svelte?

Svelte is a new way to build web applications. It&#039;s a compiler that takes your declarative components and converts them into efficient JavaScript that surgically updates the DOM.

Learn more at the [Svelte website](https://svelte.dev), or stop by the [Discord chatroom](https://svelte.dev/chat).

## Supporting Svelte

Svelte is an MIT-licensed open source project with its ongoing development made possible entirely by fantastic volunteers. If you&#039;d like to support their efforts, please consider:

- [Becoming a backer on Open Collective](https://opencollective.com/svelte).

Funds donated via Open Collective will be used for compensating expenses related to Svelte&#039;s development such as hosting costs. If sufficient donations are received, funds may also be used to support Svelte&#039;s development more directly.

## Roadmap

You may view [our roadmap](https://svelte.dev/roadmap) if you&#039;d like to see what we&#039;re currently working on.

## Contributing

Please see the [Contributing Guide](CONTRIBUTING.md) and the [`svelte`](packages/svelte) package for information on contributing to Svelte.

## Is svelte.dev down?

Probably not, but it&#039;s possible. If you can&#039;t seem to access any `.dev` sites, check out [this SuperUser question and answer](https://superuser.com/q/1413402).

## License

[MIT](LICENSE.md)
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[fanmingming/live]]></title>
            <link>https://github.com/fanmingming/live</link>
            <guid>https://github.com/fanmingming/live</guid>
            <pubDate>Sun, 13 Apr 2025 00:28:35 GMT</pubDate>
            <description><![CDATA[✯ 可直连访问的电视/广播图标库与相关工具项目 ✯ 🔕 永久免费 直连访问 完整开源 不断完善的台标 支持IPv4/IPv6双栈访问 🔕]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/fanmingming/live">fanmingming/live</a></h1>
            <p>✯ 可直连访问的电视/广播图标库与相关工具项目 ✯ 🔕 永久免费 直连访问 完整开源 不断完善的台标 支持IPv4/IPv6双栈访问 🔕</p>
            <p>Language: JavaScript</p>
            <p>Stars: 25,260</p>
            <p>Forks: 3,846</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;img alt=&quot;live.fanmingming.com&quot; src=&quot;https://live.fanmingming.com/logo.png&quot;&gt;&lt;/p&gt;
&lt;h1 align=&quot;center&quot;&gt; ✯ 一个可直连访问的电视/广播图标库与相关工具项目 ✯ &lt;/h1&gt;
&lt;h3 align=&quot;center&quot;&gt;🔕 永久免费 直连访问 完整开源 不断完善的台标 支持IPv4/IPv6双栈访问 🔕&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img alt=&quot;GitHub Repo stars&quot; src=&quot;https://img.shields.io/github/stars/fanmingming/live?style=flat-square&quot;&gt;
&lt;img alt=&quot;GitHub forks&quot; src=&quot;https://img.shields.io/github/forks/fanmingming/live?style=flat-square&quot;&gt;
&lt;img alt=&quot;GitHub issues&quot; src=&quot;https://img.shields.io/github/issues/fanmingming/live?style=flat-square&quot;&gt;
&lt;img alt=&quot;GitHub watchers&quot; src=&quot;https://img.shields.io/github/watchers/fanmingming/live?style=flat-square&quot;&gt;
&lt;img alt=&quot;GitHub contributors&quot; src=&quot;https://img.shields.io/github/contributors/fanmingming/live?style=flat-square&quot;&gt;
&lt;img alt=&quot;GitHub&quot; src=&quot;https://img.shields.io/github/license/fanmingming/live?style=flat-square&quot;&gt;
&lt;/p&gt;

---

## 🤹‍♂️使用方法:

### 🌇电视/广播图标库：

| 类 别  | 调用路径                                       | 最后更新   |
|-------|------------------------------------------------|------------|
| 📺电视  | [https://live.fanmingming.cn/tv/{name}.png](https://github.com/fanmingming/live/tree/main/tv) | 2025.04.01    |
| 📻广播  | [https://live.fanmingming.cn/radio/{name}.png](https://github.com/fanmingming/live/tree/main/radio) | 2024.8.29   |

### ⛓️创建您的m3u订阅链接：
 - 下载 `demo.m3u` 空白示例文件并使用文本编辑软件打开。
   - [https://live.fanmingming.cn/tv/m3u/demo.m3u](https://live.fanmingming.cn/tv/m3u/demo.m3u)

 - 参考下方示例代码将`可用的CCTV1节目源`替换为您当地可用的直播源链接，依此类推逐个替换。

```
#EXTM3U x-tvg-url=&quot;https://live.fanmingming.cn/e.xml&quot;
#EXTINF:-1 tvg-name=&quot;CCTV1&quot; tvg-logo=&quot;https://live.fanmingming.cn/tv/CCTV1.png&quot; group-title=&quot;央视&quot;,CCTV-1 综合
可用的CCTV1节目源
此处省略...
```

 - 将编辑完成的m3u文件上传到您的Github仓库。
 - 为您的Github仓库开启Pages。
 - 通过播放器订阅您的m3u链接。

&gt; 关于Github Pages：[https://docs.github.com/en/enterprise-cloud@latest/pages/quickstart](https://docs.github.com/en/enterprise-cloud@latest/pages/quickstart)

## 🛠️工具
- 📆**EPG接口地址**：
  -  [https://live.fanmingming.cn/e.xml](https://live.fanmingming.cn/e.xml)
- 🏞️**Bing每日图片**：
  -  [https://fanmingming.com/bing](https://fanmingming.com/bing)
- 🎞️**m3u8在线下载**：
  -  [https://live.fanmingming.cn/m3u8](https://live.fanmingming.cn/m3u8)
- 🆕**TXT转M3U格式**：
  - [https://live.fanmingming.cn/txt2m3u](https://live.fanmingming.cn/txt2m3u)
- 📄**在线M3U转TXT**：
  - Demo🔗 [https://fanmingming.com/txt?url=https://live.fanmingming.com/tv/m3u/ipv6.m3u](https://fanmingming.com/txt?url=https://live.fanmingming.cn/tv/m3u/ipv6.m3u)
- 🌐**M3U8 Web Player**:
  - Demo🔗 [https://live.fanmingming.cn/player/?vurl=https://0472.org/hls/cgtn.m3u8](https://live.fanmingming.cn/player/?vurl=https://0472.org/hls/cgtn.m3u8)

## 📖说明
- 项目EPG接口为112114.xyz站点分发，本项目无法确保其准确性。
- 通过M3U8 Web Player测试直播源需使用https协议的直播源链接。
- 在线M3U转TXT工具构建在Vercel，不会记录您的访问日志请放心使用。
- TXT转M3U工具为前端网页转换，无需上传文件，粘贴即转换，安全不偷源。
- 本项目不存储任何的流媒体内容，所有的法律责任与后果应由使用者自行承担。
- 项目`/tv/m3u/`和`/radio/m3u/`目录下的内容收集于互联网，仅供测试研究使用，本项目无法保证其有效性。
- 主域名【`live.fanmingming.com`】的WEB访问通过Github Pages自动构建，由CloudFlare提供CDN和安全防护。
- 镜像域名【`live.fanmingming.cn`】提供完整的资源WEB访问，通过Github Actions自动构建在CloudFlare Pages。
- 项目所有文件均托管在[GitHub](https://github.com/fanmingming/live)且自动构建，由项目发起人公益维护，欢迎Star本项目或点击[Issues](https://github.com/fanmingming/live/issues/new/choose)反馈您的问题。
- 您可以Frok本项目到您的Github账户，将缺失的频道Logo上传到`tv`或`radio`目录下并发起拉取请求，收到请求后我们会对您提交的内容进行验证，审核通过后会自动为您署名并发布。

## 📱联系
- Telegram: [@AirfoneBot](https://t.me/AirfoneBot)
  - 如遇资源访问问题请通过Telegram反馈。

## 📔更新
- 2025.04.01
  - 新增北京卫视4K台标。
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[PavelDoGreat/WebGL-Fluid-Simulation]]></title>
            <link>https://github.com/PavelDoGreat/WebGL-Fluid-Simulation</link>
            <guid>https://github.com/PavelDoGreat/WebGL-Fluid-Simulation</guid>
            <pubDate>Sun, 13 Apr 2025 00:28:34 GMT</pubDate>
            <description><![CDATA[Play with fluids in your browser (works even on mobile)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/PavelDoGreat/WebGL-Fluid-Simulation">PavelDoGreat/WebGL-Fluid-Simulation</a></h1>
            <p>Play with fluids in your browser (works even on mobile)</p>
            <p>Language: JavaScript</p>
            <p>Stars: 15,338</p>
            <p>Forks: 1,742</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># WebGL Fluid Simulation

[Play here](https://paveldogreat.github.io/WebGL-Fluid-Simulation/)

&lt;img src=&quot;/screenshot.jpg?raw=true&quot; width=&quot;880&quot;&gt;

## References

https://developer.nvidia.com/gpugems/gpugems/part-vi-beyond-triangles/chapter-38-fast-fluid-dynamics-simulation-gpu

https://github.com/mharrys/fluids-2d

https://github.com/haxiomic/GPU-Fluid-Experiments

## License

The code is available under the [MIT license](LICENSE)
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[lovell/sharp]]></title>
            <link>https://github.com/lovell/sharp</link>
            <guid>https://github.com/lovell/sharp</guid>
            <pubDate>Sun, 13 Apr 2025 00:28:33 GMT</pubDate>
            <description><![CDATA[High performance Node.js image processing, the fastest module to resize JPEG, PNG, WebP, AVIF and TIFF images. Uses the libvips library.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lovell/sharp">lovell/sharp</a></h1>
            <p>High performance Node.js image processing, the fastest module to resize JPEG, PNG, WebP, AVIF and TIFF images. Uses the libvips library.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 30,224</p>
            <p>Forks: 1,321</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># sharp

&lt;img src=&quot;https://cdn.jsdelivr.net/gh/lovell/sharp@main/docs/public/sharp-logo.svg&quot; width=&quot;160&quot; height=&quot;160&quot; alt=&quot;sharp logo&quot; align=&quot;right&quot;&gt;

The typical use case for this high speed Node-API module
is to convert large images in common formats to
smaller, web-friendly JPEG, PNG, WebP, GIF and AVIF images of varying dimensions.

It can be used with all JavaScript runtimes
that provide support for Node-API v9, including
Node.js (^18.17.0 or &gt;= 20.3.0), Deno and Bun.

Resizing an image is typically 4x-5x faster than using the
quickest ImageMagick and GraphicsMagick settings
due to its use of [libvips](https://github.com/libvips/libvips).

Colour spaces, embedded ICC profiles and alpha transparency channels are all handled correctly.
Lanczos resampling ensures quality is not sacrificed for speed.

As well as image resizing, operations such as
rotation, extraction, compositing and gamma correction are available.

Most modern macOS, Windows and Linux systems
do not require any additional install or runtime dependencies.

## Documentation

Visit [sharp.pixelplumbing.com](https://sharp.pixelplumbing.com/) for complete
[installation instructions](https://sharp.pixelplumbing.com/install),
[API documentation](https://sharp.pixelplumbing.com/api-constructor),
[benchmark tests](https://sharp.pixelplumbing.com/performance) and
[changelog](https://sharp.pixelplumbing.com/changelog).

## Examples

```sh
npm install sharp
```

```javascript
const sharp = require(&#039;sharp&#039;);
```

### Callback

```javascript
sharp(inputBuffer)
  .resize(320, 240)
  .toFile(&#039;output.webp&#039;, (err, info) =&gt; { ... });
```

### Promise

```javascript
sharp(&#039;input.jpg&#039;)
  .rotate()
  .resize(200)
  .jpeg({ mozjpeg: true })
  .toBuffer()
  .then( data =&gt; { ... })
  .catch( err =&gt; { ... });
```

### Async/await

```javascript
const semiTransparentRedPng = await sharp({
  create: {
    width: 48,
    height: 48,
    channels: 4,
    background: { r: 255, g: 0, b: 0, alpha: 0.5 }
  }
})
  .png()
  .toBuffer();
```

### Stream

```javascript
const roundedCorners = Buffer.from(
  &#039;&lt;svg&gt;&lt;rect x=&quot;0&quot; y=&quot;0&quot; width=&quot;200&quot; height=&quot;200&quot; rx=&quot;50&quot; ry=&quot;50&quot;/&gt;&lt;/svg&gt;&#039;
);

const roundedCornerResizer =
  sharp()
    .resize(200, 200)
    .composite([{
      input: roundedCorners,
      blend: &#039;dest-in&#039;
    }])
    .png();

readableStream
  .pipe(roundedCornerResizer)
  .pipe(writableStream);
```

## Contributing

A [guide for contributors](https://github.com/lovell/sharp/blob/main/.github/CONTRIBUTING.md)
covers reporting bugs, requesting features and submitting code changes.

## Licensing

Copyright 2013 Lovell Fuller and others.

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
[https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[GoogleChrome/chrome-extensions-samples]]></title>
            <link>https://github.com/GoogleChrome/chrome-extensions-samples</link>
            <guid>https://github.com/GoogleChrome/chrome-extensions-samples</guid>
            <pubDate>Sun, 13 Apr 2025 00:28:32 GMT</pubDate>
            <description><![CDATA[Chrome Extensions Samples]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GoogleChrome/chrome-extensions-samples">GoogleChrome/chrome-extensions-samples</a></h1>
            <p>Chrome Extensions Samples</p>
            <p>Language: JavaScript</p>
            <p>Stars: 16,271</p>
            <p>Forks: 8,529</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># Chrome Extensions samples

Official samples for Chrome Extensions and the Chrome Apps platform. (Chrome Apps are deprecated. Learn more [on the Chromium blog](https://blog.chromium.org/2020/08/changes-to-chrome-app-support-timeline.html)).

For more information on extensions, see [Chrome Developers](https://developer.chrome.com).

## Explore samples

The directory structure is as follows:

- [api-samples/](api-samples/) - extensions focused on a single API package
- [functional-samples/](functional-samples/) - full featured extensions spanning multiple API packages
- [\_archive/apps/](_archive/apps/) - deprecated Chrome Apps platform (not listed below)
- [\_archive/mv2/](_archive/mv2/) - resources for manifest version 2

You can also use the [Samples](https://developer.chrome.com/docs/extensions/samples/) page to discover extensions by type, permissions, and extension API.

## Installation

To experiment with these samples, please clone this repo and use &#039;Load Unpacked Extension&#039;.
Read more on [Development Basics](https://developer.chrome.com/docs/extensions/mv3/getstarted/development-basics/#load-unpacked).

## Contributing

Please see [the CONTRIBUTING file](/CONTRIBUTING.md) for information on contributing to the `chrome-extensions-samples` project.

## License

`chrome-extensions-samples` are authored by Google and are licensed under the [Apache License, Version 2.0](/LICENSE).
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[openai/openai-realtime-console]]></title>
            <link>https://github.com/openai/openai-realtime-console</link>
            <guid>https://github.com/openai/openai-realtime-console</guid>
            <pubDate>Sun, 13 Apr 2025 00:28:31 GMT</pubDate>
            <description><![CDATA[React app for inspecting, building and debugging with the Realtime API]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/openai-realtime-console">openai/openai-realtime-console</a></h1>
            <p>React app for inspecting, building and debugging with the Realtime API</p>
            <p>Language: JavaScript</p>
            <p>Stars: 3,130</p>
            <p>Forks: 1,177</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># OpenAI Realtime Console

This is an example application showing how to use the [OpenAI Realtime API](https://platform.openai.com/docs/guides/realtime) with [WebRTC](https://platform.openai.com/docs/guides/realtime-webrtc).

## Installation and usage

Before you begin, you&#039;ll need an OpenAI API key - [create one in the dashboard here](https://platform.openai.com/settings/api-keys). Create a `.env` file from the example file and set your API key in there:

```bash
cp .env.example .env
```

Running this application locally requires [Node.js](https://nodejs.org/) to be installed. Install dependencies for the application with:

```bash
npm install
```

Start the application server with:

```bash
npm run dev
```

This should start the console application on [http://localhost:3000](http://localhost:3000).

This application is a minimal template that uses [express](https://expressjs.com/) to serve the React frontend contained in the [`/client`](./client) folder. The server is configured to use [vite](https://vitejs.dev/) to build the React frontend.

This application shows how to send and receive Realtime API events over the WebRTC data channel and configure client-side function calling. You can also view the JSON payloads for client and server events using the logging panel in the UI.

For a more comprehensive example, see the [OpenAI Realtime Agents](https://github.com/openai/openai-realtime-agents) demo built with Next.js, using an agentic architecture inspired by [OpenAI Swarm](https://github.com/openai/swarm).

## Previous WebSockets version

The previous version of this application that used WebSockets on the client (not recommended in browsers) [can be found here](https://github.com/openai/openai-realtime-console/tree/websockets).

## License

MIT
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[DataDog/documentation]]></title>
            <link>https://github.com/DataDog/documentation</link>
            <guid>https://github.com/DataDog/documentation</guid>
            <pubDate>Sun, 13 Apr 2025 00:28:30 GMT</pubDate>
            <description><![CDATA[The source for Datadog's documentation site.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DataDog/documentation">DataDog/documentation</a></h1>
            <p>The source for Datadog's documentation site.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 509</p>
            <p>Forks: 1,160</p>
            <p>Stars today: 0 stars today</p>
            <h2>README</h2><pre># Documentation site for Datadog

Welcome to the Datadog documentation repository. The markdown stored in this repo is published to the [Datadog documentation site][17] using [hugo][1], a static website generation tool.

## Contribute to the docs

Contributions are encouraged! If you notice something on one of the pages that needs an edit, open a pull request in this repo for the documentation team to review

Most pages on the documentation site feature an **Edit** button that sends you to the source file in this repo. You can make an edit straight from the GitHub website!

![The edit button on a docs page](static/images/edit_link.png)

For more information on contributing, see the [contribution guidelines][18].

## Working on Docs

### Outside Contributors
Follow these steps if you are NOT a Datadog employee:

- Fork the master branch.
- Consult our [contributing guidelines][8].
- When you&#039;re ready to finalize your changes, commit them and make a pull request back to `DataDog/master`.
- A Datadog technical writer might change your PR title with a DOCS ticket number, such as &quot;[DOCS-9000],&quot; which means it has been added to the team&#039;s internal Jira queue to triage and review. No action is necessary from you if we change the title of your PR.

### Datadog Staff
Follow these steps if you are a Datadog employee:

- Always branch off of master; never commit directly to master.
- You MUST name your branch `&lt;name&gt;/&lt;description&gt;`. If you do not include the forward slash (`/`), the GitLab pipeline won&#039;t run, you won&#039;t get a branch preview, and your pull request will not pass in CI. Getting a branch preview makes it easier for us to check for any issues with your PR, such as broken links. Using a [Slack username][21] also ensures you get build notifications in Slack.
- Consult our [contributing guidelines][8].
- When you&#039;re ready to commit, create a new pull request to master from your branch.
- Use GitHub&#039;s [draft pull request][15] feature and appropriate labels such as &quot;Do Not Merge&quot; or &quot;Work in Progress&quot; until your PR is ready to be merged and live on production.
- If you&#039;ve named your branch correctly, a GitHub bot posts a link to the docs preview website for your PR. After the preview build completes, you can use the link to preview your changes.
- Running the build locally is optional. If you followed the branch naming conventions above, your pull request should generate a preview. For information on local builds, see the [Build setup guide][20].

### A note about markdown

This site uses [Goldmark][9] for markdown, which is compliant with [CommonMark 0.29][10].

If you include ANY Markdown in a file, give it a `.md` extension.

Make sure all files are lowercase. Macs are case-insensitive when creating links to images and pages, but our build server is not, so tests may work locally, but the site will fail in production.

## Releasing

Merging to `master` triggers an automatic deployment. This process typically begins within 10 minutes and usually takes around 35 minutes to complete, though these times may vary. 

## How to add a new integration

[See the dedicated doc page][11].

[1]: https://gohugo.io
[2]: https://nodejs.org/en/download/package-manager#macos
[3]: https://www.python.org/downloads
[4]: https://github.com/pyenv/pyenv#unixmacos
[5]: https://github.com/DataDog/documentation/blob/master/Makefile.config.example
[6]: https://github.com/DataDog/documentation/wiki/Github-personal-token
[7]: https://github.com/DataDog/documentation/wiki/Documentation-Build
[8]: https://github.com/DataDog/documentation/blob/master/CONTRIBUTING.md
[9]: https://github.com/yuin/goldmark
[10]: https://spec.commonmark.org/0.29/
[11]: https://docs.datadoghq.com/developers/integrations
[12]: https://www.docker.com/products/docker-desktop/
[13]: https://gohugo.io/getting-started/installing/
[14]: https://golang.org/doc/install
[15]: https://github.blog/2019-02-14-introducing-draft-pull-requests/
[16]: https://github.com/DataDog/documentation#docker-development
[17]: https://docs.datadoghq.com
[18]: /CONTRIBUTING.md
[19]: https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account
[20]: https://datadoghq.atlassian.net/wiki/spaces/docs4docs/pages/3960766866/Build+setup+guide
[21]: https://www.highviewapps.com/kb/how-do-i-find-my-slack-username/
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
    </channel>
</rss>