<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for javascript - JavaScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for javascript.</description>
        <lastBuildDate>Sat, 28 Jun 2025 00:04:36 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[automatisch/automatisch]]></title>
            <link>https://github.com/automatisch/automatisch</link>
            <guid>https://github.com/automatisch/automatisch</guid>
            <pubDate>Sat, 28 Jun 2025 00:04:36 GMT</pubDate>
            <description><![CDATA[The open source Zapier alternative. Build workflow automation without spending time and money.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/automatisch/automatisch">automatisch/automatisch</a></h1>
            <p>The open source Zapier alternative. Build workflow automation without spending time and money.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 12,100</p>
            <p>Forks: 884</p>
            <p>Stars today: 183 stars today</p>
            <h2>README</h2><pre># Automatisch - Open Source Zapier Alternative

![Automatisch - Screenshot](https://user-images.githubusercontent.com/2501931/191562539-e42f6c34-03c7-4dc4-bcf9-7f9473a9c64f.png)

🧐 Automatisch is a business automation tool that lets you connect different services like Twitter, Slack, and more to automate your business processes.

💸 Automating your workflows doesn&#039;t have to be a difficult or expensive process. You also don&#039;t need any programming knowledge to use Automatisch.

## Advantages

There are other existing solutions in the market, like Zapier and Integromat, so you might be wondering why you should use Automatisch.

✅ One of the main benefits of using Automatisch is that it allows you to store your data on your own servers, which is essential for businesses that handle sensitive user information and cannot risk sharing it with external cloud services. This is especially relevant for industries such as healthcare and finance, as well as for European companies that must adhere to the General Data Protection Regulation (GDPR).

🤓 Your contributions are vital to the development of Automatisch. As an open-source software, anyone can have an impact on how it is being developed.

💙 No vendor lock-in. If you ever decide that Automatisch is no longer helpful for your business, you can switch to any other provider, which will be easier than switching from the one cloud provider to another since you have all data and flexibility.

## Documentation

The official documentation can be found here: [https://automatisch.io/docs](https://automatisch.io/docs)

## Installation

```bash
# Clone the repository
git clone https://github.com/automatisch/automatisch.git

# Go to the repository folder
cd automatisch

# Start
docker compose up
```

You can use `user@automatisch.io` email address and `sample` password to login to Automatisch. Please do not forget to change your email and password from the settings page.

For other installation types, you can check the [installation](https://automatisch.io/docs/guide/installation) guide.

## Community Links

- [Discord](https://discord.gg/dJSah9CVrC)
- [Twitter](https://twitter.com/automatischio)

## Support

If you have any questions or problems, please visit our GitHub issues page, and we&#039;ll try to help you as soon as possible.

[https://github.com/automatisch/automatisch/issues](https://github.com/automatisch/automatisch/issues)

## License

Automatisch Community Edition (Automatisch CE) is an open-source software with the [AGPL-3.0 license](LICENSE.agpl).

Automatisch Enterprise Edition (Automatisch EE) is a commercial offering with the [Enterprise license](LICENSE.enterprise).

The Automatisch repository contains both AGPL-licensed and Enterprise-licensed files. We maintain a single repository to make development easier.

All files that contain &quot;.ee.&quot; in their name fall under the [Enterprise license](LICENSE.enterprise). All other files fall under the [AGPL-3.0 license](LICENSE.agpl).

See the [LICENSE](LICENSE) file for more information.
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[pot-app/pot-desktop]]></title>
            <link>https://github.com/pot-app/pot-desktop</link>
            <guid>https://github.com/pot-app/pot-desktop</guid>
            <pubDate>Sat, 28 Jun 2025 00:04:35 GMT</pubDate>
            <description><![CDATA[🌈一个跨平台的划词翻译和OCR软件 | A cross-platform software for text translation and recognition.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pot-app/pot-desktop">pot-app/pot-desktop</a></h1>
            <p>🌈一个跨平台的划词翻译和OCR软件 | A cross-platform software for text translation and recognition.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 13,069</p>
            <p>Forks: 600</p>
            <p>Stars today: 202 stars today</p>
            <h2>README</h2><pre>&lt;img width=&quot;200px&quot; src=&quot;public/icon.svg&quot; align=&quot;left&quot;/&gt;

# Pot (派了个萌的翻译器)

&gt; 🌈 一个跨平台的划词翻译软件 ([QQ 频道](https://pd.qq.com/s/akns94e1r))

![License](https://img.shields.io/github/license/pot-app/pot-desktop.svg)
![Tauri](https://img.shields.io/badge/Tauri-1.6.8-blue?logo=tauri)
![JavaScript](https://img.shields.io/badge/-JavaScript-yellow?logo=javascript&amp;logoColor=white)
![Rust](https://img.shields.io/badge/-Rust-orange?logo=rust&amp;logoColor=white)
![Windows](https://img.shields.io/badge/-Windows-blue?logo=windows&amp;logoColor=white)
![MacOS](https://img.shields.io/badge/-macOS-black?&amp;logo=apple&amp;logoColor=white)
![Linux](https://img.shields.io/badge/-Linux-yellow?logo=linux&amp;logoColor=white)

&lt;br/&gt;
&lt;hr/&gt;
&lt;div align=&quot;center&quot;&gt;

&lt;h3&gt;中文 | &lt;a href=&#039;./README_EN.md&#039;&gt;English&lt;/a&gt; | &lt;a href=&#039;./README_KR.md&#039;&gt; 한글 &lt;/a&gt;&lt;/h3&gt;

&lt;table&gt;
&lt;tr&gt;
    &lt;td&gt; &lt;img src=&quot;asset/1.png&quot;&gt;
    &lt;td&gt; &lt;img src=&quot;asset/2.png&quot;&gt;
    &lt;td&gt; &lt;img src=&quot;asset/3.png&quot;&gt;
&lt;/table&gt;

# 目录

&lt;/div&gt;

-   [使用说明](#使用说明)
-   [特色功能](#特色功能)
-   [支持接口](#支持接口)
-   [插件系统](#插件系统)
-   [安装指南](#安装指南)
-   [外部调用](#外部调用)
-   [Wayland 支持](#wayland-支持)
-   [国际化](#国际化weblate)
-   [贡献者](#贡献者)
-   [感谢](#感谢)

&lt;div align=&quot;center&quot;&gt;

# 使用说明

| 划词翻译                                             | 输入翻译                                                       | 外部调用                                                             |
| ---------------------------------------------------- | -------------------------------------------------------------- | -------------------------------------------------------------------- |
| 鼠标选中需要翻译的文本，按下设置的划词翻译快捷键即可 | 按下输入翻译快捷键呼出翻译窗口，输入待翻译文本后按下 回车 翻译 | 通过被其他软件调用实现更加方便高效的功能, 详见 [外部调用](#外部调用) |
| &lt;img src=&quot;asset/eg1.gif&quot;/&gt;                           | &lt;img src=&quot;asset/eg2.gif&quot;/&gt;                                     | &lt;img src=&quot;asset/eg3.gif&quot;/&gt;                                           |

| 剪切板监听模式                                                         | 截图 OCR                                          | 截图翻译                                         |
| ---------------------------------------------------------------------- | ------------------------------------------------- | ------------------------------------------------ |
| 在任意翻译面板上点击左上角图标启动剪切板监听默认，复制文字即可完成翻译 | 按下截图 OCR 快捷键后框选需要识别区域即可完成识别 | 按下截图翻译快捷键后框选需要识别区域即可完成翻译 |
| &lt;img src=&quot;asset/eg4.gif&quot;/&gt;                                             | &lt;img src=&quot;asset/eg5.gif&quot;/&gt;                        | &lt;img src=&quot;asset/eg6.gif&quot;/&gt;                       |

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

# 特色功能

&lt;/div&gt;

-   [x] 多接口并行翻译 ([支持接口](#支持接口))
-   [x] 多接口文字识别 ([支持接口](#支持接口))
-   [x] 多接口语音合成 ([支持接口](#支持接口))
-   [x] 导出到生词本 ([支持接口](#支持接口))
-   [x] 外部调用 ([详情](#外部调用))
-   [x] 支持插件系统 ([插件系统](#插件系统))
-   [x] 支持所有 PC 平台 (Windows, macOS, Linux)
-   [x] 支持 Wayland (在 KDE、Gnome 以及 Hyprland 上测试)
-   [x] 多语言支持

&lt;div align=&quot;center&quot;&gt;

# 支持接口

&lt;/div&gt;

## 翻译

-   [x] [OpenAI](https://platform.openai.com/)
-   [x] [智谱 AI](https://www.zhipuai.cn/)
-   [x] [Gemini Pro](https://gemini.google.com/)
-   [x] [Ollama](https://www.ollama.com/) (离线)
-   [x] [阿里翻译](https://www.aliyun.com/product/ai/alimt)
-   [x] [百度翻译](https://fanyi.baidu.com/)
-   [x] [彩云小译](https://fanyi.caiyunapp.com/)
-   [x] [腾讯翻译君](https://fanyi.qq.com/)
-   [x] [腾讯交互翻译](https://transmart.qq.com/)
-   [x] [火山翻译](https://translate.volcengine.com/)
-   [x] [小牛翻译](https://niutrans.com/)
-   [x] [Google](https://translate.google.com)
-   [x] [Bing](https://learn.microsoft.com/zh-cn/azure/cognitive-services/translator/)
-   [x] [Bing 词典](https://www.bing.com/dict)
-   [x] [DeepL](https://www.deepl.com/)
-   [x] [有道翻译](https://ai.youdao.com/)
-   [x] [剑桥词典](https://dictionary.cambridge.org/)
-   [x] [Yandex](https://translate.yandex.com/)
-   [x] [Lingva](https://github.com/TheDavidDelta/lingva-translate) ([插件](https://github.com/pot-app/pot-app-translate-plugin-template))
-   [x] [Tatoeba](https://tatoeba.org/) ([插件](https://github.com/pot-app/pot-app-translate-plugin-tatoeba))
-   [x] [ECDICT](https://github.com/skywind3000/ECDICT) ([插件](https://github.com/pot-app/pot-app-translate-plugin-ecdict))

更多接口支持见 [插件系统](#插件系统)

## 文字识别

-   [x] 系统 OCR (离线)
    -   [x] [Windows.Media.OCR](https://learn.microsoft.com/en-us/uwp/api/windows.media.ocr.ocrengine?view=winrt-22621) on Windows
    -   [x] [Apple Vision Framework](https://developer.apple.com/documentation/vision/recognizing_text_in_images) on MacOS
    -   [x] [Tesseract OCR](https://github.com/tesseract-ocr) on Linux
-   [x] [Tesseract.js](https://tesseract.projectnaptha.com/) (离线)
-   [x] [百度](https://ai.baidu.com/tech/ocr/general)
-   [x] [腾讯](https://cloud.tencent.com/product/ocr-catalog)
-   [x] [火山](https://www.volcengine.com/product/OCR)
-   [x] [迅飞](https://www.xfyun.cn/services/common-ocr)
-   [x] [腾讯图片翻译](https://cloud.tencent.com/document/product/551/17232)
-   [x] [百度图片翻译](https://fanyi-api.baidu.com/product/22)
-   [x] [Simple LaTeX](https://simpletex.cn/)
-   [x] [OCRSpace](https://ocr.space/) ([插件](https://github.com/pot-app/pot-app-recognize-plugin-template))
-   [x] [Rapid](https://github.com/RapidAI/RapidOcrOnnx) (离线 [插件](https://github.com/pot-app/pot-app-recognize-plugin-rapid))
-   [x] [Paddle](https://github.com/hiroi-sora/PaddleOCR-json) (离线 [插件](https://github.com/pot-app/pot-app-recognize-plugin-paddle))

更多接口支持见 [插件系统](#插件系统)

## 语音合成

-   [x] [Lingva](https://github.com/thedaviddelta/lingva-translate)

更多接口支持见 [插件系统](#插件系统)

## 生词本

-   [x] [Anki](https://apps.ankiweb.net/)
-   [x] [欧路词典](https://dict.eudic.net/)
-   [x] [有道](https://www.youdao.com/) ([插件](https://github.com/pot-app/pot-app-collection-plugin-youdao))
-   [x] [扇贝](https://web.shanbay.com/web/main) ([插件](https://github.com/pot-app/pot-app-collection-plugin-shanbay))

更多接口支持见 [插件系统](#插件系统)

&lt;div align=&quot;center&quot;&gt;

# 插件系统

&lt;/div&gt;

软件内置接口数量有限，但是您可以通过插件系统来扩展软件的功能。

## 插件安装

你可以在 [Plugin List](https://pot-app.com/plugin.html) 查找你需要的插件，然后前往插件仓库下载插件。

pot 插件的扩展名为 `.potext`, 下载得到`.potext`文件之后， 在 偏好设置-服务设置-添加外部插件-安装外部插件 选择对应的 `.potext` 即可安装成功，添加到服务列表中即可像内置服务一样正常使用了。

### 故障排除

-   找不到指定的模块 (Windows)

    出现类似这样的报错是因为系统缺少 C++库，前往[这里](https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist?view=msvc-170#visual-studio-2015-2017-2019-and-2022)安装即可解决问题。

-   不是有效的 Win32 应用程序 (Windows)

    出现类似这样的报错说明你没有下载对应系统或者架构的插件，前往插件仓库下载正确的插件即可解决问题。

## 插件开发

在 [Plugin List](https://pot-app.com/plugin.html) 中的 [模板](https://pot-app.com/plugin.html#%E6%A8%A1%E6%9D%BF) 章节提供了各种插件的开发模板，具体的开发文档请查看对应的模板仓库。

&lt;div align=&quot;center&quot;&gt;

# 安装指南

&lt;/div&gt;

## Windows

### 通过 Winget 安装

```powershell
winget install Pylogmon.pot
```

### 手动安装

1. 在 [Release](https://github.com/pot-app/pot-desktop/releases/latest) 页面下载最新 `exe` 安装包。

    - 64 位机器下载 `pot_{version}_x64-setup.exe`
    - 32 位机器下载 `pot_{version}_x86-setup.exe`
    - arm64 机器下载 `pot_{version}_arm64-setup.exe`

2. 双击安装包进行安装。

### 故障排除

-   启动后没有界面，点击托盘图标没有反应

    检查是否卸载/禁用了 WebView2，如果卸载/禁用了 WebView2，请手动安装 WebView2 或将其恢复。

    如果是企业版系统不方便安装或无法安装 WebView2，请尝试在 [Release](https://github.com/pot-app/pot-desktop/releases/latest) 下载内置 WebView2 的版本 `pot_{version}_{arch}_fix_webview2_runtime-setup.exe`

    若问题仍然存在请尝试使用 Windows7 兼容模式启动。

## MacOS

### 通过 Brew 安装

1. 添加我们的 tap:

```bash
brew tap pot-app/homebrew-tap
```

2. 安装 pot:

```bash
brew install --cask pot
```

3. 更新 pot

```bash
brew upgrade --cask pot
```

### 手动安装

1. 从 [Release](https://github.com/pot-app/pot-desktop/releases/latest) 页面下载最新的 `dmg` 安装包。（如果您使用的是 M1 芯片，请下载名为`pot_{version}_aarch64.dmg`的安装包，否则请下载名为`pot_{version}_x64.dmg`的安装包）
2. 双击下载的文件后将 pot 拖入 Applications 文件夹即可完成安装。

### 故障排除

-   由于开发者无法验证，“pot”无法打开。

    点击 取消 按钮，然后去 设置 -&gt; 隐私与安全性 页面，点击 仍要打开 按钮，然后在弹出窗口里点击 打开 按钮即可，以后打开 pot 就再也不会有任何弹窗告警了

    如果在 隐私与安全性 中找不到以上选项，或启动时提示文件损坏。打开 Terminal.app，并输入以下命令，然后重启 pot 即可：

    ```bash
    sudo xattr -d com.apple.quarantine /Applications/pot.app
    ```

-   如果每次打开时都遇到辅助功能权限提示，或者无法进行划词翻译，请前往设置 -&gt; 隐私与安全 -&gt; 辅助功能，移除 “pot”，并重新添加 “pot”。

## Linux

### Debian/Ubuntu

1. 从 [Release](https://github.com/pot-app/pot-desktop/releases/latest) 页面下载最新的对应架构的 `deb` 安装包。

2. 使用 `apt-get` 进行安装

    ```bash
    sudo apt-get install ./pot_{version}_amd64.deb
    ```

### Arch/Manjaro

&gt; [!WARNING]
&gt; 在最新版本的 [Webkit2Gtk](https://archlinux.org/packages/extra/x86_64/webkit2gtk) (2.42.0) 中，由于 Nvidia 专有驱动未完全实现 DMABUF，将导致无法启动和崩溃的情况发生。&lt;br&gt;
&gt; 请降级或在 `/etc/environment` （或者其他设置环境变量的地方）中加入 `WEBKIT_DISABLE_DMABUF_RENDERER=1` 环境变量关闭 DMABUF 的使用。

1. 在 [AUR](https://aur.archlinux.org/packages?O=0&amp;K=pot-translation) 查看

使用 `AUR helper` 安装：

```bash
yay -S pot-translation # 或 pot-translation-bin

# paru -S pot-translation # 或 pot-translation-bin
```

2. 如果你使用 `archlinuxcn` 源，可以直接使用 pacman 安装

```bash
sudo pacman -S pot-translation
```

### Flatpak

&gt; [!WARNING]
&gt; Flatpak 版本缺失托盘图标。

&lt;a href=&#039;https://flathub.org/apps/com.pot_app.pot&#039;&gt;
    &lt;img width=&#039;240&#039; alt=&#039;Download on Flathub&#039; src=&#039;https://flathub.org/api/badge?locale=zh-Hans&#039;/&gt;
&lt;/a&gt;

&lt;div align=&quot;center&quot;&gt;

# 外部调用

&lt;/div&gt;

Pot 提供了完整的 HTTP 接口，以便可以被其他软件调用。您可以通过向 `127.0.0.1:port` 发送 HTTP 请求来调用 pot，其中的`port`是 pot 监听的端口号，默认为`60828`,可以在软件设置中进行更改。

## API 文档:

```bash
POST &quot;/&quot; =&gt; 翻译指定文本(body为需要翻译的文本),
GET &quot;/config&quot; =&gt; 打开设置,
POST &quot;/translate&quot; =&gt; 翻译指定文本(同&quot;/&quot;),
GET &quot;/selection_translate&quot; =&gt; 划词翻译,
GET &quot;/input_translate&quot; =&gt; 输入翻译,
GET &quot;/ocr_recognize&quot; =&gt; 截图OCR,
GET &quot;/ocr_translate&quot; =&gt; 截图翻译,
GET &quot;/ocr_recognize?screenshot=false&quot; =&gt; 截图OCR(不使用软件内截图),
GET &quot;/ocr_translate?screenshot=false&quot; =&gt; 截图翻译(不使用软件内截图),
GET &quot;/ocr_recognize?screenshot=true&quot; =&gt; 截图OCR,
GET &quot;/ocr_translate?screenshot=true&quot; =&gt; 截图翻译,
```

## 示例：

-   调用划词翻译：

    如果想要调用 pot 划词翻译，只需向`127.0.0.1:port`发送请求即可。

    例如通过 curl 发送请求：

    ```bash
    curl &quot;127.0.0.1:60828/selection_translate&quot;
    ```

## 不使用软件内截图

这一功能可以让您在不使用软件内截图的情况下调用截图 OCR/截图翻译功能，这样您就可以使用您喜欢的截图工具来截图了，也可以解决在某些平台下 pot 自带的截图无法使用的问题。

### 调用流程

1. 使用其他截图工具截图
2. 将截图保存在 `$CACHE/com.pot-app.desktop/pot_screenshot_cut.png`
3. 向`127.0.0.1:port/ocr_recognize?screenshot=false`发送请求即可调用成功

&gt; `$CACHE`为系统缓存目录，例如在 Windows 上为`C:\Users\{用户名}\AppData\Local\com.pot-app.desktop\pot_screenshot_cut.png`

### 示例

在 Linux 下调用 Flameshot 进行截图 OCR:

```bash
rm ~/.cache/com.pot-app.desktop/pot_screenshot_cut.png &amp;&amp; flameshot gui -s -p ~/.cache/com.pot-app.desktop/pot_screenshot_cut.png &amp;&amp; curl &quot;127.0.0.1:60828/ocr_recognize?screenshot=false&quot;
```

## 现有用法 (快捷划词翻译)

### SnipDo (Windows)

1. 从 [Microsoft Store](https://apps.microsoft.com/store/detail/snipdo/9NPZ2TVKJVT7) 下载安装 SnipDo。
2. 从 [Release](https://github.com/pot-app/pot-desktop/releases/latest) 下载 pot 的 SnipDo 扩展 (pot.pbar)
3. 双击下载的扩展文件完成安装。
4. 选中文字，可以看到弹出的 SnipDo 工具条，点击翻译按钮即可翻译。

### PopClip (MacOS)

1. 从 [App Store](https://apps.apple.com/us/app/popclip/id445189367?mt=12) 下载安装 PopClip
2. 从 [Release](https://github.com/pot-app/pot-desktop/releases/latest) 下载 pot 的 PopClip 扩展 (pot.popclipextz)
3. 双击下载的扩展文件完成安装。
4. 在 PopClip 的扩展中启用 pot 扩展，选中文本即可点击翻译。

### Starry (Linux)

&gt; Starry 目前仍处于开发阶段，因此您只能手动编译它。

Github: [ccslykx/Starry](https://github.com/ccslykx/Starry)

&lt;div align=&quot;center&quot;&gt;

# Wayland 支持

&lt;/div&gt;

由于各大发行版对于 Wayland 的支持程度不同，所以 pot 本身没法做到特别完美的支持，这里可以提供一些常见问题的解决方案，通过合理的设置之后，pot 也可以在 Wayland 下完美运行。

## 快捷键无法使用

由于 Tauri 的快捷键方案并没有支持 Wayland，所以 pot 应用内的快捷键设置在 Wayland 下无法使用。 您可以设置系统快捷用 curl 发送请求来触发 pot，详见[外部调用](#外部调用)

## 截图无法使用

在一些纯 Wayland 桌面环境/窗口管理器(如 Hyprland)上，pot 内置的截图无法使用，这时可以通过使用其他截图工具代替，详见 [不使用软件内截图](#不使用软件内截图)

下面给出在 Hyprland 下的配置示例(通过 grim 和 slurp 实现截图)：

```conf
bind = ALT, X, exec, grim -g &quot;$(slurp)&quot; ~/.cache/com.pot-app.desktop/pot_screenshot_cut.png &amp;&amp; curl &quot;127.0.0.1:60828/ocr_recognize?screenshot=false&quot;
bind = ALT, C, exec, grim -g &quot;$(slurp)&quot; ~/.cache/com.pot-app.desktop/pot_screenshot_cut.png &amp;&amp; curl &quot;127.0.0.1:60828/ocr_translate?screenshot=false&quot;
```

其他桌面环境/窗口管理器也是类似的操作

## 划词翻译窗口跟随鼠标位置

由于目前 pot 在 Wayland 下还无法获取到正确的鼠标坐标，所以内部的实现无法工作。 对于某些桌面环境/窗口管理器，可以通过设置窗口规则来实现窗口跟随鼠标位置，这里以 Hyprland 为例：

```conf
windowrulev2 = float, class:(pot), title:(Translator|OCR|PopClip|Screenshot Translate) # Translation window floating
windowrulev2 = move cursor 0 0, class:(pot), title:(Translator|PopClip|Screenshot Translate) # Translation window follows the mouse position.
```

&lt;div align=&quot;center&quot;&gt;

# 国际化([Weblate](https://hosted.weblate.org/engage/pot-app/))

[![](https://hosted.weblate.org/widget/pot-app/pot-desktop/svg-badge.svg)](https://hosted.weblate.org/engage/pot-app/)

[![](https://hosted.weblate.org/widget/pot-app/pot-desktop/zh_Hans/multi-auto.svg)](https://hosted.weblate.org/engage/pot-app/)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

# 贡献者

&lt;/div&gt;

&lt;img src=&quot;https://github.com/pot-app/.github/blob/master/pot-desktop-contributions.svg?raw=true&quot; width=&quot;100%&quot;/&gt;

## 手动编译

### 环境要求

Node.js &gt;= 18.0.0

pnpm &gt;= 8.5.0

Rust &gt;= 1.80.0

### 开始编译

1. Clone 仓库

    ```bash
    git clone https://github.com/pot-app/pot-desktop.git
    ```

2. 安装依赖

    ```bash
    cd pot-desktop
    pnpm install
    ```

3. 安装依赖(仅 Linux 需要)

    ```bash
    sudo apt-get install -y libgtk-3-dev libwebkit2gtk-4.0-dev libayatana-appindicator3-dev librsvg2-dev patchelf libxdo-dev libxcb1 libxrandr2 libdbus-1-3
    ```

4. 开发调试

    ```bash
    pnpm tauri dev # Run the app in development mode
    ```

5. 打包构建
    ```bash
    pnpm tauri build # Build into installation package
    ```

&lt;div align=&quot;center&quot;&gt;

# 感谢

&lt;/div&gt;

-   [Bob](https://github.com/ripperhe/Bob) 灵感来源
-   [bob-plugin-openai-translator](https://github.com/yetone/bob-plugin-openai-translator) OpenAI 接口参考
-   [@uiYzzi](https://github.com/uiYzzi) 实现思路
-   [@Lichenkass](https://github.com/Lichenkass) 维护 Deepin 应用商店中的 pot
-   [Tauri](https://github.com/tauri-apps/tauri) 好用的 GUI 框架

&lt;div align=&quot;center&quot;&gt;
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[ToolJet/ToolJet]]></title>
            <link>https://github.com/ToolJet/ToolJet</link>
            <guid>https://github.com/ToolJet/ToolJet</guid>
            <pubDate>Sat, 28 Jun 2025 00:04:34 GMT</pubDate>
            <description><![CDATA[Low-code platform for building business applications. Connect to databases, cloud storages, GraphQL, API endpoints, Airtable, Google sheets, OpenAI, etc and build apps using drag and drop application builder. Built using JavaScript/TypeScript. 🚀]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ToolJet/ToolJet">ToolJet/ToolJet</a></h1>
            <p>Low-code platform for building business applications. Connect to databases, cloud storages, GraphQL, API endpoints, Airtable, Google sheets, OpenAI, etc and build apps using drag and drop application builder. Built using JavaScript/TypeScript. 🚀</p>
            <p>Language: JavaScript</p>
            <p>Stars: 35,909</p>
            <p>Forks: 4,656</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>ToolJet is an **open-source low-code framework** to build and deploy internal tools with minimal engineering effort. ToolJet&#039;s drag-and-drop frontend builder allows you to create complex, responsive frontends within minutes. Additionally, you can integrate various data sources, including databases like PostgreSQL, MongoDB, and Elasticsearch; API endpoints with OpenAPI spec and OAuth2 support; SaaS tools such as Stripe, Slack, Google Sheets, Airtable, and Notion; as well as object storage services like S3, GCS, and Minio, to fetch and write data.

 :star: If you find ToolJet useful, please consider giving us a star on GitHub! Your support helps us continue to innovate and deliver exciting features.

![Docker Cloud Build Status](https://img.shields.io/docker/cloud/build/tooljet/tooljet-ce)
![Number of GitHub contributors](https://img.shields.io/github/contributors/tooljet/tooljet)
[![Number of GitHub issues that are open](https://img.shields.io/github/issues/ToolJet/ToolJet)](https://github.com/ToolJet/ToolJet/issues)
[![Number of GitHub stars](https://img.shields.io/github/stars/ToolJet/ToolJet)](https://github.com/ToolJet/ToolJet/stargazers)
![Number of GitHub closed issues](https://img.shields.io/github/issues-closed/tooljet/tooljet)
![Number of GitHub pull requests that are open](https://img.shields.io/github/issues-pr-raw/tooljet/tooljet)
![GitHub release; latest by date](https://img.shields.io/github/v/release/tooljet/tooljet)
![GitHub commit activity](https://img.shields.io/github/commit-activity/m/tooljet/tooljet)
[![GitHub license which is AGPL license](https://img.shields.io/github/license/ToolJet/ToolJet)](https://github.com/ToolJet/ToolJet)
[![Follow us on X, formerly Twitter](https://img.shields.io/twitter/follow/ToolJet?style=social)](https://twitter.com/ToolJet)

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://user-images.githubusercontent.com/7828962/211444352-4d6d2e4a-13c9-4980-9e16-4aed4af9811b.png&quot; alt=&quot;Tooljet dashboard showing inventory and orders&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/ToolJet/ToolJet/assets/25361949/0e711f3a-edb7-496b-8833-107de3826933&quot;/&gt;
&lt;/p&gt;

## All features

- **Visual App Builder:** 45+ built-in responsive components, including Tables, Charts, Lists, Forms, and Progress Bars.
- **ToolJet Database:** Built-in no-code database.
- **Multi-Page:** Build an application with multiple pages.
- **Multiplayer editing:** Allows simultaneous app building by multiple developers.
- **50+ data sources:** Integrate with external databases, cloud storage, and APIs.
- **Desktop &amp; mobile:** Customize layout widths to fit various screen sizes.
- **Self-host:** Supports Docker, Kubernetes, AWS EC2, Google Cloud Run, and more.
- **Collaborate:** Add comments anywhere on the canvas and tag your team members.
- **Extend with plugins:** Use our [command-line tool](https://www.npmjs.com/package/@tooljet/cli) to easily bootstrap new connectors.
- **Version control:** Manage multiple application versions with a structured release cycle.
- **Run JS &amp; Python code:** Execute custom JavaScript and Python snippets.
- **Granular access control:** Set permissions at both group and app levels.
- **Low-code:** Use JS code almost anywhere within the builder, such as setting text color based on status with 
`status === &#039;success&#039; ? &#039;green&#039; : &#039;red&#039;`.
- **No-code query editors:** Query Editors are available for all supported data sources.
- **Join and transform data:** Transform query results using JavaScript or Python code.
- **Secure:** All the credentials are securely encrypted using `aes-256-gcm`.
- **Data Privacy:** ToolJet serves solely as a proxy and does not store data.
- **SSO:** Supports multiple Single Sign-On providers.

&lt;hr&gt;

## Quickstart
The easiest way to get started with ToolJet is by creating a [ToolJet Cloud](https://tooljet.ai) account. ToolJet Cloud offers a hosted solution of ToolJet. If you want to self-host ToolJet, kindly proceed to [deployment documentation](https://docs.tooljet.ai/docs/setup/).

### Try using Docker
Want to give ToolJet a quick spin on your local machine? You can run the following command from your terminal to have ToolJet up and running right away.


```bash
docker run \
  --name tooljet \
  --restart unless-stopped \
  -p 80:80 \
  --platform linux/amd64 \
  -v tooljet_data:/var/lib/postgresql/13/main \
  tooljet/try:ee-lts-latest
```

*For users upgrading their ToolJet version, we recommend choosing the LTS version over the latest version. The LTS version ensures stability with production bug fixes, security patches, and performance enhancements.*

## Tutorials and examples

[Time Tracker Application](https://docs.tooljet.ai/docs/#quickstart-guide)&lt;br&gt;
[Build your own CMS using low-code](https://blog.tooljet.ai/build-cms-using-lowcode-and-mongodb/)&lt;br&gt;
[AWS S3 Browser](https://blog.tooljet.ai/build-an-aws-s3-broswer-with-tooljet/)&lt;br&gt;

## Documentation
Documentation is available at https://docs.tooljet.ai.

- [Getting Started](https://docs.tooljet.ai)&lt;br&gt;
- [Data source Reference](https://docs.tooljet.ai/docs/data-sources/airtable/)&lt;br&gt;
- [Component Reference](https://docs.tooljet.ai/docs/widgets/button)

## Self-hosted
You can use ToolJet Cloud for a fully managed solution. If you want to self-host ToolJet, we have guides on deploying ToolJet on Kubernetes, AWS EC2, Docker, and more.

| Provider  | Documentation |
| :------------- | :------------- |
| Digital Ocean | [Link](https://docs.tooljet.ai/docs/setup/digitalocean)  |
| Docker  | [Link](https://docs.tooljet.ai/docs/setup/docker)   |
| AWS EC2 | [Link](https://docs.tooljet.ai/docs/setup/ec2)  |
| AWS ECS | [Link](https://docs.tooljet.ai/docs/setup/ecs)   |
| OpenShift | [Link](https://docs.tooljet.ai/docs/setup/openshift)   |
| Helm | [Link](https://docs.tooljet.ai/docs/setup/helm)   |
| AWS EKS (Kubernetes) | [Link](https://docs.tooljet.ai/docs/setup/kubernetes)   |
| GCP GKE (Kubernetes) | [Link](https://docs.tooljet.ai/docs/setup/kubernetes-gke)   |
| Azure AKS (Kubernetes) | [Link](https://docs.tooljet.ai/docs/setup/kubernetes-aks)   |
| Azure Container | [Link](https://docs.tooljet.ai/docs/setup/azure-container)   |
| Google Cloud Run  | [Link](https://docs.tooljet.ai/docs/setup/google-cloud-run)   |
| Deploying ToolJet client  | [Link](https://docs.tooljet.ai/docs/setup/client)   |
| Deploying ToolJet on a Subpath  | [Link](https://docs.tooljet.ai/docs/setup/tooljet-subpath/)   |

## Marketplace 
ToolJet can now be found on both AWS and Azure Marketplaces, making it simpler than ever to access and deploy our app-building platform.

Find ToolJet on AWS Marketplace [here](https://aws.amazon.com/marketplace/pp/prodview-fxjto27jkpqfg?sr=0-1&amp;ref_=beagle&amp;applicationId=AWSMPContessa) and explore seamless integration on Azure Marketplace [here](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/tooljetsolutioninc1679496832216.tooljet?tab=Overview).

## Community support
For general help using ToolJet, please refer to the official [documentation](https://docs.tooljet.ai/docs/). For additional help, you can use one of these channels to ask a question:

- [Slack](https://tooljet.ai/slack) - Discussions with the community and the team.
- [GitHub](https://github.com/ToolJet/ToolJet/issues) - For bug reports and feature requests.
- [𝕏 (Twitter)](https://twitter.com/ToolJet) - Get the product updates quickly.

## Roadmap
Check out our [roadmap](https://github.com/orgs/ToolJet/projects/15) to stay updated on recently released features and learn about what&#039;s coming next.

## Branching model
We use the git-flow branching model. The base branch is `develop`. If you are looking for a stable version, please use the main branch or tags labeled as v1.x.x.

## Contributing
Kindly read our [Contributing Guide](CONTRIBUTING.md) to familiarize yourself with ToolJet&#039;s development process, how to suggest bug fixes and improvements, and the steps for building and testing your changes. &lt;br&gt;

## Contributors
&lt;a href=&quot;https://github.com/tooljet/tooljet/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=tooljet/tooljet&amp;max=400&amp;columns=20&quot; /&gt;
  &lt;img src=&quot;https://us-central1-tooljet-hub.cloudfunctions.net/github&quot; width=&quot;0&quot; height=&quot;0&quot; /&gt;
&lt;/a&gt;

## License
ToolJet © 2023, ToolJet Solutions Inc - Released under the GNU Affero General Public License v3.0.
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[zotero/zotero]]></title>
            <link>https://github.com/zotero/zotero</link>
            <guid>https://github.com/zotero/zotero</guid>
            <pubDate>Sat, 28 Jun 2025 00:04:33 GMT</pubDate>
            <description><![CDATA[Zotero is a free, easy-to-use tool to help you collect, organize, annotate, cite, and share your research sources.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zotero/zotero">zotero/zotero</a></h1>
            <p>Zotero is a free, easy-to-use tool to help you collect, organize, annotate, cite, and share your research sources.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 11,885</p>
            <p>Forks: 848</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre>Zotero
======
[![CI](https://github.com/zotero/zotero/actions/workflows/ci.yml/badge.svg)](https://github.com/zotero/zotero/actions/workflows/ci.yml)

[Zotero](https://www.zotero.org/) is a free, easy-to-use tool to help you collect, organize, cite, and share your research sources.

Please post feature requests or bug reports to the [Zotero Forums](https://forums.zotero.org/). If you&#039;re having trouble with Zotero, see [Getting Help](https://www.zotero.org/support/getting_help).

For more information on how to use this source code, see the [Zotero documentation](https://www.zotero.org/support/dev/source_code).
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[danielmiessler/fabric]]></title>
            <link>https://github.com/danielmiessler/fabric</link>
            <guid>https://github.com/danielmiessler/fabric</guid>
            <pubDate>Sat, 28 Jun 2025 00:04:32 GMT</pubDate>
            <description><![CDATA[Fabric is an open-source framework for augmenting humans using AI. It provides a modular system for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/danielmiessler/fabric">danielmiessler/fabric</a></h1>
            <p>Fabric is an open-source framework for augmenting humans using AI. It provides a modular system for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 31,721</p>
            <p>Forks: 3,299</p>
            <p>Stars today: 49 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
Fabric is graciously supported by…

[![Github Repo Tagline](https://github.com/user-attachments/assets/96ab3d81-9b13-4df4-ba09-75dee7a5c3d2)](https://warp.dev/fabric)

&lt;img src=&quot;./images/fabric-logo-gif.gif&quot; alt=&quot;fabriclogo&quot; width=&quot;400&quot; height=&quot;400&quot;/&gt;

# `fabric`

![Static Badge](https://img.shields.io/badge/mission-human_flourishing_via_AI_augmentation-purple)
&lt;br /&gt;
![GitHub top language](https://img.shields.io/github/languages/top/danielmiessler/fabric)
![GitHub last commit](https://img.shields.io/github/last-commit/danielmiessler/fabric)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

&lt;div align=&quot;center&quot;&gt;
&lt;p class=&quot;align center&quot;&gt;
&lt;h4&gt;&lt;code&gt;fabric&lt;/code&gt; is an open-source framework for augmenting humans using AI.&lt;/h4&gt;
&lt;/p&gt;
&lt;/div&gt;

[Updates](#updates) •
[What and Why](#what-and-why) •
[Philosophy](#philosophy) •
[Installation](#installation) •
[Usage](#usage) •
[Examples](#examples) •
[Just Use the Patterns](#just-use-the-patterns) •
[Custom Patterns](#custom-patterns) •
[Helper Apps](#helper-apps) •
[Meta](#meta)

![Screenshot of fabric](images/fabric-summarize.png)

&lt;/div&gt;

## What and why

Since the start of modern AI in late 2022 we&#039;ve seen an **_extraordinary_** number of AI applications for accomplishing tasks. There are thousands of websites, chatbots, mobile apps, and other interfaces for using all the different AI out there.

It&#039;s all really exciting and powerful, but _it&#039;s not easy to integrate this functionality into our lives._

&lt;p class=&quot;align center&quot;&gt;
&lt;h4&gt;In other words, AI doesn&#039;t have a capabilities problem—it has an &lt;em&gt;integration&lt;/em&gt; problem.&lt;/h4&gt;
&lt;/p&gt;

**Fabric was created to address this by creating and organizing the fundamental units of AI—the prompts themselves!**

Fabric organizes prompts by real-world task, allowing people to create, collect, and organize their most important AI solutions in a single place for use in their favorite tools. And if you&#039;re command-line focused, you can use Fabric itself as the interface!

## Intro videos

Keep in mind that many of these were recorded when Fabric was Python-based, so remember to use the current [install instructions](#installation) below.

- [Network Chuck](https://www.youtube.com/watch?v=UbDyjIIGaxQ)
- [David Bombal](https://www.youtube.com/watch?v=vF-MQmVxnCs)
- [My Own Intro to the Tool](https://www.youtube.com/watch?v=wPEyyigh10g)
- [More Fabric YouTube Videos](https://www.youtube.com/results?search_query=fabric+ai)


## Navigation

- [`fabric`](#fabric)
  - [Navigation](#navigation)
  - [Updates](#updates)
  - [What and why](#what-and-why)
  - [Intro videos](#intro-videos)
  - [Philosophy](#philosophy)
    - [Breaking problems into components](#breaking-problems-into-components)
    - [Too many prompts](#too-many-prompts)
  - [Installation](#installation)
    - [Get Latest Release Binaries](#get-latest-release-binaries)
      - [Windows](#windows)
      - [macOS (arm64)](#macos-arm64)
      - [macOS (amd64)](#macos-amd64)
      - [Linux (amd64)](#linux-amd64)
      - [Linux (arm64)](#linux-arm64)
    - [Using package managers](#using-package-managers)
      - [macOS (Homebrew)](#macos-homebrew)
      - [Arch Linux (AUR)](#arch-linux-aur)
    - [From Source](#from-source)
    - [Environment Variables](#environment-variables)
    - [Setup](#setup)
    - [Add aliases for all patterns](#add-aliases-for-all-patterns)
      - [Save your files in markdown using aliases](#save-your-files-in-markdown-using-aliases)
    - [Migration](#migration)
    - [Upgrading](#upgrading)
    - [Shell Completions](#shell-completions)
      - [Zsh Completion](#zsh-completion)
      - [Bash Completion](#bash-completion)
      - [Fish Completion](#fish-completion)
  - [Usage](#usage)
  - [Our approach to prompting](#our-approach-to-prompting)
  - [Examples](#examples)
  - [Just use the Patterns](#just-use-the-patterns)
    - [Prompt Strategies](#prompt-strategies)
  - [Custom Patterns](#custom-patterns)
  - [Helper Apps](#helper-apps)
    - [`to_pdf`](#to_pdf)
    - [`to_pdf` Installation](#to_pdf-installation)
    - [`code_helper`](#code_helper)
  - [pbpaste](#pbpaste)
  - [Web Interface](#web-interface)
    - [Installing](#installing)
    - [Streamlit UI](#streamlit-ui)
      - [Clipboard Support](#clipboard-support)
  - [Meta](#meta)
    - [Primary contributors](#primary-contributors)
    - [Contributors](#contributors)

&lt;br /&gt;

## Updates

&gt; [!NOTE]
&gt;
&gt;June 17, 2025
&gt;
&gt;- Fabric now supports Perplexity AI. Configure it by using `fabric -S` to add your Perlexity AI API Key,
&gt;   and then try:
&gt;
&gt;   ```bash
&gt;   fabric -m sonar-pro &quot;What is the latest world news?&quot;
&gt;   ```
&gt;
&gt;June 11, 2025
&gt;
&gt;- Fabric&#039;s YouTube transcription now needs `yt-dlp` to be installed. Make sure to install the latest
&gt; version (2025.06.09 as of this note). The YouTube API key is only needed for comments (the `--comments` flag)
&gt; and metadata extraction (the `--metadata` flag).

## Philosophy

&gt; AI isn&#039;t a thing; it&#039;s a _magnifier_ of a thing. And that thing is **human creativity**.

We believe the purpose of technology is to help humans flourish, so when we talk about AI we start with the **human** problems we want to solve.

### Breaking problems into components

Our approach is to break problems into individual pieces (see below) and then apply AI to them one at a time. See below for some examples.

&lt;img width=&quot;2078&quot; alt=&quot;augmented_challenges&quot; src=&quot;https://github.com/danielmiessler/fabric/assets/50654/31997394-85a9-40c2-879b-b347e4701f06&quot;&gt;

### Too many prompts

Prompts are good for this, but the biggest challenge I faced in 2023——which still exists today—is **the sheer number of AI prompts out there**. We all have prompts that are useful, but it&#039;s hard to discover new ones, know if they are good or not, _and manage different versions of the ones we like_.

One of `fabric`&#039;s primary features is helping people collect and integrate prompts, which we call _Patterns_, into various parts of their lives.

Fabric has Patterns for all sorts of life and work activities, including:

- Extracting the most interesting parts of YouTube videos and podcasts
- Writing an essay in your own voice with just an idea as an input
- Summarizing opaque academic papers
- Creating perfectly matched AI art prompts for a piece of writing
- Rating the quality of content to see if you want to read/watch the whole thing
- Getting summaries of long, boring content
- Explaining code to you
- Turning bad documentation into usable documentation
- Creating social media posts from any content input
- And a million more…

## Installation

To install Fabric, you can use the latest release binaries or install it from the source.

### Get Latest Release Binaries

#### Windows

`https://github.com/danielmiessler/fabric/releases/latest/download/fabric-windows-amd64.exe`

#### macOS (arm64)

`curl -L https://github.com/danielmiessler/fabric/releases/latest/download/fabric-darwin-arm64 &gt; fabric &amp;&amp; chmod +x fabric &amp;&amp; ./fabric --version`

#### macOS (amd64)

`curl -L https://github.com/danielmiessler/fabric/releases/latest/download/fabric-darwin-amd64 &gt; fabric &amp;&amp; chmod +x fabric &amp;&amp; ./fabric --version`

#### Linux (amd64)

`curl -L https://github.com/danielmiessler/fabric/releases/latest/download/fabric-linux-amd64 &gt; fabric &amp;&amp; chmod +x fabric &amp;&amp; ./fabric --version`

#### Linux (arm64)

`curl -L https://github.com/danielmiessler/fabric/releases/latest/download/fabric-linux-arm64 &gt; fabric &amp;&amp; chmod +x fabric &amp;&amp; ./fabric --version`

### Using package managers

**NOTE:** using Homebrew or the Arch Linux package managers makes `fabric` available as `fabric-ai`, so add
the following alias to your shell startup files to account for this:

```bash
alias fabric=&#039;fabric-ai&#039;
```

#### macOS (Homebrew)

`brew install fabric-ai`

#### Arch Linux (AUR)

`yay -S fabric-ai`

### From Source

To install Fabric, [make sure Go is installed](https://go.dev/doc/install), and then run the following command.

```bash
# Install Fabric directly from the repo
go install github.com/danielmiessler/fabric@latest
```

### Environment Variables

You may need to set some environment variables in your `~/.bashrc` on linux or `~/.zshrc` file on mac to be able to run the `fabric` command. Here is an example of what you can add:

For Intel based macs or linux

```bash
# Golang environment variables
export GOROOT=/usr/local/go
export GOPATH=$HOME/go

# Update PATH to include GOPATH and GOROOT binaries
export PATH=$GOPATH/bin:$GOROOT/bin:$HOME/.local/bin:$PATH
```

for Apple Silicon based macs

```bash
# Golang environment variables
export GOROOT=$(brew --prefix go)/libexec
export GOPATH=$HOME/go
export PATH=$GOPATH/bin:$GOROOT/bin:$HOME/.local/bin:$PATH
```

### Setup

Now run the following command

```bash
# Run the setup to set up your directories and keys
fabric --setup
```

If everything works you are good to go.

### Add aliases for all patterns

In order to add aliases for all your patterns and use them directly as commands ie. `summarize` instead of `fabric --pattern summarize`
You can add the following to your `.zshrc` or `.bashrc` file.

```bash
# Loop through all files in the ~/.config/fabric/patterns directory
for pattern_file in $HOME/.config/fabric/patterns/*; do
    # Get the base name of the file (i.e., remove the directory path)
    pattern_name=$(basename &quot;$pattern_file&quot;)

    # Create an alias in the form: alias pattern_name=&quot;fabric --pattern pattern_name&quot;
    alias_command=&quot;alias $pattern_name=&#039;fabric --pattern $pattern_name&#039;&quot;

    # Evaluate the alias command to add it to the current shell
    eval &quot;$alias_command&quot;
done

yt() {
    if [ &quot;$#&quot; -eq 0 ] || [ &quot;$#&quot; -gt 2 ]; then
        echo &quot;Usage: yt [-t | --timestamps] youtube-link&quot;
        echo &quot;Use the &#039;-t&#039; flag to get the transcript with timestamps.&quot;
        return 1
    fi

    transcript_flag=&quot;--transcript&quot;
    if [ &quot;$1&quot; = &quot;-t&quot; ] || [ &quot;$1&quot; = &quot;--timestamps&quot; ]; then
        transcript_flag=&quot;--transcript-with-timestamps&quot;
        shift
    fi
    local video_link=&quot;$1&quot;
    fabric -y &quot;$video_link&quot; $transcript_flag
}
```

You can add the below code for the equivalent aliases inside PowerShell by running `notepad $PROFILE` inside a PowerShell window:

```powershell
# Path to the patterns directory
$patternsPath = Join-Path $HOME &quot;.config/fabric/patterns&quot;
foreach ($patternDir in Get-ChildItem -Path $patternsPath -Directory) {
    $patternName = $patternDir.Name

    # Dynamically define a function for each pattern
    $functionDefinition = @&quot;
function $patternName {
    [CmdletBinding()]
    param(
        [Parameter(ValueFromPipeline = `$true)]
        [string] `$InputObject,

        [Parameter(ValueFromRemainingArguments = `$true)]
        [String[]] `$patternArgs
    )

    begin {
        # Initialize an array to collect pipeline input
        `$collector = @()
    }

    process {
        # Collect pipeline input objects
        if (`$InputObject) {
            `$collector += `$InputObject
        }
    }

    end {
        # Join all pipeline input into a single string, separated by newlines
        `$pipelineContent = `$collector -join &quot;`n&quot;

        # If there&#039;s pipeline input, include it in the call to fabric
        if (`$pipelineContent) {
            `$pipelineContent | fabric --pattern $patternName `$patternArgs
        } else {
            # No pipeline input; just call fabric with the additional args
            fabric --pattern $patternName `$patternArgs
        }
    }
}
&quot;@
    # Add the function to the current session
    Invoke-Expression $functionDefinition
}

# Define the &#039;yt&#039; function as well
function yt {
    [CmdletBinding()]
    param(
        [Parameter()]
        [Alias(&quot;timestamps&quot;)]
        [switch]$t,

        [Parameter(Position = 0, ValueFromPipeline = $true)]
        [string]$videoLink
    )

    begin {
        $transcriptFlag = &quot;--transcript&quot;
        if ($t) {
            $transcriptFlag = &quot;--transcript-with-timestamps&quot;
        }
    }

    process {
        if (-not $videoLink) {
            Write-Error &quot;Usage: yt [-t | --timestamps] youtube-link&quot;
            return
        }
    }

    end {
        if ($videoLink) {
            # Execute and allow output to flow through the pipeline
            fabric -y $videoLink $transcriptFlag
        }
    }
}
```

This also creates a `yt` alias that allows you to use `yt https://www.youtube.com/watch?v=4b0iet22VIk` to get transcripts, comments, and metadata.

#### Save your files in markdown using aliases

If in addition to the above aliases you would like to have the option to save the output to your favorite markdown note vault like Obsidian then instead of the above add the following to your `.zshrc` or `.bashrc` file:

```bash
# Define the base directory for Obsidian notes
obsidian_base=&quot;/path/to/obsidian&quot;

# Loop through all files in the ~/.config/fabric/patterns directory
for pattern_file in ~/.config/fabric/patterns/*; do
    # Get the base name of the file (i.e., remove the directory path)
    pattern_name=$(basename &quot;$pattern_file&quot;)

    # Remove any existing alias with the same name
    unalias &quot;$pattern_name&quot; 2&gt;/dev/null

    # Define a function dynamically for each pattern
    eval &quot;
    $pattern_name() {
        local title=\$1
        local date_stamp=\$(date +&#039;%Y-%m-%d&#039;)
        local output_path=\&quot;\$obsidian_base/\${date_stamp}-\${title}.md\&quot;

        # Check if a title was provided
        if [ -n \&quot;\$title\&quot; ]; then
            # If a title is provided, use the output path
            fabric --pattern \&quot;$pattern_name\&quot; -o \&quot;\$output_path\&quot;
        else
            # If no title is provided, use --stream
            fabric --pattern \&quot;$pattern_name\&quot; --stream
        fi
    }
    &quot;
done
```

This will allow you to use the patterns as aliases like in the above for example `summarize` instead of `fabric --pattern summarize --stream`, however if you pass in an extra argument like this `summarize &quot;my_article_title&quot;` your output will be saved in the destination that you set in `obsidian_base=&quot;/path/to/obsidian&quot;` in the following format `YYYY-MM-DD-my_article_title.md` where the date gets autogenerated for you.
You can tweak the date format by tweaking the `date_stamp` format.

### Migration

If you have the Legacy (Python) version installed and want to migrate to the Go version, here&#039;s how you do it. It&#039;s basically two steps: 1) uninstall the Python version, and 2) install the Go version.

```bash
# Uninstall Legacy Fabric
pipx uninstall fabric

# Clear any old Fabric aliases
(check your .bashrc, .zshrc, etc.)
# Install the Go version
go install github.com/danielmiessler/fabric@latest
# Run setup for the new version. Important because things have changed
fabric --setup
```

Then [set your environmental variables](#environment-variables) as shown above.

### Upgrading

The great thing about Go is that it&#039;s super easy to upgrade. Just run the same command you used to install it in the first place and you&#039;ll always get the latest version.

```bash
go install github.com/danielmiessler/fabric@latest
```

### Shell Completions

Fabric provides shell completion scripts for Zsh, Bash, and Fish
shells, making it easier to use the CLI by providing tab completion
for commands and options.

#### Zsh Completion

To enable Zsh completion:

```bash
# Copy the completion file to a directory in your $fpath
mkdir -p ~/.zsh/completions
cp completions/_fabric ~/.zsh/completions/

# Add the directory to fpath in your .zshrc before compinit
echo &#039;fpath=(~/.zsh/completions $fpath)&#039; &gt;&gt; ~/.zshrc
echo &#039;autoload -Uz compinit &amp;&amp; compinit&#039; &gt;&gt; ~/.zshrc
```

#### Bash Completion

To enable Bash completion:

```bash
# Source the completion script in your .bashrc
echo &#039;source /path/to/fabric/completions/fabric.bash&#039; &gt;&gt; ~/.bashrc

# Or copy to the system-wide bash completion directory
sudo cp completions/fabric.bash /etc/bash_completion.d/
```

#### Fish Completion

To enable Fish completion:

```bash
# Copy the completion file to the fish completions directory
mkdir -p ~/.config/fish/completions
cp completions/fabric.fish ~/.config/fish/completions/
```

## Usage

Once you have it all set up, here&#039;s how to use it.

```bash
fabric -h
```

```plaintext

Usage:
  fabric [OPTIONS]

Application Options:
  -p, --pattern=                    Choose a pattern from the available patterns
  -v, --variable=                   Values for pattern variables, e.g. -v=#role:expert -v=#points:30
  -C, --context=                    Choose a context from the available contexts
      --session=                    Choose a session from the available sessions
  -a, --attachment=                 Attachment path or URL (e.g. for OpenAI image recognition messages)
  -S, --setup                       Run setup for all reconfigurable parts of fabric
  -t, --temperature=                Set temperature (default: 0.7)
  -T, --topp=                       Set top P (default: 0.9)
  -s, --stream                      Stream
  -P, --presencepenalty=            Set presence penalty (default: 0.0)
  -r, --raw                         Use the defaults of the model without sending chat options (like temperature etc.) and use the user role instead of the system role for patterns.
  -F, --frequencypenalty=           Set frequency penalty (default: 0.0)
  -l, --listpatterns                List all patterns
  -L, --listmodels                  List all available models
  -x, --listcontexts                List all contexts
  -X, --listsessions                List all sessions
  -U, --updatepatterns              Update patterns
  -c, --copy                        Copy to clipboard
  -m, --model=                      Choose model
      --modelContextLength=         Model context length (only affects ollama)
  -o, --output=                     Output to file
      --output-session              Output the entire session (also a temporary one) to the output file
  -n, --latest=                     Number of latest patterns to list (default: 0)
  -d, --changeDefaultModel          Change default model
  -y, --youtube=                    YouTube video or play list &quot;URL&quot; to grab transcript, comments from it and send to chat or print it put to the console and store it in the output file
      --playlist                    Prefer playlist over video if both ids are present in the URL
      --transcript                  Grab transcript from YouTube video and send to chat (it is used per default).
      --transcript-with-timestamps  Grab transcript from YouTube video with timestamps and send to chat
      --comments                    Grab comments from YouTube video and send to chat
      --metadata                    Output video metadata
  -g, --language=                   Specify the Language Code for the chat, e.g. -g=en -g=zh
  -u, --scrape_url=                 Scrape website URL to markdown using Jina AI
  -q, --scrape_question=            Search question using Jina AI
  -e, --seed=                       Seed to be used for LMM generation
  -w, --wipecontext=                Wipe context
  -W, --wipesession=                Wipe session
      --printcontext=               Print context
      --printsession=               Print session
      --readability                 Convert HTML input into a clean, readable view
      --input-has-vars              Apply variables to user input
      --dry-run                     Show what would be sent to the model without actually sending it
      --serve                       Serve the Fabric Rest API
      --serveOllama                 Serve the Fabric Rest API with ollama endpoints
      --address=                    The address to bind the REST API (default: :8080)
      --api-key=                    API key used to secure server routes
      --config=                     Path to YAML config file
      --version                     Print current version
      --listextensions              List all registered extensions
      --addextension=               Register a new extension from 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[i-am-shodan/USBArmyKnife]]></title>
            <link>https://github.com/i-am-shodan/USBArmyKnife</link>
            <guid>https://github.com/i-am-shodan/USBArmyKnife</guid>
            <pubDate>Sat, 28 Jun 2025 00:04:31 GMT</pubDate>
            <description><![CDATA[USB Army Knife – the ultimate close access tool for penetration testers and red teamers.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/i-am-shodan/USBArmyKnife">i-am-shodan/USBArmyKnife</a></h1>
            <p>USB Army Knife – the ultimate close access tool for penetration testers and red teamers.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 1,661</p>
            <p>Forks: 157</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://github.com/i-am-shodan/USBArmyKnife/blob/master/LICENSE&quot;&gt;&lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/github/license/mashape/apistatus.svg&quot;&gt;&lt;/a&gt;
[![PlatformIO CI](https://github.com/i-am-shodan/USBArmyKnife/actions/workflows/main.yml/badge.svg)](https://github.com/i-am-shodan/USBArmyKnife/actions/workflows/main.yml)
[![.NET](https://github.com/i-am-shodan/USBArmyKnife/actions/workflows/dotnet.yml/badge.svg)](https://github.com/i-am-shodan/USBArmyKnife/actions/workflows/dotnet.yml)
&lt;a href=&quot;https://twitter.com/intent/follow?screen_name=therealshodan&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/therealshodan?style=social&amp;logo=twitter&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;
[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/O5O8145AVW)
&lt;a href=&quot;https://www.buymeacoffee.com/therealshodan&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://cdn.buymeacoffee.com/buttons/default-orange.png&quot; alt=&quot;Buy Me A Coffee&quot; height=&quot;41&quot; width=&quot;174&quot;&gt;&lt;/a&gt;

# USB Army Knife

&lt;div align=&quot;center&quot;&gt;
  Introducing the USB Army Knife – the ultimate tool for penetration testers and red teamers.
    &lt;img src=&quot;./docs/images/t-dongle-s3-side.png&quot; width=&quot;400px&quot;&lt;/img&gt;
&lt;/div&gt;

Compact and versatile, this device packs a punch with its extensive capabilities, including USB HID attacks, mass storage emulation, network device impersonation and WiFi/Bluetooth exploits (thanks to our forked version of ESP32 Marauder).

Complete control over how and when your payloads are run. Plug in and execute, leave behind and trigger over WiFi, run on a timer or build a Hollywood-esq UI. Manage and deploy your attacks effortlessly using just a phone using a user-friendly Bootstrap web interface.

Want more? Deploy the agent and execute commands even when the machine is locked. Working over the serial interface egress is incredibly hard to detect. You can even view the victims screen over the devices&#039; dedicated WiFi connection.

Equip yourself with the USB Army Knife and elevate your local access toolkit to the next level.

## Testimonials

*&quot;Your device is evil. You are doing evil.&quot;* - Mr. Peoples via X

## Intro
There is a problem with physical access/USB attacks today. On their own, each attack doesn&#039;t provide enough of a solution to meet most objectives.
* USB keyboard attacks (Ducky, HID&amp;Run) require a logged on machine and even the best tools don’t provide a solution to this.
* Networking attacks (poison tap and alike) might get you a password hash but often require something complex hanging out of an Ethernet port to get this back for offline cracking.
* When you get on a box, what options do you still have for exfiltrating data when anything that opens a socket is getting sent to VT.

What was needed is a physical access platform that enables a suitable rogue to take the best bits of each attack and workaround their respective problems with another attack. Ideally this platform would be so cheap and covert that losing one wouldn&#039;t be an issue.

This is why I decided to create the USB Army Knife. 
* Want to become a USB Ethernet adapter PCAP the interface and egress it over WiFI? USB Army Knife.
* Want to wrap your attacks in custom UI or just show a Hollywood interface when your attack has worked? USB Army Knife
* Want a covert storage device? USB Army Knife
* Want to deauth everyone on the WiFi, PCAP the renegotiation and email this to yourself when the machine has been left unlocked for offline cracking? USB Army Knife
* Want your attack to destroy itself when it’s been found? USB Army Knife
* What to connect to other bits of hardware, motion sensors and alike? USB Army Knife.
* Want to view what’s on the victim&#039;s screen over WiFi? USB Army Knife.
* Want to record what your victim is saying? USB Army Knife.

## Video
[This video shows how the ultimate rick roll works](./examples/rickroll/)

https://github.com/user-attachments/assets/f373e18e-5cad-4871-9f2a-17523fa33398

[This video shows how the USB PCAP functionality and has a brief peak at the web interface](./examples/usb_ethernet_pcap/)

https://github.com/user-attachments/assets/0d5b1485-b808-46c6-aaf7-7cf016088b8f

[This video shows how to pull the victims machine once the agent has been installed](./examples/vnc/) 

https://github.com/user-attachments/assets/3c866d29-ef26-4eaf-943b-1206b8c40101

## Features
This project implements a variety of attacks based around an easily concealable USB/WiFi/BT dongle. The attacks include sending BadUSB (USB HID commands using DuckyScript), appearing as mass storage devices, appearing as USB network devices, and performing WiFi and Bluetooth attacks with ESP32 Marauder. Attacks are deployed using a Ducky-like language you probably already know and love. This language has been agumented with a raft of custom commands and even the entire ESP32 Marauder capability (improved). Attacks include:

- **USB HID Attacks**: Send custom HID commands using DuckyScript, supports BadUSB &amp; USB HID and run style attacks. Supports multiple keyboard layouts/languages.
- **Mass Storage Device**: Emulate a USB mass storage device (USB drive and CDROM).
- **USB Network Device**: Appear as a USB network device.
- **WiFi and Bluetooth Attacks**: Utilize ESP32 Marauder for WiFi and Bluetooth attacks. Include EvilAP, Deauth and pcap.
- **Hot Mic**: Plug in a USB device and stream audio over WiFi

## Examples

| Name      | Description   |
| ------------- | ------------- |
| [Covert Storage](./examples/covertstorage/) | Example showing how to masquerade as two different USB mass storage devices. The first time the device is plugged in the devices appears with the full contents of the micro SD card. In all subsequence attempts a different &#039;benign&#039; drive appears. |
| [Progress Bar](./examples/progressbar/) | Images are displayed on the devices LCD screen showing a progress bar. Great for those Hollywood style attacks or if you want a visual indicator to show an attack has deployed. |
| [Ultimate RickRoll](./examples/rickroll/) | Inject keystrokes to display the famous rickroll video but also uses ESP32 Marauder to blast the lyrics over WiFi. |
| [USB Ethernet PCAP](./examples/usb_ethernet_pcap/) | Turns the device into a USB network adapter and collects a PCAP of the first few seconds of network traffic. |
| [Deploy the serial agent](./examples/install_agent_and_run_command/) | Deploys the agent if it isn&#039;t already installed and sends commands over the serial port. Command output can be seen in the web interface|
| [Pull the screen](./examples/vnc/) | Deploys the agent, the agent includes a tiny VNC server. Now the screen can be viewed via the web interface|
| [Simple UI](./examples/simple_ui/) | A simple yet powerful UI to select scripts/images and run these using the hardware button. Shows how you can build complex UI interactions simply.  |
| [Stream Mic audio over WiFi](./examples/hotmic/) | The M5Stack AtomS3U has a microphone that you can stream over WiFi.  |
| [Instantly crash Linux boxes](./examples/linux_panic/) | Deploy a bad filesystem which cause Linux machines which automount to panic. |
| [Evil USB CDROM/NIC](./examples/malicious_ethernet_adapter/) | Pretend to be a USB NICs which requires a driver from a CDROM device that appears when you plug the NIC in. |
| [Use different keyboard layouts](./examples/multiple_keyboard_layouts/) | Automatically support different keyboard layouts without rewriting your payloads |

## Supported Hardware

| Hardware     | Supported      | Purchase Links |
| ------------ | -------------- | -------------- |
| **LilyGo T-Dongle S3**  (Recommended)![screenshot](./docs/images/t-dongle-s3.png) | The LilyGo T-Dongle S3 is a USB pen drive shaped ESP32-S3 development board. It features a colour LCD screen, physical button, hidden/covert micro SD card adapter (inside the USB-A connector) as well as a SPI adapter. It has 16MB of flash. It is based on the ESP32-S3 chipset which enables it to host a WiFi station as well as support a range of WiFi and Bluetooth attacks. *It is incredibly cheap!* There are two versions of this device with and without the screen. Only the version with the screen has been tested.  | &lt;ul&gt;&lt;li&gt;[AliExpress](https://s.click.aliexpress.com/e/_DCMq0ZX)&lt;/li&gt;&lt;li&gt;[Amazon UK](https://amzn.to/3YuNCg3)&lt;/li&gt;&lt;li&gt;[Amazon US](https://amzn.to/4f4AqUk)&lt;/li&gt;&lt;li&gt;[eBay UK](https://ebay.us/3TJVed)&lt;/li&gt;&lt;/ul&gt;
| **Waveshare ESP32-S3 1.47inch** ![screenshot](./docs/images/waveshare-147.png) | This device is similar in design, size and features to the LilyGo T-Dongle S3 and uses the same chipset. It is clearly a dev board as it doesn&#039;t come with a case and has exposed circuitry on the underside. Where this device betters the T-Dongle S3 is that it has a very large high quality screen and 8MB of additional RAM. | &lt;ul&gt;&lt;li&gt;[AliExpress](https://s.click.aliexpress.com/e/_DmlJI3x)&lt;/li&gt;&lt;li&gt;[eBay UK](https://ebay.us/E4gFr5])&lt;/li&gt;&lt;/ul&gt;
| **M5Stack AtomS3U** ![screenshot](./docs/images/m5stack-atoms3u.png) | This is an ESP32-S3 development board with two external interface at the rear. It doesn&#039;t feature a screen or an SD card, but does have an LED and a button. Instead of an SD card the flash memory is used to store files. Unusually it also contains a digital microphone and IR LED that are not currently supported. To put the device in boot mode hold RESET (the button on the side of the device) until a green LED comes on. | &lt;ul&gt;&lt;li&gt;[AliExpress](https://s.click.aliexpress.com/e/_EIAUNXX)&lt;/li&gt;&lt;/ul&gt;
| **ESP32 Udisk** ![screenshot](./docs/images/esp32-udisk.png) | The most basic device that can run the USB Army Knife code is a ESP32-S2 chip connected to a USB port. Often you can find these sold in a very similar enclosures to the T-Dongle S3 and tend to advertised on sites like AliExpress as Playstation 4 jailbreaks under the name &#039;USB Dongle Udisk for P4&#039;. These devices lack RAM, a screen, SD card, Bluetooth, LEDs and a good hardware button. Instead of an SD card, flash memory is used to store tiny files. These devices are incredibly cheap and are often good at running HID+WiFi payloads (like the rick roll). **Warning** They are too underpowered to run the webserver. When buying these **beware** that they can often be confused with a very similar looking device that includes a CH343P chipset and no reset button. **Make sure the device you buy has a button that can be pushed with a paperclip.** Ensure you flash this device with the Generic-ESP32-S2 configuration.  | &lt;ul&gt;&lt;li&gt;[AliExpress](https://s.click.aliexpress.com/e/_Dn5wXe5)&lt;/li&gt;&lt;li&gt;[Amazon UK](https://amzn.to/3Y4hrCE)&lt;/li&gt;&lt;li&gt;[Amazon US](https://amzn.to/4h98Jf4)&lt;/li&gt;&lt;li&gt;[eBay UK](https://ebay.us/AVZcK0)&lt;/li&gt;&lt;/ul&gt;
| **ESP32 Key** ![screenshot](./docs/images/esp32-key.png) | Very similar to the ESP32 UDisk (please see that description for a list of things it can&#039;t do) this is an ESP32-S2 on a circuit board. It is probably the cheapest device that can just about run USB Army Knife and has a price point to match. You&#039;ll need to hold down the button when you plug it in to get the device into flashing mode. Ensure you flash this device with the Generic-ESP32-S2 configuration. | &lt;ul&gt;&lt;li&gt;[AliExpress](https://s.click.aliexpress.com/e/_EyliW13)&lt;/li&gt;&lt;/ul&gt;
| **Waveshare-ESP32-GEEK** ![screenshot](./docs/images/esp32-geek.png) | ESP32-GEEK is a development board designed by Waveshare. It has USB-A, 1.14-inch LCD screen, an SD card and has external ports (SWD, UART and I2C), it doesn&#039;t have an LED. Hold down the button when you plug it in to get the device into flashing mode. This device has some SD card issues (compatibility and low speed). You may need to use 8GB partitions and try a few card brands to find something compatible (I found a Kingston 64gb card with a 9GB partition worked YMMV). | &lt;ul&gt;&lt;li&gt;[AliExpress](https://s.click.aliexpress.com/e/_EJsjVAc)&lt;/li&gt;&lt;li&gt;[Amazon UK](https://amzn.to/41hLVnn)&lt;/li&gt;&lt;li&gt;[Amazon US](https://amzn.to/3QnV9rW)&lt;/li&gt;&lt;/ul&gt;
| **Waveshare-RP2040-GEEK** ![screenshot](./docs/images/rp2040-geek.jpg) | RP2040-GEEK is a development board designed by Waveshare. It has USB-A, 1.14-inch LCD screen, an SD card and has external ports (SWD, UART and I2C). **This board does not run the ESP32 chipset. USB ethernet (NCM) mode are whole disk SD usage are both currently unsupported. ESP32 Maurader cannot work on this device!** On Windows you may also need to set this device to use a WinUSB driver using [Zadig](https://zadig.akeo.ie/). Hold down the button when you plug it in to get the device into flashing mode. | &lt;ul&gt;&lt;li&gt;[AliExpress](https://s.click.aliexpress.com/e/_EvdfVGH)&lt;/li&gt;&lt;li&gt;[Amazon UK](https://amzn.to/3YZvD1f)&lt;/li&gt;&lt;li&gt;[Amazon US](https://amzn.to/3YY4Ouy)&lt;/li&gt;&lt;/ul&gt;

## Getting Started
powershell

### Installation

There are two options for getting the USB Army Knife firmware onto your device:
* [Flashing pre-built firmware using your web browser (easiest route)]([https://github.com/i-am-shodan/USBArmyKnife/wiki/Installation#using-a-web-browser](https://github.com/i-am-shodan/USBArmyKnife/wiki/Installation#flashing-with-a-web-browser))
* [Building and flashing the source using Visual Studio Code (more powerful)]([https://github.com/i-am-shodan/USBArmyKnife/wiki/Installation#using-visual-studio-code](https://github.com/i-am-shodan/USBArmyKnife/wiki/Installation#flashing-with-visual-studio-code-and-platformio))

### Usage

1. Connect the USB dongle to your computer.
1. Connect to the WiFi access point (iPhone14) with the password of &#039;password&#039;
1. Access the web interface (http://4.3.2.1:8080) by navigating to the URL with your browser.
1. Ensure the web interface has correctly loaded. You should see thr currently running status and uptime. If not refresh the page.
1. Use the web interface to create and manage your attacks using DuckyScript.

*ESP-S2 based devices have WiFi support but do not have a web interface. Attacks are managed via DuckyScript files.*
*RP2040 devices do not have ESP32 Maurader capability*

## How to get help
* Questions about DuckyScript?
  * [DuckyScript quick reference](https://docs.hak5.org/hak5-usb-rubber-ducky/duckyscript-tm-quick-reference)
  * [The USB Army Knife command reference](https://github.com/i-am-shodan/USBArmyKnife/wiki) 
* Problem getting started?
  * Check out the examples
  * [The discussions pages](https://github.com/i-am-shodan/USBArmyKnife/discussions)
* Found a bug?
  * [Create an issue](https://github.com/i-am-shodan/USBArmyKnife/issues)

## Future plans

### USB Host Mode / Mobile device support
There is no reason the USB Army Knife can&#039;t also operate in USB host mode. That is the same mode a computer works in. In this way the USB Army Knife can issue commands as if it was a computer. With most smart phones supporting PTP (picture transfer protocol) this means you could in theory plug in a USB Army Knife (with a USB adapter) into a phone and have it pull the photos off.

[Espressif have documentation for USB host mode](https://docs.espressif.com/projects/esp-idf/en/latest/esp32s3/api-reference/peripherals/usb_host.html) and also [example code](https://github.com/espressif/esp-idf/tree/master/examples/peripherals/usb/host). They do not have an example for the PTP protocol.
You can collect a PCAP of your phone using PTP using [USB PCAP](https://desowin.org/usbpcap/) there is even a WireShark [dissector](https://wiki.wireshark.org/USB-PTP)

## Contributing

Contributions are welcome! Please fork the repository and submit a pull request.

## Contact

If you have any questions or suggestions, feel free to reach out to us:

- Raise an issue on the repository: [GitHub Repository](https://github.com/i-am-shodan/usb-army-knife)
- Connect with us on Twitter: [@therealshodan](https://twitter.com/therealshodan)

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- Inspired by various BadUSB projects and the ESP32 Marauder project.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=i-am-shodan/USBArmyKnife&amp;type=Date)](https://star-history.com/#i-am-shodan/USBArmyKnife&amp;Date)

</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[prebid/Prebid.js]]></title>
            <link>https://github.com/prebid/Prebid.js</link>
            <guid>https://github.com/prebid/Prebid.js</guid>
            <pubDate>Sat, 28 Jun 2025 00:04:30 GMT</pubDate>
            <description><![CDATA[Setup and manage header bidding advertising partners without writing code or confusing line items. Prebid.js is open source and free.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/prebid/Prebid.js">prebid/Prebid.js</a></h1>
            <p>Setup and manage header bidding advertising partners without writing code or confusing line items. Prebid.js is open source and free.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 1,450</p>
            <p>Forks: 2,194</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>[![Build Status](https://circleci.com/gh/prebid/Prebid.js.svg?style=svg)](https://circleci.com/gh/prebid/Prebid.js)
[![Percentage of issues still open](http://isitmaintained.com/badge/open/prebid/Prebid.js.svg)](https://isitmaintained.com/project/prebid/Prebid.js &quot;Percentage of issues still open&quot;)
[![Coverage Status](https://coveralls.io/repos/github/prebid/Prebid.js/badge.svg)](https://coveralls.io/github/prebid/Prebid.js)

# Prebid.js

&gt; A free and open source library for publishers to quickly implement header bidding.

This README is for developers who want to contribute to Prebid.js.
Additional documentation can be found at [the Prebid.js documentation homepage](https://docs.prebid.org/prebid/prebidjs.html).
Working examples can be found in [the developer docs](https://prebid.org/dev-docs/getting-started.html).

Prebid.js is open source software that is offered for free as a convenience. While it is designed to help companies address legal requirements associated with header bidding, we cannot and do not warrant that your use of Prebid.js will satisfy legal requirements. You are solely responsible for ensuring that your use of Prebid.js complies with all applicable laws.  We strongly encourage you to obtain legal advice when using Prebid.js to ensure your implementation complies with all laws where you operate.

**Table of Contents**

- [Usage](#Usage)
- [Install](#Install)
- [Build](#Build)
- [Run](#Run)
- [Contribute](#Contribute)

&lt;a name=&quot;Usage&quot;&gt;&lt;/a&gt;

## Usage (as a npm dependency)

*Note:* Requires Prebid.js v1.38.0+

Prebid.js depends on Babel and some Babel Plugins in order to run correctly in the browser.  Here are some examples for
configuring webpack to work with Prebid.js.

With Babel 7:
```javascript
// webpack.conf.js
let path = require(&#039;path&#039;);
module.exports = {
  mode: &#039;production&#039;,
  module: {
    rules: [

      // this rule can be excluded if you don&#039;t require babel-loader for your other application files
      {
        test: /\.m?js$/,
        exclude: /node_modules/,
        use: {
          loader: &#039;babel-loader&#039;,
        }
      },

      // this separate rule is required to make sure that the Prebid.js files are babel-ified.  this rule will
      // override the regular exclusion from above (for being inside node_modules).
      {
        test: /.js$/,
        include: new RegExp(`\\${path.sep}prebid\\.js`),
        use: {
          loader: &#039;babel-loader&#039;,
          // presets and plugins for Prebid.js must be manually specified separate from your other babel rule.
          // this can be accomplished by requiring prebid&#039;s .babelrc.js file (requires Babel 7 and Node v8.9.0+)
          // as of Prebid 6, babelrc.js only targets modern browsers. One can change the targets and build for
          // older browsers if they prefer, but integration tests on ie11 were removed in Prebid.js 6.0
          options: require(&#039;prebid.js/.babelrc.js&#039;)
        }
      }
    ]
  }
}
```

Or for Babel 6:
```javascript
            // you must manually install and specify the presets and plugins yourself
            options: {
              plugins: [
                &quot;transform-object-assign&quot;, // required (for IE support) and &quot;babel-plugin-transform-object-assign&quot;
                                           // must be installed as part of your package.
                require(&#039;prebid.js/plugins/pbjsGlobals.js&#039;) // required!
              ],
              presets: [
                [&quot;env&quot;, {                 // you can use other presets if you wish.
                  &quot;targets&quot;: {            // this example is using &quot;babel-presets-env&quot;, which must be installed if you
                    &quot;browsers&quot;: [         // follow this example.
                      ... // your browser targets. they should probably match the targets you&#039;re using for the rest
                          // of your application
                    ]
                  }
                }]
              ]
            }
```

Then you can use Prebid.js as any other npm dependency

```javascript
import pbjs from &#039;prebid.js&#039;;
import &#039;prebid.js/modules/rubiconBidAdapter&#039;; // imported modules will register themselves automatically with prebid
import &#039;prebid.js/modules/appnexusBidAdapter&#039;;
pbjs.processQueue();  // required to process existing pbjs.queue blocks and setup any further pbjs.queue execution

pbjs.requestBids({
  ...
})

```



&lt;a name=&quot;Install&quot;&gt;&lt;/a&gt;

## Install



    $ git clone https://github.com/prebid/Prebid.js.git
    $ cd Prebid.js
    $ npm ci

*Note:* You need to have `NodeJS` 12.16.1 or greater installed.

*Note:* In the 1.24.0 release of Prebid.js we have transitioned to using gulp 4.0 from using gulp 3.9.1.  To comply with gulp&#039;s recommended setup for 4.0, you&#039;ll need to have `gulp-cli` installed globally prior to running the general `npm ci`.  This shouldn&#039;t impact any other projects you may work on that use an earlier version of gulp in its setup.

If you have a previous version of `gulp` installed globally, you&#039;ll need to remove it before installing `gulp-cli`.  You can check if this is installed by running `gulp -v` and seeing the version that&#039;s listed in the `CLI` field of the output.  If you have the `gulp` package installed globally, it&#039;s likely the same version that you&#039;ll see in the `Local` field.  If you already have `gulp-cli` installed, it should be a lower major version (it&#039;s at version `2.0.1` at the time of the transition).

To remove the old package, you can use the command: `npm rm gulp -g`

Once setup, run the following command to globally install the `gulp-cli` package: `npm install gulp-cli -g`


&lt;a name=&quot;Build&quot;&gt;&lt;/a&gt;

## Build for Development

To build the project on your local machine we recommend, running:

    $ gulp serve-and-test --file &lt;spec_file.js&gt;

This will run testing but not linting. A web server will start at `http://localhost:9999` serving from the project root and generates the following files:

+ `./build/dev/prebid.js` - Full source code for dev and debug
+ `./build/dev/prebid.js.map` - Source map for dev and debug
+ `./build/dev/prebid-core.js`
+ `./build/dev/prebid-core.js.map`


Development may be a bit slower but if you prefer linting and additional watch files you can also still run just:

    $ gulp serve


### Build Optimization

The standard build output contains all the available modules from within the `modules` folder.  Note, however that there are bid adapters which support multiple bidders through aliases, so if you don&#039;t see a file in modules for a bid adapter, you may need to grep the repository to find the name of the module you need to include.

You might want to exclude some/most of them from the final bundle.  To make sure the build only includes the modules you want, you can specify the modules to be included with the `--modules` CLI argument.

For example, when running the serve command: `gulp serve --modules=openxBidAdapter,rubiconBidAdapter,sovrnBidAdapter`

Building with just these adapters will result in a smaller bundle which should allow your pages to load faster.

**Build standalone prebid.js**

- Clone the repo, run `npm ci`
- Then run the build:

        $ gulp build --modules=openxBidAdapter,rubiconBidAdapter,sovrnBidAdapter

Alternatively, a `.json` file can be specified that contains a list of modules you would like to include.

    $ gulp build --modules=modules.json

With `modules.json` containing the following
```json modules.json
[
  &quot;openxBidAdapter&quot;,
  &quot;rubiconBidAdapter&quot;,
  &quot;sovrnBidAdapter&quot;
]
```

**Build prebid.js using npm for bundling**

In case you&#039;d like to explicitly show that your project uses `prebid.js` and want a reproducible build, consider adding it as an `npm` dependency.

- Add `prebid.js` as a `npm` dependency of your project: `npm install prebid.js`
- Run the `prebid.js` build under the `node_modules/prebid.js/` folder

        $ gulp build --modules=path/to/your/list-of-modules.json

Most likely your custom `prebid.js` will only change when there&#039;s:

- A change in your list of modules
- A new release of `prebid.js`

Having said that, you are probably safe to check your custom bundle into your project.  You can also generate it in your build process.

**Build once, bundle multiple times**

If you need to generate multiple distinct bundles from the same Prebid version, you can reuse a single build with:

```
gulp build
gulp bundle --tag one --modules=one.json
gulp bundle --tag two --modules=two.json
```

This generates slightly larger files, but has the advantage of being much faster to run (after the initial `gulp build`). It&#039;s also the method used by [the Prebid.org download page](https://docs.prebid.org/download.html).

&lt;a name=&quot;Run&quot;&gt;&lt;/a&gt;

### Excluding particular features from the build

Since version 7.2.0, you may instruct the build to exclude code for some features - for example, if you don&#039;t need support for native ads:

```
gulp build --disable NATIVE --modules=openxBidAdapter,rubiconBidAdapter,sovrnBidAdapter # substitute your module list
```

Or, if you are consuming Prebid through npm, with the `disableFeatures` option in your Prebid rule:

```javascript
  {
    test: /.js$/,
    include: new RegExp(`\\${path.sep}prebid\\.js`),
    use: {
      loader: &#039;babel-loader&#039;,
      options: require(&#039;prebid.js/babelConfig.js&#039;)({disableFeatures: [&#039;NATIVE&#039;]})
    }
  }
```

Features that can be disabled this way are:

 - `VIDEO` - support for video bids;
 - `NATIVE` - support for native bids;
 - `UID2_CSTG` - support for UID2 client side token generation (see [Unified ID 2.0](https://docs.prebid.org/dev-docs/modules/userid-submodules/unified2.html))
 - `GREEDY` - disables the use blocking, &quot;greedy&quot; promises within Prebid (see below).    

#### Greedy promises

By default, Prebid attempts to hold control of the main thread when possible, using a [custom implementation of `Promise`](https://github.com/prebid/Prebid.js/blob/master/libraries/greedy/greedyPromise.js) that does not submit callbacks to the scheduler once the promise is resolved (running them immediately instead).
Disabling this behavior instructs Prebid to use the standard `window.Promise` instead; this has the effect of breaking up task execution, making them slower overall but giving the browser more chances to run other tasks in between, which can improve UX.         

You may also override the `Promise` constructor used by Prebid through `pbjs.Promise`, for example:

```javascript
var pbjs = pbjs || {};
pbjs.Promise = myCustomPromiseConstructor;
```

## Unminified code

You can get a version of the code that&#039;s unminified for debugging with `build-bundle-dev`:

```bash
gulp build-bundle-dev --modules=bidderA,module1,...
```

The results will be in build/dev/prebid.js.

## ES5 Output Support

For compatibility with older parsers or environments that require ES5 syntax, you can generate ES5-compatible output using the `--ES5` flag:

```bash
gulp build-bundle-dev --modules=bidderA,module1,... --ES5
```

This will:
- Transpile all code to ES5 syntax using CommonJS modules
- Target browsers: IE11+, Chrome 50+, Firefox 50+, Safari 10+
- Ensure compatibility with older JavaScript parsers

**Note:** Without the `--ES5` flag, the build will use modern ES6+ syntax by default for better performance and smaller bundle sizes.

## Test locally

To lint the code:

```bash
gulp lint
```

To lint and only show errors

```bash
gulp lint --no-lint-warnings
```

To run the unit tests:

```bash
gulp test
```

To run the unit tests for a particular file (example for pubmaticBidAdapter_spec.js):
```bash
gulp test --file &quot;test/spec/modules/pubmaticBidAdapter_spec.js&quot; --nolint
```

To generate and view the code coverage reports:

```bash
gulp test-coverage
gulp view-coverage
```

Local end-to-end testing can be done with:

```bash
gulp e2e-test --local
```

For Prebid.org members with access to BrowserStack, additional end-to-end testing can be done with:

```bash
gulp e2e-test --host=test.localhost
```

To run these tests, the following items are required:
- setup an alias of localhost in your `hosts` file (eg `127.0.0.1  test.localhost`); note - you can use any alias.  Use this alias in the command-line argument above.
- access to [BrowserStack](https://www.browserstack.com/) account.  Assign the following variables in your bash_profile:
```bash
export BROWSERSTACK_USERNAME=&#039;YourUserNameHere&#039;
export BROWSERSTACK_ACCESS_KEY=&#039;YourAccessKeyHere&#039;
```
You can get these BrowserStack values from your profile page.

For development:

```javascript
(function() {
    var d = document, pbs = d.createElement(&#039;script&#039;), pro = d.location.protocol;
    pbs.type = &#039;text/javascript&#039;;
    pbs.src = ((pro === &#039;https:&#039;) ? &#039;https&#039; : &#039;http&#039;) + &#039;./build/dev/prebid.js&#039;;
    var target = document.getElementsByTagName(&#039;head&#039;)[0];
    target.insertBefore(pbs, target.firstChild);
})();
```

For deployment:

```javascript
(function() {
    var d = document, pbs = d.createElement(&#039;script&#039;), pro = d.location.protocol;
    pbs.type = &#039;text/javascript&#039;;
    pbs.src = ((pro === &#039;https:&#039;) ? &#039;https&#039; : &#039;http&#039;) + &#039;./build/dist/prebid.js&#039;;
    var target = document.getElementsByTagName(&#039;head&#039;)[0];
    target.insertBefore(pbs, target.firstChild);
})();
```

Build and run the project locally with:

```bash
gulp serve
```

This runs `lint` and `test`, then starts a web server at `http://localhost:9999` serving from the project root.
Navigate to your example implementation to test, and if your `prebid.js` file is sourced from the `./build/dev`
directory you will have sourcemaps available in your browser&#039;s developer tools.

To run the example file, go to:

+ `http://localhost:9999/integrationExamples/gpt/hello_world.html`

As you make code changes, the bundles will be rebuilt and the page reloaded automatically.

&lt;a name=&quot;Contribute&quot;&gt;&lt;/a&gt;

## Contribute

Many SSPs, bidders, and publishers have contributed to this project. [Hundreds of bidders](https://github.com/prebid/Prebid.js/tree/master/modules) are supported by Prebid.js.

For guidelines, see [Contributing](./CONTRIBUTING.md).

Our PR review process can be found [here](https://github.com/prebid/Prebid.js/tree/master/PR_REVIEW.md).

### Add a Bidder Adapter

To add a bidder adapter module, see the instructions in [How to add a bidder adapter](https://docs.prebid.org/dev-docs/bidder-adaptor.html).

### Code Quality

Code quality is defined by `.eslintrc` and errors are reported in the terminal.

If you are contributing code, you should [configure your editor](http://eslint.org/docs/user-guide/integrations#editors) with the provided `.eslintrc` settings.

### Unit Testing with Karma

        $ gulp test --watch --browsers=chrome

This will run tests and keep the Karma test browser open. If your `prebid.js` file is sourced from the `./build/dev` directory you will also have sourcemaps available when using your browser&#039;s developer tools.

+ To access the Karma debug page, go to `http://localhost:9876/debug.html`

+ For test results, see the console

+ To set breakpoints in source code, see the developer tools

Detailed code coverage reporting can be generated explicitly with

        $ gulp test --coverage

The results will be in

        ./build/coverage

*Note*: Starting in June 2016, all pull requests to Prebid.js need to include tests with greater than 80% code coverage before they can be merged.  For more information, see [#421](https://github.com/prebid/Prebid.js/issues/421).

For instructions on writing tests for Prebid.js, see [Testing Prebid.js](https://prebid.org/dev-docs/testing-prebid.html).

### Supported Browsers

Prebid.js is supported on IE11 and modern browsers until 5.x. 6.x+ transpiles to target &gt;0.25%; not Opera Mini; not IE11.

### Governance
Review our governance model [here](https://github.com/prebid/Prebid.js/tree/master/governance.md).
### END
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[node-red/node-red]]></title>
            <link>https://github.com/node-red/node-red</link>
            <guid>https://github.com/node-red/node-red</guid>
            <pubDate>Sat, 28 Jun 2025 00:04:29 GMT</pubDate>
            <description><![CDATA[Low-code programming for event-driven applications]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/node-red/node-red">node-red/node-red</a></h1>
            <p>Low-code programming for event-driven applications</p>
            <p>Language: JavaScript</p>
            <p>Stars: 21,434</p>
            <p>Forks: 3,611</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># Node-RED

https://nodered.org

[![Build Status](https://github.com/node-red/node-red/actions/workflows/tests.yml/badge.svg?branch=master)](https://github.com/node-red/node-red/actions?query=branch%3Amaster)

Low-code programming for event-driven applications.

![Node-RED: Low-code programming for event-driven applications](https://nodered.org/images/node-red-screenshot.png)

## Quick Start

Check out https://nodered.org/docs/getting-started/ for full instructions on getting
started.

1. `sudo npm install -g --unsafe-perm node-red`
2. `node-red`
3. Open &lt;http://localhost:1880&gt;

## Getting Help

More documentation can be found [here](https://nodered.org/docs).

For further help, or general discussion, please use the [Node-RED Forum](https://discourse.nodered.org) or [slack team](https://nodered.org/slack).

## Developers

If you want to run the latest code from git, here&#039;s how to get started:

1. Clone the code:

        git clone https://github.com/node-red/node-red.git
        cd node-red

2. Install the node-red dependencies

        npm install

3. Build the code

        npm run build

4. Run

        npm start

## Contributing

Before raising a pull-request, please read our
[contributing guide](https://github.com/node-red/node-red/blob/master/CONTRIBUTING.md).

This project adheres to the [Contributor Covenant 1.4](http://contributor-covenant.org/version/1/4/).
 By participating, you are expected to uphold this code. Please report unacceptable
 behavior to any of the project&#039;s core team at team@nodered.org.

## Authors

Node-RED is a project of the [OpenJS Foundation](http://openjsf.org).

It is maintained by:

 * Nick O&#039;Leary [@knolleary](http://twitter.com/knolleary)
 * Dave Conway-Jones [@ceejay](http://twitter.com/ceejay)
 * And many others...


## Copyright and license

Copyright OpenJS Foundation and other contributors, https://openjsf.org under [the Apache 2.0 license](LICENSE).
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[usebruno/bruno]]></title>
            <link>https://github.com/usebruno/bruno</link>
            <guid>https://github.com/usebruno/bruno</guid>
            <pubDate>Sat, 28 Jun 2025 00:04:28 GMT</pubDate>
            <description><![CDATA[Opensource IDE For Exploring and Testing API's (lightweight alternative to Postman/Insomnia)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/usebruno/bruno">usebruno/bruno</a></h1>
            <p>Opensource IDE For Exploring and Testing API's (lightweight alternative to Postman/Insomnia)</p>
            <p>Language: JavaScript</p>
            <p>Stars: 35,219</p>
            <p>Forks: 1,712</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[axios/axios]]></title>
            <link>https://github.com/axios/axios</link>
            <guid>https://github.com/axios/axios</guid>
            <pubDate>Sat, 28 Jun 2025 00:04:27 GMT</pubDate>
            <description><![CDATA[Promise based HTTP client for the browser and node.js]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/axios/axios">axios/axios</a></h1>
            <p>Promise based HTTP client for the browser and node.js</p>
            <p>Language: JavaScript</p>
            <p>Stars: 107,134</p>
            <p>Forks: 11,153</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre># axios

[![npm version](https://img.shields.io/npm/v/axios.svg?style=flat-square)](https://www.npmjs.org/package/axios)
[![CDNJS](https://img.shields.io/cdnjs/v/axios.svg?style=flat-square)](https://cdnjs.com/libraries/axios)
![Build status](https://github.com/axios/axios/actions/workflows/ci.yml/badge.svg)
[![Gitpod Ready-to-Code](https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod)](https://gitpod.io/#https://github.com/axios/axios) 
[![code coverage](https://img.shields.io/coveralls/mzabriskie/axios.svg?style=flat-square)](https://coveralls.io/r/mzabriskie/axios)
[![install size](https://packagephobia.now.sh/badge?p=axios)](https://packagephobia.now.sh/result?p=axios)
[![npm downloads](https://img.shields.io/npm/dm/axios.svg?style=flat-square)](https://npm-stat.com/charts.html?package=axios)
[![gitter chat](https://img.shields.io/gitter/room/mzabriskie/axios.svg?style=flat-square)](https://gitter.im/mzabriskie/axios)
[![code helpers](https://www.codetriage.com/axios/axios/badges/users.svg)](https://www.codetriage.com/axios/axios)
[![Known Vulnerabilities](https://snyk.io/test/npm/axios/badge.svg)](https://snyk.io/test/npm/axios)
![npm bundle size](https://img.shields.io/bundlephobia/minzip/axios)

Promise based HTTP client for the browser and node.js

&gt; New axios docs website: [click here](https://axios-http.com/)

## Table of Contents

  - [Features](#features)
  - [Browser Support](#browser-support)
  - [Installing](#installing)
  - [Example](#example)
  - [Axios API](#axios-api)
  - [Request method aliases](#request-method-aliases)
  - [Concurrency 👎](#concurrency-deprecated)
  - [Creating an instance](#creating-an-instance)
  - [Instance methods](#instance-methods)
  - [Request Config](#request-config)
  - [Response Schema](#response-schema)
  - [Config Defaults](#config-defaults)
    - [Global axios defaults](#global-axios-defaults)
    - [Custom instance defaults](#custom-instance-defaults)
    - [Config order of precedence](#config-order-of-precedence)
  - [Interceptors](#interceptors)
    - [Multiple Interceptors](#multiple-interceptors)
  - [Handling Errors](#handling-errors)
  - [Cancellation](#cancellation)
    - [AbortController](#abortcontroller)
    - [CancelToken 👎](#canceltoken-deprecated)
  - [Using application/x-www-form-urlencoded format](#using-applicationx-www-form-urlencoded-format)
    - [URLSearchParams](#urlsearchparams)
    - [Query string](#query-string-older-browsers)
    - [🆕 Automatic serialization](#-automatic-serialization-to-urlsearchparams)        
  - [Using multipart/form-data format](#using-multipartform-data-format)    
    - [FormData](#formdata)
    - [🆕 Automatic serialization](#-automatic-serialization-to-formdata) 
  - [Files Posting](#files-posting)
  - [HTML Form Posting](#html-form-posting-browser)
  - [Semver](#semver)
  - [Promises](#promises)
  - [TypeScript](#typescript)
  - [Resources](#resources)
  - [Credits](#credits)
  - [License](#license)

## Features

- Make [XMLHttpRequests](https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest) from the browser
- Make [http](https://nodejs.org/api/http.html) requests from node.js
- Supports the [Promise](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise) API
- Intercept request and response
- Transform request and response data
- Cancel requests
- Automatic transforms for JSON data
- 🆕 Automatic data object serialization to `multipart/form-data` and `x-www-form-urlencoded` body encodings
- Client side support for protecting against [XSRF](https://en.wikipedia.org/wiki/Cross-site_request_forgery)

## Browser Support

![Chrome](https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_48x48.png) | ![Firefox](https://raw.githubusercontent.com/alrra/browser-logos/main/src/firefox/firefox_48x48.png) | ![Safari](https://raw.githubusercontent.com/alrra/browser-logos/main/src/safari/safari_48x48.png) | ![Opera](https://raw.githubusercontent.com/alrra/browser-logos/main/src/opera/opera_48x48.png) | ![Edge](https://raw.githubusercontent.com/alrra/browser-logos/main/src/edge/edge_48x48.png) | ![IE](https://raw.githubusercontent.com/alrra/browser-logos/master/src/archive/internet-explorer_9-11/internet-explorer_9-11_48x48.png) |
--- | --- | --- | --- | --- | --- |
Latest ✔ | Latest ✔ | Latest ✔ | Latest ✔ | Latest ✔ | 11 ✔ |

[![Browser Matrix](https://saucelabs.com/open_sauce/build_matrix/axios.svg)](https://saucelabs.com/u/axios)

## Installing

Using npm:

```bash
$ npm install axios
```

Using bower:

```bash
$ bower install axios
```

Using yarn:

```bash
$ yarn add axios
```

Using pnpm:

```bash
$ pnpm add axios
```

Using jsDelivr CDN:

```html
&lt;script src=&quot;https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js&quot;&gt;&lt;/script&gt;
```

Using unpkg CDN:

```html
&lt;script src=&quot;https://unpkg.com/axios/dist/axios.min.js&quot;&gt;&lt;/script&gt;
```

## Example

### note: CommonJS usage
In order to gain the TypeScript typings (for intellisense / autocomplete) while using CommonJS imports with `require()` use the following approach:

```js
const axios = require(&#039;axios&#039;).default;

// axios.&lt;method&gt; will now provide autocomplete and parameter typings
```

Performing a `GET` request

```js
const axios = require(&#039;axios&#039;).default;

// Make a request for a user with a given ID
axios.get(&#039;/user?ID=12345&#039;)
  .then(function (response) {
    // handle success
    console.log(response);
  })
  .catch(function (error) {
    // handle error
    console.log(error);
  })
  .then(function () {
    // always executed
  });

// Optionally the request above could also be done as
axios.get(&#039;/user&#039;, {
    params: {
      ID: 12345
    }
  })
  .then(function (response) {
    console.log(response);
  })
  .catch(function (error) {
    console.log(error);
  })
  .then(function () {
    // always executed
  });  

// Want to use async/await? Add the `async` keyword to your outer function/method.
async function getUser() {
  try {
    const response = await axios.get(&#039;/user?ID=12345&#039;);
    console.log(response);
  } catch (error) {
    console.error(error);
  }
}
```

&gt; **NOTE:** `async/await` is part of ECMAScript 2017 and is not supported in Internet
&gt; Explorer and older browsers, so use with caution.

Performing a `POST` request

```js
axios.post(&#039;/user&#039;, {
    firstName: &#039;Fred&#039;,
    lastName: &#039;Flintstone&#039;
  })
  .then(function (response) {
    console.log(response);
  })
  .catch(function (error) {
    console.log(error);
  });
```

Performing multiple concurrent requests

```js
function getUserAccount() {
  return axios.get(&#039;/user/12345&#039;);
}

function getUserPermissions() {
  return axios.get(&#039;/user/12345/permissions&#039;);
}

Promise.all([getUserAccount(), getUserPermissions()])
  .then(function (results) {
    const acct = results[0];
    const perm = results[1];
  });
```

## axios API

Requests can be made by passing the relevant config to `axios`.

##### axios(config)

```js
// Send a POST request
axios({
  method: &#039;post&#039;,
  url: &#039;/user/12345&#039;,
  data: {
    firstName: &#039;Fred&#039;,
    lastName: &#039;Flintstone&#039;
  }
});
```

```js
// GET request for remote image in node.js
axios({
  method: &#039;get&#039;,
  url: &#039;https://bit.ly/2mTM3nY&#039;,
  responseType: &#039;stream&#039;
})
  .then(function (response) {
    response.data.pipe(fs.createWriteStream(&#039;ada_lovelace.jpg&#039;))
  });
```

##### axios(url[, config])

```js
// Send a GET request (default method)
axios(&#039;/user/12345&#039;);
```

### Request method aliases

For convenience, aliases have been provided for all common request methods.

##### axios.request(config)
##### axios.get(url[, config])
##### axios.delete(url[, config])
##### axios.head(url[, config])
##### axios.options(url[, config])
##### axios.post(url[, data[, config]])
##### axios.put(url[, data[, config]])
##### axios.patch(url[, data[, config]])

###### NOTE
When using the alias methods `url`, `method`, and `data` properties don&#039;t need to be specified in config.

### Concurrency (Deprecated)
Please use `Promise.all` to replace the below functions.

Helper functions for dealing with concurrent requests.

axios.all(iterable)
axios.spread(callback)

### Creating an instance

You can create a new instance of axios with a custom config.

##### axios.create([config])

```js
const instance = axios.create({
  baseURL: &#039;https://some-domain.com/api/&#039;,
  timeout: 1000,
  headers: {&#039;X-Custom-Header&#039;: &#039;foobar&#039;}
});
```

### Instance methods

The available instance methods are listed below. The specified config will be merged with the instance config.

##### axios#request(config)
##### axios#get(url[, config])
##### axios#delete(url[, config])
##### axios#head(url[, config])
##### axios#options(url[, config])
##### axios#post(url[, data[, config]])
##### axios#put(url[, data[, config]])
##### axios#patch(url[, data[, config]])
##### axios#getUri([config])

## Request Config

These are the available config options for making requests. Only the `url` is required. Requests will default to `GET` if `method` is not specified.

```js
{
  // `url` is the server URL that will be used for the request
  url: &#039;/user&#039;,

  // `method` is the request method to be used when making the request
  method: &#039;get&#039;, // default

  // `baseURL` will be prepended to `url` unless `url` is absolute.
  // It can be convenient to set `baseURL` for an instance of axios to pass relative URLs
  // to methods of that instance.
  baseURL: &#039;https://some-domain.com/api/&#039;,

  // `transformRequest` allows changes to the request data before it is sent to the server
  // This is only applicable for request methods &#039;PUT&#039;, &#039;POST&#039;, &#039;PATCH&#039; and &#039;DELETE&#039;
  // The last function in the array must return a string or an instance of Buffer, ArrayBuffer,
  // FormData or Stream
  // You may modify the headers object.
  transformRequest: [function (data, headers) {
    // Do whatever you want to transform the data

    return data;
  }],

  // `transformResponse` allows changes to the response data to be made before
  // it is passed to then/catch
  transformResponse: [function (data) {
    // Do whatever you want to transform the data

    return data;
  }],

  // `headers` are custom headers to be sent
  headers: {&#039;X-Requested-With&#039;: &#039;XMLHttpRequest&#039;},

  // `params` are the URL parameters to be sent with the request
  // Must be a plain object or a URLSearchParams object
  params: {
    ID: 12345
  },

  // `paramsSerializer` is an optional config in charge of serializing `params`
  paramsSerializer: {
    indexes: null // array indexes format (null - no brackets, false - empty brackets, true - brackets with indexes)
  },

  // `data` is the data to be sent as the request body
  // Only applicable for request methods &#039;PUT&#039;, &#039;POST&#039;, &#039;DELETE , and &#039;PATCH&#039;
  // When no `transformRequest` is set, must be of one of the following types:
  // - string, plain object, ArrayBuffer, ArrayBufferView, URLSearchParams
  // - Browser only: FormData, File, Blob
  // - Node only: Stream, Buffer
  data: {
    firstName: &#039;Fred&#039;
  },
  
  // syntax alternative to send data into the body
  // method post
  // only the value is sent, not the key
  data: &#039;Country=Brasil&amp;City=Belo Horizonte&#039;,

  // `timeout` specifies the number of milliseconds before the request times out.
  // If the request takes longer than `timeout`, the request will be aborted.
  timeout: 1000, // default is `0` (no timeout)

  // `withCredentials` indicates whether or not cross-site Access-Control requests
  // should be made using credentials
  withCredentials: false, // default

  // `adapter` allows custom handling of requests which makes testing easier.
  // Return a promise and supply a valid response (see lib/adapters/README.md).
  adapter: function (config) {
    /* ... */
  },

  // `auth` indicates that HTTP Basic auth should be used, and supplies credentials.
  // This will set an `Authorization` header, overwriting any existing
  // `Authorization` custom headers you have set using `headers`.
  // Please note that only HTTP Basic auth is configurable through this parameter.
  // For Bearer tokens and such, use `Authorization` custom headers instead.
  auth: {
    username: &#039;janedoe&#039;,
    password: &#039;s00pers3cret&#039;
  },

  // `responseType` indicates the type of data that the server will respond with
  // options are: &#039;arraybuffer&#039;, &#039;document&#039;, &#039;json&#039;, &#039;text&#039;, &#039;stream&#039;
  //   browser only: &#039;blob&#039;
  responseType: &#039;json&#039;, // default

  // `responseEncoding` indicates encoding to use for decoding responses (Node.js only)
  // Note: Ignored for `responseType` of &#039;stream&#039; or client-side requests
  responseEncoding: &#039;utf8&#039;, // default

  // `xsrfCookieName` is the name of the cookie to use as a value for xsrf token
  xsrfCookieName: &#039;XSRF-TOKEN&#039;, // default

  // `xsrfHeaderName` is the name of the http header that carries the xsrf token value
  xsrfHeaderName: &#039;X-XSRF-TOKEN&#039;, // default

  // `onUploadProgress` allows handling of progress events for uploads
  // browser only
  onUploadProgress: function (progressEvent) {
    // Do whatever you want with the native progress event
  },

  // `onDownloadProgress` allows handling of progress events for downloads
  // browser only
  onDownloadProgress: function (progressEvent) {
    // Do whatever you want with the native progress event
  },

  // `maxContentLength` defines the max size of the http response content in bytes allowed in node.js
  maxContentLength: 2000,

  // `maxBodyLength` (Node only option) defines the max size of the http request content in bytes allowed
  maxBodyLength: 2000,

  // `validateStatus` defines whether to resolve or reject the promise for a given
  // HTTP response status code. If `validateStatus` returns `true` (or is set to `null`
  // or `undefined`), the promise will be resolved; otherwise, the promise will be
  // rejected.
  validateStatus: function (status) {
    return status &gt;= 200 &amp;&amp; status &lt; 300; // default
  },

  // `maxRedirects` defines the maximum number of redirects to follow in node.js.
  // If set to 0, no redirects will be followed.
  maxRedirects: 21, // default

  // `beforeRedirect` defines a function that will be called before redirect.
  // Use this to adjust the request options upon redirecting,
  // to inspect the latest response headers,
  // or to cancel the request by throwing an error
  // If maxRedirects is set to 0, `beforeRedirect` is not used.
  beforeRedirect: (options, { headers }) =&gt; {
    if (options.hostname === &quot;example.com&quot;) {
      options.auth = &quot;user:password&quot;;
    }
  },

  // `socketPath` defines a UNIX Socket to be used in node.js.
  // e.g. &#039;/var/run/docker.sock&#039; to send requests to the docker daemon.
  // Only either `socketPath` or `proxy` can be specified.
  // If both are specified, `socketPath` is used.
  socketPath: null, // default

  // `httpAgent` and `httpsAgent` define a custom agent to be used when performing http
  // and https requests, respectively, in node.js. This allows options to be added like
  // `keepAlive` that are not enabled by default.
  httpAgent: new http.Agent({ keepAlive: true }),
  httpsAgent: new https.Agent({ keepAlive: true }),

  // `proxy` defines the hostname, port, and protocol of the proxy server.
  // You can also define your proxy using the conventional `http_proxy` and
  // `https_proxy` environment variables. If you are using environment variables
  // for your proxy configuration, you can also define a `no_proxy` environment
  // variable as a comma-separated list of domains that should not be proxied.
  // Use `false` to disable proxies, ignoring environment variables.
  // `auth` indicates that HTTP Basic auth should be used to connect to the proxy, and
  // supplies credentials.
  // This will set an `Proxy-Authorization` header, overwriting any existing
  // `Proxy-Authorization` custom headers you have set using `headers`.
  // If the proxy server uses HTTPS, then you must set the protocol to `https`. 
  proxy: {
    protocol: &#039;https&#039;,
    host: &#039;127.0.0.1&#039;,
    port: 9000,
    auth: {
      username: &#039;mikeymike&#039;,
      password: &#039;rapunz3l&#039;
    }
  },

  // `cancelToken` specifies a cancel token that can be used to cancel the request
  // (see Cancellation section below for details)
  cancelToken: new CancelToken(function (cancel) {
  }),

  // an alternative way to cancel Axios requests using AbortController
  signal: new AbortController().signal,

  // `decompress` indicates whether or not the response body should be decompressed 
  // automatically. If set to `true` will also remove the &#039;content-encoding&#039; header 
  // from the responses objects of all decompressed responses
  // - Node only (XHR cannot turn off decompression)
  decompress: true // default

  // `insecureHTTPParser` boolean.
  // Indicates where to use an insecure HTTP parser that accepts invalid HTTP headers.
  // This may allow interoperability with non-conformant HTTP implementations.
  // Using the insecure parser should be avoided.
  // see options https://nodejs.org/dist/latest-v12.x/docs/api/http.html#http_http_request_url_options_callback
  // see also https://nodejs.org/en/blog/vulnerability/february-2020-security-releases/#strict-http-header-parsing-none
  insecureHTTPParser: undefined // default

  // transitional options for backward compatibility that may be removed in the newer versions
  transitional: {
    // silent JSON parsing mode
    // `true`  - ignore JSON parsing errors and set response.data to null if parsing failed (old behaviour)
    // `false` - throw SyntaxError if JSON parsing failed (Note: responseType must be set to &#039;json&#039;)
    silentJSONParsing: true, // default value for the current Axios version

    // try to parse the response string as JSON even if `responseType` is not &#039;json&#039;
    forcedJSONParsing: true,
    
    // throw ETIMEDOUT error instead of generic ECONNABORTED on request timeouts
    clarifyTimeoutError: false,
  },

  env: {
    // The FormData class to be used to automatically serialize the payload into a FormData object
    FormData: window?.FormData || global?.FormData
  },

  formSerializer: {
      visitor: (value, key, path, helpers)=&gt; {}; // custom visitor funaction to serrialize form values
      dots: boolean; // use dots instead of brackets format
      metaTokens: boolean; // keep special endings like {} in parameter key 
      indexes: boolean; // array indexes format null - no brackets, false - empty brackets, true - brackets with indexes
  }
}
```

## Response Schema

The response for a request contains the following information.

```js
{
  // `data` is the response that was provided by the server
  data: {},

  // `status` is the HTTP status code from the server response
  status: 200,

  // `statusText` is the HTTP status message from the server response
  statusText: &#039;OK&#039;,

  // `headers` the HTTP headers that the server responded with
  // All header names are lowercase and can be accessed using the bracket notation.
  // Example: `response.headers[&#039;content-type&#039;]`
  headers: {},

  // `config` is the config that was provided to `axios` for the request
  config: {},

  // `request` is the request that generated this response
  // It is the last ClientRequest instance in node.js (in redirects)
  // and an XMLHttpRequest instance in the browser
  request: {}
}
```

When using `then`, you will receive the response as follows:

```js
axios.get(&#039;/user/12345&#039;)
  .then(function (response) {
    console.log(response.data);
    console.log(response.status);
    console.log(response.statusText);
    console.log(response.headers);
    console.log(response.config);
  });
```

When using `catch`, or passing a [rejection callback](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/then) as second parameter of `then`, the response will be available through the `error` object as explained in the [Handling Errors](#handling-errors) section.

## Config Defaults

You can specify config defaults that will be applied to every request.

### Global axios defaults

```js
axios.defaults.bas

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[nodejs/undici]]></title>
            <link>https://github.com/nodejs/undici</link>
            <guid>https://github.com/nodejs/undici</guid>
            <pubDate>Sat, 28 Jun 2025 00:04:26 GMT</pubDate>
            <description><![CDATA[An HTTP/1.1 client, written from scratch for Node.js]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nodejs/undici">nodejs/undici</a></h1>
            <p>An HTTP/1.1 client, written from scratch for Node.js</p>
            <p>Language: JavaScript</p>
            <p>Stars: 6,902</p>
            <p>Forks: 645</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># undici

[![Node CI](https://github.com/nodejs/undici/actions/workflows/nodejs.yml/badge.svg)](https://github.com/nodejs/undici/actions/workflows/nodejs.yml) [![neostandard javascript style](https://img.shields.io/badge/neo-standard-7fffff?style=flat\&amp;labelColor=ff80ff)](https://github.com/neostandard/neostandard) [![npm version](https://badge.fury.io/js/undici.svg)](https://badge.fury.io/js/undici) [![codecov](https://codecov.io/gh/nodejs/undici/branch/main/graph/badge.svg?token=yZL6LtXkOA)](https://codecov.io/gh/nodejs/undici)

An HTTP/1.1 client, written from scratch for Node.js.

&gt; Undici means eleven in Italian. 1.1 -&gt; 11 -&gt; Eleven -&gt; Undici.
It is also a Stranger Things reference.

## How to get involved

Have a question about using Undici? Open a [Q&amp;A Discussion](https://github.com/nodejs/undici/discussions/new) or join our official OpenJS [Slack](https://openjs-foundation.slack.com/archives/C01QF9Q31QD) channel.

Looking to contribute? Start by reading the [contributing guide](./CONTRIBUTING.md)

## Install

```
npm i undici
```

## Benchmarks

The benchmark is a simple getting data [example](https://github.com/nodejs/undici/blob/main/benchmarks/benchmark.js) using a
50 TCP connections with a pipelining depth of 10 running on Node 22.11.0.

```
┌────────────────────────┬─────────┬────────────────────┬────────────┬─────────────────────────┐
│  Tests                 │ Samples │ Result             │ Tolerance  │ Difference with slowest │
├────────────────────────┼─────────┼────────────────────┼────────────┼─────────────────────────┤
│  &#039;axios&#039;               │ 15      │ &#039;5708.26 req/sec&#039;  │ &#039;± 2.91 %&#039; │ &#039;-&#039;                     │
│  &#039;http - no keepalive&#039; │ 10      │ &#039;5809.80 req/sec&#039;  │ &#039;± 2.30 %&#039; │ &#039;+ 1.78 %&#039;              │
│  &#039;request&#039;             │ 30      │ &#039;5828.80 req/sec&#039;  │ &#039;± 2.91 %&#039; │ &#039;+ 2.11 %&#039;              │
│  &#039;undici - fetch&#039;      │ 40      │ &#039;5903.78 req/sec&#039;  │ &#039;± 2.87 %&#039; │ &#039;+ 3.43 %&#039;              │
│  &#039;node-fetch&#039;          │ 10      │ &#039;5945.40 req/sec&#039;  │ &#039;± 2.13 %&#039; │ &#039;+ 4.15 %&#039;              │
│  &#039;got&#039;                 │ 35      │ &#039;6511.45 req/sec&#039;  │ &#039;± 2.84 %&#039; │ &#039;+ 14.07 %&#039;             │
│  &#039;http - keepalive&#039;    │ 65      │ &#039;9193.24 req/sec&#039;  │ &#039;± 2.92 %&#039; │ &#039;+ 61.05 %&#039;             │
│  &#039;superagent&#039;          │ 35      │ &#039;9339.43 req/sec&#039;  │ &#039;± 2.95 %&#039; │ &#039;+ 63.61 %&#039;             │
│  &#039;undici - pipeline&#039;   │ 50      │ &#039;13364.62 req/sec&#039; │ &#039;± 2.93 %&#039; │ &#039;+ 134.13 %&#039;            │
│  &#039;undici - stream&#039;     │ 95      │ &#039;18245.36 req/sec&#039; │ &#039;± 2.99 %&#039; │ &#039;+ 219.63 %&#039;            │
│  &#039;undici - request&#039;    │ 50      │ &#039;18340.17 req/sec&#039; │ &#039;± 2.84 %&#039; │ &#039;+ 221.29 %&#039;            │
│  &#039;undici - dispatch&#039;   │ 40      │ &#039;22234.42 req/sec&#039; │ &#039;± 2.94 %&#039; │ &#039;+ 289.51 %&#039;            │
└────────────────────────┴─────────┴────────────────────┴────────────┴─────────────────────────┘
```

## Undici vs. Fetch

### Overview

Node.js includes a built-in `fetch()` implementation powered by undici starting from Node.js v18. However, there are important differences between using the built-in fetch and installing undici as a separate module.

### Built-in Fetch (Node.js v18+)

Node.js&#039;s built-in fetch is powered by a bundled version of undici:

```js
// Available globally in Node.js v18+
const response = await fetch(&#039;https://api.example.com/data&#039;);
const data = await response.json();

// Check the bundled undici version
console.log(process.versions.undici); // e.g., &quot;5.28.4&quot;
```

**Pros:**
- No additional dependencies required
- Works across different JavaScript runtimes
- Automatic compression handling (gzip, deflate, br)
- Built-in caching support (in development)

**Cons:**
- Limited to the undici version bundled with your Node.js version
- Less control over connection pooling and advanced features
- Error handling follows Web API standards (errors wrapped in `TypeError`)
- Performance overhead due to Web Streams implementation

### Undici Module

Installing undici as a separate module gives you access to the latest features and APIs:

```bash
npm install undici
```

```js
import { request, fetch, Agent, setGlobalDispatcher } from &#039;undici&#039;;

// Use undici.request for maximum performance
const { statusCode, headers, body } = await request(&#039;https://api.example.com/data&#039;);
const data = await body.json();

// Or use undici.fetch with custom configuration
const agent = new Agent({ keepAliveTimeout: 10000 });
setGlobalDispatcher(agent);
const response = await fetch(&#039;https://api.example.com/data&#039;);
```

**Pros:**
- Latest undici features and bug fixes
- Access to advanced APIs (`request`, `stream`, `pipeline`)
- Fine-grained control over connection pooling
- Better error handling with clearer error messages
- Superior performance, especially with `undici.request`
- HTTP/1.1 pipelining support
- Custom interceptors and middleware
- Advanced features like `ProxyAgent`, `MockAgent`

**Cons:**
- Additional dependency to manage
- Larger bundle size

### When to Use Each

#### Use Built-in Fetch When:
- You want zero dependencies
- Building isomorphic code that runs in browsers and Node.js
- Simple HTTP requests without advanced configuration
- You&#039;re okay with the undici version bundled in your Node.js version

#### Use Undici Module When:
- You need the latest undici features and performance improvements
- You require advanced connection pooling configuration
- You need APIs not available in the built-in fetch (`ProxyAgent`, `MockAgent`, etc.)
- Performance is critical (use `undici.request` for maximum speed)
- You want better error handling and debugging capabilities
- You need HTTP/1.1 pipelining or advanced interceptors
- You prefer decoupled protocol and API interfaces

### Performance Comparison

Based on benchmarks, here&#039;s the typical performance hierarchy:

1. **`undici.request()`** - Fastest, most efficient
2. **`undici.fetch()`** - Good performance, standard compliance
3. **Node.js `http`/`https`** - Baseline performance

### Migration Guide

If you&#039;re currently using built-in fetch and want to migrate to undici:

```js
// Before: Built-in fetch
const response = await fetch(&#039;https://api.example.com/data&#039;);

// After: Undici fetch (drop-in replacement)
import { fetch } from &#039;undici&#039;;
const response = await fetch(&#039;https://api.example.com/data&#039;);

// Or: Undici request (better performance)
import { request } from &#039;undici&#039;;
const { statusCode, body } = await request(&#039;https://api.example.com/data&#039;);
const data = await body.json();
```

### Version Compatibility

You can check which version of undici is bundled with your Node.js version:

```js
console.log(process.versions.undici);
```

Installing undici as a module allows you to use a newer version than what&#039;s bundled with Node.js, giving you access to the latest features and performance improvements.

## Quick Start

```js
import { request } from &#039;undici&#039;

const {
  statusCode,
  headers,
  trailers,
  body
} = await request(&#039;http://localhost:3000/foo&#039;)

console.log(&#039;response received&#039;, statusCode)
console.log(&#039;headers&#039;, headers)

for await (const data of body) { console.log(&#039;data&#039;, data) }

console.log(&#039;trailers&#039;, trailers)
```

## Global Installation

Undici provides an `install()` function to add all WHATWG fetch classes to `globalThis`, making them available globally:

```js
import { install } from &#039;undici&#039;

// Install all WHATWG fetch classes globally
install()

// Now you can use fetch classes globally without importing
const response = await fetch(&#039;https://api.example.com/data&#039;)
const data = await response.json()

// All classes are available globally:
const headers = new Headers([[&#039;content-type&#039;, &#039;application/json&#039;]])
const request = new Request(&#039;https://example.com&#039;)
const formData = new FormData()
const ws = new WebSocket(&#039;wss://example.com&#039;)
const eventSource = new EventSource(&#039;https://example.com/events&#039;)
```

The `install()` function adds the following classes to `globalThis`:

- `fetch` - The fetch function
- `Headers` - HTTP headers management
- `Response` - HTTP response representation
- `Request` - HTTP request representation  
- `FormData` - Form data handling
- `WebSocket` - WebSocket client
- `CloseEvent`, `ErrorEvent`, `MessageEvent` - WebSocket events
- `EventSource` - Server-sent events client

This is useful for:
- Polyfilling environments that don&#039;t have fetch
- Ensuring consistent fetch behavior across different Node.js versions
- Making undici&#039;s implementations available globally for libraries that expect them

## Body Mixins

The `body` mixins are the most common way to format the request/response body. Mixins include:

- [`.arrayBuffer()`](https://fetch.spec.whatwg.org/#dom-body-arraybuffer)
- [`.blob()`](https://fetch.spec.whatwg.org/#dom-body-blob)
- [`.bytes()`](https://fetch.spec.whatwg.org/#dom-body-bytes)
- [`.json()`](https://fetch.spec.whatwg.org/#dom-body-json)
- [`.text()`](https://fetch.spec.whatwg.org/#dom-body-text)

&gt; [!NOTE]
&gt; The body returned from `undici.request` does not implement `.formData()`.

Example usage:

```js
import { request } from &#039;undici&#039;

const {
  statusCode,
  headers,
  trailers,
  body
} = await request(&#039;http://localhost:3000/foo&#039;)

console.log(&#039;response received&#039;, statusCode)
console.log(&#039;headers&#039;, headers)
console.log(&#039;data&#039;, await body.json())
console.log(&#039;trailers&#039;, trailers)
```

_Note: Once a mixin has been called then the body cannot be reused, thus calling additional mixins on `.body`, e.g. `.body.json(); .body.text()` will result in an error `TypeError: unusable` being thrown and returned through the `Promise` rejection._

Should you need to access the `body` in plain-text after using a mixin, the best practice is to use the `.text()` mixin first and then manually parse the text to the desired format.

For more information about their behavior, please reference the body mixin from the [Fetch Standard](https://fetch.spec.whatwg.org/#body-mixin).

## Common API Methods

This section documents our most commonly used API methods. Additional APIs are documented in their own files within the [docs](./docs/) folder and are accessible via the navigation list on the left side of the docs site.

### `undici.request([url, options]): Promise`

Arguments:

* **url** `string | URL | UrlObject`
* **options** [`RequestOptions`](./docs/docs/api/Dispatcher.md#parameter-requestoptions)
  * **dispatcher** `Dispatcher` - Default: [getGlobalDispatcher](#undicigetglobaldispatcher)
  * **method** `String` - Default: `PUT` if `options.body`, otherwise `GET`

Returns a promise with the result of the `Dispatcher.request` method.

Calls `options.dispatcher.request(options)`.

See [Dispatcher.request](./docs/docs/api/Dispatcher.md#dispatcherrequestoptions-callback) for more details, and [request examples](./docs/examples/README.md) for examples.

### `undici.stream([url, options, ]factory): Promise`

Arguments:

* **url** `string | URL | UrlObject`
* **options** [`StreamOptions`](./docs/docs/api/Dispatcher.md#parameter-streamoptions)
  * **dispatcher** `Dispatcher` - Default: [getGlobalDispatcher](#undicigetglobaldispatcher)
  * **method** `String` - Default: `PUT` if `options.body`, otherwise `GET`
* **factory** `Dispatcher.stream.factory`

Returns a promise with the result of the `Dispatcher.stream` method.

Calls `options.dispatcher.stream(options, factory)`.

See [Dispatcher.stream](./docs/docs/api/Dispatcher.md#dispatcherstreamoptions-factory-callback) for more details.

### `undici.pipeline([url, options, ]handler): Duplex`

Arguments:

* **url** `string | URL | UrlObject`
* **options** [`PipelineOptions`](./docs/docs/api/Dispatcher.md#parameter-pipelineoptions)
  * **dispatcher** `Dispatcher` - Default: [getGlobalDispatcher](#undicigetglobaldispatcher)
  * **method** `String` - Default: `PUT` if `options.body`, otherwise `GET`
* **handler** `Dispatcher.pipeline.handler`

Returns: `stream.Duplex`

Calls `options.dispatch.pipeline(options, handler)`.

See [Dispatcher.pipeline](./docs/docs/api/Dispatcher.md#dispatcherpipelineoptions-handler) for more details.

### `undici.connect([url, options]): Promise`

Starts two-way communications with the requested resource using [HTTP CONNECT](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/CONNECT).

Arguments:

* **url** `string | URL | UrlObject`
* **options** [`ConnectOptions`](./docs/docs/api/Dispatcher.md#parameter-connectoptions)
  * **dispatcher** `Dispatcher` - Default: [getGlobalDispatcher](#undicigetglobaldispatcher)
* **callback** `(err: Error | null, data: ConnectData | null) =&gt; void` (optional)

Returns a promise with the result of the `Dispatcher.connect` method.

Calls `options.dispatch.connect(options)`.

See [Dispatcher.connect](./docs/docs/api/Dispatcher.md#dispatcherconnectoptions-callback) for more details.

### `undici.fetch(input[, init]): Promise`

Implements [fetch](https://fetch.spec.whatwg.org/#fetch-method).

* https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/fetch
* https://fetch.spec.whatwg.org/#fetch-method

Basic usage example:

```js
import { fetch } from &#039;undici&#039;


const res = await fetch(&#039;https://example.com&#039;)
const json = await res.json()
console.log(json)
```

You can pass an optional dispatcher to `fetch` as:

```js
import { fetch, Agent } from &#039;undici&#039;

const res = await fetch(&#039;https://example.com&#039;, {
  // Mocks are also supported
  dispatcher: new Agent({
    keepAliveTimeout: 10,
    keepAliveMaxTimeout: 10
  })
})
const json = await res.json()
console.log(json)
```

#### `request.body`

A body can be of the following types:

- ArrayBuffer
- ArrayBufferView
- AsyncIterables
- Blob
- Iterables
- String
- URLSearchParams
- FormData

In this implementation of fetch, ```request.body``` now accepts ```Async Iterables```. It is not present in the [Fetch Standard](https://fetch.spec.whatwg.org).

```js
import { fetch } from &#039;undici&#039;

const data = {
  async *[Symbol.asyncIterator]() {
    yield &#039;hello&#039;
    yield &#039;world&#039;
  },
}

await fetch(&#039;https://example.com&#039;, { body: data, method: &#039;POST&#039;, duplex: &#039;half&#039; })
```

[FormData](https://developer.mozilla.org/en-US/docs/Web/API/FormData) besides text data and buffers can also utilize streams via [Blob](https://developer.mozilla.org/en-US/docs/Web/API/Blob) objects:

```js
import { openAsBlob } from &#039;node:fs&#039;

const file = await openAsBlob(&#039;./big.csv&#039;)
const body = new FormData()
body.set(&#039;file&#039;, file, &#039;big.csv&#039;)

await fetch(&#039;http://example.com&#039;, { method: &#039;POST&#039;, body })
```

#### `request.duplex`

- `&#039;half&#039;`

In this implementation of fetch, `request.duplex` must be set if `request.body` is `ReadableStream` or `Async Iterables`, however, even though the value must be set to `&#039;half&#039;`, it is actually a _full_ duplex. For more detail refer to the [Fetch Standard](https://fetch.spec.whatwg.org/#dom-requestinit-duplex).

#### `response.body`

Nodejs has two kinds of streams: [web streams](https://nodejs.org/api/webstreams.html), which follow the API of the WHATWG web standard found in browsers, and an older Node-specific [streams API](https://nodejs.org/api/stream.html). `response.body` returns a readable web stream. If you would prefer to work with a Node stream you can convert a web stream using `.fromWeb()`.

```js
import { fetch } from &#039;undici&#039;
import { Readable } from &#039;node:stream&#039;

const response = await fetch(&#039;https://example.com&#039;)
const readableWebStream = response.body
const readableNodeStream = Readable.fromWeb(readableWebStream)
```

## Specification Compliance

This section documents parts of the [HTTP/1.1](https://www.rfc-editor.org/rfc/rfc9110.html) and [Fetch Standard](https://fetch.spec.whatwg.org) that Undici does
not support or does not fully implement.

#### CORS

Unlike browsers, Undici does not implement CORS (Cross-Origin Resource Sharing) checks by default. This means:

- No preflight requests are automatically sent for cross-origin requests
- No validation of `Access-Control-Allow-Origin` headers is performed
- Requests to any origin are allowed regardless of the source

This behavior is intentional for server-side environments where CORS restrictions are typically unnecessary. If your application requires CORS-like protections, you will need to implement these checks manually.

#### Garbage Collection

* https://fetch.spec.whatwg.org/#garbage-collection

The [Fetch Standard](https://fetch.spec.whatwg.org) allows users to skip consuming the response body by relying on
[garbage collection](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Memory_Management#garbage_collection) to release connection resources. Undici does not do the same. Therefore, it is important to always either consume or cancel the response body.

Garbage collection in Node is less aggressive and deterministic
(due to the lack of clear idle periods that browsers have through the rendering refresh rate)
which means that leaving the release of connection resources to the garbage collector can lead
to excessive connection usage, reduced performance (due to less connection re-use), and even
stalls or deadlocks when running out of connections.

```js
// Do
const { body, headers } = await fetch(url);
for await (const chunk of body) {
  // force consumption of body
}

// Do not
const { headers } = await fetch(url);
```

The same applies for `request` too:
```js
// Do
const { body, headers } = await request(url);
await res.body.dump(); // force consumption of body

// Do not
const { headers } = await request(url);
```

However, if you want to get only headers, it might be better to use `HEAD` request method. Usage of this method will obviate the need for consumption or cancelling of the response body. See [MDN - HTTP - HTTP request methods - HEAD](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/HEAD) for more details.

```js
const headers = await fetch(url, { method: &#039;HEAD&#039; })
  .then(res =&gt; res.headers)
```

#### Forbidden and Safelisted Header Names

* https://fetch.spec.whatwg.org/#cors-safelisted-response-header-name
* https://fetch.spec.whatwg.org/#forbidden-header-name
* https://fetch.spec.whatwg.org/#forbidden-response-header-name
* https://github.com/wintercg/fetch/issues/6

The [Fetch Standard](https://fetch.spec.whatwg.org) requires implementations to exclude certain headers from requests and responses. In browser environments, some headers are forbidden so the user agent remains in full control over them. In Undici, these constraints are removed to give more control to the user.

#### `undici.upgrade([url, options]): Promise`

Upgrade to a different protocol. See [MDN - HTTP - Protocol upgrade mechanism](https://developer.mozilla.org/en-US/docs/Web/HTTP/Protocol_upgrade_mechanism) for more details.

Arguments:

* **url** `string | URL | UrlObject`
* **options** [`UpgradeOptions`](./docs/docs/api/Dispatcher.md#parameter-upgradeoptions)
  * **dispatcher** `Dispatcher` - Default: [getGlobalDispatcher](#undicigetglobaldispatcher)
* **callback** `(error: Error | null, data: UpgradeData) =&gt; void` (optional)

Returns a promise with the result of the `Dispatcher.upgrade` method.

Calls `options.dispatcher.upgrade(options)`.

See [Dispatcher.upgrade](./docs/docs/api/Dispatcher.md#dispatcherupgradeoptions-callback) for more details.

### `undici.setGlobalDispatcher(dispatcher)`

* dispatcher `Dispatcher`

Sets the global dispatcher used by Common API Methods. Global dispatcher is shared among compatible undici modules,
including undici that is bundled internally with node.js.

### `undici.getGlobalDispatcher()`

Gets the global dispatcher used by Common API Methods.

Returns: `Dispatcher`

### `undici.setGlobalOrigin(origin)`

* origin `string | URL | undefined`

Sets the global origin used in `fetch`.

If `undefined` is passed, the global origin will be reset. This will cause `Response.redirect`, `new Request()`, and `fetch` to throw an error when a relative path is passed.

```js
setGlobalOrigin(&#039;http://localhost:3000&#039;)

const response = await fetch(&#039;/api/ping&#039;)

console.log(response.url) // http://localhost:3000/api/ping
```

### `undici.getGlobalOrigin()`

Gets the global origin

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[semantic-release/semantic-release]]></title>
            <link>https://github.com/semantic-release/semantic-release</link>
            <guid>https://github.com/semantic-release/semantic-release</guid>
            <pubDate>Sat, 28 Jun 2025 00:04:25 GMT</pubDate>
            <description><![CDATA[📦🚀 Fully automated version management and package publishing]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/semantic-release/semantic-release">semantic-release/semantic-release</a></h1>
            <p>📦🚀 Fully automated version management and package publishing</p>
            <p>Language: JavaScript</p>
            <p>Stars: 22,154</p>
            <p>Forks: 1,743</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot; style=&quot;border-bottom: none;&quot;&gt;📦🚀 semantic-release&lt;/h1&gt;
&lt;h3 align=&quot;center&quot;&gt;Fully automated version management and package publishing&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/semantic-release/semantic-release/discussions&quot;&gt;
    &lt;img alt=&quot;Join the community on GitHub Discussions&quot; src=&quot;https://img.shields.io/badge/Join%20the%20community-on%20GitHub%20Discussions-blue&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/semantic-release/semantic-release/actions/workflows/test.yml&quot;&gt;
    &lt;img alt=&quot;Build states&quot; src=&quot;https://github.com/semantic-release/semantic-release/actions/workflows/test.yml/badge.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://securityscorecards.dev/viewer/?uri=github.com/semantic-release/semantic-release&quot;&gt;
    &lt;img alt=&quot;OpenSSF Scorecard&quot; src=&quot;https://api.securityscorecards.dev/projects/github.com/semantic-release/semantic-release/badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;#badge&quot;&gt;
    &lt;img alt=&quot;semantic-release: angular&quot; src=&quot;https://img.shields.io/badge/semantic--release-angular-e10079?logo=semantic-release&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/semantic-release&quot;&gt;
    &lt;img alt=&quot;npm latest version&quot; src=&quot;https://img.shields.io/npm/v/semantic-release/latest.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/semantic-release&quot;&gt;
    &lt;img alt=&quot;npm next version&quot; src=&quot;https://img.shields.io/npm/v/semantic-release/next.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/semantic-release&quot;&gt;
    &lt;img alt=&quot;npm beta version&quot; src=&quot;https://img.shields.io/npm/v/semantic-release/beta.svg&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

**semantic-release** automates the whole package release workflow including: determining the next version number, generating the release notes, and publishing the package.

This removes the immediate connection between human emotions and version numbers, strictly following the [Semantic Versioning](http://semver.org) specification and communicating the **impact** of changes to consumers.

&gt; Trust us, this will change your workflow for the better. – [egghead.io](https://egghead.io/lessons/javascript-how-to-write-a-javascript-library-automating-releases-with-semantic-release)

## Highlights

- Fully automated release
- Enforce [Semantic Versioning](https://semver.org) specification
- New features and fixes are immediately available to users
- Notify maintainers and users of new releases
- Use formalized commit message convention to document changes in the codebase
- Publish on different distribution channels (such as [npm dist-tags](https://docs.npmjs.com/cli/dist-tag)) based on git merges
- Integrate with your [continuous integration workflow](docs/recipes/release-workflow/README.md#ci-configurations)
- Avoid potential errors associated with manual releases
- Support any [package managers and languages](docs/recipes/release-workflow/README.md#package-managers-and-languages) via [plugins](docs/usage/plugins.md)
- Simple and reusable configuration via [shareable configurations](docs/usage/shareable-configurations.md)
- Support for [npm package provenance](https://github.com/semantic-release/npm#npm-provenance) that promotes increased supply-chain security via signed attestations on GitHub Actions

## How does it work?

### Commit message format

**semantic-release** uses the commit messages to determine the consumer impact of changes in the codebase.
Following formalized conventions for commit messages, **semantic-release** automatically determines the next [semantic version](https://semver.org) number, generates a changelog and publishes the release.

By default, **semantic-release** uses [Angular Commit Message Conventions](https://github.com/angular/angular/blob/main/contributing-docs/commit-message-guidelines.md).
The commit message format can be changed with the [`preset` or `config` options](docs/usage/configuration.md#options) of the [@semantic-release/commit-analyzer](https://github.com/semantic-release/commit-analyzer#options) and [@semantic-release/release-notes-generator](https://github.com/semantic-release/release-notes-generator#options) plugins.

Tools such as [commitizen](https://github.com/commitizen/cz-cli) or [commitlint](https://github.com/conventional-changelog/commitlint) can be used to help contributors and enforce valid commit messages.

The table below shows which commit message gets you which release type when `semantic-release` runs (using the default configuration):

| Commit message                                                                                                                                                                                   | Release type                                                                                                    |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------- |
| `fix(pencil): stop graphite breaking when too much pressure applied`                                                                                                                             | ~~Patch~~ Fix Release                                                                                           |
| `feat(pencil): add &#039;graphiteWidth&#039; option`                                                                                                                                                       | ~~Minor~~ Feature Release                                                                                       |
| `perf(pencil): remove graphiteWidth option`&lt;br&gt;&lt;br&gt;`BREAKING CHANGE: The graphiteWidth option has been removed.`&lt;br&gt;`The default graphite width of 10mm is always used for performance reasons.` | ~~Major~~ Breaking Release &lt;br /&gt; (Note that the `BREAKING CHANGE: ` token must be in the footer of the commit) |

### Automation with CI

**semantic-release** is meant to be executed on the CI environment after every successful build on the release branch.
This way no human is directly involved in the release process and the releases are guaranteed to be [unromantic and unsentimental](https://github.com/dominictarr/sentimental-versioning#readme).

### Triggering a release

For each new commit added to one of the release branches (for example: `master`, `main`, `next`, `beta`), with `git push` or by merging a pull request or merging from another branch, a CI build is triggered and runs the `semantic-release` command to make a release if there are codebase changes since the last release that affect the package functionalities.

**semantic-release** offers various ways to control the timing, the content and the audience of published releases.
See example workflows in the following recipes:

- [Using distribution channels](docs/recipes/release-workflow/distribution-channels.md#publishing-on-distribution-channels)
- [Maintenance releases](docs/recipes/release-workflow/maintenance-releases.md#publishing-maintenance-releases)
- [Pre-releases](docs/recipes/release-workflow/pre-releases.md#publishing-pre-releases)

### Release steps

After running the tests, the command `semantic-release` will execute the following steps:

| Step              | Description                                                                                                                     |
| ----------------- | ------------------------------------------------------------------------------------------------------------------------------- |
| Verify Conditions | Verify all the conditions to proceed with the release.                                                                          |
| Get last release  | Obtain the commit corresponding to the last release by analyzing [Git tags](https://git-scm.com/book/en/v2/Git-Basics-Tagging). |
| Analyze commits   | Determine the type of release based on the commits added since the last release.                                                |
| Verify release    | Verify the release conformity.                                                                                                  |
| Generate notes    | Generate release notes for the commits added since the last release.                                                            |
| Create Git tag    | Create a Git tag corresponding to the new release version.                                                                      |
| Prepare           | Prepare the release.                                                                                                            |
| Publish           | Publish the release.                                                                                                            |
| Notify            | Notify of new releases or errors.                                                                                               |

## Requirements

In order to use **semantic-release** you need:

- To host your code in a [Git repository](https://git-scm.com)
- Use a Continuous Integration service that allows you to [securely set up credentials](docs/usage/ci-configuration.md#authentication)
- A Git CLI version that meets [our version requirement](docs/support/git-version.md) installed in your Continuous Integration environment
- A [Node.js](https://nodejs.org) version that meets [our version requirement](docs/support/node-version.md) installed in your Continuous Integration environment

## Documentation

- Usage
  - [Getting started](docs/usage/getting-started.md)
  - [Installation](docs/usage/installation.md)
  - [CI Configuration](docs/usage/ci-configuration.md)
  - [Configuration](docs/usage/configuration.md#configuration)
  - [Plugins](docs/usage/plugins.md)
  - [Workflow configuration](docs/usage/workflow-configuration.md)
  - [Shareable configurations](docs/usage/shareable-configurations.md)
- Extending
  - [Plugins](docs/extending/plugins-list.md)
  - [Shareable configuration](docs/extending/shareable-configurations-list.md)
- Recipes
  - [CI configurations](docs/recipes/ci-configurations/README.md)
  - [Git hosted services](docs/recipes/git-hosted-services/README.md)
  - [Release workflow](docs/recipes/release-workflow/README.md)
- Developer guide
  - [JavaScript API](docs/developer-guide/js-api.md)
  - [Plugins development](docs/developer-guide/plugin.md)
  - [Shareable configuration development](docs/developer-guide/shareable-configuration.md)
- Support
  - [Resources](docs/support/resources.md)
  - [Frequently Asked Questions](docs/support/FAQ.md)
  - [Troubleshooting](docs/support/troubleshooting.md)
  - [Node version requirement](docs/support/node-version.md)
  - [Node Support Policy](docs/support/node-support-policy.md)

## Get help

- [GitHub Discussions](https://github.com/semantic-release/semantic-release/discussions)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/semantic-release)
- [Twitter](https://twitter.com/SemanticRelease)

## Badge

Let people know that your package is published using **semantic-release** and which [commit-convention](#commit-message-format) is followed by including this badge in your readme.

[![semantic-release: angular](https://img.shields.io/badge/semantic--release-angular-e10079?logo=semantic-release)](https://github.com/semantic-release/semantic-release)

```md
[![semantic-release: angular](https://img.shields.io/badge/semantic--release-angular-e10079?logo=semantic-release)](https://github.com/semantic-release/semantic-release)
```

## Team

| [![Gregor Martynus](https://github.com/gr2m.png?size=100)](https://github.com/gr2m) | [![Pierre Vanduynslager](https://github.com/pvdlg.png?size=100)](https://github.com/pvdlg) | [![Matt Travi](https://github.com/travi.png?size=100)](https://github.com/travi) |
| ----------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------- |
| [Gregor Martynus](https://github.com/gr2m)                                          | [Pierre Vanduynslager](https://github.com/pvdlg)                                           | [Matt Travi](https://github.com/travi)                                           |

## Alumni

| [![Stephan Bönnemann](https://github.com/boennemann.png?size=100)](https://github.com/boennemann) | [![Rolf Erik Lekang](https://github.com/relekang.png?size=100)](https://github.com/relekang) | [![Johannes Jörg Schmidt](https://github.com/jo.png?size=100)](https://github.com/jo) | [![Finn Pauls](https://github.com/finnp.png?size=100)](https://github.com/finnp) | [![Christoph Witzko](https://github.com/christophwitzko.png?size=100)](https://github.com/christophwitzko) |
| ------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| [Stephan Bönnemann](https://github.com/boennemann)                                                | [Rolf Erik Lekang](https://github.com/relekang)                                              | [Johannes Jörg Schmidt](https://github.com/jo)                                        | [Finn Pauls](https://github.com/finnp)                                           | [Christoph Witzko](https://github.com/christophwitzko)                                                     |

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Kill all humans&quot; src=&quot;media/bender.png&quot;&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[academind/react-complete-guide-course-resources]]></title>
            <link>https://github.com/academind/react-complete-guide-course-resources</link>
            <guid>https://github.com/academind/react-complete-guide-course-resources</guid>
            <pubDate>Sat, 28 Jun 2025 00:04:24 GMT</pubDate>
            <description><![CDATA[React - The Complete Guide Course Resources (Code, Attachments, Slides)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/academind/react-complete-guide-course-resources">academind/react-complete-guide-course-resources</a></h1>
            <p>React - The Complete Guide Course Resources (Code, Attachments, Slides)</p>
            <p>Language: JavaScript</p>
            <p>Stars: 3,235</p>
            <p>Forks: 2,488</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># React - The Complete Guide Course Resources

This repository provides access to code files, code snapshots, slides &amp; other resources that are used or provided by the [React - The Complete Guide](https://acad.link/reactjs) course.

If you&#039;re facing any issues with the code, please post in the course Q&amp;A section.

# Repository Content

- **Code Snapshots:** All code snapshots (starting snapshots, intermediate snapshots, finished snapshots) for the various course sections can be found in the [/code](/code/) folder.
- **Lecture Attachments:** Any standalone code files or other attachments that are mentioned in course lectures (and attached to those lectures) are stored in the [/attachments](/attachments/) folder.
- **Other Resources:** Other resources (like the course slides) can be found in the [/other](/other/) folder.

The **Code Snapshots** and **Lecture Attachments** folders contain one subfolder per course section - this allows you to easily access the resources for a specific course section.

# How To Use Code Snapshots

Code snapshots are primarily provided to allow you to compare your code to mine. The snapshots are taken directly from the course recordings and therefore reflect my code you see in the videos.

Of course, you can also try running those code snapshots on your machine. You&#039;ll need to run `npm install` in the individual snapshot folders, followed by `npm run dev` to start the development server - just as shown in the course.
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[docker/welcome-to-docker]]></title>
            <link>https://github.com/docker/welcome-to-docker</link>
            <guid>https://github.com/docker/welcome-to-docker</guid>
            <pubDate>Sat, 28 Jun 2025 00:04:23 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/docker/welcome-to-docker">docker/welcome-to-docker</a></h1>
            <p></p>
            <p>Language: JavaScript</p>
            <p>Stars: 633</p>
            <p>Forks: 2,128</p>
            <p>Stars today: 0 stars today</p>
            <h2>README</h2><pre># Welcome to Docker

This is a repo for new users getting started with Docker.

You can try it out using the following command.
```
docker run -d -p 8088:80 --name welcome-to-docker docker/welcome-to-docker
```
And open `http://localhost:8088` in your browser.

# Building

Maintainers should see [MAINTAINERS.md](MAINTAINERS.md).

Build and run:
```
docker build -t welcome-to-docker . 
docker run -d -p 8088:3000 --name welcome-to-docker welcome-to-docker
```
Open `http://localhost:8088` in your browser.
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[bgstaal/multipleWindow3dScene]]></title>
            <link>https://github.com/bgstaal/multipleWindow3dScene</link>
            <guid>https://github.com/bgstaal/multipleWindow3dScene</guid>
            <pubDate>Sat, 28 Jun 2025 00:04:22 GMT</pubDate>
            <description><![CDATA[A quick example of how one can "synchronize" a 3d scene across multiple windows using three.js and localStorage]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bgstaal/multipleWindow3dScene">bgstaal/multipleWindow3dScene</a></h1>
            <p>A quick example of how one can "synchronize" a 3d scene across multiple windows using three.js and localStorage</p>
            <p>Language: JavaScript</p>
            <p>Stars: 18,514</p>
            <p>Forks: 2,857</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre># Multiple Window 3D Scene using Three.js

## Introduction
This project demonstrates a unique approach to creating and managing a 3D scene across multiple browser windows using Three.js and localStorage. It&#039;s designed for developers interested in advanced web graphics and window management techniques.

## Features
- 3D scene creation and rendering with Three.js.
- Synchronization of 3D scenes across multiple browser windows.
- Dynamic window management and state synchronization using localStorage.

## Installation
Clone the repository and open `index.html` in your browser to start exploring the 3D scene.

```
git clone https://github.com/bgstaal/multipleWindow3dScene
```
## Usage
The main application logic is contained within `main.js` and `WindowManager.js`. The 3D scene is rendered in `index.html`, which serves as the entry point of the application.

## Structure and Components
- `index.html`: Entry point that sets up the HTML structure and includes the Three.js library and the main script.
- `WindowManager.js`: Core class managing window creation, synchronization, and state management across multiple windows.
- `main.js`: Contains the logic for initializing the 3D scene, handling window events, and rendering the scene.
- `three.r124.min.js`: Minified version of the Three.js library used for 3D graphics rendering.

## Detailed Functionality
- `WindowManager.js` handles the lifecycle of multiple browser windows, including creation, synchronization, and removal. It uses localStorage to maintain state across windows.
- `main.js` initializes the 3D scene using Three.js, manages the window&#039;s resize events, and updates the scene based on window interactions.

## Contributing
Contributions to enhance or expand the project are welcome. Feel free to fork the repository, make changes, and submit pull requests.

## License
This project is open-sourced under the MIT License.

## Acknowledgments
- The Three.js team for their comprehensive 3D library.
- x.com/didntdrinkwater for this readme.

## Contact
For more information and updates, follow [@_nonfigurativ_](https://twitter.com/_nonfigurativ_) on Twitter.
</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
        <item>
            <title><![CDATA[DavidAnson/markdownlint]]></title>
            <link>https://github.com/DavidAnson/markdownlint</link>
            <guid>https://github.com/DavidAnson/markdownlint</guid>
            <pubDate>Sat, 28 Jun 2025 00:04:21 GMT</pubDate>
            <description><![CDATA[A Node.js style checker and lint tool for Markdown/CommonMark files.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DavidAnson/markdownlint">DavidAnson/markdownlint</a></h1>
            <p>A Node.js style checker and lint tool for Markdown/CommonMark files.</p>
            <p>Language: JavaScript</p>
            <p>Stars: 5,229</p>
            <p>Forks: 782</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># markdownlint

&gt; A Node.js style checker and lint tool for Markdown/CommonMark files.

[![npm version][npm-image]][npm-url]
[![License][license-image]][license-url]

## Install

```bash
npm install markdownlint --save-dev
```

## Overview

The [Markdown][markdown] markup language is designed to be easy to read, write,
and understand. It succeeds - and its flexibility is both a benefit and a
drawback. Many styles are possible, so formatting can be inconsistent; some
constructs don&#039;t work well in all parsers and should be avoided.

`markdownlint` is a [static analysis][static-analysis] tool for
[Node.js][nodejs] with a library of rules to enforce standards and consistency
for Markdown files. It was inspired by - and heavily influenced by - Mark
Harrison&#039;s [markdownlint][markdownlint-ruby] for Ruby. The initial rules, rule
documentation, and test cases came from that project.

`markdownlint` uses the [`micromark` parser][micromark] and honors the
[CommonMark][commonmark] specification for Markdown. It additionally supports
popular [GitHub Flavored Markdown (GFM)][gfm] syntax like autolinks and tables
as well as directives, footnotes, and math syntax - all implemented by
[`micromark` extensions][micromark-extensions].

[commonmark]: https://commonmark.org/
[gfm]: https://github.github.com/gfm/
[markdown]: https://en.wikipedia.org/wiki/Markdown
[markdownlint-ruby]: https://github.com/markdownlint/markdownlint
[micromark]: https://github.com/micromark/micromark
[micromark-extensions]: https://github.com/micromark/micromark?tab=readme-ov-file#list-of-extensions
[nodejs]: https://nodejs.org/
[static-analysis]: https://en.wikipedia.org/wiki/Static_program_analysis

### Related

- CLI
  - [markdownlint-cli][markdownlint-cli] command-line interface for Node.js
    ([works with pre-commit][markdownlint-cli-precommit])
  - [markdownlint-cli2][markdownlint-cli2] command-line interface for Node.js
    ([works with pre-commit][markdownlint-cli2-precommit])
- GitHub
  - [GitHub Action for markdownlint-cli2][markdownlint-cli2-action]
  - [GitHub Super-Linter Action][super-linter]
  - [GitHub Actions problem matcher for
    markdownlint-cli][markdownlint-problem-matcher]
- Editor
  - [vscode-markdownlint extension for VS Code][vscode-markdownlint]
  - [Sublime Text markdownlint for Sublime Text][sublimelinter]
  - [coc-markdownlint extension for Vim/Neovim][coc]
  - [flymake-markdownlint-cli2 extension for Emacs][emacs-flymake]
- Tooling
  - [eslint-plugin-markdownlint for the ESLint analyzer][eslint-plugin]
  - [grunt-markdownlint for the Grunt task runner][grunt-markdownlint]
  - [Cake.Markdownlint addin for Cake build automation system][cake]
  - [Lombiq Node.js Extensions for MSBuild (.NET builds)][nodejs-extensions]
- Ruby
  - [markdownlint/mdl gem for Ruby][rubygems-mdl]

[cake]: https://github.com/cake-contrib/Cake.Markdownlint
[coc]: https://github.com/fannheyward/coc-markdownlint
[emacs-flymake]: https://github.com/ewilderj/flymake-markdownlint-cli2
[eslint-plugin]: https://github.com/paweldrozd/eslint-plugin-markdownlint
[grunt-markdownlint]: https://github.com/sagiegurari/grunt-markdownlint
[markdownlint-cli]: https://github.com/igorshubovych/markdownlint-cli
[markdownlint-cli-precommit]: https://github.com/igorshubovych/markdownlint-cli#use-with-pre-commit
[markdownlint-cli2]: https://github.com/DavidAnson/markdownlint-cli2
[markdownlint-cli2-action]: https://github.com/marketplace/actions/markdownlint-cli2-action
[markdownlint-cli2-precommit]: https://github.com/DavidAnson/markdownlint-cli2#pre-commit
[markdownlint-problem-matcher]: https://github.com/xt0rted/markdownlint-problem-matcher
[nodejs-extensions]: https://github.com/Lombiq/NodeJs-Extensions
[rubygems-mdl]: https://rubygems.org/gems/mdl
[sublimelinter]: https://github.com/jonlabelle/SublimeLinter-contrib-markdownlint
[super-linter]: https://github.com/super-linter/super-linter
[vscode-markdownlint]: https://marketplace.visualstudio.com/items?itemName=DavidAnson.vscode-markdownlint

### References

The following specifications are considered authoritative in cases of ambiguity:

- [CommonMark](https://spec.commonmark.org/current/)
- [GitHub Flavored Markdown Spec](https://github.github.com/gfm/)

## Demonstration

[`markdownlint` demo](https://dlaa.me/markdownlint/), an interactive, in-browser
playground for learning and exploring.

## Rules / Aliases

&lt;!-- markdownlint-disable line-length --&gt;

- **[MD001](doc/md001.md)** *heading-increment* - Heading levels should only increment by one level at a time
- **[MD003](doc/md003.md)** *heading-style* - Heading style
- **[MD004](doc/md004.md)** *ul-style* - Unordered list style
- **[MD005](doc/md005.md)** *list-indent* - Inconsistent indentation for list items at the same level
- **[MD007](doc/md007.md)** *ul-indent* - Unordered list indentation
- **[MD009](doc/md009.md)** *no-trailing-spaces* - Trailing spaces
- **[MD010](doc/md010.md)** *no-hard-tabs* - Hard tabs
- **[MD011](doc/md011.md)** *no-reversed-links* - Reversed link syntax
- **[MD012](doc/md012.md)** *no-multiple-blanks* - Multiple consecutive blank lines
- **[MD013](doc/md013.md)** *line-length* - Line length
- **[MD014](doc/md014.md)** *commands-show-output* - Dollar signs used before commands without showing output
- **[MD018](doc/md018.md)** *no-missing-space-atx* - No space after hash on atx style heading
- **[MD019](doc/md019.md)** *no-multiple-space-atx* - Multiple spaces after hash on atx style heading
- **[MD020](doc/md020.md)** *no-missing-space-closed-atx* - No space inside hashes on closed atx style heading
- **[MD021](doc/md021.md)** *no-multiple-space-closed-atx* - Multiple spaces inside hashes on closed atx style heading
- **[MD022](doc/md022.md)** *blanks-around-headings* - Headings should be surrounded by blank lines
- **[MD023](doc/md023.md)** *heading-start-left* - Headings must start at the beginning of the line
- **[MD024](doc/md024.md)** *no-duplicate-heading* - Multiple headings with the same content
- **[MD025](doc/md025.md)** *single-title/single-h1* - Multiple top-level headings in the same document
- **[MD026](doc/md026.md)** *no-trailing-punctuation* - Trailing punctuation in heading
- **[MD027](doc/md027.md)** *no-multiple-space-blockquote* - Multiple spaces after blockquote symbol
- **[MD028](doc/md028.md)** *no-blanks-blockquote* - Blank line inside blockquote
- **[MD029](doc/md029.md)** *ol-prefix* - Ordered list item prefix
- **[MD030](doc/md030.md)** *list-marker-space* - Spaces after list markers
- **[MD031](doc/md031.md)** *blanks-around-fences* - Fenced code blocks should be surrounded by blank lines
- **[MD032](doc/md032.md)** *blanks-around-lists* - Lists should be surrounded by blank lines
- **[MD033](doc/md033.md)** *no-inline-html* - Inline HTML
- **[MD034](doc/md034.md)** *no-bare-urls* - Bare URL used
- **[MD035](doc/md035.md)** *hr-style* - Horizontal rule style
- **[MD036](doc/md036.md)** *no-emphasis-as-heading* - Emphasis used instead of a heading
- **[MD037](doc/md037.md)** *no-space-in-emphasis* - Spaces inside emphasis markers
- **[MD038](doc/md038.md)** *no-space-in-code* - Spaces inside code span elements
- **[MD039](doc/md039.md)** *no-space-in-links* - Spaces inside link text
- **[MD040](doc/md040.md)** *fenced-code-language* - Fenced code blocks should have a language specified
- **[MD041](doc/md041.md)** *first-line-heading/first-line-h1* - First line in a file should be a top-level heading
- **[MD042](doc/md042.md)** *no-empty-links* - No empty links
- **[MD043](doc/md043.md)** *required-headings* - Required heading structure
- **[MD044](doc/md044.md)** *proper-names* - Proper names should have the correct capitalization
- **[MD045](doc/md045.md)** *no-alt-text* - Images should have alternate text (alt text)
- **[MD046](doc/md046.md)** *code-block-style* - Code block style
- **[MD047](doc/md047.md)** *single-trailing-newline* - Files should end with a single newline character
- **[MD048](doc/md048.md)** *code-fence-style* - Code fence style
- **[MD049](doc/md049.md)** *emphasis-style* - Emphasis style
- **[MD050](doc/md050.md)** *strong-style* - Strong style
- **[MD051](doc/md051.md)** *link-fragments* - Link fragments should be valid
- **[MD052](doc/md052.md)** *reference-links-images* - Reference links and images should use a label that is defined
- **[MD053](doc/md053.md)** *link-image-reference-definitions* - Link and image reference definitions should be needed
- **[MD054](doc/md054.md)** *link-image-style* - Link and image style
- **[MD055](doc/md055.md)** *table-pipe-style* - Table pipe style
- **[MD056](doc/md056.md)** *table-column-count* - Table column count
- **[MD058](doc/md058.md)** *blanks-around-tables* - Tables should be surrounded by blank lines
- **[MD059](doc/md059.md)** *descriptive-link-text* - Link text should be descriptive

&lt;!-- markdownlint-restore --&gt;

See [Rules.md](doc/Rules.md) for more details.

### Custom Rules

In addition to built-in rules, custom rules can be used to address
project-specific requirements. To find community-developed rules use
[keyword `markdownlint-rule` on npm][markdownlint-rule].
To implement your own rules, refer to [CustomRules.md](doc/CustomRules.md).

[markdownlint-rule]: https://www.npmjs.com/search?q=keywords:markdownlint-rule

## Tags

Tags group related rules and can be used to enable/disable multiple
rules at once.

- **`accessibility`** - `MD045`, `MD059`
- **`atx`** - `MD018`, `MD019`
- **`atx_closed`** - `MD020`, `MD021`
- **`blank_lines`** - `MD012`, `MD022`, `MD031`, `MD032`, `MD047`
- **`blockquote`** - `MD027`, `MD028`
- **`bullet`** - `MD004`, `MD005`, `MD007`, `MD032`
- **`code`** - `MD014`, `MD031`, `MD038`, `MD040`, `MD046`, `MD048`
- **`emphasis`** - `MD036`, `MD037`, `MD049`, `MD050`
- **`hard_tab`** - `MD010`
- **`headings`** - `MD001`, `MD003`, `MD018`, `MD019`, `MD020`, `MD021`,
  `MD022`, `MD023`, `MD024`, `MD025`, `MD026`, `MD036`, `MD041`, `MD043`
- **`hr`** - `MD035`
- **`html`** - `MD033`
- **`images`** - `MD045`, `MD052`, `MD053`, `MD054`
- **`indentation`** - `MD005`, `MD007`, `MD027`
- **`language`** - `MD040`
- **`line_length`** - `MD013`
- **`links`** - `MD011`, `MD034`, `MD039`, `MD042`, `MD051`, `MD052`, `MD053`,
  `MD054`, `MD059`
- **`ol`** - `MD029`, `MD030`, `MD032`
- **`spaces`** - `MD018`, `MD019`, `MD020`, `MD021`, `MD023`
- **`spelling`** - `MD044`
- **`table`** - `MD055`, `MD056`, `MD058`
- **`ul`** - `MD004`, `MD005`, `MD007`, `MD030`, `MD032`
- **`url`** - `MD034`
- **`whitespace`** - `MD009`, `MD010`, `MD012`, `MD027`, `MD028`, `MD030`,
  `MD037`, `MD038`, `MD039`

## Configuration

Text passed to `markdownlint` is parsed as Markdown, analyzed, and any
issues reported. Two kinds of text are ignored by most rules:

- [HTML comments](https://www.w3.org/TR/html5/syntax.html#comments)
- [Front matter](https://jekyllrb.com/docs/frontmatter/) (see
  `options.frontMatter` below)

Rules can be enabled, disabled, and configured via `options.config`
(described below) to define the expected behavior for a set of inputs.
To enable or disable rules at a particular location within a file, add
one of these markers to the appropriate place (HTML comments don&#039;t
appear in the final markup):

- Disable all rules: `&lt;!-- markdownlint-disable --&gt;`
- Enable all rules: `&lt;!-- markdownlint-enable --&gt;`
- Disable all rules for the current line: `&lt;!-- markdownlint-disable-line --&gt;`
- Disable all rules for the next line: `&lt;!-- markdownlint-disable-next-line --&gt;`
- Disable one or more rules by name: `&lt;!-- markdownlint-disable MD001 MD005 --&gt;`
- Enable one or more rules by name: `&lt;!-- markdownlint-enable MD001 MD005 --&gt;`
- Disable one or more rules by name for the current line:
  `&lt;!-- markdownlint-disable-line MD001 MD005 --&gt;`
- Disable one or more rules by name for the next line:
  `&lt;!-- markdownlint-disable-next-line MD001 MD005 --&gt;`
- Capture the current rule configuration: `&lt;!-- markdownlint-capture --&gt;`
- Restore the captured rule configuration: `&lt;!-- markdownlint-restore --&gt;`

For example:

```markdown
&lt;!-- markdownlint-disable-next-line no-space-in-emphasis --&gt;
space * in * emphasis
```

Or:

```markdown
space * in * emphasis &lt;!-- markdownlint-disable-line no-space-in-emphasis --&gt;
```

Or:

```markdown
&lt;!-- markdownlint-disable no-space-in-emphasis --&gt;
space * in * emphasis
&lt;!-- markdownlint-enable no-space-in-emphasis --&gt;
```

To temporarily disable rule(s), then restore the former configuration:

```markdown
&lt;!-- markdownlint-capture --&gt;
&lt;!-- markdownlint-disable --&gt;
any violations you want
&lt;!-- markdownlint-restore --&gt;
```

The initial configuration is captured by default (as if every document
began with `&lt;!-- markdownlint-capture --&gt;`), so the pattern above can
be expressed more simply:

```markdown
&lt;!-- markdownlint-disable --&gt;
any violations you want
&lt;!-- markdownlint-restore --&gt;
```

Changes take effect starting with the line a comment is on, so the following
has no effect:

```markdown
space * in * emphasis &lt;!-- markdownlint-disable --&gt; &lt;!-- markdownlint-enable --&gt;
```

To apply changes to an entire file regardless of where the comment is located,
the following syntax is supported:

- Disable all rules: `&lt;!-- markdownlint-disable-file --&gt;`
- Enable all rules: `&lt;!-- markdownlint-enable-file --&gt;`
- Disable one or more rules by name: `&lt;!-- markdownlint-disable-file MD001 --&gt;`
- Enable one or more rules by name: `&lt;!-- markdownlint-enable-file MD001 --&gt;`

This can be used to &quot;hide&quot; `markdownlint` comments at the bottom of a file.

In cases where it is desirable to change the configuration of one or
more rules for a file, the following more advanced syntax is supported:

- Configure: `&lt;!-- markdownlint-configure-file { options.config JSON } --&gt;`

For example:

```markdown
&lt;!-- markdownlint-configure-file { &quot;hr-style&quot;: { &quot;style&quot;: &quot;---&quot; } } --&gt;
```

or

```markdown
&lt;!-- markdownlint-configure-file
{
  &quot;hr-style&quot;: {
    &quot;style&quot;: &quot;---&quot;
  },
  &quot;no-trailing-spaces&quot;: false
}
--&gt;
```

These changes apply to the entire file regardless of where the comment is
located. Multiple such comments (if present) are applied top-to-bottom. By
default, content of `markdownlint-configure-file` is assumed to be JSON, but
[`options.configParsers`](#optionsconfigparsers) can be used to support
alternate formats.

## API

### Linting

Asynchronous API via `import { lint } from &quot;markdownlint/async&quot;`:

```javascript
/**
 * Lint specified Markdown files.
 *
 * @param {Options | null} options Configuration options.
 * @param {LintCallback} callback Callback (err, result) function.
 * @returns {void}
 */
function lint(options, callback) { ... }
```

Synchronous API via `import { lint } from &quot;markdownlint/sync&quot;`:

```javascript
/**
 * Lint specified Markdown files.
 *
 * @param {Options | null} options Configuration options.
 * @returns {LintResults} Results object.
 */
function lint(options) { ... }
```

Promise API via `import { lint } from &quot;markdownlint/promise&quot;`:

```javascript
/**
 * Lint specified Markdown files.
 *
 * @param {Options | null} options Configuration options.
 * @returns {Promise&lt;LintResults&gt;} Results object.
 */
function lint(options) { ... }
```

#### options

Type: `Object`

Configures the function. All properties are optional, but at least one
of `files` or `strings` should be set to provide input.

##### options.config

Type: `Object` mapping `String` to `Boolean | Object`

Configures the rules to use.

Object keys are rule names/aliases; object values are the rule&#039;s configuration.
The value `false` disables a rule, `true` enables its default configuration,
and passing an object value customizes that rule. Setting the special `default`
rule to `true` or `false` includes/excludes all rules by default. In the absence
of a configuration object, all rules are enabled. Enabling or disabling a tag
name (ex: `whitespace`) affects all rules having that tag.

The `default` rule is applied first, then keys are processed in order from top
to bottom with later values overriding earlier ones. Keys (including rule names,
aliases, tags, and `default`) are not case-sensitive.

Example:

```json
{
  &quot;default&quot;: true,
  &quot;MD003&quot;: { &quot;style&quot;: &quot;atx_closed&quot; },
  &quot;MD007&quot;: { &quot;indent&quot;: 4 },
  &quot;no-hard-tabs&quot;: false,
  &quot;whitespace&quot;: false
}
```

See [.markdownlint.jsonc](schema/.markdownlint.jsonc) and/or
[.markdownlint.yaml](schema/.markdownlint.yaml) for an example
configuration object with all properties set to the default value.

Sets of rules (known as a &quot;style&quot;) can be stored separately and loaded
as [JSON](https://en.wikipedia.org/wiki/JSON).

Example of referencing a built-in style from JavaScript:

```javascript
const options = {
  &quot;files&quot;: [ &quot;...&quot; ],
  &quot;config&quot;: require(&quot;style/relaxed.json&quot;)
};
```

Example doing so from `.markdownlint.json` via `extends` (more on this below):

```json
{
  &quot;extends&quot;: &quot;markdownlint/style/relaxed&quot;
}
```

See the [style](style) directory for more samples.

See [markdownlint-config-schema.json](schema/markdownlint-config-schema.json)
for the [JSON Schema](https://json-schema.org/) of the `options.config`
object.

See [ValidatingConfiguration.md](schema/ValidatingConfiguration.md) for ways to
use the JSON Schema to validate configuration.

For more advanced scenarios, styles can reference and build upon other styles
via the `extends` keyword and a file path or (installed) package name. The
`readConfig` function can be used to read such aggregate styles from code.

For example, assuming a `base.json` configuration file:

```json
{
  &quot;default&quot;: true
}
```

And a `custom.json` configuration file:

```json
{
  &quot;extends&quot;: &quot;base.json&quot;,
  &quot;line-length&quot;: false
}
```

Then code like the following:

```javascript
const options = {
  &quot;config&quot;: markdownlint.readConfigSync(&quot;./custom.json&quot;)
};
```

Merges `custom.json` and `base.json` and is equivalent to:

```javascript
const options = {
  &quot;config&quot;: {
    &quot;default&quot;: true,
    &quot;line-length&quot;: false
  }
};
```

##### options.configParsers

Type: *Optional* `Array` of `Function` taking (`String`) and returning `Object`

Array of functions to parse the content of `markdownlint-configure-file` blocks.

As shown in the [Configuration](#configuration) section, inline comments can be
used to customize the [configuration object](#optionsconfig) for a document. By
default, the `JSON.parse` built-in is used, but custom parsers can be specified.
Content is passed to each parser function until one returns a value (vs.
throwing an exception). As such, strict parsers should come before flexible
ones.

For example:

```javascript
[ JSON.parse, require(&quot;toml&quot;).parse, require(&quot;js-yaml&quot;).load ]
```

##### options.customRules

Type: `Array` of `Object`

List of custom rules to include with the default rule set for linting.

Each array element should define a rule. Rules are typically exported
by another package, but can be defined locally.

Example:

```javascript
const extraRules = require(&quot;extraRules&quot;);
const options = {
  &quot;customRules&quot;: [ extraRules.one, extraRules.two ]
};
```

See [CustomRules.md](doc/CustomRules.md) for details about authoring
custom rules.

##### options.files

Type: `Array` of `String`

List of files to lint.

Each array element should be a single file (via relative or absolute path);
[globbing](https://en.wikipedia.org/wiki/Glob_%28programming%29) is the
caller&#039;s responsibility.

Example: `[ &quot;one.md&quot;, &quot;dir/two.md&quot; ]`

##### options.frontMatter

Type: `RegExp`

Matches any [front matter](https://jekyllrb.com/docs/frontmatter/)
found at the beginning of a file.

Some Markdown content begins with metadata; the default `RegExp` for
this option ignores common forms of &quot;front matter&quot;. To match differently,
specify a custom `RegExp` or use the value `null` to disable the feature.

The default value:

```javascript
/((^---[^\S\r\n\u2028\u2029]*$[\s\S]+?^---\s*)|(^\+\+\+[^\S\r\n\u2028\u2029]*$[\s\S]+?^(\+\+\+|\.\.\.)\s*)|(^\{[^\S\r\n\u2028\u2029]*$[\s\S]+?^\}\s*))(\r\n|\r|\n|$)/m
```

Ignores [YAML](https://en.wikipedia.org/wiki/YAML),
[TOML](https://en.wikipedia.org/wiki/TOML), an

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>JavaScript</category>
        </item>
    </channel>
</rss>